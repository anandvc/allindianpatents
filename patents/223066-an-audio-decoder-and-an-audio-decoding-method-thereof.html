<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/223066-an-audio-decoder-and-an-audio-decoding-method-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 06:55:23 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 223066:AN AUDIO DECODER AND AN AUDIO DECODING METHOD THEREOF</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">AN AUDIO DECODER AND AN AUDIO DECODING METHOD THEREOF</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A first judging device (121) temporarily judges whether a current processing unit is a stationary noise section from a stationary judgment result of a decoding signal. A second judging device (124) judges whether a current processing unit is a stationary noise section from this temporary judgment result and a periodical judgment result of the decoded signal. Thus, the stationary noise section is exactly detected by discriminating a decoded signal including a stationary audio signal of stationary vowels or the like from a stationary noise.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>DESCRIPTION<br>
SPEECH DECODING APPARATUS AND SPEECH DECODING METHOD<br>
Technical Field<br>
The present invention relates to a speech decoding<br>
apparatus that decodes speech signals encoded at a low<br>
bit rate in a mobile communication system and packet<br>
communication system including internet communications<br>
where the speech signals are encoded and transmitted,<br>
and more particularly, to a CELP (Code Excited Linear<br>
Prediction) speech decoding apparatus that divides the<br>
speech signals to spectral envelope components and<br>
residual components to represent.<br>
Background Art<br>
In fields of digital mobile communications, packet<br>
communications as typified by internet communications<br>
and speech storage, speech coding apparatuses are used<br>
which compress speech information to effectively use the<br>
capacity of transmission path of radio signals and storage<br>
media to encode with high efficiency. Among those,<br>
systems based on CELP (Code Excited Linear Prediction)<br>
system are carried into practice widely at medium and<br>
low bit rates. Techniques of CELP are described in<br>
M.R.Schroeder and B.S.Atal:"Code-Excited Liner<br>
Prediction( CELP) : High-qual i ty Speech at Very Low Bit<br>
Rates", Proc.ICASSP-85,25.1.1, pages 937-940, 1985.<br>
apparatus, it is difficult to detect a stationary noise<br>
region by distinguishing signals such as stationary<br>
vowels that are stationary but are not noises from<br>
stationary noises.<br><br>
Disclosure of Invention<br>
It is an object of the present invention to provide<br>
a speech decoding apparatus that detects stationary noise<br>
signal regions accurately to decode speech signals,<br>
specifically, a speech decoding apparatus and speech<br>
decoding method which enable determination of speech<br>
region or non-speech region, distinguish a periodical<br>
stationary signal from a stationary noise signal like<br>
a white noise using a pitch period and adaptive code gain,<br>
and detect a stationary noise signal region accurately.<br>
The object is achieved by provisionally determining<br>
stationary noise characteristics of a decoded signal,<br>
further determining whether a current processing unit<br>
is a stationary noise region based on the provisional<br>
determination result and a determination result on the<br>
periodicity of the decoded signal, distinguishing the<br>
decoded signal containing a stationary speech signal such<br>
as a stationary vowel from a stationary noise, and<br>
detecting the stationary noise region properly.<br>
Brief Description of Drawings<br>
FIG.1 is a diagram illustrating a configuration of<br>
In the CELP speech coding system, a speech is divided<br>
into frames each with a constant length (about 5 ms to<br>
50 ms) , linear prediction analysis is performed for each<br>
frame, a prediction residual (excitation signal) by<br>
linear prediction for each frame is encoded using an<br>
adaptive code vector and fixed code vector each composed<br>
of a known waveform. The adaptive code vector is selected<br>
from an adaptive codebook that stores excitation vectors<br>
previously generated, and the fixed code vector is<br>
selected from a fixed codebook that stores a predetermined<br>
number of beforehand prepared vectors with predetermined<br>
shapes. As fixed code vectors stored in the fixed<br>
codebook are used random vectors and vectors generated<br>
by arranging a number of pulses at different positions.<br>
 A conventional CELP coding apparatus performs<br>
analysis and quantization of LPC (Liner Predictive<br>
Coefficient), pitch search, fixed codebook search and<br>
gain codebook search using input digital signals, and<br>
transmits LPC code (L) , pitch period (A) , fixed codebook<br>
index (F) and gain codebook index (G) to a decoding<br>
apparatus.<br>
The decoding apparatus decodes LPC code (L) , pitch<br>
period (A), fixed codebook index (F) and gain codebook<br>
index (G), and based on the decoding results, drives a<br>
synthesis filter with the excitation signal to obtain<br>
a decoded speech.<br>
However, in the conventional speech decoding<br><br>
a stationary noise region determining apparatus according<br>
to a first embodiment of the present invention;<br>
FIG.2 is a flow diagram illustrating procedures of<br>
grouping of pitch history;<br>
FIG.3 is a diagram illustrating part of the flow<br>
of mode selection:<br>
FIG. 4 is another diagram illustrating part of the<br>
flow of mode selection:<br>
FIG.5 is a diagram illustrating a configuration of<br>
a stationary noise post-processing apparatus according<br>
to a second embodiment of the present invention;<br>
FIG. 6 is a diagram illustrating a configuration of<br>
a stationary noise post-processing apparatus according<br>
to a third embodiment of the present invention;<br>
FIG. 7 is a diagram illustrating a speech decoding<br>
processing system according to a fourth embodiment of<br>
the present invention;<br>
FIG. 8 is a flow diagram illustrating the flow of<br>
the speech decoding system;<br>
FIG . 9 is a diagram illustrating examples of memories<br>
provided in the speech decoding system and of initial<br>
values of the memories;<br>
FIG.10 is a diagram illustrating the flow of mode<br>
determination processing;<br>
FIG. 11 is a diagram illustrating the flow of<br>
stationary noise addition processing; and<br>
FIG. 12 is a diagram illustrating the flow of scaling.<br>
Best Mode for Carrying Out the Invention<br>
Embodiments of the present invention will be<br>
described below with reference to accompanying drawings.<br>
(First embodiment)<br>
FIG.l illustrates a configuration of a stationary<br>
noise region determining apparatus according to the first<br>
embodiment of the present invention.<br>
A coder (not shown) first performs analysis and<br>
quantization of LPC (Liner Prediction Coefficients),<br>
pitch search, fixed codebook search and gain codebook<br>
search using input digital signals, and transmits LPC<br>
code (L) , pitch period (A) , fixed codebook index (F) and<br>
gain codebook index (G).<br>
Code receiving apparatus 100 receives a coded signal<br>
transmitted from the coder, and divides code L<br>
representing LPC, code A representing an adaptive code<br>
vector, code G representing gain information and code<br>
F representing a fixed code vector from the received signal.<br>
The divided code L, code; A, code G and code F are output<br>
to speech decoding apparatus 101. Specifically, code<br>
L is output to LPC decoder 110, code A is output to adaptive<br>
codebook 111, code G is output to gain codebook 112, and<br>
code F is output to fixed codebook 113.<br>
Speech decoding apparatus 101 will be described<br>
first.<br>
LPC decoder 110 decodes LPC from code L to output<br>
to synthesis filter 117. LPC decoder 110 converts the<br>
decoded LPC into LSP (Line Spectrum Pairs) parameter to<br>
exploit their better interpolation property, and outputs<br>
LSP to inter-subframe variation calculator 119, distance<br>
calculator 120 and average LSP calculator 125 provided<br>
in stationary noise region detecting apparatus 102.<br>
In general, LPC are coded in LSP domain, i.e. code<br>
L is coded LSP, and in the cases, the LPC decoder decodes<br>
LSP and then converts the decoded LSP to LPC. LSP<br>
parameter is one of examples of spectral envelope<br>
parameters representing a spectral envelope component<br>
of a speech signal. The spectral envelope parameters<br>
include PARCOR coefficient or LPC.<br>
Adaptive codebook 111 provided in speech decoding<br>
apparatus 101 updates previously generated excitation<br>
signals to temporarily store as a buffer, and generates<br>
an adaptive code vector using an adaptive codebook index<br>
(pitch period (pitch lag)) obtained by decoding input<br>
code A. The adaptive code vector generated in adaptive<br>
codebook 111 is multiplied by an adaptive code gain in<br>
adaptive code gain multiplier 114 and then output to adder<br>
116. The pitch period obtained in adaptive codebook 111<br>
is output to pitch history analyzer 122 provided in<br>
stationary noise region detecting section 102.<br>
Gain codebook 112 stores a predetermined number of<br>
sets (gain vectors) of adaptive codebook gain and fixed<br>
codebook gain, and outputs an adaptive codebook gain<br>
component (adaptive code gain) to adaptive code gain<br>
multiplier 114 and second determiner 124, and further<br>
outputs a fixed codebook gain component (fixed code gain)<br>
to fixed code gain multiplier 115, where the components<br>
are of a gain vector designated by a gain codebook index<br>
obtained by decoding input code G.<br>
Fixed codebook 113 stores a predetermined number<br>
of fixed code vectors with different shapes, and outputs<br>
a fixed code vector designated by a fixed codebook index<br>
obtained by decoding input code F to fixed code gain<br>
multiplier 115. Fixed code gain multiplier 115<br>
multiplies the fixed code vector by the fixed code gain<br>
to output to adder 116.<br>
Adder 116 adds the adaptive code vector input from<br>
adaptive code gain multiplier 114 and the fixed code vector<br>
input from fixed code gain multiplier 115 to generate<br>
an excitation signal for synthesis filter 117, and outputs<br>
the signal to synthesis filter 117 and adaptive codebook<br>
111 .<br>
Synthesis filter 117 constructs an LPC synthesis<br>
filter using LPC input from LPC decoder 110. Synthesis<br>
filter 117 performs filtering processing using the<br>
excitation signal input from adder 116 as an input to<br>
synthesize a decoded speech signal, and outputs the<br>
synthesized decoded speech signal to post filter 118.<br>
Post filter 118 performs processing such as formant<br>
enhancement and pitch enhancement to improve the<br>
subjective quality on the synthesized signal output from<br>
synthesis filter 117. The speech signal subjected to<br>
the processing is output to as a final post-filter output<br>
signal of speech decoding apparatus 101 to power variation<br>
calculator 123 provided in stationary noise region<br>
detecting apparatus 102.<br>
The decoding processing in speech decoding<br>
apparatus 101 as described above is executed on a<br>
processing unit with a predetermined time (frame of a<br>
few tens of milliseconds) basis or on a processing unit<br>
(subframe) divided from a frame basis. A case will be<br>
described below where processing is executed on a subframe<br>
basis.<br>
Stationary noise region detecting apparatus 102<br>
will be described below. First stationary noise region<br>
detecting section 103 provided in stationary noise region<br>
detecting apparatus 102 is first explained. First<br>
stationary noise region detecting section 103 and second<br>
stationary noise region detecting section 104 perform<br>
mode selection and determines whether a subframe is a<br>
stationary noise region or speech signal region.<br>
LSP output from LPC decoder 110 is output to first<br>
stationary noise region detecting section 103 and<br>
stationary noise characteristic extracting section 105<br>
provided in stationary noise region detecting apparatus<br>
102. LSP input to first stationary noise region<br>
detecting section 103 is input to inter-subframe<br>
variation calculator 119 and distance calculator 120.<br>
Inter-subframe variation calculator 119 calculates<br>
a variation in LSP from an immediately preceding (last)<br>
subframe. Specifically, based on LSP input from LPC<br>
decoder 110, the calculator 119 calculates a difference<br>
in LSP between a current subframe and last subframe for<br>
each order, and outputs the square sum of the differences<br>
as an inter-subf rame variation amount to first determiner<br>
121 and second determiner 124.<br>
In addition, it is preferable to use smoothed version<br>
of LSP in calculating the variation amount, for reducing<br>
effects of the fluctuations of quantization error and<br>
so on. Strong smoothing causes too slow variations<br>
between subframes, and therefore, the smoothing is set<br>
to be weak. For example, when smoothing LSP is defined<br>
as expressed in (Eq.l) , it is preferable to set k at about<br>
0.7 ..<br>
Smoothing LSP [current subframe]<br>
=kxLSP+(1-k)xsmoothing LSP [last subframe]...(Eq.1)<br>
Distance calculator 120 calculates a distance<br>
between average LSP in a previous stationary noise region<br>
input from average LSP calculator 125 and LSP of the<br>
current subframe input from LPC decoder 110, and outputs<br>
the calculation result to first determiner 121. As the<br>
distance between average LSP and LSP of the current<br>
subframe, for example, distance calculator 12 0 calculates<br>
for each order a difference between average LSP input<br>
from average LSP calculator 125 and LSP of the current<br>
sub frame input fromLPC decoder 110, andoutputsthe square<br>
sum of the differences. Distance calculator 120 may<br>
output the differences in LSP calculated for each order<br>
without square summing. Further, in addition to these<br>
values, the calculator 120 may outputs a maximum value<br>
of the differences in LSP calculated for each order. Thus,<br>
by outputting various measures of distance to first<br>
determiner 121, it is possible to improve determination<br>
accuracy in first determiner 121.<br>
Based on the information input from inter-subframe<br>
variation calculator 119 and distance calculator 120,<br>
first determiner 121 determines a degree of the variation<br>
in LSP between subframes, and a similarity (distance)<br>
between LSP of the current subframe and average LSP of<br>
the stationary noise region. Specifically, these<br>
determinations are made using threshold processing.<br>
When it is determined that the variation in LSP between<br>
subframes is small and LSP of the current subframe is<br>
similar to average LSP of the stationary noise region<br>
(i.e. the distance is small), the current subframe is<br>
determined as a stationary noise region. The<br>
determination result (first determination result) is<br>
output to second determiner 124.<br>
In this way, first determiner 121 provisionally<br>
determines whether a current subframe is a stationary<br>
noise region. This determination is made by determining<br>
stationary characteristics of a current subframe based<br>
on a variation amount in LSP between the last subframe<br>
and current subframe, and further determining noise<br>
characteristics of the current subframe based on the<br>
distance between average LSP and LSP of the current<br>
subframe.<br>
However, the determination based on only LSP<br>
sometimes erroneously determines that a periodical<br>
stationary signal such as a stationary vowel or sine wave<br>
is a noise signal. Therefore, second determiner 124<br>
provided in second stationary noise region detecting<br>
section 104 as described below analyzes the periodicity<br>
of the current subframe, and based on the analysis result,<br>
determines whether the current subframe is a stationary<br>
noise region. In other words, since a signal with high<br>
periodicity has a high possibility of being a stationary<br>
vowel or the like (i.e. not noise), second determiner<br>
124 determines such a signal is not a stationary noise<br>
region.<br>
Second stationary noise region detecting section<br>
104 will be described below.<br>
Pitch history analyzer 122 analyzes fluctuations<br>
between subframes in pitch period input from the adaptive<br>
codebook. Specifically, pitch history analyzer 122<br>
temporarily stores pitch periods input from adaptive<br>
codebook 111 corresponding to a predetermined number of<br>
subframes (for example, ten subframes), and performs<br>
grouping on the temporarily stored pitch periods (pitch<br>
periods of last ten subframes including the current<br>
subframe) by the method as illustrated in FIG.2.<br>
The grouping will be described using as an example<br>
a case of performing grouping on pitch periods of last<br>
ten subframes including a current subframe. FIG.2 is<br>
a flow diagram illustrating procedures of performing<br>
the grouping. First, in ST1001, pitch periods are<br>
classified. Specifically, pitch periods with the same<br>
value are sorted into a same class. In other words,<br>
pitch periods with the exactly same value are sorted<br>
into a same class, while a pitch period with even a little<br>
different value is sorted into a different class.<br>
Next, in ST1002, among classified classes, grouping<br>
is performed that classes having close pitch period<br>
values are grouped into a single group. For example,<br>
classes with pitch periods between which differences<br>
are within 1 are sorted into a single group. In performing<br>
the grouping, when there are five classes where mutual<br>
differences in pitch period are within 1 (for example,<br>
classes with pitch periods respectively of 30, 31, 32,<br>
33 and 34) , the five classes may be sorted into a single<br>
group.<br>
In ST1003, as a result of the grouping, a result<br>
of the analysis is output that indicates the number of<br>
groups to which pitch periods in last ten subframes<br>
including the current subframe belong. As the number<br>
of groups indicated by the result of the analysis is<br>
decreased, the possibility is increased that the decoded<br>
speech signal is periodical, while as the number of groups<br>
is increased, the possibility is increased that the<br>
decoded speech signal is not periodical. Accordingly,<br>
when the decoded speech signal is stationary, it is<br>
possible to use the result of the analysis as a parameter<br>
indicative of periodical stationary signal<br>
characteristics (periodicity of a stationary noise).<br>
Power variation calculator 123 receives as its<br>
inputs the post-filter output signal input from post<br>
filter 118 and average power information of the<br>
stationary noise region input from average noise power<br>
calculator 126. Power variation calculator 123 obtains<br>
the power of the post-filter output signal input from<br>
post filter 118, and calculates the ratio (power ratio)<br>
of the obtained power of the post-filter output signal<br>
to the average power of the stationary noise region.<br>
The power ratio is output to second determiner 124 and<br>
average noise power calculator 126. The power<br>
information of the post-filter output signal is also<br>
output to average noise power calculator 126. When the<br>
power (current signal power) of the post-filter output<br>
signal output from post, filter 118 is larger than the<br>
average power of the stationary noise region, there is<br>
a possibility that the current sub frame is a speech region.<br>
The average power of the stationary noise region and<br>
the power of the post-filter output signal output from<br>
post filter 118 are used as parameters to detect, for<br>
example, onset regions of a speech that is not detected<br>
using other parameters. In addition, power variation<br>
calculator 123 may calculate a difference in the power<br>
to use as a parameter, instead of the ratio of the power<br>
of the post-filter output signal to the average power<br>
of the stationary noise region.<br>
As described above, to second determiner 124<br>
are input pitch history analysis result (the number of<br>
groups) in pitch history analyzer 122 and the adaptive<br>
code gain obtained in gain codebook 112 . Using the input<br>
information, second determiner 124 determines the<br>
periodicity of the post-filter output signal. To second<br>
determiner 124 are further input the first determination<br>
result in first determiner 121, the ratio of the power<br>
of the current subframe to the average power of the<br>
stationary noise region calculated in power variation<br>
calculator 123, and the inter-subframe variation amount<br>
in LSP calculated in inter-subframe variation calculator<br>
119. Based on the input information, the first<br>
determination result, and the determination result on<br>
the above-mentioned periodicity, second determiner 124<br>
determines whether the current subframe is a stationary<br>
noise region, and outputs the determination result to<br>
a processing apparatus provided downstream. The<br>
determination result is also output to average LSP<br>
calculator 125 and average noise power calculator 126.<br>
In addition, it may be possible to provide either code<br>
receiving apparatus 100, speech decoding apparatus 101<br>
or stationary noise region detecting apparatus 102 with<br>
a decoding section that decodes information indicative<br>
of whether a state is a speech stationary state contained<br>
in the received coded, and outputs the information<br>
indicative of whether a state is a speech stationary state<br>
to second determiner 124.<br>
Stationary noise characteristic extracting section<br>
105 will be described below.<br>
Average LSP calculator 125 receives as its inputs<br>
the determination result from second determiner 124, and<br>
LSP of the current subframe from speech decoding apparatus<br>
101 (more specifically, LPC decoder 110) . Only when the<br>
determination result indicates a stationary noise region,<br>
average LSP calculator 125 updates the average LSP in<br>
the stationary noise region using the input LSP of the<br>
current subframe. The average LSP is updated, for<br>
example, using the AR smoothing equation. The updated<br>
average LSP is output to distance calculator 120.<br>
Average noise power calculator 126 receives as its<br>
inputs the determination result from second determiner<br>
124, and the power of the post-filter output signal and<br>
the power ratio (the power of the post-filter output<br>
signal/ the average power of the stationary noise region)<br>
from power variation calculator 123 . In the case where<br>
the determination result from second determiner 124<br>
indicates a stationary noise region, and in the case<br>
where (the determination result does not indicate a<br>
stationary noise region, but) the power ratio is smaller<br>
than a predetermined threshold (the power of the<br>
post-filter output signal of the current subframe is<br>
smaller than the average power of the stationary noise<br>
region) , average noise power calculator 126 updates the<br>
average power (average noise power) of the stationary<br>
noise region using the input post-filter output signal<br>
power. The average noise power is updated, for example,<br>
using the AR smoothing equation . In this case, by adding<br>
control of decreasing the smoothing as the power ratio<br>
is decreased (so that the post-filter output signal power<br>
of the current subframe tends to be reflected), it is<br>
possible to decrease a level of the average noise power<br>
promptly even when the: background noise level decreases<br>
rapidly in a speech region. The updated average noise<br>
power is output to power variation calculator 123.<br>
In the above-mentioned configuration, LPC, LSP and<br>
average LSP are parameters indicative of a spectral<br>
envelope component of a speech signal, while the adaptive<br>
code vector, noise code vector, adaptive code gain and<br>
noise code gain are parameters indicative of a residual<br>
component of the speech signal. Parameters indicative<br>
of a spectral envelope component and parameters<br>
indicative of a residual component are not limited to<br>
the above-mentioned information.<br>
Procedures of the processing will, be described below<br>
in first determiner 121, second determiner 124, and<br>
stationary noise characteristic extracting section 105<br>
with reference to FIGs.3 and 4. In FIGs.3 and 4,<br>
processing of ST1101 to ST1107 is principally performed<br>
in first stationary noise region detecting section 103,<br>
processing of ST1108 to ST1117 is principally performed<br>
in second stationary noise region detecting section 104,<br>
and processing of ST1118 to ST1120 is principally<br>
performed in stationary noise characteristic extracting<br>
section 105.<br>
In ST1101, LSP of a current subframe is calculated,<br>
and the calculated LSP undergoes the smoothing as<br>
expressedby (Eg.l) as described previously. In ST1102,<br>
a difference (variation amount) in LSP between the<br>
current subframe and the last (immediately preceding)<br>
subframe is calculated. The processing of ST1101 and<br>
ST1102 is performed in inter-subframe variation<br>
calculator 119 as described previously.<br>
An example of the method of calculating the variation<br>
amount in LSP in inter-subframe variation calculator 119<br>
is indicated in (Eq.l' ) , (Eq.2) and (Eq.3) . (Eq.l' ) is<br>
an equation to perform smoothing on LSP of the current<br>
subframe, (Eq.2) is an equation to calculate the square<br>
sum of differences in LSP subjected to the smoothing<br>
between subframes, and (Eq.3) is an equation to further<br>
perform smoothing on the square sum of differences in<br>
LSP between subframes. L'i(t) represents an ith-order<br>
smoothed LSP parameter in a tth subframe, Li(t) represents<br>
an ith-order LSP parameter in the tth subframe, DL(t)<br>
represents an LSP variation amount (the square sum of<br>
differences between subframes) in the tth subframe,<br>
DL' (t) represents a smoothed version of LSP variation<br>
amount in the tth subframe, and p represents a LSP (LPC)<br>
analysis order. In this example, inter-subframe<br>
variation calculator 119 obtains DL' (t) using (Eq.l' ) ,<br>
(Eq.2) and (Eq.3), and the obtained DL'(t) is used as<br>
the inter-subframe variation amount in LSP in mode<br>
determination.<br><br>
In ST1103, distance calculator 120 calculates a<br>
distance between LSP of the current subframe and average<br>
LSP in the previous noise region. (Eq.4) and (Eq.5)<br>
indicate a specific example of distance calculation in<br>
distance calculator 120. (Eq.4) defines the distance<br>
between the average LSP in the previous noise region and<br>
LSP of the current subframe as the square sum of<br>
differences of all the orders, and (Eq.5) defines the<br>
distance as the square of only a difference of the order<br>
where the difference is the largest. LNi is the average<br>
LSP in the previous noise region, and is updated in a<br>
noise region, for example, using (Eq.6) on a subframe<br>
basis. In this example, distance calculator 120 obtains<br>
D(t) and DX(t) using (Eq.4), (Eq.5) and (Eq.6), and<br>
obtained D(t) and DX(t) are used as information of the<br>
distance from LSP of the stationary noise region in mode<br>
determination.<br><br>
In ST1104, power variation calculator 123<br>
calculates the power of the post-filter output signal<br>
(output signal from post filter 118). The calculation<br>
of the power is performed in power variation calculator<br>
123 as described previously, and more specifically, the<br>
power is obtained using (Eq.7), for example. In (Eq.7),<br>
S (i) is the post-filter output signal, and N is the length<br>
of a subframe. Since the power calculation in ST1104<br>
is performed in power variation calculator 123 provided<br>
in second stationary noise region detecting section 104<br>
as illustrated in FIG.l, it is only required to perform<br>
the power calculation prior to ST1108, and the timing<br>
of power calculation is not limited to a position of<br>
ST1104.<br><br>
InST 1105, determination is made on stationary noise<br>
characteristics of a decoded signal. Specifically, it<br>
is determined whether the variation amount calculated<br>
in ST 1102 is small in value and the distance calculated<br>
in ST 1103 is small in value. In other words, a threshold<br>
is set with respect to each of the variation amount<br>
calculated in ST1102 and distance calculated in ST1103,<br>
and when the variation amount calculated in ST1102 is<br>
smaller than the set threshold and the distance calculated<br>
in ST1103 is also smaller than the set threshold, the<br>
stationary noise characteristics are high and the<br>
processing flow shifts to ST1107. For example, with<br>
respect to DL'D and DX as described previously, when LSP<br>
is normalized in a range of 0.0 to 1.0, using thresholds<br>
as described below enables the determination with high<br>
accuracy.<br>
Threshold for DL: 0.0004<br>
Threshold for D : 0.003+D'<br>
Threshold for DX: 0.0015<br>
D' is an average value of D in a noise region, and<br>
for example, is calculated using (Eq.8) in anoise region.<br><br>
Since LNi that is the average LSP in the previous<br>
noise region has an adequately reliable value only when<br>
the noise region with a sufficient time somewhat (for<br>
example, corresponding to about 20 subframes) is<br>
available, D and DX are not used in the determination<br>
on stationary noise characteristics in ST1005 when the<br>
previous noise region is smaller than a predetermined<br>
time length (for example, 20 subframes).<br>
In ST1107, the current subframe is determined as<br>
a stationary noise region, and the processing flow shifts<br>
to ST1108. Meanwhile, when either the variation<br>
calculated in ST1102 or the distance calculated in ST1103<br>
is larger than the threshold, the current subframe is<br>
determined to have low stationary characteristics and<br>
the processing flow shifts to ST1106. In ST1106, it is<br>
determined that the subframe is not a stationary noise<br>
region ( in other words , speech region) , and the proces sing<br>
flow shifts to ST1110.<br>
In ST1108, it is determined whether the power of<br>
the current subframe is larger than the average power<br>
of the pervious stationary noise region. Specifically,<br>
a threshold is set with respect to an output result of<br>
power variation calculator 123 (the ratio of the power<br>
of the post-filter output signal to the average power<br>
of the stationary noise region), and when the ratio of<br>
the power of the post-filter output signal to the average<br>
power of the stationary noise region is larger than the<br>
set threshold, the processing flow shifts to ST1109, and<br>
in ST1109 the current subframe is corrected in<br>
determination to be a speech region.<br>
As a specific value of the threshold using 2.0 (i.e.<br>
the processing flow shifts to ST1109 when the power P<br>
of the post-filter output signal obtained using (Eq.7)<br>
exceeds twice the average power PN' of the stationary<br>
noise region obtained in the noise region, average power<br>
PN' is updated for each subframe during the stationary<br>
noise region, for example, using (Eq.9)) enables the<br>
determination with high accuracy.<br>
PN'=0.9xPN'+0.1xP ...(Eq.9)<br>
Meanwhile, in the case where the power variation is smaller<br>
than the set threshold, the processing flow shifts to<br>
ST1112. In this case, the determination result inST1107<br>
is kept, and the current subframe is still determined<br>
as a stationary noise region.<br>
Next, in ST1110, it is checked how long the<br>
stationary state lasts and whether the stationary state<br>
is a stationary voiced speech. Then, when the current<br>
subframe is not a stationary voiced speech and the<br>
stationary state has lasted for a predetermined time<br>
duration, the processing flow proceeds to ST1111, and<br>
in ST1111 the current subframe is re-determined as a<br>
stationary noise region.<br>
Specifically, whether the current subframe is in<br>
a stationary state is determined using the output<br>
(inter-subframe variation amount) of inter-subframe<br>
variation calculator 119. In other words, when the<br>
inter-subframe variation amount obtained in ST1102 is<br>
small (smaller than the predetermined threshold (for<br>
example, the same value as the threshold used in ST1105) ) ,<br>
the current subframe is determined as the stationary state.<br>
Thus, when the stationary noise state is determined, it<br>
is checked how long the state has lasted.<br>
The check on whether the current subframe is a<br>
stationary voiced speech is performed based on<br>
information indicative of whether the current subframe<br>
is the stationary voiced speech provided from stationary<br>
noise region detecting apparatus 102 . For example, when<br>
the transmitted code information includes such<br>
information as the mode information, it is check whether<br>
the current subframe is a stationary voiced speech, using<br>
the decoded mode information. Otherwise, a section that<br>
determines speech stationary characteristics provided<br>
in stationary noise region detecting apparatus 102<br>
outputs such information, and using the information, the<br>
stationary voiced speech is checked.<br>
As a result of the check, in the case where the<br>
stationary state has lasted for a predetermined time<br>
duration (for example, 20 subframes or more) and is not<br>
the stationary voiced speech, the current subframe is<br>
re-determined as a stationary noise region in ST1111 and<br>
the processing flow shifts to ST1112 even when it is<br>
determined that the power variation is large in ST1108.<br>
On the other hand, when the determination result in ST1110<br>
is "No" (a case of speech stationary region or a case<br>
where a stationary state has not lasted for a predetermined<br>
time duration) , the determination result that the current<br>
subframe is a speech region is kept and the processing<br>
flow shifts to ST1114.<br>
Next, when it is determined that the current subframe<br>
is a stationary noise region in processes up to this point,<br>
whether the periodicity of the decoded signal is high<br>
is determined in ST1112. Specifically, based on the<br>
adaptive code gain input from speech decoding apparatus<br>
101 (more specifically, gain codebook 112) and pitch<br>
history analysis result input from pitch history analyzer<br>
122, second determiner 124 determines the periodicity<br>
of the decoded signal in the current subframe. In this<br>
case, as an adaptive code gain, it is preferable to use<br>
a smoothed version in order for the variation between<br>
subframes to be smoothed.<br>
The determination on the periodicity is made, for<br>
example, by setting a threshold with respect to the<br>
smoothed adaptive code gain, and when the smoothed<br>
adaptive code gain exceeds the predetermined threshold,<br>
it is determined that the periodicity is high and the<br>
processing flow shifts to ST1113 . InST1113, the current<br>
subframe is re-determined as a speech region.<br>
Further, since the possibility is higher that<br>
periodical signals are continued as the number of groups<br>
is smaller to which pitch periods in previous subframes<br>
belong in the pitch history analysis result, the<br>
periodicity is determined based on the number of groups.<br>
For example, when pitch periods of previous ten subframes<br>
are sorted into groups of three or less, since the<br>
possibility is high of a region where the periodical signal<br>
lasts, the processing flow shifts to ST1113, and the<br>
current subframe is re-determined to be a speech region<br>
(not a stationary noise region).<br>
When the determination result in ST1112 indicates<br>
"No" (the smoothed adaptive code gain is smaller than<br>
the predetermined threshold and previous pitch periods<br>
are sorted into a large number of groups in the pitch<br>
history analysis result), the determination result<br>
indicative of the stationary noise region is maintained<br>
and the processing flow shifts to ST1115.<br>
When the determination result indicates a speech<br>
region in processes up to this point, the processing flow<br>
shifts to ST1114 and a hangover counter is set for the<br>
predetermined number of hangover subframes (for example,<br>
10) . The hangover counter is set for the number of<br>
hangover frames as an initial value, and is decremented<br>
by 1 whenever a stationary noise region is determined<br>
according to the processing of ST1101 to ST1113. Then,<br>
when the hangover counter is "0", the current subframe<br>
is finally determined as a stationary noise region in<br>
the method of determining a stationary noise region.<br>
When the determination result indicates a noise<br>
stationary region in processes up to this point, the<br>
processing flow shifts to ST1115 and it is checked whether<br>
the hangover counter is within a hangover range ("1" to<br>
"the number of hangover frames"). In other words, it<br>
is checked whether the hangover counter is "0". When<br>
the hangover counter is within the hangover range, (in<br>
a range from "l" to "the number of hangover frames"),<br>
the processing flow shifts to ST1116 where the<br>
determination result is corrected to be a speech region<br>
and the processing flow shifts to ST1117. In ST1117,<br>
the hangover counter is decremented by 1. When the<br>
counter is not in the hangover range (is "0") , the<br>
determination result indicative of a stationary noise<br>
region is maintained and the processing flow shifts to<br>
S T111 8 .<br>
When the determination result indicates the<br>
stationary noise region, average LSP calculator 125<br>
updates the average LSP in the stationary noise region<br>
in ST1118. The update is performed, for example, using<br>
(Eq.6) when the determination result indicates the<br>
stationary noise region, while the previous value is<br>
maintained without being updated when the determination<br>
result does not indicate the stationary noise region.<br>
In addition, when the time duration previously determined<br>
as a stationary noise region is short, the smoothing<br>
coefficient, 0.95, in (Eq.6) may be decreased.<br>
In ST1119, average noise power calculator 126<br>
updates the average noise power. The update is performed,<br>
for example, using (Eq.9) when the determination result<br>
indicates the stationary noise region, while the previous<br>
value is maintained without being updated when the<br>
determination result does not indicate the stationary<br>
noise region. However, when the determination result<br>
does not indicate the stationary noise region, but the<br>
power of the current post-filter output power is smaller<br>
than the average noise power, the average noise power<br>
is updated using the same equation as (Eq.9) except the<br>
smoothing coefficient that is smaller than 0 . 9 to decrease<br>
the average noise power. By performing such update, it<br>
is possible to handle the cases where the background noise<br>
level suddenly decreases during a speech region.<br>
Finally, in ST1120, second determiner 124 outputs<br>
the determination result, average LSP calculator 125<br>
outputs the updated average LSP, and average noise power<br>
calculator 126 outputs the updated average noise power.<br>
As described above, according to this embodiment,<br>
even when it is determined that a current subframe is<br>
a stationary noise region by judging stationary<br>
characteristics using LSP, a degree of periodicity of<br>
the current subframe is examined (determined) using the<br>
adaptive code gain and pitch period, and based on the<br>
degree of periodicity, it is checked again whether the<br>
current subframe is a stationary noise region.<br>
Accordingly, it is possible to make an accurate<br>
determination on signals such as sine waves and stationary<br>
vowels that are stationary but not noises.<br>
(Second embodiment)<br>
FIG.5 illustrates a configuration of a stationary<br>
noise post-processing apparatus according to the second<br>
embodiment of the present invention. In FIG.5, the same<br>
sections as in FIG.l are assigned the same reference<br>
numerals as in FIG.l, and specific descriptions thereof<br>
are omitted.<br>
Stationary noise post-processing apparatus 200 is<br>
comprised of noise generating section 201, adder 202 and<br>
scaling section 203. Stationary noise post-processing<br>
apparatus 200 adds in adder 202 a pseudo stationary noise<br>
signal generated in noise generating section 201 and a<br>
post-filter output signal from speech decoding apparatus<br>
101, performs in scaling section 203 scaling on the<br>
post-filter output signal subjected to the addition to<br>
adjust the power, and outputs the<br>
post-processing-processed post-filter output signal.<br>
Noise generating section 201 is comprised of<br>
excitation generator 210, synthesis filter 211, LSP/LPC<br>
converter 212, multiplier 213, multiplier 214 and gain<br>
adjuster 215. Scaling section 203 is comprised of<br>
scaling coefficient calculator 216, inter-subframe<br>
smoother 217, inter-sample smoother 218 and multiplier<br>
219.<br>
The operation of stationary noise post-processing<br>
apparatus 200 with the above-mentioned configuration will<br>
be described below.<br>
Excitation generator 2 10 selects a fixed code vector<br>
at random from fixed codebook 113 provided in speech<br>
decoding apparatus 101, and based on the selected fixed<br>
code vector, generates a noise excitation signal to output<br>
to synthesis filter 211. A method of generating a noise<br>
excitation signal is not limited to a method of generating<br>
the signal based a fixed code vector selected from fixed<br>
codebook 113 provided in speech decoding apparatus 101,<br>
and it may be possible to determine a method judged as<br>
the most effective for each system in terms of computation<br>
amount, memory capacity and also characteristics of<br>
generated noise signals. Generally it is the most<br>
effective selecting fixed code vectors from fixed<br>
codebook 113 provided in speech decoding apparatus 101.<br>
LSP/LPC converter 212 converts the average LSP from<br>
average LSP calculator 125 into LPC to output to synthesis<br>
filter 211.<br>
Synthesis filter 211 constructs an LPC synthesis<br>
filter using LPC input from LSP/LPC converter 212.<br>
Synthesis filter 211 performs filtering processing using<br>
-the noise excitation signal input from excitation<br>
generator 210 as its input to synthesize a noise signal,<br>
and outputs the synthesized noise signal to multiplier<br>
213 and gain adjuster 215.<br>
Gain adjuster 215 calculates a gain adjustment<br>
coefficient to scale up the power of the output signal<br>
of synthesis filter 211 to the average noise power from<br>
average noise power calculator 126. The gain adjustment<br>
coefficient undergoes the smoothing processing so that<br>
the smoothed continuity is maintained between subframes,<br>
and further undergoes the smoothing processing for each<br>
sample so that the smoothed continuity is maintained also<br>
in a subframe. Finally, a gain adjustment coefficient<br>
for each sample is output to multiplier 213.<br>
Specifically, the gain adjustment coefficient is obtained<br>
according to (Eq.10) to (Eq.12). Psn is the power of<br>
a noise signal synthesized in synthesis filter 211<br>
(obtained in the same way as in (Eq.7)), and Psn' is<br>
obtainedby performing smoothing on Psn between subframes<br>
and is updated using (Eq.10) . PN' is the power of the<br>
stationary noise signal obtained in (Eq. 9) , and Scl is<br>
a scaling coefficient in a processing frame. Scl' is<br>
a gain adjustment coefficient adopted for each sample,<br>
and is updated for each sample using (Eq.12).<br>
Psn'=0.9xPsn'+0.1xPsn ...(Eq.10)<br>
Scl=PN'/Psn' ...(Eq.ll)<br>
Scl'=0.8 5xScl'+0.15xScl ...(Eq.12)<br>
Multiplier 213 multiplies the gain adjustment<br>
coefficient input from gain adjuster 215 by the noise<br>
signal output from synthesis filter 211. The gain<br>
adjustment coefficient is variable for each sample. The<br>
multiplication result is output to multiplier 214.<br>
In order to adjust an absolute level of a noise signal<br>
to generate, multiplier 214 multiplies a predetermined<br>
constant (for example, about 0.5) by the output signal<br>
from multiplier 213. Multiplier 214 may be incorporated<br>
into multiplier 213. The level-adjusted signal<br>
(stationary noise signal) is output to adder 202. As<br>
described above, the stationary noise signal where the<br>
smoothed continuity is maintained is generated.<br>
Adder 2 02 adds the stationary noise signal generated<br>
in noise generating section 201 to the post-filter output<br>
signal output from speech decoding apparatus 101 (more<br>
specifically, post filter 118) to output to scaling<br>
section 203 (more specifically, scaling coefficient<br>
calculator 216 and multiplier 219) .<br>
Scaling coefficient calculator 216 calculates both<br>
the power of the post-filter output signal output from<br>
speech decoding apparatus 101 (more specifically, post<br>
filter 118) and the power of the post-filter output signal<br>
to which the stationary noise signal added output from<br>
adder 202, calculates a ratio between both the power,<br>
and thus calculates a scaling coefficient for decreasing<br>
a variation in power between the scaled signal and decoded<br>
signal (to which the stationary noise is not added yet)<br>
to output to inter-subframe smoother 217. Specifically,<br>
the scaling coefficient SCALE is obtained as expressed<br>
by (Eq.13) . P is the power of the post-filter output<br>
signal and is obtained in (Eq.7), and P' is the power<br>
of the post-filter output signal to which the stationary<br>
noise signal is added and is obtained in the same equation<br>
as in P.<br>
SCALE=P/P' ...(Eq.13)<br>
Inter-subframe smoother 217 performs the<br>
inter-subframe smoothing processing on the scaling<br>
coefficient so that the scaling coefficient varies gently<br>
between subframes. Such smoothing is not executed in<br>
a speech region (or extremely weak smoothing is executed) .<br>
Whether a current subf rame is a speech region is determined<br>
based on the determination result output from second<br>
determiner 124 as shown in FIG.l. The smoothed scaling<br>
coefficient is output to inter-sample smoother 218 . The<br>
smoothed scaling coefficient SCALE' is updated by<br>
(Eq. 14) .<br>
SCALE'=0.9xSCALE' +0.lxSCALE . . . (Eq. 14)<br>
Inter-sample smoother 218 performs the<br>
inter-sample smoothing processing on the scaling<br>
coefficient so that the scaling coefficient smoothed<br>
between subframes varies gently between samples. The<br>
smoothing processing can be performed by AR smoothing<br>
processing. Specifically, smoothed scaling<br>
coefficient SCALE' ' for each sample isupdatedby (Eq.15) .<br>
SCALE' '=0. 85xSCALE' '+0.15xSCALE' . . . (Eq. 15)<br>
In this way, the scaling coefficient is subjected<br>
to the smoothing processing between samples, and thus<br>
is varied gently for each sample, and it is thereby<br>
possible to prevent the scaling coefficient from being<br>
discontinuous near a boundary between subframes. The<br>
scaling coefficient calculated for each sample is output<br>
to multiplier 219.<br>
Multiplier 219 multiplies the scaling coefficient<br>
output from inter-sample smoother 218 by the post-filter<br>
output signal to which the stationary noise signal is<br>
added input from adder 202 to output as a final output<br>
signal.<br>
In the above-mentioned configuration, the average<br>
noise power output from average noise power calculator<br>
126, LPC output from LSP/LPC converter 212 and scaling<br>
coefficient output from scaling calculator 216 both are<br>
parameters used in performing the post-processing.<br>
Thus, according to this embodiment, a noise<br>
generated in noise generating section 201 is added to<br>
the decoded signal (post-filter output signal) , and then<br>
scaling section 203 performs the scaling. In this way,<br>
since the power of the noise-added decoding signal is<br>
subjected to scaling, it is possible to equalize the power<br>
of the noise-added decoded signal to the power of the<br>
decoded signal to which the noise is not added yet.<br>
Further, since the inter-frame smoothing and inter-sample<br>
smoothing is both used, the stationary noise becomes<br>
smoother, and it is possible to improve the quality of<br>
subjective stationary noises.<br>
(Third embodiment)<br>
FIG. 6 illustrates a configuration of a stationary<br>
noise post-processing apparatus according to the third<br>
embodiment of the present invention. In FIG.6, the same<br>
sections as in FIG.5 are assigned the same reference<br>
numerals as in FIG.5, and specific descriptions thereof<br>
are omitted.<br>
The apparatus is comprised of the configuration of<br>
stationary noise post-processing apparatus 200 as<br>
illustrated in FIG.2, and further provided memories that<br>
store parameters required to generating noise signals<br>
and scaling when a frame is erased, frame erasure<br>
concealment processing control section and switches used<br>
in frame erasure concealment processing.<br>
Stationary noise post-processing apparatus 300 is<br>
comprised of noise generating section 301, adder 202,<br>
scaling section 303 and frame erasure concealment<br>
processing control section 304.<br>
Noise generating section 301 is comprised of the<br>
configuration noise generating section 2 01 as illustrated<br>
in FIG.5, and further provided memories 310 and 311 that<br>
store parameters required to generating noise signals<br>
and scaling when a frame is erased, and switches 313 and<br>
314 that are switched on/off in frame erasure concealment<br>
processing. Scaling section 303 is comprised of memory<br>
312 that stores parameters required to generating noise<br>
signals and scaling when a frame is erased, and switch<br>
315 that is switched on/off in frame erasure concealment<br>
processing.<br>
The operation of stationary noise post-processing<br>
apparatus 300 will be described below. First, the<br>
operation of noise generating section 301 is explained.<br>
Memory 310 stores the power (average noise power)<br>
of a stationary noise signal output from average noise<br>
power calculator 126 via switch 313 to output to gain<br>
adj ustor 215.<br>
Switch 313 is switched on/off according to a control<br>
signal from frame erasure concealment processing control<br>
section 304. Specifically, switch 313 is switched off<br>
in the case where the control signal is input which<br>
instructs to perform the frame erasure concealment<br>
processing, while being switched on in other cases. When<br>
switch 313 is switched off, memory 310 stores the power<br>
of the stationary noise signal in the last subframe, and<br>
outputs the power of the stationary noise signal in the<br>
last subframe to gain adjustor 215 when necessary until<br>
switch 313 is switched on again.<br>
Memory 311 stores LPC of the stationary noise signal<br>
output from LSP/LPC converter 212 via switch 314 to output<br>
to synthesis filter 211.<br>
Switch 314 is switched on/off according to a control<br>
signal from frame erasure concealment processing control<br>
section 304. Specifically, switch 314 is switched off<br>
in the case where the control signal is input which<br>
instructs to perform the frame erasure concealment<br>
processing, while beingmade in other cases. When switch<br>
314 is switched off, memory 311 stores LPC of the<br>
stationary noise signal in the last subf rame, and outputs<br>
LPC of the stationary noise signal in the last subframe<br>
to synthesis filter 211 when necessary until switch 314<br>
is switched, on again.<br>
The operation of scaling section 303 will be<br>
described below.<br>
Memory 312 stores a scaling coefficient that is<br>
calculated in scaling coefficient calculating section<br>
216 and output via switch 315, and outputs the coefficient<br>
to inter-subframe smoother 217.<br>
Switch 315 is switched on/off according to a control<br>
signal from frame erasure concealment processing control<br>
section 304. Specifically, switch 315 is switched off<br>
in the case where the control signal is input which<br>
instructs to perform the frame erasure concealment<br>
processing, while beingmade in other cases . When switch<br>
315 is switched off, memory 312 stores the scaling<br>
coefficient in the last subframe, and outputs the scaling<br>
coefficient in the last subframe to inter-subframe<br>
smoother 217 when necessary until switch 315 is switched<br>
on again.<br>
Frame erasure concealment processing control<br>
section 304 receives as its input frame erasure indication<br>
obtainedby error detection, etc, and outputs the control<br>
signal for instructing to perform the frame erasure<br>
concealment processing to switches 313 to 315, in a<br>
subframe in an erased frame and a subframe (error recovery<br>
frame) recovered from an error after an erased frame.<br>
There is a case that the frame erasure concealment<br>
processing in the error recovery subframe is performed<br>
in a plurality o f subframes (forexample, in two subframes) .<br>
The frame erasure concealment processing is to prevent<br>
the quality of decoded results from deteriorating when<br>
information is lost in part of subframes, by using<br>
information of a (previous) frame preceding the erased<br>
frame. In addition, when extreme power attenuation does<br>
not occur at all in the error recovery subframe subsequent<br>
to the erasee frame, the frame erasure concealment<br>
processing is not required in the error recovery subframe .<br>
In a generally used frame erasure concealment method,<br>
a current frame is extrapolated using previously received<br>
information. In this case, since the extrapolated data<br>
causes the subjective quality to deteriorate, the signal<br>
power is attenuated gently. However, when a frame<br>
erasures in a stationary noise region, it happens<br>
sometimes that the deterioration of objective quality<br>
due to signal discontinuity caused by power attenuation<br>
is larger than the deterioration of the subjective<br>
equality due to distortion caused by the extrapolation.<br>
In particular, in packet communications as typified by<br>
internet communications, frames sometimes are erased<br>
successively, and the deterioration due to signal<br>
discontinuity tends to be remarkable. In order to avoid<br>
the quality deterioration caused by the signal<br>
discontinuity, in the stationary noise post-processing<br>
apparatus according to the present invention, gain<br>
adjustor 215 calculates the gain adjustment coefficient<br>
to scale up to the average noise power from average power<br>
calculator 12 6 to multiply by the stationary noise signal .<br>
Further, scaling coefficient calculator 216 calculates<br>
the scaling coefficient to cause the power of the<br>
stationary noise signal to which the post-filter output<br>
signal is added not to vary greatly, and outputs the signal<br>
multiplied by the scaling coefficient as a final output<br>
signal. In this way, it is possible to suppress<br>
variations in the power of the final output signal to<br>
a small level and to maintain the stationary noise signal<br>
level obtained before frame erasure, whereby it is<br>
possible to suppress deterioration of the subjective<br>
quality due to sound signal discontinuity.<br>
(Fourth embodiment)<br>
FIG.7 is a diagram illustrating a configuration of<br>
a speech decoding processing system according to the<br>
fourth embodiment of the present invention. The speech<br>
decoding processing system is comprised of code receiving<br>
apparatus 100, speech decoding apparatus 101 and<br>
stationary noise region detecting apparatus 102 that are<br>
explained in the first embodiment, and stationary noise<br>
post-processing apparatus 300 explained in the third<br>
embodiment. In addition, the speech decoding processing<br>
system may have stationary noise post-processing<br>
apparatus 200 explained in the second embodiment, instead<br>
of stationary noise post-processing apparatus 300.<br>
The operation of the speech decoding processing<br>
system will be described below. Specific descriptions<br>
of each structural element are stated in the first to<br>
third embodiments with reference to FIG. 1, FIG. 5 and FIG. 6,<br>
and therefore in FIG.7, the same sections as in FIG.l,<br>
FIG.5 and FIG.6 are assigned the same reference numerals<br>
as in FIG.l, FIG.5 and FIG.6 respectively to omit the<br>
specific descriptions.<br>
. Code receiving apparatus 100 receives a coded signal<br>
from the transmission path, and divides various<br>
parameters to output speech decoding apparatus 101.<br>
Speech decoding apparatus 101 decodes a speech signal<br>
from the various parameters, and outputs a post-filter<br>
output signal and required parameters obtained during<br>
the decoding processing to stationary noise region<br>
detecting apparatus 102 and stationary noise<br>
post-processing section 300. Stationary noise region<br>
detecting apparatus 102 determines a current subframe<br>
is a stationary noise region using the information input<br>
form speech decoding apparatus 101, and outputs the<br>
determination result and required parameters obtained<br>
during the determination processing to stationary noise<br>
post-processing apparatus 300.<br>
With respect to the post-filter output signal input<br>
from speech decoding apparatus 101, stationary noise<br>
post-processing apparatus 300 performs the processing<br>
for generating a stationary noise signal to multiplex<br>
on the post-filter output signal, using the various<br>
parameter information input from speech decoding<br>
apparatus 101 and the determination information and<br>
various parameter information input from stationary noise<br>
region detecting apparatus 102, and outputs the<br>
processing result as a final post-filter output signal.<br>
FIG.8 is a flow diagram showing the flow of the<br>
processing of the speech decoding system according to<br>
this embodiment. FIG.8 only shows the flow of processing<br>
in stationary noise region detecting apparatus 102 and<br>
stationary noise post-processing apparatus 300 as<br>
illustrated in FIG.7, and omits the processing in code<br>
receiving apparatus 100 and speech decoding apparatus<br>
101, because such processing can be implemented by<br>
well-known techniques generally used. The operation of<br>
the processing subsequent to speech decoding apparatus<br>
101 in the system will be described below with reference<br>
to FIG.8. First in ST501, various variables stored in<br>
memories are initialized in the speech decoding system<br>
according to this embodiment. FIG.9 shows examples of<br>
memories to be initialized and initial values.<br>
Next, the processing of ST502 to ST505 is performed<br>
in a loop. The processing is performed until speech<br>
decoding apparatus 101 does not output the post-filter<br>
output signal (speech decoding apparatus 101 stops the<br>
processing) . In ST502, mode determination is made, and<br>
it is determined whether a current subf rame is a stationary<br>
noise region (stationary noise mode) or speech region<br>
(speech mode) . Theprocessing flow in ST502 is explained<br>
later specifically.<br>
In ST503, stationary noise post-processing<br>
apparatus 300 performs stationary noise addition<br>
(stationary noise post processing). The flow of the<br>
stationary noise post processing performed in ST503 is<br>
explained1ater specifical1y. In ST504, scaling section<br>
303 performs the final scaling processing. The flow of<br>
the scaling processing performed in ST504 is explained<br>
later specifically.<br>
In ST505, it is checked whether a subframe is last<br>
one to determine whether to finish or continue the loop<br>
processing of ST502 to ST505. The loop processing is<br>
performed until speech decoding apparatus 101 does not<br>
output the post-filter output signal (speech decoding<br>
apparatus 101 stops the processing) . When the loop<br>
processing ends, the processing in the speech decoding<br>
system according to this embodiment is all finished.<br>
The flow of mode determination processing in ST502<br>
will be describedbelowwith reference to FIG. 10 . First,<br>
in ST701, it is checked whether a current subframe is<br>
of an erased frame.<br>
When the current subframe is of an erased frame,<br>
the processing flowproceeds to ST702 in which the hangover<br>
counter for the frame erasure concealment processing is<br>
set for a predetermined value (herein, "3" is assumed) ,<br>
and further proceeds to ST704. The predetermined value<br>
for which the hangover counter is set corresponds to the<br>
number of frames on which the frame erasure concealment<br>
processing is performed continuously even when the<br>
subframes are successful (frame erasure does not occur)<br>
after the frame erasure occurs.<br>
When the current subframe is not of an erased frame,<br>
the processing flow proceeds to ST703, and it is checked<br>
whether a value of the hangover counter for the frame<br>
erasure concealment processing is 0. As a result of the<br>
check, when the value of the hangover counter for the<br>
frame erasure concealment processing is not 0, the value<br>
of the hangover counter for the frame erasure concealment<br>
processing is decremented by 1, and the processing flow<br>
proceeds to ST704.<br>
In ST704, it is determined whether to perform the<br>
frame erasure concealment processing. When the current<br>
subframe is neither of an erased frame nor a hangover<br>
region immediately after the eraseed frame, it is<br>
determined that the frame erasure concealment processing<br>
is not performed, and the processing flow proceeds to<br>
ST705. When the current subframe is of an erased frame<br>
or is a hangover region immediately after the erased frame,<br>
it is determined that the frame erasure concealment<br>
processing is performed, and the processing flow proceeds<br>
to ST707.<br>
In ST705, the smoothed adaptive code gain is<br>
calculated and the pitch history analysis is performed<br>
as illustrated in the first embodiment. Since the<br>
processing is illustrated in the first embodiment,<br>
descriptions thereof are omitted. In addition, the<br>
processing flow of the pitchhistory analysis is explained<br>
with reference to FIG.2. After the processing is<br>
performed, the processing flow proceeds to ST706. In<br>
ST706, the mode selection is performed. The flow of the<br>
mode selection is illustrated specifically in FIGs.3 and<br>
4. In ST708, the average LSP of the stationary noise<br>
region calculated in ST706 is converted into LPC. The<br>
processing in ST708 may be not performed subsequent to<br>
ST706, and is only required to be performed before a<br>
stationary noise signal is generated in ST503.<br>
When it is determined that the frame erasure<br>
concealment processing is performed in ST704, it is set<br>
in ST707 that the mode and average LPC of the stationary<br>
noise region in the last subframe are used repeatedly<br>
respectively as a mode and average LPC in the current<br>
subframe, and the processing flow proceeds to ST709.<br>
In ST709, the mode information (information<br>
indicative of whether the current subframe is the<br>
stationary noise mode or speech signal mode ) in the current<br>
subframe and the average LPC of the stationary noise region<br>
in the current subframe are stored in the memories. In<br>
addition, it is not required to always store the current<br>
mode information in the memory in this embodiment, but<br>
the current mode information needs to be stored when the<br>
mode determination result is used in another block (for<br>
example, speech decoding apparatus 101) . As described<br>
above, the mode determination processing in ST502 is<br>
fini shed.<br>
The flow of stationary noise addition processing<br>
in ST503 will be describedbelow with reference to FIG. 11.<br>
First in ST801, excitation generator 210 generates a<br>
random vector. Any method of generating a random vector<br>
is usable, but the method as illustrated in the second<br>
embodiment is effective in which a random vector is<br>
selected at random from fixed codebook 113 provided in<br>
speech decoding apparatus 101.<br>
In ST8 02, using the random vector generated in ST8 01<br>
as an excitation, LPC synthesis filtering processing is<br><br>
performed. In ST803, the noise signal synthesized in<br>
t<br>
ST8 02 undergoes the band- limitation filtering processing,<br>
so that the bandwidth of the noise signal is adapted to<br>
the bandwidth of the decoded signal output from speech<br>
decoding apparatus 101. It should be noticed that this<br>
processing is not mandatory. In ST804, the power of the<br>
synthesized noise signal subjected to band limitation<br>
obtained in ST803 is calculated.<br>
In ST805, the smoothing processing is performed on<br>
the signal power obtained in ST804. The smoothing can<br>
be implemented readily by performing AR processing as<br>
indicated in (Eq.l) in successive frames. The<br>
coefficient k of smoothing is determined depending on<br>
how much smoothing is required for a stationary signal.<br>
It is preferable to perform relatively strong smoothing<br>
of about 0.05 to 0.2. Specifically, (Eq.10) is used.<br>
In ST806, the ratio of the power (already calculated<br>
in ST1118) of the stationary noise signal to be generated<br>
to the signal power subjected to the inter-subframe<br>
smoothing obtained in ST805 is calculated as a gain<br>
adjustment coefficient (Eq.ll) . The calculated gain<br>
adjustment coefficient is subjected to the smoothing<br>
processing for each sample (Eq.12), and is multiplied<br>
by the synthesized noise signal subjected to the<br>
band-limitation filtering processing of ST803. The<br>
stationary noise signalmultiplied by the gain adj ustment<br>
coefficient is multiplied by a predetermined constant<br>
(fixed gain). The fixed gain is multiplied to adjust<br>
the absolute level of the stationary noise signal.<br>
In ST807, the synthesized noise signal generated<br>
in ST806 is added to the post-filter output signal output<br>
from speech decoding apparatus 101, and the power of the<br>
post-filter output signal to which the noise signal is<br>
added is calculated.<br>
In ST808, the ratio of the power of the post-filter<br>
output signal output from speech decoding apparatus 101<br>
to the power calculated in ST807 is calculated as a scaling<br>
coefficient (Eg.13). The scaling coefficient is used<br>
in the scaling processing in ST504 performed downstream<br>
of the stationary noise addition processing.<br>
Finally, adder 2 02 adds the synthesized noise signal<br>
(stationary noise signal) generated in ST806 and the<br>
post-filter output signal output from speech decoding<br>
apparatus 101 . It shouldbe noticed that this processing<br>
may be included and performed in ST807. In this way,<br>
the stationary noise addition processing in ST503 is<br>
fini shed.<br>
The flow of scaling in ST504 will be described below<br>
with reference to FIG.12. First in ST901, it is checked<br>
whether a current subframe is a target subframe for the<br>
frame erasure concealment processing. When the current<br>
subframe is a target subframe for the frame erasure<br>
concealment processing, the processing flow proceeds to<br>
ST902, while proceeding to ST903 when the current subframe<br>
is not the target subframe.<br>
In ST902 the frame erasure concealment processing<br>
is performed. In other words, it is set that the scaling<br>
coefficient in the last subframe is used repeatedly as<br>
a current scaling coefficient, and the processing flow<br>
proceeds to ST903.<br>
In ST903, using the determination result output from<br>
stationary noise region detecting apparatus 102, it is<br>
checked whether the mode is the stationary noise mode.<br>
When the mode is the stationary noise mode, the processing<br>
flow proceeds to ST904, while proceeding to ST905 when<br>
the mode is not the stationary noise mode.<br>
In ST904, using (Eq.l) as described previously, the<br>
scaling coefficient is subjected to the inter-subframe<br>
smoothing processing. In this case, a value of k is set<br>
at about 0.1. Specifically, an equation like (Eq.14)<br>
is used. The processing is performed to smoothe power<br>
variations between subframes in the stationary noise<br>
region. After performing the smoothing processing, the<br>
processing flow proceeds to ST905.<br>
In ST905, the scaling coefficient is subjected to<br>
smoothing for each sample, and the smoothed scaling<br>
coefficient is multiplied by the post-filter output<br>
signal to which is added the stationary noise generated<br>
in ST502. The smoothing for each sample is also used<br>
using (Eq.l), and in this case, a value of k is set at<br>
about 0.15. Specifically, an equation like (Eq.15) is<br>
used. As described above, the scaling processing in<br>
ST504 is finished, thus the scaled post-filter output<br>
signal mixed with the stationary noise is obtained.<br>
In each of the above-mentioned embodiments,<br>
equations indicated by (Eq.l) and others are used to<br>
calculate the smoothing and average value, but an equation<br>
used in smoothing is not limited to such an equation.<br>
For example, it may be possible to use an average value<br>
in a predetermined previous region.<br>
The present invention is not limited to the<br>
above-mentioned first to fourth embodiments, and is<br>
capable of being carried into practice with various<br>
modifications thereof. For example, the stationary<br>
noise region detecting apparatus of the present invention<br>
is applicable to any type of decoder.<br>
The present invention is not limited to the<br>
above-mentioned first to fourth embodiments, and is<br>
capable of being carried into practice with various<br>
modifications thereof. For example, the<br>
above-mentioned embodiments describe cases where the<br>
present invention is implemented as a speech decoding<br>
apparatus, but are not limited to such cases. The speech<br>
decoding method may be performed as software.<br>
For example, it may be possible that a program for<br>
executing the speech decoding method as described above<br>
is stored in a ROM (Read Only Memory) in advance, and<br>
that the program is executed by a CPU (Central Processor<br>
Unit) .<br>
Further, it may be possible to store a program for<br>
executing the speech decoding method as described above<br>
in a computer readable storage medium, further store the<br>
program stored in the storage medium in a RAM (Random<br>
Access Memory), and operate a computer according to the<br>
program.<br>
As is apparent from the foregoing, according to the<br>
present invention, a degree of periodicity of a decoded<br>
signal is determined using an adaptive code gain and pitch<br>
periods, and based on the degree of periodicity, it is<br>
determined that a subframe is a stationary noise region.<br>
Accordingly, it is possible to determine signal states<br>
accurately with respect to signals such as sine waves<br>
and stationary vowels that are stationary but not noises.<br>
This application is based on the Japanese Patent<br>
Application No.2000-366342 filed on November 30, 2000,<br>
entire content of which is expressly incorporated by<br>
reference herein.<br>
Industrial Applicability<br>
The present invention is suitable for use in mobile<br>
communication systems, packet communication systems<br>
including internet communications and speech decoding<br>
apparatuses where speech signals are encoded and<br>
transmitted.<br><br>
We Claim<br>
1. An audio decoder, comprising:<br>
a first decoding section (110) that decodes a coded signal to obtain<br>
at least one type of first parameter (LPC) indicative of a spectral envelope<br>
component of a speech signal;<br>
a second decoding section (111-116) that decodes the coded signal<br>
to obtain at least one type of second parameter indicative of a residual<br>
component of the speech signal;<br>
a synthesis section that constructs a synthesis filter (117) based on<br>
the first parameter and that drives the synthesis filter using an excitation<br>
signal generated based on the second parameter to generate a decoded<br>
signal;<br>
a first determining section (121) that determines stationary noise<br>
characteristics of the decoded signal based on the first parameter; and<br>
a second determining section (124) which determines periodicity of<br>
the decoded signal based on the second parameter, and based on a<br>
determining result of the periodicity, a determination result of the<br>
stationary noise characteristics in the first determining section (121) and<br>
the first parameter, determines whether the decoded signal is a stationary<br>
noise region.<br><br>
?. The decoder as claimed in claim 1, wherein the second parameter<br>
comprises at least a pitch period, and based on variations in the pitch<br>
period between processing units, the second determining section (124)<br>
determines the periodicity of the decoded signal.<br>
3. The decoder as claimed in claim 1, wherein the second parameter<br>
comprises at least an adaptive codebook gain to multiply by an adaptive<br>
code vector, and based on the adaptive codebook gain, the second<br>
determining section (124) determines the periodicity of the decoded<br>
signal.<br>
4. The decoder as claimed in claim 1, comprising:<br>
a variation amount calculating section (119) that calculates a<br>
variation amount in spectral envelope parameter between processing<br>
units, the first parameter having at least the spectral envelope parameter;<br>
and<br>
a distance calculating section (120) that calculates a distance<br>
between an average value of the spectral envelope parameter in a<br>
stationary noise region prior to a current processing unit and the spectral<br>
envelope parameter in the current processing unit,<br>
wherein the first determining section (121) determines stationary<br>
characteristics of the decoded signal generated in the synthesis section<br>
(117), based on the variation amount and the distance, and based on the<br>
determination result, determines the stationary noise characteristics of the<br>
decoded signal.<br><br>
5. The decoder as claimed in claim 4, wherein the variation amount<br>
calculating section (119) calculates as the variation amount a square error<br>
of the spectral envelope parameter in the current processing unit and the<br>
spectral envelope parameter in a last processing unit, wherein the<br>
distance calculating section (120) calculates as the distance a square error<br>
of the average value of the spectral envelope parameter in the stationary<br>
noise region prior to the current processing unit and the spectral envelope<br>
parameter in the current processing unit, wherein the first determining<br>
section (121) sets thresholds respectively at least with respect to the<br>
square error calculated as the variation amount and the square error<br>
calculated as the distance, and when the square error calculated as the<br>
variation amount and the square error calculated as the distance are both<br>
smaller than set respective thresholds, determines that the decoded signal<br>
is stationary.<br>
6. The decoder as claimed in claim 4, comprising<br>
a pitch history analyzing section (122) which temporarily stores<br>
respective pitch periods in a plurality of processing units prior to the<br>
current processing unit, groups pitch periods close to each other among<br>
the stored pitch periods in the plurality of processing units, and outputs<br>
the number of groups in grouping; and<br>
a signal power variation calculating section (123) that calculates a<br>
variation amount between power of the decoded signal in the current<br>
processing unit and the average power of the decoded signal in the<br>
stationary noise region prior to the current processing unit,<br><br>
wherein the second determining section (124) determines that the<br>
decoded signal is a speech region when the variation amount exceeds a<br>
predetermined threshold, determines that the decoded signal is a<br>
stationary noise region when the decoded signal is not a speech stationary<br>
region, the decoded signal is determined to be satisfactory in the first<br>
determining section (121) and a state in which the variation amount<br>
calculated in the variation amount calculating section (119) is less than<br>
the predetermined threshold has lasted for a predetermined number of<br>
processing units or more, and determines that the decode signal is a<br>
speech region when the number of groups output from the pitch history<br>
analyzing section (122) is not less than a predetermined threshold or the<br>
adaptive code gain is not more than a predetermined threshold.<br>
7. The decoder as claimed in claim 1, comprising:<br>
a post-processing section (200, 300) that multiplies a noise added<br>
(mixed) signal by a scaling coefficient to adjust power, the scaling<br>
coefficient obtained from the decoded signal generated in the synthesis<br>
section (101, 118) and the noise added (mixed) signal obtained by adding<br>
(mixing) a pseudo stationary noise signal to (with) the decoded signal.<br>
8. The decoder as claimed in claim 7, comprising:<br>
a scaling section (203) that performs smoothing on the scaling<br>
coefficient between processing units only when the second determining<br>
section (124) determines that the decoded signal is the stationary noise<br>
region.<br><br>
9. The decoder as claimed in claim 8, comprising:<br>
a storage section (310, 311, 312) that stores at least one type of<br>
third parameter used in performing post processing; and<br>
a control section (304) that outputs the third parameter in a last<br>
processing unit from the storage section when frame erasure occurs in the<br>
current processing unit, wherein the post-processing section (300)<br>
performs the post processing using the third parameter in the last<br>
processing unit.<br>
10. The decoder as claimed in claim 9, wherein the third parameter comprises<br>
at least the scaling coefficient, and the post-processing section performs<br>
the post processing using the scaling coefficient in the last processing unit<br>
output from the storage section.<br>
11. The decoder as claimed in claim 7, wherein the post-processing section<br>
(200, 300) comprises:<br>
a noise generating section (201, 301) that generates a pseudo<br>
stationary noise signal;<br>
an adding section (202) that adds the decoded signal generated in<br>
the synthesis section and the pseudo noise signal to generate a noise<br>
added (mixed) decoded signal; and<br>
a scaling section (203, 303) that multiplies the scaling coefficient by<br>
the noise added (mixed) decoded signal to adjust power.<br><br>
12.The decoder as claimed in claim 11, wherein the noise generating section<br>
(201, 301) comprises:<br>
an excitation generating section (210) that selects a random code<br>
vector at random from a fixed codebook to generate a noise excitation<br>
signal;<br>
a second synthesis filter section (211) that constructs a second<br>
synthesis filter based on a linear predictive coefficient and that drives the<br>
second synthesis filter (211) using the noise excitation signal to synthesize<br>
a pseudo stationary noise signal; and<br>
a gain adjustment section (215) that adjusts gain of the pseudo<br>
stationary noise signal synthesized in the second synthesis section.<br>
13.The decoder as claimed in claim 11, wherein the scaling section (203,<br>
303) comprises:<br>
a scaling coefficient calculating section (216) that calculates the<br>
scaling coefficient based on the decoded signal generated in the synthesis<br>
section (101, 118) and the noise added (mixed) decoded signal obtained<br>
by adding (mixing) the pseudo stationary noise signal to (with) the<br>
decoded signal);<br>
a first smoothing section (217) that performs smoothing on the<br>
scaling coefficient between processing units;<br><br>
a second smoothing section (218) that performs smoothing on the<br>
scaling coefficient on which the first smoothing section performs the<br>
smoothing; and<br>
a multiplying section (219) that multiplies the scaling coefficient on<br>
which the second smoothing section (218) performs the smoothing by the<br>
noise added (mixed) decoded signal.<br>
14. An audio decoding method, comprising:<br>
decoding at least one type of first parameter indicative of a spectral<br>
envelope component of a speech signal;<br>
decoding at least one type of second parameter indicative of a<br>
residual component of the speech signal;<br>
constructing a synthesis filter based on the first parameter, and<br>
driving the synthesis filter using an excitation signal generated based on<br>
the second parameter to generate a decoded signal;<br>
determining stationary noise characteristics of the decoded signal<br>
based on the first parameter; and<br>
determining periodicity of the decoded signal based on the second<br>
parameter, and based on a determination result of the periodicity and a<br>
determination result of the stationary noise characteristics, further<br>
determining whether the decoded signal is a stationary noise region.<br>
15. An audio decoding program product which when loaded and operated on<br>
an apparatus, provides instructions to perform the method as claimed in<br>
claim 14, the instructions comprising:<br>
decoding at least one type of first parameter indicative of a spectral<br>
envelope component of a speech signal;<br>
decoding at least one type of second parameter indicative of a<br>
residual component of the speech signal;<br>
constructing a synthesis filter based on the first parameter, and<br>
driving the synthesis filter using an excitation signal generated based on<br>
the second parameter to generate a decoded signal;<br>
determining stationary noise characteristics of the decoded signal<br>
based on the first parameter; and<br>
determining periodicity of the decoded signal based on the second<br>
parameter, and based on a determination result of the periodicity and a<br>
determination result of the stationary noise characteristics, further<br>
determining whether the decoded signal is a stationary noise region.<br>
A first judging device (121) temporarily judges whether a current processing unit<br>
is a stationary noise section from a stationary judgment result of a decoding<br>
signal. A second judging device (124) judges whether a current processing unit is<br>
a stationary noise section from this temporary judgment result and a periodical<br>
judgment result of the decoded signal. Thus, the stationary noise section is<br>
exactly detected by discriminating a decoded signal including a stationary audio<br>
signal of stationary vowels or the like from a stationary noise.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1jb3JyZXNwb25kZW5jZS5wZGY=" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1leGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1mb3JtIDIucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1mb3JtIDI2LnBkZg==" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1ncGEucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1yZXBseSB0byBleGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC1zcGVjaWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-specification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYyLWtvbG5wLTIwMDMtZ3JhbnRlZC10cmFuc2xhdGVkIGNvcHkgb2YgcHJpb3JpdHkgZG9jdW1lbnQucGRm" target="_blank" style="word-wrap:break-word;">662-kolnp-2003-granted-translated copy of priority document.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="223065-method-for-transmitting-and-receiving-digital-data-representing-a-content-from-a-source.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="223067-injection-solution-of-an-lhrh-antagonist.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>223066</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>662/KOLNP/2003</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>36/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>05-Sep-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>03-Sep-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>26-May-2003</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>MATSUSHITA ELECTRIC INDUSTRIAL CO. LTD</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>1006, OAZA KADOMA, KADOMA-SHI, OSAKA 571-8501</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>EHARA HIROYUKI</td>
											<td>2-37-8, MARUYAMADAI, KONAN-KU, YOKOHAMA-SHI, KANAGAWA 233-0013</td>
										</tr>
										<tr>
											<td>2</td>
											<td>YASUNAGA KAZUTOSHI</td>
											<td>1-284-401, KYO-MACHI, FUSHIMI-KU, KYOTO 612-8083</td>
										</tr>
										<tr>
											<td>3</td>
											<td>MANO KAZUNORI</td>
											<td>C/O NTT INTELLECTUAL PROPERTY CENTER, 9-11, MIDORI-CHO 3-CHOME, MUSASHINO-SHI, TOKYO 180-8585</td>
										</tr>
										<tr>
											<td>4</td>
											<td>HIWASAKI YUSUKE</td>
											<td>C/O NTT INTELLECTUAL PROPERTY CENTER, 9-11, MIDORI-CHO 3-CHOME, MUSASHINO-SHI, TOKYO 180-8585</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G10L 19/04, 19/12</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/JP01/10519</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-11-30</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>2000-366342</td>
									<td>2000-11-30</td>
								    <td>Japan</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/223066-an-audio-decoder-and-an-audio-decoding-method-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 06:55:24 GMT -->
</html>
