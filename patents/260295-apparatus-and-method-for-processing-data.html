<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/260295-apparatus-and-method-for-processing-data by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:28:07 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 260295:APPARATUS AND METHOD FOR PROCESSING DATA</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">APPARATUS AND METHOD FOR PROCESSING DATA</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>i ABSTRACT &quot;APPARATUS AND METHOD FOR PROCESSING DATA&quot; I A register data store (20) is provided within a data processing system (2). The register data store (20) may be accessed via registers for which a data processing instruction specifies a register size Q, D and a data element size 816, S8 for the multiple SIMD data elements to be manipulated by that data processing instruction. A given data processing element may be accessed via different registers depending upon the mapping between the register specifier, the register size and the data element size to a particular location within the register data store (20). I Figure 1.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>The present invention relates to apparatus and method for processing data.<br>
ORIGINAL<br>
FTET^D OF THE INVENTION<br>
^ This invention relates to the field of data processing systems. More<br>
) particularly, this invention relates to data processing systems incorporating a register<br>
data store from v/ithin which access is made using registers.<br>
BACKGROUND OF THE INVENTION<br>
It is knovioi to provide data processing systems, such as ARM processor cores<br>
1( designed by ARM Limited, Cambridge, England, which have a register bank<br>
containing a predetermined number of fixed size registers, such as sixteen registers,<br>
each being 32 bits in length. A data value stored within such a register may be read<br>
from the register by an appropriate read instraction. The instruction writing to that<br>
register and the instruction reading from that .register will specify the particular<br>
1: register concerned in the same way, e.g. use the same register number/name.<br>
With the increasing demands for data processing systems capable of<br>
performing processing operations upon large volumes of data, such as during moving<br>
image data processing etc, there have been developed processing techniques generally<br>
20 referred to SIMD (single instruction multiple data). With these techniques a register<br>
containing multiple discrete data elements, such as pixel component values, is subject<br>
to a processing instruction apphed to all of the data elentents within that register in<br>
parallel. As an example, it may be desired to multiply the component values of a<br>
pixel by a certain scaling- factor and the SIMD instraction can control this to take<br>
2: i place in response to a single instruction which separately applies the scaling value to<br>
\ each of the different data elements. It will be appreciated that in these systems the<br>
data elements are isolated from one another in the sense that the processing performed<br>
upon them is not permitted to inappropriately influence other data elements held<br>
' within the same register.<br>
•<br>
' Whilst SIMD processing techniques do allow the execution in parallel of<br>
multiple desired operations, they suffer from the considerable disadvantage that it is<br>
generally necessary to spend time and processing cycles arranging the data elements<br>
into the necessary positions within the SIMD registers before the SIMD instructions<br>
t<br>
•!<br>
!<br>
1<br>
-2-<br>
1^ can be executed upon them. This requirement disadvantageously reduces the benefits<br>
achieved by SIMD operation.<br>
It is also known to provide a data processing system for executing a time<br>
; i separated sequence of data processing operations in response to a single vector data<br>
processing instruction. An example of such a vector data processing system is the<br>
VFP (vector floating point) coprocessor designed by ARM Limited, Cambridge,<br>
England. Such vector coprocessors operate by using a single vector instruction to first<br>
select one set of registers upon which an operation is to be performed, performing that<br>
10 operation, selecting a next set of registers, performing the operation again and so<br>
forth. The VFP processor is provided with its own register data store for use with<br>
these manipulations. The register data store can either be divided into short registers<br>
each holding a short single precision floating point value or a smaller number of long<br>
registers each holding a long double precision value. Instructions allow separate<br>
1 i operation on either single or double precision values.<br>
SUMMARY OF THE INVENTION<br>
Viewed from one aspect the present invention provides apparatus for<br>
processing data, said apparatus comprising:<br>
2) a register data store operable to store a plurality of data elements; and<br>
processmg logic responsive to a data processmg instruction to perform a data<br>
processing operation in parallel upon a selected plurality of data elements accessed as<br>
a register of said register data store; wherein<br>
data elements of said selected plurahty of data elements share one of a<br>
2) plurality of different data element sizes, said register has one of a pluraKty of different<br>
register sizes and said data processing instruction specifies for said data processing<br>
operation a data element size shared by said selected plurality of data elements and a<br>
register size of said register; and forther comprising<br>
register accessing logic operable to map said register to a portion of said<br>
3 3 register data store dependent upon said register size of said register such that a data<br>
element stored within said portion of said register data store is accessible as a part of<br>
respective different registers of differing register size.<br>
-3-<br>
^ The present invention recognises that SMD data elements stored within a<br>
register data store can be accessed more flexibly and accordingly with a reduced need<br>
for dedicated data element rearrangement operations if the instructions are allowed to<br>
specify the data element size and the register size and register accessing logic is<br>
) provided which maps a particular register to a portion of the register data store in<br>
dependence upon the register size. Thus, an indi^ddual data element may be written to<br>
a particular point Avithin the register data store as part of the contents of one register of<br>
a particular register size, but then read firom that same position as part of a different<br>
register having a different register size and possibly a different data element size.<br>
1) Registers of differing sizes are effectively ahased on top of each other in a marmer<br>
which advantageously allows highly flexible access to the data elements without<br>
incurring overhead in rearranging those data elements.<br>
It will be appreciated that a data processing instruction may specify one or<br>
1J more source registers and/or one or more destination registers. The register size and<br>
data element size of these different source and destination registers may be<br>
independently specified by the data processing instruction. Alternatively, instruction<br>
encoding space may be saved by requiring particular relationships between register<br>
sizes and element sizes. These relationships can be targeted at those commonly<br>
2) encountered so that flexibility is not imduly reduced.<br>
A particularly advantageous use of the present technique is one in which the<br>
destination data element size differs from one or more of the source data element<br>
sizes. This situation commorily arises in SIMD processing operations whereby the<br>
2) data width is increased as a consequence of the processing operation, e.g. multiplying<br>
two n-bit numbers together results in a 2n-bit result. The flexibility of register<br>
accessing provided by the present technique allows this difference in data element<br>
size and register size to be accommodated "with a single instruction and with the full<br>
result being obtained.<br>
Other common examples of the usefulness of the aliasing technique are when<br>
data elements written to the register store as part of two separate registers can then be<br>
simultaneously read from the register data store as part of a single different register.<br>
Conversely, data elements written to the register data store as part of a single register<br>
35 can be independently read from the register data store as part of two different further<br>
^ registers. This type of behaviour can be exploited by software writers and softwai-e<br>
compilers to produce high code density and rapid execution since it helps avoid the<br>
need for data rearrangement within the register data store.<br>
i Particularly useful relationships between source register sizes and destination<br>
register sizes are where these are all equal, where the source register sizes are half the<br>
destination register size and where the source register size is t^vice the destination<br>
register size. These relationships can be efficiently encoded Avithin the instructions<br>
and are advantageously common and useful within real Hfe programming. There may<br>
li) be one or two source registers.<br>
Preferred embodiments use a set of register specifying fields which are<br>
constrained by the available bit space within the .data processing instructions and<br>
which map onto different portions of the register data store in dependence upon the<br>
1) register size and the data element size. Advantageously these different portions are<br>
arranged to be contiguous portions within the register data store. Thus, a fixed<br>
number of small data elements wdll all be stored together in one contiguous portion of<br>
the register data store with the remainder of the register data store being un-accessible<br>
for registers of that register size and that data element size. Conversely, the same<br>
2i) register specifiers when qualified with large register size and data element size values<br>
will spread over a greater amount of the register data store. This type of mapping also<br>
allows flexibiHty for different embodiments to provide different amounts of storage<br>
capacity within their register data store and yet allow this to be addressed by data<br>
processing instructions having essentially the same form and support legacy code<br>
2 j written for smaller register data stores. Also the instruction bit space consumed by<br>
register specifiers is held constant.<br>
In preferred embodiments said data processing instruction includes a plurality<br>
of bits encoding a register number of said register, said plurality of bits being mapable<br>
3) to a contiguous field of bits which is rotatable by a number of bit positions dependent<br>
upon said register size to form said register number. This encoding advantageously<br>
permits a simpher and faster decoding of the register field despite the register size<br>
variation.<br>
__^^^^ - c- ^ ^ ^ _ _ _<br>
^ Viewed from another aspect the present invention provides a method of<br>
processing data, said method comprising the steps of:<br>
storing a pluraHty of data elements within a register data store; and<br>
in response to a data processing instruction performing a data processing<br>
:i operation in parallel upon a selected plurality of data elements accessed as a register<br>
of said register data store; wherein<br>
data elements of said selected plurahty of data elements share one of a<br>
plurality of different data element sizes, said register has one of a plurality of different<br>
register sizes and said data processiag instruction specifies for said data processing<br>
10 operation a data element size shared by said selected plurality of data elements and a<br>
register size of said register; and further comprising<br>
mapping said register to a portion of said register data store dependent upon<br>
said register size of said register such that a data element stored within said portion of<br>
said register data store is accessible as a part of respective different registers of<br>
1) differing register size.<br>
The invention can also be considered in a complementary aspect to take the<br>
form of a computer program product including a computer program including data<br>
processing instructions for accessing a register data store in accordance with the<br>
23 above techniques.<br>
-4'<br>
j - i i i f f l i u - j . . . - - - - - • - • • '-• •' '- ^"' ' " •<br>
- &amp; •<br>
DESCRIPTION OF THE DRAWINGS<br>
Embodiments Avill now be described, by way of example only, with reference<br>
to the accGmpan3dng dra"wings in which:<br>
• i<br>
Figure 1 schematically illustrates an integrated circuit supporting both<br>
conventional scalar data processing and SIMD data processing;<br>
Figure 2 schematically illustrates a read and write port arrangement for a<br>
li) SIN-ID register data store;<br>
Figure 3 schematically illustrates an example SIMD read and write operation<br>
in which the destination register is twice the width of the source registers;<br>
1 &gt; Figure 4 shows different types of relationship between source register size and<br>
destination register size for different data processing operations;<br>
Figure 5 schematically illustrates a syntax which may be used to define a data<br>
processing instruction in accordance with the present techniques;<br>
21)<br>
Figure 6 schematically illustrates the SIMD register data store viewed as 64-<br>
bit registers and 128-bit registers;<br>
Figure 7 schematically illustrates the overlap ("aliasing") between 64-bit and<br>
2) 128-bit registers;<br>
Figure 8 schematically illustrates a plurahty of data elements stored within<br>
SIMD registers of different sizes;<br>
3) Figure 9 schematically illustrates the referencing of a scalar value within a<br>
SIMD vector register;<br>
Figure 10 schematically illustrates a data processing instruction in which the<br>
number of processing lanes and the data element size remain constant;<br>
35<br>
^ Figures UA and IIB schematically illustrate a data processing instruction in<br>
[ which the number of processing lanes remains constant and the data element size<br>
changes;<br>
5 Figure 12 illustrates the transfer of data between a SIMD register data store<br>
and a scalar register data store;<br>
Figures 13, 14 and 15 schematically illustrate the operation of various register<br>
transfer instructions;<br>
1 )<br>
Figure 16 is a flow diagram illustrating an example of a situation in which<br>
register transfer instructions of the types illustrated in Figures 14 and 15 maybe<br>
usefully employed;<br>
1) Figure 17 is a diagram schematically illustrating how data elements are loaded<br>
from a continuous block of memory into some specified registers in accordance with<br>
one embodiment;<br>
Figure 18 schematically illustrates some examples of different structures that<br>
2) may exist within memory in accordance with embodiments;<br>
Figures 19A to 19C illustrate the operation of a particular example of a single<br>
store instruction in accordance with one embodiment;<br>
2 5 Figures 20A to 20C illustrate the operation of a particular example of a single<br>
load instruction in accordance with one embodiment;<br>
Figures 21A to 21C illustrate the operation of a further particular example of a<br>
single load instruction in accordance with one embodiment;<br>
3 3<br>
Figures 22A to 22C illustrate the operation of another particular example of a<br>
single load instruction in accordance with one embodiment;<br>
Figure 23 is a block diagram illustrating in more detail the logic provided<br>
3 5 within the reordering logic of Figure 1;<br>
- . ^ - . . -"^— - ^<br>
^ Figures 24-26 illustrate the flow of data through the reordering logic for four<br>
different sequences of single access instructions in accordance with embodiments;<br>
j Figure 27 illustrates a known folding operation;<br>
Figure 28 illustrates a folding operation of one embodiment;<br>
Figure 29 illustrates a folding operation of another embodiment;<br>
1 )<br>
Figures 30a to 30d illustrate the operation of various folding instructions;<br>
Figure 31 illustrates schematically logic arranged to perform a folding<br>
operation provided within the SIMD processing logic of Figure 1;<br>
1.;<br>
Figure 32 illustrates the operation of a vector-by-scalar instruction;<br>
Figure 33 illustrates an arrangement of scalar operands in the SIMD register<br>
file of Figure 1;<br>
2')<br>
Figure 34 illustrates schematically logic arranged to perform a vector-byscalar<br>
operation provided within the SIMD processiag logic of Figure 1;<br>
Figure 35 shows a method of shifting right and packing high according to the<br>
2.) prior art;<br>
Figure 36 schematically shows a shift right and. narrow operation according to<br>
an embodiment of the present technique;<br>
3 ) Figure 37 schematically shows a shift left and narrow according to the present<br>
technique;<br>
Figure 38 schematically shows a cast up and shift left according to an<br>
embodiment of the present technique;<br>
3i<br>
- jo- _ __<br>
- u i m i i E J - - — -- ' c^ ' """"' ^"^ " " • " • " - - - - . . .<br>
" ^<br>
Figure 39 schematically shows a shifting of data elements by different<br>
^ amounts;<br>
Figure 40 schematically shows a conventional multiplexer;<br>
i<br>
Figure 41 schematically shows an embodiment where the selection of source<br>
values a or b is done on a bit-wise basis;<br>
Figure 42 schematically shows an altemative embodiment where the selection<br>
1' I of source values a or b is done on a data element basis;<br>
Figure 43 schematically shows three examples of multiplexer arrangements<br>
corresponding to the three multiplexing instructions provided by the present<br>
technique;<br>
1:;<br>
Figure 44 schematically illustrates a SIMD register storing multiple data<br>
elements in different layouts depending upon the endianess mode;<br>
Figure 45 schematically illustrates the operation of memory accessing logic<br>
20 and data element reordering logic m accordance with a first example;<br>
Figure 46 schematically illustrates the operation of memory accessing logic<br>
and data element reordering logic in accordance with a second example;<br>
2.&gt; Figure 47 schematically illustrates an example embodiment of the data<br>
element reordering logic of Figures 45 and 46 in more detail;<br>
Figure 48 schematically illustrates a register data store including two registers<br>
serving as table registers, a result register and an index register;<br>
3)<br>
Figure 49 schematically illustrates the action of a table lookup extension<br>
instruction;<br>
a i H f f l i L - i - - -. -.^-.^-.-^-.-.- - -—- - -- - -. - - , _ _ , , . _ , _ . „ . . . ..<br>
J ^ "^ •-'<br>
^ Figure 50 schematically illustrates processing performed upon an index<br>
register before the index values within the index register are reused by a further table<br>
lookup extension instruction;<br>
) Figure 51 schematically illustrates the operation of a table lookup instruction<br>
in which zero values are written into the result registers at locations corresponding to<br>
out-of-range index values;<br>
Figure 52 illustrates how the LSU of Figure 1 is coupled with a memory<br>
1) system and z. Memory Management Unit in accordance with one embodiment;<br>
Figures 53A to 53D are diagrams schematically illustrating various examples<br>
of data blocks to be accessed in accordance with an embodiment;<br>
1) Figures 54A and 54B are diagrams schematically illustrating further examples<br>
of data blocks to be accessed in accordance with an embodiment;<br>
•<br>
Figures 55A to 55C schematically illustrate an interleave operation, a deinterleave<br>
operation and a transpose operation, respectively;<br>
2)<br>
Figures 56A and 56B schematically illustrate how interleave and transpose<br>
operations are performed in accordance with one embodiment;<br>
Figures 57A to 57C illustrate how a sequence of instructions in accordance<br>
2 5 with one embodiment may be used to transpose an array of image pixels;<br>
Figure 58 illustrates how an instruction of one embodiment may be used to<br>
interleave real and imaginary parts of complex numbers;<br>
30 Figures 59A and 59B illustrate how a sequence of two instructions in<br>
accordance with one embodiment can be used to perform in parallel a multiplication<br>
of two complex numbers;<br>
Figure 60 schematically shows an add returning high half operation and its<br>
3 5 associated instruction;<br>
.--Loiiau . - - -— - - —' " ----^^.:----'<br>
Figure 61 schematically shows an add returning high half operation with<br>
rounding and its associated instruction;<br>
5 • Figure 62 schematically shows a subtract returning high half operation and its<br>
associated instruction;<br>
Figure 63 shows a table of possible constants generated from an instruction<br>
having a data portion, abcdefgh and a control portion associated with it;<br>
n<br>
Figure 64 shows constant generation logic;<br>
Figure 65 shows a data processor having constant generation logic;<br>
1 j Figure 66A and 66B schematically show a data processor response to two<br>
types of instruction with generated constant; and<br>
Figure 67 shows the generation of a bit mask according to the present<br>
technique.<br>
2)<br>
DESCRIPTION OF EMBQDDslENTS<br>
Figure 1 schematically illustrates a data processing system (iategrated circuit)<br>
2 incorporating both a scalar data processing functionality and a SIMD data<br>
2 j processing functionality. The scalar data processing portion can be considered to be a<br>
standard AEIM processor core incorporating a scalar register data store 4, a multiplier<br>
6, a shifter 8, aa adder 10, an instruction pipeline 12 and a scalar decoder 14 as well<br>
as many other circuit elements which have not, for the sake of clarity, been illustrated.<br>
In operation, such a scalar processor core stores fixed length 32-bit data values within<br>
3 D the scalar register data store 4 and manipulates these using the multipHer 6, shifter 8<br>
and adder 10 under control of data processing instructions passed along the instruction<br>
pipeline 12 and supphed to the scalar decoder 14. The scalar decoder 14 produces<br>
control signals which control the operation of the scalar processing -elements in a<br>
conventional way.<br>
35<br>
^ 13-<br>
""'""^"^ -^. ~- - - ~ 42- ' ' ^ '<br>
As illustrated in Figure 1 the integrated circuit 2 iacludes various dedicated<br>
. SIMD processing elements iacludiag a SIMD register data store 20, dedicated SIMD<br>
processing logic 18 and reordering logic 24. A load store imit 22 is shared with the<br>
scalar portion and could be the same or a modified version of the load store unit<br>
) conventionally found within a scalar processor.<br>
The instruction pipeline 12 is extended with additional pipeline stages which<br>
serve to control SIMD processing operation via a dedicated SIMD decoder 16. (It<br>
will be appreciated that in other embodiments the SIMD pipehne may be provided in<br>
1) parallel with the scalar pipeline.) The SIMD decoder 16 generates SIMD control<br>
signals which control the operation of the SIMD processing elements, such as reading<br>
of SIMD registers, writing of SIMD registers and the configuration of the SIMD<br>
processing logic so as to perform the desired data processing operations. The SIMD<br>
pipeline stages follow the scalar stages resulting in the SIMD portion of the processor<br>
1 i effectively seeing a different execution point to the scalar portion. This can result in<br>
the need for some interlocking as will be discussed below:<br>
The reordering logic 24 serves the purpose of reordering data elements<br>
retrieved from a memory (not illustrated) coupled to the integrated circuit 2 in to an<br>
2 ) order more suited to the desired SIMD processing operation. This reordering logic<br>
24, its operations and advantages will be discussed further below. There axe also<br>
provided load and store FIFOs 23 and 23' between the load store unit 22 and the<br>
reordering logic 24.<br>
2 J The scalar register data store 4 can in this example be considered as being<br>
divided into a fixed number of fixed length registers, such as the conventional 16 32-<br>
bit ARM registers. In contrast, the SIMD register data store 20 provides a block of<br>
storage which may be addressed/accessed in a flexible way depending upon the<br>
parameters associated with the SIMD data processing instruction concemed. More<br>
3) particularly, the SIMD data processing instruction specifies source and destination<br>
register numbers, data element sizes and register sizes associated with the data<br>
processing instruction. These parameters are together combined by the SIMD<br>
decoder 16 and read/write ports nf the register data store 20 to control the mapping of<br>
the different portions and accordingly data elements stored within the SIMD register<br>
3 5 data store 20 to the register -being accessed. Thus, SIMD registers of differing si^es,<br>
differing data element sizes and the like can effectively be aliased together (i.e. these<br>
^ registers can be considered as overlapping and accessible via different register<br>
specifiers, register size and data element size combinations as may be desired. The<br>
SIMD decoder 16 and the read/write ports can- be considered to provide register<br>
j accessing logic in this example embodiment).<br>
Figure 2 schematically illustrates the read and write port arrangement which<br>
may be provided for the SIMD register data store 20. In this example thirty tvs^o<br>
SIMD registers are capable of being specified by the register specifying field (5 bits)<br>
1) within the SIMD data processing instructions. N read ports are associated with the<br>
SIMD register data store 20. The minimum granularity-supported is a 64-bit register.<br>
value. In this example, tlie register sizes directly supported are 64-bits and 128-bits.<br>
It will be readily apparent to those in this field that this arrangement could be scaled<br>
to support 256-bit and higher register sizes directly, or indirectly by synthesis using<br>
15 supported instructions with smaller sizes of register. Figure 2 schematically illustrates<br>
M de-multiplexers serving as write ports to the SIMD register data store 20, It will be<br>
appreciated that in practice such de-muitiplexers are provided in the form of<br>
appropriately directed enable signals to rows of storage elements wdthin the SIMD<br>
register data store together with the action of multiplexers routing the desired inputs<br>
23 to their destination.<br>
Figure 3 illustrates a particular example in which two 64-bit SIMD register<br>
values (denoted as a D double words) each containing.multiple data elements are<br>
multiplied together to generate multiple output data elements that are stored together<br>
25 in a 128-bit register (denoted as a Q quad word). Separate read ports are arranged to<br>
read the source SIMD register values Di and D2 from the SIMD register data store 20.<br>
Two write ports act together to respectively allow the first Q [63:0] portion and<br>
second Q [127:64] portion of the 128-bit result to be written back to the SIMD<br>
register store 20. It will be appreciated that the data element size within the D<br>
: 0 registers and the Q registers can vary. As an example, four 16-bit data elements may<br>
be contained within each of the -source D registers with the destination Q register<br>
containing a set of corresponding four 32-bit data elements being the result of the<br>
multipKcati-on. In thi-s example it will be seen how the number of lanes of parallel<br>
processing (four) remains constant whilst the data element size is increased from 16-<br>
: 5 bits to 32-bits as required by the multiplication operation being performed.<br>
^ u ^ ' '• -" • • - -• •-•<br>
Figure 4 illustrates 'various different types of relationship between source<br>
register size and destination register size which may be supported. In the uppermost<br>
example given the number of lanes of parallel processing remains constant and the<br>
j data element size remains constant. In the second and fourth examples the number of<br>
lanes of parallel processing remains constant but the data element size changes<br>
between the source and the destination. In the third example the two source elements<br>
have different data element sizes. The SIMD processing structure and techniques of<br>
the present system support these different types of data processing instruction as will<br>
1) be described further below. The final three examples are unary operations with a<br>
( single input variable. The fifth example keeps the same data element size. The sixth<br>
example doubles the data element size and the seventh example halves .the data<br>
element size.<br>
1) Figure 5 schematically illustrates the syntax of a SIMD data processing<br>
instruction. The first portion of the syntax specifies the SIMD operator concerned, in<br>
this case a multiplication operation. This is followed by a field indicating the output<br>
data element size and other characteristics of the output data elements. In this<br>
example the output data elements are 16-bits in length and are signed integers. The<br>
2} next field indicates the input data element size and characteristics, in this case signed<br>
8-bit integers. The next field indicates the destination register size and register<br>
specifier. In this example the 128-bit quad word SIMD register with the register<br>
specifier 12 is to be used as the destination SIMD register. The two source SIMD<br>
registers are each double word 64-bit registers with the register specifiers respectively<br>
2 5 being " 1 " and "4". Further information on the syntax is described below.<br>
A set of data types to represent the different data formats are defined. These<br>
are described ic Table 0. Most instructions use at least one data type quaUfier to<br>
determine the exact operation. However, operations do not necessarily support all data<br>
30 types. The data type is applied as a suffix to the fields indicating the data element size<br>
and characteristics.<br>
a-utiiuju-u—. - - - -. -,. — . • - - £-Sji."<br>
•<br>
Data t)'pe Qualifier Interpretation<br>
.<size> Any element of <si2e> bits<br>
.I<size> Signed or unsigned modulo integer of <si2e> bits<br>
.F<size> Floating-point number of <size> bits<br>
.P<size> Polynomial over {0,1} of degree less than <size><br>
.S<size> Signed Integer of <si2e> bits<br>
.U<size> Unsigned Integer of <size> bits<br>
I Table 0<br>
Figure 6 illustrates how the SIMD register data store 20 may be viewed as<br>
' ) being divided into thirty two 64-bit registers or sixteen 128-bit registers. These<br>
registers map to the same physical SEMD register data store 20 and accordingly alias<br>
together. As an example, a data element within register DO may also be accessed as a<br>
data element within register QO.<br>
1) Figure 7 schematically further illustrates the overlap betAveen the 64-bit and<br>
128-bit registers. As illustrated, a 128-bit register Q(n) corresponds to two 64-bit<br>
registers D(2n+1) and D(2n).<br>
Figure 8 schematically illustrates example data elements which may be stored<br>
1 &gt; within SMD registers of differing sizes. In the upper portion of Figure 8, a 128-bit<br>
SIMD register is illustrated as either containing four 32-bit data elements or eight 16-<br>
bit data elements. The data elements may be signed or unsigned integers, floating<br>
point numbers or other formats of number as desired and suited to the parallel<br>
processing to be performed.<br>
23<br>
The lower portion of Figure 8 illustrates a 64-bit SIMD register which may<br>
contain either two signed 32-bit integers or four unsigned 16-bit integers. Many other<br>
possibilities are available and will be apparent to those in the technical field.<br>
25 Figure 9 schematically illustrates how an individual -scalar value within a<br>
SIMD register may be referenced. The illustrated SIMD register. 26 contains four<br>
signed integer values. If this SBVDD register is considered as register Dn, then the<br>
different individual signed integer values can be denoted as Dn[3] to Dn[0]. Such<br>
referencing of individual data elements within a SIMDD register is used, for example,<br>
^ [• when performing register transfer instructions which select one of the data elements<br>
within a SIMD register and move it to or from one of the registers within the scalar<br>
register data store 4.<br>
Figure 10 illustrates how a SIMD data processiag instraction may be<br>
performed with the number of processing lanes remaining constant and the data<br>
element size remaining constant between the two source registers and the destination<br>
register. In this example the source SIMD registers are D registers (64-bits and<br>
1) containing four 16-bit data elements) having four parallel processing lanes. The<br>
! destination SIMD register is also a 64-bit D register containing four result 16-bit data<br>
; element values.<br>
In contrast to Figure 10, Figure l lA illustrates an example in which the<br>
1J destination SIMD register is twice the width of the source SIMD registers. The<br>
number of lanes of processing remains constant but the data element size doubles.<br>
This type of behaviour is suited for use with SIMD operations such as multiply, add,<br>
subtract and shift (particularly left shift). Figure IIB illustrates an example in which<br>
the destination SIMD register is half the width of the source SIMD registers. This<br>
2) type of instruction is useful for add and shifts (particularly right shifts).<br>
The ability to alter data element size between source and destination whilst<br>
maintaining the number of processing lanes allows sequences of SIMD data<br>
processing instructions to be built up without the requirement for data element<br>
2 5 reordering or doubling up of instructions as a consequence of changes in data element<br>
size produced by the data processing operations performed. This is a significant<br>
advantage in terms of processing speed, code density, power consumption and the<br>
Uke.<br>
3 3 Figure 12 schematically illustrates the scalar register data store 4 and the<br>
SIMD register data store 20 coupled together by register transfer logic 28. Control<br>
signals received from either or both the scalar decoder 14 or the SIMD decoder 16<br>
control the register transfer logic 2B in response to register transfer instructions within<br>
the instmction pipeline 12 to move data between a specified register within the scalar<br>
3 5 register data store 4 and a-specifi'ed position within a specified register of the SBVH)<br>
register data store 20. A data value moving from the scalar register to the SIMD<br>
register may also be copied to all positions within the SMD register as is illustrated<br>
in Figure 13. This type of register transfer instruction with duplication is well suited<br>
to rapidly populating all processing lanes within a SIMD register with values, such as<br>
5 scaling values, which need to be appHed to different other operands within SIMD<br>
registers by the SIMD processing logic IS.<br>
Figure 14 illustrates a different type of register transfer instruction. In this<br>
example a 32-bit scalar value A is moved to a specified position (lane) within the<br>
1) SMD register. The other lanes maintain their original values. The scalar value is not<br>
duplicated across the entire scalar register. The position within the destination scalar<br>
register can be changed by an appropriate field value within the register transfer<br>
instruction. This type of operation allows an individual data element within a SIMD<br>
register to be populated with a data value taken from the scalar register data store.<br>
1 5<br>
Figure 15 illustrates a further type of register transfer instruction. In this<br>
example a 16-bit data element from within the SIMD register is taken from a specified<br>
variable position within that SEVID register and copied to one of the scalar registers.<br>
Since the scalar register is a 32-bit register, then the data element is in this example<br>
2) sign extended. The data element could instead be zero extended depending upon the<br>
requirements of the particular algorithm or system.<br>
Figure 16 is a flow diagram schematically illustrating an example type of<br>
processing in which the register transfer instructions of Figure 14 and Figure 15 may<br>
2j be advantageously employed. At step 30 some SIMD processing is performed in<br>
parallel upon multiple lanes each containing then: own data elements. At some point this processing requires a data manipulation to be performed which is either not !<br>
supported by the SIMD processing logic 18 or can only be inefficiently so supported.<br>
hi this circumstance it is desired to separately move the individual data elements<br>
3) across to the scalar processing system to allow this complex data operation to be ,<br>
performed. Step 32 selects the first data element to be so moved. Step 34 then<br>
executes a register transfer instruction such as that illusfrated in Figure 15. Step 36<br>
executes the desired complex processing upon the individual data element now in the<br>
scalar portion of the system. When this complex processing has been completed, step<br>
3 5 y&amp; executes a register transfer instruction such as that illustrated in Figure 14 to return<br>
the now modified data element back to its original position. Step 40 determines<br>
whether the last data element has been reached, and if this is not the case the step 42<br>
selects the next data element before returning processing to step 34. If all of the data<br>
elements which required the complex operation to be perfonned upon them have been<br>
&gt; moved across to the scalar system, subject to the desired processing and moved back<br>
to the SIMD system, then processing proceeds fi-om step 40 to step 44 at which the<br>
parallel SIMD processing is resumed.<br>
Data processing instructions specifying SIMD registers for accessing the<br>
1) register data store include one or more register fields encoding a register numver of a<br>
register to be accessed. The 5-bit register specifiers used are designed to be the same<br>
as those used by the AJRM Vector Floating Pouit (VFP) unit - that is, the instruction<br>
' bits that specify a register are:<br>
-<br>
1 j * For destiaation registers:<br>
D = bit[22]<br>
Rd-bits[15:12]<br>
* For first source register specifiers:<br>
2) N = bit[7]<br>
Rn = bits[19:16]<br>
I * For second source register specifiers: ;<br>
m = bit[5]<br>
2 5 Rm = bits[3:0]<br>
Furthermore, the use of these bits is chosen so that Di registers and word scalars are i<br>
encoded consistently with the way that VFP specifies double- and single-precision ;<br>
registers respectively, and the encodings for Qi registers and haLFivord scalars follow<br>
3) the same principles. The following describes how (D,Rd) are used; (N,Rn) and •<br>
(MjRm) are used analogously; ' •<br>
Qd: Qi register number is (D,Rd[3]JR.d[2],Rd[l])<br>
Corresponding Di register numbers are (D,Rd[3],Rd[2],Rd[l],0) and t<br>
3 5 (D,Rd[3],Rd[2],Rd{l],l) I<br>
j.-.ueaii3J.-_i...— , . - . . , . — -<br>
Rd[0] Should Be Zero<br>
Dd: Di register number is (D,Rd[3],Rd[2],Rd[l],Rd[0])<br>
1 Word scalar:<br>
Di register number is (0,Rd[3],Rd[2],Rd[l],Rd[0])<br>
word[D] is selected from register on little-endian basis<br>
Half\vord scalar:<br>
1) Di register number is (0,0,Rd[2],Rd[l],Rd[0])<br>
halfword[(D,Rd[3])] is selected from register on little-endian basis.<br>
Byte scalar:<br>
Di register number is (0,0,0,Rd[l],Rd[0])<br>
1 &gt; byte[(D,Rd[3],Rd[2])] is selected from register on little-endian basis.<br>
Thus, the bits D, Rd[3], Rd[2], Rd[l] and Rd[0] may be considered as<br>
mappable to a 5-bit contiguous field which is rotatable by a number of bit positions<br>
dependent upon the register size for the register number. In practice the register<br>
2) encoding bits are not mapped or rotated as separate operations but are supplied to the<br>
reiger accessing logic to form a row address and a column address for accessing the<br>
register data store with a movable mask being apphed depending upon register size to<br>
select the correct portions of the bit to serve as row and portion column addresses.<br>
2) In accordance with embodiments, load and store instructions are provided for<br>
moving data between the SIMD register file 20 (see figure 1) and memory. The load<br>
instructions can be used to load data elements from memory into specified registers,<br>
whilst the store' instructions are used to store data elements from specified registers to<br>
memory. These load and store instructions are designed to support the movement of<br>
33 data required by algorithms using the SIMD processing logic 18. The load and store<br>
instruction.; of embodiments specify the size of data elements that they are loading<br>
and storing, ;uid this information is used to provide a consistent ordering within a<br>
register regardless of the endiaimess of the memory system.<br>
^ The load and store instructions of embodiments allow a number of data<br>
elements from a continuous block of memory to be loaded into or stored from the<br>
SIMD register file 20. hi accordance with one embodiment, accesses can be<br>
performed at any byte alignment,'and load or store up to 32 bytes.<br>
The load and store instructions of embodiments are considered to access the<br>
data from memory in which the data elements are arranged into structures, with each<br>
structure having a number of components. In accordance with one embodiment, the<br>
structures in memory can contain between one and four components where a<br>
1) component can have any data type size that is recognised by the SIMD processing<br>
logic 18, in preferred embodiments these data type sizes being 8, 16, 32 or 64-bits.<br>
Some conunon examples of structure formats used in embodiments are shown in the<br>
following table:<br>
Format Description<br>
(a) Single component<br>
(x, y) 2-D Position Coordinate<br>
(real, imm) Complex Number<br>
(x, y, z) 3-D Vector<br>
(r. g, b) Pixel<br>
[ (x, y, z, w) I 4-D Vector<br>
1 5<br>
TABLE 1<br>
For any particular load or store instruction, each structure in memory the<br>
subject of the access will have the same structure format, and accordingly will include<br>
the same number of components. The load and store instructions are arranged to<br>
2) identify the number of components in the structure format, and this information is<br>
used by the reordering logic 24 to provide de-interleaving of data elements when<br>
performing load operations, and interleaving of data elements when performing store<br>
operations, allowing data to be arranged in registers such that the difier-ent data<br>
elements of the structure appear in different registers. This concept is illustrated !<br>
2 5 schematically in Figure 17 for the situation of a load instruction used to load a number<br>
of data elements from a continuous block of memory into three specified registers. In<br>
this example, the specified registers are the three 64-bit registers DO 220, Dl 225 and<br>
D2 230. In this example, the stmcture format is a 3D vector format, and accordingly<br>
•each stmcture 210 in the memory 200 has three components 2r5.<br>
30<br>
^ As shown in figure 1, the load instruction is routed from the instruction<br>
pipeline 12 to the scaler decoder 14, resulting in appropriate memory access control<br>
signals being sent to the load store unit (LSU) 22. The LSU then accesses the<br>
required four structures A[0], A[l], A[2], and A[3] from a continuous block of<br>
5 memory. Accordingly, the LSU 22 can operate iu its normal manner. Thereafter, the<br>
data is routed via the reordering logic 24 which is arranged to de-interleave the three<br>
components in each structure, such that data elements pertaining to the X component<br>
are routed to register DO 220, data elements of the Y component are routed to register<br>
Dl 225, and elements of the Z component are routed to register D2 230.<br>
1)<br>
I The abihty to load from an array of structures and separate the information<br>
into separate registers as part of the load operation can be used to allow data to be<br>
immediately ready for efficient SIMD processing.<br>
1) The reordering logic 24 is also arranged to perform an analogous process<br>
when storing data from specified registers back to the continuous block of memory, in<br>
this instance the reordering logic 24 performing an interleaving operation in order to<br>
reproduce the structure format prior to the data being stored in memory.<br>
2) As can be seen from Figure 1, the load instructions are routed from the<br>
instruction pipeline to the scalar decoder 14 prior to those instructions reaching the<br>
SEMD stages of the instruction pipeline 12. This enables the process of loading the<br>
data into the SIMD register files 20 to occur earlier than would otherwise be possible,<br>
and has the benefit that a subsequent SIMD processing instruction will not typically<br>
25 have to wait for the data to be loaded before it can begin execution, thereby<br>
significantly reducing the latency of load operations. Store instructions however will<br>
need to be passed through the instruction pipeline until they can be routed to the<br>
SIMD decoder 16, from where appropriate confrol signals can be used to control the<br>
accessing of the data from the SIMDD register files 20, and the appropriate reordering<br>
3 3 within the reordering logic 24 prior to the data being stored via the LSU 22 back to<br>
the memory. However, certain parts of the store instruction can be performed whilst<br>
in the ARM portion of the instruction pipeline 12, for example checking the address,<br>
memory access pennissions, etc., to ensure that the instruction will not cause a data<br>
abort.<br>
?5<br>
j . ^ u a 3 « u _ i — •-- ^ ^ - . - • - - - - • --- • • ,•.._- - -- • . ,—<br>
The load and store instructions of embodiments can be viewed as following a<br>
single syntax. The syntax can be expressed as follows:<br>
V(LDlST)<st>.<dt>{@<a>} <regust>, { <n>J <addr><br>
&gt; where<br><st> The Structure Format<br>
Data elements in memory are considered as an array of structures having <st><br>
I) components. This information is used to interleave and de-interleave data elements as<br>
they move between memory and the SIMD register store to enable efficient SIMD<br>
processing.<br>
' <dt> The Data Type<br>
1) This determines the size of the data elements being loaded<br><a> An Alignment Specifier (optional)<br><reghst> The SIMD Register List<br>
2) This determines the SIMD register state that will be written to or read from. For loads,<br>
this is precisely the parts of the SIMD register file that will be affected by the<br>
instruction. The register list is considered a collection of data elements of size <dt>,<br>
spht in to <st> vectors of equal length.<br>
Note that the number of bytes within the register list is not necessarily the same as the<br>
2) number of b3^es of memory accessed. See the <n> options and Figures 20A to 20C.<br><n> Number of Structures (optional)<br>
This defines the number of structures to load or store. This allows a register list to<br>
3) only partially be loaded with memory data, and the remaining parts be zeroed. When<br>
it is not supplied, it takes the default value which means the register list and memory<br>
access size are the same.<br>
default <n> := elements<dt>(<reglist>) / <st><br>
3) <addr> The Addressing Mode used for the access<br>
In accordance with embodiments, the addressing mode can take a variety of<br>
forms, and in particular the three forms illustrated below:<br>
;// <addr><br>
4) [Fn] ;// address := Rn<br>
[Rxi\! ;// address := Rn, Rn := Rn + transfer_size (where "transfer__size" is the<br>
amount of memory accessed)<br>
[Rn], Rm ;// address := Rn, Rn ;= Rn + Rm<br>
The semantics discussed above allow single structures or multiple structures to<br>
be loaded or stored, logical zeros to be written to remaining parts of registers that are<br>
j not filled with data firom memory, and insertion into registers by using a register list<br>
containing scaler qualifiers (e.g. D0[1]). It will be appreciated that in embodiments<br>
the actual load and store instructions that are provided will typically be a subset of all<br>
possible combinations of the above syntax.<br>
1) With regard to the structure format, Figure 18 illustrates three possible<br>
examples of structure format, and their corresponding "st" value. As can be seen fi:om<br>
' Figure 18, the first structure 250 has only a single component, and accordingly the st<br>
( value is one. In the second example, the structure 255 has two components, for<br>
example representing real part x and imaginary part y of a complex number, and<br>
1 j accordingly the st value is tAvo. Finally, in the third example, the structure 260 has<br>
three components, representing R, G and B data elements, and accordingly the st<br>
value is three.<br>
To help illustrate some of the flmctionality available when using the load and<br>
2) store instructions of embodiments. Figures 19 to 22 illustrate specific examples of<br>
load and store instructions. Considering first Figures 19A to 19C, Figure 19A<br>
illustrates the reglist states specified by a store instruction<br>
\,<br>
(' VST 2.16 (DO, Dl, D2, D3}, [rl]<br>
25<br>
This instruction is used to store multiple structures firom the specified register<br>
files to a continuous block of memory. As can be seen, Figure 19 A identifies that the<br>
reglist contains four specified registers DO 270, Dl 280, D2 290 and D3 300. As<br>
shown in Figure 19B, these registers can be considered as being split into "st" vectors<br>
3 D (i.e. 2) of "dt" sized (i.e. 16-bit) data elements. In register DO, these data elements are<br>
referenced by the numeral 275, in Dl by the numeral 285, in D2 by the numeral 295<br>
and in D3 by the numeral 305. As can be seen fi-om Figure 19C, the reordering logic<br>
24 is arranged to interleave data elements from these two vectors so that each data<br>
element 314 is -stored to the memory 310 in the required stincture format for the<br>
35- structure 312.<br>
Figures 20A to 20C are a similar set of diagrams illustrating the operation<br>
performed by the mstruction<br>
VLD2.16{D0,Dl},#lJrl]<br>
Figure 20A illustrates the collection of the regUst state, identifying the<br>
registers DO 270 and Dl 280. Figure 20B tiaen illustrates how these registers are split<br>
into St vectors (i.e. 2) of dt sized (i.e. 16-bit) data elements.<br>
1} In contrast to the example of Figures 19A to 19C, this instruction specijBes an<br>
"n" parameter identifying the number of structures to be accessed, in this example n<br>
being 1. Accordingly, for this load instruction, n x st (i.e. 1x2) data elements need to '<br>
be read from memory beginning at the effective address and to then be distributed into<br>
the vectors in a round-robin allocation beginning at the lowest indexed element of the<br>
15 first vector. This process is illustrated in Figure 20C, and results in the data element<br>
Xo of the first component 314 being written into the lowest 16 bits of the register DO,<br>
• whilst the data element yo of the second-component is written to the lowest 16 bits of<br>
the register Dl. In accordance with this embodiment, any parts of the register state<br>
not -v^nitten to once all of the data elements have been loaded are set to zero. It should<br>
: 0 be noted that for the equivalent store instruction, n x st data elements are stored in the<br>
reverse manner to the loads.<br>
Figures 21A to 21C illustrate another particular example in which the syntax<br>
for the instructions is extended to allow two data types to be specified, namely the<br>
: 5 data type for the data elements being accessed and the data type for the resultant data<br>
elements to be loaded into the registers, or stored to memory. Accordingly, Figures<br>
21A to 21C illustrate the operation performed by the instruction<br>
VLD 2.32.S16 {DO, Dl, D2, D3}, [rl]<br>
. !0 As shown in Figure 21 A, the reglist state is collected, identifying registers DO<br>
270, Dl 280, D2 290 and D3 300. Then, as shown by Figure 2 I B , this register state is<br>
spHt into st vectors (i.e. 2) of dt sized (i.e. 32-bit) data elements, since this instruction<br>
specifies that by the time the data elements are stored within the registers, they will be<br>
32 bits in length.<br>
-55-<br>
As also specified by the instniction, the data elements ia memory are 16-bits<br>
^ in length, and accordingly once the data elements have been accessed from the<br>
memory 310, they will be passed through some transformation logic 340 (which<br>
optionally can be incorporated as part of the reordering logic 24) which is used to then<br>
5 extend each of the 16-bit data elements to form new 32-bit data elements 342. These<br>
data elements are de-interleaved so that data elements of the first component are<br>
stored Avithin registers DO and Dl, whilst data elements of the second component are<br>
stored within registers D2 and D3.<br>
13 Figures 22A to 22C illustrate a further example, and in particular illustrate the<br>
J operation of the instruction.<br>
VLD2.16{D0[2],D1[2]}, [rl]<br>
Whilst this instruction can share the same syntax as the previous instructions,<br>
15 this instruction is conceptually a different type of instruction, in that rather than<br>
loading data elements from a continuous block of memory in which the data elements ^<br>
are stored as an array of structures, this load instruction only loads a single structure.<br>
Further, the data elements of the single structure that are loaded can be placed into<br>
any chosen lane of processing within the specified registers. Hence, when<br>
2 3 considering 64-bit wide registers, and 16-bit data elements, there are four possible<br>
lanes of processing within which the data elements can be placed. In preferred<br>
embodiments, the chosen lane for the particular instruction is indicated within the<br>
reghst data by identifying the particular lane.<br>
2 5 Considering Figure 22A, it can be seen that when the reglist state is collected,<br>
this identifies lane 2 320 of register DO, and lane 2 325 of register Dl. As shown in<br>
Figure 22B, these are then split into st vectors (i.e. 2) of dt sized (i.«. 16-bit) data<br>
elements. Thereafter, as shown in Figure 22C, once the structure 312 has been<br>
accessed from the memory 310, the reordering logic 24 is arranged to direct the data<br>
3} element XQ to lane 2 of the DO register 330, Avhilst directing the data element yo to lane<br>
2 of the Dl register 335. In this example, it will be appreciated that the lanes can be<br>
identified in the range from 0 to 3.<br>
For the interested reader, the following tables identify various types of load<br>
3) and store instructions that may be provided in one particular embodiment:<br>
I, .<br>
^ ^ Mnemonic Data Type Operand Format Description<br>
i9 VLDl ,S <list>, <ad> Load multiple elements<br>
.16<br>
.32 <iist> :=<br>
&gt; .64 {DJ<br>
I {D„, D„+i}<br>
I {D„, D,H, D„«}<br>
I {Dn, D„4.i, D^^-z, D„^3}<br>
VLDl .8 <list>, #UIMM, <addr> Load multiple elements and Zero<br>
13 .16 UIMM_lreg = (l)..(a-l)<br>
.32 <ust>:= UIMM_2reg = (a+l)..(b-l)<br>
{Dn} where<br>
|{D„,D„+i} a = (64/size<dt>)<br>
b = (128/size<dt>)<br>
15 VLDl .8 Dd[x], <addr> Load single element<br>
.16<br>
32<br>
' VSTl .8 <list>, <addx> Store multiple elements<br>
.16<br>
2 0 .32 <list> :=<br>
.64 {D„}<br>
I {D„, D„+,}<br>
! {D„, D„+„ Dn+z}<br>
1 {Dn. Dn+l. Dn+2. Dn+j}<br>
2 5 VSTl .8 <iist>, iWIMM, <addr> Store m\iltiple elements<br>
.16 im4M_lreg=(2)..(a-l)<br>
UIMM_2reg = •(a+l)..(b-l)<br>
.32 <list> := where<br>
{D„} a = (64/size<dt>)<br>
30 IPii,D„+i} b = (I28/size<dt>)<br>
VSTl .8 Dd[x], <addr> Store siogle element<br>
.16<br>
32<br>
J 5 VSTl<br>
Examples<br>
VLDl.16 DO, [Rl]<br>
VLD1.8 {D0,D1},P12]!<br>
\n.D1.8 Q2, #10, [R2], R7<br>
^ 0 VLDl. 16 D20[3], [R8], Rl<br>
VST1.32 P8,D9,D10,D11},{R0]!<br>
VST1.32 Q7, #3, [RID]<br>
VST1.8 D30[0], [RO], R14<br>
^5 TABLE 2<br>
. 1 .1 |];-;i:iri4:i.:. i _. _^<br>
- ^<br>
™ Mnemonic Data Type Operand Format Description<br>
VLD2 .8 <list>, <addr> Load multiple 2-element structures<br>
.16<br>
5 .32 <list>:=<br>
{D.,D„«}<br>
I {Dn, D„«}<br>
I {Dn&gt; Dn+b Dn+2; Dn+3}<br>
VLD2 .8 <list>, #1, <addr> Load single 2-element structure and<br>
10 Zero<br>
.16<br>
.32 <list>:= I<br>
{Dn,D„,,}<br>
1{D„,D„,2}<br>
15<br>
VLD2 .8 <list>, <addr> Load single 2-element structure<br>
.16 where<br>
.32 <list> := list {D„[x], D„+2[x]} not available<br>
{D„[x], Dn+i [x]} when dt = 8<br>
iO I {Dn[x], D„+2[X]} I<br>
VST2 .8 <list>, <addr> Store multiple 2-element structures<br>
.16 .32 <lis1>:=<br>
2 5 {Dn,D„+,}<br>
I {D„, D„+2}<br>
I p „ , D„+„ D„«, D„«} I<br>
VST2 .8 <list>, <addr> Store single 2-element structure<br>
3D .16 where<br>
.32 , <list>:== list {Dn[x],Dn+2[x]} not available<br>
when dt = 8<br>
{D„[x],D„«[x]}<br>
• |{DnM.Dnt2W}<br>
35 Examples<br>
VLD2.16 {D0,D1}, [Rl]<br>
VLD2.32 {D2, D3, D4, D5}, [R3]!<br>
VLD2.8 {D0,D1},#1,[R1],R7<br>
VLD2.16 {D2[l],D4[l]},pi6]<br>
40 VST2.8 {D20, D21}, [RO]<br>
VST2.32 {D20[0],D21[0]}.[R5],R6 .<br>
TABLE 3<br>
• ^ Mnemonic Data Type Operand Format Description<br>
VLD3 .8 <list>, <addr> Load multiple 3-element structures<br>
.16<br>
5 .32 <list> :=<br>
{Dn, D^i, D„^2}<br>
VLD3 .8 <lis1> Load single 3-element structure and<br>
Zero<br>
13 .16<br>
.32 <list> :=<br>
(Dn, Dn+i, Dn+2}<br>
I (Dm Dn+2, Dn+4}<br>
VLD3 .8 <list>, <addr> Load single 3-element structure<br>
15 .16 where<br>
.32 <list>-.= list {D„[x], D„+2[x], Dn+4[x]} not<br>
available when dt = 8<br>
( {D„[x],D„«[x],D„+2W}<br>
((Dn[x],Dn^2W,Dn^4M}<br>
2 3 VST3 .8 <list>, <addr> Store multiple 3-element structures<br>
.16<br>
.32 <list> :=<br>
{Dn, DnH-i, Dn+2}<br>
{DID Dn+2i Dn+4}<br>
2J VST3 .8 <list>, <addr> Store single 3-element structure<br>
.16 where<br>
.32 <list>:= list {Dn[x], Dn+2[x], Dn+4[x]} not<br>
available when <it></it>
{D„[x],D„^,[x],D„+2[X]}<br>
3) |{D„[X3,D„«W,D„M[X]}<br>
Examples<br>
VLD3.8 {D0,D1,D2},[R1]!<br>
( VLD3.16 {D2,D3,D4},#1,[R3],R4<br>
3) VLD3.16 {D2[1],D3[1],D4[1]},[R3],R4<br>
VST3.32 {D20, D22, D24}, [R7]<br>
VST3.8 {D0[0], D1[0], D2[0]}, [RIO], R14<br>
TABLE 4<br>
4<br>
-30-<br>
" Mnemonic Data Type Operand Format Description<br>
VLD4 .8 <list>, <addr> Load multiple 4-element structures<br>
.16<br>
5 • .32 <list> :=<br>
Dn+2jDn+3} j<br>
Dn+4; Dn+S; ^ ]<br>
VLD4 .8 <list>, #1, <addr> Load single 4-element stracture<br>
I and Zero<br>
n .16<br>
.32 <list>:= I<br>
(Dn, Dn+I, Dn-f^, Dn+3}<br>
1 {Dfl; DiH-2) Dn+4; Dn+6}<br>
VLD4 .8 <lis1>, <addr> Load single 4-element stracture<br>
1) .16 where<br>
.32 <list>:= list {Dn[x],D„+2[x],D,+4[x],D„+6W}<br>
not available when dt = 8<br>
{D„[x], D„+i[x], I<br>
D„«[x],D„+3[x]}<br>
2) I {D„[x], D„«[x], I<br>
Dn+4[X3, Dn+fiW) VST4 .8 <list>, <addr> Store multiple 4-element structures<br>
.16<br>
.32 <list>:=<br>
2) (Dn, Dn+i, Dn+2, Dn+3}<br>
^ I {Dn, Dn4-2! Dn+4; Dn+s}<br>
VST4 .8 <list>, <addr> ' Store single 4-element stracture<br>
.16 where<br>
.32 <iist>:= Iist.{Dn[x],D„+2[x],D„+4W,D„+6[x]}<br>
3 ) not available when dt = 8<br>
{D„[x],D„+,[x],<br>
D„«[x],D„„[x]}<br>
I {D„[x3, D„.2[x],<br>
D^4{X], Dn+6[X]}<br>
3.;<br>
Examples<br>
VLD4.8 {DO, Dl, D2, D3}, [Rl]!.<br>
VLD4.16 {D2,D3,D4,D5},#1,[R3]<br>
VLD4.16 {D2[1],D4[1],D6[1],D8[1]},[R3],R4<br>
411 VST4.32 {D20, D22, D24, D26}, [R7]<br>
VST4.8 {D20[5],D21[5],D22[5],D23C5]},[R1],R4<br>
TABLES<br>
- 3 1 - _ _ _ i<br>
-J i i r ' i i i j i . i — I •• - - ---- - - • • - — - OQ.<br>
I<br>
In one embodiment, the reordering logic 24 of figure 1 takes the form i<br>
^ illustrated in figure 23. The logic of figure 23 includes two multiplexers 350, 355 at its |<br>
inputs, which in the event of a load instruction are arranged to receive data from a load<br>
FIFO 23 associated with ihe LSU 22 illustrated in figure I, or in the event of a store<br>
:! instruction are arranged to receive data from the SHVED register store 20. Further, in<br>
some situations, a load instruction may also cause the logic of figure 23 to receive data<br>
firom the SIMD register store 20. The multiplexers 350, 355 are controlled to choose<br>
between the different inputs, and to route the chosen inputs to the associated input |<br>
registers 360, 365. hi one embodiment, each input register is able to store 64 bits of<br>
10 data. The data stored in the input registers is then read through the crossbar<br>
multiplexer 375 into the register cache 380, crossbar control register 370 providing<br>
drive signals to the crossbar multiplexer to direct individual bytes of data received<br>
from the input registers to desired byte locations within the register cache. The values<br>
in control register 370 are derived by the instruction decoder.<br>
1 5<br>
As shown in figure 23, the register cache 380 can be considered as consisting<br>
of four registers, and in one embodiment each register is 64 bits in lengfb.<br>
After data has been stored in the register cache 380, it can then be read via<br>
j<br>
2 D output multiplexers 385 to either the store data FIFO 23' associated with the LSU 22<br>
(in the event of a store instruction), or the SIMD register file 20 (in the event of a load<br>
instruction).<br>
"Whilst the byte crossbar multiplexer 375 can read the input registers at byte<br>
: 5 granularity and write into the register cache at byte granularity, the write multiplexers<br>
385 read from the register cache at 64-bit granularity.<br>
The reordering logic 24 is largely autonomous from the rest of the SIMD<br>
processing logic 18, but is given instructions in program order in the same fashion as<br>
I ; 0 other fimctional units within the integrated circuit. In one embodiment, it has two<br>
j register file read ports and two write ports which it confrols itself. In order that j<br>
I hazards are detected and avoided the reordering logic 24 may be arranged to<br>
communicate with some interlock logic (not shown) using scoreboards. !<br>
i 1<br>
-at<br>
Store instructions from the SIMD register file 20 are performed out-of-order<br>
with respect to other SIMD instructions, but remain in-order with, respect to other<br>
store instructions from the SIMD register file. Pending stores are kept in a queue, and<br>
when the store data is ready it is read and passed into the store FIFO 23' associated<br>
5 with the LSU 22 via the reordering logic 24.<br>
In one embodiment, all data passing between memory and the SIMD register<br>
file 20 is routed via the reordering logic 24. However, in an alternative embodiment,<br>
a bypass path around the reordering logic 24 may be provided for situations where it<br>
0 is determined that no reordering is required.<br>
i ' • •'<br>
The register cache 380 is referred to as a "cache" since under certain<br>
conditions it caches register values before they are written to the SIMD register file<br>
20. The register cache holds data in the format that data is to be output from the<br>
] 5 reordering logic 24.<br>
Figures 24A to 24C illustrate the operation of the reordering logic 24 to<br>
implement the necessary reordering required when performing an instruction of the<br>
type VLD 3.16 {DO, Dl, D2}, [rl].<br>
:o<br>
Once the data has been loaded by the LSU 22, then in a first cycle (as shown<br>
in Figure 24A) 64 bits of the retrieved data is loaded via multiplexer 350 into the<br>
input register 360, whilst the next 64 bits are loaded via the multiplexer 355 into the<br>
input registers 365. In the example illustrated in figures 24A through 24C, it is<br>
25 assumed that the structure format represents a 3D vector having components x, y, z.<br>
In the next cycle, as shown in Figure 24B, the 16-bit data elements within the input<br>
registers are read into the register cache 380 via the byte crossbar multiplexer 375<br>
which reorders the data so that any data elements relating to x components are placed<br>
in a first register, any data elements relating to y components are placed in a second<br>
3 0 register, and any data elements relating to z components are placed in a third register<br>
of the register cache. Also during this cycle, the next 64 bits of data from the load<br>
FIFO 23 are loaded via multiplexer 350 into the input register 360.<br>
In tiie next cycle, as shown in Figure 24C, the data elements from the input<br>
35 register 360 ar-e routed throng the byte crossbar multiplex-er into the register cache,<br>
•32-<br>
^ with the X, y and z components being de-interleaved as discussed earlier. As shown<br>
iQ figure 24C, this results in the register cache containing four x components in a first<br>
register, four y components in a second register, and four z components in a third<br>
register. The contents of the register cache can then be output via the write<br>
5 multiplexers 385, two registers at a time, to the registers specified by the load<br>
instruction.<br>
Figures 25A-25D illustrate a second example of the flow of data through the<br>
reordering logic in order to perform the necessary reordering required when executing<br>
1) the instraction VLD 3.16 {D0[1], Dl[l], D2[l]}, [rl]. In accordance with this<br>
I instruction, data is going to be loaded into a particular lane of the registers DO, Dl and<br>
D2, namely the second 16-bit wide lane of four 16-bit wide lanes within those<br>
registers. Before a data element can be stored in a particular lane of a register, the<br>
current contents of the register need to be retrieved, so that when the register is<br>
15 subsequently written to, the contents of the register are written as a whole. This<br>
feature avoids the need to provide for any writing to onl}' a portion of a register in the<br>
SIMD register file 20. Accordingly, during a first cycle, as shown in Figure 25A, the<br>
current contents of the registers DO and Dl are read from the SIMD register file via<br>
the multiplexers 350, 355 into the input registers 360, 365. In the next cycle, as<br>
2} shown in figure 25B, these contents are read into the register cache 380 through the<br>
crossbar multiplexer 375 with the contents of DO being placed in a first register and<br>
the contents of Dl being placed in a second register of the register cache. During the<br>
same cycle, the contents of the register D2 are retrieved from the SIMD register file<br>
via the multiplexer 350 and stored in the input register 360.<br>
25<br>
In the next cycle, as shown in Figure 25 C, the contents of the register D2 are<br>
read into the register cache 380 via the crossbar multiplexer 375, such that they are<br>
stored in a third register of the register cache. During the same cycle, the data<br>
stmcture the subject of the load, which typically will have already have been retrieved<br>
3D by the LSU, is read firom the load FIFO 23 via the multiplexer 350 into the input<br>
registers 360. In the example illustrated in figure 25C, it is again considered that the<br>
structure in memory represents 3D vector data with components x, y and z. In the<br>
next cycle, as shown in Figure 25D, the x, y and z components are read into the<br>
second lane of data elements via the crossbar multiplexer 375, so that tiie data element<br>
j 5 Xo overwrites within the register cache the previous contents of the second lane of<br>
-34'<br>
^ register DO, the component yo overwrites within the register cache the data element<br>
previously in the second lane of the register Dl, and the component zO overwrites<br>
within the register cache the data element previously stored in the second lane of the<br>
register D2.<br>
5<br>
It will be appreciated that at this point the actual contents of the registers DO,<br>
Dl and D2 in the SIMD register file have not yet changed. However, the data stored<br>
in the register cache can now be output via the write multiplexers 385 back to the<br>
registers DO, Dl, D2 to overwrite the previous contents. As a result, it can be seen<br>
13 that a single load instruction can be used to load the components of a particular<br>
structure from memory, and to then insert the individual components of that structure<br>
into different registers at a chosen lane location.<br>
Figures 25E to 25H illustrate a third example of a flow of the data through the<br>
15 reordering logic in order to perform the necessary reordering required when executing<br>
the complementary store instruction to the load instruction that was discussed earlier<br>
with reference to Figures 25A to 25D. Accordingly, Figures 25E to 25H illustrate the<br>
steps required to perform the necessary reordering when executing the instruction<br>
VST 3.16 {D0[1], Dl[l], D2[l]}, [rl]. Hence, in accordance with this instruction,<br>
2 0 data is going to be stored from the second 16-bit wide lane of the registers DO, Dl and<br>
D2 back to memory. As shown in Figure 25E, during a first cycle, the current<br>
contents of the registers DO and Dl are read from the SIMD register file via the<br>
multiplexers 350, 355 into the input registers 360, 365. In the next cycle, as shown in<br>
Figure 25F, the data elements in the second lane, i.e. the values XQ and yo, are read<br>
25 into a first register of the register cache 380 through the crossbar multiplexer 375.<br>
During the same cycle, the contents of the register D2 are retrieved from the SIMD<br>
register file via the multiplexer 350 and stored in the input register 360.<br>
In the next cycle, as shown in Figure 25G, the data element in the second lane<br>
2 0 of register D2 is read into the first register of the register cache 380 via the crossbar<br>
multiplexer 375. Then, in the next cycle, as shown in Figure 25H, the x, y and z<br>
components can now be output by the write multiplexers 385 to the LSU for storing<br>
back to memory. It will be appreciated that at this stage the data-elements have now<br>
been reordered into the structure format required for storage in memory.<br>
:5<br>
^ Figures 26A to 26E illustrate tiie reordering that takes place within the<br>
reordering logic during execution of the following sequence of four instructions:<br>
VLD 3.16 {DO, p i , D2}, #1, [rl]<br>
VLD 3.16 {DO [1], Dl [1], D2 [1]}, [r2]<br>
5 VLD 3.16 {DO [2], Dl [2], D2 [2]}, [r3]<br>
VLD 3.16 {DO [3], Dl [3], D2 [3]}, [r4]<br>
Once the data identified by the first load iustniction has been retrieved by the<br>
LSU, it is read via the multiplexer 350 into the iuput register 360 during a first cycle<br>
13 (see Figure 26A). In the next cycle, it is read into the register cache 380 via the<br>
i crossbar multiplexer 375, such that the x, y and z components are placed in different<br>
registers of the register cache. The "#1" Avithin the first instruction signifies that each<br>
data element should be placed in the least significaut data lanes of each register, and<br>
that the remaining lanes should be filled with logic 0 values, this being shown in<br>
1) figure 26B. Also during this cycle, the data elements identified by the second load<br>
instruction are retrieved into the input register 360. During the next cycle (see Figure<br>
26C), the data elements stored in the input register 360 are moved into the register<br>
cache 380 via the cross bar multiplexer 375, where they are stored in the second lane.<br>
Also during this cycle, the data elements of the third load instruction are placed within<br>
2i) the input register 3 60.<br>
In the next cycle, the contents of the input register 360 are routed via the<br>
crossbar multiplexer 375 into the third lane of the register cache, whilst the data<br>
elements of the subject of the fourth load instruction are retrieved into the input<br>
2: i register 360. This is shown in figure 26D.<br>
Finally, as shown in figure 26E, in the next cycle these data elements are<br>
routed via the crossbar multiplexer 375 into the register cache 380, where they are<br>
stored in the fourth lane. Thereafter, the 64-bit wide chunlcs of data in each register of<br>
3( I the register cache can be output to the specified registers of the SIMD register file.<br>
It should be noted that in contrast to the approach taken in figures 25A to 25D,<br>
the use of the first VLD instruction illustrat-ed with reference to figures 26K to 26E,<br>
whereby once the data elements have been placed in a particular lane, the remaining<br>
3; i lanes are filled with 0 values, avoids the need to retrieve fi:om the SIMD register file<br>
the current contents of any of the registers DO to D2 before any updates are made.<br>
From a review of figures 26A to 26E, it can be seen that the register cache 380 in this |<br>
instance acts as a "-v^nite through cache", since it caches the data elements for a<br>
sequence of load instructions, and when each instruction is completed, -writes the data<br>
5 to the relevant registers of the SIMD register file. However, the register file does not<br>
typically need to be read fi-om whilst each subsequent instruction in the sequence is<br>
being performed.<br>
It is often required in data processing to reduce a so-called vector of elements<br>
1) to a single element by applying a commutative and associative operator 'op' between<br>
all the elements. This will be described as a folding operation. Typical examples of<br>
folding operations are to sum the elements of a vector, or find the maximum value of<br>
the elements in a vector.<br>
15 In a parallel prdcessiag architecture, one known approach used to perform<br>
such a foldiag operation is described with reference to Figure 27. The data elemeAts<br>
[0] to [3] to be folded are contained a register rl. It will be appreciated that a benefit<br>
of parallel processing architectures is that it can enable the same operation to be<br>
performed concurrently on multiple data elements. This is concept can be more<br>
2) clearly understood with reference to so-called parallel processing lanes. In this<br>
example, each parallel processing lane contains one of the data element [0] to [3].<br>
Firstly, at step A, a first instmction is issued which-causes rotation of the data<br>
elements by two places to form rotated data elements in register r2. This places<br>
2) different data elements in each processing lane so that Single Instmction Multiple<br>
Data (SIMD) operation can be applied at step B.<br>
Thereafter, at step B, a second instmction is issued which causes a SIMD<br>
operation to be performed on the data elements in each lane. In this example, the<br>
3 ) resultant data elements of these multiple parallel operations are stored in register r3.<br>
Accordingly, it can be seen that entries in r3 now contain the results of the<br>
combination of half of data elements of the register rl (i.e. r3 contains: [0] op [2]; [1]<br>
op [3]; [2] op [0]; and [3] op [1]).<br>
^ Next, a third instructioii is issued which, causes the results stored in the register<br>
r3 to he rotated by one parallel processing lane at step C and stored in the register r4.<br>
Once again, the rotation of the data elements of stored in r3 with respect to those of r4<br>
enables different data elements to occupy the same parallel processing lane.<br>
5<br>
Finally, at step D, a fourth instruction is issued which causes a further single<br>
instruction multiple data operation to be performed on data elements stored in each<br>
lane and the results are stored in register r5.<br>
1) Accordingly, it can be seen that by using just four instructions all the data<br>
elements across the register can be combined and the results stored in each entry in<br>
the register r5 (i.e. each entry in r5 contains: [0] op [1] op [2] op [3]). The resultant<br>
data element can be read as required from any of the four entries in the register r5.<br>
1:1 Figure 28 illustrates the principle of a folding instruction of one embodiment.<br>
Unlike the conventional arrangement of parallel processing lanes (which is described<br>
with reference to Figure 27) in which each parallel processing lane has a fixed width<br>
throughout the lane which is equal to the width of one data element, in this<br>
embodiment the arrangement of the parallel processing lanes differs^ In this new<br>
2(1 arrangement, the width of each parallel processing lane at its input is equal to the<br>
width of at least two source data elements .and at its output is generally equal to the<br>
width of one resultant data element. It has been found that arranging the parallel<br>
processing lanes in this way provides significant advantages over prior art<br>
arrangements since groups of data elements (for example pairs of data elements)<br>
2' within a single register can be the subject of parallel processing operations. As will be<br>
clear from the discussion below, this obviates the need to perform the data<br>
manipulation operations of the prior art arrangements (i.e. the rotation operations)<br>
since there is no need to arrange data elements in the correct entry locations in further<br>
registers in order to enable multiple operations to occur in parallel.<br>
3(<br>
Accordingly, source data elements d[0] to d[3] are provided in respective<br>
entries in a register. The adjacent source data elements d[0] and d[l] can be<br>
considered as a pair of source data elements. The source data elements d[2] and d[3]<br>
can also be considered as a pair of source data elements. Hence, in this example,<br>
3! there are two pairs ofsource data elements.<br>
-3^-<br>
—" - q^^<br>
• • • ••<br>
W At step (A) an operation is performed on each pair of source data elements<br>
within the register m order to generate a resultant data element, the same operation<br>
occurring on each adjacent pair of source data elements.<br>
Hence, it will be appreciated that the pair of source data elements and the<br>
corresponding resultant data element all occupy the same lane of parallel processing.<br>
It can be seen that after step (A) the number of resultant data elements is half that of<br>
the number of source data elements. The data elements d[2] op d[3] and d[0] op d[l]<br>
1) can also be considered as a pair of source data elements.<br>
At step (B) a further identical operation is performed on a pair of source data<br>
elements in order to generate a resultant data element d[0] op d[l] op d[2] op d[3]. It<br>
can be seen that after step (B) the number of resultant data elements is also half that of<br>
1J the number of source data elements. As mentioned previously, the operations are<br>
commutative and associative operations and so the same resultant data elements are<br>
generated irrespective of the exact order of combination of the source data elements.<br>
Hence, it can be seen that the number of source data elements can be halved as<br>
2 3 a result of each operation and that the same operation can be performed on those<br>
source data elements in order to produce the required result. Accordingly, it can be<br>
seen that tiie required resultant data element can be generated in just two operations<br>
whereas the prior art arrangement of Figure 27 needed to perform at least four<br>
operations. It will be appreciated that this improvement in efficiency is achieved<br>
2 5 through performing parallel processing operations on groups of data elements within a<br>
source register. Although just two pairs of source data elements have been illustrated<br>
for reasons of clarity, it will be appreciated that any number of pairs of source data<br>
elements could have been the subject of the operation. Also, whilst operations on<br>
pairs of source data elements have been illustrated for reasons of clarity, it will be<br>
30 appreciated that any number of source data elements (e.g. three, four or more) could<br>
have been the subject of the operation.<br>
In practice, for efficiency reasons, the folding instruction is arranged to<br>
perform parallel operations on a minimum number of data elements, determined by<br>
35 the smallest supported register size in the register data 'file 20. Figur-e 29 illustrates an<br>
..i-ixxuiiii„i— .. - - ".io- " ' ' """ — ^<br>
^ implementation which generates the same number of resultant data elements as the<br>
number of source data elements.<br>
Source data elements d[0] to d[3] are provided in a register Dn. In order to<br>
j generate the same number of resultant data elements, the source data elements d[0] to<br>
d[3] are also provided in a register Dm- It will be appreciated that the registers D,, and<br>
Dm are likely to be the same register with the SIMD processing logic 18 reading each<br>
source data element from the register Dn twice in order to generate dupHcated<br>
resultant data elements.<br>
n<br>
At step (A), a single SIMD instruction is issued, each pair of source data<br>
elements have am operation performed thereon and a corresponding resultant data<br>
element is generated.<br>
15 At step (B), another single SIMD instruction is issued to cause each pair of<br>
source data elements to have an operation performed thereon in order to generate a<br>
corresponding resultant data element.<br>
Accordingly, it can be seen that all the -source data elements have been<br>
2 0 combined to produce resultant data elements.<br>
Figures 30a to 30d illustrate the operation of various folding instructions<br>
which follow the same syntax described elsewhere. It will be appreciated that where<br>
two source registers are indicated that these may be the same register. Also, it will be<br>
: 5 appreciated that each source register could be specified as the destination register in<br>
order to reduce the amount of register space utilised.<br>
Figmre 30a illustrates the operation of a SIMD folding instruction whereby<br>
pairs of source data elements from the same register, represented by 'n' bits, have an<br>
; 0 operation performed thereon in order to generate resultant data elements represented<br>
by 2n bits. Promoting the resultant data elements to have 2n bits reduces the<br>
probability that an overflow will occur. When promoting the resultant data elements,<br>
they are typically sign-extended or padded with O's. The following example summing<br>
folding instructions support such an operation:<br>
:\5<br>
^ Mnemonic Data Type Operand Fonnat Description<br>
VSUM.S16.SS Dd, Dm (add adjacent pairs of elements<br>
and promote)<br>
.S32.S16 Qd, Qm<br>
i .S64.S32<br>
.U16.US<br>
.U32.U16<br>
.U64.U32<br>
1) In the particular example shown in Figure 30a (¥5111^1.832.816 Dd, Dm), a<br>
I 64-bit register Dm containing four 16-bit data elements are folded and stored in a 64-<br>
' bit register Dd containing two 32-bit resultant data elements.<br>
Figure 30b illustrates the operation of a SIMD folding instruction whereby<br>
1 i pairs of source data elements from different registers, represented by 'n' bits, have an<br>
operation perfoimed thereon in order to generate resultant data elements also<br>
represented by 'n' bits. The following example smnming, maximum and minimum<br>
instructions support such an operation:<br>
2) Mnemonic Data Type Operand Format Description<br>
VSUM .18 Dd, Dn, Dm (add adjacent pairs of elements)<br>
.116<br>
.B2<br>
.F32<br>
1 )<br>
Mnemonic Data Type Operand Fonnat Description<br>
VFMX.S8 Dd, Dn, Dm (take maximum of adjacent pairs)<br>
.816<br>
.832<br>
3) .U8<br>
.U16<br>
.U32<br>
.F32<br>
Mnemonic Data Type Operand Fonnat Description<br>
VFMN .S8 Dd, Dn, Dm (take minimum of adjacent pairs)<br>
.S16<br>
5 .S32<br>
.US<br>
.U16<br>
.U32<br>
.F32<br>
10<br>
^ In the particular example shown in Figure 30b (VSUM.I16 Dd, Dn, Dm), two<br>
64-bit registers Dm, Dn, each containing four 16-bit data elements are folded and<br>
stored in a 64-bit register Dd containing four 16-bit resultant data elements.<br>
15 Figure 30c illustrates the operation of a SIMD folding instruction whereby<br>
pairs of source data elements from the same register, represented by 'n' bits, have an<br>
operation performed thereon in order to generate resultant data elements also<br>
represented by 'n' bits, hi the particular example shown in Figure 3'Oc, a 128-bit<br>
register Qm containing eight 16-bit data elements are folded and stored in a 64-bit<br>
2 3 register Dd containing four 16-bit resultant data elements.<br>
Figure 30d illustrates the operation of a SBVDD folding instruction similar to<br>
Figure 30b, but where Dm=Dn which causes the resultant data values to be dupUcated<br>
in the destination register. Pairs of source data elements from the same register,<br>
25 represented by 'n' bits, have an operation performed thereon in order to generate<br>
resultant data elements also represented by 'n' bits, each of which is duplicated in<br>
another entry ia the register, hi the particular example shown in Figure 30d, a 64-bit<br>
register Dm containing four 16-bit data elements are folded and stored in a 64-bit<br>
register Dd containing two sets of two 16-bit resultant data elements.<br>
33<br>
Figure 31 illusfrates schematically example SIMD folding logic which can<br>
support folding instructions and which is provided as part of the SIMD processing<br>
logic IS. For sake of clarity, the logic sho^vn is used to support instructions which<br>
select the maximum of each adjacent pair. However, it will be ^predated that the<br>
~ * ^ ^ ' ^ ^^ ^ " '<br>
^ logic can be leadily adapted to provide support for other operations, as will be<br>
described in more detail below.<br>
The logic receives source data elements (Dni[0] to Dm[3]) from the register<br>
5 Dm, optionally together with source data elements (Dn[0] to Dn[3]) from the register<br>
Dn. Altemativel}', the logic receives source data elements (Qm[0] to Qm[7]) from the<br>
register Qm. Each pair of adjacent source data elements are provided to an associated<br>
folding operation logic unit 400. Each folding operation logic unit 400 has an<br>
arithmetic imit 410 which subtracts one source data element from the other and<br>
10 provides an indication of which was the greater over the path 415 to a multiplexer<br>
I 420. Based upon the indication provided over the path 415, the multiplexer outputs<br>
the greater value source data element from the operation logic unit 400. Hence, it can<br>
be seen that each folding operation logic unit 400 is arranged to output the maximum<br>
of the associated adjacent pair of data elements over respective paths 425, 435, 445,<br>
15 455.<br>
Selection and distribution logic 450 receives the resultant data elements and<br>
provides these as required over paths 431 to 434 for storage in entries of a register Dd<br>
in the SBS'ID register data file 20 ia support of the above-mentioned instructions. The<br>
'j. 0 operation of the selection and distribution logic 450 will now be described.<br>
In order to support the instruction illustrated in Figure 30a, source data<br>
elements Dm[0] to Dm[3] are provided to the lower two folding operation logic units<br>
400. The folding operation logic units 400 output data elements over the paths 425<br>
: 5 and 435. The paths 431 and 432 will provide Dm[0] op Dm[l] in a sign-extended or<br>
zero-extended format, whilst paths 433 and 434 will provide Dm[2] op Dm[3] in a<br>
sign-extended or zero-extended format. This is achieved by signals being generated<br>
by the SIN4D decoder 16 in response to the folding instruction which cause the<br>
multiplexers 470 to select their B input, the multiplexers 460 to select either sign-<br>
;0 extension or zero-extension, the multiplexers 490 to select their E input and the<br>
multiplexer 480 to select its D input.<br>
In order to support the instmction illustrated in Figure 30b, source data<br>
elements Dm[0] to Dm[3] are provided to the lower two folding operation logic units<br>
: 5 400, whilst source data elements Dn[0] to Dn[3] are provided to the upper two folding<br>
7J<br>
-42- -<br>
^ operation logic units 400. The folding operation logic units 400 output data elements<br>
over the paths 425, 435, 445 and 455. Path 431 will provide Dm[0] op Dm[l], path<br>
432 will provide Dm[2] op Dni[3], path 433 will provide Dn[0] op Dn[l], and path<br>
434 will provide Dn[2] op Dn[3]. This is achieved by signals being generated by the<br>
j SIMD decoder 16 in response to the folding instraction which cause the multiplexers<br>
470 to select their A input, the multiplexer 480 to select its C input and the<br>
multiplexers 490 to select their E input.<br>
In order to support the instruction illustrated in Figure 30c, source data<br>
1') elements Qm[0] to Qm[7] are provided to the folding operation logic units 400. The<br>
I folding operation logic units 400 output data elements over the paths 425, 435, 445<br>
and 455. .Path 431 will provide Qm[0] .op Qm[l], path 432 will provide Qm[2] op<br>
Qm[3], path 433 will provide Qm[4J op Qm[5], and path 434 will provide Qm[6] op<br>
Qm[7]. This is achieved by signals being generated by the SIMD decoder 16 in<br>
1:' response to the folding instruction which cause the multiplexers 470 to select their A<br>
input, the multiplexer 480 to select its C input and the multiplexers 490 to select their<br>
E input.<br>
In order to support the instruction illustrated in Figure 30d, source data<br>
2( I elements Dm[0] to Dm[3] are provided to the lower two folding operation logic units<br>
400. The folding operation logic units 400 output data elements over the paths 425<br>
and 435. Path 431 will provide Dm[.0] op Dm[l], path 432 will provide Dm[2] op<br>
Dm[3], path 433 will provide Dm[0] op Dm[l], and path.434 will provide Dm[2] op<br>
Dm[3]. This is achieved by signals being generated by the SIMD decoder 16 in<br>
11 response to the folding instruction which cause the multiplexers 470 to select their A<br>
input, the multiplexer 480 to select its D input and the multiplexers 490 to select their<br>
F input. Alternatively, it will be appreciated that the source data elements could have<br>
instead also been provided to the upper two folding operation logic units 400 and the<br>
same operation as that illustration to reference to Figure 30b could have been<br>
3(' performed which would reduce the complexity of the selection and distribution logic<br>
450.<br>
Accordingly, it can be seen that this logic enables a resultant data element to<br>
be generated from two adjacent source data elements in a single operation directly'<br>
3; i from the source data elements.<br>
-43-<br>
As mentioned above, the folding operation logic unit 400 may be arranged to<br>
perform any number of operations on the source data elements. For example, further<br>
logic could readily be provided to selectively enable the multiplexer 420 to supply the<br>
) minimum of the source data elements over the path 425. Alternatively, the arithmetic<br>
unit 410 could be arranged to selectively add, subtract, compare or multiply the<br>
source data elements and to output the resultant data element. Hence, it will be<br>
appreciated that the approach of tiie present embodiment advantageously provides a<br>
great deal of flexibility in the range of folding operations that can be performed using<br>
1) this arrangement.<br>
Also, it vv'ill be appreciated that widlst the logic described with reference to<br>
Figure 31 supports 16-bit operations, similar logic could be provided in order to<br>
support 32 or 8-bit operations, or indeed any other sizes.<br>
1 )<br>
Figure 32 illustrates the operation of a vector-by-scalar SMD instruction. The<br>
SIMD instmctions follow the same syntax described elsewhere. "It will be appreciated<br>
that, as before, where two source registers are indicated, these may be the same<br>
register. Also, each source register could be specified as the destination register in<br>
2} order to reduce the amount of register space utilised and to enable efficient<br>
recirculation of data elements.<br>
A register Dm stores a number of data elements Dni[0] to Dni[3]. Each of these<br>
data elements represent a selectable scalar operand. The vector by scalar SIMD<br>
25 instruction specifies one of the data elements as the scalar operand and performs an<br>
operation using that scalar operand in parallel on all the data elements in another<br>
register Dn, the results of which are stored in a .corr-esponding entry in the register Dd.<br>
It will be appreciated that the data elements stored in the registers Dm, Dn and Dd<br>
could all be of differing sizes. In particular, the resultant data elements may be<br>
;0 promoted with respect to the source data elements. Promoting may involve zero<br>
padding or sign extending to convert firom one data type to another. This may have<br>
the additional advantage of guaranteeing that an overflow can not occur.<br>
Being able to select one scalar operand for a SIMD operation is particular<br>
; 5 efficient in -situations involving matrices of data elements. Different scalar operands<br>
^ can be written to the SDvED register file 20 and then readily selected for different<br>
vector-by-scalar operations without the need to re-wiite data elements or move data<br>
elements around. The following example multipMcation instructions support such an<br>
operation:<br>
Multiply by Scalar<br>
Mnernonic Data Type Operand Format Description<br>
VMUL .116 Dd, Dn, Dm[x] (Vd[i] = Vn[i] * Vm[x])<br>
.B2 Qd, Qn, Dm[x]<br>
1) .F32<br>
.S32.S16 Qd,Dn,Dm[x]<br>
.S64.S32<br>
.U32.U16<br>
.U64.U32<br>
Multiply Accumulate by Scalar<br>
Mnemonic Data Type Operand Format Description<br>
\/MLA.Il 6 Dd, Dn, Dm[x] (Vd[i] = Vd[i] + (Vn[i] * Vm[x]))<br>
.132 Qd, Qn, Dm[x]<br>
2) .F32<br>
.S32.S16 Qd,Dn,Dm{x]<br>
.S64.S32<br>
.U32.U16<br>
.U64.U32<br>
2j<br>
Multiply Subtract by Scalar<br>
Mnemonic Data Type Operand Format Description<br>
VMLS.I16 Dd, Dn, Dm[x] (Vd[i] = Vd[i] - (Vn[i] *• Vm[x]))<br>
.132 Qd, Qn,Dm[x]<br>
3) .F32<br>
.S32.S16 Qd,Dn,Dm{x]<br>
.S64.S32<br>
.U32.U16<br>
.U64.U32<br>
3)<br>
Vd, Vn and Vm describe vectors of elements constructed from the chosen<br>
^ register fomiat and chosen data type. Elements within this vector are selected using<br>
I the array notation [x]. For example, Vd[0] selects the lowest elenaertt in the vector<br>
Vd.<br>
j<br>
An iterator i is used to allow a vector definition; the semantics hold for all<br>
values of i where i is less than the number of elements within the vector. The<br>
instruction definitions provide 'Data Type' and 'Operand Format' colunons; a vahd<br>
instruction is constructed by taking one from each column.<br>
1)<br>
Figure 33 illustrates an arrangement of scalar operands HO to H31 in the<br>
SIMD register file 20. As mentioned elsewhere, the preferred number of bits used in<br>
a field of the instruction to specify the location of a data element in the SIMD register<br>
file 20 is 5-bits. This enables 32 possible locations to be specified. It will be<br>
1) appreciated that one possible way to map the scalar operands onto the SIMD register<br>
file 20 would have been to have placed -each operand in the first entry in -each of the<br>
registers Do to D31. However, the SIMD register file 20 is instead arranged to map or<br>
alias the selectable scalar operands to the first 32 logical entries in the SIMD register<br>
file 20. Mapping the scalar operands in this way provides significant advantages.<br>
2) Firstly, by locating the scalar operands in contiguous entries minimises the number of<br>
D registers used to store the scalar operands which in turn maximises the number of D<br>
registers available to store other data elements. By having the scalar operands stored<br>
in contiguous entries enables all scalar operands within a vector to be accessed, which<br>
is particularly beneficial when performing matrix or filter operations. For example, a<br>
2 S matrix by vector multiplication requires a vector by scalar operation to be performed<br>
for each scalar chosen from the vector. Furthermore, storing the selectable scalar<br>
operands in this way enables, from at least some of the registers, all the scalar<br>
operands to be selected from those registers.<br>
3D Figure 34 illusfrates schematically logic arranged to perform a vector-byscalar<br>
operation of an embodiment.<br>
The source data elements (Dn,[0] to Dm[3]) provided from the r-egister Dm-<br>
Each source data element is provided to scalar selection logic 510 which comprises a<br>
---^-^ ^ -^4-<br>
-46- --<br>
^ number of multiplexers 500. Each source data element is provided to one input of<br>
each multiplexer 500 (i.e. each multiplexer receives source data elements Dm[0] to<br>
Djn[3]. Hence, it can be seen that each multiplexer can output any of the source data<br>
elements Dm[0] to Dm[3]. In this embodiment, each multiplexer is arranged to output<br>
; the same source data element. Hence, the scalar selection logic 510 can be arranged<br>
to select and output one scalar operand. This is achieved by signals being generated<br>
by the SIMD decoder 16 in response to the vector-by-scalar instruction which cause<br>
the multiplexers to output one of the source data elements Dm[0] to Dn,[3] as the<br>
selected scalar operand.<br>
K<br>
I Vector-by-scalar operation logic 520 receives the selected scalar operand and<br>
also receives source data elements Dn[0] to Dn[3] provided from the register Dn. Each<br>
source data element is proAdded to the vector-by-scalar operation logic 520 which<br>
comprises a number of operation units 530. Each source data element is provided to<br>
I. one of the operation units 530 (i.e. each operation unit receives one of the source data<br>
elements Djn[0] to Dm[3] and the selected scalar operand). The vector-by-scalar<br>
operation logic 520 performs an operation on the two data elements and outputs a<br>
resultant data element for storage in respective entries of a register in the SIMD<br>
register data file 20 in support of the above-mentioned instructions. This is achieved<br>
2
instruction which cause the operations units 530 to perform the required<br>
op eration on the received data elements.<br>
Accordingly, it can be seen that this logic enables one of data element of a<br>
2 j source register to be selected as a scalar operand and to perform the vector-by-scalar<br>
operations using the same scalar operand on all source data elements from another<br>
register.<br>
Figure 35 shows a known way of dealing with a shift and narrow operation<br>
3} during SIMD processing. As can be seen three separate instructions (SHR, SHR and<br>
PACK LO) are required to perform this operation. Intermediate values are shown<br>
with dotted hnes for clarity in Figui-e 35 and in Figures 36 and 3 8.<br>
Figute 36 shows a shift right and narrow operation according to the present<br>
: 5 technique. The architecture of the present embodiment is particularly well adapted to<br>
process shift and narrow operations and can do so in response to a single insti-uction.<br>
^ The instruction is decoded by an instraction decoder within SIMD decoder 16 (see 1<br>
Figure 1). In this example the data in register Qn, located in SIMD register file 20<br>
(see Fig 1) is shifted right by 5 bits and then the remaining data is rounded and then<br>
5 the 16 right hand side bits are transferred across to the destination register Dd, also<br>
located in SIMD register file 20. The hardware is able to optionally support rounding<br>
and/or saturation of the data depending on the iustmction. Generally shifting right<br>
instructions do not require saturation as when dealing with integers shifting right<br>
generally produces a smaller number. However, when shifting right and narrowing<br>
1D saturation may be appropriate.<br>
Saturation is a process that can be used to restrict a data element to a certain<br>
range by choosing the closest allowable value. For example if two unsigned 8-bit<br>
integers are multiplied using 8 bit registers, the result may overflow. In this case the<br>
15 most accurate result that could be given is binary 11111111, and thus, the number will<br>
be saturated to give this value. A similar problem may arise when shifting and<br>
narrowing, whereby a number that is narrowed cannot fit into the narrower space. In<br>
this case in the case of an unsigned number, when any of the bits that are discarded in<br>
the shift step are not zero then the number is saturated to the maximum allowable<br>
20 value. In the case of a signed number the problem is more complicated. In this case<br>
the number must be saturated to the maximum allowable positive number or<br>
maximum allowable negative number when the most Significant bit is different from<br>
any of the discarded bits.<br>
2 5 Saturation can also occur where the type of data element, input is different to<br>
that output, e.g. a signed value may be shifted and narrowed, saturated and an<br>
unsigned value output. The ability to output different data types can be very useful.<br>
For example, in pbcel processing luminance is an unsigned value, however, during<br>
processing this value it may be appropriate to process it as a signed value. Following<br>
; 0 processing an unsigned value should be output, however simply switching firom a<br>
signed to an unsigned value could cause problems, unless the ability to saturate the<br>
value is provided. For example, if during processing due to slight inaccuracies the<br>
luminance value has dropped to a negative number, simply outputting this negative<br>
signed value as an unsigned value would be a nonsense. Thus, the abihty to saturate<br>
i<br>
.-uuraiui-j -. ,„_„ . -^ iT<br>
- 4 &amp; " • • '<br>
^ any negative number to zero prior to outputting the unsigned value is a very u-sefiil<br>
tool.<br>
Examples of possible formats for different shift instructions are given below in<br>
) tables 6 and 7. As can be seen the instructions specifies that it is vector instruction by<br>
having a V at the front, a shift is then specified with the SH and in the case of shifting<br>
with immediates, the direction right or left is then indicated by an R or L. The<br>
instruction then comprises two types, as in table 0, the first being the size of the data<br>
elements in the destination register and the second being the size of the element in the<br>
13 source register. The next information comprises the name of the destination register<br>
1 and of the source register and then^ an immediate value may be given, this value<br>
indicates the number of bits that the data is to be shifted and is preceded by a #.<br>
Modifiers to the general format of the instruction may be used, a Q is used to indicate<br>
the operation uses saturating integer arithmetic and a R is used to indicate that the<br>
15 operation performs rounding More details of the format of the instructions are given<br>
earher in the description, for example, in table 0.<br>
Table 7 shows instructions for shifting by signed variables. This instruction is the same<br>
as the shifting left by immediates, but instead of providing an immediate with the<br>
2 D instmction a register address indicating where a vector of signed variable is stored is<br>
provided with the iustruction. In this case a negative number indicates a right hand shift.<br>
As the number of bits to be shifted are stored in a vector, a different signed variable can<br>
be stored for each data element so that they can each be shifted by different amounts.<br>
This process is sho^vn in more detail in Figure 39.<br>
25<br>
TABLE 6<br>
Shift by Immediate<br>
2 0 Immediate shifts use an immediate value encoded within the instruction to shift all<br>
elements of the source vector by the same amount. Narrowing versions allow casting<br>
down of values, which can include saturation, while Long versions allow casting up<br>
with any fixed point.<br>
2 5 Shift with accumulate versions are provid-ed to support efficient scaling and<br>
accumulation found in many DSP algorithms. Right shift instructions also provide<br>
rounding options. Rounding is performed by in effect adding a half to the number-to<br>
be rounded. Thus, when shifting right by n places 2""' is add-ed to the value prior to<br>
shifting it._ Thus, in the following table round(n) = 2""' if n ^ or 0 if n
^0<br>
49- i<br>
^ Bitwise extract instructions are included to allow efficient packing of data.<br>
' Mnemonic Data Type Operand F o r m a t D e s c r i p t i on<br>
VSHR .S8 Dd, Dn, #UIMM Shift Right by Immediate<br>
i .S16 Dd, Dn, #UIMM Vd[i] := V n [ i ] &gt;&gt; UIMM<br>
.S32<br>
.S64<br>
.U8<br>
. a iG<br>
1) .U32<br>
.U64<br>
. 3 8 . s l 6 Dd, Qn, #UIMM Shift Right by Immediate and narrow<br>
. 3 1 6 . S32 Vd[i] := V n [ i ] &gt;&gt; UIMM<br>
I j .S32.S64<br>
.U8.U16<br>
.U16.U32<br>
.U32.US4<br>
I<br>
2) VRSHR .38 Dd, Dn, tUIMM Shift Right by Immediate with rounding<br>
. 3 1 6 Qd, Qn, #UIMM V(i[i] : = (Vii[i]+round(UIMM) )<br>
. 3 3 2 » UIMM<br>
. 3 6 4<br>
.U8<br>
25 .U16<br>
. U 32<br>
.UG4<br>
. S 8 . S 1 6 Dd, Qn, #UIMM shift Right by Immediate<br>
3 } .515.S32 and Narrow w i t h Rounding<br>
. 3 3 2 . S 6 4 Vd[i] := (Vn[i] + round<br>
. U 8 . U 1 6 (UIMM)) » UIMM<br>
. U 1 6 . U 3 2<br>
. U 3 2 . U 6 4<br>
35<br>
VQSHR .38. S I 6 Dd, Qn, #UIMM Saturating s h i f t Right<br>
by Immediate and Narrow<br>
. 3 1 6 . 3 3 2 Vd[i] := s a t  ( V n [ i ] &gt;&gt; 0IMM)<br>
. 3 3 2 . 3 6 4<br>
^0 .U8.U16<br>
. U 1 6 . U 3 2<br>
. U 3 2 . U 6 4<br>
. U 8 . S 1 6<br>
. U 1 6 . S 3 2<br>
^5 .U32.S64<br>
VQRSHR .38. S I 6 Dd, Qn, #UIMM saturating s h i f t Right by<br>
. 3 1 6 . S3 2 Immediate and Narrow with Rounding<br>
. S 3 2 . S 6 4 Vd[i] := sat<td>-
to .U8.U16 + round(UIMM)) » UIMM)<br>
.U16.U32<br>
.U32.U64<br>
, U 8 . S 1€<br>
. U 1 6 . S 32<br>
^5 .U32.S64<br>
VSRA TsB Dd, Dn, #iriMM Shift R i g h t by I m m e d i a te<br>
.SX6 -Qd, Qn, #ITIMM and A c c u m u l a te<br>
.S32 Vd(i] := VdUl + (Vn[i] » UIMM)<br>
\.Q .364<br>
.U8<br>
.•U16<br>
j-jcnxiu--'— -- -^fr<br>
.•U32<br>
• ' -^^^<br>
VQSRA .SB Dd, Dn, #U1MM saturating Shift Right by<br>
5 .S16 Qd, Qn, #UIMM immediate and Accumulate<br>
.S32 Vd[i] := s a t  ( V d [ i]<br>
.SS4 + (Vn[i] » UIMM) )<br>
.U8<br>
.1716<br>
13 .U32<br>
.U64<br>
VRSRA Tsi Dd, Dn, #UIMM Shift Right by Immediate<br>
.516 Qd, Qn, #triMM and Accumulate with Rounding<br>
15 .S3 2 Vd[i] := Vd[i3 + ((Vn[i] +<br>
.564 round(UIMM)) » UIMM)<br>
.U8<br>
.U16<br>
.U32<br>
23 .Ue4<br>
VQRSRA .SB Dd, Dn, #UIMM saturating Shift Right by Immediate<br>
.S16 Qd, Qn, ttUIMM and Accumulate with Rounding<br>
.S32 Vd[i] := s a t (<br>
2 5 .S64 Vd[i] + ( ( V n [ i ] +<br>
.U8 round(UIMM)) » UIMM))<br>
.U16<br>
.U32<br>
.U64<br>
3) , , , _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ = _ _ _ _ _ _ _ _ _ . _^<br>
VSHL .18 Dd, Dn, #UIMM shift Left by Immediate<br>
.116 Qd, Qn, #UIMM Vd[i] := Vn [i] 
.132<br>
3) .164<br>
.S16.S8 Qd, Dn, #UIMM Shift Left Long by<br>
Immediate<br>
.S32.Sie Vd[i] := Vn[i] 
.S64.S32<br>
4) .U16.ua<br>
.U32.U15<br>
•U64.U32<br>
VQSHL .S8 Dd, Dn, #UIMM Saturating Shift Left<br>
.S16 Qd, Qn, #UIMM by Immediate<br>
4) .S32 Vd[i] := sat</td>
<td>
<vn uimm></vn>
.S64<br>
.UB<br>
.U16<br>
.U32<br>
5) .U64<br>
. U 8 . S8<br>
. U 1 6 . S 16<br>
. U 3 2 . S 32<br>
. U 6 4 . S S4<br>
5)<br>
TABLE?<br>
Shift by Signed Variable<br>
w Shifts in this section perform shifts on one vector of elements controlled by the -signed<br>
shift amoimts specified in a second vector. Supporting signed shift amounts allows<br>
,j_uwaxiJLi-,_i.,., , - -^ - - --<br>
^ support for shifting by exponent values, which may reasonably be negative; a<br>
^ negative control value will perform a -sliift right. Vector shifts allow -each element to<br>
be shifted by a different amount, but can be used to shift all lanes by the same amount<br>
by duphcating the shift control operand to all lanes of a vector before perfonniug the<br>
5 shift. The signed shift control value is an element is the same SVLQ as the smallest<br>
operand element size of the operand to be shifted. However, the shifter variable is<br>
interpreted using only the bottom 8-bits of each lane to determine the shift amount.<br>
Rounding and Saturation options are also available.<br>
13 Mnemonic Data Type Operand Format Description<br>
VSHL .S8 Dd, Dn, Dm Shift Left by Signed<br>
V a r i a b l e<br>
.S16 Qd, Qn, Qm Vd[i] := Vn[i] 
.S32<br>
15 .S64<br>
.UB<br>
.U16<br>
.U32<br>
.U64<br>
2Q<br>
VQSHL .S8 Dd, Dn, Dm Saturating S h i f t Left<br>
.S16 Qd, Qn, Qm by Signed V a r i a b le<br>
. S 3 2 Vd[i] ;= sat</td>
<td>(Vn[i] « V m [ i ])<br>
. S 64<br>
25 .U8<br>
. U lS<br>
.U32<br>
.U64<br>
VRSHL .S8 Dd, Dn, Dm Rounding Shifb Left by signed variable<br>
3 3 .S16 Qd, Qn, Qm Vd[i] := (Vn[i] + round<br>
. 5 3 2 (-Vm[i])) « Vm{i]<br>
. 5 64<br>
.U8<br>
3 5 .U16<br>
.U32<br>
.U64<br>
VQRSHL .58 Dd, Dn, Dm Saturating Rounding Shift<br>
43 .515 Qd, Qn, -Qm Left by Signed Variable<br>
. 5 3 2 vd[i] := sat«td&gt;((Va[i] +<br>
. 5 6 4 round(-Vni[i]) ) 
.US<br>
.U16<br>
45 .U32<br>
.U64<br>
Thus, as can be seen the hardware supports instructions that are able to specify<br>
both the size of the source data element and resultant data element and also sometimes<br>
53 the number of places that the data is to be shifted. This makes it an extremely<br>
adaptable and powerful tool.<br>
The shift right and narrow operation shown in Figure 36 has a number of<br>
possible applications. For example, in calculations involving fixed point numbers<br>
Sp where a certain accuracy is required, it may be appropriate to place a say 16-bit<br>
^ mimber somewhere towards the centre of a 32-bit data value to reduce the risk of data<br>
over or under flow, while -calculations are performed. At the end of the calculations a<br>
16-bit number may be required, and thus a shift and narrow operation as shown in<br>
Figure 36 would be appropriate. The possibility envisaged by the present technique<br>
5 of using different sized source and destination registers is particularly effective here<br>
•<br>
and allows different sized data to remain in a particular lane during SIMD processing.<br>
A further use of the shift and narrow operation similar to that illustrated in<br>
Figure 36 could be in the processing of colour pixel data. SIMD processing is<br>
10 particularly appropriate for video data as video data comprises many pixels tiiat all<br>
require the same operation to be performed upon fhem. Thus, different pixel data can<br>
be in different lanes in a register and a single instruction can perform the same<br>
operations on all of the data. Often, video data may come as red green and blue data.<br>
This needs to be separated out before meaningftil operations can be performed upon<br>
15 it. Figure 37 shows a typical example of red green and blue data being present in a<br>
16-bit data element. In the example shown the blue data could be extracted by a shift<br>
left by 3 bits and narrow operation. The shift left by 3 places sends the blue data to<br>
the right of the middle of the data element, as is sho-wn schematically by the dotted I<br>
r &gt;<br>
line register (representing an intennediate value), three zeros fiU in the three empty<br>
: 0 positions at the right of the data value caused by the shift left of the data. The narrow<br>
operation results m the blue data and the three zeros being transferred to the resultant<br>
8 bit data element.<br>
In addition to shifting and narrowing the present technique can also be used to<br>
; 5 cast up and shift, this process is shown in Figure 38. In this case, the casting up is<br>
performed followed by a shift left. This operation can be used to for example transfer<br>
a 32-bit value to a 64-bit value, the 32 bit value being placed in an appropriate<br>
position within the 64 bit value, hi the example shown two 32 bit values are<br>
transferred to 64 bit values by being placed at the most significant bits in the lane with<br>
: 0 zeros being added as least significant bits.<br>
Figure 39 shows the possibility of using a vector of values indicating the<br>
number of places each data element should be shifted, the values being signed<br>
integers, negative numbers indicating a shift right. A register holding a value for each<br>
: 5 data element is used and each -data element is shifted by the amount specified by the<br>
.-i-uoajiu—-J .._, - - -• - —- ... • _ _^<br>
^ value located in its lane. The instructions for such operations are set out previously in<br>
table 7.<br>
Figure 40 schematically shov/s a simple multiplexing operation. In this<br>
5 multiplexing operation, multiplexer 700 selects either value a or value b to be output<br>
at D depending on the value of the control bit c. c is used to select the output between<br>
a and b. c is often based upon the result of a decision such as is a &gt; b. Embodiments<br>
of the architecture provide the abihty to perform multiplexing operations during<br>
SJMD processing. SIMD processing is not suitable for performing branch operations<br>
10 and thus multiplexing can not be performed using standard if then else instructions,<br>
rather a mask is created, the mask being used to indicate which parts of two source<br>
registers a and b are to be selected.<br>
This mask consists of control values that are used to indicate which parts of<br>
15 two source registers a and b are to be selected. In some embodiments a one in a<br>
certain position may indicate that a certain section of b is to be selected while a .zero<br>
in that position would indicate that a corresponding section of a is to be selected. This<br>
mask is stored ki a general-purpose register thereby reducing the heed for special<br>
purpose registers.<br>
Generation of the mask is dependent on the multiplexing operation to be<br>
performed and is created in response to this operation. For example in the case .given<br>
above a comparison of a and b is performed. This can be done on a portion by portion<br>
basis, for example corresponding data elements in the SIMD processing are<br>
25 compared. Corresponding data elements of b and a are compared and a value is<br>
written to the portion of the general purpose register that is being used to store the<br>
I control values depending whether b is greater than a, or b is -equal to or less than a.<br>
This can be done using a compare greater than instruction VCGT on all of the data<br>
elements in parallel. This instruction is provided in the instruction-set of embodiments<br>
20 of the system. Table 8 below shows some of the wide range of comparison<br>
instructions that are provided by embodiments of the architecture.<br>
TABLES<br>
2 5 Comparison and Selection<br>
-J .!Bi.ini_i - - ... - .--<br>
•<br>
Comparison and tests of variables to generate masks can be performed which can be<br>
used to provide data plane selection and masking. It also provides iastructions to<br>
' ^ select the maximum, and minimum, including folding versions which can be used at<br>
the end of vectorised code to find the maximum or minimum within a vector.<br>
.<br>
Mnemonic Data Type Operand Foxmat Description<br>
VCEQ .18 Dd, Dn, Dm Compare Equal<br>
.116 Qd, Qn, Qm Vd [i] := (Vnti] ==Vm[i]) ?<br>
. 1 3 2 ones : z e r os<br>
10 . F3 2<br>
• VCGE .S8 Dd; Dn, Dm Compare Greater-than or Equal<br>
. S 1 6 Qd, Qn, Qm Vd[i] := (Vn[i] &gt;= V m [ i ])<br>
. S 3 2 ? ones : ?;eros<br>
.US<br>
l,i .U16<br>
.U32<br>
. F 32<br>
VCGT .S8 Dd, Dn, Dm Compare G r e a t e r - t h an<br>
2) .S16 Qd, Qn, Qm Vd[±] := (Vn[i] &gt; V m [ i ] ) ?<br>
. S 3 2 ones : z e r os<br>
.U8 j<br>
.U16 I<br>
.U32 I<br>
2) .F32 I<br>
VCAGE .F32 Dd, Dn, Dm compare Absolute Greater-than or Equal<br>
Qd, Qn, Qm Vd[i] •:= (|Vn[i] | &gt;= |Vni[i]|) ? ones :<br>
zeros<br>
3) VCAGT .F32 Dd, Dn, Dm Compare Absolute Gteater-than<br>
Qd, Qn, Qm Vd[i] := (|Vii[i]| &gt; |vm[i] |)?onesi zeros<br>
VCEQZ ,18 Dd, Dm Compare E q u a l t o Zero<br>
. 1 1 6 Qd, Qm Vd[i] := (Vm[i] == 0)<br>
. 1 3 2 ? ones : z e r os<br>
3 ) .F32 •'_<br>
VCGEZ . S8 Dd, Dm compare Greater-than or Equal to Zero<br>
. S 1 6 Qd, Qm Vd[i] .-= (Vm[i] &gt;= 0)<br>
. S 3 2 ? ones : z e r os<br>
. F 32<br>
4)<br>
VCGTZ .38 Dd, Dm Compare G r e a t e r - t h a n Zero<br>
. S 1 6 Qd, Qm Vd[i] := (Vm[i] &gt; 0) ?<br>
. S 3 2 : o n e s : z e r os<br>
. F 32<br>
4) VCLEZ .F32 Dd, Dm Compare Less-than or Equal t o Zero<br>
Qd, Qm Vd[i] 1= (Vm[i] 
JJbte: Xnteger a  0)<br>
VCLTZ .F32 Dd, Dm Compare L e s s - t h a n Z e ro<br>
5) Qd, Qm Vd[i] := (Vm[i] 
: o n e s : z e r os<br>
Note; Integer a = 0)<br>
VTST ^Ti Dd, Dn, Dm Test B i ts<br>
55 .116 -Qd, Qn, Qm vd[i] := ((Vn[i] tVmEi]) != o)<br>
. 1 3 2 ? ones : zeros<br>
VMAX .S8 Dd, Dn, Dm Maximum<br>
. S r 6 Qd, Qn, Qm Vd[i] := (Vn[i] &gt;= Vm[i] ) ?<br>
. S 3 2 Vn{i] : Vm[i] {<br>
^3 .US<br>
.XJV6<br>
.U32<br>
^ S f c " .. . . -- -<br>
t J L i U i a j - j , : . ^- - . • - - • —- •-- - -<br>
•F32<br>
9 VMIN .SB Dd, Dn, Dm Minimum<br>
I .Sie Qd, Qn, Qm Vd[i] := (Vnfi] &gt;=Vm[i]) ?<br>
^ .S32 Vm[i] : Vn[i]<br>
i .U8<br>
. U lS<br>
.U32<br>
.Fsa<br>
1) Once the mask has been created a single instruction can be used to select<br>
either a or b using the general-purpose register containing this mask, the control<br>
register C. Thus, the data processor is controlled by C to perform the multiplexing<br>
operation of selecting either a or b.<br>
' 15 Figure 41 schematically shows an embodiment of the system wherein the<br>
selection of source values a or b is done on a bit wise basis, hi this case the control<br>
register 730 has been filled with data by comparing data elements in registers a 710<br>
and b 720. Thus, data element aO, which is say eight bits wide is compared with data<br>
element bO having the same size, hi this case a is less than or equal to b and thus<br>
2 3 eight zeros are inserted mto the corresponding portion of the control register 730. If a<br>
is greater than b 8 ones are inserted into the corresponding portion of the control<br>
register 730. A similar comparison is performed in parallel for all the data elements<br>
and corresponding control bits produced. The comparison operation that generates the<br>
control vector corresponds to the instruction VCGT.S8 c,a,b. Selection can then be<br>
2 5 performed very simply on a bit by bit basis by performing simple logical operations<br>
between the bits store in tlie source registers and the corresponding bits stored in the<br>
control register, each resultant bit being written to a destination register, which in this<br>
example is register 730, i.e. the results overwrite the control values. The advantage of<br>
this bitwise selection is that it is independent of data type and widiii and if appropriate<br>
; 0 different sized data elements can be compared.<br>
Figure 42 shows an altemative embodiment where the control is not done on a<br>
bit- wise basis but is done on a data element basis. In the embodiment shown if a data<br>
element in the control register C 730, is greater than or equal to zero then a<br>
: 5 corresponding data element in -source register b 720, it is written to the destination<br>
register (in this -case register 720). If, as in this example, C is a signed integer, then<br>
only tiie most significant bit of-C needs to be considered when deciding which of a or |<br>
b to select.<br>
_LJuauJix_i_ &gt; - . . . . . . . . - . . _ - "—SJ / _,<br>
' In other embodiments other properties of C can be used to determine whether<br>
^ a data element from register a, 710 is to be selected, or one from data register b, 720.<br>
Examples of such properties include, whether C is odd or even, where again only one<br>
) bit of the control value need to be considered, in this case the l e ^ t significant bit, or if<br>
C is equal to zero, not equal to zero or greater than zero. I<br>
j<br>
i<br>
Generally ARM instructions and in fact many other RISC instructions only<br>
provide three operands mth any instruction. Multiplexing operations in general |<br>
1} require four operands to specify two source registers a and b, a control register C and i<br>
&gt; a destination register D. Embodiments of the present system take advantage of the !<br>
fact that generally following a multiplexing operation, at least one of the two sets of<br>
source data or the control data is no longer required. Thus, the destination register is<br>
chosen to be either one of the two source registers or the control register. This only<br>
1S works as the control register is a general-purpose register and not a special register.<br>
In embodiments of the system, three different instructions are provided in the<br>
instruction set, an instruction specific to "WTiting back to one source register, another<br>
instraction for writing back to the other source register and a third instruction for<br>
writing to the control register. Each instruction requires just three operands,<br>
2D specifying two soxirce registers and a control register. These three instructions are<br>
specified in table 9 below.<br>
TABLE 9<br>
25 Logical and Bitwise selection<br>
Mnemonic Data Type Operand Format Description<br>
VBIT none Dd, fin, Dm Bitwise Insert if True<br>
2 0 Qd, Qn, Qm Vd ;= (Vm) ? Vn ; Vd<br>
VBIP none Dd, Dn, Dm Bitwise Insert if False<br>
Qd, Qn, Qm Vd := (Vm) ? Vd : Vn<br>
VBSL none Dd, Dn, Dm Bitwise Select<br>
Qd, Qn, Qm Vd := (Vd) ? Vn : Vm<br>
35<br>
Figure 43 schematically shows three examples of multiplexer arrangements<br>
corresponding to the three multiplexing instructions provided by &amp;e system. Figure<br>
43a shows multiplexer 701 wired to perform the instruction bitwise select VBSL. In<br>
\bis example, contrary to the example illustrated in Figures -41 and 42, A is 'selected i<br>
^ 0 when C is false (0), and B is selected when C is true (1). ha the embodiment<br>
^ illustrated the destinatiDn register is the same as the control register so that the<br>
resultant values overwrite the control values. If the reverse selection v/as required,<br>
i.e. A is selected v/hen C is true and B when C is false, the same circuit could be used<br>
' by simply swapping the operands A and B.<br>
j<br>
Figure 43b shows a multiplexer 702 corresponding to the instruction BIT<br>
bitwise insert if true, and results in source register A acting as both source and<br>
destination register and being overwritten with the result data. In this example B is<br>
written into A when C is true, while if C is false the value present in register A<br>
13 remains unchanged. In this embodiment if the reverse selection is required, i.e. it is<br>
desired to ^vrite B to the destination register if C is false rather than true it is not<br>
possible to simply swtch the registers around as the device does not have the<br>
symmetry of multiplexer 701.<br>
1 j Figure 43 c shows a multiplexer 703 that is set up to correspond to the reverse<br>
selection of Figure 43b, i.e. the instruction BIF bitwise insert if false. In this<br>
embodiment the value in register A is written into register B when C is false, while<br>
when C is true the value in register B remains unchanged. As in figure 43b there is no<br>
symmetry in this system.<br>
23<br>
Figure 44 schematically illustrates a sequence of bytes of data Bo to B? stored<br>
i within a memory. These bytes are stored in accordance with byte invariant addr-essing<br>
whereby the same byte of data will be returned m response to reading of a given<br>
memory address irrespective of the current endianess mode. The memory also<br>
2 5 supports unaligned addressing whereby half words, words or larger multi-byte data<br>
elements may be read from the memory starting at an arbitrary memory byte address.<br>
When the eight bytes of data Bo to B7 are read from the memory with the<br>
system in little endian mode, then the bytes Bo to By are laid out within a register 800<br>
3 3 in tbie order shown in Figure 44. The register 800 contains four data elements each<br>
comprising a half word of sixteen bits. Figure 44 also shows the same eight bytes of<br>
data Bo to B7 being read out into a register S02 when the system is operating in big<br>
endian mode.<br>
I<br>
^ In this example, the data once read out from memory into the respective SIMD<br>
register 800, 802 is subject to a squaring operation which results in a doubling of the<br>
data element size. Accordingly, the result is written in two destination SIMD ,<br>
registers 804, 806. As will be seen from Figure 44, the result values written<br>
) respectively in the first or second of these register pairs 804, 806 vary depending upon<br>
the endianess mode in which the data has been read from the memory. Accordingly, a<br>
SIMD computer program Avhich is to further manipulate the squared result values may<br>
need to be altered to take account of the different layout of the data depending upon<br>
the endianess mode. This disadvantageously results in the need to produce two<br>
13 different forms of the computer program to cope with different endianess in the way<br>
that the data has been stored within the memory.<br>
I<br>
Figure 45 addresses this problem by the provision of reordering logic 808.<br>
The data processing system includes memory accessing logic 810 which serves to<br>
15 read the eight bytes of data Bo to B7 from the memory starting at a specified memory<br>
address and utilising the b3/te invariant addressing characteristic of the memory. The<br>
output of the memory accessing logic 810 accordingly presents bytes read from a<br>
given memory address at the same output lane irrespective of the endianess mode.<br>
Thus, in the example illustrated in which the data elements are half words, a byte<br>
i 0 recovered from a particular memory address may be the most significant portion of a<br>
half word when in one endianess mode whilst it is the least significant portion of a half word in the other endianess mode.<br>
The data element reordering logic 808 is responsible for reordering the data<br>
; 5 elements retrieved from the memory by the memory access logic 810 such that the<br>
data elements which are loaded into the SIMD register 812 will be in a form<br>
consistent with the data having been stored in a little endian form and loaded without<br>
rearrangement irrespective of the endianess mode being used within the memory<br>
system, hi the case of a little endian mode being used within the memory system, the<br>
iO data element reordering logic 808 will not reorder the bytes and will pass these<br>
through unaltered. However, in the case of the data being stored in a big endian form<br>
within the memory system, the data element reordering logic 808 serves to reverse the |<br>
j<br>
order of the bytes read from the memory within each half word so that the half word<br>
dataelement will appear in little endian form Avithin the SIMD register 812. In this<br>
S5 way, a single SIMD computer program can perform the correct data processing<br>
LicaiuiJ.-....-. -- ^.,, - - -""<br>
j y -<br>
operations upon the data elements traasferxed into the SIMD register irrespective of<br>
the endianess mode in which these were stored within the memory. It will be seen<br>
from Figure 45 that the data element reordering logic 808 is responsive to a signal<br>
indicating the endianess mode being used by the memory and a signal indicating the<br>
i size of the data elements concerned. The endianess mode being used will control<br>
whether or not any reordering is required and the size will control the nature of the<br>
reordering applied if it is required. It will be seen that when the data is stored within<br>
the memory in little endian mode and the SMD registers are little endian, then no<br>
reordering is required. Conversely, if the SIMD registers assumed a big endian form<br>
1) then no reordering would be required when the data was stored in big endian form<br>
within the memory but reordering would be required when the data was stored within<br>
a little endian form within the memory.<br>
Figure 46 illustrates an example similar to that of Figure 45 except that in this<br>
1) example the data elements are 32-bit data words. As will be seen, when these data<br>
words are stored within the memory in a big endian form, the reordering apphed by<br>
the data element reordering logic 808 reverses the byte order of four byte data<br>
elements as retrieved by the memory accessing logic 810 so that these are stored into<br>
the SIMD register 812 in a form consistent with the data having been stored in a little<br>
2) endian form in the memory and loaded without rearrangement.<br>
It will be appreciated that in the context of the processor system as a whole<br>
described herein, the memory accessing logic 810 and the data element reordering<br>
element 808 may form part of the previously described load store unit. The data<br>
2 3 element reordering logic 808 may also be used to compensate for memory system<br>
endianess when reading data into the scalar registers when a particular endianess is<br>
&gt;eing assumed for the data within the scalar registers.<br>
Figure 47 illustrates the data element reordering logic 808 in more detail. It<br>
3 3 will be seen that this is formed as three levels of multiplexers controlled by respective<br>
controlled signals Z, Y and X. These three layers are respectively responsible for<br>
reversing positions of adjacent bytes, adjacent half words and adjacent words of data.<br>
The control signals X, Y and Z are decoded from an endianess signal which when<br>
asserted indicates big endian mode and a size signal indicating respectively 64, 32 or<br>
2 5 16 bit data element size as is illustrated in Figure 47. It will be appreciated that many<br>
- fel -<br>
,J_JJLilUXiL_L - -^- - ., ^^ . . _._<br>
-60- ' ' ~<br>
^ other foims of data element reordering logic could be used to achieve the same<br>
I functional result as is illustrated in Figures 45 and 46.<br>
The memory access instruction which is.used to perform the b3^e invariant<br>
5 addressing of the memory conveniently uses a memory address pointer wliich is held<br>
within a register of a scalar register bank of the processor. The processor supports<br>
data processing instructions which change the data element size as well as data<br>
processing instructions which operate on selected ones of data elements within a<br>
SIMD register. I<br>
I<br>
10 I<br>
Figure 48 illustrates a register data store 900 which includes a list of registers<br>
DO, Dl each serving as a table register, an index register D7 and a result register D5.<br>
It will be seen that the table registers DO, Dl are contiguously numbered registers<br>
within the register data store 900. The result register D7 and the index register D5 are<br>
] 5 arbitrarily positioned relative to the table registers and each other. The syntax of the I<br>
instruction corresponding to this data manipulation is sho^vn in the figure.<br>
Figure 49 schematically illustrates the action of a table lookup extension<br>
instruction. This instruction specifies a list of registers to be used as a block of table<br>
20 registers, such as by specifying the first register in the Hst and the number of registers<br>
in the list (e.g. one to four). The instruction also specifies a register to be used as the<br>
( index register D7 and a register to be used as the result register D5. The table lookup<br>
extension instruction further specifies the data elements size of the data elements<br>
stored within the table registers DO, Dl and to be selected and written into the result<br>
25 register D5. In the example illustrated, the table registers DO, Dl each contain eight<br>
data elements. Accordingly, the index values have an in-range span of 0 to 15. Index<br>
values outside of this predetermined range will not result in a table lookup and instead<br>
the corresponding position within the result register D5 will be left unchanged. As<br>
illustrated, the fourth and sixth index values are out-of-range in this way. The other<br>
30 index values point to respective data elements within the table registers DO, Dl and<br>
these data elements are then stored into the corresponding positions within the result<br>
register D5. There is a one-to-one correspondence between index value position<br>
within the index register D7 and data element position within the result register D5. j<br>
The values marked "U" in the result register D5 indicate that the values stored at I<br>
35 those locations are preserved during the action of the table lookup extension<br>
.•i^J.!il1!3.l-J . • - -.- .-,.--_ „<br>
^ instruction. Thus, whatever bits were stored in those locations prior to execution of<br>
W<br>
' the instruction are still stored within those positions followmg the execution of the<br>
instruction.<br>
j<br>
i<br>
j Figure 50 illustrates the index values from Figure 49 which are then subject to<br>
a SIMD subtraction operation whereby an offset of sixteen is applied to each of the index values. This takes the previously in-raage index values to out-of-range values.<br>
The previously out-of-range values are now moved in-range. Thus, when the index<br>
register D7 containing the now modified iadex values is reused in another table<br>
13 lookup extension instruction, the fourth and sixth index values are now in-range and<br>
I result in table lookups being performed in table registers DO, Dl (or other different<br>
registers which may be specified in the second table lookup extension instruction)<br>
which have also been reloaded prior to the execution of a second table lookup<br>
extension instruction. Thus, a single set of index values within an index register D7<br>
15 ma}' be subject to an offset and then reused with reloaded table registers DO, Dl to<br>
give the effect of a larger table being available.<br>
Figure 51 illustrates fiirther a table lookup instruction which may be provided<br>
in addition to the table lookup extension instruction. The difference between these<br>
20 instructions is that when an out-of-range index value is encountered in a table lookup<br>
instruction, the location within the result register D5 corresponding to that index value<br>
is written to with zero values rather than being left unchanged. This type of behaviour<br>
is useful in certain programming situations. The example Figure 51 illustiates three<br>
table registers rather than two table registers. The first, third, fourth, sixth and<br>
: 5 seventh index values are out-of-range. The second, fifth and eighth index values are<br>
in-range and result in table lookups of corresponding data elements within the table<br>
registers.<br>
As mentioned earlier, load and store instiuctions are provided for moving data<br>
: 0 between the SIMD register file 20 (see Figure 1) and memory. Each such load and<br>
store instruction will specify a start address identifying tiie location within the<br>
memory from which the access operation (whether that be a load operation or a store<br>
operation) should begin. In accordance with the load and store instructions of :<br>
embodiments, the amount of data that is the subj-ect of that load or-store instruction<br>
: 5 can be varied on a per instniction basis. In particular embodiments, the amount of<br>
•^ data is identified by identifying the data type "dt" (i.e. the size of each data element)<br>
and identifying the number of data elements to be accessed by identifying the SIMD<br>
register list and optionally the number of structures to be accessed.<br>
,; When performing SIMD processing, it is often the case that the access<br>
operations performed with respect to the necessary data elements are often unaligned<br>
accesses (also referred to herein as byte aligned accesses), in other words, the start<br>
address will often be unaligned, and in such situations the LSU 22 needs to allocate to<br>
the access operation the maximum number of accesses that may be required to enable<br>
1) the access operation to complete.<br>
Whilst in a possible implementation, the LSU 22 could be arranged to assume<br>
that every access is unahgned, this means that the LSU 22 is unable to improve the<br>
efficiency of the access operations in situations where the start address is in fact<br>
1) aligned with a certain multiple number of bytes.<br>
Whilst the LSU 22 would be able to determine firom the start address whether |<br>
the start address has a predetermined alignment, the LSU 22 typically has to commit<br>
the number of accesses for the access operation at a time before the start address has<br>
2) actually been computed. In a particular embodiment, the LSU 22 has a pipelined<br>
architecture, and the number of accesses to be used to perform any particular access<br>
operation is determined by the LSU in the decode stage of the pipeline. However,<br>
often the start address is computed in a subsequent execute stage of the pipeline, for<br>
example by adding an offset value to a base address, and accordingly the LSU 22 is<br>
2) unable to await determination of the start address before determining how many<br>
accesses to allocate to the access operation.<br>
In accordance with an embodiment, this problem is alleviated by providing an<br>
aUgnment specifier field within the access instruction, also referred to herein as an<br>
3) ahgmnent qualifier. In one particular embodiment, the ahgnment qualifier can take a<br>
i<br>
first value which indicates that the -start address is to be treated as byte aligned, i.e.<br>
unaligned. It will be appreciated that this first value could be provided by any<br>
predetermined encoding of the alignment specifier field. In addition, the ahgnment<br>
qualifier can take any one of a plurahty of -second values indicating different<br>
3 5 predetermined alignments that the -start address is to be treated as conforming to, and<br>
i ' i r n i ] -R I I ,<br>
-63- " ' '<br>
^ in one particular embodiment, the pliirality of available second values axe as indicated<br>
in the following table:<br>
Alignment Start Address Promise and Availability<br>
Qualifier Format<br>
@16 ..xxxxxxxO The start address is to be considered to be a multiple<br>
of 2 bytes.<br>
Available to instructions that transfer exactly 2 bytes.<br>
@32 ..xxxxxxOO The start address is to be considered to be a multiple<br>
of 4 bytes.<br>
Available to instructions that transfer exactly 4 bytes.<br>
@64 ..xxxxxOOO The start address is to b e considered to b e a multiple<br>
of 8 bj^es.<br>
Available to instructions that transfer a multiple of 8<br>
I bytes.<br>
@128 ..xxxxOOOO The start address is to b e considered to be a multiple<br>
of 16b3^es.<br>
Available to instructions that transfer a multiple of 16<br>
; bytes. I<br>
@256 ..xxxOOOOO The start address is to b e considered to be a multiple<br>
of 32 bytes.<br>
Available to instructions that transfer a multiple of 32<br>
I I b y t e s . I i<br>
Table 10 |<br>
The manner in which this alignment specifier information is used in one<br>
embodiment will now be described with reference to Figure 52. As shown in Figure<br>
52, the LSU 22 will typically be connected to a memory system via a data bus of a<br>
predetermined width. Often the memory system "will consist of a number of different<br>
ID levels of memory, and the first level of memory is often a cache, this being the level<br>
of memory wilii which the LSU communicates via the data bus. Accordingly, as<br>
shown in Figure 52, the LSU 22 is arranged to communicate with a level 1 cache<br>
1010 of the memory via a data bus 1020, in this particular example the data bus being<br>
considered to have a width of 64 bits. In the event of a cache hit the access takes<br>
]5 place with respect of the contents of the level 1 cache, whereas in the event of a cache<br>
miss, the level 1 cache 1010 will then communicate with other -parts of the memory<br>
system 1000 via one or more fiirther buses 1030.<br>
The various parts of the memory system may be distributed, and in the<br>
; 0 example illustrated in Figure 52, it is assumed that the level 1 cache lOlO is provided<br>
on-chip, i.-e. is incorporated within the iategrated circuit 2 of Figure 1, whilst the rest<br>
of the memory system 1000 is-provided off-chip. The delimitation between on-chip<br>
^ and off-chip is indicated by the dotted line 1035 in Figure 52. However, it will be<br>
appreciated by those skilled in the art that other configurations may be used, and so<br>
for example aU of the memory system may be provided off-chip, or some other<br>
delimitation between the on-chip parts of the memory system and the off-chip parts of<br>
5 the memory system may be provided.<br>
The LSU 22 is also arranged to communicate with a memory management unit<br>
(MMU) 1005, which typically incorporates a Translation Lookaside Buffer (TLB)<br>
1015. As will be appreciated by those skilled in the art, an MMU is used to perform<br>
ID certain access control functions, for example conversion of virtual to physical<br>
! addresses, determination of access permissions (i.e. whether the access can take<br>
place), etc. To do this, the MMU stores within the TLB 1015 descriptors obtained<br>
I from page tables in memory. Each descriptor defines for a corresponding page of<br>
memory the necessary access control information relevant to that page of memory.<br>
1 5<br>
The LSU 22 is arranged to communicate -certain details of the access to both<br>
the level 1 cache 1010 and the MMU 1005 via a control path 1025. In particular, the<br>
LSU 22 is arranged to output to the level 1 cache and the MMU a start address and an<br>
indication of the size of the block of data to be accessed. Furthermore, in accordance<br>
2) with one embodiment, the LSU 22 also outputs alignment uiformation derived from<br>
the alignment specifier. The manner in which the alignment specifier information is<br>
used by the LSU 22 and/or by the level 1 cache 1010 and the MMU 1005 will now be<br>
described further Avith reference to Figures 53A to 54B.<br>
2 &gt; Figure 53 A illustrates a memory address space, with each soUd horizontal line<br>
indicating a 64-bit alignment in memory. If the access operation specifies the 128-bit<br>
long data block 1040, which for the sake of argument we will assume has a start<br>
address of 0x4, then the LSU 22 needs to determine the number of separate accesses<br>
over the 64-bit data bus 1020 to allocate to the access operation. Further, as discussed<br>
3) earlier, it will typically need to make this determination before it knows what the start<br>
address is. In the embodiment envisaged with respect to Figure 52, the LSU 22 is<br>
arranged to use the alignment specifier information when determining the nimiber of<br>
accesses to allocate.<br>
^rc.- i<br>
^ In the example of Figure 53A, the start address is 32-bit aligned, and the<br>
alignment specifier may have identified this aHgnment. In that instance, as can be<br>
seen firom Figure 53A, the LSU 22 has to assume the worst case scenario, and hence I<br>
assume that three separate accesses will be required in order to perform the necessary<br>
j access operation with regard to the data block 1040. This is the same number of<br>
accesses that would have to be allocated for an imaUgned access. i<br>
However, if we now consider the similar example illustrated in Figure 53B, it<br>
can be seen that again a 128-bit data block 1045 is to be accessed, but in this instance<br>
1) the start address is 64-bit aHgned. If the alignment specifier information identifies<br>
this 64-bit alignment, or indeed identifies the data as being 128-bit aligned, then in<br>
this case the LSU 22 only needs to allocate two separate accesses to the access<br>
operation, thereby providing a significant improvement in efficiency. If, however, the<br>
data bus were 128-bits wide, then if the ahgnment specifier indicated 128-bit<br>
15 aHgnment rather than 64^it ahgnment, the LSU 22 would only need to allocate a<br>
single access. |<br>
Considering now the example in Figure 53C, here it can be seen that a 96-bit<br>
size data block 1050 needs to be accessed, and in this instance it is assumed that the<br>
20 alignment specifier identifies that the start address is 32-bit aligned. Again, in this<br>
example, even though the LSU 22 will not actuall)' have calculated the start address at<br>
the time the number of accesses needs to be committed, the LSU 22 can still assume<br>
that only two accesses need to be allocated to the access operation. Figure 5 3D<br>
illustrates a fourth example in which an 80-bit data block 1055 is to be accessed, and<br>
25 in which the alignment specifier identifies that the start address is 16-bit atigned.<br>
Again, the LSU 22 only needs to allocate two accesses to the access operation. If<br>
instead the alignment specifier had indicated that the access was to be treated as an<br>
unaHgned access, then it is clear that the LSU would have to have allocated three<br>
accesses to the access operation, as indeed would have been the case for the access<br>
JO illustrated in Figure 53 C. Accordingly, it can be seen that the alignment specifier<br>
information can be used by the LSU 22 to significantly improve the performance of<br>
accesses in situations where the alignment specifier indicates a certain predetermined<br>
alignment of the start address.<br>
•^^•UJLJ-] I I J I L. . .. - . - - - - --„— _^<br>
- 06<br>
^ It should be noted that the aHgmnent specifier cannot be taken as a guarantee<br>
that the start address (also referred to herein as the effective address) will have that ahgnment, but does provide the LSU 22 with an assumption on which to proceed. If<br>
the start address subsequently turns out not to obey the alignment specified by the<br>
) alignment specifier, then in one embodiment the associated load or store operation is<br>
arranged to generate an alignment fault. The alignment fault can then be handled<br>
using any one of a number of known techniques. I<br>
As mentioned earlier, the ahgnment information is not only used by the LSU<br>
1) 22, but is also propagated via path 1025 to both the level 1 cache 1010 and the MMU<br>
I<br>
' 1005. The manner in which this information may be used by the level 1 cache or the I<br>
MMU will now be described with reference to Figures 54A and 54B. As illustrated in<br>
Figures 54A and 54B, an access to a 256-bit data block 1060, 1065 is considered, in<br>
these examples the sohd horizontal lines in the diagrams indicating a 128-bit<br>
1 &gt; alignment in memory. ID Figure 54A, it is assumed that the data block is 64-bit<br>
ahgned, whilst in Figure 54B it is assumed that the data block is 128-bit aligned. In<br>
both instances, since the data bus 1020 is only 64-bits wide, it will be clear that the<br>
LSU 22 has to allocate four accesses to the access operation. From the LSU's<br>
perspective, it does not matter whether the ahgnment specifier specifies that the start<br>
2) address is 64-bit aligned or 128-bit aligned.<br>
However, the cache lines within the level 1 cache 1010 may each be capable<br>
of storing in excess of 256 bits of data, and fiulher may be 128-bit ahgned. In the<br>
example of Figure 54A, since the data block is not 128-bit ahgned, the cache will<br>
2) need to assume that two cache hnes will need to be accessed. However, in the<br>
example of Figure 54B, the level 1 cache 1010 can determine firom the alignment<br>
specifier that only a single cache line within the level 1 cache needs to be accessed,<br>
and this can be used to increase the efficiency of the access operation within the level<br>
1 cache 1010.<br>
3)<br>
Similarly, the page tables that need to be accessed by the MMU in order to<br>
retrieve the appropriate descriptors into the TLB 1015 will often store in excess of<br>
256 bits of data, and may often be 128-bit ahgned. Accordingly, the MMU 1005 can<br>
use the alignment information provided over path 1025 in order to determine the<br>
3 5 number of page tables to be accessed. Whilst in the example of Figure 54A, the<br>
- 6 ^ • '•' ' " '-<br>
MMU 1005 may need to assume that more than one page table will need to be<br>
^ . accessed, m the example of Figure 546, the MMU can determine from the alignment<br>
specifier that only a single page table needs to be accessed, and this information can<br>
be used to improve the efficiency of the access control functions performed by the<br>
) MMU 1005.<br>
Accordingly, it can be seen that the use of the ahgnment specifier within the<br>
load or store instructions as described above can be used to enable the hardware to<br>
optimise certain aspects of the access operation, which is especially useful if the<br>
10 number of access cycles and/or cache accesses has to be committed to before tlae start<br>
; address can be determined. This scheme is useful for load or store instructions<br>
specifying various lengths of data to be accessed, and on processors with difieiing<br>
data bus sizes between the LSU and the memory system.<br>
:5 There are a number of data processing operations which do not lend<br>
themselves to being performed in a standard SBVCD format, where multiple data<br>
elements ai-e placed side-by-side within a register, and then the operation is perfoixaed<br>
in parallel on those data elements. Examples of some such operations are illustrated<br>
in Figures 55A to 55C. Figure 55A illustrates an interleave operation, where it is<br>
;.0 desired to interleave four data elements A, B, C, D within a first register 1100 with<br>
four data elements E, V, G, H within a second register 1102. In Figure 55A, the<br>
resultant interleave data elements are shown within destination registers 1104, 1106.<br>
These destination registers may be different registers to the source registers 1100,<br>
1102, or alternatively maybe the same set of two registers as the source registers. As<br>
!5 can be seen from Figure 55A, in accordance with this interleave operation, the first<br>
data elements from each source register are placed side-by-side within the destination<br>
registers, followed by the second data elements from both source registers, followed<br>
by the third data elements from both source registers, followed by the fourth data<br>
elements from both source registers.<br>
50<br>
Figure 55B illustrates the reverse de-interleave operation, where it is required<br>
to de-interleave the eight data elements placed in the tv^'o source registers 1108 and<br>
1110. In accordance with this operation, the first, third, fifth and seventh data<br>
elements are placed in one destination register 1112, whilst the -second, fouilh, sixth<br>
: 3 and eighth data elements are placed in a second destination register 1114. As wjtfa the<br>
i<br>
j ^ . Figure 55A example, it will be appreciated that the destination registers may be<br>
i different to the source registers, or alternatively may be the same registers. If in the<br>
examples of Figures 55 A and 55B it is assumed that the registers are 64-bit registers,<br>
then in this particular example the data elements being interleaved or de-interleaved<br>
,; are 16-bit wide data elements. However, it will be appreciated that there is no<br>
requirement for the data elements being interleaved or de-interleaved to be 16-bits<br>
wide, nor for the source and destination registers to be 64-bit registers.<br>
Figure 55C illustrates the function performed by a transpose operation. In<br>
1) accordance with this example, two data elements A, B from a first source register<br>
1116, and t\vo data elements C, D from a second source register 1118, are to be<br>
transposed, and the result of the transposition is that -the second data element from the<br>
first source register 1116 is SAvapped with the first data element from the second<br>
source register 1118, such that within the first destination register 1120, the data<br>
15 elements A, C are provided, whilst in a second destination register 1122 the data<br>
elements B, D are provided. Again, the destination registers may be different to the<br>
source registers, but it is often the case that the destination registers are in fact the<br>
same registers as the source registers. In one example, each of the registers 1116, I<br>
1118, 1120, 1122 may be considered to be 64-bit registers, in which event the data<br>
: 0 elements are 32-bit wide data elements. However, there is no requirement for the data<br>
elements to be 32-bit wide, nor for the registers to be 64-bit registers.<br>
Further, whilst in all of the above examples it has been assumed that the entire<br>
contents of the registers are shown, it is envisaged that any of these three discussed<br>
: ,5 operations could be performed independently on the data elements within different<br>
portions of the relevant som-ce registers, and hence the figures in that ease illustrate<br>
only a portion of the source/destination registers.<br>
As mentioned earlier, the standard SMD approach involves placing multiple<br>
!0 data elements side-by-side within a register, and then performing an operation in<br>
parallel on those data elements. In other words, the paraUelisation of the operation is<br>
performed at the data element granularity. Whilst this leads to very efficient<br>
execution oF operations where tie required data elements can be arranged in such a<br>
I manner, for example by spreading the required 'source data elements across multiple<br>
S5 registers, there are a significant number of •operations where it is not practical to<br>
^ 0 - , ._.<br>
arrange the required source data elements in such a way, and hence in which the<br>
^ potential speed benefits of a SIMD approach have not previously been able to be<br>
exploited. The above interleave, de-interleave and transpose operations are examples<br>
of such operations which have not previously been able to take advantage of the speed<br>
; benefits of a SIMD approach, but it will be appreciated that there are also many other<br>
examples, for example certain types of arithmetic operations. One particular example<br>
of such an arithmetic operation is an arithmetic operation which needs to be applied to<br>
a complex number consisting of real and imaginary parts.<br>
1) hi accordance with one embodiment, this problem is alleviated by providing<br>
/ the ability for certain data processing instructions to identify not only a data element<br>
size, but also to fiirther identify as a separate entity a lane size, the lane size being a<br>
' multipleof the data element size. The parallehsation of the data processing operation<br>
then occurs at the granularity of the lane size rather than the data element size, such<br>
1) that more than one data element involved in a particular instantiation of the data<br>
processing operation can co-exist within- the same source register. Hence, the<br>
processing logic used to perform the data processing operation can define based on<br>
the lane size a number of lanes of parallel processing, and the data processing<br>
operation can then be performed in parallel in each of the lanes, the data processing<br>
2) operation being appHed to selected data elements within each such lane of parallel<br>
processing.<br>
By such an approach, it is possible to perform in a SIMD manner interleave<br>
operations such as those described earher with reference to Figure 55A. In particular,<br>
2) Figure 56A illustrates the processing performed when executing a "ZIP" instruction in<br>
accordance with one embodiment. In this particular example, the ZIP instmction is a<br>
321 ZIP.8 instruction. This iastruction hence identifies that the data elements are 8-<br>
bits wide, and the lanes are 32-bits wide. For the example of Figure 56A, it is<br>
assumed that the ZIP instruction has specified the source registers to be the 64-bit<br>
3 ) registers DO 1125 and Dl 1130. Each of these registers hence contains eight 8-bit<br>
data elements. Within each lane the interleave operation is appHed independently,<br>
and in parallel, resulting in the rearrangement of data elements as shown in the lower<br>
half of Figure 5 6 A. In one embodiment, it is assumed that for the ZIP instruction, the<br>
destination registers are the same as the source registers, and accordingly these<br>
3 5 rearranged data elements are once again stored within the r-egisters DO 1125 and Dl<br>
--tl-<br>
1130. As can be seen from Figure 56A, within lane 1, the first four data elements of<br>
^ each source register have been interleaved, and within lane 2, the second four data<br>
elements of each source register have been iaterleaved.<br>
5 It will be readily appreciated that different forms of interleaving could be<br>
performed by changing either the lane size, or the data element size. For example, if<br>
the lane size was identified as being 64-bits, i.e. resulting in there being only a single<br>
lane, then it can be seen that the destination register DO would contain the interleaved<br>
result of the first four data elements of each register, whilst the destination register Dl<br>
13 would contain the interleaved result of the second four data elements of each register.<br>
It will be appreciated that a corresponding UNZIP instruction can be provided in<br>
order to perform the corresponding de-interleave operation, the UNZff instruction<br>
again being able to specify both a lane size and a data element size.<br>
15 Typically, a transpose operation is considered to be a quite different operation<br>
to an interleave operation or a de-interleave operation, and hence it would typically be<br>
envisaged that a separate instruction would need to be provided to perform transpose<br>
operations. However, it has been realised that when providing an interleave or a deinterleave<br>
instruction with the ability to separately define a lane size and a data<br>
2 3 element size, then the same instruction can in fact be used to perform a transpose<br>
operation when two source registers are specified, and the lane size is set to be twice<br>
I the data element size. This is illustiated in Figure 56B where the interleave<br>
instruction ZIP has been set to identify a data element size of 8 bits, and a lane size of<br>
16 bits (i.e. twice the data element size). Assuming the same 64-bit source registers<br>
25 DO 1125 and Dl 1130 are chosen as in the Figure 56A example, this defines four<br>
lanes of parallel processing as shown in Figure 56B. As can then be seen firom the<br>
lower half of Figure 56B, the interleaving proce5s actually results within each lane in<br>
the generation of a transposed result, in that the first data element of the second source<br>
register within each lane is swapped with the second data element of the first source<br>
3 3 register within each lane.<br>
Hence, in accordance with the above described embodiment, the same ZIP<br>
instruction can be used to perform either an interleave, or a transpose operation,<br>
dependent on how the lane size and data element size are defined. It should further be<br>
3 5 noted that a transposition can also be performed in exactly the same manner using the<br>
_ _ _ ^ -^i-<br>
UNZff instruction, and accordingly a 161 UNZIP. 8 instruction will perform exactly<br>
^ the same transpose operation as a 161 ZIP.8 instruction. i<br>
Figures 57A to 57C illustrate one particular example of an implementation of<br>
5 such ZIP instructions, in which a four-by-four array of pixels 1135 within an image are to be transposed about the line 1136 (see Figure 57A). Each pixel will typically<br>
consist of red, green and blue components expressed in RGB format. If for the sake !<br>
of argument we assume that the data required to define each pixel is 16-bits in length,<br>
then it can be seen that the data for each horizontal line of four pixels ia the array<br>
n 1135 pan be placed in a separate source register A, B, C,D.<br>
Figure 57B illustrates the various transpositions that occur if the following two<br>
• instructions are executed:<br>
32lZP.16A,B<br>
15 32lZff.l6C,D I<br>
Each ZIP instruction hence defines the lane width to be 32-bits, and the data<br>
element width to be 16-bits, and thus within each lane the first data element in the<br>
second register is swapped with the second data element in the first regiBter, as shown<br>
2) by the four diagonal arrowed lines illustrated in Figure 57B. Hence, separate<br>
transpositions occur within each of the four two-by-two blocks 1137, 1141^, 1143 and<br>
y 1145.<br>
Figure 57C then illustrates the transposition that occurs as a result of execution<br>
2 5 of the following two instructions:<br>
64|Zff.32A, C<br>
64|ZIP.32B,D<br>
In accordance with these instructions, the lane width is set to be 64-bits, i.e.<br>
I 3 3 the entire width of the source registers, and the data element width is chosen to be 32-<br>
bits. Execution of the first ZIP instruction thus results in the second 32-bit wide data<br>
element in register A 1147 being swapped with the first 32-bit wide data element<br>
within the register C 1151. Similarly, the second ZIP instruction results in the second<br>
32-bit wide data element in the register B 1149 being swapped with the first 32-bit<br>
data element within the register D 1153. As illustrated by the diagonal arrowed line<br>
in Figui-e 57C, this hence results in the two-by-two block of pixels in the top left<br>
being swapped by the t^vo-by-two block of pixels in the bottom right. As will be<br>
appreciated by those skilled in the art, this sequence of four ZIP instructions has<br>
) hence transposed the entire four-by-four array 1135 of pixels about the diagonal line<br>
1136. Figure 58 illustrates one particular example of the use of the interleave<br>
instruction, hi this example, complex numbers consisting of real and imaginary parts<br>
are considered. It may be the case that a certain computation needs to be performed<br>
on the real parts of a series of complex numbers, whilst a separate computation needs<br>
13 to be performed on the imaginary part of those complex numbers. As a result, the real<br>
, parts may have been arranged in a particular register DO 1155 whilst the imaginary<br>
parts may have been placed in a separate register Dl 1160. At some point, it may be<br>
desired to reunite the real and imaginary parts of each complex number so that they<br>
are adjacent to each other within the registers. As is illustrated in Figure 58, this can<br>
15 be achieved through the use of a 641 ZIP. 16 instruction which sets the lane width to be<br>
the full width of the source registers, and sets the data element width to be 16-bits, i.e.<br>
the width of each of the real and imaginary parts. As shown by the lower half of<br>
Figure 58, the result of the execution of the ZIP instraction is that each of the real and<br>
imaginary parts of each complex number a, b, c, d are reunited within the register<br>
2 0 space, the destination register DO 1155 containing the real and imaginary parts of the<br>
complex numbers a and b and the destination register Dl 1160 containing the real and<br>
I imaginary parts of the complex numbers c and d.<br>
It is not just data rearranging instructions like interleave and de-interleave<br>
25 instructions that can take advantage of the ability to' specify the lane size<br>
independently of the data element size. For example, figures 59A and 59B illustrate a<br>
sequence of two instructions that can be used to perform a multiphcation of two<br>
complex numbers. In particular, it is desired to multiply a complex number A by a<br>
complex number B, in order to generate a resultant complex number D, as illustrated<br>
: 0 by the following equation:<br>
Dre = Are * Bpe - Aim * Bjm<br>
D™ = Are*Bin, + Ain,*B„<br>
Figure 59A shows the operation performed in response to a first multiply<br>
2 5 instruction ofthe following form:<br>
.,i...utmai--' .... ..-—"• . . . - . ft<br>
.3%-<br>
^ 321MLIL. 16 Dd, Dn, Dni[0]<br>
The source registers are 64-bit registers, and the multiply instruction specifies<br>
a lane width of 32 bits and a data element size of 16 bits. The multiply instruction is<br>
) arranged within each lane to multiply the first data element in that lane within the<br>
source register Dm 1165 with each of the data elements in that lane in the second<br>
source register Dn 1170 (as shown in Figure 59A), with the resultant values being<br>
stored in corresponding locations Avithin the destination register Dd 1175. Within<br>
each lane, the first data element in the destiaation register is considered to represent<br>
1) the real part of the partial result of the complex number, and the second data element<br>
i is considered to represent the imaginary part of the partial result of the complex<br>
number.<br>
FolloAving execution of the instruction illustrated in Figure 59A, the following<br>
15 instraction is then executed:<br>
32|MASX.16Dd,Dn,Dm[l] |<br>
As illustrated by Figure 598, this instruction is a "multiply add subtract with<br>
exchange" instruction. In accordance with this instruction, the second data element |<br>
2 3 within each lane of the source register Dm is multiplied with each data element within i<br>
the coiresponding lane of the second source register Dn, in the manner illustrated in<br>
Figure 59B. Then, the result of that multipHcation is either added to, or subtracted<br>
fi:om, the values of corresponding data elements already stored within the destination<br>
register Dd 1175, with the result then being placed back within the destination register<br>
25 Dd 1175. It win be appreciated firom a comparison of the operations of Figures 59A<br>
and 59B mth the earlier identified equations for generating the real and imaginary<br>
parts of the resultant complex number D that by employing these two instructions in<br>
sequence, the computation can be performed in parallel for two sets of complex<br>
numbers, thereby enabling the speed benefit of a SIMD approach to be reaHsed.<br>
30<br>
From the above examples, it will be appreciated that by providing an<br>
instruction with the abiUty to -specify a lane size in addition to a data element size, the<br>
mmiber of operations that can potentially benefit fi-om a SIMD implementation is<br>
increased, and hence this provides' a much improved flexibility with regard to the<br>
3 5 implementation of operations in a SIMD manner.<br>
-UiCJTm.-L- - - - •• - -. .-,-. .. - -,.. _<br>
The present technique provides the ability to perform SIMD processing on<br>
vectors where the source and destination data element widths are different. One<br>
particularly useful operation in this environment is an add or subtract then return high<br>
5 half SIMD operation. Figure 60 shows an example of an add return high half<br>
operation according to the present technique. An instruction decoder within the<br>
SJMD decoder 16 (see Figure 1) decodes instruction VADH.I16.B2 Dd,Qn,Qm and i<br>
performs the addition return high half illustrated in Figure 60 and set out below.<br>
ID In Figure 60 two source registers located in the SIMD register file 20 (see<br>
Figure 1), Qn and Qm contain vectors of 32-bit data elements a and b. These are<br>
added together to form a vector of 16-bit data elements Dd also located in register file<br>
(<br>
20 formed from the high half of the data sums:<br>
15 Qn = {a3a2al aO]<br>
Qm=[b3b2blb]<br>
Output<br>
2 0 Dd = [(a3+b3)»16, (a2+b2)»16, (al+bl)»16, (a0+b0)»16].<br>
Figure 61 schematically shows a similar operation to that shown in Figure 60<br>
but in this case, the instruction decoded is VRADH.Il 6.132 Dd,Qn,Qm and the<br>
operation performed is an add return high vnlh rounding. This is performed in a very<br>
2 5 similar way to the operation illustrated in Figure 60 but the high half is rounded. This<br>
is done, in this example, by adding a data value having a one in the most significant<br>
bit position of the lower half of the data value and zeros elsewhere afier the addition<br>
and prior to taking the high half<br>
2 0 In this Figure as in Figure 61 intermediate values are shown with dotted hnes<br>
for clarity.<br>
Further instructions (not illustrated) that may be supported are an addition or<br>
subtraction return high with saturation. In this case the addition or subtraction will be<br>
3: saturated where appropriate prior to the high half being taken.<br>
' " ' " ' - ^ '" '<br>
^ Table 11 shows examples of some of the instructions that are supported by the !<br>
present technique. Size<a> returns the size of the data type in bits and ro-und</a>
</td>
<td>
<br>
returns rounding constant l«(size<dt> -1).<br>
:: !<br>
Mnemonic Data Type Operand Description<br>
Format i<br>
VADH .18.116 bd, Qn, Qm Add returning High Half<br>
.116.132 Vd[ i ] := (Vn[ i ]+Vm[ i ] )»size<td>
<br>
i<br>
1 ) .B2.I64<br>
VRADH .18.116 Dd, Qn, Qm Add returning High Half with Rounding<br>
.116.132 Vd[ i ] := (Vn[ i ]+Vm[ i ]+ round</td>
<td>) »size</td>
<td>
<br>
.132.164<br>
( VSBH .18.116 Dd, Qn, Qm Subtract returning High Half<br>
15 .116.132 Vd [ i ] := (Vn [ i ] - Vm[ i ] )»si2e</td>
<td>
<br>
.132.164<br>
VRSBH .18.116 Dd, Qn, Qm Subtract returning High Half with Rounding i<br>
.116.132 Vd [ i ] := (Vn [ i ] - Vm[ i ]+round</td>
<td>) »si2e</td>
<td> .B2.I64<br>
2)<br>
Table 11<br>
The present technique can be performed on different types of data provided<br>
that taking the high half of the data is a sensible thing to do. It is particularly<br>
, 2 5 appropriate to processing performed on fixed point numbers.<br>
The above technique has many applications and can be used, for example, to<br>
I accelerate SIMD FFT implementations. SIMD is particularly useful for performing<br>
1 FFT (fast fourier transform) operations, where the same operations need to be<br>
3 )i performed on multiple data. Thus, using SIMD processing allows the multiple data to<br>
1 be processed in parallel. The calculations performed for FFTs often invoh^e<br>
multiplying complex numbers together. This involves the multiplication of data<br>
values and.then the addition or subtraction of the products. In SIMD processing these<br>
calculations are performed in parallel to increase processing speed.<br>
35 ^<br>
A simple example of the sort of sums that need to be -performed is .given<br>
below.<br>
i<br>
9 (a +ic) * (b + id) = e +if<br>
•<br>
Thus, the real portion e is equal t o : a * b - c * d and<br>
; The imaginary portion f is equal to: a * d + c * b I<br>
i<br>
Figure 62 shows a calculation to determine the real portion e. As can be seen I<br>
the vectors for a containing 16 bit data element are multiplied with the vectors for b<br>
containing the same size data elements and those for c with d. These products<br>
1) produce two vectors with 32 bit data elements. To produce e one of the vectors needs<br>
to be subtracted from the other but the final result is only needed to the same accuracy<br>
as the original values. Thus, a resulting vector with 16 bit data elements is required.<br>
This operation can be performed in response to the single instruction VSBH. 16.32<br>
Dd, Qn, Qm as is shoAvn in the Figure. This instruction, subtract r-etum high half, is<br>
1 &gt; therefore particularly useful in this context. Furthermore, it has the advantage of<br>
allowing the arithmetic operation to be performed on the wider data width and the<br>
narrowing only occurring after the arithmetic operation (subtraction). This generally<br>
gives a more accurate result than narrowing prior to performing the subtraction.<br>
2) ARM have provided their instruction set with an instruction encoding which<br>
allows an immediate to be specified with some instructions. Clearly, the immediate<br>
size should be limited if it is encoded with the instruction.<br>
An immediate value of a size suitable for encoding with an instruction has<br>
2 5 limited use in SIMD processing where data elements are processed in parallel. In<br>
order to address this problem, a set of instractions with generated constant is provided<br>
that have a limited size immediate associated therewith, but have the ability to expand<br>
this immediate. Thus, for example, a byte sized immediate can be expanded to<br>
produce a 64-bit constant or immediate. In this way the immediate can be used in<br>
3) logical operations with a 64-bit source register comprising multiple source data<br>
elements in SIMD processing.<br>
Figure 63 shows an immediate abcdefgh, that is encoded within an instruction j<br>
along with a control value, which is shown in the left hand column of the table. The<br>
3B binary immediate can be expanded to fill a '64-bit register, the actual expansion<br>
performed depending on the inBtruction and the control portion associated with it. In<br>
" the example shoAvn, the 8-bit immediate abcdefgh, is repeated at different places<br>
within a 64 bit data value, the positions at which the immediate is placed depending<br>
on the control value. Furthermore, zeros and/or ones can be used to fill the empty<br>
) spaces where the value is not placed. The choice of either ones and/or zeros is also<br>
determined by the control value. Thus, in this example a wide range of possible<br>
constants for use in SIMD processing can be produced firom an instruction having an<br>
8-bit immediate and 4-bit control value associated with it.<br>
13 In one embodiment (last line of the table), instead of repeating the immediate<br>
, at certain places, each bit of the immediate is expanded to produce the new 64 bit<br>
immediate or constant.<br>
As can be seen in some cases, die constant is the same in each lane, while in<br>
15 others different constants appear in some of the lanes. In some embodiments (not<br>
shown), the possibihty of inverting these constants is also provided and this also<br>
increases the number of constants that can be generated.<br>
An example of the format of an instruction that can be used for constant<br>
2 0 generation as shown in Figure 63 is given below. In this iostructions <value> is .the<br>
data portion or immediate and <mode> is the control portion which provides an<br>
indication as to how the <value> portion is to be expanded within the generated<br>
constant (shown as different lines in the table of Figure 63).<br>
25 VMOV Dd, #<value>, <mode><br>
where<br><value> is a byte<br><mode> is one of the enumerated expansion functions<br>
2 0 These adapted instructions generally have an associated data value that has a<br>
data portion <value> which comprises the unmediate and a CDntrol portion <mode>.<br>
As is shown in Figure 63 the control portion indicates how tiie immediate is to be<br>
expanded. This may be done in a variety of ways, but in some embodiments, the<br>
control portion indicates which expansion of the constant is to be performed using<br>
35 constant generation logic.<br>
I<br>
^ Figure 64 schematically shows an example of constant generation logic<br>
operable to generate a constant from a data portion 1210 and a control portion 1200<br>
associated with an instruction according to the present technique. In the example<br>
5 shown, the control portion 1200 controls the control generation logic 1220, which<br>
comprises gates 1230 to output either a portion of the data value 1210, or a one or a<br>
zero to each bit within the constant 1240 to be generated.<br>
Figure 65 shows a data processor (integrated circuit) similar to that shoivn in<br>
10 Figure 1, with like reference numerals representing hke features. Figure 65 differs<br>
I from Figure 1 in that it explicitly shows constant generation logic 1220. Constant<br>
generation logic 1220 can be considered to be adjacent to, or forming part, of the<br>
decode/control portion 14, 16. As can be seen instructions are sent from the<br>
instruction pipehne 12 to the decode/confrol logic 14, 16. This produces control<br>
1 5 • signals which contiol the operation of the SIMD processing logic 18, the load store<br>
unit 22, and the scalar processing portion 4, 6, 8, 10 of the processor. If an instruction<br>
with constant generation is received at the decode/control portion 14, 16, the constant<br>
generation logic is used to generate a constant for use in SIMD processing. This can<br>
either be sent directly to the SIMD register data store 20 (dotted line 1222), or if the<br>
2 0 instmction with constant generation comprises a SIMD data processing part, the<br>
generated constant is sent to the SIMD processing logic (line 1224) where fiirther<br>
manipulations are performed on the generated constant to produce a new data value.<br>
Figure 66A and B schematically illustrates the two different paths shown in<br>
:.5 Figure 65. Figure 66A shows the case where the instruction generates a constant<br>
which is sent directly to the register store, i.e. dotted line 1222. Figure 66B, shows<br>
the case where the instruction with generated constant comprises a data processing<br>
part. In this case data processing operations (OP) are perfoimed on the generated<br>
constant and a ftuther source operand 1250 to produce a final data value 1260 in<br>
: p response to the instraction, this corresponds to line 1224 of Figure 65.<br>
In addition to the constants shown in Figures 63 and their inversions,<br>
additional data processing operations such as an OR, AND, test, add or -subtract can<br>
be performed on the generated constants to generate a much wider range of data<br>
: 15 values. This correBponds to Figure 13B and path 1224 in Figure 65. Table 12 gives<br>
- ( S o -<br>
an example of bitwise AND and bitwise OR that can be used to generate some<br>
9 additional data values.<br>
Mnemonic Data Type Operand Format Description<br>
5 VAM) none Dd, #<value>,<mode> Bitwise AND with<br>
generated constant<br>
Vd := Vd &amp; <generated constant><br>
VORR none Dd, #<value>,<mode> Bitwise OR with<br>
1D generated constant<br>
Vd := Vd I <generated constant><br>
' The abihty to perform fiirther data processing operations on the generated<br>
constants can have a variety of uses. For example, Figure 67 shows how<br>
15 embodiments of the present technique can be used to generate a bit mask to -extract a<br>
certain bit or bits from a number of data elements in a vector. In the example shown<br>
the fourth bit of each data element from a source vector is extracted, hiitially the<br>
immediate 8 is expanded by repeating it and then this is followed by a logical AND<br>
instruction which AMDs the generated constant with a source vector to exfract the<br>
2 0 desired bit from each data element. These operations are performed in response to the<br>
instruction<br>
VAM)Dd,#Ob00001000, ObllOO<br>
2 5 Wherein the <mode> value 1100 refers to a generated constant comprising an<br>
expanded data portion (see Figure 63).<br>
Although a particular embodiment has been described herein, it will be<br>
appreciated that the invention is not limited thereto and that many modifications and<br>
: 0 additions thereto may be made v/ithin tlie scope of the invention. For example, various<br>
combinations of the features of the following dependent claims could be.made with the<br>
features of the independent claims without depaJrting from the scope of the present<br>
invention.<br>
I<br><br><br><br><br><br><br><br>
- 8 1 '<br>
ORIGINAL<br>
We Claim<br>
1. Apparatus for processing data, said apparatus comprising:<br>
a register data store (20) operable to store a plurality of data elements;<br>
and processing logic (6, 8, 10, 12) responsive to a data processing instruction to perform<br>
a data processing operation in parallel upon a selected plurality of data elements accessed as a<br>
register of said register data store (20);<br>
wherein data elements of said selected plurality of data elements share one of a plurality<br>
of different data element sizes, said register has one of a plurality of different register sizes and<br>
said data processing instruction specifies for said data processing operation a data element size<br>
shared by said selected plurality of data elements and a register size of said register; and<br>
wherein said apparatus comprises register accessing logic operable to map said register to<br>
a portion of said register data store (20) dependent upon said register size of said register such<br>
that a data element stored within said portion of said register data store (20) is accessible as a<br>
part of respective different registers of differing register size.<br>
2. Apparatus as claimed in claim 1, wherein said data processing instruction specifies one or<br>
more source registers each with a respective source register size and source data element size<br>
specified by said data processing instruction.<br>
3. Apparatus as claimed in any one of claims 1 and 2, wherein said data processing<br>
instruction specifies one or more destination registers with a destination register size and<br>
destination data element size specified by said data processing instruction.<br>
4. Apparatus as claimed in claims 2 and 3, wherein said destination data element size differs<br>
from at least one of said one or more source data element sizes.<br>
5. Apparatus as claimed in any one of the preceding claims, wherein said register accessing<br>
logic is configured to read from said data store within a single further register a set of data<br>
elements written to said register data store (20) with two different registers.<br>
W 6. Apparatus as claimed in claim 5, wherein said register accessing logic is configured to write<br>
said set of data elements with two different registers to adjacent portions of said register data<br>
store (20).<br>
7. Apparatus as claimed in claim 6, wherein said single fiirther register has a register size<br>
equal to a sum of the register sizes of said two different registers.<br>
8. Apparatus as claimed in any one of the preceding claims, wherein said register accessing<br>
logic is configured to read from said data store within two different fiirther registers a group of<br>
data elements written together to said register data store (20) from a single register.<br>
9. Apparatus as claimed in claim 8, wherein said two different further registers read from<br>
adjacent portions of said register data store (20).<br>
10. Apparatus as claimed in claim 9, wherein said single register has a register size equal to a<br>
sum of the register sizes of said two different further registers.<br>
11. Apparatus as claimed in any one of claims 1 to 7, wherein a group of data elements<br>
written together to said register data store (20) from a first register of a first register size can be<br>
read from said register data store (20) within a second register of a second register size, said first<br>
register size being different to said second register size.<br>
12. Apparatus as claimed in any one of the preceding claims, wherein said data processing<br>
instruction specifies two source registers with respective register sizes Si and S2 and a<br>
destination register with a register size D.<br>
13. Apparatus as claimed in claim 12, wherein Si = S2 = D.<br>
14. Apparatus as claimed in claim 12, wherein 2* Si = 2* S2 = D.<br>
15. Apparatus as claimed in claim 12, wherein 2* Si = S2 = D.<br>
" 16. Apparatus as claimed in claim 12, wherein Si= 82= 2*D.<br>
17. Apparatus as claimed in any one of claims 1 to 11, wherein said data processing<br>
instruction specifies a source register with a register size S and a destination register with a<br>
register size D.<br>
18. Apparatus as claimed in claim 17, wherein S=D.<br>
19. Apparatus as claimed in claim 17, wherein 2*S=D.<br>
20. Apparatus as claimed in claim 17, wherein S=2*D.<br>
21. Apparatus as claimed in any one of the preceding claims, wherein said data processing<br>
instruction includes a register specifying field operable to specify a register within said register<br>
data store (20), and said register accessing logic is configured to map said register to a portion of<br>
said register data store (20) such that said register for a given register specifying field<br>
corresponds to a different portion of said register data store (20) in dependence upon said data<br>
element size and said register size.<br>
22. Apparatus as claimed in claim 21, wherein said register accessing logic is configured to<br>
map a plurality of registers corresponding to a range of said register specifying field for a given<br>
data element size and register size to a contiguous portion of said register data store (20) when<br>
accessed with registers using at least one of a different register size and a different data element<br>
size.<br>
23. Apparatus as claimed in any one of the preceding claims, wherein said different registers<br>
of differing register size include at least one register with a different data element size from that<br>
of said data element stored within said portion.<br>
24. Apparatus as claimed in any one of the preceding claims, wherein said data processing<br>
instruction includes a plurality of bits encoding a register number of said register, said plurality<br>
of bits being mapable to a contiguous field of bits which is rotatable by a number of bit positions<br>
dependent upon said register size to form said register number.<br>
^ 25. Apparatus as claimed in claim 24, wherein said register accessing logic is also operable<br>
to access said register data store (20) as a scalar register storing a single data element read from<br>
said register data store (20).<br>
26. Apparatus as claimed in claim 24, wherein said register accessing logic is also operable<br>
to access said register data store (20) as a register storing a plurality of copies of a single data<br>
element read from said register data store (20).<br>
27. Apparatus as claimed in any one of claims 25 and 26, wherein said register accessing<br>
logic is operable to generate a row address and a column address for accessing said register data<br>
store (20), a first part of said contiguous field of bits corresponding to said row address and a<br>
second part of said contiguous field of bits corresponding to said column address.<br>
28. Apparatus as claimed in claim 27, wherein one or more boundaries between said first part<br>
and said second part vary in position in dependence upon said data element size.<br>
29. A method of processing data, said method comprising the steps of:<br>
storing a plurality of data elements within a register data store (20); and<br>
in response to a data processing instruction, processing logic (6, 8, 10, 12) performing a<br>
data processing operation in parallel upon a selected plurality of data elements accessed as a<br>
register of said register data store (20), wherein:<br>
data elements of said selected plurality of data elements share one of a plurality of<br>
different data element sizes, said register has one of a plurality of different register sizes and said<br>
data processing instruction specifies for said data processing operation a data element size shared<br>
by said selected plurality of data elements and a register size of said register, and<br>
wherein said method comprises register accessing logic mapping said register to a portion<br>
of said register data store (20) dependent upon said register size of said register such that a data<br>
element stored within said portion of said register data store (20) is accessible as a part of<br>
respective different registers of differing register size.<br>
i<br>
_ i<br>
9 30. A method as claimed in claim 29, wherein said data processing instruction specifies one<br>
or more source registers each with a respective source register size and source data element size<br>
specified by said data processing instruction.<br>
31. A method as claimed in any one of claims 29 and 30, wherein said data processing<br>
instruction specifies one or more destination register with a destination register size and<br>
destination data element size specified by said data processing instruction.<br>
32. A method as claimed in claims 30 and 31, wherein said destination data element size<br>
differs from at least one of said one or more source data element sizes.<br>
33. A method as claimed in any one of claims 29 to 32, said register accessing logic reading<br>
from said register data store (20) within a single further register a set of data elements written to<br>
said register data store (20) with two different registers.<br>
34. A method as claimed in claim 33, wherein said register accessing logic writing said set<br>
of data elements with two different registers to adjacent portions of said register data store (20).<br>
35. A method as claimed in claim 34, wherein said single further register has a register size<br>
equal to a sum of the register sizes of said two different registers.<br>
36. A method as claimed in any one of claims 29 to 35, said register accessing logic reading<br>
from said register data store (20) within two different further registers a group of data elements<br>
written together to said register data store (20) from a single register.<br>
37. A method as claimed in claim 36, wherein said two different further registers read from<br>
adjacent portions of said register data store (20).<br>
38. A method as claimed in claim 37, wherein said single register has a register size equal to<br>
a sum of the register sizes of said two different further registers.<br>
™ 39. A method as claimed in any one of claims 29 to 35, wherein a group of data elements<br>
written together to said register data store (20) from a first register of a first register size can be<br>
read from said register data store (20) within a second register of a second register size, said first<br>
register size being different to said second register size.<br>
40. A method as claimed in any one of claims 29 to 39, wherein said data processing<br>
instruction specifies two source registers with respective register sizes Si and Siand a destination<br>
register with a register size D.<br>
41. A method as claimed in claim 40, wherein Si = S2 = D.<br>
42. A method as claimed in claim 40, wherein 2* Si = 2* S2 = D.<br>
43. A method as claimed in claim 40, wherein 2* Si = S2 = D.<br>
44. A method as claimed in claim 40, wherein Si = S2= 2*D.<br>
45. A method as claimed in any one of claims 29 to 39, wherein said data processing<br>
instruction specifies a source register with a register size S and a destination register with a<br>
register size D.<br>
46. A method as claimed in claim 45, wherein S=D.<br>
47. A method as claimed in claim 45, wherein 2*S=D.<br>
48. A method as claimed in claim 45, wherein S=2*D.<br>
49. A method as claimed in any one of claims 29 to 44, wherein said data processing<br>
instruction includes a register specifying field operable to specify a register within said register<br>
data store (20), and said register accessing logic maps said register to a portion of said register<br>
data store (20) such that said register for a given register specifying field corresponds to a<br>
" different portion of said register data store (20) in dependence upon said data element size and<br>
said register size.<br>
50. A method as claimed in claim 49, said register accessing logic mapping a plurality of<br>
registers corresponding to a range of said register specifying field for a given data element size<br>
and register size to a contiguous portion of said register data store (20) when accessed with<br>
registers using at least one of a different register size and a different data element size.<br>
51. A method as claimed in any one of claims 29 to 50, wherein said register accessing logic<br>
maps register to a portion of said register data store (20) such that said different registers of<br>
differing register size include at least one register with a different data element size from that of<br>
said data element stored within said portion.<br>
52. A method as claimed in any one of claims 29 to 51, wherein said data processing<br>
instruction includes a plurality of bits encoding a register number of said register, said plurality<br>
of bits being mapable to a contiguous field of bits which is rotatable by a number of bit positions<br>
dependent upon said register size to form said register number.<br>
53. A method as claimed in claim 52, wherein said register accessing logic is also operable to<br>
access said register data store (20) as a scalar register storing a single data 20 element read from<br>
said register data store (20).<br>
54. A method as claimed in claim 52, wherein said register accessing logic is also operable to<br>
access said register data store (20) as a register storing a plurality of copies of a single data<br>
element read from said register data store (20).<br>
55. A method as claimed in any one of claims 53 to 54, wherein said register accessing logic<br>
is operable to generate a row address and a column address for accessing said register data store<br>
(20), a first part of said contiguous field of bits corresponding to said row address and a second<br>
part of said contiguous field of bits corresponding to said column address.<br>
W 56. A method as claimed in claim 55, wherein one or more boundaries between said first part<br>
and said second part vary in position in dependence upon said data element size.<br>
57. A computer program product comprising a computer program including at least one data<br>
processing instruction operable to control processing logic to perform a method as claimed in<br>
any one of claims 249 to 456.<br>
[S]</mode></generated></mode></value></generated></mode></value></mode></value></mode></value></mode></value></value></mode></value>
</td>
    </dt>
</td></iist></addr></list></list></addr></list></list></addr></lis1></list></addr></list></list></addr></list></list></addr></list></list></addr></list></list></addr></list></list></lis1></list></addr></list></list></addr></list></lis1></addr></list></list></addr></list></list></addr></list></list></addr></list></addr>
</dt>
</dt></list></addr></iist></list></addx></list></addr>
</dt>
</dt></ust></addr></list></iist></ad></list></addr></addr></st></reglist>
</dt></n></n></n></st>
</dt></reghst></a>
</dt></st></st></addr></n></regust></a>
</dt></st></size></size></si2e></size></size></size></size></size></si2e></size></si2e></size></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUNsYWltcy0oMDEtMDQtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Claims-(01-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUNsYWltcy0oMDgtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Claims-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWNvcnJlc3BvbmRlbmNlIC1vdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-correspondence -others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMDEtMDQtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Correspondence Others-(01-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMTgtMDMtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Correspondence Others-(18-03-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMDgtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Correspondence-Others-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LURlc2NyaXB0aW9uIChDb21wbGV0ZSktKDA4LTA4LTIwMTMpLnBkZg==" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Description (Complete)-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWRlc2NyaXB0aW9uIC0oY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-description -(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LURyYXdpbmdzLSgwOC0wOC0yMDEzKS5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Drawings-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUZvcm0tMi0oMDgtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Form-2-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUZvcm0tMy0oMDgtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Form-3-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUdQQS0oMDgtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-GPA-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LUdQQS0oMTgtMDMtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-GPA-(18-03-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC0xMDEucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-101.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC0yMTAucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-210.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC0yMjAucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC0yMzcucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC0zMDQucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC00MDkucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-409.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBjdC00MTYucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-pct-416.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LVBldGl0aW9uLTEzNy0oMDEtMDQtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Petition-137-(01-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LVBldGl0aW9uLTEzNy0oMDgtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-Petition-137-(08-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzEwNC1kZWxucC0yMDA2LXBldGl0aW9uLTEzOC5wZGY=" target="_blank" style="word-wrap:break-word;">3104-delnp-2006-petition-138.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="260294-method-and-apparatus-for-assembling-a-complex-product-in-a-parallel-process-system.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="260296-process-for-production-of-polyester-particles-polyester-particles-polyester-resin-particles-and-process-for-production-thereof.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>260295</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3104/DELNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>17/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>25-Apr-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>21-Apr-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>31-May-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>ARM LIMITED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>110 FULBOURN ROAD, CHERRY HINTON, CAMBRIDGE CB1 9NJ, ENGLAND</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DAVID JAMES SEAL</td>
											<td>14 HIGH STREET, CHERRY HINTON, CAMBRIDGE CB1 9HZ, GREAT BRITAIN</td>
										</tr>
										<tr>
											<td>2</td>
											<td>SIMON FORD</td>
											<td>5 LIMETREE CLOSE, CAMBRIDGE, CAMBRIDGESHIRE CB1 8PF, GREAT BRITAIN.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F 15/80</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/GB2004/002836</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-07-01</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>0328513.7</td>
									<td>2003-12-09</td>
								    <td>U.K.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/260295-apparatus-and-method-for-processing-data by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:28:08 GMT -->
</html>
