<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/251966-a-computer-implemented-method-of-increasing-glue-logic-distribution-efficiency by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:37:46 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 251966:A COMPUTER-IMPLEMENTED METHOD OF INCREASING GLUE LOGIC DISTRIBUTION EFFICIENCY</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A COMPUTER-IMPLEMENTED METHOD OF INCREASING GLUE LOGIC DISTRIBUTION EFFICIENCY</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>There is disclosed a computer-implemented method of increasing glue logic distribution efficiency, for execution in an integrated circuit device design scheme, wherein a device design comprises a plurality of pre-existing design blocks, the method comprising the steps of copying a selected glue logic element, thereby creating a duplicate element set having said selected element and its copy; and distributing said duplicate element set to the plurality of design blocks.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>BACKGROUND OF THE INVENTION<br>
Field of the Invention<br>
The present invention relates in general to a method of increasing glue<br>
logic distribution efficiency and an interface system therefor, and more<br>
specifically to the design of systems re-using pre-designed circuit blocks. This<br>
application has been divided out of Indian Patent Application No.<br>
IN/PCT/2001/00363 filed on 28/03/2001 (hereinafter referred to as the "Parent<br>
Application").<br>
BACKGROUND OF THE INVENTION<br>
In recent years, constant innovation in silicon process technology has<br>
drastically reduced the price and increased the performance and functionality of<br>
integrated circuit devices, thus stimulating the development of the electronics<br>
manufacturing and information processing industries. In turn, these fast growing<br>
industries impose increasing demands on the integrated circuit design system<br>
developers for still faster and cheaper devices. As a result, the design industry is<br>
now undergoing drastic changes, including :<br><br>
(1) Chip designs are getting larger and more complex. For<br>
example, in 1997, a typical integrated circuit contained from 100-500K<br>
gates. In 1998, the typical device contained one to two million gates.<br>
Technology in 1999 has shown the continuation of this trend with<br>
devices of four to six million gates being built.<br>
(2) Chip designs are becoming more application-specific. In the<br>
early days of iC design, device manufactures wouid produce various "off-<br>
the-shelf" chips, which end users would design into their electronic<br>
products. Currently, electronic product manufactures more often order<br>
custom chip designs to perform specific functions.<br>
(3) Electronic product development is now primarily driven by<br>
consumer demand, which has shortened product life cycles and, therefore<br>
shortened allowed design time and resources. For example, in 1997, the<br>
average design cycle was between 12-18 months. In 1998, that average<br>
time decreased to 10-12 months and in 1999 the industry is pushing<br>
towards 8-10 month design-cycle times.<br>
(4) Design time constraints require parallel design effort. Formerly,<br>
critical design decisions for upstream system components could wait until<br>
downstream system component designs were verified. Design managers<br>
no longer have the luxury of sequentially performing design tasks.<br>
Several system components may have to be developed concurrently.<br>
Thus, design managers are required to make crucial predictions before at<br>
least some system component designs are complete.<br>
To address these demands, electronic system design is now<br>
moving to a methodology known in the art as Block Based Design<br><br>
("BBD"), in which a system is designed by integrating a plurality of<br>
existing component design blocks (also referred to in the art as<br>
"intellectual property blocks" or "IP blocks"). These pre designed blocks<br>
may be obtained from internal design teams or licensed from other design<br>
companies, and may be supported by fundamentally different design<br>
structures and environments. Moreover, pre-designed blocks may be<br>
developed to meet different design requirements and constraints.<br>
Another challenge faced by designers using BBD is the front-end<br>
(project acceptance) delays and risk brought about by uncertainty in<br>
determining system design feasibility. Current ASIC (application-specific<br>
integrated circuit) designs are primarily presented at the RTL (register<br>
transfer level) stage, and some even earlier, at specification level, to<br>
designers by customers. These designs are then partitioned in a manner<br>
based upon the limitations of available synthesis technology, according to<br>
the area, performance, and power tradeoffs required to provide cost-<br>
effective implementation. In this manner, the designer accepts a system<br>
specification as input and ultimately provides a netlist-level design for<br>
physical implementation (including design place, route, and verification).<br>
If design specifications are within the capabilities of the intended or<br>
available processing technology, including clocking, power, and size<br>
specifications, the available design methodology is reasonably predictable<br>
and works well with available circuit design tools.<br>
However, the RTL-level design and the system-level design<br>
activities are typically uncoupled or loosely coupled, meaning there is no<br>
coherent link from the system-level functional definition to the ASIC (RTL)<br>
level. The RTL-level design is developed based upon a paper ASIC<br><br>
specification and verified by a newly formed test suit created around the<br>
ASIC interface. Thus, available design and implementation methodologies<br>
for ASIC design present a number of problems, which hamper efficient<br>
block integration.<br>
First, current methodologies do not provide a top-down approach<br>
to comprehensively evaluate and ensure compatibility to integrate a<br>
plurality of design blocks provided by multiple sources having differing<br>
design considerations, while providing hierarchical verification and short<br>
assembly time within tight time-to-market constraints.<br>
Also, existing methodologies for ASIC design do not provide<br>
scalability. A significant number of existing methodologies are focused<br>
around a flat design. This approach has led to significant problems in the<br>
length of time required to assemble the top-level design for a system<br>
having more than one million gates.<br>
In addition, existing ASIC design methodologies are not suitable for<br>
reuse of pre-designed circuit blocks. Available schemes do not provide<br>
guidelines to solve the timing, clock, bus, power, block arrangement,<br>
verification, and testing problems associated with integrating circuit<br>
design blocks within specific device architectures. Thus, without a<br>
comprehensive approach to block reuse, existing methodologies bring<br>
about an ad-hoc and unpredictable design approach, reduce design<br>
realization feasibility, increase cost and time to delivery, and often trigger<br>
performance-reducing modifications to the pre-designed circuit blocks<br>
themselves in order to fit them into the designed system. Furthermore,<br>
existing methodologies do not provide performance trade-off analysis and<br>
feedback of critical design parameters, such as clock frequency, and area<br><br>
versus risk of successfully and predictably completing chip designs and<br>
implementations.<br>
There is, therefore, a need for a methodology that can satisfy the<br>
evolving environment and address the shortcomings of the available art.<br>
There is also a need for a suitable methodology for using and re-<br>
using pre-designed circuit blocks from multiple sources in a circuit design.<br>
Combining IP blocks also brings about the need for "glue" logic,<br>
the logic that allows the blocks to work together on a single device. Glue<br>
logic is the logic primarily responsible for interconnecting design blocks,<br>
and normally resides between the blocks, dispersed throughout the<br>
design. Glue logic elements can be added to a design during various<br>
stages of chip planning, or can reside at the outermost boundary of each<br>
block within a design to act as an interconnect mechanism for the host<br>
block. Regardless of its source, glue logic must be optimally placed<br>
within the design to minimize wire congestion and timing complications<br>
which arise from placement of glue logic between blocks, introducing<br>
delays which may not have been contemplated by the original block<br>
designer.<br>
There is therefore a need in the art to which the present invention<br>
pertains for an improved method of placing and distributing glue logic in a<br>
block based design.<br>
There is also a need for a glue logic distribution mechanism that<br>
takes into account the functional affinity of various glue logic elements,<br>
and groups them into new design blocks.<br><br>
There is also a need in the relevant art for a glue logic distribution<br>
mechanism that returns an optimized amount of glue logic to existing<br>
design<br>
In addition, existing ASIC design methodologies are not suitable for<br>
reuse of pre-designed circuit blocks. Available schemes do not provide<br>
guidelines to solve the timing, clock, bus, power, block arrangement,<br>
verification, and testing problems associated with integrating circuit<br>
design blocks within specific device architectures. Since the circuit<br>
blocks are from multiple inconsistent sources, the challenge is how to<br>
integrate these circuit blocks into a circuit system in a fashion suitable to<br>
block-based design.<br>
Therefore, there is a need for a method and apparatus suitable to<br>
inter-connect the circuit blocks from multiple inconsistent sources in a<br>
fashion suitable to block-based design.<br>
There is another need for a method and apparatus to provide<br>
interfaces for converting the circuit blocks having different interfaces into<br>
the ones having standardized interfaces.<br>
 Of course, all ICs, even those containing an entire system on a<br>
single chip, must pass a series of tests to verify that the chip meets<br>
performance requirements and that there are no hidden manufacturing<br>
defects. If a manufacturing defect is missed, the faulty chip may not be<br>
discovered until after the assembly process or, worse yet, in the field.<br>
The cost of such "test escapes" in terms of their effect on customer<br>
satisfaction can be devastating to a product line.<br><br>
Generally, there are three types of tests for detecting defects: DC<br>
parametric tests, AC parametric tests, and functional ("PLL") tests. In DC<br>
parametric tests, the inputs, outputs, input-to-output transmission, total<br>
current, and power consumption of the chip are measured. In AC<br>
parametric tests, the rising and falling times of the input and output<br>
signals, delay time in propagation between input and output terminals,<br>
minimum clock pulse width, and operation frequency of the chip are<br>
measured. In functional tests, the chip is tested to see if it functions as<br>
designed under prescribed operating conditions. Typically, applying a test<br>
pattern to an input terminal ("test vectors"} and comparing an output<br>
pattern detected at an output terminal with an expected pattern carries<br>
out a functional test.<br>
Before the advent of Design for Test ("DFT") methodologies,<br>
designers created and assembled a chip, then passed the completed<br>
design to test designers. The test designers then added package-level test<br>
logic, and sent the chip to the manufacturer (the "fab"). The fab testers<br>
then probed the chip and ran a board test protocol including the above-<br>
described tests on the package-level logic. The available Scan Design<br>
methodology is a simple example of a highly effective and widely used<br>
method for applying a "single" test method to the entire chip with<br>
predictable and consistent test result. Other ad hoc methods may be<br>
used to handle nonscannable design styles.<br>
Today, logic previously contained in a whole chip is now used as a<br>
single virtual component (VC) or design block to be included in a larger<br>
chip. Thus, tests can no longer be designed after circuit design is<br>
complete. Designers must plan how to test each design block, as well as<br><br>
the whole packaged chip, throughout the design process. The design<br>
process must therefore ensure testability by applying one or more test<br>
methods as appropriate.<br>
The benefits of DFT are well known. DFT logic and test vector<br>
verification functions allow shorter, production-ready tests early in a<br>
production cycle. Also, DFT scan paths provide access to chip and<br>
system states that are otherwise unavailable. A good DFT plan thereby<br>
shortens time-to-market and reduces testing cost by easing the front-end<br>
design process and the development of manufacturing tests.<br>
There are therefore four needs presented by the available art.<br>
First, a new DFT for BBD must be able to make effective use of the pre-<br>
designed test data among other dissimilar test methods, to share limited<br>
test access, and to meet the overall SOC level test objectives.<br>
Second, it must face the emerging difficulties of new defect types<br>
and new defect levels due to technology scaling, the new complexities of<br>
mixed-signal and mixed technology design, and the increasing I/O count<br>
and new packaging techniques.<br>
Third, it must face the difficulties of integrating IP blocks, which<br>
inherently lack a unified structural test model. SOC level test access and<br>
fault isolation are needed, and the demand for low power design<br>
techniques (i.e., latch-based, gated clock, derived clock/pipelines, and<br>
low threshold voltage) which are largely unsupported by the currently<br>
available DFT methodologies must be addressed.<br><br>
And the new DFT methodology must overcome the time to market<br>
pressure with a coherent and consistent test integration model even<br>
when faced with limited or inadequate test information.<br>
The available art requires structural information (i.e., fault models<br>
and test models) so that the test data can be partially or fully generated<br>
and verified for a set of faults. For example, the Scan Design<br>
Methodology is only applicable to synchronous design and detects only<br>
single stuck-at-fault models. Moreover, other DFT solutions are scan-<br>
based, thus making it rather difficult for sharing and verifying the hard IP<br>
test model, which does not contain structural information.<br>
The available art also requires a non-linear computation model that<br>
cannot sustain the current gate count explosion, even if sharing and<br>
verifying were possible (i.e., soft IP models). However, soft IPs are not<br>
necessarily scannable or mergeable, sometimes resulting in unpredictable<br>
and unmanageable test development.<br>
Turning finally to design verification, a challenge presented by the<br>
use of multiple pre-designed blocks in SOC design is the need for a<br>
reliable and efficient functional verification method. In the available art,<br>
test suites are used to verify a multi-block design. Each test in the suite<br>
is used to test each of the blocks before they are integrated. Then, after<br>
integration of the blocks, significant effort is required to adjust the test<br>
suite to enable functional verification at the system level. The process of<br>
testing and debugging may need to be repeated for a number of iterations<br>
before a final, full system verification can be confidently provided.<br><br>
One available approach to this problem is the substitution of<br>
implementation modules for their corresponding behavioral models,<br>
thereby allowing chip level simulation and testing in a mixed mode<br>
situation. While this approach can offer desirable results if performed<br>
effectively, and can be less costly than the iterative block-based<br>
simulations described above, this approach is still quite expensive and<br>
slow, since the entire chip must be simulated to obtain reliable functional<br>
verification.<br>
An especially acute challenge is presented in multi-block designs by<br>
the need to functionally verify bus structures. In the available art, bus<br>
verification is achieved in either of two ways. The bus may be debugged<br>
and verified as an integral part of the overall chip, or it may be verified<br>
using bus functional models for the pre-defined blocks, taking into<br>
account the detailed implementation provided by newly authored blocks.<br>
However, integral bus verification can be slow and costly. The entire<br>
chip must be used to verify the bus design, and integral bus verification<br>
can only be executed late in the design cycle, when debugging is difficult<br>
and time consuming due to the level of detail and the potential for finding<br>
no bus-related bugs. The bus functional model approach eases some of<br>
these'problems, but requires implementation detail for the newly authored<br>
blocks. Moreover, the bus functional models may be error prone<br>
themselves and may be available only as "black boxes", making signal<br>
tracing and debug difficult or impossible.<br><br>
SUMMARY OF THE INVENTION<br>
To address the shortcomings of the available art, the invention<br>
disclosed in the parent application provides a method and apparatus for<br>
designing a circuit system, the method, comprising the steps of:<br>
(a)	selecting a plurality of pre-designed circuit blocks to be used to<br>
design the circuit system;<br>
(b)	collecting data reflecting the experience of the designer<br>
regarding the pre-designed circuit blocks, the designer's experience being<br>
adaptable to a processing method;<br>
(c)	accepting or rejecting a design of the circuit system in a manner<br>
based on the designer's experience data and acceptable degree of risk;<br>
(d)	upon acceptance, forming block specifications containing<br>
criteria and modified constraints for each of the circuit blocks (FEA);<br>
(e)	upon acceptance, forming block specifications for deploying the<br>
circuit blocks on a floor plan of a chip, in compliance with the criteria and<br>
modified constraints without changing the selected circuit block and the<br>
processing method.<br>
It is an object of the present invention to provide a computer-implemented method<br>
of increasing glue logic distribution efficiency, for execution in an integrated circuit device<br>
design scheme, wherein a device design comprises a plurality of pre-existing design blocks,<br>
the method comprising the steps of copying a selected glue logic element, thereby creating a<br>
duplicate element set having said selected element and its copy; and distributing said<br>
duplicate element set to the plurality of design blocks.<br><br>
BRIEF DESCRIPTION OF THE ACCOMPANYING DRAWINGS<br>
Embodiments of the invention covered by the parent application and this<br>
"divisional" application will now be described, by way of example only with<br>
reference to the accompanying drawings, in which :<br>
FIG. 1 is a flowchart illustrating a design process based on the<br>
block-based design methodology, in accordance with the present<br>
invention;<br>
FIG. 2 is a flowchart illustrating the steps of front-end access, in<br>
accordance with the present invention;<br>
FIG. 3 illustrates a clock-planing module, in accordance with the<br>
present invention;<br>
FIG. 4 illustrates a bus identification and planing module, in<br>
accordance with the present invention;<br>
FIG. 5 illustrates a power-planning module, in accordance with the<br>
present invention;<br>
FIG. 6 illustrates the I/O and analog/mixed-signal requirements, in<br>
accordance with the present invention;<br>
FIG. 7 illustrates a test-planning module, in accordance with the<br>
present invention;<br>
FIG. 8 illustrates a timing and floor-planning module, in accordance<br>
with the present invention;<br>
FIG. 9 shows meta flow of a block design, in accordance with the<br>
present invention;<br>
FIG. 10 illustrates data flow of a chip assembly, in accordance with<br>
the present Invention;<br>
FIG. 11 illustrates task flow of a chip assembly, in accordance with<br>
the present invention; and<br>
FIGS. 12, 13, 14, and 15 illustrate functional verification flow in<br>
accordance with the present invention.<br><br>
FIG. 16 illustrates a methodology to assess feasibility of a circuit<br>
design using a plurality of pre-designed circuit blocks, in accordance with<br>
the present invention.<br>
FIG. 17 illustrates a feasibility assessment result using the<br>
methodology shown in FIG. 2, in accordance with the present invention.<br>
FIG. 18 shows a methodology to assess feasibility of a circuit<br>
design using a plurality of pre-designed circuit blocks, in accordance with<br>
the present invention.<br>
FIG. 19 illustrates a feasibility assessment result using the<br>
methodology shown in FIG. 18, in accordance with the present invention.<br>
FIG. 20 shows an front-end acceptance (TEA") process, in<br>
accordance with the present invention.<br>
FIG. 21 illustrates a refinement process, in accordance with the<br>
present invention.<br>
FIG. 22 shows an exemplary estimate correctness curve, in<br>
accordance with the present invention.<br>
FIG. 23 shows a process of validating an FEA, in accordance the<br>
present invention.<br>
FIG. 24 shows a refined estimate correctness curve using an FEA<br>
design-property refinement process, in accordance with the present<br>
invention.<br>
FIG. 25 shows an FEA data-extraction process, in accordance with<br>
the present invention.<br>
FIG. 26 illustrates a process of identifying the need for block-<br>
estimate refinement, in accordance with the present invention.<br>
FIG. 27 shows an FEA assessment-axes metric, in accordance with<br>
the present invention.<br><br>
FIG, 28 shows a classification collapse curve, in accordance with<br>
the present invention.<br>
FIG. 29 shows a plurality of design blocks in a circuit design,<br>
wherein glue logic interferes with optimal design block placement.<br>
FIG. 30 illustrates a first type of glue logic distribution, in<br>
accordance with the present invention.<br>
FIG. 31 illustrates second and third types of glue logic distribution,<br>
in accordance with the present invention.<br>
FIG. 32 shows a collaring process of embedding a circuit block into<br>
a collar, in accordance with the present invention.<br>
FIG. 33 illustrates creating a complete set of abstracts for a block,<br>
to be used in a design in accordance with the present invention;<br>
FIG. 34 is a flowchart illustrating the collaring process, in<br>
accordance with the present invention.<br>
FIG. 35 shows a collar having two layers, in accordance with the<br>
present invention.<br>
FIG. 36 illustrates the logic view between a collar and a circuit<br>
block, in accordance with the present invention;<br>
FIG. 37 illustrates the physical view between a coiiar and a circuit<br>
block, in accordance with the present invention.<br>
FIG. 38 shows a system design without using the collaring process<br>
of the present invention.<br><br>
FIG. 39 shows a system design using the collaring process of the<br>
present invention.<br>
FIG. 40 shows a computer system for performing the steps in the<br>
collaring process of FIG. 34, in accordance with the present invention.<br>
FIG. 41 illustrates a series of steps comprising the bus<br>
Identification and planning scheme of the present invention;<br>
FIG. 42 illustrates the internal structure of an interconnection<br>
section of a behavioral model constructed according to method of the<br>
present invention.<br>
FIGS. 43-47 and 49-56 are tables illustrating improved delay times<br>
through bus modifications implemented using the system and method of<br>
the present invention.<br>
FIG. 48 illustrates a bus bridge used in the method and system of<br>
the present invention.<br>
 FfG. 57 illustrates a bus bridge used in the method and system of<br>
the present invention.<br>
FIG. 58 illustrates a bus bridge including a FIFO used in the method<br>
and system of the present invention.<br><br>
FIG. 59 is a tabie illustrating bus utilization and latency<br>
characteristics for a variety of bus types.<br>
FIG. 60 illustrates an Exemplary Consistency Check truth table<br>
FIG. 61 illustrates the top-level hierarchy of a chip from the DFT<br>
perspective using the method of the present invention.<br>
FIG. 62 illustrates a design made up of functional blocks and<br>
socket access ports ("SAPs").<br>
FIG. 63 is a table illustrating appropriate test methods for a variety<br>
of design architectures.<br>
FIG. 64 is a flowchart illustrating the top-level architecture<br>
specification procedure for the method and system of the present<br>
invention.<br>
FIG. 65 illustrates a socketization procedure of the method and<br>
system of the present invention.<br>
FIG. 66 illustrates a block level test development procedure of the<br>
method and system of the present invention.<br>
FIG. 67 illustrates a chip level test development procedure of the<br>
method and system of the present invention.<br>
FIG. 68 illustrates a test flow from planning to chip assembly<br>
according to the method and system of the present invention.<br>
FIG. 69 illustrates a designer's view of the front-end acceptance<br>
verification tools of the present invention.<br>
FIG. 70 illustrates a designer's view of moving from chip planning<br>
to block design.<br><br>
FIG. 71 illustrates a designer's view of the evolving bus block<br>
model and test bench generation of the method and system of the<br>
present invention.<br>
FIG. 72 illustrates a designer's view of a block test bench and a<br>
chip test bench.<br>
FIG. 73 is a designer's view of block and chip logical verification<br>
models.<br><br>
DETAILED DESCRIPTION PREFERRED AND<br>
ALTERNATIVE EMBODIMENTS<br>
To overcome the shortcomings of the available an, the present<br>
invention discloses a novel methodology and implementation for block-<br>
based design ("BBD").<br>
Referring to FIG. 1, a flowchart 100 illustrating a design process<br>
based on the block-based design (BSD) methodology in accordance with<br>
the present invention is shown. As shown in FIG. 1, the design process <br>
includes front-end acceptance design stage 102, chip planning design<br>
stage 104, block design stage 106, chip assembly design stage 108, and<br>
verification design stage 110.<br>
Front-end acceptance design stage 102 enables a system<br>
integrator (chip designer) to evaluate the feasibility of a prospective<br>
design project. At front-end acceptance design stage 102, the designer<br>
receives a specification from a customer including functional and other<br>
requirements (such as delivery time and budget) for designing an ASIC.<br>
The customer may also provide some pre-designed circuit blocks and test<br>
benches for these circuit blocks. Along with the customer supplied<br>
blocks, the designer utilizing front end acceptance design stage 102 may<br>
accept, as input, circuit blocks from different sources, some of which<br>
may be supplied by a third party, some of which may be legacy circuit<br>
blocks, and some of which may be newly authored. These selected<br>
circuit blocks can be in a soft, firm, or hard design state. (Note that: soft<br>
state is at RTL level; hard is at GDSII level; and firm is between soft and<br>
hard, such as at gate level or netlist level). Front-end acceptance design<br>
stage 102 then collects the designer's available experiences, including<br><br>
field of use data, estimation data through behavior simulation, and/or<br>
partial implementation data. The process of front-end acceptance design<br>
stage 102 then provides an assessment to help the designer decide<br>
whether to accept the design project based on the design property<br>
parameters, including the customer's requirements, the designer's<br>
available experience , and the designer's acceptable degree of risk.<br>
Furthermore, based on the functional specification, the result of front-end<br>
acceptance design stage 102 dictates the final set of pre-designed circuit<br>
blocks to be used in the circuit design.<br>
Front-end acceptance design stage 102 provides for three phases<br>
of assessment: coarse-grained assessment, medium-grained assessment,<br>
and fine-grained assessment. If an assessment at one phase is not<br>
satisfactory, front-end acceptance design stage 102 enables refinement<br>
of design property parameters and makes a further assessment at the<br>
next phase.<br>
If the proposed design project is found acceptable, front-end<br>
acceptance design stage 102 provides comprehensive steps to ensure<br>
that problems in the design ahead are detected early, and to ensure that<br>
these problems can be solved in a comprehensive manner within the<br>
bounds defined by project requirements, the designer's available<br>
experience, and the processing method selected. Front-end acceptance<br>
design stage 102 generates a design specification defining a processing<br>
methodology including selected pre-designed circuit blocks, design<br>
criteria, and inter-dependant design constraints.<br><br>
Chip planning design stage 104 translates the design specification<br>
from the output of front-end acceptance design stage 102 into block<br>
specifications for each of the selected circuit blocks. Tasks executed in<br>
chip planning design stage 104 include: (1) developing plans for chip<br>
design, assembly, and implementation focused on predictability of delays,<br>
routability, area, power dissipation, and timing, and (2) identifying and<br>
adjusting constraints. Specifically, based on the design criteria and inter-<br>
dependant constraints provided as the output of front-end acceptance<br>
design stage 102, chip planning design stage 104 provides chip planning<br>
within the bounds (such as requirements and constraints) dictated at<br>
front-end acceptance. The inventive chip planning design stage 104<br>
considers one constraint at a time, and yet meets the overall design<br>
criteria as specified by front-end acceptance design stage 102. Chip<br>
planning design stage 104 achieves this by forming the budget for each<br>
of the circuit blocks selected in front-end acceptance design stage 102,<br>
revising the specification for the circuit block, and adjusting constraints<br>
within the processing method specified by front-end acceptance design<br>
stage 102. In contrast to the chip planning design stage of the present<br>
invention, existing methodologies either generate new functional blocks<br>
or change the processing technology to meet the design criteria,<br>
increasing design time and raising project risk. Chip planning design<br>
stage 104 also generates specifications for glue logic (i.e. the hardware<br>
that is required to interconnect the selected circuit blocks), discussed in<br>
further detail below. Chip planning design stage 104 provides as output<br>
three types of glue logic, including new glue logic blocks that occupy one<br>
or more areas in a chip, distributed glue logic distributed into the selected<br>
circuit blocks, and top level block glue logic elements.<br><br>
To seamlessly interconnect the selected circuit blocks, if<br>
necessary, block design stage 106 embeds an interface (called a collar)<br>
around each circuit block to form a standard interface. Since a circuit<br>
block can be soft, firm, or hard, each collar may be soft, firm, or hard as<br>
well. Block design stage 106 output provides that: (1) all circuit blocks in<br>
the chip meet the constraints and budget, and fit into dictated chip<br>
design plans and architectures; (2) chip assembly design stage 108 is<br>
provided with all required models and views of all circuit blocks; (3) the<br>
design is enabled for developing methodologies and flows for authoring<br>
the new circuit blocks generated in the chip planning design stage 104,<br>
adapting legacy circuit blocks, and adapting third party circuit blocks; and<br>
(4) the design fits into given chip architectures and budgets.<br>
Chip assembly design stage 1GB integrates circuit blocks to tape-<br>
out the top-level design for design stage fabrication. Chip assembly<br>
design stage 108 includes the final placement of hard blocks and chip bus<br>
routing, as well as the completion of any global design details. Chip<br>
assembly design stage 108 does not begin until all circuit blocks are<br>
designed, modified, and integrated into the chip plan. Inputs for chip<br>
assembly design stage 108 include power, area, and timing margin<br>
specifications received from the front-end acceptance design stage 102<br>
or chip planning design stage 104.<br>
Verification design stage 110 ensures that the design at each stage<br>
meets the customer functional requirements as detailed in the functional<br>
specification and chip test bench supplied at front-end acceptance design<br>
stage 102. Verification design stage 110 includes functional verification<br>
112, timing verification 114, and physical verification 116.<br><br>
Functional verification step 112 ensures that the logic functions<br>
and chip test benches for the selected circuit blocks at each stage of the<br>
design meet the functional requirements of the customer specification.<br>
Functional verification can be performed during front-end acceptance<br>
design stage 102, chip planning design stage 104, block design stage<br>
106, or chip assembly design stage 108. Timing verification ensures that<br>
signal timing at each stage of the design is appropriate to generate the<br>
logic functions and pass the tests specified in the customer's<br>
specification. Timing verification can be performed during front-end<br>
acceptance design stage 102, chip planning design stage 104, block<br>
design stage 106, or chip assembly design stage 108. Physical<br>
verification ensures that the physical layout for the circuit design meets<br>
the customer specification,<br>
During the design process, front-end acceptance design stage 102,<br>
chip planning design stage 104, block design stage 106, and chip<br>
assembly design stage 108 not only perform their intended functions, but<br>
also generate the information needed for functional verification 112,<br>
timing verification 114, and physical verification 116 which, together,<br>
comprise verification function 110. If any errors occur during verification<br>
at a particular stage of the design process, these errors are preferably<br>
corrected before going to the next stage.<br>
Thus, at chip assembly design stage 108, the design process not<br>
only generates a top-level design for fabricating a chip, but also<br>
completes verifications of chip test benches for each of the circuit blocks<br>
used in the design and the overall chip test bench for the chip.<br><br>
Figures 2-15 will now be described in summary form. Each of<br>
these figures provides a high level description of materials discussed in<br>
greater detail below.<br>
II.00 FRONT END ACCEPTANCE 102<br>
Referring to FIG. 2, flowchart 200 illustrates the steps 210-216 of<br>
front-end acceptance design stage 102, in accordance with the present<br>
invention.<br>
III. CHIP PLANNING 104<br>
Chip planning design stage 104 includes the following modules:<br>
(1)	clock planning;<br>
(2)	bus identification and planning;<br>
(3)	power planning:<br>
(4)	I/O and analog/mixed-signal requirements;<br>
(5)	test planning;<br>
(6)	timing and floor planning; and<br>
(7)	bus verification.<br>
Referring to FIG. 3, there is shown the clock-planning module, in<br>
accordance with the present invention.<br>
'Referring to FIG. 4, there is shown the bus identification and<br>
planing module, in accordance with the present invention.<br>
Referring to FIG. 5, there is shown the power-planning module, in<br>
accordance with the present invention.<br>
Referring to FIG. 6, there is shown the I/O and analog/mixed-signal<br>
requirements, in accordance with the present invention.<br><br>
Referring to FIG. 7, there is shown the test-planning module, in<br>
accordance with the present invention.<br>
Referring to FIG. 8, there is shown the timing and floor-planning<br>
module, in accordance with the present invention.<br>
IV. BLOCK PLANNING 106<br>
Referring to FIG. 9, there is shown the flow of the block design<br>
stage, in accordance with the present invention.<br>
V. CHIP ASSEMBLY 108<br>
Referring to FIG. 10, there is shown the data flow of the chip<br>
assembly design stage, in accordance with the present invention.<br>
Referring to FiG. 11, there is shown the task flow of the chip<br>
assembly design stage, in accordance with the present invention.<br>
VI. VERIFICATION 110<br>
Referring to FIGS. 12, 13, 14, and 15, there is shown the functional<br>
verification flow for the verification design stage of the present invention.<br>
SCALABLE METHODOLOGY FOR FEASIBILITY ASSESSMENT<br>
- Turning first to front-end assessment, FIG. 16 illustrates the<br>
inventive methodology to assess feasibility of a circuit design using a<br>
plurality-of pre-designed circuit blocks, in accordance with the present<br>
invention. .<br>
in FIG. 16, the inputs for the methodology are originally designed<br>
to use field of use data as inputs. However, in assessing a new design<br>
project, new types of inputs 1, 2, and 3 need to be used to assess the<br><br>
feasibility of the new design project. To accommodate the methodology,<br>
the new types of inputs are processed so that the methodology can use<br>
the new types of inputs to perform feasibility assessment for the new<br>
design project.<br>
FIG. 17 shows the feasibility assessment result using the<br>
methodology shown in FIG. 16, in accordance with the present invention.<br>
FIG. 17 indicates risk on the vertical axis and time/cost along the<br>
horizontal axis. According to the risk indicator, the risk of using these<br>
three types of new data increases slightly compared with the risk<br>
presented when only using the field of use data. Also from FIG. 17, it<br>
can be seen that a type 3 input has the greatest impact on risk.<br>
However, according to the time/cost indicator, by using these three types<br>
of new data, the time/cost increases greatly compared with the risk<br>
created by using only field of use data. By considering the ramifications<br>
of the inventive risk v. time/cost calculus indicated in FIG. 17, the pre-<br>
staged blocks are pre-designed and qualified for proper use in the design<br>
methodology. The pre-staged design plan is preferably a section of an<br>
existing methodology, for example, a block-authoring piece.<br>
FIG 18 shows a methodology to assess the feasibility of a circuit<br>
design using a plurality of pre-designed circuit blocks, in accordance with<br>
the present invention. In FIG. 18, the inputs for the methodology are<br>
originally designed to use field of use data as inputs. However, in<br>
assessing a new design project, new types of inputs X, Y, Z need to be<br>
used to assess the feasibility of the new design project. To<br>
accommodate the new input types, the methodology is modified so that<br><br>
the new inputs can be used to perform feasibility assessment for the new<br>
design project.<br>
FIG. 19 illustrates the assessed feasibility obtained using the<br>
inventive methodology shown in FIG. 18, in accordance with the present<br>
invention. FIG. 19 indicates risk along the vertical axis and time/cost<br>
along the horizontal axis. According to the risk indicator, the risk<br>
provided when using the three new input types increases greatly in<br>
comparison with the risk provided when only using field of use data. .<br>
Also from FIG. 19, we can see that a type Z input has the greatest<br>
impact on risk. However, according to the time/cost indicator, the<br>
time/cost provided by additionally using these three types of new inputs<br>
increases moderately comparing with the time/cost by only using the field<br>
of use data.<br>
The new types of inputs can be estimation data or implementation<br>
data for the pre-designed circuits. Based on the results shown in FIGS.<br>
16-19, a system integrator can make tradeoff decisions.<br>
FEASIBILITY ASSESSMENT IN THE FRONT END ACCEPTANCE<br>
The front-end acceptance (FEA) design stage 102 in FIG. 1<br>
involves feasibility and risk assessment of a proposed design. A design is<br>
feasible if the assessed criteria are within allowable risk tolerance.<br>
In a sense, the FEA is a process of design refinement to a point at<br>
which the system integrator can assume the risk of accepting a proposed<br>
design. As such, it is the process of reduction of lack-of-knowledge and,<br>
therefore, error in the requested design's final.outcome. As a starting<br><br>
point, the FEA process receives a set of design requirements delivered by<br>
a customer, the integrator's risk profile for accepting a design, a set of<br>
pre-designed blocks, and the integrator's previous knowledge of and<br>
experience with the pre-designed blocks. The pre-designed blocks can be<br>
at various levels of resolution (hard, soft or firm). The resolution,<br>
previous experience and understanding of a block give rise to a large<br>
range of error-bounds in the prediction of area, power, performance, etc.,<br>
across the blocks.<br>
For each of the blocks, the design refinement may be presented in<br>
three levels of resolution:<br>
(1)	integrator's field of experience (FOE),<br>
(2)	estimation using actual models and tools to execute those<br>
models, and<br>
(3)	dip by taking a block into a higher level of design resolution<br>
than that at which it was received.<br>
It should be noted that three levels of design resolution are arranged in<br>
ascending order as: soft, firm, and hard. Efficiency is achieved by<br>
providing a mechanism to conduct feasibility assessment without<br>
needlessly refining all block and interconnect criteria predictions.<br>
FIG. 20 shows a flow diagram for an FEA process in accordance<br>
with the present invention.<br>
In FIG. 20, the FEA process includes three phases of feasibility<br>
assessment, reflecting the three levels of design refinement discussed<br>
above. These three phases are: coarse-grained assessment, medium-<br>
grained assessment, and fine-grained assessment.<br><br>
Coarse-grained assessment is a field of experience dominated<br>
assessment based upon the design integrator's previous experience with<br>
similar designs. Coarse-grained assessment is especially suited to ten's<br>
of blocks and system design options, and to situations where design<br>
estimation-error tolerance is on the order of fifty percent or more. Coarse<br>
analysis can be used to make a cursory examination of blocks being<br>
considered, where the estimation of interaction between blocks is non-<br>
critical. At this phase, it is most likely that not all blocks being<br>
considered are used in the final design.<br>
Medium-grained assessment is an estimation-dominated<br>
assessment, to estimate by analytic formulation of behavior through<br>
equation or simulation. It is suitable for from two to ten system design<br>
options, and to a situation where acceptable design estimation-error<br>
tolerance is on the order of 20%, and the integrator has an understanding<br>
of how the blocks interact. It can be used to examine the interaction<br>
between blocks critical to operational sufficiency of the design. In this<br>
phase, all blocks in consideration have a high probability of being used in<br>
the final design.<br>
Most refined (fine-grained) assessment is a design-dip-dominated<br>
assessment to make measurements from a refinement of block design.<br>
Dipping is a process in which a new block is transformed into a soft<br>
block, a pre-designed soft block into a firm block, and a pre-defined firm<br>
block into a hard block. Results are generated from either simulation,<br>
emulation or prototyping. Fine-grained assessment is suitable to all or<br>
part of a single-option chip design where acceptable design estimation-<br>
error tolerance is less than 5%, such as during final resolution of critical<br><br>
issues for which existing design refinement is insufficient. It can be used<br>
to examine a subset of chip behaviors or block-interactions which need to<br>
be studied in detail to guarantee sufficiency or to guarantee that<br>
resolution provided by any existing simulation model for the block is<br>
sufficient. It can also be used to examine the failure of the block to meet<br>
design requirements, which will strongly impact final design feasibility. In<br>
this phase, not every block in consideration will be dipped; instead,<br>
substantially only those blocks that have critical impact on the FEA<br>
decision process are dipped.<br>
In FIG. 20, the width of each triangle represents the error in<br>
prediction of the system FEA criteria. At each level of the assessment,<br>
the key is to refine as little as possible the FEA criteria while reducing the<br>
designer's error so that an FEA decision can be made quickly. At each<br>
phase of the FEA process, the basic intent and strategy is the same, as<br>
listed below:<br>
(1)	Gather available information about the blocks under<br>
consideration;<br>
(2)	Identify and refine locally those blocks most likely to impact<br>
system-estimate error;<br>
(3); Assess whether the design meets the FEA constraints. If so,<br>
stop the FEA process; and if not,<br>
(4) Refine globally the block-estimates in the system if FEA<br>
constraints are not met.<br>
A key part of the FEA process illustrated in FIG. 20 is how to<br>
calculate the acceptable global error {or overall error) in the prediction of<br>
system criteria, and identify which few blocks require estimate refinement<br><br>
to bring the global error to within acceptable bounds. This calculation<br>
process requires three parameters:<br>
(1)	Estimate of the acceptable global error for making a decision;<br>
(2)	Estimate of the global error which will result from current<br>
system analysis; and<br>
(3)	The sensitivity of the global error to the error in estimating a<br>
particular block in the design (also referred to as the block-error impact).<br>
The first parameter is defined by the risk-profile of the system<br>
integrator, the constraints supplied by the customer, and a good<br>
prediction of the global error, which will result from basing a system<br>
prediction upon the current state of data. The second and third<br>
parameters are all derived from building accurate Error Impact Curves.<br>
Referring to FIG. 21, there is illustrated the driving of the refinement<br>
process, given the error impact curves, in accordance with the present<br>
invention.<br>
To further define the FEA process, the present invention uses four<br>
basic assessment techniques:<br>
1. FEA Decision Process: Defining Data-in, Data-Out and<br>
the Decision Process based upon Data-Out. (i.e., How<br>
is Data-Out related to the assessment of acceptable<br>
risk?);<br>
2. FEA Data Extraction Process: Moving from a<br>
complete set of Data-in for the abstraction level being<br>
considered to the generation of Data-Out;<br><br>
3. FEA Block-Refinement Identification: Defining a<br>
common mechanism for establishing the System-<br>
Estimation Impact, given the Estimation-Error and '<br>
Block Criticality within a system design. (i.e., Highest<br>
potential impact blocks are refined further if the<br>
acceptance criteria for the Decision Process are not<br>
met); and<br>
4. FEA Assessment-Axes Metrics: Defining the actual<br>
metrics to be used for each of the axes-of-acceptance<br>
associated with FEA. (i.e., defining how the criticality<br>
of a block within a system is defined).<br>
In the method and system of the present invention, a set of<br>
estimate correctness curves are used to validate the FEA process. Each<br>
of the estimate correctness curves is presented over an FEA axes, which<br>
visually provides the elements and criteria for validating the FEA process.<br>
To better explain the function of an estimate correctness curve, the<br>
following elements and criteria are defined. Collectively, these elements<br>
and criteria are referred to as the FEA Axes of Acceptance. These<br>
definitions apply to both blocks and the overall system.<br>
Power	- per mode of operation (e.g., mW)<br>
Performance	- intra-cycle delay (e.g., ps/ns/us)<br>
-	latency (e.g., ns/us/ms)<br>
-	throughput (objects/second - e.g., 50kB/sec)<br><br>
Area	- area including: gates, routing, perimeters, unused<br>
white-space (e.g., mils)<br>
Cost	- Non-recurrent engineering cost (e.g., U.S. $)<br>
-	Cost per Unit (e.g., U.S. $)<br>
Schedule - Resource allocation (e.g., man-years)<br>
-	Deliverable timelines (time)<br>
Risk	- Possibility of error (%)<br>
-	Impact of errors (U.S. $, and/or time)<br>
Before conducting the FEA process, the customer provides the<br>
system integrator with as much of the following information as possible:<br>
(1)	A set of circuit blocks which are either in soft, firm, or hard<br>
format;<br>
(2)	A set of simulators (estimators) or previous-experience<br>
estimates for the blocks, along with error-tolerances for the estimates;<br>
(3)	A set of specifications describing the overall chip functionality<br>
and performance requirements; and<br>
(4)	A set of stipulations regarding acceptable schedule, cost, and<br>
risk for the project.<br>
The customer may also provide:<br>
(5)	Behavioral definitions for any new blocks to be incorporated<br>
into the chip; and<br>
(6)	Identification of known critical issues.<br>
Before conducting the FEA process, the system integrator should:<br><br>
(1) Determine a risk profile by which design suitability is<br>
assessed, including:<br>
a.	Guard-Bands - The integrator's over-design margin for each<br>
of the FEA axes;<br>
b.	Acceptance Risk - Certainty that design will satisfy<br>
requirements prior to accepting a customer request. This is simply<br>
expressed as a standard-deviation measure - the Aσ design-acceptance<br>
risk; and<br>
c. Rejection Risk - Certainty that specified design is unable to<br>
be assembled and fabricated with available blocks. Note that rejection is<br>
actually a risky behavior for the system integrator: the risk being taken is<br>
that the rejected design was actually feasible even though initial<br>
assessment made it appear doubtful. This is also expressed as a<br>
standard-deviation measure - the Rσ design-rejection risk.<br>
(2) Verify that the submitted blocks, in combination with any new<br>
or third party blocks, are sufficient to meet the project constraints within<br>
acceptable limits of risk.<br>
Referring to FIG. 22, an exemplary correctness curve estimate is<br>
shown, in accordance with the present invention. The horizontal axis is<br>
an FEA axis, which can represent any customer constraints or the overall<br>
constraint for the system. To facilitate explanation, assume that the FEA<br>
axis represents power. The vertical axis represents estimate correctness.<br>
According to FIG. 22, the guardband of the power constraint is between<br>
the constraint initially specified by the customer and the constraint<br>
modified by the FEA process. Note that, in the example given, the design<br>
is rejected because the power constraint modified by the guardband lies<br><br>
within the rejection region. This is true even though the power constraint<br>
initially specified is not in the rejection region.<br>
If the modified power constraint had been between the Aσ and Rσ<br>
markers, the FEA refinement process would have proceeded. This<br>
process would continue to reduce the expected error variance (i.e., the<br>
power-error variance, in this example) until an accept or reject decision<br>
can be made based on a refined estimate correctness curve.<br>
Referring to FIG. 23, a process to validate an FEA is shown, in<br>
accordance with the present invention. The inventive FEA validation<br>
process includes four phases:<br>
0. Pre-FOE Phase (not shown):<br>
Obtain the customer design constraints for each of the FEA axes<br>
of acceptance. Modify each of these constraints by the required<br>
guard-band. These modified customer constraints are used only<br>
for verification of the FEA process, and are referred to simply as<br>
the design constraints.<br>
1. FOE Dominant Phase:<br>
The system integrator commences FEA by combining together the<br>
FOE estimates and estimate-error tolerances to determine whether<br>
the required constraints are guaranteed (confidence is higher than<br>
defined by: Aσ for a pass, or Rσ for a fail) to be met.<br>
(a) If, despite consideration of third party blocks, constraints are<br>
still violated, then the design is not possible. The system<br><br>
. integrator must return to the customer with a set of options<br>
and the constraints met by these configurations.<br>
(b)	If the constraints are met to within acceptable risk, the FEA<br>
process is complete.<br>
(c)	If there exists less-than-acceptable confidence of predicting<br>
the passing or failure of the design, then the estimation phase<br>
must commence. To enter the estimation phase, the set of<br>
"most-likely-to-pass" design configurations (i.e., best) must be<br>
selected.<br>
2. Estimation Dominant Phase:<br>
For the set of best designs derived from the FOE stage, an<br>
identification of criticality must be made; i.e., given the error<br>
tolerances on each of the blocks involved, which are statistically<br>
the most likely to validate that the design has passed constraint<br>
validation. This will be a product of both the size of the variance<br>
of the FOE specification prediction for a block, and the impact<br>
that block has upon the design constraint in question.<br>
Estimation should proceed by stubbing-out as much of the non-<br>
critical design as possible, and generating design specific<br>
estimates for that which remains.<br>
(a) Violation: Similar to procedure 1 (a) discussed above.<br><br>
(b) Satisfaction:: If the level of indeterminacy is unlikely to be<br>
reduced further by increasing the accuracy of estimation<br>
(reducing the amount of stubbing will not improve the<br>
estimate in any statistically significant way, due to the fact<br>
that the error-tolerance is dominated by blocks already<br>
included in the estimation), or a full estimate of the SOC<br>
design has been built given existing block models, then the<br>
best design must pass onto the dipping phase.<br>
3. Design-Dip Dominant Phase:<br>
Refine the block estimate to which the global error is most<br>
sensitive, then proceed as per the estimation phase. Continue<br>
iterating this process until the FEA is confirmed or denied. The<br>
definition of statistical criticality is similar.<br>
Referring to FIG. 24, a refined estimate correctness curve using the<br>
inventive FEA design-property refinement process of the present invention<br>
is shown. Through the refinement process of moving from FEA phases 0<br>
to 3, discussed above, the expected error variance on the refined<br>
estimate correctness curve is greatly reduced compared with that of the<br>
estimate correctness curve shown in FIG. 22. Thus, a decision to accept<br>
or reject may be made based on a refined estimate correctness curve, as<br>
shown in FIG. 24, whereas such a decision may or may not be made<br>
based on the estimate correctness curve shown in FIG. 22.<br>
If an FEA decision cannot be made based on the available information<br>
and data at one phase of validation, the present invention performs a<br>
design-property refinement process to reduce the expected error variance.<br>
Based on the refined data and information, the present invention performs<br><br>
the FEA validation at the next phase. The design-property refinement<br>
process comprises the following three aspects:<br>
(1} FEA Data-Extraction Process;<br>
(2)	FEA Block-Refinement Identification; and<br>
(3)	FEA assessment-Axes Metrics.<br>
Referring to FIG. 25, the FEA Data-Extraction Process is shown, in<br>
accordance with the present invention. There is a standardized<br>
mechanism, or process, for establishing an "Estimation of System<br>
Impact" for prediction error associated with each block in a system<br>
design. This mechanism, referred to as Block-Refinement Identification,<br>
enables the required error-boundary on properties (the FEA Design Criteria<br>
-- e.g., power, area, performance, etc.) of any specific block to be<br>
determined for each refinement phase of FEA system-design assessment.<br>
Let L(β) be the limit specified by the customer, as modified by any<br>
required Design Margin, for the design to satisfy FEA Criteria β. Let the<br>
expected value of the design as measured against FEA Criteria p be<br>
E(β). The Design Decision Constraint, or the "maximum error tolerable",<br>
for the design to be defined as pass/fail relative to the FEA Criteria p is<br>
given by: DDC(β) = |L(β) - E(β)| . For an expected "Pass", E(β) itself<br>
must lie within the acceptance region for the FEA Criteria, and for an<br>
expected "Fail" E(β) must lie within the rejection region. Effectively, in<br>
the first case for a "Pass" we require: Aσ system 
case for a "Fail": Rσsystem 
then the system analysis does not produce a decision-quality result.<br>
It should be noted that, in general, the average estimate E(β) is the<br>
final estimate of system-criteria B as produced by the previous phase of<br><br>
system-assessment, i.e., The Medium Grain Assessment stage takes as<br>
the average the final estimate of the Coarse Assessment Stage, the Fine<br>
Grain Assessment Stage takes as the average the final estimate of the<br>
Medium Grain Assessment Stage. To initiate the process, the Coarse<br>
Assessment Stage must be entered by first establishing a coarse-level<br>
expected-value estimate for each of the FEA Criteria.<br>
For the system to be assessed relative to the Design Decision<br>
Constraint (DDC) for a particular FEA Criteria p, a relationship must be<br>
established between the errors associated with block estimates and the<br>
total estimate error for the system. Note that the error associated with a<br>
block estimate is not just the inherent error of estimating the p-criteria for<br>
the block, but also the specific influence of that block and block-error<br>
upon the difficulty of estimating integration cost. The error in estimating<br>
the block is consequently scaled by a system-criticality measure, C,<br>
which is a measure of the difficulty in integrating the block based upon<br>
its properties or lack-or-definition {error) for FEA Criteria p. The<br>
determination as to the Pass (Fail) of the system is established through<br>
the relation of the set of {Cblock.oblock J block s system} to σsystem and the<br>
required inequalities: Aσsystem 
FEA Criteria.<br>
it should also be noted that to keep the inclusion of the criticality<br>
measures Cblock neutral relative the system inequalities expressed above<br>
(i.e, σsystem is formulated from an expression which combines the criticality<br>
scaled block errors: Cblock.σblock), the criticality measures are normalized<br>
such that: ∑blocks(Cblock)2 = 1 . The process for assessing this varies<br><br>
slightly depending upon the class of system-property being assessed.<br>
From the perspective of FEA, there are three classes of system-properties<br>
each described below:<br>
•	Absolute (Block) Constraints (e.g., Intra-Cycle Delay, Throughput)<br>
•	Relative (Block) Constraints (e.g., Power, Area, Latency, Cost,<br>
Schedule)<br>
•	Mixed (Block) Constraints (e.g., Quality)<br>
For simplicity, for an FEA Criteria p define BDC as the Block Design<br>
Constraint where: BDCblock = A.Cblock.σblock in the case of test for design<br>
acceptance, and BDCblock = R.Cblock.σblock in the case of test for design<br>
rejection. Then, for each FEA Criteria:<br>
a. Absolute Constraint: To achieve a decision-quality result each<br>
block, or each block immersed in its immediate environment<br>
(e.g., including routing load, etc.), must pass the DDC for the<br>
Absolute Constraint. Mathematically, achievement of a<br>
decision-quality result on an Absolute Constraint implies:<br>
For all blocks E in the system, BDCblock 
b. Relative Constraints: A decision quality result is achieved if the<br>
square summation of block-design constraints throughout the<br>
system is iess than the square of the DDC. The term relative is<br>
used as the acceptable error of assessment for this constraint<br>
has the flexibility of being partitioned amongst the blocks,<br>
which make up the entire system. Note that some assessment<br>
criteria of the Relative type may have multiple constraints. An<br><br>
example of this is Latency, as there may be several critical<br>
paths, which contribute to a valid assessment of the complete<br>
system. Mathematically, achievement of a decision-quality<br>
■result on a Relative Constraint implies ∑block(BDCblock)2 
 assuming that all block-errors are Gaussian-distributed,<br>
independent random-variables.<br>
c. Mixed Constraints: A mixed constraint is a type that involves<br>
both the relative and absolute types of constraint. For example<br>
Quality is a mixed constraint. No block within a design can<br>
exceed a specified bound on its measure of quality, but the<br>
summation of all quality assessment across the system must<br>
also fall to within a specified range. In this case there is both a<br>
DDCblock for the blocks, as weii as a DDCsystem for the overall<br>
system. Mathematically, for a mixed-constraint system-<br>
property two criteria need to be satisfied:<br>
(i) For All: block ∑ system, BDCblock 
(ii)	∑block(BDCblock)2 
Referring to FIG. 26, there is shown a process of identifying the need<br>
for block-estimate refinement, in accordance with the present invention.<br>
As shown, there are three steps in FEA Block-Refinement Identification,<br>
including:<br><br>
1: For each FEA assessment criteria of the Absolute or Mixed Constraint<br>
type, the level of work required to achieve the absolute error<br>
tolerances (CIC's) is determined. As a by-product of refining a model<br>
to satisfy the need of Absolute Constraints, some error-bounds<br>
associated with Relative Constraints may also be reduced.<br>
2: Based upon the error predicted after the models are refined to satisfy<br>
the Absolute Constraints, and Absolute part of the Mixed Constraint<br>
Type, the remaining system-error tolerance (CIC) for the system are<br>
determined and partitioned amongst the separate IP blocks. The<br>
partitioning will be defined in such a way as to minimize the work<br>
required to build an estimate. The flexibility of this partitioning is<br>
moderated by the defined criticality of contribution for each of the<br>
blocks within the assembled system. This defines the notion of error<br>
impact. Note that this problem must simultaneously optimize<br>
necessary work against acceptable error-tolerance along each FEA<br>
axis.<br>
3: If at any stage system suitability Cannot be determined using the<br>
proposed CIC's, these need to be tightened further and the process<br>
re-iterated either:.<br>
(a)	for the block, if a specific absolute constraint is insufficient,<br>
or<br>
(b)	for the system, if a relative constraint for the chip is<br>
insufficient.<br>
Referring to FIG. 27, there is shown an FEA Assessment-Axes Metric,<br>
containing a table defining the concept of Assessment-Axis Criticality<br>
(AAC), in accordance with the present invention and including, where<br><br>
appropriate, exemplary criticality measures. The AAC relates to Expected<br>
System-Impact (ESI) through Expected Estimation Error (EEE) based upon<br>
the following relation: ESI = AAC * EEE.<br>
As shown in FIG. 27, the table contains five columns, as the<br>
following:<br>
(1)	Assessment Axis FEA is measured based upon these criteria<br>
(2)	Constraint Type Each FEA Assessment Axis may have one<br>
or multiple constraint-types associated<br>
with it<br>
(3)	Constraint Class Class as defined above<br>
(4)	Routing<br>
Refinement	Type of routing-refinement necessary to<br>
ensure that the impact of chip routing is of<br>
the same degree of error as the specified<br>
block and system constraints<br>
(5)	Criticality Measure Standardized way of measuring the<br>
criticality of a property associated with an<br>
FEA Assessment Axis<br>
Some elements of the table make reference to Routing Criticality.<br>
Routing Criticality is defined for any output pin of a block or chip input<br>
pad as Pin Routing Criticality = (Expected Net Length)*(Capacitance/Unit<br>
Length). Block Routing Criticality is the sum of Pin Routing Criticality<br>
across the output pins of a block.<br>
The symbol: ᾳ denotes an effective-routing-area scalar whereby:<br>
ᾳ*(Routing Criticality) translates units and the scale of Routing Criticality<br>
into an area-applicable number.<br><br>
Power consumed as a consequence of routing requires an estimate oi<br>
activity on the lines. This can be done at a block or pin level of<br>
resolution. When applied to the block, the activity estimate is derived<br>
from the average activity on the output lines of the block, denoted: Eblock.<br>
A point connection counts as any fanout point unless several fanout<br>
points are connected by use of a shared bus. A shared bus counts as a<br>
single distinct block. Routing criticality is a measure of the expected<br>
difficulty in routing connections to a pin and, therefore, it is a measure of<br>
FEA uncertainty.<br>
Note that many of the assessment axes might be identified as mixed<br>
constraints at some level of resolution; e.g., an area may be defined as<br>
mixed after initial floor plan is defined and used to partition the SOC<br>
design chip-level constraints into block-level constraints. However, the<br>
dominant constraint type used during the rapid FEA period is listed.<br>
The term Error used in the table refers to the bound on error as<br>
relates to the property in question.<br>
Organizing the Field of Experience Data<br>
Designer experience is a crucial part in the system-decision process of<br>
the BBD methodology. The BBD methodology extends the concept of<br>
experience associated with a single key designer or architect to the<br>
concept of "company design experience". This general "pool" of<br>
experience is referred to as the BBD Field of Experience (FOE) of the<br>
present invention.<br><br>
It is the purpose of BBD method to propose four concepts and<br>
mechanisms for the building and use of FOE. These concepts are:<br>
a)	Data Gathering - Definition of rigorous processes for obtaining and<br>
initiating FOE data.<br>
b)	Data Classification - Information classification and mechanisms for<br>
developing relevant classifications. Such classification guarantees<br>
that gathered data may be statistically analyzed, extrapolated, and<br>
globally refined as the amount of accumulated design-knowledge<br>
increases.<br>
c)	Data Certification - Definition of a process that builds the correct<br>
assurance of "trust" in what might otherwise be referred to as "rule-<br>
of-thumb" numbers. Certifying FOE data will guarantee that<br>
estimates built from the FOE database are statistically well bounded.<br>
d)	Data Application - The mechanism for application of FOE to the<br>
design process. This is a part of Front End Acceptance for BBD.<br>
Field of Experience Definition<br>
In BBD, Field of Experience can be defined as compiled data from<br>
measurement of prior designs classified according to design styles, design<br>
purpose, and critical measurements of design characteristics. Critical<br>
characteristics may include: area, throughput, power and latency. The<br>
definition of Experience-Based Estimation is systematic prediction based<br>
upon experience with similar designs or design behaviors. It follows that<br>
the definition of FOE Estimation is Experience-Based Estimation using FOE<br>
data.<br>
It should be noted that this is distinct from BBD Estimation in that<br>
it does not imply the specific analysis of the design in question, or --<br><br>
where the hardware design is actually known from previous exposure --<br>
specific analysis of a new behavior requested of that hardware. For<br>
example, a DSP core may have been developed within a company and an<br>
FIR-Filter embedded routine run upon it in a previous instantiation of the<br>
core. It may then be requested that feasibility of an FFT algorithm<br>
running on that same core be considered. If that first rule-of-thumb is<br>
based solely upon the previous algorithmic efficiency observed when<br>
executing the FIR operation upon the design, but without entering into<br>
the details highly specific to the FFT algorithm, then this is an FOE<br>
estimate.<br>
Field of Experience must explicitly draw upon information derived<br>
during a set of previous design projects. FOE data must be able to be<br>
catalogued, stored and accessed through a standard database.<br>
There are three different classes of experience-based data used in<br>
design, each form of data being associated with a specific error profile:<br>
a) Project Data - Designer-requested estimate at project time. The<br>
designer does not draw upon the experience of others as logged in<br>
the FOE database, but more upon his own uncatalogued design<br>
experience. Error in the design estimate is given by a Designer-Error<br>
Variance, which has been observed for general designs. Designer-<br>
Error Variance is built from measuring a general history of designers'<br>
ability to accurately predict results.<br>
b) Predicted Data - Within a design classification but without a specific<br>
project in mind, a designer is requested to give his best-guess<br>
parameter-relationships for extending existing FOE data. In this case,<br><br>
the FOE data being extended may consist of as little as a single<br>
design-point. Error for this.is in part specified by the designer's best<br>
guess at the parameterization error, but also modified by the history<br>
of designers' ability to accurately predict results. Assuming statistical<br>
independence, these error variances would be summed.<br>
C) Collated Data - Collected, classified and parameterized data from a<br>
set of design experiences. There is a possibility of measurement error<br>
directly associated with this data, but this is likely to be minor. The<br>
main error is defined as the difference between measured results and<br>
those predicted by the variation of data-parameters.<br>
Note the Project Data is not a form of FOE data as it provides no<br>
mechanism to extend the current estimates to future designs.<br>
Furthermore, as Project Data is gathered at the commencement of a<br>
project, not the completion, it is not verifiable against catalogued design<br>
experience. This implies that it is not certified. Any data gathered from<br>
Final Measurement of the design may be entered into the FOE database,<br>
and the accuracy of the Project Data versus Final Measurement be used<br>
to refine Designer Error Variance for the company.<br>
Predicted Data are referred to as FOE seed-data. Predicted Data may<br>
be immediately applied to FOE estimation on like designs.<br>
A common classification of the types of data received must apply to<br>
both of the above sources of FOE data. Such common classification<br>
permits the quick identification and cataloging of received data. Initial<br>
classification-specification is regarded as the planning stage for FOE, and<br>
the entering/gathering of data is the building stage. As the amount of<br><br>
information in the FOE database grows, the refinement process is applied<br>
to reduce error tolerances to within those being observed statistically. In<br>
parallel with all three of these stages is the FOE certification process.<br>
The parameters listed above are used to extrapolate from existing,<br>
general FOE data to derive project-specific FOE estimates. Such a<br>
relationship between extrapolated estimates and FOE data is preferably<br>
defined for each design classification. Each parameter FOE relationship<br>
may be defined by a designer's personal experience (see Predicted Data<br>
above), or may be empirically specified through curve-fitting the FOE data<br>
if sufficient information is available. Parameters might include such<br>
technical variables as pipeline depth, degree of parallelism, bit-width, and<br>
clocking-speed.<br>
It should be noted that FOE applies not only to design blocks, but also<br>
to the interconnect between the blocks. In such cases, FOE may be<br>
specified as the cost of routing between blocks of one classification and<br>
blocks of another. Like the application to blocks, FOE estimates for<br>
interconnect may also be parameterized.<br>
Estimating with Maximum Accuracy:<br>
A key aspect of FOE is the generation of estimates of maximum<br>
accuracy given the data provided. This is a twofold process:<br>
a) Refinement - As mentioned above, refinement is the process of<br>
reducing the error-of-estimate to within that being observed<br>
statistically. That is, when the amount of FOE data in a specific<br>
category is small, the error tolerance for-the data is large. This is not<br>
due to an inherent error, but rather to the unknown (or untested)<br><br>
applicability of the parameterized data to other specific designs. As<br>
the number of examined designs increases, the statistical spread of<br>
data can be measured directly against parameterized predictions.<br>
When a large number of cases are catalogued for a specific<br>
classification of design, then the accuracy of the narameterization<br>
method will be well established. Identification of large correlated<br>
error fas opposed to random spread of data) could motivate the re-<br>
thinking of the parameter relationships.<br>
b) Classification Collapse - The different classifications of designs may<br>
be related by proximity to one another. For example, the Butterfly<br>
FFT implementation may be one classification of design, but all FFT<br>
blocks may be regarded as closely proximal to this design. If the<br>
number of data associated with a particular classification of interest is<br>
too small to be statistically significant, then close proximity FOE data<br>
may be collapsed together to reduce the overall estimation error. The<br>
collapsing of classifications together will itself induce an error due to<br>
the slight difference in design types, but the statistical improvement<br>
in terms of number of designs considered may overwhelm this<br>
difference-error. It is preferable to compute a curve such as that<br>
shown in FIG. 28, and from that pick the configuration of best error.<br>
The process/use model for FOE is therefore as follows:<br>
I.	Choose Block Classifications applicable to block being assessed<br>
II.	Does enough data exist for that classification? (i.e., is the<br>
Expected Error sufficient?)<br>
Yes - Return the best FOE estimate and END<br>
No - Proceed<br><br>
III.	Collapse categories of close proximity until estimate error ceases<br>
to improve<br>
IV.	Is the Expected Error sufficient for FOE estimation?<br>
Yes - Return the best FOE estimate and END<br>
No - Proceed<br>
V. Ask the designer to generate his best guess for the design. (This<br>
may be a dip into the Estimation Phase of BBD.)<br>
FOE Certifying<br>
Certification of FOE is the process by which the FOE information<br>
gathered is shown to be reliable. This certification process will establish<br>
the error of estimation during the Building and Refinement stages.<br>
There are two aspects of certification:<br>
a)	Certification of Completeness - ail FEA metrics must be measurable<br>
through the parameterization schemes provided.<br>
b)	Certification of Accuracy - including experience measures for<br>
designer, and the definition of process to ensure accuracy of collected<br>
data;<br>
Glue Logic<br>
The present invention further discloses an improved glue logic<br>
distribution and reduction methodology. The combination of three<br>
alternative glue logic distribution mechanisms comprises a preferred<br>
embodiment of the present invention. First, glue logic that is not<br>
incorporated into predesigned blocks can be duplicated into multiple<br><br>
copies for. distribution to the existing blocks. Second, logic that has no<br>
affinity to a block at the top level can be left as small blocks, optimally<br>
placed to minimize effective gate monopolization, wiring congestion, and<br>
floorplanning impact. Third, where the number of blocks exceeds the<br>
block place and route limitations, glue logic may be clustered into glue<br>
cluster blocks until the block count is reduced to an acceptable level.<br>
Referring to FIG. 29, there is illustrated a circuit design view<br>
wherein glue logic 2910 resides disadvantageously between<br>
interconnected blocks, thereby rendering inefficient the use of significant<br>
areas of silicon real estate and creating significant wiring congestion.<br>
Referring to FIG. 30, we will begin with a description of the<br>
present method for creating multiple copies of glue logic for distribution<br>
to larger top-level blocks. If an element 3010 has output nets driving<br>
multiple loads, the element is split into multiple elements 3012, each<br>
having only a single load on the output. In turn, each input "cone" (not<br>
shown) driving the duplicated element is copied as well, until all block<br>
outputs are reached. Similarly, large input gates are reduced to trees of<br>
non-inverting two-input gates, with a two-input gate of the original<br>
function at the top of the tree. In this way, substantially more logic is<br>
dedicated to the previously much smaller glue logic function. However,<br>
by removing glue logic from the areas between the larger blocks, the<br>
larger blocks can be more efficiently placed, resulting in a net efficiency<br>
increase.<br>
Any glue logic element that cannot be effectively duplicated for<br>
distribution is then preferably merged into a larger block having the<br>
closest affinity to the placed element. Glue logic merger is executed in a<br><br>
manner based on a number of criteria, the most significant of which is<br>
whether the merger reduces the number of top-level pin-outs, thus,<br>
when multiple copies are created, since most of the resulting logic is<br>
comprised of two-input gates, merging such gates into blocks wherein<br>
one pin is connected to the block reduces the pin count by two. When<br>
two or more blocks are equal candidates for merger, the block having the<br>
lowest pin density is preferably chosen. Finally, the lowest priority<br>
preferably goes to timing considerations.<br>
Next, referring to FIG. 31, gates and small blocks 3110 that cannot<br>
be merged are clustered into clusters 3112. Gates that cannot be<br>
merged most likely have multiple loads on both their input and output<br>
nets. By recombining gates with inputs having similar function, gate<br>
count can be reduced.<br>
The present invention further discloses a method to convert pre-<br>
designed circuit blocks into circuits having standardized interfaces.<br>
The tasks performed in the block design stage 106 in FIG. 1<br>
include: (1) creating any missing abstracts for the selected circuit blocks,<br>
(2) embedding the circuit blocks into their respective standardized<br>
interfaces known as collars, and (3) creating a complete set of abstracts<br>
for the collared circuit blocks.<br>
Referring to FIG. 32, a collaring process of embedding a circuit<br>
block into a collar is shown, in accordance with the present invention.<br>
In the BBD methodology, selected circuit blocks are the primary<br>
input components at the chip-level. The collaring process places a collar<br><br>
around each of the circuit blocks to create a standard interface around<br>
the boundary of the circuit block. To successfully integrate coilared<br>
blocks into the chip-level, a complete set of abstracts has to be created<br>
for the collared blocks. Before creating the complete set of abstracts for<br>
the collared blocks, the system of the present invention first forms any<br>
missing abstracts for the selected blocks, where abstracts are models or<br>
views of the block, or collared block designs required by chip-level<br>
assembly or planning tools. Exemplary abstracts include :<br>
(1)	Static Timing Abstraction - TLF<br>
(2)	Layout Blockage File - LEF<br>
(3)	Models for Verification - Bolted-Bus-Block model<br>
(4)	Block layout constraints to the system<br>
Referring to FIG. 33, creating a complete set of abstracts of a<br>
circuit block is illustrated, in accordance with the present invention, while<br>
FIG. 34 illustrates a combination of the features illustrated in FIGS. 32<br>
and 33.<br>
We will move next to a description of the collaring process,<br>
wherein it is assumed that a standard interface has been defined for each<br>
type of the blocks to be used in design.<br>
At a first step, the process checks whether each of the blocks has<br>
a completed block abstraction. If any of the blocks does not have a<br>
complete block abstraction, the process forms a complete block<br>
abstraction for the block.<br><br>
Next, the process identifies a block type for each of the blocks.<br>
Specifically, a block can be: a memory type, a processor type, a power<br>
type, or an analog/mixed signal type. However, a type of circuit blocks<br>
from different sources may have different interfaces that require different<br>
designs to connect other circuit blocks. For example, the processors<br>
designed by different vendors may have different interfaces and bus<br>
structure.<br>
Next, the process associates the identified block with its respective<br>
interface standard.<br>
Thereafter, the process creates a first collar portion containing the<br>
components connectable to the specific interface of the identified block.<br>
At a next step, the process creates a second collar portion in<br>
compliance with the standard interface associated with the identified<br>
circuit block.<br>
The process then creates a third collar portion containing the<br>
components for converting the specific interface into a format<br>
connectable to the standard interface and connecting the first collar<br>
portion with the second collar portion.<br>
A block collar can be comprised of multiple "layers. Currently, two<br>
collar iayers (a block standard collar and a system-specific collar) have<br>
been defined for BBD and SOC, respectively. Referring to FIG. 35, a<br>
collar containing two layers is shown, one collar being standard for a<br>
particular block, and the other being specific to the particular system in<br>
which the block is to be deployed. The block standard collar contains<br>
those interface components that can be defined without the knowledge<br><br>
of the specific system or the specific context in which it is being<br>
integrated. For example, in the context of BBD, a particular design group<br>
may decide that a JTAG-standard test interface is required in a design.<br>
Thus, for all blocks to be used in any of the systems being designed, a<br>
JTAG test interface is a standard and, thus, belongs in the block standard<br>
collar. The system-specific collar (or adaptation collar) contains interface<br>
components which belongs to the block, but are system or context<br>
specific. For example, the standard set for data lines may not require a<br>
parity bit, but for a particular system being designed a parity bit is<br>
required on all data lines. The logic to generate the parity bit is<br>
associated with the block during chip planning and should reside in the<br>
system-specific collar.<br>
Another distinction between the two collar layers in BBD is that the<br>
block standard collar can be put on prior to front end acceptance and chip<br>
planning (chip planning may require that an initial collar is designed as<br>
part of a dipping process to better perform the chip planning functions<br>
required), but the system-specific collar can only be added after chip<br>
planning.<br>
A more subtle difference between the two collar types is that the<br>
standards set for the block standard collar may be much narrower in<br>
scope than the standards set in SOC. For example, a certain power<br>
interface can be a standard for BBD, but only for a particular company,<br>
and the other companies do not need to conform to that standard power<br>
interface for the block. Consequently, the blocks from outside of the<br>
company need a system-specific collar, which converts the standard<br>
power interface to the company one. This is contrasted with SOC, where<br><br>
an industry-wide power interface standard exists and resides in the block<br>
standard collar. The ultimate goaf in SOC is to create a standard collar<br>
that is an industry-wide standard. A block that has such a collar can be<br>
called a socketized block. In the future, if all the aspects of the collar are<br>
industry-wide, there will be no need for an additional layering of system-<br>
specific collar, thus bringing the block closer to the ideal of plug-and-play.<br>
Another dimension to the system-specific collar is that, although it<br>
is intended to be designed after chip planning, one can speed up the chip<br>
integration process by making a system-specific collar in chip planning,<br>
wherein the parameters for capturing the ranges that the system-specific<br>
collar will have to be targeted. This speeds up the integration process<br>
since, after chip planning, only the parameters need to be varied while<br>
the system-specific collar does not have to be re-designed from scratch.<br>
The collars and blocks can be in various combinations of soft, firm,<br>
and hard. Just as there are advantages and disadvantages as to the<br>
hardness of a block, there are advantages and disadvantages to<br>
combinations of softness, firmness, and hardness of the collars. For<br>
example, if the block itself is soft, it may be suitable to leave the block<br>
standard collar soft so that when the system-specific collar is added, the<br>
entire block can be synthesized, placed and routed flat for the final<br>
conversion to layout. Whereas if a block is hard, it may be suitable to<br>
use a hard block standard collar to handle predominately physical<br>
interface issues with only a small amount of standard functional changes,<br>
since a soft system-specific collar to handle the system-specific issues<br>
mostly involves functional changes.<br><br>
A collar transforms a block-specific interface into a standard<br>
interface in the following ways:<br>
(1)	transforming the physical configurations specific to the block<br>
into standard physical configurations, including pin layer, pin location, and<br>
pin separation;<br>
(2)	transforming the power supply specific to the block into a<br>
standard power supply, including power loading and power physical<br>
location;<br>
(3)	transforming the test process specific to the block into a<br>
standard test process, including test access port (TAP) controller and test<br>
protocol;<br>
(4)	transforming the timing specific to the block into a standard<br>
timing, including setup and hold time, flip-flop, or latch;<br>
(5)	transforming the clock ports specific to the block into standard<br>
clock ports, including the loading of each of the clock ports;<br>
(6)	transforming data/control signals specific to the block into<br>
standard data/control signals, including standardizing signal<br>
positive/negative assertion; and<br>
(7)	transforming the bus interface specific to the block into a<br>
standard bus interface, by adding registers for blocks expecting valid<br>
input on all cycles, big-endian or little-endian {a big-endian has the 0 bit<br>
on the left end of the data unit; a little-endian's is on the right), and<br>
converting bit width.<br>
In addition, a collar may contain components (glue logic, as<br>
described above) for performing extra functions for a collared block. Glue<br>
can exist in three levels: (1) the glue deployed into a collar, (2) the glue<br>
combined at chip-level, and (3) the glue deployed in one or more mini-<br><br>
blocks at chip-level. Specifically, glue logic can include anything from<br>
simple functional translators (e.g., NAND gates along each of the bit<br>
lines) to more complicated functions (e.g., registers, accumulators, etc.).<br>
Although glue logic can be of arbitrary size, if the glue size becomes<br>
significant relative to the block, estimates made during front-end<br>
assembly and chip planning may become inaccurate because glue size<br>
was not considered. A constraint may need to put on the relative size of<br>
the glue to the block.<br>
A set of assumptions are used in the collaring process, as follows:<br>
(1)	The decision of whether or not to add glue logic is made in chip<br>
planning;<br>
(2)	Of the three types of glue logic (glue put into collars;<br>
combination glue at chip level; glue put in mini-blocks at chip level), the<br>
collaring process preferably only addresses glue put into collars;<br>
(3)	Aspect ratio issues are handled during synthesis (not in block<br>
collaring); and<br>
(4)	For BBD, the output of a collared block is layout.<br>
Referring to FIG. 36, a logic view between a collar 602 and a block<br>
604 is shown, illustrating some exemplary functions of a collar discussed<br>
above in accordance with the present invention.<br>
As shown in FIG. 36, the collar 602 includes three portions<br>
performing three different functions. The first portion contains .<br>
components that is connectable to the specific interface around the<br>
boundary of the block 604. The second portion contains the input output<br>
components in compliance with a standard, and the third portion contains<br>
components to convert the outputs from block 604 into the standard.<br><br>
Specifically, in collar 602, the bus interface 606 combines two<br>
one-directional buses 608 and 610 into a bi-directional bus 612. Test<br>
Access Port 614 is connected to input 616 to collect the information<br>
from and perform testing on block 604. The gate 618 inverts the<br>
incoming signal to a format suitable for block 604, as received by gates<br>
619, and gates 620-624 perform clock buffering.<br>
Referring to FIG. 37, a physical view between a collar 702 and a<br>
block 704 is shown, illustrating some exemplary functions of a collar<br>
discussed above in accordance with the present invention. In FIG. 37,<br>
collar 702 and block 704 both contain multiple metal layers. A power<br>
standard exists for deploying the Vdd voltage on metal layer 3 (M3) and<br>
GND on metal layer 4 (M4). If block 704 does not comply with the<br>
power standard, collar 702 converts the power to comply. The region<br>
706 sets a pin spacing/layer standard. If block 704 does not comply with<br>
the pin spacing/layer standard, collar 702 converts it to comply with the<br>
pin spacing/layer standard. Collar 702 also contains glue 708 in a hard<br>
state.<br>
Referring next to FIG. 39, a system design 800 is shown without<br>
using the collaring process of the present invention. As shown in FIG.<br>
38, the system design 800 is composed of four circuit blocks A, B, C,<br>
and D. Each arrow line connected to a block represents a constraint to<br>
design an interface for that block. Thus, if a system is composed of n<br>
circuit blocks (n = 4 in this example), the interface for any particular block<br>
may need to satisfy up to n-1 sets of constraints. Therefore, the total<br>
number of constraints that need to be satisfied for all blocks is 0(n2).<br><br>
Referring to FIG. 40, a system design 900 is shown using the<br>
collaring process of the present invention. System design 900 is<br>
composed of four circuit blocks A, B, C, and D. Each arrow line<br>
connected to a block represents a constraint to design an interface for<br>
that block. Using the collaring process of the present invention, each<br>
block needs only to satisfy one set of constraints defined by the collaring<br>
interface. Thus, if a system is composed of n circuit blocks (n = 4 in this<br>
example), the total number of constraints that need to be satisfied for all<br>
blocks is 0(n).<br>
Referring to FIG. 38, a computer system 1000 for performing the<br>
steps for collaring and the other inventive BBD processes discussed<br>
herein is shown in accordance with the present invention. The computer<br>
system 1000 includes a system bus 1001, a processing unit 1002, a<br>
memory device 1004, a disk drive interface 1006, a hard disk 1008, a<br>
display interface 1010, a display monitor 1012, a serial bus interface<br>
1014, a mouse 1016, and a keyboard 1018.<br>
The hard disk 1008 is coupled to the disk drive interface 1006; the<br>
monitor display 1012 is coupled to the display interface 1010; and the<br>
mouse 1016 and keyboard 1018 are coupled to the serial bus interface<br>
1014. Coupled to the system bus 1001 are the processing unit 1002,<br>
the memory device 1004, the disk drive interface 1006, and the display<br>
interface 1010.<br>
Memory device 1004 stores data and programs. Operating<br>
together with the disk drive interface 1006, the hard disk 1008 also<br>
stores data and programs. However, memory device 1004 has faster -<br><br>
access speed than hard disk 1008, while the hard disk 1008 normally has<br>
higher capacity than memory device 1004.<br>
Operating together with the display interface 1010, the display<br>
monitor 1012 provides visual interfaces between the programs executed<br>
and users, and displays the outputs generated by the programs.<br>
Operating together with the serial bus interface 1014, the mouse 1016<br>
and keyboard 1018 provide inputs to the computer system 1000.<br>
The processing unit 1002, which may include more than one<br>
processor, controls the operations of the computer system 1000 by<br>
executing the programs stored in the memory device 1004 and hard disk<br>
1008. The processing unit also controls the transmissions of data and<br>
programs between the memory device 1004 and the hard disk 1008.<br>
In the present invention, the programs for performing the steps<br>
discussed herein can be stored in memory device 1004 or hard disk<br>
1008, and executed by the processing unit 1002, as will be understood<br>
by those skilled in the art to which the present invention pertains.<br>
Bus Identification and Planning<br>
The methodology of the present invention also provides for<br>
meeting the performance requirements of the overall design of the "system<br>
desired by the end user or design team, as defined during front end<br>
acceptance (described above). While performance dictates the primary<br>
consideration for the design methodology of the present invention, a<br>
secondary consideration is reducing the gate count during bus type<br>
selection, since bus size can vary between available bus types such that<br><br>
a large, simple bus consumes more logic than a smaller, more complex<br>
one. <br>
Turning first to FIG.41, there is illustrated a series of steps<br>
comprising the method of the present invention. At step 4110, Front-End<br>
Acceptance of the customer's initial specification is completed. This step<br>
has been described in detail above. Next, at step 4112, predefined bus<br>
requirements are analyzed, as explained below. At step 4114, bus<br>
clustering is planned while variables including latency, bandwidth,<br>
direction, and existing interfaces for each of the blocks are analyzed as<br>
well, making reference at step 4116 to a bus taxonomy reference library.<br>
Next, at step 4118, new bus specifications are developed and at step<br>
4120 the new specifications are verified, including generation of a<br>
compliance suite and bus model verification substep. Steps 4118 and<br>
4120 are performed with reference to block prestaging step 4122,<br>
wherein new block specifications covering arbiters and bridges are<br>
created, block specifications, including collars, are modified, glue<br>
specifications are defined and testbenches are created.<br>
We will begin with a discussion of bus planning, including<br>
translating front-end specifications into top-level bus specifications. In<br>
the available art, system designers start with a high-level functional<br>
model or specification of the system being designed. Using system<br>
expertise and knowledge of similar systems, the designer constructs a<br>
high-level diagram of the bus structure for the design. The designer<br>
usually has a rough idea of the traffic on each of the buses, and can<br>
estimate how many buses and of what complexity are needed. Buses are<br>
designed to meet required system performance while minimizing interface<br><br>
logic and design effort. Designers then use this architecture to create a<br>
bus functional model to verify that the design operates as defined in the<br>
specification. This traditional process has been difficult to quantify<br>
because results vary with the expertise and past experience of the<br>
designer. The tasks defined herein apply a formal structure to the process<br>
of defining bus structures in chip design. However, these tasks require at<br>
least the average level of skill in the relevant bus and system<br>
development arts to achieve the best results.<br>
Bus Protocols<br>
Buses provide the preferred communication medium between<br>
circuit blocks in a design. A bus, in its simplest form, can be a collection<br>
of point-to-point connections that require little logic but many wires. A<br>
simple bus transfers data between blocks at every clock cycle. While<br>
some blocks might require this type of information transfer, most blocks<br>
in a system need information from other blocks only occasionally. And<br>
since chip pins are very expensive in large system designs, buses are<br>
normally used to reduce the number of chip pins needed and to allow<br>
periodic communication between many different blocks in a system with<br>
little loss in performance. To do this, designers must add logic to each of<br>
the blocks to keep track of data transfer scheduling issues, such as:<br>
which block can use the bus wires; what block the data is being sent to;<br>
when the sender sends the data; and whether the receiver gets the data.<br>
These issues are handled by control signals on the bus and the<br>
establishment of a procedure for controlling communication between<br>
blocks (the bus protocol).<br><br>
Two examples of bus protocol are the peripheral bus and the<br>
packet network. In a simple peripheral bus protocol, one device controls<br>
the bus. All information and data flows through this device, which<br>
decides, one case at a time, which block will send or receive data.<br>
Although peripheral bus processing requires relatively little logic, it does<br>
not use bus wires efficiently, and is not very flexible. Packet network<br>
protocols are relatively complex. All the information about which block<br>
sent the data and which block must receive it is stored with the data in a<br>
packet. Packet protocols let any block send data to any other block at<br>
any time. This protocol is very flexible and uses the bus wires efficiently,<br>
but each block needs a lot of logic to know when to send packets and<br>
decipher the packets it receives.. Other bus protocols have different<br>
levels of flexibility, utilization, and latency {initial delay in transferring<br>
information from one block to another on the bus). A taxonomy for<br>
different bus types and their protocols is provided in FIG. 59.<br>
The BBD bus design methodology of the present invention<br>
preferably uses defined bus types. The designer is not expected to<br>
develop buses from scratch unless they are part of an authored block.<br>
Also, the designer preferably logically connects blocks to existing,<br>
well-defined bus types rather than creating complex buses. The BBD<br>
methodology of the present invention therefore treats buses as signal<br>
connections between blocks. The logic for the bus is preferably<br>
distributed among the blocks in the design, as is the glue logic for<br>
allowing the buses to communicate outside the buses, as described<br>
herein above in the glue logic section.<br><br>
All logical interconnect is treated as either simple or complex<br>
buses. Simple forms of interconnection are defined by the bus<br>
connection rules, but a specific protocol for complex buses is preferably<br>
not defined. The BBD methodology of the present invention preferably<br>
supports buses that: have hierarchy; are completely contained within<br>
blocks; have wires external to blocks; are completely contained within<br>
one level of logical hierarchy; are completely contained within one level of<br>
physical hierarchy; are compliant with VSI's on-chip bus (OCB) attributes<br>
specification; and are verified with compliance transaction vectors. Also,<br>
many of the out-of-scope conditions for BBD are preferably supported in .<br>
SOC methodologies under the present invention.<br>
Buses are preferably either completely contained within blocks or<br>
defined as interconnect at the top hierarchy level. Buses that are defined<br>
at the top level are created at that level, allowing bus components to be<br>
distributed among and within the blocks.<br>
To define buses for a BBD chip, the following steps are executed,<br>
each of which will be described in detail below:<br>
Extract Bus Requirements<br>
- . Define Buses Based on Clustering<br>
Select Buses<br>
Specify the Bus Design<br>
Reference the Bus Taxonomy<br>
Verify Bus Selection<br>
Block Design Assumptions<br>
In the BBD methodology, when the designer specifies the bus<br>
design, he or she must connect to block structures. This task assumes<br><br>
that if a firm or hard block contains a specific bus interface, that interface<br>
is soft,as defined above with reference to collars. It also assumes that<br>
blocks of all types contain a simplified interface between the bus<br>
interface logic and the actual function of the block. This is not an<br>
unreasonable assumption for peripheral blocks because many third-party<br>
block providers have created their own simple interface so users can add<br>
bus interface logic. Blocks that are tailored to multiple designs have<br>
separate internal functions and bus interface logic. The internal interface<br>
allows one to reuse these blocks with different buses. When a hard block<br>
has specific bus interface logic that cannot be separated from its internal<br>
function, a more complex bus protocol translation must be added to the<br>
block. In either case, the resulting bus interface logic becomes part of<br>
the soft collar created during block design.<br>
Extracting Bus Requirements<br>
Data received from the front-end acceptance task includes the bus<br>
nets, signal nets, and pins on each of the blocks. There are four<br>
categories of signal nets: 1) predefined bus signals, which are block pins<br>
and nets comprising a bus, such as a PCI or AMBA bus, required by<br>
certain blocks such as processors; 2) bus signals, which are block pins<br>
and nets that must be buses, such as Read and Write signals; 3) possible<br>
bus signals, which are block pins and nets that might be wires or buses;<br>
and 4} signals, which are wire nets and are not dealt with by buses<br>
When the designer has determined the signal types, data received<br>
from the front-end acceptance task is organized according to these four<br>
types of signal nets. For type 1 and 2 nets, the data necessary to create<br>
a bus must either be provided by the customer or otherwise available.<br><br>
The required data is further defined in VSI's On-Chip Bus (OCB) Attributes<br>
Specification OCB1 1.0, which is incorporated herein by reference.<br>
In additional, each bus that is specified or might be used in the<br>
design must have: a complete user's guide sufficient to create the bus;<br>
an implementation guide that defines the physical requirements for the<br>
bus; a complete set of simulation tools to test and verify the bus; and a<br>
list of technical attributes and how the bus compares with the list. Also,<br>
to create buses that comply with the VSI's On-Chip Bus Attributes<br>
Specification, vendors must provide the documentation and models<br>
described below.<br>
User's Guide and Simulation Tools<br>
The user's guide and simulation tools are used in bus design to<br>
build and test bus components. The set of simulation tools includes<br>
models written in behavioral Verilog and/or VHDL for the following<br>
elements: bus master; bus slave; bus support functions (arbiter, address<br>
decoder); and standard bus bridges. These are used to verify the bus, as<br>
described herein in the section related to bus verification.<br>
Implementation Guide<br>
The implementation guide is used in block design, chip assembly,<br>
and subsequent tasks in chip design planning to describe the attributes of<br>
the buses. The following information is passed to block design as part of<br>
the block specifications: special cells required; physical properties of the<br>
cells; bus multiplexing or steering options; memory map; power<br>
distribution; and timing guidelines. Timing and maximum loading<br>
guidelines are also used in subsequent steps in chip design planning.<br><br>
Timing guidelines, maximum loading, and restrictions on bus layout or<br>
wiring are passed to the chip assembly task for use in bus<br>
implementation.<br>
Technical Attributes List<br>
The technical attributes must be translated into a form that can be<br>
maintained as bus attributes in the bus taxonomy reference library. The<br>
bus taxonomy reference and the bus type table are therefore used by the<br>
designer to choose the bus types. For predefined bus signals, the<br>
designer checks to insure that the required connections can meet the<br>
maximum loading and timing guidelines, and that bus layout and wiring<br>
restrictions can be met during chip assembly.. If not, the design is sent<br>
back to the front-end acceptance task to be modified by the customer.<br>
Defining Buses Based on Clustering<br>
To define buses based on clustering, the designer uses the<br>
interconnect bandwidths and latencies received at front-end acceptance.<br>
This step determines, for each of the clusters and blocks within the<br>
clusters, the latency, bandwidth, existing bus interface types, and<br>
direction of data flow. This information is then passed to the next step,<br>
selecting buses.<br>
A bus hierarchy is defined by clustering the highest bandwidth and<br>
lowest latency bus interconnect. Possible bus signals that are<br>
point-to-point nets can be eliminated from this and subsequent bus<br>
analysis and design, since these signals are provided directly to the chip<br>
assembly task for routing.<br><br>
Create the Communication Manager Behavioral Model<br>
The behavioral model of the chip as verified contains behavioral<br>
models and an abstract model of the interconnect between blocks.<br>
Typically, this interconnect is a software mechanism that transfers data<br>
among the test bench and blocks. Ideally, it is a form of communication<br>
manager, possibly a scheduler, to which all the blocks are connected. At<br>
the other extreme, the interconnect may also be a directly connected<br>
point-to-point interface in the behavioral model.<br>
The communication manager or, as referred to hereafter, the<br>
scheduler, is usually at the top level of the simulation module.<br>
Pseudocode for such a scheduler might look like this:<br>
While queue is not empty Do,<br>
Get next transaction from queue;<br>
Get target block from transaction;<br>
Call Target Block(transaction);<br>
End;<br>
In this pseudocode example, each block does the following:<br>
Target Block (transaction);<br>
Do block's function;<br>
Add new transactions to the queue;<br>
- End;<br>
At this code level, neither timing or bus size are defined. All"<br>
communication is done in transactions or by transferring information<br>
packets of any size. The transactions might include possible bus signals<br>
and non-bus wires so that all communication between blocks goes<br>
through the scheduler.<br><br>
Alternatively, the designer may modify the block pseudocode to<br>
send and read the non-bus signals asynchronously. In this case, each<br>
block does the following:<br>
Target Block (transaction);<br>
Get non-bus signal values from top level;<br>
Do block's function;<br>
Add new transactions to the queue;<br>
Apply new non-bus signal values to top level;<br>
End<br>
It should be noted that, for the sake of simplicity, these examples<br>
do not include non-bus signals. However, the designer can make similar<br>
adjustments to the examples that follow to include non-bus signals.<br>
A pattern set is a collection of vectors in a test bench that force<br>
one block to communicate with another block. The test bench must<br>
include enough pattern sets to execute the functionality of the entire<br>
chip. The designer must assign target performance levels to each of the<br>
pattern sets at a coarse level. For example, if there is frame data for an<br>
MPEG decoder in one pattern set, the designer must be able to define<br>
how long the target hardware takes to process the frames in that set. If<br>
the designer knows that the output rate must be about 30 frames per<br>
second the processing rate must exceed that number. These<br>
performance targets are used in the subsequent stages of this process to<br>
define the required bus bandwidths.<br>
The blocks selected for the chip must have some cycle-<br>
approximate performance specifications. If the behavioral models do not<br>
already have these specifications, they should be incorporated into the<br>
model in this step.<br><br>
Figure 42 illustrates the internal structure of the interconnect<br>
section of the behavioral model. First, the test bench and requirements<br>
are received. Next, the preliminary scheduler is created. Interconnect<br>
manager/scheduler 4210 transfers information between the blocks in the<br>
design and schedules their execution. Interconnect 4210 is then<br>
modified, and modified interconnect manager 4212 includes statistics<br>
gathering and a delay matrix that is added as the model is adjusted to<br>
cycle-approximate operation. Finally, the test bench is again utilized for<br>
testing and design iteration. The details of these modifications are<br>
described in the sections that follow.<br>
Modify the Model to Account for Latency<br>
Some designs have no specific latency requirement. Other designs,<br>
such as hubs and switches, are sensitive to data latency (the length of<br>
time it takes the first unit of data to go from the sender to the receiver).<br>
Most network devices, especially asynchronous transfer mode (ATM)<br>
devices, have specific latency requirements for information transfer,<br>
which translates into tight latency requirements for the components<br>
within the networks and for the buses. Once the designer knows the<br>
latency requirements for the design, he or she adjusts the interconnect<br>
model as follows. First two matrixes are created for each pattern set that<br>
specify 1) the amount of data to be transferred between blocks, and 2)<br>
the number of transactions executed. Second, a matrix is created for<br>
each pattern set that specifies cycle count approximations. This second<br>
step is not necessary for designs with no latency requirements.<br>
Data Transfer Matrix<br><br>
To create a data transfer matrix, the designer first adds the amount<br>
of data that is being transferred from one block to another to the<br>
communications manager model. Next, using a spreadsheet tool, the<br>
designer accumulate this data in a table for each pattern set.<br>
For example, the table for a chip with three blocks and a test<br>
bench would be a 4x4 from/to table with the sum of all data transferred,<br>
in bytes, in each entry in the table. The diagonal would be all zeros. It<br>
should be noted that a more practical model takes into consideration the<br>
buses going into and out of the chip, so the test bench would probably<br>
have more than one entry on each axis.<br>
An example of a data transfer matrix is illustrated in the table of<br>
FIG. 43. The design behind this matrix has three blocks and three ports<br>
for the test bench: an interface to external memory, a PCI interface, and<br>
a parallel I/O interface. As shown in the table, the data transferred from<br>
Block 1 to Block 2 is 10,000 bytes, and the data transferred from Block 2<br>
to Block 1 is 8,000 bytes.<br>
Thus, the first step in creating a data transfer matrix is to create a<br>
table, with a count of all transactions, as illustrated in FIG. 44, showing<br>
transactions for exemplary Pattern Set X.<br>
To create the tables illustrated in FIGS. 43 and 44, the designer<br>
may modify the scheduler pseudocode as follows:<br>
While queue is not empty Do;<br>
Get next transaction from queue;<br>
Get sender block from transactions;<br>
Get target block from transaction;<br>
Get Transaction byte count;<br><br>
Transactions Matrix (sender,target)<br>
= Transactions Matrix(sender,target) +<br>
Transactions Matrix (sender,target)<br>
= Transactions Matrix(sender,target)<br>
+ Transaction byte count;<br>
Call Target Block(transaction);<br>
End;<br>
Because non-bus block-to-block wires have some delay (typically, at least<br>
one clock cycle), these are preferably added as separate transactions in<br>
the timing queue, in addition to the bus transactions.<br>
Latency Matrix<br>
Since the clock cycle time for each block has already been defined<br>
at front-end acceptance, the designer can then translate raw performance<br>
into cycle counts as follows:<br>
1. To reflect the cycle-approximate operation defined in their<br>
specifications, the designer adds the estimated clock cycles for<br>
each biock to its existing behavioral model. This step is preferably<br>
executed before sending the block to the block design task, but<br>
after verification.<br>
. .2. :The designer integrates the blocks back into the chip model.<br>
The chip model will then have cycle-approximate blocks with no<br>
time defined in the interconnect.<br>
3. The designer uses a spreadsheet to set up a table similar to that<br>
illustrated in FIGS. 43 and 44. Instead of the number of bytes<br>
transferred, the designer specifies the number of cycles each<br>
transfer takes, from the time the data is available to the time the<br>
data arrives at the next block or test bench (latency).<br><br>
4. The designer modifies the interconnect model to use the<br>
performance values illustrated in the new table.<br>
Figure 45 illustrates an exemplary latency matrix. A pseudo code<br>
example of these modifications is shown below:<br>
While queue is not empty Do,<br>
Get next transaction from queue;<br>
Get time from transaction;<br>
Get target block from transaction;<br>
Call Target Block(transaction, time);<br>
End;<br>
Where each block does the following:<br>
Target B(ock(transaction,time);<br>
Do block's function;<br>
Set Transaction times to time + delay + Latency(this block,<br>
target);<br>
Sort new transactions to the queue;<br>
End<br>
it should be noted that the entries that read "0" in FIG. 44 indicate that<br>
no data is transferred and as such are not applicable to the latency<br>
matrix.<br>
5.	The designer modifies the test bench to include the chip latency<br>
requirements with estimated interconnect cycle count delays using<br>
knowledge of the design data flow.<br>
6.	The designer simulates the design to see if it meets the cycle<br>
requirements.<br><br>
7. The designer modifies the latency matrix, and repeats the<br>
verification process until the cycle requirements of the chip are<br>
met.<br>
To create a table with the maximum cycle counts available for each<br>
type of bus transfer, the designer should use large cycle counts to begin<br>
with and reduce them until the specifications are met, since tighter<br>
latency requirements translate into more gate-intensive bus interconnect<br>
schemes.<br>
Determine the Cluster Measure<br>
Next, to reflect the natural clustering of the data, the designer<br>
reorganizes the data transfer matrix by moving the largest counts closest<br>
to the center diagonal. There are a number of ways to perform this<br>
process; the preferred method is referred to herein as pivoting. The<br>
purpose of pivoting is to cluster blocks with the highest transfer rates to<br>
minimize the number of pins required. The designer may set up a<br>
spreadsheet to do the calculations automatically.<br>
To measure how effective clustering is, each site in the data<br>
transfer matrix must be accurately weighted. This example uses a<br>
distance matrix, illustrated in FIG. 46, to weight the sites. In the table of<br>
FIG. 46, each cell contains the square of the distance that cell is from the<br>
diagonal. Other measures to weight the data transfer matrix sites may be<br>
used, however, the square of the distance is preferred since it has been<br>
shown, in placement algorithms, to converge quickly while allowing some<br>
mobility of elements in the system, which higher-order measures restrict.<br><br>
Next, the designer multiplies each cell in the data transfer matrix<br>
by its corresponding cell in the distance matrix and adds all the values for<br>
all the cells together. The result is the cluster measure. The cluster<br>
measure of the matrix in the table of FIG. 43 is 428,200. The lower the<br>
cluster measure, the more effective the bus clustering.<br>
Pivot Blocks<br>
To try to get a lower cluster measure, the designer should pivot the<br>
data transfer matrix by swapping rows one by one and recalculating the<br>
cluster measure after every swap to see if the cluster measure improves.<br>
One can swap rows by performing a sort, where the sites are elements in<br>
a list to be sorted, as illustrated in pseudocode below:<br>
Get Current cluster measure of matrix;<br>
Do for Current site = site 1 to n-l in the matrix;<br>
Do for Next site = Current site +1 to n in the matrix;<br>
Swap Next site with Current site;<br>
Get Next cluster measure of matrix;<br>
 If Next cluster measure &gt; Current cluster measure<br>
Then Swap Next site with Current site back to<br>
originaf location.<br>
Else<br>
Current cluster measure = Next cluster<br>
measure;<br>
End<br>
End;<br>
This sort is similar to a quadratic placement algorithm, although the<br>
interconnect is bandwidth instead of connections. The designer can use<br>
other methods that provide similar results instead of this one.<br>
Pivoting as illustrated above preferably produces, for example, the<br>
matrix of FIG. 47, with an improved cluster measure of 117,000. It<br>
should be noted that, in this idealized example, components do not create<br><br>
information. Components write what they read, so the column and row<br>
totals match, except for block 3 and the PIO. This may not be the case<br>
for use in the field.<br>
The designer can then use a table like that illustrated in FIG. 47 to<br>
define the bus clusters. This example shows a high rate of data transfer<br>
between block 1, block 2, the PCI, and memory. These components must<br>
therefore be on a high-speed bus. Because there is a low data transfer<br>
rate between block 3 and the PIO, these design elements can be on a<br>
low-speed bus.<br>
The PIO is output-only, but all the other components are<br>
bidirectional. Because the components inside and outside the clusters<br>
must communicate, the designer must create a bridge between the two<br>
buses, as illustrated in FIG. 48.<br>
Defining Buses Based On Clustering<br>
Initial clustering preferably must include ail predefined bus signal<br>
nets. The designer can pivot within the clusters to show the natural<br>
internal subclusters, but, unless more than one bus type is defined for<br>
these signals, they should be treated as one cluster in the next task.<br>
Where a processor's system and peripheral buses are defined, the<br>
clusters are broken into a system bus and a peripheral bus or buses,<br>
based on the clustering information. For example if the bus matrix in the<br>
table of FIG. 47 is composed of predefined bus signal nets, the initial<br>
clustering contains the whole matrix. If more than one bus is defined, the<br>
blocks that need to be on a high-speed bus form one bus and the rest<br>
form another bus. This partition is then passed to the next task.<br><br>
If there are no predefined bus connections, buses are defined in a<br>
manner based upon the cluster information. The pivoted matrix usually<br>
has groups of adjacent blocks with relatively high levels of<br>
communication between them compared to other adjacent blocks. The<br>
table in FIG. 49 illustrates this kind of clustering, similar to the previous<br>
pivoted matrix. Figure 49 is based upon a different example from those<br>
previously shown, to make the clustering process clearer. It should be<br>
noted that "##" represents a large number.<br>
In this example, blocks A, B, and C form one independent bus<br>
cluster because there is a high rate of communication among the three<br>
blocks and there is no communication between these blocks and blocks D<br>
through H. Blocks D, E, and F form another cluster because there is a<br>
high rate of communication between all three. Also, blocks D, E, and F<br>
could form two separate buses: a point-to-point bus between D and E,<br>
and another between E and F. Blocks G and H form a third cluster. There<br>
are lower-bandwidth connections between the EF pair and the GH pair.<br>
Depending on the amount of data transfer, E, F, G, and H might be on<br>
one bus or on two separate EF and GH buses with a bidirectional bridge<br>
between them for lower-level communication.<br>
 To choose from a number of different clustering options, the<br>
following guidelines are followed:<br>
1. Identify the cut points between blocks to determine possible<br>
clusters. A cut point a high communication area from a relatively low<br>
communication area. A cut between C and D in the matrix in FIG. 49<br>
produces the diagram illustrated in FIG. 50. To determine the amount of<br>
communication between the ABC and DEFGH groups, the cells in the<br><br>
lower left and upper right groups are summed. If this sum is 0, which is<br>
the case in this example, the two groups have no communication<br>
between them. These groups form completely separate buses. Cut the<br>
pivoted matrix where the resulting communication across the cut is 0.<br>
2. Within each of the identified groups, find the significant cuts.<br>
The communication between the resulting groups should be much less<br>
than within each group. In FIG. 50, one cut appears in the D-H group and<br>
no cuts appear in the A-C group, as shown in FIG. 51. The data transfer<br>
rate between the GH groups is 22, but the data transfer rate within the<br>
other groups is a very large number (##). These clusters can form two<br>
buses with a bridge between them.<br>
3. If the communication between clusters or within clusters does<br>
not involve all blocks, you might need to optimize the clustering. It is<br>
only important to optimize if the latency matrix has very different<br>
requirements for communication between certain blocks. For example,<br>
FIG. 51 shows that the GH cluster does not communicate with DE. DE<br>
and EF communicate but D and F do not. If the latency requirements for<br>
DE are very tight, the designer should therefore split out the DE<br>
communication from the rest of the bus. From FIG. 52, we can see the<br>
resulting matrix. This example splits E into E and E' so it appears to be<br>
two separate blocks, because separate interfaces will be created on E for<br>
the two buses. If a block has two or more bus interfaces, this technique<br>
may be used to make effective use of the separate interfaces.<br>
If this technique is used on the original example of FIG. 43, the<br>
clusters illustrated in FIG. 53 are created, comprising two buses with a<br>
bridge between them. One bus transfers a significant amount of data<br><br>
while the other transfers very little. Another cut between Block 3 and PIO<br>
would result in even lower communication between the clusters.<br>
However, this is not a significant cut because it-leaves only one block in a<br>
cluster, so it is not made.<br>
4. When all the cuts are made, the resulting cluster information is<br>
passed on to the next task.<br>
This clustering technique requires system knowledge to generate a<br>
bus structure for the chip. The designer must consider data timing and<br>
implementation details such as existing block bus interfaces, additional<br>
processor requirements, and the number of masters on the bus. These<br>
factors might suggest that deviating from the structure obtained using<br>
this clustering method creates a bus structure with better performance or<br>
lower gate count than the one obtained by purely following the<br>
procedure. If so, the designer might want to repeat this task to modify<br>
the clustering results.<br>
Selecting Buses<br>
Once the designer has defined buses using the clustering method,<br>
bus types and performance hierarchy must be selected. Bus hierarchy is<br>
the order of buses that are interconnected from the highest-performance<br>
bus down to the lowest. For example, if a design contains a high-speed<br>
system bus and two lower-speed peripheral buses, the hierarchy is from<br>
the system bus to the two peripheral buses.<br>
The bus attributes and sizes from the bus taxonomy reference<br>
library are preferably used to define the bus type for each bus. The<br>
library lists a set of bus attributes for each of the available bus types. To<br><br>
select the appropriate bus, the designer analyzes each block in the cluster<br>
for existing bus interfaces. If there are none or few, the bus type in the<br>
bus taxonomy reference that has the most similar attributes is selected.<br>
The result of this selection process is a defined set of buses and hierarchy<br>
that is used in the next task, specifying the bus design.<br>
Buses should be selected as follows, checking the parameters in<br>
the bus taxonomy reference library and the interfaces of the blocks in the<br>
design:<br>
1.	Eliminate buses that do not meet the cluster's bandwidth and<br>
latency<br>
requirements;<br>
2.	If the bus is already defined, use that bus, but otherwise;<br>
3.	If a processor is present, use the system bus to which it already<br>
connects, otherwise;<br>
4.	Select a bus to which most blocks already connect;<br>
5.	Use a bus that can handle the endian-ness (a big-endian has the<br>
0 bit on the left end of the data unit; a little-endian's is on the right) of<br>
most blocks to which it is connected;<br>
6.	If the loading on the bus is excessive, use multiple buses;<br>
 7: Separate lower bandwidth devices onto a peripheral bus or<br>
buses;<br>
8.	Use a peripheral bus with an existing bridge to the selected<br>
system bus;<br>
9.	If there is more than one choice after the selection process is<br>
complete, choose the bus type that best meets the OCB attributes list,<br>
since it will have the most tool and model support.<br><br>
Calculate the Bus Size'<br>
The bus latency table are used as the starting point for this step.<br>
Once specific bus. configurations are identified using clustering, the<br>
information must be translated into a form usable to determine the size of<br>
the buses. In the matrix from the previous task's example, the first four<br>
entries are clustered in one group and the last two are clustered into a<br>
second group.<br>
Calculating the bus sizes requires determining the bandwidth<br>
needed for the amount of data being transferred and calculating<br>
bandwidth, substituting different bus width values until the target<br>
bandwidth is approached as closely as possible.<br>
Determine the Target Bandwidth<br>
Determining the target bandwidth needed for the buses in a pattern<br>
set requires the following steps:<br>
1. Add all the transactions that occur in each cluster in the pivoted<br>
data transfer matrix. Continuing with the same example, there are<br>
62,600 in the large cluster, 100 in the small cluster, and 1,200 between<br>
the clusters. The matrix in FIG. 55 is therefore created by adding the<br>
entries in each of the four groups of FIG. 54.<br>
2. Determine the time this pattern set is expected to take. The<br>
front-end acceptance task provides this information. For this example, the<br>
pattern set must be transferred in one millisecond, that is, the fast cluster<br>
must transfer 63,800 bytes of data — 1,200 bytes to the bridge and<br>
62,600 bytes internal to the bus — in 1 ms. Bandwidth is defined as the<br><br>
amount of data, in bits, that can be transferred in one second. In this<br>
example, we can transfer 510 Kbits in 1 ms, and the bandwidth is<br>
approximately 510 MHz.<br>
Calculate the Bus Width<br>
Bandwidth is comprised of the number of wires in the bus (bus<br>
width) times the clock frequency at which the data is being transferred.<br>
The calculation is as follows:<br>
(util / clockcycle) X bus_width = bandwidth<br>
where:<br>
util	is the minimum bus utilization percentage for the bus<br>
type selected (see FIG. 59);<br>
c!ock_ cycle, is the clock cycle for the design; and<br>
bus_width is the number of wires in the bus. This value must be<br>
a power of 2;<br>
To: calculate, we start at 21 for the bus_ width and keep<br>
substituting higher values (22, 23, ... ) until the resulting bandwidth value<br>
is greater than the target bandwidth. For example, if the clock cycle is 20<br>
ns and the bus utilization is 25%, the number of wires rounded to the<br>
nearest power of 2 is 64 bits, where<br>
(25%/20 ns) * 26 = 800 MHz &gt; 510 MHz.<br><br>
In this example, if one selected a type 4 or 5 bus from the table in<br>
FIG. 59 one would need at least 64 bits in the bus for the fast cluster.<br>
Similarly, a 20 ns cycle time would need only 8 bits for the slower<br>
cluster.<br>
The latency information is partially a function of the utilization,<br>
since increased utilization of a bus increases latency. To keep the<br>
example simple, such complexity is not included; it is partially accounted<br>
for in the utilization numbers. In general, however, if one uses the<br>
minimum bus utilization numbers for the bandwidth calculation, the<br>
latency tends toward the minimum as well. To account for this effect, the<br>
designer should select the worst-case (smallest) latency requirement from<br>
the cluster.<br>
The designer can therefore derive the latency of the entire<br>
transaction from the latency matrix used in simulation, but the table of<br>
FIG. 59 shows the bus latency data and transfer values as separate<br>
numbers. FIG. 59 shows a maximum transfer latency of 10 for a type 4<br>
bus. The minimum data latency is closer to the number of cycles required<br>
for the data alone. The designer therefore needs to calculate what the net<br>
transfer latency is by subtracting the data transfer time from the numbers<br>
in the latency matrix, illustrated below:<br>
data_tr.ansfer_time = min_cycles / num_words * avg_trans<br>
where:<br>
min_cycles is the minimum number of data latency cycles for this<br>
bus type;<br>
num_words is the number of words in the bus; and<br><br>
avg_trans is the average transaction size: the number of bytes of<br>
data from the data transfer matrix (FIG. 43) divided by<br>
the number of transactions in the transaction matrix<br>
(FIG. 44).<br>
To compare the latency from the table, the designer must create a<br>
new latency matrix that uses the latency values from the simulation<br>
matrix minus the transaction's data latency. In the example above this<br>
table would be as illustrated in FIG, 56. Each element in this matrix is <br>
calculated as follows: [Resulting Latency(x,y) - Min Bus Latency data<br>
(type)l * (Data Transfer(x,y) / [Transaction(x,y) * bus size])<br>
The smallest number in the system bus cluster is 25. This value<br>
must be larger than the largest transfer latency for the type of bus<br>
needed because of bandwidth. That number is 10 in the table of FIG. 59<br>
for transfer latency for bus type 4, so the designer can choose bus type 4<br>
or better for the fast cluster.<br>
Create the Bus Hierarchy<br>
Once the designer has identified the buses and their loads, the bus<br>
performance hierarchy must be identified, comprising determining which<br>
are high-speed buses, which are low-speed buses, and what bridges and<br>
arbiters are required. If two buses are connected in the reduced bus<br>
matrix (their from/to cells have non-zero values), then we create a bridge<br>
between them. Using the example in FIG. 54, we create the following bus<br>
model from the pivoted data matrix and the reduced bus matrix:<br>
A system bus (type 4 or 5) of 64 bits connected to:<br>
Block 1 (RNV)<br><br>
Block 2 (RNV)<br>
Memory (RNV)<br>
PCI (RNV)<br>
A bridge (RNV) to a peripheral bus (type 3 or better) of 8 bits<br>
connected to:<br>
Block 3 (R/W)<br>
PIO (Write only)<br>
Note: The PIO is write-only because there is no data<br>
coming from it. The bridge is read/write because both<br>
diagonals between bus 1 and 2 are non-zero.<br>
This map is then passed to the next task, specifying the bus design.<br>
Specify the Bus Design<br>
To specify the bus design, the designer expands the created buses<br>
into a set of interface specifications for the original blocks, a set of new<br>
blocks, such as bridges and arbiters, and a set of glue logic. The original<br>
and new block specifications are passed to the block design task. The<br>
glue logic, as mini-blocks, are transferred through block design to the chip<br>
assembly task. If a bus meets the OCB attributes specification, it has<br>
models/for master and slave devices, as well as other bus objects such as<br>
arbiters and bridges. Using the map defined selecting buses, the designer<br>
then creates the detailed bus structure.<br>
Detailed Bus Structure<br>
To create the detailed bus structure, the designer should then:<br>
1. Optimize the bus by eliminating all buses with a single load and<br>
a bridge. The load should be placed on the other side of the bridge, since<br><br>
it is slower and more costly in terms of gates to translate between the<br>
protocol of the system bus and the peripheral bus for only one load.<br>
While the designer may not be able to entirely eliminate the bridge logic,<br>
tristate interface can be eliminated since the bus reduces to a<br>
point-to-point communication. Also, 8 bits can be turned into 16 without<br>
much penalty, since the two ends can be placed together.<br>
2. Assign bus master and slaves to the various loads. The designer<br>
should start with the bridge. It is a master on the slower side and a slave<br>
on the faster side. All devices on peripheral buses are slave devices. On<br>
the system bus, master and slave are defined by which devices need to<br>
control the bus. Knowledge of the design can help with this decision. If a<br>
processor is connected to the bus, its interface is a master. Otherwise, if<br>
there are no obvious masters, the external interface, such as the PCI, is a<br>
master. The memory interface is almost always a slave interface. To<br>
determine which block requires a master interface, the designer should<br>
refer to the interconnect requirements for the bus.<br>
3. If a processor or other block is connected to a bus that also has<br>
a memory interface, and the block specifically requires it, the designer<br>
should include one or more direct memory access (DMA) devices on the<br>
bus. These devices act as bus masters.<br>
4. Finally, if two or more devices on a bus are bus masters, add an<br>
arbiter.<br>
Detailed Bus Design<br>
When the bus structure has been defined, the block bus interface is<br>
checked. If blocks already have bus interfaces, the interfaces must be in<br><br>
a soft, firm, or parameterized form for tailoring to the bus. If this is the<br>
case, the existing bus interface logic should be used, otherwise the<br>
models provided with the bus are acceptable. If there is a different bus<br>
interface on the blocks, it should be eliminated if possible.<br>
The bus logic should be modified to interface with the bus as follows:<br>
1. Assign address spaces for each of the interfaces. The address<br>
space is usually designed to match the upper bits of the transaction<br>
address to determine if this block is being addressed. Also, one should<br>
ensure that each block has sufficient address space for the internal<br>
storage or operational codes used in the block.<br>
2. Eliminate write or read buffers if only one function is used.<br>
Most existing bus interfaces are designed to both read and write. The<br>
designer can significantly reduce the logic if only one of these functions is<br>
needed. For example, if the bus takes more than one clock cycle, read<br>
and write data are usually buffered separately. If only one function is<br>
needed, the designer can eliminate half the register bits.<br>
3. Expand or contract the design to meet the defined bus size.<br>
Most bus interfaces are designed for the standard 32- or 64-bit bus, but<br>
other alternatives are available. If the designer needs a non-standard bus<br>
interface, he or she must modify the logic to eliminate or add registers<br>
and signal lines. Similarly, the address is usually the same size as the<br>
data, but this might not be the case. For busses that interleave the<br>
address and data onto the same bus signals, a mismatch in data and<br>
address size only eliminates the upper-order address decode or data<br>
register logic, not the signals.<br><br>
 4. Add buffers to the bridges if necessary. Such modifications<br>
should be made for both sides of the bridge as in Step 3.<br>
5. Modify the bridge size mapping between the buses. For a<br>
read/write interface, bridges need at least one register for each function,<br>
equal to the larger of the buses on both sides. In addition to the data<br>
buffer for each function, bursts of data can be transferred more<br>
efficiently if the data is accepted by the bridge before being transferred to<br>
the next bus, using, for example, the bridge illustrated in FIG. 57. This<br>
might require a FIFO for each function to store a burst and forward it to<br>
the next bus, as illustrated in the bridge of FIG. 58.<br>
6. Define the priority of the bus masters and the type of<br>
arbitration. If there is more than one master on a bus, there must be<br>
some kind of arbitration between the masters. There are many types of<br>
arbitration, ranging from a strict ordered priority to round-robin arbitration.<br>
If the masters both handle the same amount of data with a similar<br>
number of transactions and required latency, they should have equal<br>
priority. On the other hand, if there is a clear ranking in the importance of<br>
the masters, with an equivalent order in the amount of data, transactions,<br>
and latency, arbitration should be serialized, putting the most critical<br>
master first.<br>
7. Create and connect the arbiter based on the definitions in Step<br>
5. Arbitration schemes can be distributed or centralized, depending on<br>
the bus. Arbitration logic should be as distributed as possible, to enabled<br>
it to be distributed into the blocks with the glue logic.<br><br>
8. Map the bus to the interface logic as required by the device's<br>
endian-ness. Most buses are little-endian, but some devices are<br>
big-endian. When there is a mismatch between the end types, the<br>
designer must decide how to swap the bytes of data from the bus. This<br>
decision is generally context-dependent. If all transactions to and from<br>
the bus are of the same type of data, the designer may use fixed<br>
byte-swapping, otherwise the bus masters must do the swapping.<br>
9.	Tailor the DMA devices to the bus. Direct memory access<br>
devices are controllers that transfer data from one block to another. They<br>
should be modified to the size of the address bus as one would any other<br>
device.<br>
10.	Add testability ports and interfaces if necessary. The lowest<br>
level of test is the ability to test the bus itself. The standard chip test<br>
logic can also use the bus. These test features might require additional<br>
signals to differentiate test from the normal operation mode.<br>
11.	Add initialization parameters if necessary. Some buses such as<br>
PCI have configuration registers. These registers might be hardcoded for<br>
configurations that do not change.<br>
12.	Add optional bus capabilities if required by the devices on the<br>
bus. Some buses have advanced capabilities such as threads, split<br>
transactions, and error retry, which may not need to be implemented if<br>
the devices connected to the bus do not need them. Some of the<br>
additional capabilities, such as DMA devices, non-contiguous burst<br><br>
transfers, and error recovery control, might require more signals than are<br>
defined in the standard bus. These signals should be added to the bus if<br>
necessary.<br>
When these modifications are complete, the bus interface logic is<br>
connected to the resulting interface of the block.<br>
Bus Taxonomy Reference<br>
The bus taxonomy reference is a library that lists the bus attributes<br>
and their relationship to bandwidth, latency, and data direction for the<br>
buses that are available in a cell library. The taxonomy library is a<br>
relatively fixed collection of information. The person in charge of this<br>
library might need to update the bus attributes when a new bus becomes<br>
available.<br>
Bus Type Reference<br>
Bus types can be categorized by latency and bandwidth utilization.<br>
Pure bandwidth is a function of the number of wires in the bus times the<br>
clock frequency at which the data is being transferred, but bandwidth<br>
utilization is a function of architecture.<br>
" Figure 59 shows a list of specific bus attributes from lowest<br>
bandwidth utilization and longest latency to the highest bandwidth<br>
utilization and shortest latency. Typically the cost in logic and wires is<br>
smallest with the first and largest with the last. Each bus in the library<br>
must have a bus type assigned from this table. Each bus type can have a<br>
range of latency in cycles and bus bandwidth in utilization percentage.<br>
Each bus might have a different clock cycle time and size, so the<br>
utilization percentage is the effective throughput over the product of the<br><br>
cycle time times the size of the bus. A bus utilization value of 100%<br>
means that every cycle is fully utilized. The Data Latency column gives<br>
the number of cycles it takes for a bus to transfer a word of data. The<br>
Transfer Latency column is the average number of cycles it takes to begin<br>
a bus transaction. The table in FIG. 59 gives a rough estimate of the bus<br>
utilization and latency values. A designer's group can specify values<br>
based on experience and the type of its designs.<br>
Bus Taxonomy Reference<br>
Over a number of projects, a design group accumulates a library of<br>
buses. Each bus contains a set of information that includes the type of<br>
bus from the reference library noted in FIG. 41, and the list of bus<br>
attributes from the VSI OCB Attributes Specification and the Bus<br>
Taxonomy Reference found in "Block-Based Design Methodology<br>
Documentation" Version 1.2, May 21, 1999 (the entirety of which is<br>
incorporated herein by reference), at section B.2, pages B-5 to B-10.<br>
This information should be used as described for determining which bus<br>
to use.<br>
Design for Test<br>
As described in the background, ease, of testing is among the most<br>
important attributes of an SOC design. Thus, design for test ("DFT") has<br>
become the standard. For a given customer specification, the DFT<br>
knowledge base derived using the method and system of the present<br>
invention can be searched and extracted to present the customer with a<br>
Question &amp; Answer (Q&amp;A) form. Through this device, the test objectives<br>
can be negotiated and test issues resolved in the Statement Of Work<br>
(SOW) negotiated during front end acceptance.<br><br>
results of this four-pronged initial analysis provide the DFT objectives for<br>
the overall system design of the present invention.<br>
Using DFT Rules<br>
DFT architectural rules, which are specific, test-related constraints,<br>
are used to maintain consistent test development flow and cohesive test<br>
data management. These rules guide the application of test attributes to<br>
each non-mergeable block for placement in a virtual socket at the top<br>
level, guide the execution of trade-offs to get the simplest and most<br>
adaptive test strategy, shape the creation of a top-level test specification<br>
for the design, and enable the derivation of a test plan to detail the test<br>
implementation process.<br>
DFT Glossary<br>
The listed DFT terms, as used and claimed herein, have the following<br>
definitions:<br>
Authorization	A conversion process that makes it possible to integrate a<br>
pre-designed block.<br>
BIST	Built-in self test<br>
BSR	Boundary scan register(s)<br>
CAP	Chip access port<br>
CTAP	Core test access port<br>
DAP	Design access port<br>
DFT	Design for test<br>
Fault coverage Stuck-at fault coverage of a test<br>
ICTAP	Integrated circuit test access port<br><br>
IP	intellectual property<br>
JTAG 	Joint Test Action Group (iEEE-i 149.1}<br>
Legacy block	A predesigned gate-level block that cannot be modified or<br>
reverse-engineered for reusability without risking unknown<br>
consequences<br>
Mergeable	The test requirements for a mergeable component can be<br>
combined with those of one or more other components, so<br>
they can be tested as a unit, saving test time and costs<br>
MISIR	Multiple input signature generator<br>
Mux	Multiplexer<br>
Non-mergeable	Cannot be merged with other blocks for parallel testing<br>
PRPG	Pseudo-random pattern generator<br>
SAP	Socket access port<br>
Socketization	An adaptation process to specify and add a test collar to a<br>
pre-designed block that permits testing within a design<br>
TAP	Test access port<br>
TBA	Test bus architecture<br>
Test collar	A collection of test ports and logic surrounding a<br>
predesigned block that provide test access and control<br>
Test-mergeable A block that can be merged with at least one other block,<br>
the two or more blocks being tested by a single test<br>
protocol<br>
Timeset	Cyclized tester time formats; RZ (return to zero), NRZ<br>
(nonreturn to zero), RTO (return to one), DNRZ (delayed<br>
nonreturn to zero)<br>
UDL	User-defined logic<br>
VC	Virtual component<br><br>
Virtual socket	A placeholder for a predesigned block that includes its test<br>
interface<br>
VSIA	Virtual Socket Interface Alliance<br>
Making a Test Plan<br>
The process of creating an overall DFT test plar. begins with the<br>
test designer receiving, from the FEA-generated input, test techniques for<br>
each block, expected test vector specifications, test time requirements<br>
for production, and special parametric or analog tests supplied by the I/O<br>
and analog/mixed-signal ("AMS") requirements module (xref). Creating a<br>
complete DFT plan therefore comprises effective organization and use of<br>
this data.<br>
Test Requirements for Non-Mergeable Blocks<br>
A chip-level test requirement includes the non-mergeable block test<br>
requirements, which, in turn, comprise four components: test models,<br>
test control logic such as dedicated test ports and test modes, test<br>
isolation iogic such as safe-outs, and test validation components such as<br>
test benches and test vectors. When non-mergeable blocks are delivered<br>
to the customer, they specify: test access and control data {such as test<br>
modes, activation, and deactivation), test protocols, test data, tester<br>
format, and test application/setup time.<br>
Test Requirements for Mergeable Blocks<br>
The chip-level test requirement also contains test information for all<br>
test-mergeable blocks, which, in turn, comprise test method, test control<br>
logic, interconnect implementation mechanism, and test validation<br>
components.<br><br>
Chip-Level Test Requirements<br>
The chip-level test requirement also includes DC test requirements,<br>
AC test requirements, Iddq test requirements such as power distribution,<br>
and analog test requirements,<br>
Chip-level test controller<br>
Test controls at the chip level can be the test interface, JTAG,<br>
PRPG, and MISR.<br>
Component Attributes Matrix<br>
The designer may use a matrix to plan the test development<br>
environment for components in the BBD design. This matrix documents<br>
issues, recommends or evaluates possible resolutions, and notes where<br>
additional information is required. The matrix aiso identifies areas of<br>
conflict where there are difficulties and incompatibilities in the test<br>
design.<br>
Using DFT Rules<br>
Once the designer has filtered and classified the chip-level test<br>
requirements by using the matrix, he or she can process these<br>
requirements with a set of DFT architectural rules. Using architectural<br>
rules allows for the establishment of common access, test control, test<br>
clocks, and asynchronous attributes, and trade-offs based on available<br>
DFT architectures to enable the creation of a unique hybridized DFT<br>
architecture for the chip being designed.<br>
Adaptability is a key feature of the BBD DFT strategy of the<br>
present invention. To ensure proper test integration, the designer assigns<br>
a virtual socket to each non-mergeable block based on the constraints<br><br>
and test information received at the end of front-end acceptance.The<br>
DFT architecture completes the specification by integrating these virtual<br>
sockets into the rest of the chip-level test requirements. Each virtual<br>
socket has a socket access port (SAP) mapped to the chip access port<br>
(CAP) to effect such a transformation of the test data.<br>
Before the designer can make a test plan and start preparing the<br>
design for test, he or she must check the group's DFT architecture rules<br>
for consistency and cohesion.<br>
Consistency<br>
Consistency is the degree to which test development coverage for<br>
each component is complete, in four operating modes: normal, test,<br>
isolation, and boundary (co-test). The designer may use a checklist for<br>
each component to ensure that its model, controller design, isolation, and<br>
test validation values are consistent between each block and the chip-<br>
level description.<br>
For example, in a design with three non-mergeable blocks, A, B,<br>
and C, the test controller design can test block A only if blocks B and C<br>
are isolated. The test controller specification must specifically enable a<br>
block-A test access only when both B and C are isolated. If block B and<br>
block C are to be tested concurrently, the test controller specification<br>
must enable test access to both blocks with a test validation scheme that<br>
synchronizes their test data in a single simulation environment.<br>
For this example, the table of FIG. 60 illustrates an exemplary<br>
block A consistency check.<br>
Cohesion<br><br>
Cohesion is the degree to which test methods in a flow are related<br>
to one'another. There are five closely-reiated test method parameters;<br>
each can modify the others. For example, the test access method defines<br>
the activation condition of a test protocol, the test protocol defines how<br>
, _ J_J._ r_	»j „„,4 tactdiita ie hrnt&amp;n rloiA/fl iXLa Sfi± £&gt;f oattemS<br>
WO 00/19343	PCT/US99/22984<br>
The test planning phase is followed by test budgeting, test<br>
scheduling and test management, resulting in a set of specifications and a<br>
test plan to further break test development into separate, independent<br>
subtasks for a clearly defined goal with a set of known resources and<br>
procedures.<br>
Each test block is concurrently developed according to a prescribed<br>
recipe, which can be tested with the best available techniques.<br>
Once the test blocks are readied for test integration, they can be<br>
mapped to the unconstrained SOC boundary where no I/O restriction is<br>
applied, thereby allowing each layer to become a "test-readied" template<br>
for the unconstrained SOC to be transformed into a design block. The<br>
unconstrained SOC is then constrained to a specific I/O packaging with<br>
additional I/O level test. This enables a test scheduling process to take<br>
place and fulfill the SOC level test objective.<br>
Making a DFT Test Plan<br>
After acquisition of the customer's plan during FEA, the inventive<br>
test plan development scheme of the present invention preferably begins<br>
with an assessment of each block to see if it is test-mergeable (whether<br>
the test may be performed simultaneously on a plurality of blocks). Next,<br>
the designer determines how "testable" each of the non-mergeable blocks<br><br>
Because the chip-level DFT architecture has only a single level, all<br>
attributes are at the top ievei. It is therefore intended that the designer<br>
should use the following architectural rules in accordance with the<br>
method of the present invention to put attributes in extractable comment<br>
form in the top-level design file:<br>
1.	Describe the DFT architecture hierarchically.<br>
2.	Create a single chip access port (CAP) at the highest level of<br>
hierarchy. The CAP specification should preferably:<br>
a.	Map all test control and test data pins to the package-<br>
level pin to consistently maintain design and test data.<br>
b.	Separate the test control pins from the test data pins.<br>
c.	Set the test control pin attribute to either dedicated or<br>
selectable:<br>
i.	dedicated if it should preferably be exclusively<br>
deactivated in normal mode; a dedicated pin cannot be<br>
shared with a functional pin.<br>
ii. selectable if it can be set to a test constant -<br>
a logical value - throughout a test; a<br>
selectable pin can be shared with a<br>
functional pin.<br>
d. Set the test data pin attribute to:<br><br>
test_clock if it is used as a clock during test; a<br>
test_clock pin can only be shared with an<br>
external functional clock pin.<br>
test_async if it is used asynchronously during<br>
test for reset; a test_async pin can be dedicated<br>
or shared if it does not cause any conflicts with<br>
other tests, test modes, or isolation modes.<br>
test_group(i) where (i) is the test_clock with<br>
which the test_group pin is synchronized during<br>
a test.<br>
e. Describe the following for each test mode:<br>
i.	The test setup needed to gain access to the<br>
device under test if it requires an accessing<br>
sequence. Describe the protocol, such as<br>
JTAG instruction, test clock, or test reset.<br>
ii. The test execution needed to perform the<br>
actual test. Describe the test sequence in<br>
phases down to the task level, the iteration<br>
counts, the cycle time, the test length, and<br>
the test results.<br>
iii. The test postprocessing needed to close out the<br>
test and put the chip back in the default<br>
condition (normal mode).<br><br>
Create a CAP controller specification that describes the test setup<br>
and test processing sequences for each test mode. The<br>
specification should preferably be implementable (synthesizable)<br>
and verifiable (via test benches and test sequences).<br>
The designer may optionally specify a set of staging latches to fold<br>
the internal test data bus into the available test data pins. The<br>
staging action should preferably not alter the subsequent test<br>
result. The staging should preferably be<br>
a.	Free from state-altering, time-sensitive signals. Use<br>
test_async signals or follow the persistent order of<br>
occurrence relative to the test_clock to resolve it.<br>
b.	If it is not free from state-altering, time-sensitive<br>
signals, it should have extra test pins. This rule should<br>
preferably be used judiciously to avoid test packaging<br>
problems.<br>
The designer may optionally specify a test data signature analysis<br>
capability such as MISR to compress the test data, which<br>
minimizes the physical I/O constraint. The signature analysis should<br>
preferably be deterministic for each cycle of operation and should<br>
preferably:<br>
a. be free from X-value propagation by avoiding it at the MISR<br>
inputs.<br><br>
b. if step a. fails, suppress the affected MISR cycle. This<br>
rule should be followed judiciously to avoid the loss of<br>
fault coverage.<br>
The designer may optionally create a set of other test mechanisms<br>
at the chip periphery to perform the following special tests: DC and<br>
AC parametric tests such as boundary scan tests; frequency tests<br>
such as PLL tests; and mixed-signal tests such as ADO and DAC<br>
tests. The control pins for these tests should preferably be<br>
included in the table of all test_control pins. The designer might<br>
also want to include them in the CAP controller specification to<br>
avoid conflicting interactions.<br>
Specify a single device access port (DAP) at the next level of<br>
hierarchy, the level without l/Os or l/O-related cells, unrestricted to<br>
the physical I/O.<br>
The DAP should preferably be a hybridized test port that can be<br>
formed by concatenating, merging, resizing, and multiplexing<br>
generic ports, such as TAP-based ports.<br>
The designer should preferably be able to configure the DAP<br>
directly from the CAP controller. Partition each configuration into<br>
test control, test data, or test isolation ports. In each configuration:<br>
a. Set the test control port attribute to<br>
test_con f(k) if it should preferably be used<br>
to set the targeted configuration k.<br><br>
test_select if it can be set to a test<br>
constant.<br>
b. Set the test data port attribute to<br>
test_ciock if it Is used as a clock during test.<br>
test_async if it is used asynchronously<br>
during test.<br>
test_group(i) vyhere (I) indicates the test<br>
clock to which the ports are synchronized.<br>
test_direction if it is used to indicate the<br>
test data direction. The test direction<br>
can only be a 1 or 0 value.<br>
c. Set the test isolation port attribute to safe_state if it<br>
should preferably be isolated during test with a safe state<br>
logic value of 0,1, or Z, and to dontcare if it can be set to a<br>
non-floating logic value of 0 or 1.<br>
Specify the interconnection of the CAP, the CAP controller, the<br>
-staging latches, the MISR, the DAP, and the other test mechanisms<br>
in the top-level DFT architecture.<br>
Specify the CAP controller, the staging latches, the MISR, the<br>
design body, and the other test mechanisms in a dedicated section.<br>
Specify detail on the DAP the sockets, the UDL, and the test<br>
interconnect for the design body architecture only.<br><br>
13.	The design body architecture should preferably be described<br>
hierarchically.<br>
14.	There should preferably be multiple SAPs at the next level of<br>
hierarchy, the socket level.<br>
1 5. Each SAP should preferably be a recursive image of the DAP with<br>
one or many applicable configurations available to the DAP. All<br>
configurations of the SAP should preferably be supported by the<br>
DAR.<br>
Socketization Rules<br>
Once a non-mergeable block or VC is placed in a design, its I/O<br>
ports are no longer accessible from the chip I/O. Its test data, which is<br>
created at the I/O ports, is no longer usable either.<br>
In general, recreating test data at the chip level is difficult and<br>
unpredictable because design block test values must propagate through<br>
other logic blocks. The preferred approach, therefore, is to add<br>
accessibility to the design block itself by creating a virtual socket for the<br>
design block. The virtual socket includes test access, isolation, and<br>
boundary test functionalities accessible from the chip I/O.<br>
The designer can use the virtual socket as a placeholder for the<br>
design block in the design, or can also use the socket to put test<br>
constraints on the design block itself. A design block is socketized when<br>
constraints are mapped to it in a design using I/O mapping and<br>
restrictions. The constraints are design-sensitive and conditional, but they<br>
let the designer divide each design block socketization task cohesively<br>
while keeping track of the design blocks during design integration.<br><br>
The socketized design block might need extra I/O ports and a logic<br>
or test collar to match the chip-level test constraints while maintaining<br>
the functional interface. Because the interface timing might be changed<br>
slightly, it is best to write the test collar in RTL code, to be characterized<br>
or rebudgeted in synthesis for each socketized design block. Adding the<br>
test collar at the gate level after synthesizing the whole design might<br>
cause timing problems.<br>
The design block socketization rules are as follows:<br>
1.	The socket can be described hierarchically but the top level should<br>
preferably contain all the test attributes.<br>
2.	There can be only one SAP per socket.<br>
3.	The SAP Is the only reference for test information about how to<br>
isolate, test, diagnose, and debug every element in the socket.<br>
4.	Each SAP should preferably be constructed or synthesized<br>
according to the higher level specification.<br>
5.	The designer should preferably be able to verify, at the higher level<br>
of construction and context, that each SAP can activate and<br>
deactivate normal, test, isolation, and boundary modes. This means<br>
the designer should verify the external test information structure of<br>
the socket.<br>
a. The external test information structure should<br>
preferably conform to the standardized description<br>
language specified in the VSIA compliance rules.<br><br>
b. If a standardized description language is not available,<br>
the test information structure should conform to the<br>
chip-level design test attributes at the virtual socket.<br>
Each SAP should preferably be validated at the socket level with<br>
the reformatted test data to ensure that it properly performs the<br>
test setup, test execution, and test postprocessing sequences. This<br>
means the designer should verify the internal test information<br>
structure of the socket.<br>
a.	The internal test information structure should<br>
preferably include all design block test models, all<br>
functional blocks, and all other logic bounded by the<br>
socket.<br>
b.	The internal test information structure should<br>
preferably be co-simulated and interoperable with the<br>
chip-level simulation environment.<br>
In normal mode, all test logic associated with the SAP should<br>
preferably be deactivated simultaneously and directly, not<br>
sequentially, from the SAP interface. Normal mode should be<br>
activated by a single test control port.<br>
In isolation (rest) mode, all test logic associated with the SAP<br>
should be deactivated and assigned to safe-state values without<br>
intermediate conflicts. No functional states may be implied in the<br>
isolation sequence.<br><br>
9.	in test mode, all test logic associated with the SAP should<br>
preferably be enabled by a single activating sequence, then<br>
; optionally by a configuring sequence, before beginning a test<br>
sequence. To minimize test time, successive test sequences of the<br>
same configuration should be bundled.<br>
10.	All of the socket's peripheral logic should be testable in boundary<br>
(co-test) mode, including the test logic associated with the SAP.<br>
Designing a Top-Level Test Logic Specification<br>
When the designer designs a top-level test logic specification to<br>
meet coverage and time requirements, he or she will need to make<br>
tradeoffs that increase the parallel nature of the test logic. The major<br>
decision is how serial or parallel to make the individual biock tests.<br>
The test constraints are used for each virtual socket with the<br>
socketization rules to establish test requirements for constructing the test<br>
collar. From the test access perspective, the SAP is complete and<br>
adequate for test integration purposes. To avoid design changes that can<br>
cause design and test conflicts, the SAP should not share or use<br>
functional elements of the block. This separation makes even more sense<br>
when different block types - soft, firm, or hard blocks - are utilized,<br>
making it possible to avoid unpredictability during test integration.<br>
In general, each architecture aims at a unique set of solutions or a<br>
specific set of tools, and targets a specific range of test applications.<br>
Many architectures originate in specific design environments that span<br>
almost every role of a design. Therefore, a development flow is needed<br>
that does the following:<br><br>
1.	Characterizes and categorizes test problems in the<br>
design context;<br>
2.	Addresses the trade-offs for each architecture;<br>
3.	Provides additional alterations for each targeted<br>
design.<br>
4.	Until the advent of the present invention, BBD test problems<br>
were evident in the following areas:<br>
Test data reusability<br>
Test socket design and socket information<br>
UDL and chip-level interconnect testing<br>
Test packaging<br>
Test validation<br>
Test protocols<br>
Diagnostics and debugging<br>
These issues are related to the assumptions made during BBD<br>
design planning. However, the design plan requires many specific<br>
processes to package a design block with reusable test data, such as:<br>
creating the BBD design for test, customizing the design block test<br>
interface, designing and validating the test access and control<br>
mechanism, and packaging the test with the chip I/O and within the test<br>
budget.<br>
DFT Taxonomy<br>
DFT architectures are classified by their test methods, their test<br>
interfaces, and the types of blocks with which they can be used. There<br>
are four different generic DFT architectures, but they rarely have similar<br><br>
test interfaces. For example, most chips have embedded RAM that uses a<br>
memory BIST interface while the rest of the chip might use a scan<br>
method. The table in FIG. 63 lists the typical choices in a design scenario.<br>
Procedure for creating a Top-Level DFT Architecture<br>
The flowchart of FIG. 64 illustrates the procedure used to create<br>
the top-level architecture specification and specify chip-level test<br>
structures. The DFT plan should preferably specify the block-level test<br>
logic for every block on the chip. Blocks with test logic should receive<br>
interfaces to the top level. Blocks without test logic should receive test<br>
logic requirements. Transfer both of these design requirements to the<br>
block design task, preferably creating both the top-level test logic and the<br>
access mechanism.<br>
The flowchart in FIG. 65 illustrates the socketization procedure<br>
used to create the block test logic specification. For each socket in the<br>
design, specify the test collar for each design block to conform with the<br>
DFT architecture as illustrated.<br>
Creating a Test Generation Mechanism<br>
The BBD strategy for test generation can comprise manual vectors,<br>
ATPG, or mixed. The translation and concatenation mechanisms should<br>
be defined to match the top-level test logic and the individual blocks' test<br>
mechanisms. In BBD, test development comprises two independent<br>
processes.<br>
1. Block-level test development for each virtual socket. In most<br>
cases, this process consists of the following tasks:<br><br>
a. SAP declaration: Add the SAP to the behavioral model<br>
interface and re-instantiate the block with its virtual socket.<br>
i.	Test logic insertion: Add test access, isolation,<br>
interconnect test, and test control logic to form the test<br>
collar around the targeted block. For best results, describe<br>
the test collar in synthesizable RTL format.<br>
ii. Test data transformation: Expand and map test<br>
data into SAP ports. One should modify the block-level test<br>
bench to accept the new test data format. To streamline the<br>
test flow, one might alter the tester timing on some blocks<br>
to minimize test setup time per socket and concurrently run<br>
multiple block tests.<br>
iii. Test verification: Modify the block-level test<br>
bench to verify the test logic. Verify the target block with a<br>
subset of the complete block-level test vector set to ensure<br>
test data integrity before and after the previous steps<br>
2. Chip-level test development for all test-mergeable blocks and<br>
chip-level tests such as DC tests and analog tests. This process<br>
comprises the following tasks:<br>
a. Test logic insertion: Add the test controller, dedicated<br>
test pins, DC test logic, analog test logic, and, it<br>
necessary, clock muxes and test clocks for all tests.<br><br>
This task also involves scan insertion for test<br>
mergeable blocks and UDL if necessary.<br>
b. Test generation: Use ATPG tools to generate test<br>
data for the test-mergeable blocks and UDL, or<br>
capture cyclic functional test data. It is important to<br>
meet fault coverage objectives with the targeted<br>
manufacturing test data.<br>
c. Test verification: Modify the chip-level test bench to<br>
verify the test controller and perform DC tests, analog<br>
tests, tests for all virtual socket in the design, and the<br>
UDL test. These tests might need pre- and post-test<br>
sequences such as JTAG requires.<br>
d. Test data formatting: Take the simulation results and<br>
put them in a test data description language such as<br>
WGL.<br>
We turn next to the application of DFT at the block level in a BBD<br>
DFT methodology context. The final product of an intellectual property<br>
core or design block is a "test-readied" block with a standardized or<br>
generic test interface and a test data set that can be reused at the chip<br>
level. The design block socketization scheme is employed to transform a<br>
design block into an integral part of the chip level tests while reusing<br>
most of the test procedure and apparatus generated during the designing<br>
of each block. The inventive BBD DFT mix-and-match strategy provides a<br>
flexible approach to integrate a variety of pre-designed blocks with<br><br>
different test methods and test interfaces by sorting out non-mergeable<br>
blocks in contrasting to the most popular scan based test methodology.<br>
The reason to make scan design methodology the basis for test<br>
mergeable selection is simply the ease of automation purpose.<br>
The block design plan involved in many specific processes to<br>
package a design block with re-usable test data is based on a<br>
standardized or customized design block test interface, taking into<br>
account certain assumption about accessibility of block l/Os. However,<br>
once embedded, the block l/Os can be placed in different contexts and<br>
potentially become inaccessible. To ensure the ease of integration, the<br>
test interface should be separate from the functional interface to provide<br>
some orthogonalities from the chip design perspective. in BBD, one<br>
attempts to mix and match the design block interfaces and unify them at<br>
the chip level (as illustrated in FIG. 68). Therefore, the flexibility and<br>
modifiability of the test interface should be provided to design and<br>
validate the test access and control mechanism, and to package the test<br>
with the chip I/O and within the block level test budget. As understood<br>
by one skilled in the art to which the present invention pertains, though<br>
possible-, the use of an On Chip Bus (OCB) as part of the test bus is<br>
contemplated by the present invention but beyond the scope of this<br>
description.<br>
Non Mergeable Blocks<br>
DFT logic and test vector verification functions let the designer run<br>
shorter, production ready tests earlier in the production cycle, DFT scan<br>
paths provide access to chip and system states that are otherwise<br>
unavailable. Memory BIST uses algorithmic test vectors to cover different<br><br>
embedded memory fault classes. Logic BIST takes advantage of random<br>
testable structure of scan based design to reduce test access and test<br>
data bottlenecks. However, each predesigned block may become non-<br>
mergeable for a number of reasons. In general, non-mergeable blocks<br>
are:	-<br>
Synthesizable RTL soft blocks that may not be compatible with<br>
common test methods due to lack of internal test accessibility (e.g.<br>
gated-clock, latch-based, data paths), or lack of fault coverage<br>
(e.g. asynchronous).<br>
Gate-level soft blocks that may not be compatible with common<br>
test methods such as scan methodologies (i.e. synchronous), scan<br>
styles (e.g. mux-scan, clock-scan, LSSD).<br>
Compiled blocks that are generally array-based. For example;<br>
embedded RAMs, ROMs, DRAM, FLASH, etc. do not have the<br>
same fault; models as combinational logic. These blocks require<br>
large algorithmic test patterns.<br>
Hard blocks that are created with a specific test method but does<br>
not have the infrastructure available for test integration. Generally,<br>
these blocks should preferably be delivered with a specific block<br>
level test data set with or without a specific test interface.<br>
Legacy blocks that are created with or without a specific test<br>
method but does have the infrastructure for integration. Generally,<br>
these block may not be modified to avoid unknown consequences.<br>
Test Collars<br><br>
The socketized design block can be modeled by creating a new<br>
module that describes the socket with the SAP specification, instantiating<br>
the original design block, and inserting test logic between them, as<br>
illustrated in the flowchart of FIG. 66. The socketized design block first<br>
restores the design block functional interface, add test access, test<br>
isolation, boundary test structures then provide the basic test interface<br>
(e.g. TAR scan, BSR, or direct-muxes) as defined during the chip<br>
planning. The result is the SAP with test attributes added as comments<br>
for each associated test I/O port. Each non-mergeable block will be<br>
wrapped by a test collar to add test access, isolation, and interconnect<br>
test facilities for performing test setup, test execution, and test post<br>
processing on a block by block basis. The output is a socketized design<br>
block including:<br>
1.	test access and control (e.g. test modes, activation, and<br>
deactivation)<br>
2.	test protocol, (e.g. functional, mux-scan, BIST, diagnostics);<br>
3: test data (e.g. test language, vector size, fault coverage);<br><br>
4.	tester format (e.g. tester specification, timesets, test speed);<br>
5.	test application time (e.g. no test setup time);<br>
Adding Testability<br>
For each non-mergeable block which does not come with re-usable<br>
test data, the design planning phase can specify the test interface, test<br>
method, test data format, expected fault coverage, and test budget by<br><br>
inserting test structures and estimate the overall area and timing cost.<br>
This estimate becomes the constraint for adding testability to each block.<br>
Synthesizable RTL Soft Blocks<br>
If the pre-designed block is a synthesizabie soft block which does<br>
not compatible with scan based test application then fault coverage could<br>
be a problem. For example, scan design rule check can be done at the<br>
RTL or gate level to screen out scan violations. Since scan chain or test<br>
points can not be easily inserted into the model, sequential ATPG can be<br>
used in conjunction with functional test vectors, as illustrated in the<br>
flowchart of FIG. 67. The fault coverage for this type of design is difficult<br>
to predict and fault simulation should preferably be used to establish the<br>
re-usability criteria of such block during the planning phase. The TBA<br>
based test collar is the best test interface but the BSR based test collar<br>
could be considered if test budget for the block is allowed.<br>
Verification<br>
Moving now from DFT to design verification, the primary objective<br>
of the verification method and system of the present invention is to<br>
ensure that a completed design (at final tape out) meets the customer's<br>
functional requirements as specified in the Functional Specification and<br>
Chip Test Bench, supplied as part of front-end acceptance. A secondary<br>
objective is to achieve the primary objective in the minimum time<br>
possible.<br>
It is especially essential to the proper function of the present<br>
invention, as it is to any design test scheme, that the customer-supplied<br>
Chip Test Bench form a complete test of the customer's requested<br>
functionality. This assumption is preferably emphasized during front-end<br><br>
acceptance. The BBD design flow will thereby incorporate grading of the<br>
Chip Test Bench while running on the Functional Specification model,<br>
thereby providing a measure of the Chip Test Bench.<br>
The inventive approach is to utilize both the Functional<br>
Specification and the Chip Test Bench in an integrated manner, to insure<br>
that the two are consistent. Subsequently, as detail is added and refined<br>
through chip planning, chip assembly and block design, the design is<br>
re-verified via the Chip Test Bench to ensure that functionality remains<br>
consistent with the original Functional Specification. Verification of<br>
progressively more-detailed views may be performed at the complete chip<br>
level or at the individual block level with distinct Block Test Benches<br>
extracted from the Chip Test Bench, as described below.<br>
Experience reveals that bus logic and the interaction of various<br>
blocks connected along the same bus can take significant time to resolve,<br>
causing iterative re-designs if not addressed early and continuously in the<br>
design process. For this reason, particular attention is given to validation<br>
of the bus functionality early in the design cycle. The bus and associated<br>
logic is therefore identified at an early stage and verified, independent of<br>
the rest.of the design, using Bus Compliance Test Benches, as described<br>
below. However, it should be noted that the preferred verification flow<br>
of the present invention is flexible enough to handle a wide variety of<br>
designs with rapid turnaround. For example, if a design uses simple<br>
busses or the designer has significant experience with the blocks<br>
attached to the bus, then some or all of the bus compliance testing may<br>
be deferred. Similarly, if some or all of the blocks are either simple or<br>
reused from a prior design, then a portion of the individual block<br><br>
verification may be skipped, and verification deferred until the chip level<br>
verification stage is reached.<br>
The detailed flow to be followed for a particular design should be<br>
established as part of the FEA process. Figures 12-15 provide a<br>
generalized flow of the tasks to be performed during functional<br>
verification according to the present invention. These figures will be<br>
described in detail, with cross-reference make to chip test bench figures<br>
69-73. It should noted that in figures 12-15, a large arrow signifies task<br>
flow, a smaller arrow signifies task inputs, and a dashed arrow signifies<br>
an optional bypass path.<br>
Referring to FIG. 12, after completion of FEA, as described above,<br>
the method of the present invention continues with chip test bench<br>
verification step 8210, wherein the chip-level functional model is<br>
exercised with the chip test bench 8310 in FIG. 69. Both the model and<br>
the test bench are customer-supplied, the purpose of verification being to<br>
ensure that the test bench and functional model are consistent. The<br>
model will preferably be in Verilog, VHDL or executable C code, although<br>
any compatible language will suffice. Chip test bench 8310 will be in a<br>
file compatible with the model. Any miss-matches between the model<br>
and "the" test bench will be fed back to the customer and either the model<br>
or the test bench will be modified to achieve internal consistency.<br>
Next, the chip test bench is graded while running on the functional<br>
model. Such grading provides a "goodness" measure, or coverage<br>
metric, of the test bench by measuring one or more of the following<br>
attributes: statement coverage, toggle coverage, FSM arc coverage,<br>
visited state coverage, pair arc coverage, path/branch coverage and/or<br><br>
expression coverage. This coverage metric is then fed back to the<br>
customer. The coverage metric may highlight areas of the design that<br>
appear to be poorly tested, as where a design is inadequately tested or<br>
the design includes redundant functionality. In either case the customer<br>
may chose to modify the test bench or the model to improve the<br>
coverage metric, thereby resetting the project start time for the BBD<br>
design methodology herein described.<br>
Once the chip test bench is certified consistent with the functional<br>
model, a new view 8312 {in FIG. 69) of the chip is created at step 8212<br>
(of FIG. 12) by combining the block functional models for each of the<br>
blocks with the defined glue logic between these blocks. The block<br>
functional models 8312 are either customer supplied or created via a<br>
"dipping" process during FEA, as described above. A glue logic model is<br>
also specified during chip planning, as described above.<br>
Referring again to FIG. 12, chip level structural verification step<br>
8214 comprises simulating the block functional model of the chip with<br>
the chip test bench. Any discrepancies are resolved by modifying one or<br>
more of the block functional models 8312 or the glue logic model, and<br>
rerunning the simulation. This step ensures that the block functional<br>
models are consistent with the chip functional model.<br>
Turning next to FIGS. 13 and 14, the objective of the bus<br>
verification flow is to ensure that the bus logic within the chip, operates<br>
correctly and that interactions between the different bus elements will<br>
not cause bus protocol errors. Thus, compliance vectors are created for<br>
the bus design. These vectors may be based on compliance test suites<br>
supplied by the customer or block design supplier. The vectors will have<br><br>
to be manipulated to correspond to the specific bus topology of the<br>
design. Where compliance vectors have not been provided, they will have<br>
to be written by the design team, preferably in such a manner that they<br>
exercise the interactions of the various blocks attached to the bus,<br>
exercise all boundary conditions, and verify that bus errors are correctly<br>
handled.<br>
Step 8218 in FIG. 13 provides for the verification of bus<br>
functionality. The bus compliance vectors are simulated against the<br>
cycle-accurate model of the bus supplied from the chip planning stage<br>
discussed above. Any errors must be resolved by either modifying the<br>
compliance vector set (not shown) or by modifying one or more of the<br>
bus logic elements 8512 shown in FIG. 70, This step is repeated until the<br>
compliance test suite executes successfully on the bus logic model.<br>
Referring next to FIG. 14, bus block model and test bench creation<br>
steps 8610 through 8614 are illustrated. The objective of both bus block<br>
model creation step 8610 and test bench generation extraction step<br>
8612, as well as bus block model verification step 8614, is to create a<br>
high level behavioral model and associated test bench for each of the<br>
blocks within the design. These are passed to the block designers and<br>
define the target functionality for each of the blocks.<br>
Creating bus block model 8510 in FIG. 70 for each block comprises<br>
combining the functionally correct, cycle-approximate block functional<br>
model 8312 with a cycle-accurate bus logic model for that block. The bus<br>
logic is extracted from the bus glue logic model supplied from chip<br><br>
planning and verified above. Some modification of the Bus Functional<br>
Models may be required to get the interfaces to "align."<br>
The bus block models are then verified by assembling a model of<br>
the chip combining all of the bus block models. The chip model is then<br>
verified by simulating it with the chip test bench. While the chip test<br>
bench has previously been verified on cycle approximate models, this<br>
behavioral block model of the chip has some cycle accurate operations<br>
and so some refinement of the chip test bench will be required to get the<br>
block model to pass. In some cases, errors may result due to<br>
miss-matches in the block functional model and the bus logic, at which<br>
time the model may be modified to correct the errors. Once the chip test<br>
bench successfully executes on this chip model, the individual bus block<br>
models may be sent to the block designers for detailed implementation.<br>
At step 8612 in FIG. 14, block test benches are extracted. Once<br>
the chip test bench executes successfully on the chip level bus block<br>
model 8710, as illustrated in FIG. 71, probes can be set on the interfaces<br>
of the individual blocks and block test benches can be extracted from<br>
chip test bench 8712 as it executes on the model. These block test<br>
benches are sent to the block designers for validation of the blocks as<br>
they progress through implementation.<br>
Proceeding next to the logical verification flow illustrated in FIG.<br>
15, the objective of the logical verification tasks is to ensure that each of<br>
the blocks is functionally correct as it progresses through the<br>
implementation phases of the design (from RTL to pre-layout netiists to<br>
post-layout netiists). Also tested is whether the assembled chip continues<br>
to provide the required functionality.<br><br>
Verification may be done either dynamically through functional<br>
simulation or statically using formal verification tools that perform<br>
equivalency checks. Dynamic verification requires simulation tools that<br>
are required and described elsewhere in the BBD methodology flow of the<br>
present invention. Dynamic verification also utilizes vector sets used<br>
elsewhere and so aids in the migration of the test suite from cycle<br>
approximate to cycle accurate in nature. Static verification requires the<br>
inclusion of new tools. However, static verification will typically run<br>
faster than simulation and provides a "complete* equivalency check, in<br>
contrast to simulation, which only proves equivalency to the extent that<br>
the test bench exercises the design functionality.<br>
Next, individual RTL block models are verified at step 8710,<br>
wherein RTL simulation models created by the block designers are verified<br>
against the chip test bench. This can be done by swapping the block RTL<br>
model with the corresponding behavioral model in the chip level<br>
behavioral model and performing a mixed mode simulation of the chip<br>
using the full chip test bench. In the alternative, the individual block RTL<br>
model can be simulated with the extracted block test bench. In either<br>
case, miss-matches can be expected due to the transition from a cycle<br>
approximate model to a cycle accurate model. These miss-matches will<br>
be resolved by modifying the test bench. If miss-matches are triggered by<br>
missing or incorrect functionality, then the RTL model must be modified<br>
to correct the errors.<br>
At step 8712, RTL block models are verified at the chip level. The<br>
RTL simulation models for each of the blocks are combined to create a<br>
chip level RTL model. This model is verified by simulating with the chip<br><br>
test bench. Again, some errors may be present due to the transition from<br>
a cycle.approximate model to a cycle accurate model. These errors will be<br>
resolved by modifying the chip test bench. Any functioral errors will<br>
have to be resolved by modifying one or more of the block level RTL<br>
models.<br>
At step 8714, individual pre-layout block netiists are verified. The<br>
post synthesis netlist simulation models for each block are against the<br>
RTL model for that block.<br>
At step 8716, dynamic and static chip level pre-layout block<br>
netiists are verified. Dynamic verification can either be done by swapping<br>
the block level post synthesis netlist with the corresponding behavioral<br>
model in the chip level behavioral model and performing a mixed mode<br>
simulation of the chip using the full chip test bench. In the alternative,<br>
the individual block level post synthesis netlist can be simulated with the<br>
block test bench. In either case, miss-matches can again be expected due<br>
to the transition from a cycle accurate model to a model with intra-cycle<br>
timing. These miss-matches will be resolved by modifying the timing<br>
strobes within the test bench. Static verification is performed by running<br>
the equivalency checking tools on the post synthesis netlist and the RTL<br>
model for each block. Miss-matches will be resolved by modifying the<br>
post synthesis netlist to match the RTL model.<br>
The post synthesis netiists for each of the blocks are then<br>
combined to create a chip post synthesis netlist. This chip level netlist is<br>
verified either through simulation or statically through formal equivalency<br>
checking tools. Dynamic verification is accomplished by simulating the<br>
chip post synthesis netiist with the chip test bench. Static chip level<br><br>
pre-Iayout verification is performed by running the equivalency checking<br>
tools on the chip post synthesis netlist and the chip RTL model for each<br>
block. Miss-matches will be resolved by modifying the post synthesis<br>
netlist to match the RTL model.<br>
At step 8718, individual post-layout block netlists are verified.<br>
This step is a repeat of step 8714, but with the post-layout netlist<br>
substituted for the pre-Iayout netlist. The only difference, at the netlist<br>
level, between these two models should be the modification of buffers<br>
and drive strengths to achieve, the timing goals of the laid-out design. Any<br>
errors encountered should be limited to the incorrect addition or deletion<br>
of buffers. The timing of the block test bench may have to be modified if<br>
the post-layout timing changes has moved signals with respect to the<br>
timing strobes.<br>
This verification may be done either statically or dynamically.<br>
Dynamic verification can be done by swapping the block level post layout<br>
netlist with the corresponding block RTL model in the chip level RTL<br>
model and performing a mixed mode simulation of the chip using the full<br>
chip test bench. Alternatively, the individual block level post layout<br>
netlist can be simulated with the block test bench. Static verification is<br>
performed by running the equivalency checking tools on the post layout<br>
netlist and the RTL model for each block. Miss-matches will be resolved<br>
by modifying the post synthesis netlist to match the RTL model.<br>
Verification of the chip level post-layout netlist is accomplished at<br>
step 8720, a repeat of step 8716 but with the post-layout chip level<br>
netlist substituted for the pre-Iayout netlist. The only difference, at the<br><br>
netlist level, between these two models should be the modification of<br>
buffers and drive strengths to achieve the timing goals of the laid-out<br>
design. Any errors encountered should be limited to the incorrect addition<br>
or deletion of buffers. Dynamic verification is accomplished by simulating<br>
the chip post layout netlist with the chip test bench. Static verification is<br>
performed by running the equivalency checking tools on the chip post<br>
layout netlist and the chip RTL model. Miss-matches will be resolved by<br>
modifying the post layout netlist to match the RTL model.<br>
Finally, physical verification is accomplished as illustrated in FIGS.<br>
72 and 73, wherein both block and chip tape out are verified in the<br>
manner understood by one skilled in the art to which the present<br>
invention pertains. The objective of the physical verification tasks is to<br>
verify that the GDSII files created through the block design and chip<br>
assembly phases of the design are functionally correct and free of any<br>
violations of the design rules for the target technology.<br>
The GDSII for each of the blocks, created by the block design<br>
process, are verified by running DRCs for the target technology. Any<br>
errors and warnings are fed back to the block designer for resolution. LVS<br>
is also run between the block GDSII file and the post layout netlist for<br>
that block. Any errors or warnings are fed back to the block designer for<br>
resolution.<br>
The GDSII for the complete chip, created by the chip assembly<br>
process, is verified by running DRCs for the target technology. Any errors<br>
and warnings are sent back to the chip assembly designer for resolution.<br>
LVS is also run between the chip GDSII file and the post layout netlist for<br><br>
the chip. Any errors or warnings are fed back to the chip assembly<br>
designer for resolution.<br>
While the invention has been illustrated and described in detail in<br>
the drawing and foregoing description, it should be understood that the<br>
invention may be implemented through alternative embodiments within<br>
the spirit of the present invention. Thus, the scope of the invention is not<br>
intended to be limited to the illustration and description in this<br>
specification, but is to be defined by the appended claims.<br><br>
We Claim:<br>
1.	A computer-implemented method of increasing glue logic distribution efficiency, for<br>
execution in an integrated circuit device design scheme, wherein a device design comprises a plurality<br>
of pre-existing design blocks, the method comprising the steps of:<br>
copying a selected glue logic element, thereby creating a duplicate element set having said<br>
selected element and its copy; and<br>
distributing said duplicate element set to the plurality of design blocks.<br>
2.	The method as claimed in claim 1, wherein the act of distributing comprises:<br>
splitting the first element into a plurality of derivative glue logic elements in the event of a first<br>
glue logic element having an output net driving a plurality of loads; and<br>
distributing said derivative elements to the plurality of design blocks.<br>
3.	The method as claimed in claim 2, wherein each derivative element has only a single output<br>
load.<br>
4.	The method as claimed in claim 2, wherein if a first glue logic element has a plurality of<br>
inputs, the split element is the first element.<br>
5.	The method as claimed in claim 2, wherein a derivative element has only two-inputs.<br>
6.	The method as claimed in claim 1, wherein the act of distributing comprises:<br>
analyzing the plurality of elements for a selected quality; and<br>
merging a selected glue logic element into a selected block in a manner based upon the analysis.<br>
7.	The method as claimed in claim 6, wherein the selected block is selected in a manner based<br>
upon its functional affinity to the selected element.<br><br>
8.	The method as claimed in claim 7, wherein said functional affinity comprises whether the<br>
merger would reduce the number of physical I/0 elements required for the proper function of said<br>
circuit device design.<br>
9.	The method as claimed in claim 6, wherein if two or more design blocks are equal<br>
candidates for the merger, the block having the lowest pin density is chosen.<br>
10.	The method as claimed in claim 7, wherein said functional affinity comprises whether a<br>
selected element and a selected block together have improved chip level timing characteristics.<br>
11.	The method as claimed in claim 1, wherein the act of distributing comprises:<br>
identifying a plurality of elements that can be neither copied and distributed among the design<br>
blocks or merged with the design blocks; and<br>
clustering the identified plurality of elements.<br>
12.	The method as claimed in claim 11, wherein each of the clustered elements has multiple<br>
loads on input nets and multiple loads on output nets.<br>
13.	The method as claimed in claim 11, wherein the plurality of elements have inputs with<br>
similar function.<br>
14.	The method as claimed in claim 1, wherein the act of distributing comprises:<br>
identifying a first feature of a first glue logic element; and<br>
identifying a second glue logic element having a second feature making the second glue logic<br>
element compatible with the first glue logic element;<br>
merging said first glue logic element with the identified second glue logic element.<br>
15.	The method as claimed in claim 14, wherein said first feature comprises the number of<br>
pins required by said first glue logic element.<br><br>
16.	The method as claimed in claim 14, wherein said first feature comprises the input structure<br>
of said first glue logic element.<br>
17.	The method as claimed in claim 14, wherein said first feature comprises the output<br>
structure of said first glue logic element.<br>
18.	The method as claimed in claim 14, wherein the second glue logic element is a design<br>
block.<br><br><br>
There is disclosed a computer-implemented method of increasing glue logic distribution<br>
efficiency, for execution in an integrated circuit device design scheme, wherein a device design<br>
comprises a plurality of pre-existing design blocks, the method comprising the steps of copying a<br>
selected glue logic element, thereby creating a duplicate element set having said selected element and<br>
its copy; and distributing said duplicate element set to the plurality of design blocks.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LSgxMi0wOS0yMDExKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-(12-09-2011)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LSgyNS0wNC0yMDEyKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-(25-04-2012)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LSgyNS0wNC0yMDEyKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-(25-04-2012)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUFCU1RSQUNULTEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-ABSTRACT-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">438-kol-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUFNQU5ERUQgQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-AMANDED CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">438-kol-2005-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">438-kol-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUNPUlJFU1BPTkRFTkNFIDEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-CORRESPONDENCE 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUNPUlJFU1BPTkRFTkNFIDEuMi5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-CORRESPONDENCE 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWNvcnJlc3BvbmRlbmNlLnBkZg==" target="_blank" style="word-wrap:break-word;">438-kol-2005-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LURFU0NSSVBUSU9OIChDT01QTEVURSktMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-DESCRIPTION (COMPLETE)-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">438-kol-2005-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LURSQVdJTkdTLTEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-DRAWINGS-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">438-kol-2005-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gMSAxLjIucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 1 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gMS0xLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 1-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">438-kol-2005-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gMTggMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 18 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">438-kol-2005-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gMi0xLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 2-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWZvcm0gMi5wZGY=" target="_blank" style="word-wrap:break-word;">438-kol-2005-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gMyAxLjIucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 3 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gMy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 3-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">438-kol-2005-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gNSAxLjIucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 5 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUZPUk0gNS0xLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-FORM 5-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">438-kol-2005-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdQQSAxLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GPA 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">438-kol-2005-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LUdSQU5URUQtU1BFQ0lGSUNBVElPTi5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-GRANTED-SPECIFICATION.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LU9USEVSUyAxLjIucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-OTHERS 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LU9USEVSUy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-OTHERS-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LVBBLnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LVBFVElUSU9OIFVOREVSIFJVTEUgMTM3LnBkZg==" target="_blank" style="word-wrap:break-word;">438-KOL-2005-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVCAxLjEucGRm" target="_blank" style="word-wrap:break-word;">438-KOL-2005-REPLY TO EXAMINATION REPORT 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LUtPTC0yMDA1LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">438-KOL-2005-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDM4LWtvbC0yMDA1LXNwZWNpZmljYXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">438-kol-2005-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="251965-panoramic-periscope.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="251967-method-for-the-humanization-of-antibodies-and-humanized-antibodies-thereby-obtained.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>251966</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>438/KOL/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>16/2012</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>20-Apr-2012</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>18-Apr-2012</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>24-May-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>CADENCE DESIGN SYSTEMS, INC.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>2655 SEELY AVENUE, SAN JOSE, CALIFORNIA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>COOKE LARRY</td>
											<td>25399 SPANISH RANCH ROAD LOS GATOS, CALIFORNIA 95033</td>
										</tr>
										<tr>
											<td>2</td>
											<td>CHANG HENRY</td>
											<td>437 SOUTH MARY, APT.#18 SUNNYVALE, CALIFORNIA 94086</td>
										</tr>
										<tr>
											<td>3</td>
											<td>HUNT MERRILL</td>
											<td>2460 REILLVIEW DRIVE, ESCONDIDO, CALIFORNIA 92025</td>
										</tr>
										<tr>
											<td>4</td>
											<td>KE WUUDIANN</td>
											<td>1086 HUNTERSTON PLACE CUPERTINO, CALIFORNIA 95014</td>
										</tr>
										<tr>
											<td>5</td>
											<td>LENNARD CHRISTOPHER K</td>
											<td>745 SOUTH BERNARDO AVENUE, APT. #319-A, SUNNYVALE CALIFORNIA 94087</td>
										</tr>
										<tr>
											<td>6</td>
											<td>MARTIN GRANT</td>
											<td>2424 RAVEN ROAD, PLEASANTON, CALIFORNIA 94566</td>
										</tr>
										<tr>
											<td>7</td>
											<td>PATERSON PETER</td>
											<td>25585 PACIFIC HILLS DRIVE MISSION VIEJO, CALIFORNIA 92692</td>
										</tr>
										<tr>
											<td>8</td>
											<td>TRUONG KHOAN</td>
											<td>2206 GLENVIEW DRIVE, MILPITAS CALIFORNIA 95035</td>
										</tr>
										<tr>
											<td>9</td>
											<td>VENKATRAMANI KUMAR</td>
											<td>19495 VIA REAL DRIVE, SARATOGA, CALIFORNIA 95070</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F13/14</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/102,566</td>
									<td>1998-09-30</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/251966-a-computer-implemented-method-of-increasing-glue-logic-distribution-efficiency by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:37:47 GMT -->
</html>
