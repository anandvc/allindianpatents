<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/256341-video-encoding-and-decoding-methods-and-corresponding-devices by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 09:39:40 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 256341:VIDEO ENCODING AND DECODING METHODS AND CORRESPONDING DEVICES</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">VIDEO ENCODING AND DECODING METHODS AND CORRESPONDING DEVICES</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to the field of video compression and, more specifically, to a video encoding method applied to an input sequence of frames in which each frame is subdivided into blocks of arbitrary size. This method comprises, for at least a part of said blocks of the current frame, the steps of generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame, generating from said motion-compensated frames residual signals, using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques, and coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream. According to the invention, said method is such that, when using said MP algorithm, a specific dictionary is available at the encoding side for each block shape respectively. According to another implementation, it is also possible to use several specific dictionaries. In this second solution, if several dictionaries are available at the encoding side, a bitstream syntax is defined for placing, at a predetermined level, flags provided to indicate which dictionary should be used and placed for example at the atom level, at the block level, at the macroblock level or at the picture level.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
WO 2005/015501<br><br>
PCT/IB2004/002478<br><br>
"VIDEO ENCODING AND DECODING METHODS AND CORRESPONDING DEVICES"<br>
FIELD OF THE INVENTION<br>
The present invention generally relates to the field of video compression and, for instance, more particularly to the video standards of the MPEG family (MPEG-1, MPEG-2, MPEG-4) and to the video coding recommendations of the ITU H26X family (H.261, H.263 and extensions). More specifically, the invention relates to a video encoding method applied to an input sequence of frames in which each frame is subdivided into blocks of arbitrary size, said method comprising for at least a part of said blocks of the current frame the steps of:<br>
-	generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame ;<br>
-	generating from said motion-compensated frames residual signals ;<br>
-	using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques ;<br>
- coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream.<br>
BACKGROUND OF THE INVENTION<br>
In the current video standards (up to the video coding MPEG-4 standard and H.264 recommendation), the video, described in terms of one luminance channel and two chrominance ones, can be compressed thanks to two coding modes applied to each channel : the "intra" mode, exploiting in a given channel the spatial redundancy of the pixels (picture elements) within each image, and the "inter" mode, exploiting the temporal redundancy between separate images (or frames). The inter mode, relying on a motion compensation operation, allows to describe an image from one (or more) previously decoded image(s) by encoding the motion of the pixels from one (or more) image(s) to another one. Usually, the current image to be coded is partitioned into independent blocks (for instance, of size 8 x 8 or 16 x 16 pixels in MPEG-4, or of size 4 x 4, 4 x 8, 8 x 4, 8 x 8, 8x16,16x8 and 16 x 16 in H.264), each of them being assigned a motion vector (the three channels share such a motion description). A prediction of said image can then be constructed by displacing pixel blocks from a reference image according to the set of<br><br>
motion vectors associated to each block. Finally, the difference, or residual signal, between the current image to be encoded and its motion-compensated prediction can be encoded in the intra mode (with 8x8 discrete cosine transforms - or DCTs - for MPEG-4, or 4 x 4 DCTs for H.264 in the main level profile).<br>
The DCT is probably the most widely used transform, because it offers a good compression efficiency in a wide variety of coding situations, especially at medium and high bitrates. However, at low bitrates, the hybrid motion compensated DCT structure may be not able to deliver an artefact-free sequence for two reasons. First, the structure of the motion-compensated inter prediction grid becomes visible, with blocking artifacts. Moreover, the block edges of the DCT basis functions become visible in the image grid, because too few coefficients are quantized - and too coarsely - to make up for these blocking artifacts and to reconstruct smooth objects in the image.<br>
The document "Very low bit-rate video coding based on matching pursuits", R.Neff and A. Zakhor, IEEE Transactions on Circuits and Systems for Video Technology, vol.7, n°l, February 1997, pp.158-171, describes a new motion-compensated system including a video compression algorithm based on the so-called matching pursuit (MP) algorithm, a technique developed about ten years ago (see the document "Matching pursuits with time-frequency dictionaries", S.G.Mallat and Z.Zhang, IEEE Transactions on Signal Processing, vol.41, n°12, December 1993, pp.3397-3414). Said technique provides a way to iteratively decompose any function or signal (for example, image, video,...) into a linear expansion of waveforms belonging to a redundant dictionary of basis functions, well localized both in time and frequency and called atoms. A general family of time-frequency atoms can be created by scaling, translating and modulating a single function g(t) € L2(R) supposed to be real and continuously differentiable. These dictionary functions may be designated by:<br>
gy(t)  έ  G  (G = dictionary set),	(1)<br>
7 (= gamma) being an indexing parameter associated to each particular dictionary element (or atom). As described in the first cited document, assuming that the functions gy{t) have<br>
unit norm, i.e. =l, the decomposition of a one-dimensional time signal f(t)<br>
begins by choosing y to maximize the absolute value of the following inner product:<br>
p = <f rr>,	(2)<br><br><br><br><br><br><br>
To obtain this parameter set, a training set of motion residual images was decomposed using a dictionary derived from a much larger set of parameter triples. The dictionary elements which were most often matched to the training images were retained in the reduced set. The obtained dictionary was specifically designed so that atoms can freely match the structure of motion residual image when their influence is not confined to the boundaries of the block they lie in (see Fig.2 shoving the example of an atom placed in a block-divided image without block-restrictions).<br><br>
However, it has been recently proposed, in a European patent application filed on August 5, 2003, by the applicant with the number EP03300081.1 (PHFR030085), a hybrid motion-compensated coding system using atoms that are confined to block boundaries, as depicted in Fig.3. More precisely, the invention described and claimed in said patent application mainly relates to a video encoding method applied to an input sequence of frames in which each frame is subdivided into blocks of arbitrary size, said method comprising for at least a part of said blocks of the current frame the steps of:<br>
-	generating on a block basis motion-compensated frames, each one being<br>
obtained from each current original frame and a previous reconstructed frame;<br>
-	generating from said motion-compensated frames residual signals ;<br>
-using a so-called matching pursuit (MP) algorithm for decomposing each of<br>
said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques (the words "at least a part of said blocks" used above mean that some blocks or all the blocks are concerned by the implementation of the invention, the other ones being processed by these other techniques, which justifies the fact that the coding system is called "hybrid");<br>
-	coding said atoms and the motion vectors determined during the motion<br>
compensation step, for generating an output coded bitstream ;<br>
said method being such that, when using said MP algorithm, any atom acts only on one block B at a time, said block-restriction leading to the fact that the reconstruction of a<br>
residual signal f is obtained from a dictionary that is composed of basis functions g<br>
restricted to the block B corresponding to the indexing parameter yR, according to the following 2D spatial domain operation :<br><br>
The main interest of this previous approach is to better model the blocky structure of residual signals, to augment the dictionary diversity for the same coding cost and to offer the possibility of alternating MP and DCT transforms since there is no interference across block boundaries (it also avoids the need to resort to overlapped motion compensation to limit blocking artefacts). The main elements useful to understand this previous implementation are recalled with reference to Figs 4 to 7.<br><br>
A simplified block diagram of a video encoding device implementing a hybrid video coder using multiple coding engines is shown in Fig.4. Several coding engines implement predetermined coding techniques, for instance a coding engine 41 can implement the intra-DCT coding method, a second one 42 the inter-DCT coding method, and a third one 43 the matching pursuit algorithm. Each frame of the input video sequence is received ("video signal") by a block partitioner device 44, which partitions the image into individual blocks of varying size, and decides which coding engine will process the current original block. The decisions representing the block position, its size and the selected coding engine is then inserted into the bitstream by a coding device 45. The current original signal block is then transferred to the selected coding engine (the engine 43 in the situation illustrated in Fig.4).<br>
A matching pursuit coding engine is illustrated in Fig.5. Each of the original signal blocks of the input video sequence assigned to the coding engine 43 is received on one side by motion compensating means 51 for determining motion vectors (said motion vectors are conventionally found using the block matching algorithm), and the vectors thus obtained are coded by motion vector coding means 52, the coded vectors being delivered to a multiplexer 53 (referenced, but not shown). On the other side, a subtracter 54 delivers on its output the residual signal between the current image and its prediction. Said residual signal is then decomposed into atoms (the dictionary of atoms is referenced 57) and the atom parameters thus determined (module 55) are coded (module 56). The coded motion vectors and atom parameters then form a bitstream that is sent to match a predefined condition for each frame of the sequence.<br>
The encoding engine 43 carries out a method of coding an input bitstream that comprises the following steps. First, as in most coding structures, the original frames of the input sequence are motion-compensated (each one is motion-compensated on the basis of the previous reconstructed frame, and the motion vectors determined during said motion-compensated step are stored in view of their later transmission). Residual signals are then generated by difference between the current frame and the associated motion-compensated prediction. Each of said residual signals is then compared with a dictionary of functions consisting of a collection of 2D separable Gabor functions, in order to generate a dictionary structure g (t) specified by the indexing parameter γ an expansion coefficient<br>
p(n) and a residual Rn(t) - p. gy (t) which is passed on to the next stage of this iterative procedure. Once the atom parameters are found, they can be coded (together with the<br><br><br><br>
decoded atom parameters to an atom device 72 (the dictionary of atoms is referenced 73) which reconstructs the matching pursuit functions at the decoded position within the assigned video block to form the decoded residual signal. The entropy decoder device also outputs motion vectors which are fed into a motion compensation device 74 to form a motion prediction signal from previously reconstructed video signals. The motion prediction and the reconstructed residual signal are then summed in an adder 75 to produce a video signal reconstructed block.<br>
The interest of the previous approach, recalled above in a detailed manner, resides in the fact that because a single atom cannot span several blocks, it does not have to deal with the high-frequency discontinuities at block edges. Instead, it can be adapted to block boundaries, and even to block sizes, by designing block-size dependent dictionaries. Moreover, since overlapped motion compensation is no longer mandatory to preserve the MP efficiency, classical motion compensation may be used. However, with such an approach, it is not sure that the dictionary is well adapted to the structure of the signal to be modelled, when its atoms are confined in arbitrarily sized blocks.<br>
SUMMARY OF THE INVENTION<br>
It is therefore an object of the invention to propose a video encoding method based on matching pursuit algorithm and solving the above-indicated problem of adaptation.<br>
To this end, the invention relates to a video encoding method such as defined in the introductory part of the description and which is moreover such that, when using said MP algorithm, a specific dictionary is available at the encoding side for each block shape respectively.<br>
In another implementation of the method according to the invention, when using said MP algorithm, several dictionaries are available at the encoding side, and a bitstream syntax is defined for placing at a predetermined level flags provided to indicate which dictionary should be used.<br>
It is another object of the invention to propose video encoding devices allowing to carry out these two implementations of the method according to the invention.<br>
It is still an object of the invention to propose video decoding methods and devices allowing to decode signals coded by means of said video encoding methods and devices.<br><br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The present invention will now be described, by way of example, with reference to the accompanying drawing in which :<br>
-	Fig.l allows a visualization of the 400 basis functions of the 2D Gabor dictionary used in the implementation of the matching pursuit algorithm ;<br>
-	Fig.2 illustrates the example of an atom placed in a block-divided image without block-restrictions;<br>
-	Fig.3 illustrates the case of a block-restricted matching pursuit residual coding, with an atom being confined into the motion-compensated grid and acting only on a block at a time ;<br>
-	Fig.4 illustrates an example of hybrid video encoder ;<br>
-	Fig. 5 shows an example of a video encoding device for implementing a MP algorithm;<br>
-	Fig.6 illustrates an example of hybrid video decoder according to the invention ;<br>
-	Fig.7 shows an example of a video decoding device implementing the MP algorithm.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
A simplified block diagram of a video encoding device implementing a matching pursuit algorithm has been described above in relation with Fig. 5. This encoding device carries out a method of coding an input bitstream that comprises the same steps as described above :<br>
-	the original frames of the input sequence are motion-compensated ;<br>
-	residual signals are generated by difference between the current frame and the associated motion-compensated prediction;<br>
-	each of said residual signals is compared with a dictionary of functions consisting of a collection of 2D separable Gabor functions ;<br>
-	once the atom parameters are found, they can be coded (together with the motion vectors previously determined), the coded signals thus obtained forming the bitstream sent to the decoder.<br>
The technical solution now proposed according to the invention consists in having separate dictionaries, one for each block shape respectively (4 x 4, 4 x 8, 8 x 4, 8 x 8, 8 x 16,16 x 8,16 x 16, for example): with such a rule used by the encoder, the video decoder would implicitly know which dictionary an atom refers to. According to another<br><br>
implementation of the invention, the technical solution can also consists in providing several dictionaries, available at both the encoding side and decoding side, and in defining a bitstream syntax, which lets the encoder say to the decoder which dictionary should be used : for instance, the codeword MP_dictionary_l tells the decoder that the next atom will refer to the first dictionary, MP_dictionary__2 tells the decoder to switch to the second dictionary, and so on, such codewords, or flags, being placed for example at the atom level, the block level, the macroblock level or the picture level.<br><br><br><br><br><br><br>
CLAIMS :<br>
1.	A video encoding method applied to an input sequence of frames in which each frame is subdivided into blocks of arbitrary size, said method comprising for at least a part of said blocks of the current frame the steps of:<br>
-	generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	generating from said motion-compensated frames residual signals ;<br>
-	using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques ;<br>
-	coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream ;<br>
said method being further characterized in that, when using said MP algorithm, a specific dictionary is available at the encoding side for each block shape respectively.<br>
2.	A video encoding method according to claim 1, characterized in that, when using said MP algorithm, several dictionaries are available at the encoding side, a bitstream syntax being defined for placing at a predetermined level flags provided to indicate which dictionary should be used.<br>
3.	A method according to claim 2, characterized in that said flags are placed at the atom level.<br>
4.	A method according to claim 2, characterized in that said flags are placed at the block level.<br>
5.	A method according to claim 2, characterized in that said flags are placed at the macroblock level.<br>
6.	A method according to claim 2, characterized in that said flags are placed at the picture level.<br>
7.	A video encoding device applied to an input sequence of frames in which each frame is subdivided into blocks of arbitrary size, said device applying to at least a part of said blocks of the current frame the following means :<br><br>
-	means for generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	means for generating from said motion-compensated frames residual<br><br>
signals ;<br>
-	means for performing a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques;<br>
-	means for coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream ;<br>
said device being further characterized in that, when using said MP algorithm, several dictionaries are available at the encoding side, one for each block shape. 8.      A video decoding method for decoding a coded bitstream generated by implementation of a video encoding method applied to an input sequence of frames in which each block is subdivided into blocks of arbitrary size, said encoding method comprising for at least a part of said blocks of the current frame the steps of:<br>
-	generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	generating from said motion-compensated frames residual signals ;<br>
-	using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques;<br>
-	coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream ;<br>
a specific dictionary being available at the encoding side for each block shape respectively, said decoding method comprising the steps of:<br>
-	decoding said atoms and motion vectors;<br>
-	using the MP algorithm for reconstructing residual signals ;<br>
-	generating from said reconstructed signals and predicted signals built from the coded motion vectors output reconstituted signal corresponding to the original frames of said input sequence ;<br>
said decoding method being further characterized in that the same dictionaries as at the encoding side are available at the decoding side, one for each block shape respectively.<br><br>
9.	A video decoding device for decoding a coded bitstream generated by<br>
implementation of a video encoding method applied to an input sequence of frames<br>
in which each block is subdivided into blocks of arbitrary size, said encoding<br>
method comprising for at least a part of said blocks of the current frame the steps<br>
of:<br>
-	generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	generating from said motion-compensated frames residual signals ;<br>
-	using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques;<br>
-	coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream ;<br>
a specific dictionary being available at the encoding side for eache block shape respectively, said decoding device applying to the concerned blocks the following means :<br>
-	means for decoding said atoms and motion vectors ;<br>
-	means for performing the MP algorithm, for reconstructing residual signals;<br>
-	means for generating from said reconstructed signals and predicted signals built from the coded motion vectors output reconstituted signal corresponding to the original frames of said input sequence ;<br>
said decoding device being further characterized in that the same dictionaries as at the encoding side are available at the decoding side, one for each block shape respectively.<br>
10.	A video encoding device applied to an input sequence of frames in which each<br>
frame is subdivided into blocks of arbitrary size, said device applying to at least a<br>
part of said blocks of the current frame the following means :<br>
-	means for generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	means for generating from said motion-compensated frames residual signals ;<br><br>
-	means for performing a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques ;<br>
-	means for coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream ;<br>
said device being further characterized in that, when using said MP algorithm, several dictionaries are available at the encoding side, and a bitstream syntax is defined for placing at a predetermined level flags provided to indicate which dictionary should be used.<br>
11.	A method according to claim 10, characterized in that said flags are placed at the atom level.<br>
12.	A method according to claim 10, characterized in that said flags are placed at the block level.<br>
13.	A method according to claim 10, characterized in that said flags are placed at the macroblock level.<br>
14.	A method according to claim 10, characterized in that said flags are placed at the picture level.<br>
15.	A video decoding method for decoding a coded bitstream generated by implementation of a video encoding method applied to an input sequence of frames in which each block is subdivided into blocks of arbitrary size, said encoding method comprising for at least a part of said blocks of the current frame the steps of:<br><br>
-	generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	generating from said motion-compensated frames residual signals;<br>
-	using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques;<br>
-	coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream;<br>
several dictionaries being available at the encoding side, together with a bitstream syntax defined for placing at a predetermined level flags provided to indicate which dictionary should be used, said decoding method comprising the steps of:<br>
-	decoding said atoms and motion vectors,<br><br>
• using the MP algorithm for reconstructing residual signals;<br>
-	generating from said reconstructed signals and predicted signals built from the<br>
coded motion vectors output reconstituted signal corresponding to the original frames of<br>
said input sequence;<br>
said decoding method being further characterized in that the same dictionaries as at the<br>
encoding side are available at the decoding side, and a step is provided for reading the<br>
transmitted flags and, when using the MP algorithm, selecting the corresponding<br>
dictionary.<br>
16.    A video decoding device for decoding a coded bitstream generated by<br>
implementation of a video encoding method applied to an input sequence of frames in<br>
which each block is subdivided into blocks of arbitrary size, said encoding method<br>
comprising for at least a part of said blocks of the current frame the steps<br>
of:<br>
-	generating on a block basis motion-compensated frames, each one being obtained from each current original frame and a previous reconstructed frame;<br>
-	generating from said motion-compensated frames residual signals ;<br>
-	using a so-called matching pursuit (MP) algorithm for decomposing each of said generated residual signals into coded dictionary functions called atoms, the other blocks of the current frame being processed by means of other coding techniques ;<br>
-	coding said atoms and the motion vectors determined during the motion compensation step, for generating an output coded bitstream;<br>
several dictionaries being available at the encoding side, together with a bitstream syntax defined for placing at a predetermined level flags provided to indicate which dictionary should be used, said decoding device applying to the concerned blocks the following means:<br>
-	means for decoding said atoms and motion vectors,<br>
-	means for performing the MP algorithm, for reconstructing residual signals ;<br>
-	means for generating from said reconstructed signals and predicted signals built from the coded motion vectors output reconstituted signal corresponding to the original frames of said input sequence ;<br>
said decoding device being further characterized in that the same dictionaries as at the encoding side are available at the decoding side, and means are provided for reading the<br><br>
0 2005/015501	PCT/IB2004/002478<br>
17 transmitted flags and, when performing the MP algorithm, selecting the corresponding<br>
dictionary.<br><br></f></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDUyNC1jaGVucC0yMDA2ICBjb21wbGV0ZSBzcGVjaWZpY2F0aW9uIGFzIGdyYW50ZWQucGRm" target="_blank" style="word-wrap:break-word;">0524-chenp-2006  complete specification as granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBBTUVOREVEICBQQUdFUyBPRiBTUEVDSUZJQ0FUSU9OICAxNS0wNC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   AMENDED  PAGES OF SPECIFICATION  15-04-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBBTUVOREVEICBQQUdFUyBPRiBTUEVDSUZJQ0FUSU9OICAxOS0xMS0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   AMENDED  PAGES OF SPECIFICATION  19-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBBTUVOREVEIENMQUlNUyAgMTUtMDQtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   AMENDED CLAIMS  15-04-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBBTUVOREVEIENMQUlNUyAgMTktMTEtMjAxMi5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   AMENDED CLAIMS  19-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBDT1JSRVNQT05ERU5DRSBPVEhFUlMgIDA0LTEwLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   CORRESPONDENCE OTHERS  04-10-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBDT1JSRVNQT05ERU5DRSBPVEhFUlMgMTUtMDQtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   CORRESPONDENCE OTHERS 15-04-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBFWEFNSU5BVElPTiBSRVBPUlQgUkVQTFkgUkVDRUlWRUQgIDE5LTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   EXAMINATION REPORT REPLY RECEIVED  19-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBGT1JNLTEgIDE5LTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   FORM-1  19-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBGT1JNLTMgIDE1LTA0LTIwMTMucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   FORM-3  15-04-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBGT1JNLTMgIDE5LTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   FORM-3  19-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgICBGT1JNLTUgIDE5LTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006   FORM-5  19-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIEFTU0lHTk1FTlQgMTQtMDYtMjAxMC5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  ASSIGNMENT 14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIENPUlJFU1BPTkRFTkNFIE9USEVSUyAgMTQtMDMtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  CORRESPONDENCE OTHERS  14-03-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYgIGZvcm0tMSAxNC0wNi0yMDEwLnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006  form-1 14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIEZPUk0tMiAxNC0wNi0yMDEwLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  FORM-2 14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIEZPUk0tNiAgMDctMDItMjAwOC5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  FORM-6  07-02-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIEZPUk0tNiAxNC0wNi0yMDEwLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  FORM-6 14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIFBPV0VSIE9GIEFUVE9STkVZICAwMy0wNC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  POWER OF ATTORNEY  03-04-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIFBPV0VSIE9GIEFUVE9STkVZIDE0LTA2LTIwMTAucGRm" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  POWER OF ATTORNEY 14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgIFJFUVVFU1QgRk9SIFBPU1QgREFUSU5HICAxMS0wMy0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006  REQUEST FOR POST DATING  11-03-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgQ09SUkVTUE9OREVOQ0UgT1RIRVJTLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006 CORRESPONDENCE OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgRk9STSAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006 FORM 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgRk9STSAxOC5wZGY=" target="_blank" style="word-wrap:break-word;">524-CHENP-2006 FORM 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006 FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LUNIRU5QLTIwMDYgRk9STSA2LnBkZg==" target="_blank" style="word-wrap:break-word;">524-CHENP-2006 FORM 6.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">524-chenp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtY29ycmVzcG9uZG5lY2Utb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtZGVzY3JpcHRpb24oY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">524-chenp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtZm9ybSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtZm9ybSAyNi5wZGY=" target="_blank" style="word-wrap:break-word;">524-chenp-2006-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtZm9ybSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtZm9ybSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI0LWNoZW5wLTIwMDYtcGN0LnBkZg==" target="_blank" style="word-wrap:break-word;">524-chenp-2006-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="256340-an-improved-structure-of-a-dual-surface-optical-disc.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="256342-a-process-for-recovering-ruthenium-from-spent-catalysts-comprising-ruthenium-oxide.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>256341</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>524/CHENP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>23/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>07-Jun-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>04-Jun-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>10-Feb-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>TRIDENT MICROSYSTEMS (FAR EAST) LTD.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>UGLAND HOUSE, SOUTH CHURCH STREET, GRAND CAYMAN</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>VALENTE, STEPHANE</td>
											<td>C/O SOCIETE CIVILE SPID, 156 BOULEVARD HAUSSMANN, F--75008 PARIS, FRANCE</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06T9/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB04/02478</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-07-14</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>03300085.2</td>
									<td>2003-08-12</td>
								    <td>EUROPEAN UNION</td>
								</tr>
								<tr>
									<td>2</td>
									<td>03300084.5</td>
									<td>2003-08-12</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/256341-video-encoding-and-decoding-methods-and-corresponding-devices by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 09:39:41 GMT -->
</html>
