<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/268869-apparatus-for-encoding-an-information-signal-and-apparatus-for-decoding-an-encoded-information-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:25:58 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 268869:&quot;APPARATUS FOR ENCODING AN INFORMATION SIGNAL AND APPARATUS FOR DECODING AN ENCODED INFORMATION SIGNAL&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;APPARATUS FOR ENCODING AN INFORMATION SIGNAL AND APPARATUS FOR DECODING AN ENCODED INFORMATION SIGNAL&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A very coarse quantization exceeding the measure determined by the masking threshold without or only very little quality losses is enabled by quantizing not immediately the prefiltered signal, but a prediction error obtained by forward-adaptive prediction of the prefiltered signal. Due to the forward adaptivity, the quantizing error has no negative effect on the prediction on the decoder side.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Information Signal Encoding<br>
Description<br>
The present invention relates to information signal<br>
encoding, such as audio or video encoding.<br>
The usage of digital audio encoding in new communication<br>
networks as well as in professional audio productions for<br>
bi-directional real time communication requires a very<br>
inexpensive algorithmic encoding as well as a very short<br>
encoding delay. A typical scenario where the application of<br>
digital audio encoding becomes critical in the sense of the<br>
delay time exists when direct, i.e. unencoded, and<br>
transmitted, i.e. encoded and decoded signals are used<br>
simultaneously. Examples therefore are live productions<br>
using cordless microphones and simultaneous (in-ear)<br>
monitoring or "scattered" productions where artists play<br>
simultaneously in different studios. The tolerable overall<br>
delay time period in these applications is less than 10 ms.<br>
If, for example, asymmetrical participant lines are used<br>
for communication, the bit rate is an additional limiting<br>
factor.<br>
The algorithmic delay of standard audio encoders, such as<br>
MPEG-1 3 (MP3), MPEG-2 AAC and MPEG-2/4 low delay ranges<br>
from 20 ms to several 100 ms, wherein reference is made,<br>
for example, to the article M. Lutzky, G. Schuller, M.<br>
Gayer; U. Kraemer, S. Wabnik: "A guideline to audio codec<br>
delay", presented at the 116th AES Convention, Berlin, May<br>
2004. Voice encoders operate at lower bit rates and with<br>
less algorithmic delay, but provide merely a limited audio<br>
quality.<br>
The above outlined gap between the standard audio encoders<br>
on the one hand and the voice encoders on the other hand<br>
is, for example, closed by a type of encoding scheme<br>
described in the article B. Edler, C. Faller and G.<br><br>
Schuller, "Perceptual Audio Coding Using a Time-Varying<br>
Linear Pre- and Postfilter", presented at 109th AES<br>
Convention, Los Angeles, September 2000, according to which<br>
the signal to be encoded is filtered with the inverse of<br>
the marking threshold on the encoder side and is<br>
subsequently quantized to perform irrelevance reduction,<br>
and the quantized signal is supplied to entropy encoding<br>
for performing redundancy reduction separate from the<br>
irrelevance reduction, while the quantized prefiltered<br>
signal is reconstructed on the decoder side and filtered in<br>
a postfilter with the marking threshold as transmission<br>
function. Such an encoding scheme, referred to as ULD<br>
encoding scheme below, results in a perceptual quality that<br>
can be compared to standard audio encoders, such as MP3,<br>
for bit rates of approximately 80 kBit/s per channel and<br>
higher. An encoder of this type is, for example, also<br>
described in WO 2005/078703 Al.<br>
Particularly, the ULD encoders described there use<br>
psychoacoustically controlled linear filters for forming<br>
the quantizing noise. Due to their structure, the<br>
quantizing noise is always on the given threshold, even<br>
when no signal is in a given frequency domain. The noise<br>
remains inaudible, as long as it corresponds to the<br>
psychoacoustic masking threshold. For obtaining a bit rate<br>
that is even smaller than the bit rate as predetermined by<br>
this threshold, the quantizing noise has to be increased,<br>
which makes the noise audible. Particularly, the noise<br>
becomes audible in domains without signal portions.<br>
Examples therefore are very low and very high audio<br>
frequencies. Normally, there are only very low signal<br>
portions in these domains, while the masking threshold is<br>
high. If the masking threshold is increased uniformly<br>
across the whole frequency domain, the quantizing noise is<br>
at the increased threshold, even when there is no signal,<br>
so that the quantizing noise becomes audible as a signal<br>
that sounds spurious. Subband-based encoders do not have<br><br>
this problem, since the same simply quantize subbands<br>
having smaller signals than the threshold to zero.<br>
The above-mentioned problem that occurs when the allowed<br>
bit rate falls below the minimum bit rate, which causes no<br>
spurious quantizing noise and which is determined by the<br>
masking threshold, is not the only one. Further, the ULD<br>
encoders described in the above references suffer from a<br>
complex procedure for obtaining a constant data rate,<br>
particularly since an iteration loop is used, which has to<br>
be passed in order to determine, per sampling block, an<br>
amplification factor value adjusting a dequantizing step<br>
size.<br>
It is the object of the present invention to provide an<br>
information encoding scheme that makes it possible to allow<br>
the short delay time typical for ULD encoder types at a low<br>
bit rate and yet a high encoding quality.<br>
This object is achieved by apparatuses according to claim 1<br>
or 24, methods according to claim 44 or 45 as well as an<br>
encoder according to claim 4 7 and a decoder according to<br>
claim 48.<br>
The central idea of the present invention is the finding<br>
that extremely coarse quantization exceeding the measure<br>
determined by the masking threshold is made possible,<br>
without or only very little quality losses, by not directly<br>
quantizing the prefiltered signal but a prediction error<br>
obtained by forward-adaptive prediction of the prefiltered<br>
is. Due to the forward adaptivity, the quantizing error has<br>
no negative effect on the prediction coefficient.<br>
According to a further embodiment, the prefiltered signal<br>
is even quantized in a nonlinear manner or even clipped,<br>
i.e. quantized via a quantizing function, which maps the<br>
unquantized values of the prediction error on quantizing<br>
indices of quantizing stages, and whose course is steeper<br><br>
below a threshold than above a threshold. Thereby, the<br>
noise PSD increased in relation to the masking threshold<br>
due to the low available bit rate adjusts to the<br>
signal PSD, so that the violation of the masking threshold<br>
does not occur at spectral parts without signal portion,<br>
which further improves the listening quality or maintains<br>
the listening quality, respectively, despite a decreasing<br>
available bit rate.<br>
According to a further embodiment of the present invention,<br>
quantization is even quantized or limited, respectively, by<br>
clipping, namely by quantizing to a limited and fixed<br>
number of quantizing levels or stages, respectively. By<br>
prediction of the prefiltered signal via forward-adaptive<br>
prediction, the coarse quantization has no negative effect<br>
on the prediction coefficients themselves. By quantizing to<br>
a fixed number of quantizing levels, prevention of<br>
iteration for obtaining a constant bit rate is inherently<br>
enabled.<br>
According to a further embodiment of the present invention,<br>
a quantizing step size or stage height, respectively,<br>
between the fixed number of quantizing levels is determined<br>
in a backward-adaptive manner from previous quantizing<br>
level indices obtained by quantization, so that, on the one<br>
hand, despite a very low number of quantizing levels, a<br>
better or at least best possible quantization of the<br>
prediction error or residual signal, respectively, can be<br>
obtained, without having to provide further side<br>
information to the decoder side. On the other hand, it is<br>
possible to ensure that transmission errors during<br>
transmission of the quantized residual signal to the<br>
decoder side only have a short-time effect on the decoder<br>
side with appropriate configuration of the backward-<br>
adaptive step size adjustment.<br><br>
Preferred embodiments of the invention will be discussed<br>
below with reference to the accompanying drawings. They<br>
show:<br>
Fig. 1 a block diagram of an encoder according to an<br>
embodiment of the present invention;<br>
Figs. 2a/b graphs showing exemplarily the course of the<br>
noise spectrum in relation to the masking<br>
threshold and signal power spectrum density for<br>
the case of the encoder according to claim 1<br>
(graph a) or for a comparative case of an encoder<br>
with backward-adaptive prediction of the<br>
prefiltered signal and iterative and masking<br>
threshold block-wise quantizing step size<br>
adjustment (graph b), respectively;<br>
Figs. 3a/3b and 3c graphs showing exemplarily the signal<br>
power spectrum density in relation to the noise<br>
or error power spectrum density, respectively,<br>
for different clip extensions or different<br>
numbers of quantizing levels, respectively, for<br>
the case that, like in the encoder of Fig. 1,<br>
forward-adaptive prediction of the prefiltered<br>
signal but still an iterative quantizing step<br>
size adjustment is performed;<br>
Fig. 4 a block diagram of a structure of the coefficient<br>
encoder in the encoder of Fig. 1 according to an<br>
embodiment of the present invention;<br>
Fig. 5 a block diagram of a decoder for decoding an<br>
information signal encoded by the encoder of<br>
Fig. 1 according to an embodiment of the present<br>
invention;<br>
Fig. 6 a block diagram of a structure of the coefficient<br>
encoders in the encoder of Fig. 1 or the decoder<br><br>
of Fig. 5 according to an embodiment of the<br>
present invention;<br>
Fig. 7 a graph for illustrating listening test results;<br>
and<br>
Figs. 8a to 8c graphs of exemplary quantizing functions<br>
that can be used in the quantizing and<br>
quantizing/clip means, respectively, in Figs. 1,<br>
4, 5 and 6.<br>
Before embodiments of the present invention will be<br>
discussed in more detail with reference to the drawings,<br>
first, for a better understanding of the advantages and<br>
principles of these embodiments, a possible implementation<br>
of an ULD-type encoding scheme will be discussed as<br>
comparative example, based on which the essential<br>
advantages and considerations underlying the subsequent<br>
embodiments, which have finally led to these embodiments,<br>
can be illustrated more clearly.<br>
As has already been described in the introduction of the<br>
description, there is a need for an ULD version for lower<br>
bit rates of, for example, 64 k Bit/s, with comparable<br>
perceptual quality, as well as simpler scheme for obtaining<br>
a constant bit rate, particularly for intended lower bit<br>
rates. Additionally, it would be advantageous when the<br>
recovery time after a transmission error would remain low<br>
or at a minimum.<br>
For redundancy reduction of the psychoacoustically<br>
preprocessed signal, the comparison ULD encoder uses a<br>
sample-wise backward-adaptive closed-loop prediction. This<br>
means that the calculation of prediction coefficients in<br>
encoder and decoder is based merely on past or already<br>
quantized and reconstructed signal samples. For obtaining<br>
an adaption to the signal or the prefiltered signal,<br>
respectively, a new set of predictor coefficients is<br><br>
calculated again for every sample. This results in the<br>
advantage that long predictors or prediction value<br>
determination formulas, i.e. particularly predictors having<br>
a high number of predictor coefficients can be used, since<br>
there is no requirement to transmit the predictor<br>
coefficients from encoder to decoder side. On the other<br>
hand, this means that the quantized prediction error has to<br>
be transmitted to the decoder without accuracy losses, for<br>
obtaining prediction coefficients that are identical to<br>
those underlying the encoding process. Otherwise, the<br>
predicted or predicated values, respectively, in the<br>
encoder and decoder would not be identical to each other,<br>
which would cause an instable encoding process. Rather, in<br>
the comparison ULD encoder, periodical reset of the<br>
predictor both on encoder and decoder side is required to<br>
allow selective access to the encoded bit stream as well as<br>
to stop a propagation of transmission errors. However, the<br>
periodic resets cause bit rate peaks, which presents no<br>
problem for a channel with variable bit rate, but for<br>
channels with fixed bit rate where the bit rate peaks limit<br>
the lower limit of a constant bit rate adjustment.<br>
As will result from the subsequent more detailed<br>
description of the ULD comparison encoding scheme with the<br>
embodiments of the present invention, these embodiments<br>
differ from the comparison encoding scheme by using a<br>
block-wise forward-adaptive prediction with a backward-<br>
adaptive quantizing step size adjustment instead of a<br>
sample-wise backward-adaptive prediction. On the one hand,<br>
this has the disadvantage that the predictors should be<br>
shorter in order to limit the amount of required side<br>
information for transmitting the required prediction<br>
coefficients towards the encoder side, which again might<br>
result in reduced encoder efficiency, but, on the other<br>
hand, this has the advantage that the procedure of the<br>
subsequent embodiments still functions effectively for<br>
higher quantizing errors, which are a result of reduced bit<br><br>
rates, so that the predictor on the decoder side can be<br>
used for quantizing noise shaping.<br>
As will also result from the subsequent comparison,<br>
compared to the comparison ULD encoder, the bit rate is<br>
limited by limiting the range of values of the prediction<br>
remainder prior to transmission. This results in noise<br>
shaping modified compared to the comparison ULD encoding<br>
scheme, and also leads to different and less spurious<br>
listening artifacts. Further, a constant bit rate is<br>
generated without using iterative loops. Further, "reset"<br>
is inherently included for every sample block as result of<br>
the block-wise forward adaption. Additionally, in the<br>
embodiments described below, an encoding scheme is used for<br>
prefilter coefficients and forward prediction coefficients,<br>
which uses difference encoding with backward-adaptive<br>
quantizing step size control for an LSF (line spectral<br>
frequency) representation of the coefficients. The scheme<br>
provides block-wise access to the coefficients, generates a<br>
constant side information bit rate and is, above that,<br>
robust against transmission errors, as will be described<br>
below.<br>
In the following, the comparison ULD encoder and decoder<br>
structure will be described in more detail, followed by the<br>
description of embodiments of the present invention and the<br>
illustration of its advantages in the transmission from<br>
higher constant bit rates to lower bit rates.<br>
In the comparison ULD encoding scheme, the input signal of<br>
the encoder is analyzed on the encoder side by a perceptual<br>
model or listening model, respectively, for obtaining<br>
information about the perceptually irrelevant portions of<br>
the signal. This information is used to control a prefilter<br>
via time-varying filter coefficients. Thereby, the<br>
prefilter normalizes the input signal with regard to its<br>
masking threshold. The filter coefficients are calculated<br><br>
once for every block of 128 samples each, quantized and<br>
transmitted to the encoder side as side information.<br>
After multiplication of the prefiltered signal with an<br>
amplification factor by subtracting the backward-adaptive<br>
predicted signal, the prediction error is quantized by a<br>
uniform quantizer, i.e. a quantizer with uniform step size.<br>
As already mentioned above, the predicted signal is<br>
obtained via sample-wise backward-adaptive closed-loop<br>
prediction,. Accordingly, no transmission of prediction<br>
coefficients to the decoder is required. Subsequently, the<br>
quantized prediction residual signal is entropy encoded.<br>
For obtaining a constant bit rate, a loop is provided,<br>
which repeats the steps of multiplication, prediction,<br>
quantizing and entropy-encoding several times for every<br>
block of prefiltered samples. After iteration, the highest<br>
amplification factor of a set of predetermined<br>
amplification values is determined, which still fulfills<br>
the constant bit rate condition. This amplification value<br>
is transmitted to the decoder. If, however, an<br>
amplification value smaller than one is determined, the<br>
quantizing noise is perceptible after decoding, i.e. its<br>
spectrum is shaped similar to the masking threshold, but<br>
its overall power is higher than predetermined by the<br>
prediction model. For portions of the input signal<br>
spectrum, the quantizing noise could even get higher than<br>
the input signal spectrum itself, which again generates<br>
audible artifacts in portions of the spectrum, where<br>
otherwise no audible signal would be present, due to the<br>
usage of a predictive encoder. The effects caused by<br>
quantizing noise represent a limiting factor when lower<br>
constant bit rates are of interest.<br>
Continuing with the description of the comparison ULD<br>
scheme, the prefilter coefficients are merely transmitted<br>
as intraframe LSF differences, and also only as soon as the<br>
same exceed a certain limit. For avoiding transmission<br>
error propagation for an unlimited period, the system is<br><br>
reset from time to time. Additional techniques can be used<br>
for minimizing a decrease in perception of the decoded<br>
signal in the case of transmission errors. The transmission<br>
scheme generates a variable side information bit rate,<br>
which is leveled in the above-described loop by adjusting<br>
the above-mentioned amplification factor accordingly.<br>
The entropy encoding of the quantized prediction residual<br>
signal in the case of the comparison ULD encoder comprises<br>
methods, such as a Golomb, Huffman, or arithmetic encoding<br>
method. The entropy encoding has to be reset from time to<br>
time and generates inherently a variable bit rate, which is<br>
again leveled by the above-mentioned loop.<br>
In the case of the comparison ULD encoding scheme, the<br>
quantized prediction residual signal in the decoder is<br>
obtained from entropy encoding, whereupon the prediction<br>
remainder and the predicted signal are added, the sum is<br>
multiplied with the inverse of the transmitted<br>
amplification factor, and therefrom, the reconstructed<br>
output signal is generated via the postfilter having a<br>
frequency response inverse to the one of the prefilter,<br>
wherein the postfilter uses the transmitted prefilter<br>
coefficients.<br>
A comparison ULD encoder of the just described type<br>
obtains, for example, an overall encoder/decoder delay of<br>
5.33 to 8 ms at sample frequencies of 32 kHz to 48 kHz.<br>
Without (spurious loop) iterations, the same generates bit<br>
rates in the range of 80 to 96 kBit/s. As described above,<br>
at lower constant bit rates, the listening quality is<br>
decreased in this encoder, due to the uniform increase of<br>
the noise spectrum. Additionally, due to the iterations,<br>
the effort for obtaining a uniform bit rate is high. The<br>
embodiments described below overcome or minimize these<br>
disadvantages. At a constant transmission data rate, the<br>
encoding scheme of the embodiments described below causes<br>
altered noise shaping of the quantizing error and requires<br><br>
no iteration. More precisely, in the above-discussed<br>
comparison ULD encoding scheme, in the case of constant<br>
transmission data rate in an iterative process, a<br>
multiplicator is determined, with the help of which the<br>
signal coming from the prefilter is multiplied prior to<br>
quantizing, wherein the quantizing noise is spectrally<br>
white, which causes a quantizing noise in the decoder which<br>
is shaped like the listening threshold, but which lies<br>
slightly below or slightly above the listening threshold,<br>
depending on the selected multiplicator, which can, as<br>
described above, also be interpreted as a shift of the<br>
determined listening threshold. In connection therewith,<br>
quantizing noise results after decoding, whose power in the<br>
individual frequency domains can even exceed the power of<br>
the input signal in the respective frequency domain. The<br>
resulting encoding artifacts are clearly audible. The<br>
embodiments described below shape the quantizing noise such<br>
that its spectral power density is no longer spectrally<br>
white. The coarse quantizing/limiting or clipping,<br>
respectively, of the prefilter signal rather shapes the<br>
resulting quantizing noise similar to the spectral power<br>
density of the prefilter signal. Thereby, the quantizing<br>
noise in the decoder is shaped such that it remains below<br>
the spectral power density of the input signal. This can be<br>
interpreted as deformation of the determined listening<br>
threshold. The resulting encoding artifacts are less<br>
spurious than in the comparison ULD encoding scheme.<br>
Further, the subsequent embodiments require no iteration<br>
process, which reduces complexity.<br>
Since by describing the comparison ULD encoding scheme<br>
above, a sufficient base has been provided for turning the<br>
attention to the underlying advantages and considerations<br>
of the following embodiments for the description of these<br>
embodiments, first, the structure of an encoder according<br>
to an embodiment of the present invention will be described<br>
below.<br><br>
The encoder of Fig. 1, generally indicated by 10, comprises<br>
an input 12 for the information signal to be encoded, as<br>
well as an output 14 for the encoded information signal,<br>
wherein it is exemplarily assumed below that this is an<br>
audio signal, and exemplarily particularly an already<br>
sampled audio signal, although sampling within the encoder<br>
subsequent to the input 12 would also be possible. Samples<br>
of the incoming output signal are indicated by x(n) in<br>
Fig. 1.<br>
As shown in Fig. 1, the encoder 10 can be divided into a<br>
masking threshold determination means 16, a prefilter<br>
means 18, a forward-predictive prediction means 20 and a<br>
quantizing/clip means 22 as well as bit stream generation<br>
means 24. The masking threshold determination means 16<br>
operates according to a perceptual model or listening<br>
model, respectively, for determining a representation of<br>
the masking or listening threshold, respectively, of the<br>
audio signal incoming at the input 12 by using the<br>
perceptual model, which indicates a portion of the audio<br>
signal that is irrelevant with regard to the perceptibility<br>
or audibility, respectively, or represents a spectral<br>
threshold for the frequency at which which spectral energy<br>
remains inaudible due to psychoacoustic covering effects or<br>
is not perceived by humans, respectively. As will be<br>
described below, the determining means 16 determines the<br>
masking threshold in a block-wise manner, i.e. the same<br>
determines a masking threshold per block of subsequent<br>
blocks of samples of the audio signal. Other procedures<br>
would also be possible. The representation of the masking<br>
threshold as it results from the determination means 16<br>
can, in contrary to the subsequent description,<br>
particularly with regard to Fig. 4, also be a<br>
representation by spectral samples of the spectral masking<br>
threshold.<br>
The prefilter or preestimation means 18 is coupled to both<br>
the masking threshold determination means 16 and the input<br><br>
12 and filters the output signal for normalizing the same<br>
with regard to the masking threshold for obtaining a<br>
prefiltered, signal f(n). The prefilter means 18 is based,<br>
for example, on a linear filter and is implemented to<br>
adjust the filter coefficients in dependence on the<br>
representation of the masking threshold provided by the<br>
masking threshold of the determination means 16, such that<br>
the transmission function of the linear filter corresponds<br>
substantially to the inverse of the masking threshold.<br>
Adjustment of the filter coefficients can be performed<br>
block-wise, half block-wise, such as in the case described<br>
below of the blocks overlapping by half in the masking<br>
threshold determination, or sample-wise, for example by<br>
interpolating the filter coefficients obtained by the<br>
block-wise determined masking threshold representations, or<br>
by filter coefficients obtained therefrom across the<br>
interblock gaps.<br>
The forward prediction means 20 is coupled to the prefilter<br>
means 18, for subjecting the samples f(n) of the<br>
prefiltered signal, which are filtered adaptively in the<br>
time domain by using the psychoacoustic masking threshold<br>
to a forward-adaptive prediction, for obtaining a predicted<br>
<br>
signal f (n) , a residual signal r(n) representing a<br>
prediction error to the prefiltered signal f(n), and a<br>
representation of prediction filter coefficients, based on<br>
which the predicted signal can be reconstructed.<br>
Particularly, the forward-adaptive prediction means 20 is<br>
implemented to determine the representation of the<br>
prediction filter coefficients immediately from the<br>
prefiltered signal f and not only based on a subsequent<br>
quantization of the residual signal r. Although, as will be<br>
discussed in more detail below with reference to Fig. 4,<br>
the prediction filter coefficients are represented in the<br>
LFS domain, in particular in the form of a LFS prediction<br>
residual, other representations, such as an intermediate<br>
representation in the shape of linear filter coefficients,<br>
are also possible. Further, means 20 performs the<br><br>
prediction filter coefficient determination according to<br>
the subsequent description exemplarily block-wise, i.e. per<br>
block in subsequent block of samples f(n) of the<br>
prefiltered signal, wherein, however, other procedures are<br>
also possible. Means 20 is then implemented to determine<br>
the predicted signal f via these determined prediction<br>
filter coefficients, and to subtract the same from the<br>
prefiltered signal f, wherein the determination of the<br>
predicted signal is performed, for example, via a linear<br>
filter, whose filter coefficients are adjusted according to<br>
the forward-adaptively determined prediction coefficient<br>
representations. The residual signal available on the<br>
decoder side, i.e. the quantized and clipped residual<br>
signal ic(n), added to previously output filter output<br>
signal values, can serve as filter input signal, as will be<br>
discussed below in more detail.<br>
The quantizing/clip means 22 is coupled to the prediction<br>
means 20, for quantizing or clipping, respectively, the<br>
residual signal via a quantizing function mapping the<br>
values r(n) of the residual signal to a constant and<br>
limited number of quantizing levels, and for transmitting<br>
the quantized residual signal obtained in that way in the<br>
shape of the quantizing indices ic(n), as has already been<br>
mentioned, to the forward-adaptive prediction means 20.<br>
i<br>
The quantized residual signal ic(n), the representation of<br>
the prediction coefficients determined by the means 20, as<br>
well as the representation of the masking threshold<br>
determined by the means 16 make up information provided to<br>
the decoder side via the encoded signal 14, wherein<br>
therefore the bit stream generation means 24 is provided<br>
exemplarily; in Fig. 1, for combining the information<br>
according to a serial bit stream or a packet transmission,<br>
possibly by using a further lossless encoding.<br>
Before the more detailed structure of the encoder of Fig. 1<br>
will be discussed, the mode of operation of the encoder 1<br><br>
will be described below based on the above structure of the<br>
encoder 10. By filtering the audio signal by the prefilter<br>
means 18 with a transmission function corresponding to the<br>
inverse of the masking threshold, a prefiltered signal f(n)<br>
results, which obtains a spectral power density of the<br>
error by uniform quantizing, which mainly corresponds to a<br>
white noise, and would result in a noise spectrum similar<br>
to the masking threshold by filtering in the postfilter on<br>
the decoder side. However, first, the residual signal f is<br>
reduced to a prediction error r by the forward-adaptive<br>
prediction means 20 by a forward adapted predicted signal<br>
<br>
f by subtraction. The subsequent coarse quantization of<br>
this prediction error r by the quantizing/clipping means 22<br>
has no effect on the prediction coefficients of the<br>
prediction means 20, neither on the encoder nor the decoder<br>
side, since the calculation of the prediction coefficients<br>
is performed in a forward-adaptive manner and thus based on<br>
the unquantized values f(n). Quantization is not only<br>
performed in a coarse way, in the sense that a coarse<br>
quantizing step size is used, but is also performed in a<br>
coarse manner in the sense that even quantization is<br>
performed only to a constant and limited number of<br>
quantizing levels, so that for representing every quantized<br>
residual signal ic(n) or every quantizing index in the<br>
encoded audio signal 14 only a fixed number of bits is<br>
required, which allows inherently a constant bit rate with<br>
regard to the residual values ic(n). As will be described<br>
below, quantization is performed mainly by quantizing to<br>
uniformly spaced quantizing levels of fixed number, and<br>
below exemplarily to a number of a merely three quantizing<br>
levels, wherein quantization is performed, for example,<br>
such that an unquantized residual signal value r(n) is<br>
quantized to the next quantizing level, for obtaining the<br>
quantizing index ic(n) of the corresponding quantizing<br>
level for the same. Extremely high and extremely low values<br>
of the unquantized residual signal r(n) are thus mapped to<br>
the respective highest or lowest, respectively, quantizing<br>
level or the respective quantizing level index,<br><br>
respectively, even when they would be mapped to a higher<br>
quantizing level at uniform quantizing with the same step<br>
size. In so far, the residual signal r is also "clipped" or<br>
limited, respectively, by the means 22. However, the latter<br>
has the effect, as will be discussed below, that the error<br>
PSD (PSD =' power spectral density) of the prefiltered<br>
signal is no longer a white noise, but is approximated to<br>
the signal PSD of the prefiltered signal depending on the<br>
degree of clipping. On the decoder side, this has the<br>
effect that the noise PSD remains below the signal PSD even<br>
at bit rates that are lower than predetermined by the<br>
masking threshold.<br>
In the following, the structure of the encoder in Fig. 1<br>
will be described in more detail. Particularly, the masking<br>
threshold determination means 16 comprises a masking<br>
threshold determiner or a perceptual model 26,<br>
respectively, operating according to the perceptual model,<br>
a prefilter coefficient calculation module 28 and a<br>
coefficient encoder 30, which are connected in the named<br>
order between the input 12 and the prefilter means 18 as<br>
well as the bit stream generator 24. The prefilter means 18<br>
comprises a coefficient decoder 32 whose input is connected<br>
to the output of the coefficient encoder 30, as well as the<br>
prefilter 34, which is, for example, an adaptive linear<br>
filter, and which is connected with its data input to the<br>
input 12 and with its data output to the means 20, while<br>
its adaption input for adapting the filter coefficients is<br>
connected to an output of the coefficient decoder 32. The<br>
prediction means 20 comprises a prediction coefficient<br>
calculation module 36, a coefficient encoder 38, a<br>
coefficient decoder 40, a subtractor 42, a prediction<br>
filter 44, a delay element 46, a further adder 48 and a<br>
dequantizer 50. The prediction coefficient calculation<br>
module 46 and the coefficient encoder 38 are connected in<br>
series in this order between the output of the prefilter 34<br>
and the input of the coefficient decoder 40 or a further<br>
input of the bit stream generator 24, respectively, and<br><br>
cooperate for determining a representation of the<br>
prediction coefficients block-wise in a forward-adaptive<br>
manner. The coefficient decoder 4 0 is connected between the<br>
coefficient encoder 38 and the prediction filter 44, which<br>
is, for example, a linear prediction filter. Apart from the<br>
prediction coefficient input connected to the coefficient<br>
decoder 40, the filter 44 comprises a data input and a data<br>
output, to which the same is connected in a closed loop,<br>
which comprises, apart from the filter 44, the adder 48 and<br>
the delay element 46. Particularly, the delay element 46 is<br>
connected between the adder 48 and the filter 44, while the<br>
data output of the filter 44 is connected to a first input<br>
of the adder 48. Above that, the data output of the<br>
filter 44 is also connected to an inverting input of the<br>
subtractor 42. A non-inverting input of the subtractor 42<br>
is connected to the output of the prefilter 34, while the<br>
second input of the adder 48 is connected to an output of<br>
the dequantizer 50. A data input of the dequantizer 50 is<br>
coupled to the quantizing/clipping means 22 as well as to a<br>
step size control input of the dequantizer 50. The<br>
quantizing/clipping means 22 comprises a quantizer<br>
module 52 as well as a step size adaption block 54, wherein<br>
again the quantizing module 52 consists of a uniform<br>
quantizer 56 with uniform and controllable step size and a<br>
limiter 58, which are connected in series in the named<br>
order between an output of the subtractor 42 and the<br>
further input of the bit stream generator 24, and wherein<br>
the step size adaption block 54 again comprises a step size<br>
adaption module 60 and a delay member 62, which are<br>
connected in series in the named order between the output<br>
of the limiter 58 and a step size control input of the<br>
quantizer 56. Additionally, the output of the limiter 58 is<br>
connected to the data input of the dequantizer 50, wherein<br>
the step size control input of the dequantizer 50 is also<br>
connected to the step size adaption block 60. An output of<br>
the bit stream generator 24 again forms the output 14 of<br>
the encoder 10.<br><br>
After the detailed structure of the encoder of Fig. 1 has<br>
been described in detail above, its mode of operation will<br>
be described below. The perceptual model module 26<br>
determines or estimates, respectively, the masking<br>
threshold in a block-wise manner from the audio signal.<br>
Therefore, the perceptual model module 26 uses, for<br>
example, a DFT of the length 256, i.e. a block length of<br>
256 samples x(n), with 50% overlapping between the blocks,<br>
which results in a delay of the encoder 10 of 128 samples<br>
of the audio signal. The estimation of the masking<br>
threshold output by the perceptual model module 26 is, for<br>
example, represented in a spectrally sampled form in a Bark<br>
band or linear frequency scale. The masking threshold<br>
output per block by the perceptual model module 26 is used<br>
in the coefficient calculation module 24 for calculating<br>
filter coefficients of a predetermined filter, namely the<br>
filter 34. The coefficients calculated by the module 28<br>
can, for example, be LPC coefficients, which model the<br>
masking threshold. The prefilter coefficients for every<br>
block are again encoded by the coefficient encoder 30,<br>
which will be discussed in more detail with reference to<br>
Fig. 4. The coefficient decoder 34 decodes the encoded<br>
prefilter coefficients for retrieving the prefilter<br>
coefficients of the module 28, wherein the prefilter 34<br>
again obtains these parameters or prefilter coefficients,<br>
respectively, and uses the same, so that it normalizes the<br>
input signal x(n) with regard to its masking threshold or<br>
filters the same with a transmission function,<br>
respectively, which essentially corresponds to the inverse<br>
of the masking threshold. Compared to the input signal, the<br>
resulting prefiltered signal f(n) is significantly smaller<br>
in amount.<br>
In the prediction coefficient calculation module 36, the<br>
samples f(n) of the prefiltered signal are processed in a<br>
block-wise manner, wherein the block-wise division can<br>
correspond exemplarily to the one of the audio signal 12 by<br>
the perceptual model module 26, but does not have to do<br><br>
this. For every block of prefiltered samples, the<br>
coefficient calculation module 36 calculates prediction<br>
coefficients for usage by the prediction filter 44.<br>
Therefore, the coefficient calculation module 36 performs,<br>
for example, LPC (LPC = linear predictive coding) analysis<br>
per block of the prefiltered signal for obtaining the<br>
prediction coefficients. The coefficient encoder 38 encodes<br>
then the prediction coefficients similar to the coefficient<br>
encoder 30, as will be discussed in more detail below, and<br>
outputs this representation of the prediction coefficients<br>
to the bit stream generator 24 and particularly the<br>
coefficient decoder 40, wherein the latter uses the<br>
obtained prediction coefficient representation for applying<br>
the prediction coefficients obtained in the LPC analysis by<br>
the coefficient calculation module 36 to the linear filter<br>
44, so that the closed loop predictor consisting of the<br>
closed loop of filter 44, delay member 46 and adder 48<br>
<br>
generates the predicted signal f (n), which is again<br>
subtracted from the prefiltered signal f(n) by the<br>
subtractor 42. The linear filter 44 is, for example, a<br>
linear prediction filter of the type A(z) = of the<br>
length N, wherein the coefficient decoder 40 adjusts the<br>
values ai in dependence on the prediction coefficients<br>
calculated by the coefficient calculation module 36, i.e.<br>
the weightings with which the previous predicted values<br>
<br>
f (n) plus . the dequantized residual signal values are<br>
weighted and then summed for obtaining the new or current,<br>
<br>
respectively, predicted value f<br>
The prediction remainder r(n) obtained by the subtractor 42<br>
is subject to uniform quantization, i.e. quantization with<br>
uniform quantizing step size, in the quantizer 56, wherein<br>
the step size A(n) is time-variable, and is calculated or<br>
determined, respectively, by the step size adaption module<br>
in a backward-adaptive manner, i.e. from the quantized<br>
residual values to the previous residual values r(m<n></n>
More precisely, the uniform quantizer 56 outputs a<br>
quantized residual value q(n) per residual value r(n) ,<br><br>
which can be expressed as q(n) = i(n). A(n) and can be<br>
referred to as provisional quantizing step with index. The<br>
provisional quantizing index i(n) is again clipped by the<br>
limiter 58, to the amount C = [-c;c], wherein c is a<br>
constant c e{l,2,...}. Particularly, the limiter 58 is<br>
implemented such that all provisional index values i (n)<br>
with |i(n)|&gt; c are either set to -c or c, depending on which<br>
is closer. Merely the clipped or limited, respectively,<br>
index sequence or series ic(n) is output by the limiter 58<br>
to the bit stream generator 24, the dequantizer 50 and the<br>
step size adaption block 54 or the delay element 62,<br>
respectively, because the delay member 62, as well as all<br>
other delay members in the present embodiments, delays the<br>
incoming values by one sample.<br>
Now, backward-adaptive step size control is realized via<br>
the step size adaption block 54, in that the same uses past<br>
index sequence values ic(n) delayed by the delay member 62<br>
for constantly adapting the step size A(n), such that the<br>
area limited by the limiter 58, i.e. the area set by the<br>
"allowed" quantizing indices or the corresponding<br>
quantizing levels, respectively, is placed such to the<br>
statistic probability of occurrence of unquantized residual<br>
values r(n), that the allowed quantizing levels occur as<br>
uniformly as possible in the generated clipped quantizing<br>
index sequence stream ic(n). Particularly, the step size<br>
adaption module 60 calculates, for example, the current<br>
step size A(n) for example by using the two immediately<br>
preceding clipped quantizing indices ic(n-l) and i2(n-2) as<br>
well as the immediately previously determined step size<br>
value A(n-l) to A(n) = β∆(n-l) + 8(n), with (3 e[0.0;1.0[,<br>
8(n) = δ0 for |ic(n-l) + ic(n-2)| 
1) + ic(n-2)| &gt;I, wherein δ0, δX and I are appropriately<br>
adjusted constants, as well as β.<br>
As will be discussed in more detail below with reference to<br>
Fig. 5, the decoder uses the obtained quantizing index<br>
sequence ic(n) and the step size sequence A(n), which is<br><br>
also calculated in a backward-adaptive manner for<br>
reconstructing the dequantized residual value sequence<br>
qc(n) by calculating ic(n) • ∆(n), which is also performed<br>
in the encoder 10 of Fig. 1, namely by the dequantizer 50<br>
in the prediction means 20. Like on the decoder side, the<br>
residual value sequence qc(n) constructed in that way is<br>
<br>
subject to an addition with the predicted values f (n) in a<br>
sample-wise manner, wherein the addition is performed in<br>
the encoder 10 via the adder 48. While the reconstructed or<br>
dequantized, respectively, prefiltered signal obtained in<br>
that way is no longer used in the encoder 10, except for<br>
<br>
calculating the subsequent predicted values f (n) , the<br>
postfilter generates the decoded audio sample sequence y(n)<br>
therefrom on the decoder side, which cancels the<br>
normalization by the prefilter 34.<br>
The quantizing noise introduced in the quantizing index<br>
sequence qc(n) is no longer white due to the clipping.<br>
Rather, its spectral form copies the one of the prefiltered<br>
signal. For illustrating this, reference is briefly made to<br>
Fig. 3, which shows, in graphs a, b and c, the PSD of the<br>
prefiltered signal (upper graph) and the PSD of the<br>
quantizing error (respective lower graph) for different<br>
numbers of quantizing levels or stages, respectively,<br>
namely for C = [-15; 15] in graph a, for a limiter range of<br>
[-7;7] in graph b, and a clipping range of [-1;1] in graph<br>
c. For clarity reasons, it should further be noted that the<br>
PSD courses of the error PSDs in graphs A-C have each been<br>
plotted with an offset of -10dB. As can be seen, the<br>
prefiltered signal corresponds to a colored noise with a<br>
power of a2 = 34. At a quantization with a step size A = 1,<br>
the signal lies within [-21/21], i.e. the samples of the<br>
prefiltered signal have an occurrence distribution or form<br>
a histogram, respectively, which lies within this domain.<br>
For graphs a to c in Fig. 3, the quantizing range has been<br>
limited, as mentioned, to [-15/15] in a), [-7/7] in b) and<br>
[-1/1] in c). The quantizing error has been measured as the<br>
difference between the unquantized prefiltered signal and<br><br>
the decoded prefiltered signal. As can be seen, a<br>
quantizing noise is added to the prefiltered signal by<br>
increasing clipping or with increasing limitation of the<br>
number of quantizing levels, which copies the PSD of the<br>
prefiltered signal, wherein the degree of copying depends<br>
on the hardness or the extension, respectively, of the<br>
applied clipping. Consequently, after postfiltering, the<br>
quantizing noise spectrum on the decoder side copies more<br>
the PSD of the audio input signal. This means that the<br>
quantizing noise remains below the signal spectrum after<br>
decoding. This effect is illustrated in Fig. 2, which shows<br>
in graph a, for the case of backward-adaptive prediction,<br>
i.e. prediction according to the above described comparison<br>
ULD scheme, and in graph b, for the case of forward-<br>
adaptive prediction with applied clipping according to<br>
Fig. 1, respectively three courses in a normalized<br>
frequency domain, namely, from top to bottom, the signal<br>
PSD, i.e. the PSD of the audio signal, the quantizing error<br>
PSD or the quantizing noise after decoding (straight line)<br>
and the masking threshold (dotted line) . As can be seen,<br>
the quantizing noise for the comparison ULD encoder<br>
(Fig. 2a) is formed like the masking threshold and exceeds<br>
the signal spectrum for portions of the signal. The effect<br>
of the forward-adaptive prediction of the prefiltered<br>
signal combined with subsequent clipping or limiting,<br>
respectively, of the quantizing level number is now clearly<br>
illustrated in Fig. 2b, where it can be seen that the<br>
quantizing noise is always lower than the signal spectrum<br>
and its shape represents a mixture of the signal spectrum<br>
and the masking threshold. In listening tests, it has been<br>
found out that the encoding artifacts according to Fig. 2b<br>
are less spurious, i.e. the perceived listening quality is<br>
better.<br>
The above description of the mode of operation of the<br>
encoder of Fig. 1 concentrated on the postprocessing of the<br>
prefiltered signal f(n), for obtaining the clipped<br>
quantizing indices ic(n) to be transmitted to the decoder<br><br>
side. Since they originate from an amount with a constant<br>
and limited number of indices, they can each be represented<br>
with the same number of bits within the encoded data stream<br>
at the output 14. Therefore, the bit stream generator 24<br>
uses, for example, an injective mapping of the quantizing<br>
indices to m bit words that can be represented by a<br>
predetermined number of bits m.<br>
The following description deals with the transmission of<br>
the prefilter or prediction coefficients, respectively,<br>
calculated by the coefficient calculation modules 28 and 36<br>
to the decoder side, i.e. particularly with an embodiment<br>
for the structure of the coefficient encoders 30 and 38.<br>
As is shown, the coefficient encoders according to the<br>
embodiment of Fig. 4 comprise an LSF conversion module 102,<br>
a first subtractor 104, a second subtractor 106, a uniform<br>
quantizer 108 with uniform and adjustable quantizing step<br>
size, a limiter 110, a dequantizer 112, a third adder 114,<br>
two delay members 116 and 118, a prediction filter 120 with<br>
fixed filter coefficients or constant filter coefficients,<br>
respectively, as well as a step size adaption module 122.<br>
The filter coefficients to be encoded come in at an input<br>
124, wherein an output 126 is provided for outputting the<br>
encoded representation.<br>
An input of the LSF conversion module 102 directly follows<br>
the input 124. The subtractor 104 with its non-inverting<br>
input and its output is connected between the output of the<br>
LSF conversion module 102 and a first input of the<br>
subtractor 106, wherein a constant lc is applied to the<br>
input of the subtractor 104. The subtractor 106 is<br>
connected with its non-inverting input and its output<br>
between the first subtractor 104 and the quantizer 108,<br>
wherein its inverting input is coupled to an output of the<br>
prediction filter 120. Together with the delay member 118<br>
and the adder 114, the prediction filter 120 forms a<br>
closed-loop predictor, in which the same are connected in<br><br>
series in a loop with feedback, such that the delay member<br>
118 is connected between the output of the adder 114 and<br>
the input of the prediction filter 120, and the output of<br>
the prediction filter 120 is connected to a first input of<br>
the adder 114. The remaining structure corresponds again<br>
mainly to the one of the means 22 of the encoder 10, i.e.<br>
the quantizer 108 is connected between the output of the<br>
subtractor 106 and the input of the limiter 110, whose<br>
output is again connected to the output 126, an input of<br>
the delay member 116 and an input of the dequantizer 112.<br>
The output of the delay member 116 is connected to an input<br>
of the step size adaption module 122, which thus form<br>
together a step size adaption block. An output of the step<br>
size adaption module 122 is connected to step size control<br>
inputs of the quantizer 108 and the dequantizer 112. The<br>
output of the dequantizer 112 is connected to the second<br>
input of the adder 114.<br>
After the structure of the coefficient encoder has been<br>
described above, its mode of operation will be described<br>
below, wherein reference is made again to Fig. 1. The<br>
transmission of both the prefilters and the prediction or<br>
predictor coefficients, respectively, or their encoding,<br>
respectively, is performed by using a constant bit rate<br>
encoding scheme, which is realized by the structure<br>
according to Fig. 4. Then, in the LSF conversion module<br>
102, the filter coefficients, i.e. the prefilter or<br>
prediction coefficients, respectively, are first converted<br>
to LSF values l(n) or transferred to the LSF domain,<br>
respectively. Every spectral line frequency l(n) is then<br>
processed by the residual elements in Fig. 4 as follows.<br>
This means the following description relates to merely one<br>
spectral line frequency, wherein the processing of course,<br>
is performed for all spectral line frequencies. For<br>
example, the module 102 generates LSF values for every set<br>
of prefilter coefficients representing a masking threshold,<br>
or a block of prediction coefficients predicting the<br>
prefiltered signal. The subtractor 104 subtracts a constant<br><br>
reference value lc from the calculated value l(n), wherein<br>
a sufficient range for lc ranges, for example, from 0 to π.<br>
From the resulting difference ld(n), the subtractor 106<br>
subtracts a predicted value ld(n), which is calculated by<br>
the closed-loop predictor 120, 118 and 114 including the<br>
prediction filter 120, such as a linear filter, with fixed<br>
coefficients A(z). What remains, i.e. the residual value,<br>
is quantized by the adaptive step size quantizer 108,<br>
wherein the quantizing indices output by the quantizer 108<br>
are clipped by the limiter 110 to a subset of the<br>
quantizing indices received by the same, such as, for<br>
example, that for all clipped quantizing indices le(n), as<br>
they are output by the limiter 110, the following applies:<br>
 : le(n)  {-1,0,1}. For quantizing step size adaption of<br>
A(n) of the LSF residual quantizer 108, the step size<br>
adaption module 122 and the delay member 116 cooperate for<br>
example in the way described with regard to the step size<br>
adaption block 54 with reference to Fig. 1, however,<br>
possibly with a different adaption function or with<br>
different constants β, I, δ0, δ1 and I. While the<br>
quantizer 108 uses the current step size for quantizing the<br>
current residual value to le(n), the dequantizer 112 uses<br>
the step size ∆i(n) for dequantizing this index value le(n)<br>
again and for supplying the resulting reconstructed value<br>
for the LSF residual value, as it has been output by the<br>
subtractor 106, to the adder 114, which adds this value to<br>
the corresponding predicted value ld(n), and supplies the<br>
same via the delay member 118 delayed by a sample to the<br>
filter 120 for calculating the predicted LSF value Îd(n)<br>
for the next LSF value ld(n).<br>
If the two coefficient encoders 30 and 38 are implemented<br>
in the way described in Fig. 4, the coder 10 of Fig. 1<br>
fulfills a constant bit rate condition without using any<br>
loop. Due to the block-wise forward adaption of the LPC<br>
coefficients and the applied encoding scheme, no explicit<br>
reset of the predictor is required.<br><br>
Before results of listening tests, which have been obtained<br>
by an encoder according to Figs. 1 and 4, will be discussed<br>
below, the structure of a decoder according to an<br>
embodiment of the present invention will be described<br>
below, which is suitable for decoding an encoded data<br>
stream from this encoder, wherein reference is made to<br>
Figs. 5 and 6. Fig. 6 also shows the structure of the<br>
coefficient decoder in Fig. 1.<br>
The decoder generally indicated by 200 in Fig. 5 comprises<br>
an input 202 for receiving the encoded data stream, an<br>
output 204 for outputting the decoded audio stream y(n) as<br>
well as a dequantizing means 206 having a limited and<br>
constant number of quantizing levels, a prediction means<br>
208, a reconstruction means 210 as well as a postfilter<br>
means 212. Additionally, an extractor 214 is provided,<br>
which is coupled to the input 202 and implemented to<br>
extract, from the incoming encoded bit stream, the<br>
quantized and clipped prefilter residual signal ic(n), the<br>
encoded information about the prefilter coefficients and<br>
the encoded information about the prediction coefficients,<br>
as they have been generated from the coefficient encoders<br>
30 and 38 (Fig. 1) and to output the same at the respective<br>
outputs. The dequantizing means 206 is coupled to the<br>
extractor 214 for obtaining the quantizing indices ic(n)<br>
from the same and for performing dequantization of these<br>
indices to a limited and constant number of quantizing<br>
levels, namely - sticking to the same notation as above -<br>
{-c • ∆(n); c • ∆(n)}, for obtaining a dequantized or<br>
reconstructed prefilter signal qc(n), respectively. The<br>
prediction means 208 is coupled to the extractor 214 for<br>
obtaining a predicted signal for the prefiltered signal,<br>
<br>
namely fc<n> from the information about the prediction<br>
coefficients. The prediction means 208 is coupled to the<br>
extractor 214 for determining a predicted signal for the<br>
<br>
prefiltered signal, namely f (n), from the information<br>
about the prediction coefficients, wherein the prediction<br>
means 208 according to the embodiment of Fig. 5 is also<br><br>
connected to an output of the reconstruction means 210. The<br>
reconstruction means 210 is provided for reconstructing the<br>
<br>
prefiltered signal, based on the predicted signal f (n) and<br>
the dequantized residual signals qc(n). This reconstruction<br>
is then used by the subsequent postfilter means 212 for<br>
filtering the prefiltered signal based on the prefilter<br>
coefficient information received from the extractor 214,<br>
such that the normalization with regard to the masking<br>
threshold is canceled for obtaining the decoded audio<br>
signal y(n).<br>
After the basic structure of the decoder of Fig. 5 has been<br>
described above, the structure of the decoder 200 will be<br>
discussed in more detail. Particularly, the dequantizer 206<br>
comprises a step size adaption block of a delay member 216<br>
and a step size adaption module 218 as well as a uniform<br>
dequantizer 220. The dequantizer 220 is connected to an<br>
output of the extractor 214 with its data input, for<br>
obtaining the quantizing indices ic(n). Further, the step<br>
size adaption module 218 is connected to this output of the<br>
extractor 214 via the delay member 216, whose output is<br>
again connected to a step size control input of the<br>
dequantizer 220. The output of the dequantizer 220 is<br>
connected to a first input of the adder 222, which forms<br>
the reconstruction means 210. The prediction means 208<br>
comprises a coefficient decoder 224, a prediction<br>
filter 226 as well as delay member 228. Coefficient<br>
decoder 224, adder 222, prediction filter 226 and delay<br>
member 228 correspond to elements 40, 44, 46 and 48 of the<br>
encoder 10 with regard to their mode of operation and their<br>
connectivity. In particular, the output of the prediction<br>
filter 226 is connected to the further input of the adder<br>
222, whose output is again fed back to the data input of<br>
the prediction filter 226 via the delay member 228, as well<br>
as coupled to the postfilter means 212. The coefficient<br>
decoder 224 is connected between a further output of the<br>
extractor 214 and the adaption input of the prediction<br>
filter 226. The postfilter means comprises a coefficient<br><br>
decoder 230; and a postfilter 232, wherein a data input of<br>
the postfilter 232 is connected to an output of the<br>
adder 222 and a data output of the postfilter 232 is<br>
connected to the output 204, while an adaption input of the<br>
postfilter 232 is connected to an output of the coefficient<br>
decoder 230 for adapting the postfilter 232, whose input<br>
again is connected to a further output of the<br>
extractor 214.<br>
As has already been mentioned, the extractor 214 extracts<br>
the quantizing indices ic(n) representing the quantized<br>
prefilter residual signal from the encoded data stream at<br>
the input 202. In the uniform dequantizer 220, these<br>
quantizing indices are dequantized to the quantized<br>
residual values qc(n). Inherently, this dequantizing<br>
remains within the allowed quantizing levels, since the<br>
quantizing indices ic(n) have already been clipped on the<br>
encoder side. The step size adaption is performed in a<br>
backward-adaptive manner, in the same way as in the step<br>
size adaption block 54 of the encoder of Fig. 1. Without<br>
transmission errors, the dequantizer 220 generates the same<br>
values as the dequantizer 50 of the encoder of Fig. 1.<br>
Therefore, the elements 222, 226, 228 and 224 based on the<br>
encoded prediction coefficients obtain the same result as<br>
it is obtained in the encoder 10 of Fig. 1 at the output of<br>
the adder 48, i.e. a dequantized or reconstructed prefilter<br>
signal, respectively. The latter is filtered in the<br>
postfilter 232, with a transmission function corresponding<br>
to the masking threshold, wherein the postfilter 232 is<br>
adjusted adaptively by the coefficient decoder 230, which<br>
appropriately adjust the postfilter 230 or its filter<br>
coefficients, respectively, based on the prefilter<br>
coefficient: information.<br>
Assuming that the encoder 10 is provided with coefficient<br>
encoders 30 and 38, which are implemented as described in<br>
Fig. 4, the coefficient decoders 224 and 230 of the encoder<br>
200 but also the coefficient decoder 40 of the encoder 10<br><br>
are structured as shown in Fig. 6. As can be seen, a<br>
coefficient decoder comprises two delay members 302, 304, a<br>
step size adaption module 306 forming a step size adaption<br>
block together with the delay member 302, a uniform<br>
dequantizer 308 with uniform step size, a prediction filter<br>
310, two adders 312 and 314, an LSF reconversion module 316<br>
as well as an input 318 for receiving the quantized LSF<br>
residual values le(n) with constant offset -lc and an<br>
output 320 for outputting the reconstructed prediction or<br>
prefilter coefficients, respectively. Thereby, the delay<br>
member 302 is connected between an input of the step size<br>
adaption module 306 and the input 318, an input of the<br>
dequantizer 308 is also connected to the input 318, and a<br>
step size adaption input of the dequantizer 308 is<br>
connected to an output of the step size adaption<br>
module 306. The mode of operation and connectivity of the<br>
elements 302, 306 and 308 corresponds to the one of 112,<br>
116 and 122 in Fig. 4. A closed-loop predictor of delay<br>
member 304, prediction filter 310 and adder 312, which are<br>
connected in a common loop by connecting the delay member<br>
304 between an output of the adder 312 and an input of the<br>
prediction filter 310, and by connecting a first input of<br>
the adder 312 to the output of the dequantizer 308, and by<br>
connecting a second input of the adder 312 to an output of<br>
the prediction filter 310, is connected to an output of the<br>
dequantizer 308. Elements 304, 310 and 312 correspond to<br>
the elements 120, 118 and 114 of Fig. 4 in their mode of<br>
operation and connectivity. Additionally, the output of the<br>
adder 312 is connected to a first input of the adder 314,<br>
at the second input of which the constant value lc is<br>
applied, wherein, according to the present embodiment, the<br>
constant lc is an agreed amount, which is present to both<br>
encoder and the decoder and thus does not have to be<br>
transmitted as part of the side information, although the<br>
latter would also be possible. The LSF reconversion module<br>
316 is connected between an output of the adder 314 and the<br>
output 320.<br><br>
The LSF residual signal indices le(n) incoming at the<br>
input 318 are dequantized by the dequantizer 308, wherein<br>
the dequantizer 308 uses the backward-adaptive step size<br>
values A(n), which had been determined in a backward-<br>
adaptive manner by the step size adaption module 306 from<br>
already dequantized quantizing indices, namely those that<br>
had been delayed by a sample by the delay member 302. The<br>
adder 312 adds the predicted signal to the dequantized LSF<br>
residual values, which calculates the combination of delay<br>
member 304 and prediction filter 210 from sums that the<br>
adder 312 has already calculated previously and thus<br>
represent the reconstructed LSF values, which are merely<br>
provided with a constant offset by the constant offset lc.<br>
The latter is corrected by the adder 314 by adding the<br>
value lc to the LSF values, which the adder 312 outputs.<br>
Thus, at the output of the adder 314, the reconstructed LSF<br>
values result, which are converted by the module 316 from<br>
the LSF domain back to reconstructed prediction or<br>
prefilter coefficients, respectively. Therefore, the LSF<br>
reconversion module 316 considers all spectral line<br>
frequencies, whereas the discussion of the other elements<br>
of Fig. 6 was limited to the description of one spectral<br>
line frequency. However, the elements 302-314 perform the<br>
above-described measures also at the other spectral line<br>
frequencies.<br>
After providing both encoder and decoder embodiments above,<br>
listening test results will be presented below based on<br>
Fig. 7, as they have been obtained via an encoding scheme<br>
according to Figs. 1, 4, 5 and 6. In the performed tests,<br>
both an encoder according to Figs. 1, 4 and 6 and an<br>
encoder according to the comparison ULD encoding scheme<br>
discussed at the beginning of the description of the Figs,<br>
have been tested, in a listening test according to the<br>
MUSHRA standard, where the moderators have been omitted.<br>
The MUSHRA test has been performed on a laptop computer<br>
with external digital-to-analog converter and STAX<br>
amplifier/headphones in a quiet office environment. The<br><br>
group of eight test listeners was made up of expert and<br>
non-expert listeners. Before the participants began the<br>
listening test, they had the opportunity to listen to a<br>
test set. The tests have been performed with twelve mono<br>
audio files: of the MPEG test set, wherein all had a sample<br>
frequency of 32 kHz, namely es01 (Suzanne Vega), es02 (male<br>
speech), German), es03 (female speech, English), sc01<br>
(trumpet), sc02 (orchestra), sc03 (pop music), si01<br>
(cembalo), si02 (castanets), si03 (pitch pipe), sm01<br>
(bagpipe), sm02 (glockenspiel), sm03 (puckled strings).<br>
For the comparison ULD encoding scheme, a backward-adaptive<br>
prediction with a length of 64 has been used in the<br>
implementation, together with a backward-adaptive Golomb<br>
encoder for entropy encoding, with a constant bit rate of<br>
64 kBit/s. In contrast, for implementing the encoder<br>
according to Figs. 1, 4 and 6, a forward-adaptive predictor<br>
with a length of 12 has been used, wherein the number of<br>
different quantizing levels has been limited to 3, namely<br>
such that Vn : ic(n) 6 {-1,0,1}. This resulted, together<br>
with the encoded side information, in a constant bit rate<br>
of 64 kBit/s, which means the same bit rate.<br>
The results, of the MUSHRA listening tests are shown in<br>
Fig. 7, wherein both the average values and 95 % confidence<br>
intervals are shown, for the twelve test pieces<br>
individually and for the overall result across all pieces.<br>
As long as the confidence intervals overlap, there is no<br>
statistically significant difference between the encoding<br>
methods.<br>
The piece esOl (Suzanne Vega) is a good example for the<br>
superiority, of the encoding scheme according to Figs. 1, 4,<br>
5 and 6 at lower bit rates. The higher portions of the<br>
decoded signal spectrum show less audible artifacts<br>
compared to the comparison ULD encoding scheme. This<br>
results in a significantly higher rating of the scheme<br>
according to Figs. 1, 4, 5 and 6.<br><br>
The signal transients of the piece sm02 (Glockenspiel) have<br>
a high bit rate requirement for the comparison ULD encoding<br>
scheme. In the used 64kBit/s, the comparison ULD encoding<br>
scheme generates spurious encoding artifacts across full<br>
blocks of samples. In contrast, the encoder operating<br>
according to Figs. 1, 4 and 6 provides a significantly<br>
improved listening quality or perceptual quality,<br>
respectively. The overall rating, seen in the graph of<br>
Fig. 7 on the right, of the encoding scheme formed<br>
according to Figs. 1, 4 and 6 obtained a significantly<br>
better rating than the comparison ULD encoding scheme.<br>
Overall, this encoding scheme got an overall rating of<br>
"good audio quality" under the given test conditions.<br>
In summary, from the above-described embodiments, an audio<br>
encoding scheme with low delay results, which uses a block-<br>
wise forward-adaptive prediction together with<br>
clipping/limiting instead of a backward-adaptive sample-<br>
wise prediction. The noise shaping differs from the<br>
comparison ULD encoding scheme. The listening test has<br>
shown that the above-described embodiments are superior to<br>
the backward-adaptive method according to the comparison<br>
ULD encoding scheme in the case of lower bit rates.<br>
Subsequently, the same are a candidate for closing the bit<br>
rate gap between high quality voice encoders and audio<br>
encoders with low delay. Overall, the above-described<br>
embodiments provided a possibility for audio encoding<br>
schemes having a very low delay of 6 - 8 ms for reduced bit<br>
rates, which has the following advantages compared to the<br>
comparison ULD encoder. The same is more robust against<br>
high quantizing errors, has additional noise shaping<br>
abilities, has a better ability for obtaining a constant<br>
bit rate, and shows a better error recovery behavior. The<br>
problem of audible quantizing noise at positions without<br>
signal, as is the case in the comparison ULD encoding<br>
scheme, is addressed by the embodiment by a modified way of<br>
increasing the quantizing noise above the masking<br><br>
threshold, namely by adding the signal spectrum to the<br>
masking threshold instead of uniformly increasing the<br>
masking threshold to a certain degree. In that way, there<br>
is no audible quantizing noise at positions without signal.<br>
In other words, the above embodiments differ from the<br>
comparison ULD encoding scheme in the following way. In the<br>
comparison ULD encoding scheme, backward-adaptive<br>
prediction is used, which means that the coefficients for<br>
the prediction filter A(z) are updated on a sample-by-<br>
sample basis from previously decoded signal values. A<br>
quantizer having a variable step size is used, wherein the<br>
step size adapts all 128 samples by using information from<br>
the entropy encoders and the same is transmitted as side<br>
information to the decoder side. By this procedure, the<br>
quantizing step size is increased, which adds more white<br>
noise to the prefiltered signal and thus uniformly<br>
increases the masking threshold. If the backward-adaptive<br>
prediction lis replaced with a forward-adaptive block-wise<br>
prediction in the comparison ULD encoding scheme, which<br>
means that the coefficients for the prediction filter A(z)<br>
are calculated once for 128 samples from the unquantized<br>
prefiltered samples, and transmitted as side information,<br>
and if the quantizing step size is adapted for the 128<br>
samples by using information from the entropy encoder and<br>
transmitted as side information to the decoder side, the<br>
quantizing step size is still increased, as it is the case<br>
in the comparison ULD encoding scheme, but the predictor<br>
update is unaffected by any quantization. The above<br>
embodiments used only a forward adapted block-wise<br>
prediction, wherein additionally the quantizer had merely a<br>
given number 2N+1 of quantizing stages having a fixed step<br>
size. For the prefiltered signals x(n) with amplitudes<br>
outside the quantizer range [-NA;NA] the quantized signal<br>
was limited to [-N∆;N∆]. This results in a quantizing<br>
noise having a PSD, which is no longer white, but copies<br>
the PSD of the input signal, i.e. the prefiltered audio<br>
signal.<br><br>
As a conclusion, the following is to be noted on the above<br>
embodiments. First, it should be noted that different<br>
possibilities exist for transmitting information about the<br>
representation of the masking threshold, as they are<br>
obtained by the perceptual model module 26 within the<br>
encoder to the prefilter 34 or prediction filter 44,<br>
respectively, and to the decoder, and there particularly to<br>
the postfilter 232 and the prediction filter 226.<br>
Particularly, it should be noted that it is not required<br>
that the coefficient decoders 32 and 40 within the encoder<br>
receive exactly the same information with regard to the<br>
masking threshold, as it is output at the output 14 of the<br>
encoder and as it is received at the output 202 of the<br>
decoder. Rather, it is possible, that, for example in a<br>
structure of the coefficient encoder 30 according to<br>
Fig. 4, the obtained indices le(n) as well as the prefilter<br>
residual signal quantizing indices ic(n) originate also<br>
only from an amount of three values, namely -1, 0, 1, and<br>
that the bit stream generator 24 maps these indices just as<br>
clearly to corresponding n bit words. According to an<br>
embodiment according to Figs. 1, 4 or 5, 6, respectively,<br>
the prefilter quantizing indices, the prediction<br>
coefficient quantizing indices and/or the prefilter<br>
quantizing indices each originating from the amount -1, 0,<br>
1, are mapped in groups of fives to a 8-bit word, which<br>
corresponds to a mapping of 35 possibilities to 28 bit<br>
words. Since the mapping is not surjective, several 8-bit<br>
words remain unused and can be used in other ways, such as<br>
for synchronization or the same.<br>
On this occasion, the following should be noted. Above, it<br>
has been described with reference to Fig. 6 that the<br>
structure of the coefficient decoders 32 and 230 is<br>
identical. In this case, the prefilter 34 and the<br>
postfilter 232 are implemented such that when applying the<br>
same filter coefficients they have a transmission function<br>
inverse to each other. However, it is of course also<br><br>
possible that, for example, the coefficient encoder 32<br>
performs an additional conversion of the filter<br>
coefficients, so that the prefilter has a transmission<br>
function mainly corresponding to the inverse of the masking<br>
threshold, whereas the postfilter has a transmission<br>
function mainly corresponding to the masking threshold.<br>
In the above embodiments, it has been assumed that the<br>
masking threshold is calculated in the module 26. However,<br>
it should be noted that the calculated threshold does not<br>
have to exactly correspond to the psychoacoustic threshold,<br>
but can represent a more or less exact estimation of the<br>
same, which might not consider all psychoacoustic effects<br>
but merely some of them. Particularly, the threshold can<br>
represent a psychoacoustically motivated threshold, which<br>
has been deliberately subject to a modification in contrast<br>
to an estimation of the psychoacoustic masking threshold.<br>
Further, it should be noted that the backward-adaptive<br>
adaption of the step size in quantizing the prefilter<br>
residual signal values does not necessarily have to be<br>
present. Rather, in certain application cases, a fixed step<br>
size can be sufficient.<br>
Further, it should be noted that the present invention is<br>
not limited to the field of audio encoding. Rather, the<br>
signal to be encoded can also be a signal used for<br>
stimulating a fingertip in a cyber-space glove, wherein the<br>
perceptual model 26 in this case considers certain tactile<br>
characteristics, which the human sense of touch can no<br>
longer perceive. Another example for an information signal<br>
to be encoded would be, for example, a video signal.<br>
Particularly the information signal to be encoded could be<br>
a brightness information of a pixel or image point,<br>
respectively, wherein the perceptual model 26 could also<br>
consider different temporal, local and frequency<br>
psychovisual covering effects, i.e. a visual masking<br>
threshold.<br><br>
Additionally, it should be noted that quantizer 56 and<br>
limiter 58 or quantizer 108 and limiter 110, respectively,<br>
do not have to be separate components. Rather, the mapping<br>
of the unquantized values to the quantized/clipped values<br>
could also be performed by a single mapping. On the other<br>
hand, the quantizer 56 or the quantizer 108, respectively,<br>
could also be realized by a series connection of a divider<br>
followed by a quantizer with uniform and constant step<br>
size, where the divider would use the step size value A(n)<br>
obtained from the respective step size adaption module as<br>
divisor, while the residual signal to be encoded formed the<br>
dividend. The quantizer having a constant and uniform step<br>
size could be provided as simple rounding module, which<br>
rounds the division result to the next integer, whereupon<br>
the subsequent limiter would then limit the integer as<br>
described above to an integer of the allowed amount C. In<br>
the respective dequantizer, a uniform dequantization would<br>
simply be performed with A(n) as multiplicator.<br>
Further, it should be noted that the above embodiments were<br>
restricted to applications having a constant bit rate.<br>
However, the present invention is not limited thereto and<br>
thus quantization by clipping of, for example, the<br>
prefiltered signal used in these embodiments is only one<br>
possible alternative. Instead of clipping, a quantizing<br>
function with nonlinear characteristic curve could be used.<br>
For illustrating this, reference is made to Figs. 8a to 8c.<br>
Fig. 8a shows the above-used quantizing function resulting<br>
in clipping on three quantizing stages, i.e. a step<br>
function with three stages 402a, b, c, which maps<br>
unquantized values (x axis) to quantizing indices (y axis),<br>
wherein the quantizing stage height or quantizing step size<br>
A(n) is also marked. As can be seen, unquantized values<br>
higher than A(n)/2 are clipped to the respective next stage<br>
402a or c, respectively. Fig. 8b shows generally a<br>
quantizing function resulting in clipping to 2n+l<br>
quantizing stages. The quantizing step size ∆(n) is again<br><br>
shown. The quantizing functions of Figs. 8a and 8b<br>
represent quantizing functions, where the quantization<br>
between thresholds -∆(n) and ∆(n) or -N∆(n) and N∆(n)<br>
takes place in uniform manner, i.e. with the same stage<br>
height, whereupon the quantizing stage function proceeds in<br>
a flat way, which corresponds to clipping. Fig. 8c shows a<br>
nonlinear quantizing function, where the quantizing<br>
function proceeds across the area between -N∆(n) and N∆(n)<br>
not completely flat but with a lower slope, i.e. with a<br>
larger step size or stage height, respectively, compared to<br>
the first area. This nonlinear quantization does not<br>
inherently result in a constant bit rate, as it was the<br>
case in the above embodiments, but also generates the<br>
above-described deformation of the quantizing noise, so<br>
that the same adjusts to the signal PSD. Merely as a<br>
precautionary measure, it should be noted with reference to<br>
Figs. 8a-c, that instead of the uniform quantizing areas<br>
non-uniform quantization could be used, where, for example,<br>
the stage height increases continuously, wherein the stage<br>
heights could be scalable via a stage height adjustment<br>
value ∆(n). while maintaining their mutual relations.<br>
Therefore, for example, the unquantized value could be<br>
mapped via a nonlinear function to an intermediate value in<br>
the respective quantizer, wherein either before or<br>
afterwards multiplication with ∆(n) is performed, and<br>
finally the resulting value is uniformly quantized. In the<br>
respective dequantizer, the inverse would be performed,<br>
which means uniform dequantization via ∆(n) followed by<br>
inverse nonlinear mapping or, conversely, nonlinear<br>
conversion mapping at first followed by dequantization with<br>
∆(n). Finally, it should be noted that a continuously<br>
uniform, i.e. linear quantization by obtaining the above-<br>
described effect of deformation of the error PSD would also<br>
be possible, when the stage height would be adjusted so<br>
high or quantization so coarse that this quantization<br>
effectively works like a nonlinear quantization with regard<br>
to the signal statistic of the signal to be quantized, such<br>
as the prefiltered signal, wherein this stage height<br><br>
adjustment is again made possible by the forward adaptivity<br>
of the prediction.<br>
Further, the above-described embodiments can also be varied<br>
with regard to the processing of the encoded bit stream.<br>
Particularly, bit stream generator and extractor 214,<br>
respectively, could also be omitted.<br>
The different quantizing indices, namely the residual<br>
values of the prefiltered signals, the residual values of<br>
the prefilter coefficients and the residual values of the<br>
prediction coefficients could also be transmitted in<br>
parallel to each other, stored or made available in another<br>
way for decoding, separately via individual channels. On<br>
the other hand, in the case that a constant bit rate is not<br>
imperative, these data could also be entropy-encoded.<br>
Particularly, the above functions in the blocks of Figs. 1,<br>
4, 5 and 6 could be implemented individually or in<br>
combination by sub-program routines. Alternatively,<br>
implementation of an inventive apparatus in the form of an<br>
integrated circuit is also possible, where these blocks are<br>
implemented, for example, as individual circuit parts of an<br>
ASIC.<br>
Particularly, it should be noted that depending on the<br>
circumstances, the inventive scheme could also be<br>
implemented in software. The implementation can be made on<br>
a digital memory medium, particularly a disc or CD with<br>
electronically readable control signals, which can<br>
cooperate with a programmable computer system such that the<br>
respective method is performed. Generally, thus, the<br>
invention consists also in a computer program product<br>
having a program code stored on a machine-readable carrier<br>
for performing the inventive method when the computer<br>
program product runs on the computer. In other words, the<br>
invention can be realized as a computer program having a<br><br>
program code for performing the method when the computer<br>
program runs on a computer.<br><br>
1. An apparatus for encoding an information signal into<br>
an encoded information signal, comprising:<br>
a means (16) for determining a representation of a<br>
psycho-perceptibility motivated threshold, which<br>
indicates a portion of the information signal<br>
irrelevant with regard to perceptibility, by using a<br>
perceptual model;<br>
a means (18) for filtering the information signal	for<br>
normalizing the information signal with regard to	the<br>
psycho-perceptibility motivated threshold,	for<br>
obtaining a prefiltered signal;<br>
a means (20) for predicting the prefiltered signal in<br>
a forward-adaptive manner to obtain a predicted<br>
signal, a prediction error for the prefiltered signal<br>
and a representation of prediction coefficients, based<br>
on which the prefiltered signal can be reconstructed;<br>
and<br>
a means (22) for quantizing the prediction error for<br>
obtaining a quantized prediction error, wherein the<br>
encoded information signal comprises information about<br>
the representation of the psycho-perceptibility<br>
motivated threshold, the representation of the<br>
prediction coefficients and the quantized prediction<br>
error.<br>
2. The apparatus according to claim 1, wherein the<br>
means (22) for quantizing is implemented to quantize<br>
the prediction error via a quantizing function, which<br>
maps unquantized values of the prediction error to<br>
quantizing indices of quantizing stages, and whose<br><br>
course below a threshold is steeper than above a<br>
threshold.<br>
3.	The apparatus according to claim 1 or 2, wherein the<br>
means (22) for quantizing is implemented to obtain a<br>
quantizing stage height ∆(n) of the quantizing<br>
function in a backward-adaptive manner from the<br>
quantized prediction error.<br>
4.	The apparatus according to one of the preceding<br>
claims, wherein the means (22) for quantizing the<br>
prediction error is implemented such that the<br>
unquantized values of the prediction error are<br>
quantized via clipping by the quantizing function,<br>
which maps the unquantized values of the prediction<br>
error to quantizing indices of a constant and limited<br>
first number of quantizing stages for obtaining the<br>
quantized prediction error.<br>
5.	The apparatus according to claim 4, wherein the means<br>
(22) for quantizing is implemented to obtain a<br>
quantizing stage height ∆(n) of the quantizing<br>
function for quantizing a value (r(n)) of the<br>
prediction error in a backward-adaptive manner of two<br>
past quantizing indices ic(n-l) and ic(n-2) of the<br>
quantized prediction error according to ∆(n) = β 	∆(n-<br>
1) + 8(11), with β[0.0;1.0],δ(n) = δ0 for |ic(n-l) +<br>
ic(n-2)| ≤ I and δ(n) = δi for |ic(n-l) + ic(n-2)| &gt; I<br>
with constant parameters δ0, δi, I, wherein ∆(n-l)<br>
represents a quantizing stage height obtained for<br>
quantizing a previous value of the prediction error.<br>
6.	The apparatus according to claims 4 or 5, wherein the<br>
means for quantizing is implemented to quantize the<br>
prediction error in a nonlinear manner.<br>
7.	The apparatus according to one of claims 4 to 6,<br>
wherein the constant and limited first number is 3.<br><br>
8.	The apparatus according to one of the preceding<br>
claims, wherein the means (16) for determining is<br>
implemented to determine the psycho-perceptibility<br>
motivated threshold in a block-wise manner from the<br>
information signal.<br>
9.	The apparatus according to one of the preceding<br>
claims, wherein the means (16) for determining is<br>
implemented to represent the psycho-perceptibility<br>
motivated threshold in the LSF domain.<br>
10.	The apparatus according to one of the preceding<br>
claims, wherein the means (16) for determining is<br>
implemented to determine the psycho-perceptibility<br>
motivated threshold in a block-wise manner and to<br>
represent the same in filtered coefficients, to<br>
subject the filter coefficients to a prediction and to<br>
subject a filter coefficient residual signal resulting<br>
from the prediction to a quantization via a further<br>
quantizing function, which maps the unquantized values<br>
of the filter coefficient residual signal to<br>
quantizing indices of quantizing stages, and whose<br>
course below a further threshold is steeper than above<br>
the further threshold, for obtaining a quantized<br>
filter coefficient residual signal, wherein the<br>
encoded information signal also includes information<br>
about the quantized filter coefficient residual<br>
signal.<br>
11.	The apparatus according to claim 10, wherein the means<br>
(16) for determining is implemented such that the<br>
unquantized values of the filter coefficient residual<br>
signal are quantized via clipping by the further<br>
quantizing function, which maps the unquantized values<br>
of the filter coefficient residual signal to<br>
quantizing indices of a constant and limited second<br>
number of quantizing stages.<br><br>
12.	The apparatus according to claim 11, wherein the means<br>
(16) for determining is implemented such that the<br>
prediction is performed in a backward-adaptive manner<br>
based on quantizing indices of the quantized filter<br>
coefficient residual signal.<br>
13.	The apparatus according to one of claims 10 to 12,<br>
wherein the means (16) for determining is implemented<br>
such that the prediction of the filter coefficients is<br>
performed by using a prediction filter with constant<br>
coefficients.<br>
14.	The apparatus according to one of claims 9 to 13,<br>
wherein the means (16) for determining is further<br>
implemented to subject the filter coefficients for<br>
representing the psycho-perceptibility motivated<br>
threshold to a subtraction with a constant value,<br>
prior to subjecting the same to prediction.<br>
15.	The apparatus according to one of the preceding<br>
claims, wherein the means (20) for predicting the<br>
prefiltered signal in a forward-adaptive manner<br>
further comprises:<br>
a means (36) for determining prediction filter<br>
coefficients from the prefiltered signal; and<br>
a means (44, 446, 48) for predicting the prefiltered<br>
signal via a filter (44) controlled by the prediction<br>
filter coefficients.<br>
16.	The apparatus according to claim 15, wherein the<br>
means (36) for determining is implemented to determine<br>
the prediction filter coefficients in a block-wise<br>
manner from the prefiltered signal.<br><br>
17.	The apparatus according to claim 15 or 16, wherein the<br>
means (36) for determining is implemented to represent<br>
the prediction filter coefficients in the LSF domain.<br>
18.	The apparatus according to one of claims 15 to 17,<br>
wherein the means (36) for determining is implemented<br>
to determine the prediction filter coefficients in a<br>
block-wise manner, to subject the prediction filter<br>
coefficients to a prediction, and to subject a<br>
prediction filter coefficient residual signal<br>
resulting from the prediction to quantization by a<br>
third quantizing function, which maps the unquantized<br>
values of the prediction filter coefficient residual<br>
signal to quantizing indices of quantizing stages, and<br>
whose course below a third threshold is steeper than<br>
above the third threshold, for obtaining a quantized<br>
prediction filter coefficient residual signal, wherein<br>
the encoded information signal also comprises<br>
information about the quantized prediction filter<br>
coefficient residual signal.<br>
19.	The apparatus according to claim 18, wherein the means<br>
(36) for determining is implemented such that the<br>
unquantized values of the prediction filter<br>
coefficient residual signal are quantized via clipping<br>
to quantizing indices of the third number of<br>
quantizing stages by the third quantizing function,<br>
which maps the unquantized values of the prediction<br>
filter coefficient residual signal to quantize the<br>
indices of a constant and limited third number of<br>
quantizing stages.<br>
20.	The apparatus according to claim 18, wherein the means<br>
(36) for determining is implemented such that the<br>
prediction is performed in a backward-adaptive manner<br>
based on quantizing indices of the quantized<br>
prediction filter coefficients residual signal for one<br>
or several previous blocks of the prefiltered signal.<br><br>
21.	The apparatus according to one of claims 18 to 19,<br>
wherein the means (36) for determining is implemented<br>
such that the prediction of the prediction filter<br>
coefficients is performed by using a prediction filter<br>
with constant coefficients.<br>
22.	The apparatus according to one of claims 18 to 21,<br>
wherein the means (36) for determining is further<br>
implemented to subject the prediction filter<br>
coefficients to a subtraction with a constant value<br>
prior to subjecting the same to prediction.<br>
23.	The apparatus according to one of the preceding<br>
claims, which is implemented for encoding an audio<br>
signal or a video signal as information signal,<br>
wherein the perceptual model is a psychoacoustic model<br>
and the psycho-perceptibility motivated threshold a<br>
psychoacoustically motivated threshold, or the<br>
perceptual model is a psychovisual model and the<br>
psycho-perceptibility motivated threshold is a<br>
pyschovisually motivated threshold.<br>
24.	An apparatus for decoding an encoded information<br>
signal comprising information about a representation<br>
of a psycho-perceptibility motivated threshold, a<br>
representation of prediction coefficients and a<br>
quantized prediction error into a decoded information<br>
signal, comprising:<br>
a means (206) for dequantizing the quantized<br>
prediction error for obtaining a dequantized<br>
prediction error;<br>
a means (208) for determining a predicted signal based<br>
on the prediction coefficients;<br><br>
a means (210) for reconstructing a prefiltered signal<br>
based on the predicted signal and the dequantized<br>
prediction error; and<br>
a means (212) for filtering the prefiltered signal	for<br>
reconverting a normalization with regard to	the<br>
psycho-perceptibility motivated threshold for<br>
obtaining the decoded information signal.<br>
25.	The apparatus according to claim 24, wherein the means<br>
(206) for dequantizing is implemented to dequantize<br>
the quantized prediction error to a limited and<br>
constant number of quantizing stages.<br>
26.	The apparatus according to claim 25, wherein the means<br>
(206) for dequantizing is implemented to obtain a<br>
quantizing stage height ∆(n) between the quantizing<br>
stages in a backward-adaptive manner from already<br>
dequantized quantizing indices of the quantized<br>
prediction error.<br>
27.	The apparatus according to claim 25 or 26, wherein the<br>
means (260) for dequantizing is implemented to obtain<br>
a quantizing stage height (∆(n)) between the<br>
quantizing stages for dequantizing a quantizing index<br>
of the quantized prediction error in a backward-<br>
adaptive manner from two previous quantizing indices<br>
ic(n-l) and ic(n-2) of the quantized prediction error<br>
according to ∆(n) = β∆(n-l) + 8(n) with<br>
β[0.0;1.0],δ(n) = δ0 for |ic(n-l) + ic(n-2)| ≤ I and<br>
δ(n) = δi for |ic(n-l) + ic(n-2)| &gt; I having constant<br>
parameters δ0, δi, I, wherein ∆(n-l) represents a<br>
quantizing stage height obtained for dequantizing<br>
ic(n-l).<br>
28.	The apparatus according to one of claims 25 to 27,<br>
wherein the constant and limited number is less than<br>
or equal to 32.<br><br>
29.	The apparatus according to one of claims 25 to 28,<br>
wherein the constant and limited number is 3.<br>
30.	The apparatus according to one of claims 24 to 29,<br>
wherein the means (212) for filtering comprises:<br>
a means (230) for determining perceptual threshold<br>
filter coefficients from the information about the<br>
representation of the psycho-perceptibility motivated<br>
threshold in a block-wise manner for blocks of a<br>
sequence of blocks of the prefiltered signal; and<br>
a postfilter (232) for filtering the prefiltered<br>
signal by using the perceptual threshold filter<br>
coefficients.<br>
31.	The apparatus according to one of claims 24 to 30,<br>
wherein the means (230) for determining is implemented<br>
to obtain the perceptual threshold filter coefficients<br>
by reconversion from an LSF domain.<br>
32.	The apparatus according to one of claims 24 to 31,<br>
wherein the means (230) for determining is implemented<br>
to obtain quantizing indices of a quantized filter<br>
coefficient residual signal from the representation of<br>
the psycho-perceptibility motivated threshold, to<br>
dequantize the same to a limited and constant second<br>
number of quantizing levels, for obtaining a<br>
dequantized filter coefficient residual signal, to<br>
predict the filter coefficients representing the<br>
psycho-perceptibility motivated threshold and to add<br>
the same to the dequantized filter coefficient<br>
residual signal and to convert a reconstructed filter<br>
coefficient residual signal resulting from the<br>
addition by reconversion into the perceptual threshold<br>
filter coefficients.<br><br>
33.	The apparatus according to claim 32, wherein the means<br>
(230) for determining is implemented such that the<br>
prediction is performed in a backward-adaptive manner<br>
based on already predicted filter coefficients<br>
representing the psycho-perceptibility motivated<br>
threshold.<br>
34.	The apparatus according to claims 32 or 33, wherein<br>
the means (230) for determining is implemented such<br>
that the prediction of the filter coefficients<br>
representing the psycho-perceptibility motivated<br>
threshold is performed by using a prediction filter<br>
with constant coefficients.<br>
35.	The apparatus according to one of claims 32 to 34,<br>
wherein the means (230) for determining is further<br>
implemented to subject the reconstructed filter<br>
coefficient residual signal resulting from the<br>
addition to an addition with a constant value prior to<br>
reconversion.<br>
36.	The apparatus according to one of claims 24 to 37,<br>
wherein the means (208) for determining a predicted<br>
signal further comprises:<br>
a means (224) for determining prediction filter<br>
coefficients from the representation of prediction<br>
coefficients comprised in the encoded information<br>
signal; and<br>
a means (226, 228) for predicting the prefiltered<br>
signal via a filter (226) controlled by the prediction<br>
filter coefficients.<br>
37.	The apparatus according to claim 36, wherein the means<br>
(224) for determining prediction filter coefficients<br>
is implemented to determine the same in a block-wise<br><br>
manner for blocks of a sequence of blocks of the<br>
prefiltered signal.<br>
38.	The apparatus according to one of claims 36 or 37,<br>
wherein the means (224) for determining is implemented<br>
to obtain the prediction filter coefficients by<br>
reconversion from an LSF domain.<br>
39.	The apparatus according to one of claims 36 to 38,<br>
wherein the means (224) for determining is implemented<br>
to obtain quantizing indices of a quantized prediction<br>
coefficient residual signal from the representation of<br>
the prediction coefficients, to dequantize the same to<br>
a limited and constant third number of quantizing<br>
levels for obtaining a dequantized prediction<br>
coefficient residual signal, to predict prediction<br>
filter coefficients and to add the same to the<br>
dequantized prediction coefficient residual signal and<br>
to convert a reconstructed prediction coefficient<br>
residual signal resulting from the addition by<br>
reconversion into the prediction filter coefficients.<br>
40.	The apparatus according to claim 39, wherein the means<br>
(224) for determining is implemented such that the<br>
prediction is performed in a backward-adaptive manner<br>
based on the already predicted prediction<br>
coefficients.<br>
41.	The apparatus according to claim 39 or 40, wherein the<br>
means (224) for determining is implemented such that<br>
the prediction of the prediction coefficients is<br>
performed by using a prediction filter with constant<br>
coefficients.<br>
42.	The apparatus according to one of claims 39 to 41,<br>
wherein the means (224) for determining is further<br>
implemented to subject the reconstructed prediction<br>
coefficient residual signal resulting from the<br><br>
addition to an addition with the constant value prior<br>
to reconversion.<br>
43.	The apparatus according to one of claims 24 to 42,<br>
which is implemented for decoding an audio signal or a<br>
video signal as information signal, and wherein the<br>
psycho-perceptibility motivated threshold is an<br>
acoustic masking threshold or a visual masking<br>
threshold.<br>
44.	A method for encoding an information signal into an<br>
encoded information signal, comprising:<br>
using a perceptibility model, determining a<br>
representation of a psycho-perceptibility motivated<br>
threshold indicating a portion of the information<br>
signal irrelevant with regard to perceptibility;<br>
filtering the information signal for normalizing the<br>
information signal with regard to the psycho-<br>
perceptibility motivated threshold for obtaining a<br>
prefiltered signal;<br>
predicting the prefiltered signal in a forward-<br>
adaptive manner to obtain a prefiltered signal, a<br>
prediction error to the prefiltered signal and a<br>
representation of prediction coefficients, based on<br>
which the prefiltered signal can be reconstructed; and<br>
quantizing the prediction error to obtain a quantized<br>
prediction error, wherein the encoded information<br>
signal comprises information about the representation<br>
of the psycho-perceptibility motivated threshold, the<br>
representation of the prediction coefficients and the<br>
quantized prediction error.<br>
45.	A method for decoding an encoded information signal<br>
comprising information about the representation of a<br><br>
psycho-perceptibility motivated threshold, a<br>
representation of prediction coefficients and a<br>
quantized prediction error into a decoded information<br>
signal, comprising:<br>
dequantizing the quantized prediction error to obtain<br>
a dequantized prediction error;<br>
determining a predicted signal based on the prediction<br>
coefficient;<br>
reconstructing a prefiltered signal based on the<br>
predicted signal and the dequantized prediction error;<br>
and<br>
filtering the prefiltered signal for converting a<br>
normalization with regard to the psycho-perceptibility<br>
motivated threshold to obtain the decoded information<br>
signal.<br>
46.	A computer program with a program code for performing<br>
the method according to claim 44 or 45 when the<br>
computer program runs on a computer.<br>
47.	An encoder, comprising:<br>
an information signal input (12);<br>
a perceptibility threshold determiner (26) operating<br>
according to a perceptibility model having an input<br>
coupled to the information signal input and a<br>
perceptibility threshold output;<br>
an adaptive prefilter (34) comprising a filter input<br>
coupled to the information signal input, a filter<br>
output and a adaption control input coupled to the<br>
perceptibility threshold output,<br><br>
a forward prediction coefficient determiner (36)<br>
comprising an input coupled to the prefilter output<br>
and a prediction coefficient output;<br>
a first subtracter (42) comprising a first input<br>
coupled to the prefilter output, a second input and an<br>
output;<br>
a clipping and quantizing stage (52) comprising a<br>
limited and constant number of quantizing levels, an<br>
input coupled to the subtracter output, a quantizing<br>
step size control input and an output;<br>
a step size adjuster (54) comprising an input coupled<br>
to the output of the clipping and quantizing stage<br>
(52) and a quantizing step size output coupled to the<br>
quantizing step size control input of the clipping and<br>
quantizing stage (52);<br>
a dequantizing stage (50) comprising an input coupled<br>
to the output of the clipping/quantizing stage and a<br>
dequantizer control output;<br>
an adder (48) comprising a first adder input coupled<br>
to the dequantizer output, a second adder input and an<br>
adder output;<br>
a prediction filter (44, 46) comprising a prediction<br>
filter input coupled to the adder output, a prediction<br>
filter output coupled to the second subtracter input<br>
as well as to the second adder input, as well as a<br>
prediction coefficient input coupled to the prediction<br>
coefficient output;<br>
an information signal generator (24) comprising a<br>
first input coupled to the perceptibility threshold<br>
output, a second input coupled to the prediction<br>
coefficient output, a third input coupled to the<br><br>
output of the clipping and quantizing stage and an<br>
output representing an encoder output.<br>
48. A decoder for decoding an encoded information signal<br>
comprising information about a representation of a<br>
psycho-perceptibility motivated threshold, prediction<br>
coefficients and a quantized prediction error, into a<br>
decoded information signal, comprising:<br>
a decoder input;<br>
an extractor (214) comprising an	input coupled to the<br>
decoder input, a perceptibility	threshold output, a<br>
prediction coefficient output	and a quantized<br>
prediction error output;<br>
a dequantizer (206) comprising a limited and constant<br>
number of quantizing levels, a dequantizer input<br>
coupled to the quantized prediction error output, a<br>
dequantizer output and a quantizing threshold control<br>
input;<br>
a backward-adaptive threshold adjuster comprising an<br>
input coupled to the quantized prediction error<br>
output, and an output coupled to the quantized<br>
threshold control input;<br>
an adder (222) comprising a first adder input coupled<br>
to the dequantizer output, a second adder input and an<br>
adder output;<br>
a prediction filter (226) comprising a precision<br>
filter input coupled to the adder output, a prediction<br>
filter output coupled to the second input, and a<br>
prediction filter coefficient input coupled to the<br>
prediction coefficient output; and<br><br>
an adaptive postfilter (232) comprising a prediction<br>
filter input coupled to the adder output, a prediction<br>
filter output representing a decoder output, and an<br>
adaption control input coupled to the perceptibility<br>
threshold output.<br><br>
A very coarse quantization exceeding the measure<br>
determined by the masking threshold without or only<br>
very little quality losses is enabled by quantizing<br>
not immediately the prefiltered signal, but a<br>
prediction error obtained by forward-adaptive<br>
prediction of the prefiltered signal. Due to the<br>
forward adaptivity, the quantizing error has no<br>
negative effect on the prediction on the decoder side.</n></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=6Tnp9wnlp4kaQQ1SU2p1bQ==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=6Tnp9wnlp4kaQQ1SU2p1bQ==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="268868-venturi-for-a-nebulization-device-and-nebulization-device-therefor.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="268870-apparatus-and-method-for-the-optical-examination-of-value-documents.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>268869</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>4589/KOLNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>39/2015</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>25-Sep-2015</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>21-Sep-2015</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>12-Nov-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER GESELLSCHAFT ZUR FORDERUNG DER ANGEWANDTEN FORSCHUNG E. V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C, 80686 MUNICH</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>GERALD SCHULLER</td>
											<td>LEOPOLDSTRASSE 13, 99089 ERFURT</td>
										</tr>
										<tr>
											<td>2</td>
											<td>ULRICH KRAMER</td>
											<td>ERFURTER STRASSE 31C, 98693 ILMENAU</td>
										</tr>
										<tr>
											<td>3</td>
											<td>MANFRED LUTZKY</td>
											<td>HEINRICH VON BRENTANO-STRASSE 9 90427 NURNBERG</td>
										</tr>
										<tr>
											<td>4</td>
											<td>STEFAN WABNIK</td>
											<td>UNTERPORLITZER STRASSE 58 98693 ILMENAU</td>
										</tr>
										<tr>
											<td>5</td>
											<td>JENS HIRSCHFELD</td>
											<td>STEINWEG 32, 36266 HERING</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G10L 19/02</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2007/001730</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2007-02-28</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>102006022346.2</td>
									<td>2006-05-12</td>
								    <td>Germany</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/268869-apparatus-for-encoding-an-information-signal-and-apparatus-for-decoding-an-encoded-information-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:25:59 GMT -->
</html>
