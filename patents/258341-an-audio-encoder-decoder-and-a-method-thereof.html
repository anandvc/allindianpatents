<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/258341-an-audio-encoder-decoder-and-a-method-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 05:54:31 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 258341:AN AUDIO ENCODER, DECODER AND A METHOD THEREOF</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">AN AUDIO ENCODER, DECODER AND A METHOD THEREOF</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to an audio encoder and decoder and methods for audio encoding and decoding. In the encoder an audio signal is split into an anechoic signal part and information regarding a reverberant field associated with the audio signal, preferably by a representation using only few parameters such as reverberation time and reverberation amplitude. The anechoic signal is then encoded using an audio codec. At the decoder the anechoic signal part is restored using the audio codec, and the restored anechoic signal part is transformed into the substantially original audio signal by applying reverberance according to the information regarding the reverberant field, preferably by convolution with a room impulse response generated on the basis of the reverberant field information. According to the invention the audio codec involved needs only be capable of encoding anechoic audio signals, thus solving the problem of parametric audio codecs providing poor performance on reverberant audio signals.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
Coding reverberant sound signals<br>
The invention relates to the field of audio signal coding. Especially, the invention relates to the field of efficient coding of reverberant audio signals. The invention relates to an encoder, a decoder, methods for encoding and decoding, an encoded audio signal, storage and transmission media with data representing such encoded signal, and audio devices with an encoder and/or decoder.<br>
Reverberation is caused by the acoustics of the environment, e.g. a concert hall, in which the sound is recorded. It consists of the reflections against surfaces in this environment. As a result, the recorded sound signal does not only contain the direct "dry" audio signal, but also a series of delayed and attenuated reflections. I.e. the reverberation component consists of delayed and attenuated versions of the direct "dry11 sound and, as a result, the reverberant component is correlated with the direct signal Here, "dry" means "anechoic", i.e. containing substantially no echos or reverberation.<br>
Experiments show that some non-transparent sound codecs do not function properly by coding sound signals with a significant amount of reverberation, i.e. the codecs produce sound signals with clearly audible artefacts. However, the same sound codec may perform well on sound signals with very or purely "dry" signals, i.e. sound signals recorded in an anechoic environment or artificially created sounds without reverberation added.<br>
In many applications, reverberation is considered a negative characteristic of the sound signal. For example, the performance of automatic speech recognition systems degrades when the speech contains reverberation, and, in communication applications, reverberation negatively affects the intelligibility and quality of the speech. A solution to this problem may be to remove the reverberation from the signal, i.e., to de-reverberate, and this is also done in some systems (Basbug et al., 2003) - see the list of references.<br>
In high-quality audio coding, however, the situation is different. Audio coding strives for transparency, and therefore the reverberation needs to be coded as well. Moreover, in music the reverberation component is an important part of the signal and audio signals<br><br>
with this component are preferred to signals without it, which sound "dry" or dull, and the sound lacks the significant individual character of the recording environment.<br>
To the knowledge of the inventors in the prior art no special precautions are taken to code the reverberation component of sound signals and this may lead to quality problems.<br>
It may be seen as an object of the present invention to provide a method and an audio encoder and decoder capable of handling reverberant audio signals in high quality by using audio codecs.<br>
According to a first aspect of the invention, this object is complied with by providing an audio encoder adapted to encode an audio signal, the audio encoder comprising<br>
separation means adapted to separate the audio signal into a substantially anechoic audio signal and information describing a reverberant field associated with the audio signal,<br>
encoder means adapted to encode the substantially anechoic audio signal into a first encoded signal part and encode the information describing the reverberant field into a second encoded signal part.<br>
The separation means serves to split the audio signal into an anechoic, i.e. "dry", part and into information regarding reverberant aspects related to the audio signal. In other words, the audio signal is de-reverberated, and information describing a reverberant field associated with the audio signal is extracted, i.e. information enabling a substantially transparent recreation of the reverberance.<br>
The encoder means handles the "dry" part and the reverberant part separately. Thus, it is possible to apply an audio codec for encoding the "dry" part to the first encoded signal part, while the reverberation part may be encoded according to completely different algorithms suited to describe reverberation, such as a parametric description sufficiently precise to substantially recreate the reverberation part of the signal at the encoder.<br>
This relieves the audio codec from the task of coding the reverberation component, solving the problem of coding reverberant sound signals. Instead, means for encoding a reverberant part of the reverberant audio signal may comprise reverberation algorithms based on a parametric description of the reverberant part of the original audio signal such using a very limited number of parameters. As an effect, a parametric codec may be used solely for encoding a "dry" signal, which such codec is well suited for. Hereby it is<br><br>
possible to substantially transparently encode and decode a reverberant audio signal using an audio codec in combination with means for encoding a reverberant part of the reverberant audio signal.<br>
In addition, encoding efficiency is increased compared to encoding a<br>
reverberant sound signal directly. This is due to the fact that an encoder according to the first aspect exploits the correlation introduced in the sound signal by the reverberant field to the maximum, resulting in higher coding efficiency. I.e. redundancy in the reverberant part is taken into account specifically.<br>
In one embodiment the encoder means may be adapted to encode the substantially anechoic audio signal according to a parametric audio codec, e.g. (Schuijers et al., 2003). In another preferred embodiment, the separation means is adapted to apply Unoki's de-reverberation algorithm to the audio signal so as to separate it into the substantially anechoic part and the information describing the reverberant field. By Unoki's de-reverberation algorithm is understood the de-reverberation principles described in: M. Unoki, M. Furukawa, K. Sakata, and M. Akagi, "A Method based on the MTF Concept for dereverberating the Power Envelope from the Reverberant Signal," in Proc. IEEE Int. Conf. on Acoust, Speech, Signal Processing, Hong Kong, China, April 6-19, Vol. I, pp. 840- 843, 2003. This paper is hereby incorporated by reference.<br>
A second aspect of the invention provides an audio decoder adapted to regenerate an audio signal from an encoded audio signal with first and second parts, the audio decoder comprising<br>
decoder means adapted to decode the first encoded signal part into a substantially anechoic audio signal, the decoder means further being adapted to generate from the second encoded signal part information describing a reverberant field associated with the audio signal, and<br>
transforming means adapted to add reverberance to the substantially anechoic audio signal based on the information describing the reverberant field.<br>
Thus, the audio decoder according to the second aspect is adapted to decode an encoded signal from the audio encoder according to the first aspect and thus form an encoder/decoder system.<br>
In the decoder means the "dry" signal is reconstructed. Reverberance is then added to the "dry" signal by the transforming means based on the reverberation information. This is known from existing artificial reverberation generators or room simulators that are able to produce high audio quality reverberation based on few parameters. An extra<br><br>
advantage of this method, i.e., addition of reverberation in the decoder, is that the reverberance masks some potential artefacts in the decoded "dry" signal.<br>
Preferably, the transforming means comprises means for convoluting the regenerated anechoic audio signal with an impulse response h(t) being a function of time t, wherein h(t) is based on the second encoded signal part.<br>
Preferably, the second encoded signal part comprises a representation of<br>
a first parameter T related to a reverberation time of the audio signal, and<br>
a second parameter A related to a reverberation amplitude of the audio signal.<br>
The decoder means may be adapted to decode the first encoded signal part according to a parametric audio codec.<br>
In a third aspect the invention provides a method of encoding an audio signal, comprising the steps of<br>
separating the audio signal into a substantially anechoic part and information describing a reverberant field associated with the audio signal,<br>
encoding the substantially anechoic part of the audio signal into a first encoded signal,<br>
encoding the information describing the reverberant field into a second encoded signal.<br>
In a fourth aspect the invention provides a method of decoding an encoded audio signal representing an original audio signal, the method comprising the steps of<br>
decoding a first encoded signal part into a first audio signal,<br>
decoding a second encoded signal part into information describing a reverberant field associated with the original audio signal, and<br>
transforming the first audio signal by adding reverberation based on the information describing the reverberant field so as to regenerate the original audio signal.<br>
In a fifth aspect the invention provides an encoded audio signal representing an original audio signal, the encoded signal comprising<br>
a first part representing a substantially anechoic part of the original audio signal, and<br>
a second part representing information about a reverberant field associated with the original audio signal.<br>
The encoded signal may be a digital electrical signal with a format according to standard digital audio formats. The signal may be transmitted using an electrical connecting cable between two audio devices. However, the encoded signal could be a<br><br>
wireless signal, such as an air-borne signal using a radio frequency carrier, or it may be an optical signal adapted for transmission using an optical fiber.<br>
In a sixth aspect the invention provides a storage medium comprising data representing an encoded audio signal according to the fifth aspect. The storage medium is preferably a standard audio data storage medium such as DVD, CD, read-writable CD, minidisk, MP3 disc, compact flash, memory stick etc. However, it may also be a computer data storage medium such as a computer harddisk, a computer memory, a floppy disk etc.<br>
In a seventh aspect the invention provides an audio device comprising an audio encoder according to the first aspect.<br>
In an eighth aspect the invention provides an audio device comprising an audio decoder according to the second aspect.<br>
Preferred audio devices according to the seventh and eighth aspects are all different types of tape, disk, or memory based audio recorders and players. For example: MP3 players, DVD players, audio processors for computers etc. In addition, it may be advantageous for mobile phones.<br>
In the following the invention is described in more details with reference to the accompanying Fig, 1 illustrating a block diagram of a preferred encoder and decoder according to the invention.<br>
While the invention is susceptible to various modifications and alternative forms, specific embodiments have been shown by way of example in the drawing and will be described in detail herein. It should be understood, however, that the invention is not intended to be limited to the particular forms disclosed. Rather, the invention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the invention as defined by the appended claims.<br>
Figure 1 shows a block diagram illustrating the principles of a preferred embodiment of an encoder 1 and decoder 2 with respect to signal flow.<br>
An audio signal is received at an input IN of the encoder 1. First, the audio signal is handled by a reverberation extractor REV EXT. Here, the audio signal is de-reverberated using Unoki's de-reverberation algorithm (Unoki et al., 2003). It should be noted that for monaural signals, it is not trivial to extract the reverberation component from a<br><br>
reverberant audio signal. However, this extraction does not have to be perfect and a gain may already be obtained by removing part of the reverberant field. For multi-channel signals already good de-reverberation algorithms exist.<br>
The resulting "dry" signal is then encoded in an SSC encoder part of the encoder means ENC such as described in (Schuijers et al., 2003), while another part of the encoder means ENC encodes the reverberant part extracted by the reverberation extractor REV EXT. Output from the encoder 1 has two parts: a first part being a bit stream 3 provided by the SSC encoder part of the encoder means ENC, and a second part comprising two reverberation parameters 4 provided by the reverberation extractor REV EXT, i.e. a parameter description of the removed reverberation part of the original audio signal. Preferably, the two reverberation parameters 4 are the reverberation time TR, and a reverberation amplitude constant A, associated with a level of the reverberation part of the original audio signal relative to the "dry" part of the audio signal, being a very brief description of the room reverberation impulse response h(t). One could also send the complete room reverberation impulse response h(t) in the beginning of the signal, with updates during the signal when needed; this is also efficient, because h(t) usually varies slowly or not at all. The encoder part of the encoder means ENC that encodes the reverberant part highly depends on the actual form of the reverberant part delivered by the reverberation extractor REV EXT. In case the reverberation extractor REV EXT delivers only a few reverberation parameters, encoding of the reverberation part can be said to be included in the extraction itself, and thus the encoder means ENC may not need to add further encoding to the reverberation part received from the reverberation extractor REV EXT.<br>
The decoder 2 receives the SSC encoded signal 3 and the two reverberation parameters 4 from the encoder 1. It is to be understood that the Fig. 1 merely illustrates the principles of an encoder/decoder system. The encoded signals 3,4, or data representing these signals 3,4, may typically be stored on a data carrier or storage medium, such as an audio disk for a MP3 player etc.<br>
In the decoder 2 the SSC encoded signal 3 is decoded by a SSC decoder part of the decoder means DEC thus restoring the substantially "dry" audio signal. This restored "dry" signal is then fed to a reverberation processor REV. The reverberation processor REV also receives the two reverberation parameters 4 that have been decoded by another part of the decoder means DEC, and based on these parameters 4, the reverberation processor REV generates an impulse response based on the extracted reverberation information in the two reverberation parameters 4, i.e. a room impulse response is constructed based on the two<br><br>
reverberation parameters 4. The reverberation part of the original audio signal is applied to the restored "dry" audio signal from the SSC decoder part of the decoder means DEC by convolution with the generated reverberation impulse response. The restored "dry" audio signal is thus transformed into a restored, or at least substantially restored, original audio signal. Finally, this restored original audio signal is the provided at an output OUT of the encoder 2.<br>
The room reverberation impulse response h(t), where t denotes time, generated in the reverberation processor REV is preferable of the form:<br>
h(t) - A*exp(-6.9 t/TR)*n(t), in which n(t) is a white noise signal.<br>
In principle the invention can be used in connection with any audio encoder, e.g. the SSC encoder as mentioned described in (Schuijers et al., 2003), which is currently being standardised in MPEG, and with any de-reverberation algorithm.<br>
Encoders and decoders according to the invention may be implemented on a single chip with a digital signal processor. The chip can then be applied built into audio devices independent on signal processor capacities of such devices. The encoders and decoders may alternatively be implemented purely by algorithms running on a main signal processor of the application device.<br>
In the claims reference signs to the figures are included for clarity reasons only. These references to exemplary embodiments in the figures should not in any way be construed as limiting the scope of the claims.<br><br>
LIST OF REFERENCES:<br>
F. Basbug, K. Swaminathan, and S. Nandkumar, "Noise Reduction and Echo Cancellation Front-End for Speech Codecs," IEEE Transactions on Speech and Audio Processing, vol.11, no.l, 2003.<br>
E. Schuijers, W. Oomen, B. den Brinker, J. Breebaart, "Advances in Parametric Coding for High-Quality Audio," in Proc. of the 114th AES Convention 2003 March 22-25 Amsterdam, The Netherlands, 2003.<br>
M. Unoki, M. Furukawa, K. Sakata, and M. Akagi, "A Method based on the MTF Concept for dereverberating the Power Envelope from the Reverberant Signal," in Proc. IEEE Int. Conf. on Acoust., Speech, Signal Processing, Hong Kong, China, April 6-19, Vol. I, pp. 840-843,2003.<br><br><br>
WE CLAIM:<br>
1.	An audio encoder (1) adapted to encode an audio signal, the audio encoder (1) comprising:<br>
separation means adapted to separate the audio signal into a substantially anechoic audio signal and information describing a reverberant field associated with the audio signal,<br>
encoder means adapted to encode the substantially anechoic audio signal into a first encoded signal part (3) and encode the information describing the reverberant field into a second encoded signal part (4).<br>
2.	Audio encoder (1) according to claim 1, wherein the separation means is adapted to apply Unoki's de-reverberation algorithm to the audio signal so as to separate it into the substantially anechoic part and the information describing the reverberant field.<br>
3.	Audio encoder (1) according to claim 1, wherein the encoder means is adapted to encode the substantially anechoic audio signal according to a parametric audio codec.<br>
4.	An audio decoder (2) adapted to regenerate an audio signal from an encoded audio signal with first (3) and second (4) parts, the audio decoder (2) comprising<br>
decoder means adapted to decode the first encoded signal part (3) into a substantially anechoic audio signal, the decoder means further being adapted to generate from the second encoded signal part (4) information describing a reverberant field associated with the audio signal, and<br>
transforming means adapted to add reverberance to the substantially anechoic audio signal based on the information describing the reverberant field.<br>
5.	Audio decoder (2) according to claim 4, wherein the transforming means comprises means for convoluting the substantially anechoic audio signal with an impulse response h(t) being a function of time t, wherein h(t) is based on the information describing the reverberant field.<br><br>
6.	Audio decoder (2) according to claim 5, wherein the decoder means is adapted to generate from the second encoded signal part (4)<br>
a first parameter T related to a reverberation time of the audio signal, and a second parameter A related to a reverberation amplitude of the audio signal.<br>
7.	Audio decoder (2) according to claim 6, wherein the transforming means is adapted to calculate said impulse response h(t) based on said first and second parameters as h(t) = A*exp(k*t/T)*n(t), wherein k represents a constant and n(t) represents a noise signal.<br>
8.	Audio decoder (2) according to claim 4, wherein the decoder means is adapted to decode the first encoded signal part (3) according to a parametric audio codec.<br>
9.	A method of encoding an audio signal, comprising the steps of separating the audio signal into a substantially anechoic part and information<br>
describing a reverberant field associated with the audio signal,<br>
encoding the substantially anechoic part of the audio signal into a first<br>
encoded signal,<br>
encoding the information describing the reverberant field into a second<br>
encoded signal.<br>
10.	A method of decoding an encoded audio signal representing an original audio signal, the method comprising the steps of<br>
decoding a first encoded signal part into a first audio signal, decoding a second encoded signal part into information describing a<br>
reverberant field associated with the original audio signal, and<br>
transforming the first audio signal by adding reverberation based on the<br>
information describing the reverberant field so as to regenerate the original audio signal.<br>
11.	Encoded audio signal (3), (4) representing an original audio signal, the encoded signal (3), (4) comprising<br>
a first part (3) representing a substantially anechoic part of the original audio signal, and<br><br>
a second part (4) representing information about a reverberant field associated with the original audio signal.<br>
12.	A storage medium comprising data representing an encoded audio signal (3), (4) according to claim 11.<br>
13.	Audio device comprising an audio encoder (1) according to claim 1.<br>
14.	Audio device comprising an audio decoder (2) according to claim 4.<br>
Dated this 3rd day of January 2007 <br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIEFNRU5ERUQgQ0xBSU1TICAxNC0xMS0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   AMENDED CLAIMS  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIEFNRU5ERUQgUEFHRVMgT0YgU1BFQ0lGSUNBVElPTiAgMTQtMTEtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   AMENDED PAGES OF SPECIFICATION  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIENPUlJFU1BPTkRFTkNFIE9USEVSUyAgMTAtMTItMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   CORRESPONDENCE OTHERS  10-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIEVYQU1JTkFUSU9OIFJFUE9SVCBSRVBMWSBSRUNFSVZFRCAgMTQtMTEtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   EXAMINATION REPORT REPLY RECEIVED  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIEZPUk0tMSAgMTQtMTEtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   FORM-1  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIEZPUk0tMyAgMTQtMTEtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   FORM-3  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIEZPUk0tNSAgMTQtMTEtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   FORM-5  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIE9USEVSUyAgMTQtMTEtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   OTHERS  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyAgIFBPV0VSIE9GIEFUVE9STkVZICAxNC0xMS0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">72-CHENP-2007   POWER OF ATTORNEY  14-11-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyBBTUVOREVEIENMQUlNUyAxOS0xMi0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">72-CHENP-2007 AMENDED CLAIMS 19-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyBBTUVOREVEIFBBR0VTIE9GIFNQRUNJRklDQVRJT04gMTktMTItMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007 AMENDED PAGES OF SPECIFICATION 19-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyBFWEFNSU5BVElPTiBSRVBPUlQgUkVQTFkgUkVDSVZFRCAxOS0xMi0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">72-CHENP-2007 EXAMINATION REPORT REPLY RECIVED 19-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyBGT1JNLTEgMTktMTItMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">72-CHENP-2007 FORM-1 19-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyBPVEhFUlMgUEFURU5UIERPQ1VNRU5UIDE5LTEyLTIwMTMucGRm" target="_blank" style="word-wrap:break-word;">72-CHENP-2007 OTHERS PATENT DOCUMENT 19-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItQ0hFTlAtMjAwNyBQT1dFUiBPRiBBVFRPUk5FWSAxOS0xMi0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">72-CHENP-2007 POWER OF ATTORNEY 19-12-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">72-chenp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1jb3JyZXNwb25kbmVjZS1vdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1kZXNjcmlwdGlvbihjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">72-chenp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1mb3JtIDI2LnBkZg==" target="_blank" style="word-wrap:break-word;">72-chenp-2007-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzItY2hlbnAtMjAwNy1wY3QucGRm" target="_blank" style="word-wrap:break-word;">72-chenp-2007-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="258340-a-machine-perfusion-solution-for-maintaining-donor-organ-viability.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="258342-assignment-acknowledgement-for-a-wireless-communication-system.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>258341</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>72/CHENP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>01/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>03-Jan-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>01-Jan-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>08-Jan-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>KONINKLIJKE PHILIPS ELECTRONICS N.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>GROENEWOUDSEWEG 1, NL- 5621 BA EINDHOVEN</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>GERRITS, ANDREAS, J.</td>
											<td>C/O PROF. HOLSTLAAN 6, NL - 5656AA, EINDHOVEN</td>
										</tr>
										<tr>
											<td>2</td>
											<td>BOSCARINO, CORRADO</td>
											<td>C/O PROF. HOLSTLAAN 6, NL - 5656AA, EINDHOVEN</td>
										</tr>
										<tr>
											<td>3</td>
											<td>VAN SCHIJNDEL, NICOLLE, H.</td>
											<td>C/O PROF. HOLSTLAAN 6, NL - 5656AA, EINDHOVEN</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G10L 19/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB2005/051820</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-06-03</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>04102582.6</td>
									<td>2004-06-08</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/258341-an-audio-encoder-decoder-and-a-method-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 05:54:32 GMT -->
</html>
