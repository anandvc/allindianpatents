<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/257008-method-and-apparatus-for-encoding-and-decoding-audio-signals by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:55:50 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 257008:METHOD AND APPARATUS FOR ENCODING AND DECODING AUDIO SIGNALS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR ENCODING AND DECODING AUDIO SIGNALS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to a method for encoding audio channels, the method comprising : generating two or more cue codes for one or more audio channels, wherein at least one cue code is an envelope cue code generated by characterizing a temporal envelope in one of the one or more audio channels, wherein the two or more cue codes further comprise one or more of inter- channel correlation (ICC) codes, inter-channel level difference (ICLD) codes, and inter-channel time difference (ICTD) codes, wherein a first time resolution associated with the envelope cue code is finer than a second time resolution associated with the other cue code(s), and wherein the temporal envelope is characterized in that, for the corresponding audio channel in a time domain or individually for different signal sub bands of the corresponding audio channel in a sub band domain; and transmitting the two or more cue codes.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
INDIVIDUAL CHANNEL SHAPING FOR BCC SCHEMES AND THE LIKE<br>
BACKGROUND OF THE INVENTION<br>
Cross-Reference to Related Applications<br>
This application claims the benefit of the filing date of U.S. provisional application no.<br>
60/620,480, filed on 10/20/04 as attorney docket no. Allamanche 2-3-18-4, the teachings of which are<br>
incorporated herein by reference.<br>
In addition, the subject matter of this application is related to the subject matter of the following<br>
U.S. applications , the teachings of all of which are incorporated herein by reference:<br>
o U.S. application serial number 09/848,877, filed on 05/04/01 as attorney docket no. Faller 5;<br>
o U.S. application serial number 10/045,458, filed on 11/07/01 as attorney docket no. Baumgarte 1-<br>
6-8, which itself claimed the benefit of the filing date of U.S. provisional application no.<br>
60/311,565, filed on 08/10/01;<br>
o U.S. application serial number 10/155,437, filed on 05/24/02 as attorney docket no. Baumgarte 2-<br>
10;<br>
o U.S. application serial number 10/246,570, filed on 09/18/02 as attorney docket no. Baumgarte 3-<br>
11;<br>
o U.S. application serial number 10/815,591, filed on 04/01/04 as attorney docket no. Baumgarte 7-<br>
12;<br>
o U.S. application serial number 10/936,464, filed on 09/08/04 as attorney docket no. Baumgarte 8-<br>
7-15;<br>
o U.S. application serial number 10/762,100, filed on 01/20/04 (Faller 13-1); and<br>
o U.S. application serial number 10/xxx,xxx, filed on the same date as this application as attorney<br>
docket no. Allamanche 1-2-17-3.<br>
The subject matter of this application is also related to subject matter described in the following<br>
papers, the teachings of all of which are incorporated herein by reference:<br>
o F. Baumgarte and C. Faller, "Binaural Cue Coding - Part I: Psychoacoustic fundamentals and<br>
design principles," IEEE Trans, on Speech and Audio Proc, vol. 11, no. 6, Nov. 2003;<br>
o C. Faller and F. Baumgarte, "Binaural Cue Coding - Part II: Schemes and applications," IEEE<br>
Trans, on Speech and Audio Proc, vol. 11, no. 6, Nov. 2003; and<br>
o C. Faller, "Coding of spatial audio compatible with different playback formats," Preprint 117th<br>
Conv. Aud. Eng. Soc, October 2004.<br><br>
Field of the Invention<br>
The present invention relates to the encoding of audio signals and the subsequent synthesis of<br>
auditory scenes from the encoded audio data.<br>
Description of the Related Art<br>
When a person hears an audio signal (i.e., sounds) generated by a particular audio source, the<br>
audio signal will typically arrive at the person's left and right ears at two different times and with two<br>
different audio (e.g., decibel) levels, where those different times and levels are functions of the<br>
differences in the paths through which the audio signal travels to reach the left and right ears,<br>
respectively. The person's brain interprets these differences in time and level to give the person the<br>
perception that the received audio signal is being generated by an audio source located at a particular<br>
position (e.g., direction and distance) relative to the person. An auditory scene is the net effect of a<br>
person simultaneously hearing audio signals generated by one or more different audio sources located at<br>
one or more different positions relative to the person.<br>
The existence of this processing by the brain can be used to synthesize auditory scenes, where<br>
audio signals from one or more different audio sources are purposefully modified to generate left and<br>
right audio signals that give the perception that the different audio sources are located at different<br>
positions relative to the listener.<br>
Fig. 1 shows a high-level block diagram of conventional binaural signal synthesizer 100, which<br>
converts a single audio source signal (e.g., a mono signal) into the left and right audio signals of a<br>
binaural signal, where a binaural signal is defined to be the two signals received at the eardrums of a<br>
listener. In addition to the audio source signal, synthesizer 100 receives a set of spatial cues<br>
corresponding to the desired position of the audio source relative to the listener. In typical<br>
implementations, the set of spatial cues comprises an inter-channel level difference (ICLD) value (which<br>
identifies the difference in audio level between the left and right audio signals as received at the left and<br>
right ears, respectively) and an inter-channel time difference (ICTD) value (which identifies the<br>
difference in time of arrival between the left and right audio signals as received at the left and right ears,<br>
respectively). In addition or as an alternative, some synthesis techniques involve the modeling of a<br>
direction-dependent transfer function for sound from the signal source to the eardrums, also referred to as<br>
the head-related transfer function (HRTF). See, e.g., J. Blauert, The-Psychophysics of Human Sound<br>
Localization, MIT Press, 1983, the teachings of which are incorporated herein by reference.<br>
Using binaural signal synthesizer 100 of Fig. 1, the mono audio signal generated by a single<br>
sound source can be processed such that, when listened to over headphones, the sound source is spatially<br>
placed by applying an appropriate set of spatial cues (e.g., ICLD, ICTD, and/or HRTF) to generate the<br><br>
audio signal for each ear. See, e.g., D.R. Begault, 3-D Sound for Virtual Reality and Multimedia,<br>
Academic Press, Cambridge, MA, 1994.<br>
Binaural signal synthesizer 100 of Fig. 1 generates the simplest type of auditory scenes: those<br>
having a single audio source positioned relative to the listener. More complex auditory scenes<br>
comprising two or more audio sources located at different positions relative to the listener can be<br>
generated using an auditory scene synthesizer that is essentially implemented using multiple instances of<br>
binaural signal synthesizer, where each binaural signal synthesizer instance generates the binaural signal<br>
corresponding to a different audio source. Since each different audio source has a different location<br>
relative to the listener, a different set of spatial cues is used to generate the binaural audio signal for each<br>
different audio source.<br>
SUMMARY OF THE INVENTION<br>
According to one embodiment, the present invention is a method, apparatus, and machine-<br>
readable medium for encoding audio channels. One or more cue codes are generated and transmitted for<br>
one or more audio channels, wherein at least one cue code is an envelope cue code generated by<br>
characterizing a temporal envelope in one of the one or more audio channels.<br>
According to another embodiment, the present invention is an apparatus for encoding C input<br>
audio channels to generate E transmitted audio channel(s). The apparatus comprises an envelope<br>
analyzer, a code estimator, and a downmixer. The envelope analyzer characterizes an input temporal<br>
envelope of at least one of the C input channels. The code estimator generates cue codes for two or more<br>
of the C input channels. The downmixer downmixes the C input channels to generate the E transmitted<br>
channels), where O&gt;E. 4, wherein the apparatus transmits information about the cue codes and the<br>
characterized input temporal envelope to enable a decoder to perform synthesis and envelope shaping<br>
during decoding of the E transmitted channel(s).<br>
According to another embodiment, the present invention is an encoded audio bitstream generated<br>
by encoding audio channels, wherein one or more cue codes are generated for one or more audio<br>
channels, wherein at least one cue code is an envelope cue code generated by characterizing a temporal<br>
envelope in one of the one or more audio channels. The one or more cue codes and E transmitted audio<br>
channel(s) corresponding to the one or more audio channels, where E* i, are encoded into the encoded<br>
audio bitstream.	<br>
According to another embodiment, the present invention is an encoded audio bitstream<br>
comprising one or more cue codes and E transmitted audio channel(s). The one or more cue codes are<br>
generated for one or more audio channels, wherein at least one cue code is an envelope cue code<br><br>
generated by characterizing a temporal envelope in one of the one or more audio channels. The E<br>
transmitted audio channel(s) correspond to the one or more audio channels.<br>
According to another embodiment, the present invention is a method, apparatus, and machine-<br>
readable medium for decoding E transmitted audio channel(s) to generate C playback audio channels,<br>
where C&gt;E. 1. Cue codes corresponding to the E transmitted channel(s) are received, wherein the cue<br>
codes comprise an envelope cue code corresponding to a characterized temporal envelope of an audio<br>
channel corresponding to the E transmitted channel(s). One or more of the E transmitted channel(s) are<br>
upmixed to generate one or more upmixed channels. One or more of the C playback channels are<br>
synthesized by applying the cue codes to the one or more upmixed channels, wherein the envelope cue<br>
code is applied to an upmixed channel or a synthesized signal to adjust a temporal envelope of the<br>
synthesized signal based on the characterized temporal envelope such that the adjusted temporal envelope<br>
substantially matches the characterized temporal envelope.<br>
BRIEF DESCRIPTION OF THffDRAWINGS<br>
Other aspects, features, and advantages of the present invention will become more fully apparent<br>
from the following detailed description, the appended claims, and the accompanying drawings in which<br>
like reference numerals identify similar or identical elements.<br>
Fig. 1 shows a high-level block diagram of conventional binaural signal synthesizer;<br>
Fig. 2 is a block diagram of a generic binaural cue coding (BCC) audio processing system;<br>
Fig. 3 shows a block diagram of a downmixer that can be used for the downmixer of Fig. 2;<br>
Fig. 4 shows a block diagram of a BCC synthesizer that can be used for the decoder of Fig. 2;<br>
Fig. 5 shows a block diagram of the BCC estimator of Fig. 2, according to one embodiment of the<br>
present invention;<br>
Fig. 6 illustrates the generation of ICTD and ICLD data for five-channel audio;<br>
Fig. 7 illustrates the generation of ICC data for five-channel audio;<br>
Fig. 8 shows a block diagram of an implementation of the BCC synthesizer of Fig. 4 that can be<br>
used in a BCC decoder to generate a stereo or multi-channel audio signal given a single transmitted sum<br>
signal s(n) plus the spatial cues;<br>
Fig. 9 illustrates how ICTD and ICLD are varied within a subband as a function of frequency;<br>
Fig. 10 shows a block diagram of time-domain processing that is added to a BCC encoder, such as<br>
the encoder of Fig. 2, according to one embodiment of the present invention;<br>
Fig. 11 illustrates an exemplary time-domain application of TP processing in the context of the<br>
BCC synthesizer of Fig. 4;<br><br>
Figs. 12(a) and (b) show possible implementations of the TPA of Fig. 10 and the TP of Fig. 11,<br>
respectively, where envelope shaping is applied only at frequencies higher than the cut-off frequency fTP;<br>
Fig. 13 shows a block diagram of frequency-domain processing that is added to a BCC encoder,<br>
such as the encoder of Fig. 2, according to an alternative embodiment of the present invention;<br>
Fig. 14 illustrates an exemplary frequency-domain application of TP processing in the context of<br>
the BCC synthesizer of Fig. 4;<br>
Fig. 15 shows a block diagram of frequency-domain processing that is added to a BCC encoder,<br>
such as the encoder of Fig. 2, according to another alternative embodiment of the present invention;<br>
Fig. 16 illustrates another exemplary frequency-domain application of TP processing in the<br>
context of the BCC synthesizer of Fig. 4;<br>
Figs. 17(a)-(c) show block diagrams of possible implementations of the TPAs of Figs. 15 and 16<br>
and the ITP and TP of Fig. 16; and<br>
Figs. 18(a) and (b) illustrate two exemplary modes of operating the control block of Fig. 16.<br>
DETAILED DESCRIPTION<br>
In binaural cue coding (BCC), an encoder encodes C input audio channels to generate E<br>
transmitted audio channels, where C&gt;E.1. In particular, two or more of the C input channels are<br>
provided in a frequency domain, and one or more cue codes are generated for each of one or more<br>
different frequency bands in the two or more input channels in the frequency domain. In addition, the C<br>
input channels are downmixed to generate the E transmitted channels. In some downmixing<br>
implementations, at least one of the E transmitted channels is based on two or more of the C input<br>
channels, and at least one of the E transmitted channels is based on only a single one of the C input<br>
channels.<br>
In one embodiment, a BCC coder has two or more filter banks, a code estimator, and a<br>
downmixer. The two or more filter banks convert two or more of the C input channels from a time<br>
domain into a frequency domain. The code estimator generates one or more cue codes for each of one or<br>
more different frequency bands in the two or more converted input channels. The downmixer downmixes<br>
the C input channels to generate the E transmitted channels, where C&gt;E.1.<br>
In BCC decoding, E transmitted audio channels are decoded to generate C playback audio<br>
channels. In particular, for each of one or more different frequency bands, one or more of the E<br>
transmitted channels are upmixed in a frequency domain to generate two or more of the C playback<br>
channels in the frequency domain, where C&gt;E.1. One or more cue codes are applied to each of the one<br>
or more different frequency bands in the two or more playback channels in the frequency domain to<br>
generate two or more modified channels, and the two or more modified channels are converted from the<br><br>
frequency domain into a time domain. In some upmixing implementations, at least one of the C playback<br>
channels is based on at least one of the E transmitted channels and at least one cue code, and at least one<br>
of the C playback channels is based on only a single one of the E transmitted channels and independent of<br>
any cue codes.<br>
In one embodiment, a BCC decoder has an upmixer, a synthesizer, and one or more inverse filter<br>
banks. For each of one or more different frequency bands, the upmixer upmixes one or more of the E<br>
transmitted channels in a frequency domain to generate two or more of the C playback channels in the<br>
frequency domain, where C&gt;E.1. The synthesizer applies one or more cue codes to each of the one or<br>
more different frequency bands in the two or more playback channels in the frequency domain to generate<br>
two or more modified channels. The one or more inverse filter banks convert the two or more modified<br>
channels from the frequency domain into a time domain.<br>
Depending on the particular implementation, a given playback channel may be based on a single<br>
transmitted channel, rather than a combination of two or more transmitted channels. For example, when<br>
there is only one transmitted channel, each of the C playback channels is based on that one transmitted<br>
channel. In these situations, upmixing corresponds to copying of the corresponding transmitted channel.<br>
As such, for applications in which there is only one transmitted channel, the upmixer may be<br>
implemented using a replicator that copies the transmitted channel for each playback channel.<br>
BCC encoders and/or decoders may be incorporated into a number of systems or applications<br>
including, for example, digital video recorders/players, digital audio recorders/players, computers,<br>
satellite transmitters/receivers, cable transmitters/receivers, terrestrial broadcast transmitters/receivers,<br>
home entertainment systems, and movie theater systems.<br>
Generic BCC Processing<br>
Fig. 2 is a block diagram of a generic binaural cue coding (BCC) audio processing system 200<br>
comprising an encoder 202 and a decoder 204. Encoder 202 includes downmixer 206 and BCC estimator<br>
208.<br>
Downmixer 206 converts C input audio channels xi(n) into E transmitted audio channels yi(n),<br>
where C&gt;E.1. In this specification, signals expressed using the variable n are time-domain signals, while<br>
signals expressed using the variable k are frequency-domain signals. Depending on the particular<br>
implementation, downmixing can be implemented in either the time domain or the frequency domain.<br>
BCC estimator 208 generates BCC codes from the C input audio channels and transmits those BCC codes<br>
as either in-band or out-of-band side information relative to the E transmitted audio channels. Typical<br>
BCC codes include one or more of inter-channel time difference (ICTD), inter-channel level difference<br>
(ICLD), and inter-channel correlation (ICC) data estimated between certain pairs of input channels as a<br><br>
function of frequency and time. The particular implementation will dictate between which particular<br>
pairs of input channels, BCC codes are estimated.<br>
ICC data corresponds to the coherence of a binaural signal, which is related to the perceived<br>
width of the audio source. The wider the audio source, the lower the coherence between the left and right<br>
channels of the resulting binaural signal. For example, the coherence of the binaural signal corresponding<br>
to an orchestra spread out over an auditorium stage is typically lower than the coherence of the binaural<br>
signal corresponding to a single violin playing solo. In general, an audio signal with lower coherence is<br>
usually perceived as more spread out in auditory space. As such, ICC data is typically related to the<br>
apparent source width and degree of listener envelopment. See, e.g., J. Blauert, The Psychophysics of<br>
Human Sound Localization, MIT Press, 1983.<br>
Depending on the particular application, the E transmitted audio channels and corresponding BCC<br>
codes may be transmitted directly to decoder 204 or stored in some suitable type of storage device for<br>
subsequent access by decoder 204. Depending on the situation, the term "transmitting" may refer to<br>
either direct transmission to a decoder or storage for subsequent provision to a decoder. In either case,<br>
decoder 204 receives the transmitted audio channels and side information and performs upmixing and<br>
BCC synthesis using the BCC codes to convert the E transmitted audio channels into more than E<br>
(typically, but not necessarily, C) playback audio channels for audio playback. Depending on the<br>
particular implementation, upmixing can be performed in either the time domain or the frequency domain.<br>
In addition to the BCC processing shown in Fig. 2, a generic BCC audio processing system may<br>
include additional encoding and decoding stages to further compress the audio signals at the encoder and<br>
then decompress the audio signals at the decoder, respectively. These audio codecs may be based on<br>
conventional audio compression/decompression techniques such as those based on pulse code modulation<br>
(PCM), differential PCM (DPCM), or adaptive DPCM (ADPCM).<br>
When downmixer 206 generates a single sum signal (i.e., E=1), BCC coding is able to represent<br>
multi-channel audio signals at a bitrate only slightly higher than what is required to represent a mono<br>
audio signal. This is so, because the estimated ICTD, ICLD, and ICC data between a channel pair contain<br>
about two orders of magnitude less information than an audio waveform.<br>
Not only the low bitrate of BCC coding, but also its backwards compatibility aspect is of interest.<br>
A single transmitted sum signal corresponds to a mono downmix of the original stereo or multi-channel<br>
signal. For receivers that do not support stereo or multi-channel sound reproduction, listening to the<br>
transmitted sum signal is a valid method of presenting the audio material on low-profile mono<br>
reproduction equipment. BCC coding can therefore also be used to enhance existing services involving<br>
the delivery of mono audio material towards multi-channel audio. For example, existing mono audio<br>
radio broadcasting systems can be enhanced for stereo or multi-channel playback if the BCC side<br><br>
information can be embedded into the existing transmission channel. Analogous capabilities exist when<br>
downmixing multi-channel audio to two sum signals that correspond to stereo audio.<br>
BCC processes audio signals with a certain time and frequency resolution. The frequency<br>
resolution used is largely motivated by the frequency resolution of the human auditory system.<br>
Psychoacoustics suggests that spatial perception is most likely based on a critical band representation of<br>
the acoustic input signal. This frequency resolution is considered by using an invertible filterbank (e.g.,<br>
based on a fast Fourier transform (FFT) or a quadrature mirror filter (QMF)) with subbands with<br>
bandwidths equal or proportional to the critical bandwidth of the human auditory system.<br>
Generic Downmixing<br>
In preferred implementations, the transmitted sum signal(s) contain all signal components of the<br>
input audio signal. The goal is that each signal component is fully maintained. Simply summation of the<br>
audio input channels often results in amplification or attenuation of signal components. In other words,<br>
the power of the signal components in a "simple" sum is often larger or smaller than the sum of the power<br>
of the corresponding signal component of each channel. A downmixing technique can be used that<br>
equalizes the sum signal such that the power of signal components in the sum signal is approximately the<br>
same as the corresponding power in all input channels.<br>
Fig. 3 shows a block diagram of a downmixer 300 that can be used for downmixer 206 of Fig. 2<br>
according to certain implementations of BCC system 200. Downmixer 300 has a filter bank (FB) 302 for<br>
each input channel xi(n), a downmixing block 304, an optional scaling/delay block 306, and an inverse FB<br>
(IFB) 308 for each encoded channel yi(n).<br>
Each filter bank 302 converts each frame (e.g., 20 msec) of a corresponding digital input channel<br>
xi(n) in the time domain into a set of input coefficients in the frequency domain. Downmixing<br>
block 304 downmixes each sub-band of C corresponding input coefficients into a corresponding sub-band<br>
of E downmixed frequency-domain coefficients. Equation (1) represents the downmixing of the kth sub-<br>
band of input coefficients to generate the kth sub-band of downmixed<br>
coefficients as follows:<br><br><br>
where DCE is a real-valued C-by-E downmixing matrix.<br>
Optional scaling/delay block 306 comprises a set of multipliers 310, each of which multiplies a<br>
corresponding downmixed coefficient   by a scaling factor ei(k) to generate a corresponding scaled<br>
coefficient . The motivation for the scaling operation is equivalent to equalization generalized for<br>
downmixing with arbitrary weighting factors for each channel. If the input channels are independent,<br>
then the power  of the downmixed signal in each sub-band is given by Equation (2) as follows:<br><br>
where is derived by squaring each matrix element in the C-by-E downmixing matrix DCEand<br>
  is the power of sub-band k of input channel i.<br>
If the sub-bands are not independent, then the power values of the downmixed signal will<br>
be larger or smaller than that computed using Equation (2), due to signal amplifications or cancellations<br>
when signal components are in-phase or out-of-phase, respectively. To prevent this, the downmixing<br>
operation of Equation (1) is applied in sub-bands followed by the scaling operation of multipliers 310.<br>
The scaling factors ei(k) (1 • h• E) can be derived using Equation (3) as follows:<br><br>
where  is the sub-band power as computed by Equation (2), and  is power of the<br>
corresponding downmixed sub-band signal <br>
In addition to or instead of providing optional scaling, scaling/delay block 306 may optionally<br>
apply delays to the signals.<br><br>
Each inverse filter bank 308 converts a set of corresponding scaled coefficients  in the<br>
frequency domain into a frame of a corresponding digital, transmitted channel yi(n).<br>
Although Fig. 3 shows all C of the input channels being converted into the frequency domain for<br>
subsequent downmixing, in alternative implementations, one or more (but less than C-1) of the C input<br>
channels might bypass some or all of the processing shown in Fig. 3 and be transmitted as an equivalent<br>
number of unmodified audio channels. Depending on the particular implementation, these unmodified<br>
audio channels might or might not be used by BCC estimator 208 of Fig. 2 in generating the transmitted<br>
BCC codes.<br>
In an implementation of downmixer 300 that generates a single sum signal y(n), E=1 and the<br>
signals .  of each subband of each input channel c are added and then multiplied with a factor e(k),<br>
according to Equation (4) as follows:<br><br>
the factor e(k) is given by Equation (5) as follows:<br><br>
where   is a short-time estimate of the power of at time index k, and   is a short-<br>
time estimate of the power of . The equalized subbands are transformed back to the time<br>
domain resulting in the sum signal y{n) that is transmitted to the BCC decoder.<br>
Generic BCC Synthesis<br>
Fig. 4 shows a block diagram of a BCC synthesizer 400 that can be used for decoder 204 of Fig. 2<br>
according to certain implementations of BCC system 200. BCC synthesizer 400 has a filter bank 402 for<br>
each transmitted channel yi(n), an upmixing block 404, delays 406, multipliers 408, correlation block 410,<br>
and an inverse filter bank 412 for each playback channel <br><br>
Each filter bank 402 converts each frame of a corresponding digital, transmitted channel yi(n) in<br>
the time domain into a set of input coefficients  in the frequency domain. Upmixing block 404<br>
upmixes each sub-band off corresponding transmitted-channel coefficients into a corresponding sub-<br>
band of Cupmixed frequency-domain coefficients. Equation (4) represents the upmixing of the kth sub-<br>
band of transmitted-channel coefficients to generate the kth sub-band of<br>
upmixed coefficients as follows:<br><br>
where UEC is a real-valued is-by-C upmixing matrix. Performing upmixing in the frequency-domain<br>
enables upmixing to be applied individually in each different sub-band.<br>
Each delay 406 applies a delay value di(k) based on a corresponding BCC code for ICTD data to<br>
ensure that the desired ICTD values appear between certain pairs of playback channels. Each multiplier<br>
408 applies a scaling factor ai(k) based on a corresponding BCC code for ICLD data to ensure that the<br>
desired ICLD values appear between certain pairs of playback channels. Correlation block 410 performs<br>
a decorrelation operation A based on corresponding BCC codes for ICC data to ensure that the desired<br>
ICC values appear between certain pairs of playback channels. Further description of the operations of<br>
correlation block 410 can be found in U.S. Patent Application No. 10/155,437, filed on 05/24/02 as<br>
Baumgarte2-10.<br>
The synthesis of ICLD values may be less troublesome than the synthesis of ICTD and ICC<br>
values, since ICLD synthesis involves merely scaling of sub-band signals. Since ICLD cues are the most<br>
commonly used directional cues, it is usually more important that the ICLD values approximate those of<br>
the original audio signal. As such, ICLD data might be estimated between all channel pairs. The scaling<br>
factors ai(k) (1. r C) for each sub-band are preferably chosen such that the sub-band power of each<br>
playback channel approximates the corresponding power of the original input audio channel.<br>
One goal may be to apply relatively few signal modifications for synthesizing ICTD and ICC<br>
values. As such, the BCC data might not include ICTD and ICC values for all channel pairs. In that case,<br>
BCC synthesizer 400 would synthesize ICTD and ICC values only between certain channel pairs.<br><br>
Each inverse filter bank 412 converts a set of corresponding synthesized coefficients in<br>
the frequency domain into a frame of a corresponding digital, playback channel .<br>
Although Fig. 4 shows all E of the transmitted channels being converted into the frequency<br>
domain for subsequent upmixing and BCC processing, in alternative implementations, one or more (but<br>
not all) of the E transmitted channels might bypass some or all of the processing shown in Fig. 4. For<br>
example, one or more of the transmitted channels may be unmodified channels that are not subjected to<br>
any upmixing. In addition to being one or more of the C playback channels, these unmodified channels,<br>
in turn, might be, but do not have to be, used as reference channels to which BCC processing is applied to<br>
synthesize one or more of the other playback channels. In either case, such unmodified channels may be<br>
subjected to delays to compensate for the processing time involved in the upmixing and/or BCC<br>
processing used to generate the rest of the playback channels.<br>
Note that, although Fig. 4 shows C playback channels being synthesized from E transmitted<br>
channels, where C was also the number of original input channels, BCC synthesis is not limited to that<br>
number of playback channels. In general, the number of playback channels can be any number of<br>
channels, including numbers greater than or less than C and possibly even situations where the number of<br>
playback channels is equal to or less than the number of transmitted channels.<br>
"Perceptually relevant differences" between audio channels<br>
Assuming a single sum signal, BCC synthesizes a stereo or multi-channel audio signal such that<br>
ICTD, ICLD, and ICC approximate the corresponding cues of the original audio signal. In the following,<br>
the role of ICTD, ICLD, and ICC in relation to auditory spatial image attributes is discussed.<br>
Knowledge about spatial hearing implies that for one auditory event, ICTD and ICLD are related<br>
to perceived direction. When considering binaural room impulse responses (BRIRs) of one source, there<br>
is a relationship between width of the auditory event and listener envelopment and ICC data estimated for<br>
the early and late parts of the BRIRs. However, the relationship between ICC and these properties for<br>
general signals (and not just the BRIRs) is not straightforward.<br>
Stereo and multi-channel audio signals usually contain a complex mix of concurrently active<br>
source signals superimposed by reflected signal components resulting from recording in enclosed spaces<br>
or added by the recording engineer for artificially creating a spatial impression. Different source signals<br>
and their reflections occupy different regions in the time-frequency plane. This is reflected by ICTD,<br>
ICLD, and ICC, which vary as a function of time and frequency. In this case, the relation between<br>
instantaneous ICTD, ICLD, and ICC and auditory event directions and spatial impression is not obvious.<br><br>
The strategy of certain embodiments of BCC is to blindly synthesize these cues such that they<br>
approximate the corresponding cues of the original audio signal.<br>
Filterbanks with subbands of bandwidths equal to two times the equivalent rectangular bandwidth<br>
(ERB) are used. Informal listening reveals that the audio quality of BCC does not notably improve when<br>
choosing higher frequency resolution. A lower frequency resolution may be desired, since it results in<br>
less ICTD, ICLD, and ICC values that need to be transmitted to the decoder and thus in a lower bitrate.<br>
Regarding time resolution, ICTD, ICLD, and ICC are typically considered at regular time<br>
intervals. High performance is obtained when ICTD, ICLD, and ICC are considered about every 4 to 16<br>
ms. Note that, unless the cues are considered at very short time intervals, the precedence effect is not<br>
directly considered. Assuming a classical lead-lag pair of sound stimuli, if the lead and lag fall into a<br>
time interval where only one set of cues is synthesized, then localization dominance of the lead is not<br>
considered. Despite this, BCC achieves audio quality reflected in an average MUSHRA score of about 87<br>
(i.e., "excellent" audio quality) on average and up to nearly 100 for certain audio signals.<br>
The often-achieved perceptually small difference between reference signal and synthesized signal<br>
implies that cues related to a wide range of auditory spatial image attributes are implicitly considered by<br>
synthesizing ICTD, ICLD, and ICC at regular time intervals. In the following, some arguments are given<br>
on how ICTD, ICLD, and ICC may relate to a range of auditory spatial image attributes.<br>
Estimation of spatial cues<br>
In the following, it is described how ICTD, ICLD, and ICC are estimated. The bitrate for<br>
transmission of these (quantized and coded) spatial cues can be just a few kb/s and thus, with BCC, it is<br>
possible to transmit stereo and multi-channel audio signals at bitrates close to what is required for a single<br>
audio channel.<br>
Fig. 5 shows a block diagram of BCC estimator 208 of Fig. 2, according to one embodiment of<br>
the present invention. BCC estimator 208 comprises filterbanks (FB) 502, which may be the same as<br>
filterbanks 302 of Fig. 3, and estimation block 504, which generates ICTD, ICLD, and ICC spatial cues<br>
for each different frequency subband generated by filterbanks 502.<br>
Estimation of ICTD. ICLD. and ICC for stereo signals<br>
The following measures are used for ICTD, ICLD, and ICC for corresponding subband signals<br><br><br><br>
Estimation of ICTD, ICLD. and ICC for multi-channel audio signals<br>
When there are more than two input channels, it is typically sufficient to define ICTD and ICLD<br>
between a reference channel (e.g., channel number 1) and the other channels, as illustrated in Fig. 6 for<br>
the case of C=5 channels, where denote the ICTD and ICLD, respectively,<br>
between the reference channel 1 and channel c.<br>
As opposed to ICTD and ICLD, ICC typically has more degrees of freedom. The ICC as defined<br>
can have different values between all possible input channel pairs. For C channels, there are C(C-1)/2<br>
possible channel pairs; e.g., for 5 channels there are 10 channel pairs as illustrated in Fig. 7(a). However,<br>
such a scheme requires that, for each subband at each time index, C(C-1)/2 ICC values are estimated and<br>
transmitted, resulting in high computational complexity and high bitrate.<br><br>
Alternatively, for each subband, ICTD and ICLD determine the direction at which the auditory<br>
event of the corresponding signal component in the subband is rendered. One single ICC parameter per<br>
subband may then be used to describe the overall coherence between all audio channels. Good results can<br>
be obtained by estimating and transmitting ICC cues only between the two channels with most energy in<br>
each subband at each time index. This is illustrated in Fig. 7(b), where for time instants k-\ and A: the<br>
channel pairs (3, 4) and (1,2) are strongest, respectively. A heuristic rule may be used for determining<br>
ICC between the other channel pairs.<br>
Synthesis of spatial cues<br>
Fig. 8 shows a block diagram of an implementation of BCC synthesizer 400 of Fig. 4 that can be<br>
used in a BCC decoder to generate a stereo or multi-channel audio signal given a single transmitted sum<br>
signal s(n) plus the spatial cues. The sum signal s(n) is decomposed into subbands, where ?(&amp;) denotes<br>
one such subband. For generating the corresponding subbands of each of the output channels, delays dc,<br>
scale factors ac, and filters hc are applied to the corresponding subband of the sum signal. (For simplicity<br>
of notation, the time index k is ignored in the delays, scale factors, and filters.) ICTD are synthesized by<br>
imposing delays, ICLD by scaling, and ICC by applying de-correlation filters. The processing shown in<br>
Fig. 8 is applied independently to each subband.<br><br>
The delay for the reference channel, d„ is computed such that the maximum magnitude of the delays dc is<br>
minimized. The less the subband signals are modified, the less there is a danger for artifacts to occur. If<br>
the subband sampling rate does not provide high enough time-resolution for ICTD synthesis, delays can<br>
be imposed more precisely by using suitable all-pass filters.<br>
ICLD synthesis<br>
In order that the output subband signals have desired ICLDs AL12 (k) between channel c and the<br>
reference channel 1, the gain factors ac should satisfy Equation (13) as follows:<br><br><br>
Additionally, the output subbands are preferably normalized such that the sum of the power of all output<br>
channels is equal to the power of the input sum signal. Since the total original signal power in each<br>
subband is preserved in the sum signal, this normalization results in the absolute subband power for each<br>
output channel approximating the corresponding power of the original encoder input audio signal. Given<br>
these constraints, the scale factors ac are given by Equation (14) as follows:<br><br>
ICC synthesis<br>
In certain embodiments, the aim of ICC synthesis is to reduce correlation between the subbands<br>
after delays and scaling have been applied, without affecting ICTD and ICLD. This can be achieved<br>
by designing the filters hc in Fig. 8 such that ICTD and ICLD are effectively varied as a function of<br>
frequency such that the average variation is zero in each subband (auditory critical band).<br>
Fig. 9 illustrates how ICTD and ICLD are varied within a subband as a function of frequency.<br>
The amplitude of ICTD and ICLD variation determines the degree of de-correlation and is controlled as a<br>
function of ICC. Note that ICTD are varied smoothly (as in Fig. 9(a)), while ICLD are varied randomly<br>
(as in Fig. 9(b)). One could vary ICLD as smoothly as ICTD, but this would result in more coloration of<br>
the resulting audio signals.<br>
Another method for synthesizing ICC, particularly suitable for multi-channel ICC synthesis, is<br>
described in more detail in C. Faller, "Parametric multi-channel audio coding: Synthesis of coherence<br>
cues," IEEE Trans, on Speech and Audio Proc, 2003, the teachings of which are incorporated herein by<br>
reference. As a function of time and frequency, specific amounts of artificial late reverberation are added<br>
to each of the output channels for achieving a desired ICC. Additionally, spectral modification can be<br>
applied such that the spectral envelope of the resulting signal approaches the spectral envelope of the<br>
original audio signal.<br>
Other related and unrelated ICC synthesis techniques for stereo signals (or audio channel pairs)<br>
have been presented in E. Schuijers, W. Oomen, B. den Brinker, and J. Breebaart, "Advances in<br>
parametric coding for high-quality audio," in Preprint 114th Conv. Aud. Eng. Soc, Mar. 2003, and J.<br>
Engdegard, H. Purnhagen, J. Roden, and L. Liljeryd, "Synthetic ambience in parametric stereo coding," in<br><br>
Preprint 117th Conv. And. Eng. Soc, May 2004, the teachings of both of which are incorporated here by<br>
reference.<br>
C-to-E BCC<br>
As described previously, BCC can be implemented with more than one transmission channel. A<br>
variation of BCC has been described which represents C audio channels not as one single (transmitted)<br>
channel, but as E channels, denoted C-to-E BCC. There are (at least) two motivations for C-to-E BCC:<br>
o BCC with one transmission channel provides a backwards compatible path for upgrading existing<br>
mono systems for stereo or multi-channel audio playback. The upgraded systems transmit the<br>
BCC downmixed sum signal through the existing mono infrastructure, while additionally<br>
transmitting the BCC side information. C-to-i? BCC is applicable to is-channel backwards<br>
compatible coding of C-channel audio,<br>
o C-to-E BCC introduces scalability in terms of different degrees of reduction of the number of<br>
transmitted channels. It is expected that the more audio channels that are transmitted, the better<br>
the audio quality will be.<br>
Signal processing details for C-to-E BCC, such as how to define the ICTD, ICLD, and ICC cues, are<br>
described in U.S. application serial number 10/762,100, filed on 01/20/04 (Faller 13-1).<br>
Individual Channel Shaping<br>
In certain embodiments, both BCC with one transmission channel and C-to-E BCC involve<br>
algorithms for ICTD, ICLD, and/or ICC synthesis. Usually, it is enough to synthesize the ICTD, ICLD,<br>
and/or ICC cues about every 4 to 30 ms. However, the perceptual phenomenon of precedence effect<br>
implies that there are specific time instants when the human auditory system evaluates cues at higher time<br>
resolution (e.g., every 1 to 10 ms).<br>
A single static filterbank typically cannot provide high enough frequency resolution, suitable for<br>
most time instants, while providing high enough time resolution at time instants when the precedence<br>
effect becomes effective.<br>
Certain embodiments of the present invention are directed to a system that uses relatively low<br>
time resolution ICTD, ICLD, and/or ICC synthesis, while adding additional processing to address the<br>
time instants when higher time resolution is required. Additionally, in certain embodiments, the system<br>
eliminate the need for signal adaptive window switching technology which is usually hard to integrate in<br>
a system's structure. In certain embodiments, the temporal envelopes of one or more of the original<br>
encoder input audio channels are estimated. This can be done, e.g., directly by analysis of the signal's<br>
time structure or by examining the autocorrelation of the signal spectrum over frequency. Both<br><br>
approaches will be elaborated on further in the subsequent implementation examples. The information<br>
contained in these envelopes is transmitted to the decoder (as envelope cue codes) if perceptually required<br>
and advantageous.<br>
In certain embodiments, the decoder applies certain processing to impose these desired temporal<br>
envelopes on its output audio channels:<br>
o This can be achieved by TP processing, e.g., manipulation of the signal's envelope by<br>
multiplication of the signal's time-domain samples with a time-varying amplitude modification<br>
function. A similar processing can be applied to spectral/subband samples if the time resolution<br>
of the subbands is sufficiently high enough (at the cost of a coarse frequency resolution),<br>
o Alternatively, a convolution / filtering of the signal's spectral representation over frequency can<br>
be used in a manner analogous to that used in the prior art for the purpose of shaping the<br>
quantization noise of a low-bitrate audio coder or for enhancing intensity stereo coded signals.<br>
This is preferred if the filterbank has a high frequency resolution and therefor a rather low time<br>
resolution. For the convolution/filtering approach:<br>
o The envelope shaping method is extended from intensity stereo to C-to-ii multi-channel<br>
coding.<br>
o The technique comprises a setup where the envelope shaping is controlled by parametric<br>
information (e.g., binary flags) generated by the encoder but is actually carried out using<br>
decoder-derived filter coefficient sets.<br>
o In another setup, sets of filter coefficients are transmitted from the encoder, e.g., only when<br>
perceptually necessary and/or beneficial.<br>
The same is also true for the time domain/subband domain approach. Therefore, criteria (e.g.,<br>
transient detection and a tonality estimate) can be introduced to additionally control transmission of<br>
envelope information.<br>
There may be situations when it is favorable to disable the TP processing in order to avoid<br>
potential artifacts. In order to be on the safe side, it is a good strategy to leave the temporal processing<br>
disabled by default (i.e., BCC would operate according to a conventional BCC scheme). The additional<br>
processing is enabled only when it is expected that higher temporal resolution of the channels yields<br>
improvement, e.g., when it is expected that the precedence effect becomes active.<br>
As stated earlier, this enabling/disabling control can be achieved by transient detection. That is, if<br>
a transient is detected, then TP processing is enabled. The precedence effect is most effective for<br>
transients. Transient detection can be used with look-ahead to effectively shape not only single transients<br>
but also the signal components shortly before and after the transient. Possible ways of detecting<br>
transients include:<br><br>
o Observing the temporal envelope of BCC encoder input signals or transmitted BCC sum signal(s).<br>
If there is a sudden increase in power, then a transient occurred,<br>
o Examining the linear predictive coding (LPC) gain as estimated in the encoder or decoder. If the<br>
LPC prediction gain exceeds a certain threshold, then it can be assumed that the signal is transient<br>
or highly fluctuating. The LPC analysis is computed on the spectrum's autocorrelation.<br>
Additionally, to prevent possible artifacts in tonal signals, TP processing is preferably not applied<br>
when the tonality of the transmitted sum signal(s) is high.<br>
According to certain embodiments of the present invention, the temporal envelopes of the<br>
individual original audio channels are estimated at a BCC encoder in order to enable a BCC decoder<br>
generate output channels with temporal envelopes similar (or perceptually similar) to those of the original<br>
audio channels. Certain embodiments of the present invention address the phenomenon of precedence<br>
effect. Certain embodiments of the present invention involve the transmission of envelope cue codes in<br>
addition to other BCC codes, such as ICLD, ICTD, and/or ICC, as part of the BCC side information.<br>
In certain embodiments of the present invention, the time resolution for the temporal envelope<br>
cues is finer than the time resolution of other BCC codes (e.g., ICLD, ICTD, ICC). This enables envelope<br>
shaping to be performed within the time period provided by a synthesis window that corresponds to the<br>
length of a block of an input channel for which the other BCC codes are derived.<br>
Implementation Examples<br>
Fig. 10 shows a block diagram of time-domain processing that is added to a BCC encoder, such as<br>
encoder 202 of Fig. 2, according to one embodiment of the present invention. As shown in Fig. 10(a),<br>
each temporal process analyzer (TPA) 1002 estimates the temporal envelope of a different original input<br>
channel xc(n), although in general any one or more of the input channels can be analyzed.<br>
Fig. 10(b) shows a block diagram of one possible time domain-based implementation of TPA<br>
1002 in which the input signal samples are squared (1006) and then low-pass filtered (1008) to<br>
characterize the temporal envelope of the input signal. In alternative embodiments, the temporal envelope<br>
can be estimated using an autocorrelation / LPC method or with other methods, e.g., using a Hilbert<br>
transform.<br>
Block 1004 of Fig. 10(a) parameterizes, quantizes, and codes the estimated temporal envelopes<br>
prior to transmission as temporal processing (TP) information (i.e., envelope cue codes) that is included in<br>
the side information of Fig. 2.<br>
In one embodiment, a detector (not shown) within block 1004 determines whether TP processing<br>
at the decoder will improve audio quality, such that block 1004 transmits TP side information only during<br>
those time instants when audio quality will be improved by TP processing.<br><br>
Fig. 11 illustrates an exemplary time-domain application of TP processing in the context of BCC<br>
synthesizer 400 of Fig. 4. In this embodiment, there is a single transmitted sum signal s(n), C base signals<br>
are generated by replicating that sum signal, and envelope shaping is individually applied to different<br>
synthesized channels. In alternative embodiments, the order of delays, scaling, and other processing may<br>
be different. Moreover, in alternative embodiments, envelope shaping is not restricted to processing each<br>
channel independently. This is especially true for convolution/filtering-based implementations mat<br>
exploit coherence over frequency bands to derive information on the signal's temporal fine structure.<br>
In Fig. 11(a), decoding block 1102 recovers temporal envelope signals a for each output channel<br>
from the transmitted TP side information received from the BCC encoder, and each TP block 1104<br>
applies the corresponding envelope information to shape the envelope of the output channel.<br>
Fig. 11(b) shows a block diagram of one possible time domain-based implementation of TP 1104<br>
in which the synthesized signal samples are squared (1106) and then low-pass filtered (1108) to<br>
characterize the temporal envelope b of the synthesized channel. A scale factor (e.g., sqrt {alb)) is<br>
generated (1110) and then applied (1112) to the synthesized channel to generate an output signal having a<br>
temporal envelope substantially equal to that of the corresponding original input channel.<br>
In alternative implementations of TPA 1002 of Fig. 10 and TP 1104 of Fig. 11, the temporal<br>
envelopes are characterized using magnitude operations rather than by squaring the signal samples. In<br>
such implementations, the ratio alb may be used as the scale factor without having to apply the square<br>
root operation.<br>
Although the scaling operation of Fig. 11(c) corresponds to a time domain-based implementation<br>
of TP processing, TP processing (as well as TPA and inverse TP (iTP) processing) can also be<br>
implemented using frequency-domain signals, as in the embodiment of Figs. 16-17 (described below). As<br>
such, for purposes of this specification, the term "scaling function" should be interpreted to cover either<br>
time-domain or frequency-domain operations, such as the filtering operations of Figs. 17(b) and (c).<br>
In general, each TP 1104 is preferably designed such that it does not modify signal power (i.e.,<br>
energy). Depending on the particular implementation, this signal power may be a short-time average<br>
signal power in each channel, e.g., based on the total signal power per channel in the time period defined<br>
by the synthesis window or some other suitable measure of power. As such, scaling for ICLD synthesis<br>
(e.g., using multipliers 408) can be applied before or after envelope shaping.<br>
Since full-band scaling of the BCC output signals may result in artifacts, envelope shaping might<br>
be applied only at specified frequencies, for example, frequencies larger than a certain cut-off frequency<br>
fTP (e.g., 500 Hz). Note that the frequency range for analysis (TPA) may differ from the frequency range<br>
for synthesis (TP).<br><br>
Figs. 12(a) and (b) show possible implementations of TPA 1002 of Fig. 10 and TP 1104 of Fig.<br>
11 where envelope shaping is applied only at frequencies higher than the cut-off frequency fTP. In<br>
particular, Fig. 12(a) shows the addition of high-pass filter 1202, which filters out frequencies lower than<br>
fTP prior to temporal envelope characterization. Fig. 12(b) shows the addition of two-band filterbank 1204<br>
having with a cut-off frequency offTP between the two subbands, where only the high-frequency part is<br>
temporally shaped. Two-band inverse filterbank 1206 then recombines the low-frequency part with the<br>
temporally shaped, high-frequency part to generate the output channel.<br>
Fig. 13 shows a block diagram of frequency-domain processing that is added to a BCC encoder,<br>
such as encoder 202 of Fig. 2, according to an alternative embodiment of the present invention. As<br>
shown in Fig. 13(a), the processing of each TPA 1302 is applied individually in a different subband,<br>
where each filterbank (FB) is the same as a corresponding FB 302 of Fig. 3 and block 1304 is a subband<br>
implementation analogous to block 1004 of Fig. 10. In alternative implementations, the subbands for<br>
TPA processing may differ from the BCC subbands. As shown in Fig. 13(b), TPA 1302 can be<br>
implemented analogous to TPA 1002 of Fig. 10.<br>
Fig. 14 illustrates an exemplary frequency-domain application of TP processing in the context of<br>
BCC synthesizer 400 of Fig. 4. Decoding block 1402 is analogous to decoding block 1102 of Fig. 11,<br>
and each TP 1404 is a subband implementation analogous to each TP 1104 of Fig. 11, as shown in Fig.<br>
14(b).<br>
Fig. 15 shows a block diagram of frequency-domain processing that is added to a BCC encoder,<br>
such as encoder 202 of Fig. 2, according to another alternative embodiment of the present invention. This<br>
scheme has the following setup: The envelope information for every input channel is derived by<br>
calculation of LPC across frequency (1502), parameterized (1504), quantized (1506), and coded into the<br>
bitstream (1508) by the encoder. Fig. 17(a) illustrates an implementation example of the TPA 1502 of<br>
Fig. 15. The side information to be transmitted to the multichannel synthesizer (decoder) could be the<br>
LPC filter coefficients computed by an autocorrelation method, the resulting reflection coefficients, or<br>
line spectral pairs, etc., or, for the sake of keeping the side information data rate small, parameters derived<br>
from, e.g., the LPC prediction gain like "transients present/not present" binary flags.<br>
Fig. 16 illustrates another exemplary frequency-domain application of TP processing in the<br>
context of BCC synthesizer 400 of Fig. 4. The encoding processing of Fig. 15 and the decoding<br>
processing of Fig. 16 may be implemented to form a matched pair of an encoder/decoder configuration.<br>
Decoding block 1602 is analogous to decoding block 1402 of Fig. 14, and each TP 1604 is analogous to<br>
each TP 1404 of Fig. 14. In this multichannel synthesizer, transmitted TP side information is decoded<br>
and used for controlling the envelope shaping of individual channels. In addition, however, the<br>
synthesizer includes an envelope characterizer stage (TPA) 1606 for analysis of the transmitted sum<br><br>
signals, an inverse TP (ITP) 1608 for "flattening" the temporal envelope of each base signal, where<br>
envelope adjusters (TP) 1604 impose a modified envelope on each output channel. Depending on the<br>
particular implementation, ITP can be applied either before or after upmixing. In detail, this is done using<br>
the convolution/filtering approach where envelope shaping is achieved by applying LPC-based filters on<br>
the spectrum across frequency as illustrated in Figs. 17(a), (b), and (c) for TPA, ITP, and TP processing,<br>
respectively. In Fig. 16, control block 1610 determines whether or not envelope shaping is to be<br>
implemented and, if so, whether it is to be based on (1) the transmitted TP side information or (2) the<br>
locally characterized envelope data from TPA 1606.<br>
Figs. 18(a) and (b) illustrate two exemplary modes of operating control block 1610 of Fig. 16. In<br>
the implementation of Fig. 18(a), a set of filter coefficients is transmitted to the decoder, and envelope<br>
shaping by convolution/filtering is done based on the transmitted coefficients. If transient shaping is<br>
detected to be not beneficial by the encoder, then no filter data is sent and the filters are disabled (shown<br>
in Fig. 18(a) by switching to a unity filter coefficient set "[1,0...]").<br>
In the implementation of Fig. 18(b), only a "transient/non transient flag" is transmitted for each<br>
channel and this flag is used to activate or deactivate shaping based on filter coefficient sets calculated<br>
from the transmitted downmix signals in the decoder.<br>
Further Alternative Embodiments<br>
Although the present invention has been described in the context of BCC coding schemes in<br>
which there is a single sum signal, the present invention can also be implemented in the context of BCC<br>
coding schemes having two or more sum signals. In this case, the temporal envelope for each different<br>
"base" sum signal can be estimated before applying BCC synthesis, and different BCC output channels<br>
may be generated based on different temporal envelopes, depending on which sum signals were used to<br>
synthesize the different output channels. An output channel that is synthesized from two or more<br>
different sum channels could be generated based on an effective temporal envelope that takes into account<br>
(e.g., via weighted averaging) the relative effects of the constituent sum channels.<br>
Although the present invention has been described in the context of BCC coding schemes<br>
involving ICTD, ICLD, and ICC codes, the present invention can also be implemented in the context of<br>
other BCC coding schemes involving only one or two of these three types of codes (e.g., ICLD and ICC,<br>
but not ICTD) and/or one or more additional types of codes. Moreover, the sequence of BCC synthesis<br>
processing and envelope shaping may vary in different implementations. For example, when envelope<br>
shaping is applied to frequency-domain signals, as in Figs. 14 and 16, envelope shaping could<br>
alternatively be implemented after ICTD synthesis (in those embodiments that employ ICTD synthesis),<br><br>
but prior to ICLD synthesis. In other embodiments, envelope shaping could be applied to upmixed<br>
signals before any other BCC synthesis is applied.<br>
Although the present invention has been described in the context of BCC encoders that generate<br>
envelope cue codes from the original input channels, in alternative embodiments, the envelope cue codes<br>
could be generated from downmixed channels corresponding to the original input channels. This would<br>
enable the implementation of a processor (e.g., a separate envelope cue coder) that could (1) accept the<br>
output of a BCC encoder that generates the downmixed channels and certain BCC codes (e.g., ICLD,<br>
ICTD, and/or ICC) and (2) characterize the temporal envelope(s) of one or more of the downmixed<br>
channels to add envelope cue codes to the BCC side information.<br>
Although the present invention has been described in the context of BCC coding schemes in<br>
which the envelope cue codes are transmitted with one or more audio channels (i.e., the E transmitted<br>
channels) along with other BCC codes, in alternative embodiments, the envelope cue codes could be<br>
transmitted, either alone or with other BCC codes, to a place (e.g., a decoder or a storage device) that<br>
already has the transmitted channels and possibly other BCC codes.<br>
Although the present invention has been described in the context of BCC coding schemes, the<br>
present invention can also be implemented in the context of other audio processing systems in which<br>
audio signals are de-correlated or other audio processing that needs to de-correlate signals.<br>
Although the present invention has been described in the context of implementations in which the<br>
encoder receives input audio signal in the time domain and generates transmitted audio signals in the time<br>
domain and the decoder receives the transmitted audio signals in the time domain and generates playback<br>
audio signals in the time domain, the present invention is not so limited. For example, in other<br>
implementations, any one or more of the input, transmitted, and playback audio signals could be<br>
represented in a frequency domain.<br>
BCC encoders and/or decoders may be used in conjunction with or incorporated into a variety of<br>
different applications or systems, including systems for television or electronic music distribution, movie<br>
theaters, broadcasting, streaming, and/or reception. These include systems for encoding/decoding<br>
transmissions via, for example, terrestrial, satellite, cable, internet, intranets, or physical media (e.g.,<br>
compact discs, digital versatile discs, semiconductor chips, hard drives, memory cards, and the like).<br>
BCC encoders and/or decoders may also be employed in games and game systems, including, for<br>
example, interactive software products intended to interact with a user for entertainment (action, role<br>
play, strategy, adventure, simulations, racing, sports, arcade, card, and board games) and/or education that<br>
may be published for multiple machines, platforms, or media. Further, BCC encoders and/or decoders<br>
may be incorporated in audio recorders/players or CD-ROM/DVD systems. BCC encoders and/or<br>
decoders may also be incorporated into PC software applications that incorporate digital decoding (e.g.,<br><br>
player, decoder) and software applications incorporating digital encoding capabilities (e.g., encoder,<br>
ripper, recoder, and jukebox).<br>
The present invention may be implemented as circuit-based processes, including possible<br>
implementation as a single integrated circuit (such as an ASIC or an FPGA), a multi-chip module, a single<br>
card, or a multi-card circuit pack. As would be apparent to one skilled in the art, various functions of<br>
circuit elements may also be implemented as processing steps in a software program. Such software may<br>
be employed in, for example, a digital signal processor, micro-controller, or general-purpose computer.<br>
The present invention can be embodied in the form of methods and apparatuses for practicing<br>
those methods. The present invention can also be embodied in the form of program code embodied in<br>
tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other machine-readable storage<br>
medium, wherein, when the program code is loaded into and executed by a machine, such as a computer,<br>
the machine becomes an apparatus for practicing the invention. The present invention can also be<br>
embodied in the form of program code, for example, whether stored in a storage medium, loaded into<br>
and/or executed by a machine, or transmitted over some transmission medium or carrier, such as over<br>
electrical wiring or cabling, through fiber optics, or via electromagnetic radiation, wherein, when the<br>
program code is loaded into and executed by a machine, such as a computer, the machine becomes an<br>
apparatus for practicing the invention. When implemented on a general-purpose processor, the program<br>
code segments combine with the processor to provide a unique device that operates analogously to<br>
specific logic circuits.<br>
It will be further understood that various changes in the details, materials, and arrangements of the<br>
parts which have been described and illustrated in order to explain the nature of this invention may be<br>
made by those skilled in the art without departing from the scope of the invention as expressed in the<br>
following claims.<br>
Although the steps in the following method claims, if any, are recited in a particular sequence<br>
with corresponding labeling, unless the claim recitations otherwise imply a particular sequence for<br>
implementing some or all of those steps, those steps are not necessarily intended to be limited to being<br>
implemented in that particular sequence.<br><br>
WE CLAIM :<br>
1.	A method for encoding audio channels, the method comprising :<br>
generating two or more cue codes for one or more audio channels,<br>
wherein at least one cue code is an envelope cue code generated by<br>
characterizing a temporal envelope in one of the one or more audio<br>
channels, wherein the two or more cue codes further comprise one or<br>
more of inter-channel correlation (ICC) codes, inter-channel level<br>
difference (ICLD) codes, and inter-channel time difference (ICTD) codes,<br>
wherein a first time resolution associated with the envelope cue code is<br>
finer than a second time resolution associated with the other cue code(s),<br>
and wherein the temporal envelope is characterized in that, for the<br>
corresponding audio channel in a time domain or individually for different<br>
signal sub bands of the corresponding audio channel in a sub band<br>
domain; and<br>
transmitting the two or more cue codes.<br>
2.	The method as claimed in claim 1, comprising transmitting E transmitted<br>
audio channel(s) corresponding to the one or more audio channels, where<br>
≥1.<br>
3.	The method as claimed in claim 2, wherein:<br>
the one or more audio channels comprise C input audio channels, where<br>
C&gt;E; and<br>
the C input channels are downmixed to generate the E transmitted<br>
channel(s).<br><br>
4.	The method as claimed in claim 1, wherein the two or more cue codes are<br>
transmitted to enable a decoder to perform envelope shaping during<br>
decoding of E transmitted channel(s) based on the two or more cue<br>
codes, wherein the E transmitted audio channel(s) correspond to the one<br>
or more audio channels, where E≥1.<br>
5.	The method as claimed in claim 4, wherein the envelope shaping adjusts a<br>
temporal envelope of a synthesized signal generated by the decoder to<br>
match the characterized temporal envelope.<br>
6.	The method as claimed in claim 1, wherein the temporal envelope is<br>
characterized only for specified frequencies of the corresponding audio<br>
channel.<br>
7.	The method as claimed in claim 1, wherein the temporal envelope is<br>
characterized only for frequencies of the corresponding audio channel<br>
above a specified cutoff frequency.<br>
8.	The method as claimed in claim 1, wherein the sub band domain<br>
corresponds to a quadrature mirror filter (QMF).<br>
9.	The method as claimed in claim 1, comprising determining whether to<br>
enable or disable the characterizing.<br><br>
10.	The method as claimed in claim 9, comprising generating and transmitting<br>
an enable/disable flag based on the determining to instruct a decoder<br>
whether or not to implement envelope shaping during decoding of E<br>
transmitted channel(s) corresponding to the one or more audio channels,<br>
where E≥1.<br>
11.	The method as claimed in claim 9, wherein the determining is based on<br>
analyzing an audio channel to detect transients in the audio channel such<br>
that the characterizing is enabled if occurrence of a transient is detected.<br>
12.	The method as claimed in claim wherein the step of generating the<br>
envelope cue code includes squaring (1006) or forming a magnitude and<br>
low-pass filtering (1008) of signal samples of the audio channel or of sub<br>
band signals of the audio channel in order to characterize the temporal<br>
envelope.<br>
13.	The method as claimed in claim 1 or 12 wherein the step of generating<br>
furthermore comprises a step of parametrizing quantizing and coding an<br>
estimated temporal envelope.<br>
14.	Apparatus for encoding audio channels, the apparatus comprising :<br>
means for generating two or more cue codes for one or more audio<br>
channels, wherein at least one cue code is an envelope cue code<br>
generated by characterizing a temporal envelope in one of the one or<br>
more audio channels, wherein the two or more cue codes further<br>
comprise one or more of inter-channel correlation (ICC) codes, inter-<br>
channel level difference (ICLD) codes, and inter-channel time difference<br>
(ICTD) codes, wherein a first time resolution associated with the envelope<br><br>
cue code is finer than a second time resolution associated with the other<br>
cue code(s) and wherein the temporal envelope is characterized in that for<br>
the corresponding audio channel in a time domain or individually for<br>
different signal sub bands of the corresponding audio channel in a sub<br>
band domain; and<br>
means for transmitting information about the two or more cue codes.<br>
15.	The apparatus as claimed in claim 14,<br>
wherein the apparatus is operative for encoding C input audio channels to<br>
generate E transmitted audio channel(s), wherein the means for<br>
generating comprises an envelope analyzer adapted to characterize the<br>
input temporal envelope of at least one of the C input channels,<br>
wherein the means for generating comprises a code estimator adapted to<br>
generate the cue codes for two or more of the C input channels and<br>
wherein the apparatus comprises a downmixer adapted to downmix the C<br>
input channels to generate the E transmitted channel(s) where C&gt;E≥1,<br>
wherein the means for transmitting is adapted to transmit the information<br>
about the two or more cue codes to enable a decoder to perform<br>
synthesis and envelope shaping during decoding of the E transmitted<br>
channel(s).<br>
16.	The apparatus as claimed in claim 15, wherein:<br>
the apparatus is selected from the group consisting of a digital video<br>
recorder, a digital audio recorder, a computer, a satellite transmitter, a<br>
cable transmitter, a terrestrial broadcast transmitter, a home<br>
entertainment system, and a movie theater system; and<br>
comprises the envelope analyzer, the code estimator, and the downmixer.<br><br>
17. A method for decoding E transmitted audio channel(s) to generate C<br>
playback audio channels, where C&gt;E≥1, the method comprising:<br>
receiving cue codes corresponding to the E transmitted channel(s),<br>
wherein the cue codes comprise an envelope cue code corresponding to a<br>
characterized temporal envelope of an audio channel corresponding to the<br>
E transmitted channel(s), wherein the two or more cue codes further<br>
comprise one or more of interchannel correlation (ICC) codes, inter-<br>
channel level difference (ICLD) codes, and inter-channel time difference<br>
(ICTD) codes, wherein a first time resolution associated with the envelope<br>
cue code is finer than a second time resolution associated with the other<br>
cue code(s);<br>
upmixing one or more of the E transmitted channel(s) to generate one or<br>
more upmixed channels; and synthesizing one or more of the C playback<br>
channels by applying the cue codes to the one or more upmixed channel,<br>
wherein the envelope cue code is applied to an upmixed channel or a<br>
synthesized signal to adjust a temporal envelope of the synthesized signal<br>
based on the characterized temporal envelope by scaling time domain or<br>
sub band domain signal samples using a scaling factor such that the<br>
adjusted temporal envelope matches the characterized temporal envelope<br>
matches the characterized temporal envelope.<br><br>
18.	The method as claimed in claim 18, wherein the envelope cue code<br>
corresponds to a characterized temporal envelope in an original input<br>
channel used to generate the E transmitted channel(s).<br>
19.	The method as claimed in claim 19, wherein the synthesis comprises late-<br>
reverberation ICC synthesis.<br>
20.	The method as claimed in claim 19, wherein the temporal envelope of the<br>
synthesized signal is adjusted prior to ICLD synthesis.<br>
21.	The method as claimed in claim 18, wherein:<br>
the temporal envelope of the synthesized signal is characterized; and<br>
the temporal envelope of the synthesized signal is adjusted based on both<br>
the characterized temporal envelope corresponding to the envelope cue<br>
code and the characterized temporal envelope of the synthesized signal.<br>
22.	The method as claimed in claim 22, wherein:<br>
a scaling function is generated based on the characterized temporal<br>
envelope corresponding to the envelope cue code and the characterized<br>
temporal envelope of the synthesized signal; and<br>
the scaling function is applied to the synthesized signal.<br>
23.	The method as claimed in claim 18, comprising adjusting a transmitted<br>
channel based on the characterized temporal envelope to generate a<br>
flattened channel, wherein the upmixing and synthesis are applied to the<br>
flattened channel to generate a corresponding playback channel.<br><br>
24.	The method as claimed in claim 18, comprising adjusting an upmixed<br>
channel based on the characterized temporal envelope to generate a<br>
flattened channel, wherein the synthesis is applied to the flattened<br>
channel to generate a corresponding playback channel.<br>
25.	The method as claimed in claim 18, wherein the temporal envelope of the<br>
synthesized signal is adjusted only for specified frequencies.<br>
26.	The method as claimed in claim 26, wherein the temporal envelope of the<br>
synthesized signal is adjusted only for frequencies above a specified cutoff<br>
frequency.<br>
27.	The method as claimed in claim 18, wherein temporal envelopes are<br>
adjusted individually for different signal sub bands in the synthesized<br>
signal.<br>
28.	The method as claimed in claim 18, wherein a sub band domain<br>
corresponds to a QMF.<br>
29.	The method as claimed in claim 18, wherein the temporal envelope of the<br>
synthesized signal is adjusted in a time domain.<br>
30.	The method as claimed in claim 18, comprising determining whether to<br>
enable or disable the adjusting of the temporal envelope of the<br>
synthesized signal.<br><br>
31.	The method as claimed in claim 31, wherein the determining is based on<br>
an enable/disable flag generated by an audio encoder that generated the<br>
E transmitted channel(s).<br>
32.	The method as claimed in claim 31, wherein the determining is based on<br>
analyzing the E transmitted channel(s) to detect transients such that the<br>
adjusting is enabled if occurrence of a transient is detected.<br>
33.	The method as claimed in claim 18, comprising:<br>
characterizing a temporal envelope of a transmitted channel; and<br>
determining whether to use (1) the characterized temporal envelope<br>
corresponding to the envelope cue code or (2) the characterized temporal<br>
envelope of the transmitted channel to adjust the temporal envelope of<br>
the synthesized signal.<br>
34.	The method as claimed in claim 18, wherein power within a specified<br>
window of the synthesized signal after adjusting the temporal envelope is<br>
equal to power within a corresponding window of the synthesized signal<br>
before the adjusting.<br>
35.	The method as claimed in claim 35, wherein the specified window<br>
corresponds to a synthesis window associated with one or more non-<br>
envelope cue codes.<br>
36.	Apparatus for decoding E transmitted audio channel(s) to generate C<br>
playback audio channels, where C&gt;E&gt;1, the apparatus comprising:<br>
means for receiving cue codes corresponding to the E transmitted<br>
channel(s), wherein the cue codes comprise an envelope cue code<br><br>
corresponding to a characterized temporal envelope of an audio channel<br>
corresponding to the E transmitted channels, wherein the two or more cue<br>
codes further comprise one or more of inter-channel correlation (ICC)<br>
codes, inter-channel level difference (ICLD) codes, and interchannel time<br>
difference (ICTD) codes, wherein a first time resolution associated with<br>
the envelope cue code is fine than a second time resolution associated<br>
with the other cue code(s);<br>
means for upmixing one or more of the E transmitted channels to<br>
generate one or more upmixed channels; and means for synthesizing one<br>
or more of the C playback channels by applying the cue codes to the one<br>
or more upmixed channels, wherein the envelope cue code is applied to<br>
an upmixed channel or a synthesized signal to adjust a temporal envelope<br>
of the synthesized signal based on the characterized temporal envelope by<br>
scaling time domain or sub band domain signal samples using a scaling<br>
factor such that the adjusted temporal envelope matchers the<br>
characterized temporal envelope.<br>
37. Apparatus for decoding E transmitted audio channel(s) to generate C<br>
playback audio channels, where C&gt;E&gt;1, the apparatus comprising:<br>
a receiver adapted to receive cue codes corresponding to the E<br>
transmitted channel(s), wherein the cue codes comprise an envelope cue<br>
code corresponding to a characterized temporal envelope of an audio<br>
channel corresponding to the E transmitted channels, wherein the one or<br>
more cue codes further comprise one or more of inter-channel correlation<br>
(ICC) codes, inter-channel level difference (ICLD) codes, and inter-<br>
channel time difference (ICTD) codes, wherein a first time resolution<br>
associated with the envelope cue code is finer than a second time<br>
resolution associated with the other cue code(s);<br><br>
an upmixer adapted to upmix one or more of the E transmitted channels<br>
to generate one or more upmixed channels; and<br>
a synthesizer adapted to synthesize one or more of the C playback<br>
channels by applying the cue codes to the one or more upmixed channels,<br>
wherein the envelope cue code is applied to an upmixed channel or a<br>
synthesized signal to adjust a temporal envelope of the synthesized signal<br>
based on the characterized temporal envelope by scaling time domain or<br>
sub band domain signal samples using a scaling factor such that the<br>
adjusted temporal envelope substantially matches the characterized<br>
temporal envelope.<br>
38. The apparatus as claimed in claim 37, wherein:<br>
The apparatus selected from the group consisting of a digital video player,<br>
a digital audio player, a computer, a satellite receiver, a cable receiver, a<br>
terrestrial broadcast receiver, a home entertainment system, and a movie<br>
theater system; and comprises the receiver, the upmixer, and the<br>
envelope adjuster.<br><br><br><br>
ABSTRACT<br><br><br>
TITLE " INDIVIDUAL CHANNEL SHAPING FOR BCC<br>
SCHEMES AND THE LIKE"<br><br>
The invention relates to a method for encoding audio channels, the method<br>
comprising : generating two or more cue codes for one or more audio channels,<br>
wherein at least one cue code is an envelope cue code generated by<br>
characterizing a temporal envelope in one of the one or more audio channels,<br>
wherein the two or more cue codes further comprise one or more of inter-<br>
channel correlation (ICC) codes, inter-channel level difference (ICLD) codes, and<br>
inter-channel time difference (ICTD) codes, wherein a first time resolution<br>
associated with the envelope cue code is finer than a second time resolution<br>
associated with the other cue code(s), and wherein the temporal envelope is<br>
characterized in that, for the corresponding audio channel in a time domain or<br>
individually for different signal sub bands of the corresponding audio channel in a<br>
sub band domain; and transmitting the two or more cue codes.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1jbGFpbXMgMS4wLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-claims 1.0.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1jbGFpbXMgMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-claims 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-correspondence others 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4yLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-correspondence others 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4zLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-correspondence others 1.3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1jb3Jyb3Nwb25kIG90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-corrospond others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1mb3JtIDEgMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-form 1 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1mb3JtIDIucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1ncGEucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1pbnRlcm5hdGlvbmFsIHNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-international search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1vdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1wY3QgcmVxdWVzdC5wZGY=" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-pct request.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwOTcta29sbnAtMjAwNy1wcmlvcml0eSBkb2N1bWVudC5wZGY=" target="_blank" style="word-wrap:break-word;">01097-kolnp-2007-priority document.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgwMi0wOC0yMDEzKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(02-08-2013)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgwMi0wOC0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(02-08-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgwMi0wOC0yMDEzKS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(02-08-2013)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgwMi0wOC0yMDEzKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(02-08-2013)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1BTUFOREVEIENMQUlNUy5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-AMANDED CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1FWEFNSU5BVElPTiBSRVBPUlQgUkVQTFkgUkVDSUVWRUQuUERG" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-EXAMINATION REPORT REPLY RECIEVED.PDF</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1GT1JNIDEucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1GT1JNIDIucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1GT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1GT1JNIDUucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LSgxNy0wMS0yMDEyKS1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-(17-01-2012)-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUNBTkNFTExFRCBQQUdFUy5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-CANCELLED PAGES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUZPUk0gMTgucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-FORM 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUZPUk0gMjYucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-FORM 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUdSQU5URUQtU1BFQ0lGSUNBVElPTi1DT01QTEVURS5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-GRANTED-SPECIFICATION-COMPLETE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgUFVCTElDQVRJT04ucGRm" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-INTERNATIONAL PUBLICATION.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-INTERNATIONAL SEARCH REPORT &amp; OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LVBFVElUSU9OIFVOREVSIFJVTEUgMTM3LnBkZg==" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTA5Ny1LT0xOUC0yMDA3LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">1097-KOLNP-2007-REPLY TO EXAMINATION REPORT.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="257007-extrusion-head-for-extruding-a-surface-layer.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="257009-a-catalytic-conversion-process-for-producing-light-olefins-with-a-high-yield-from-petroleum-hydrocarbons.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>257008</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1097/KOLNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>37/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>13-Sep-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>26-Aug-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>29-Mar-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER-GESELLSCHAFT ZUR FORDERUNG DER ANWANDTEN FORSCHUNG E.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C, 80686, MUNICH, GERMANY</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>ERIC ALLAMANCHE</td>
											<td>GROSSREUTHERSTRASSE 130, 90425 NUERNBERG GERMANY</td>
										</tr>
										<tr>
											<td>2</td>
											<td>JUERGEN HERRE</td>
											<td>HALLERSTRASSE 24, 91054 BUCKENHOF / GERMANY</td>
										</tr>
										<tr>
											<td>3</td>
											<td>CHRISTOF FALLER</td>
											<td>GUETRAIN 1, 8274 TAEGERWILEN / SWITZERLAND</td>
										</tr>
										<tr>
											<td>4</td>
											<td>SASCHA DISCH</td>
											<td>TURNSTRASSE 7, 90763 FUERTH / GERMANY</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G10L 19/02</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2005/009618</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-09-07</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>11/006,482</td>
									<td>2004-12-07</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/620,480</td>
									<td>2004-10-20</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/257008-method-and-apparatus-for-encoding-and-decoding-audio-signals by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:55:51 GMT -->
</html>
