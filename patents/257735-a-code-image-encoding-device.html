<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/257735-a-code-image-encoding-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:36:25 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 257735:&quot;A CODE IMAGE ENCODING DEVICE&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;A CODE IMAGE ENCODING DEVICE&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A machine readable code, a code encoding method and device and a code decoding method and device are provided. This machine readable code includes a data area (1 1) made up of at least one data cell, in which different colors or shades are encoded and expressed depending on the content of the information. Various types of information can be expressed in a code image using colors, shades. shapes andlor pattens according to the present invention. The code system according to the present invention enables to encode more diversified and voluminous information compared to the other codes of the prior arts.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>business card of a company, users trying to send messages to the E-mail<br>
address must type the entire E-mail address.<br>
However, Internet home page addresses or E-mail addresses do not<br>
consist of one or two letters but generally of over ten letters to several tens<br>
s of letters. Thus, inputting the home page addresses or E-mail addresses<br>
can be a burden to users.<br>
v In order to solve this problem, U.S.C. Patent No. 5,869,828 entitled<br>
lor and shape system for encoding and decoding d a0 as been<br>
proposed. USP 5,869,828 discloses a method and system for<br>
l o encodingldecoding character data using a color figure, in which a color<br>
figure having a simple structure is printed on the exterior surface of<br>
products to represent information on the products.<br>
Printers may have different printing characteristics, so that a color<br>
figure may be printed in different colors depending on the type of printers.<br>
1s That is, if an item of data is encoded into a color figure and the color figure<br>
is printed by printers provided by different companies, the shades of the<br>
printed color figures may vary depending on the characteristics of each of<br>
the printers. Accordingly, in USP 5,869,828, even when an identical color<br>
figure is printed, different color figures may be obtained due to differences<br>
m in the printing environment, so that it is likelihood that the original data<br>
encoded in a color figure may not be correctly decoded.<br>
Disclosure of the Invention<br>
To solve the above problem, an objective of the present invention is 1<br>
2s to provide a machine readable code in which information is expressed by<br>
various colors, shades, shapes or patterns or a combination thereof.<br>
Another objective of the present invention is to provide a method and<br>
apparatus for encoding predetermined information into the abovedescribed<br>
code.<br>
30 Still another objective of the present invention is to provide a method<br>
and apparatus for decoding a code encoded by the above encoding method<br>
to extract the original information.<br>
Yet another objective of the present invention is to provide a<br>
computer-readable recording medium which records a program for<br>
accomplishing the encoding or decoding methods.<br>
To achieve the first objective, the present invention provides a<br>
s machine readable code for representing information, comprising: a<br>
background area; and a data area made up of at least one data cell,<br>
distinguished from the background area, in which different colors, shades,<br>
shapes or patterns or a combination thereof are encoded and expressed<br>
depending on the content of the information.<br>
10 The present invention also provides a machine readable code for <br>
representing information, comprising: a data area made up of at least one<br>
data cell, in which different colors, shades, shapes or patterns or a<br>
combination thereof are encoded and expressed depending on the content<br>
of the information; and a parity area made up of at least one parity cell, the<br>
1s parity area provided to determine whether colors, shades, shapes or<br>
patterns or a combination thereof expressed in the data cells have been<br>
properly expressed depending on the content of the information.<br>
Th-e re is further provided a machine readable code for representing <br>
information, the machine readable code comprising: at least two areas<br>
20 including a data area and a reference area, each of which includes at least<br>
one cell wherein the data area is forrned by at least one data cell in which<br>
different colors, shades, shapes or patterns or a combination thereof are<br>
encoded and expressed according to the content of the information to be<br>
represented therein; and a reference area formed by at least one reference<br>
2s cell which provides a base color, a base shade, a base shape or a base<br>
pattern or a combination thereof for determining the colors, shades, shapes<br>
or patterns or a combination thereof of data cells formed in the data area.<br>
To L<br>
achieve the s e s ; a n d ~ i v et, k g ~ g r o v i d ea s<br>
method of encoding a code image, including: (a) setting up a code<br>
b-- - - - - - . - - . ? - - - -- - - --<br>
30 conversion table in which different colors, shades, shapes or patterns or a<br>
combination thereof are mapped according to recognizable characters<br>
including numerals and symbols; (b) setting target data to be encoded; (c)<br>
encoding the target data using the code conversion table and forming a<br>
data area with an image formed in a series of colors, shades, shapes or<br>
patterns or a combination thereof; (d) setting up a parity area for<br>
determining whether the image formed in the data area is suitable for the<br>
s target data; and (e) obtaining a physical or electronic code image from the<br>
image for the data area and the parity area.<br>
There is also provided a code image encoding method comprising<br>
the steps of: setting a code &amp;version table in-which recognizable<br>
characters including numbers and symbols are mapped to different colors,<br>
l o shades, shapes or pattems or a combination thereof corresponding to the<br>
characters respectively; setting target data to be encoded; encoding the<br>
target data according to the code conversion table and generating an image<br>
expressed in a data area; setting a reference area in which base colors,<br>
base shades, base shapes or base patterns or a combination thereof for<br>
15 providing interpretation bases for colors, shades, shapes or patterns or a<br>
combination thereof expressed in the data area are expressed; and<br>
generating a physical or electronic code image from the image formed by<br>
the data area and reference area.<br>
To achieve the second objective, the present invention provides a<br>
.--<br>
m code image encoding device including: a storage unit for storing a code<br>
conversion table in which different colors, shades, shapes or patterns or a<br>
combination thereof are mapped according to recognizable characters<br>
including numerals and symbols; a data area formation unit for receiving<br>
target data to ,be encoded and encoding the target data using the code<br>
a conversion table to form an image to be expressed on a data area; a parity<br>
area formation unit for forming a parity area for determining whether the<br>
image formed in the data area is suitable for the target data upon decoding;<br>
and a code image formation unit for forming a physical or electronic code<br>
image from the image formed on the data area and the parity area.<br>
30 There is also provided a code image encoding apparatus<br>
comprising: a storage unit for storing a code conversion table in which<br>
recognizable characters including numbers and symbols are mapped to<br>
different colors, shades, shapes or pattems or a combination thereof<br>
corresponding to characters respectively; a data area generating unit for<br>
receiving target data to be encoded and then generating an image<br>
expressed in a data area by encoding the target data according to Vle code<br>
s conversion table; a reference area generating unit for setting a reference<br>
area in which base colors, base shades, base shapes or base pattems or<br>
a combination thereof for providing interpretation bases of colors, shades,<br>
shapes or pattems or a combination thereof to be expressed in the data<br>
area are expressed; and a code image generating unit for generating a<br>
lo physical or electronic code image from the image formed of the data area<br>
and reference area.<br>
To achieve the third objective, there is provided a code image<br>
decoding method according to an embodiment of the present invention,<br>
including: receiving a code image having a data area in which target data<br>
1s is encoded with colors, shades, shapes or pattems or a combination thereof<br>
into an image, and a reference area in which base colors, base shades,<br>
base shapes or base patterns or a combination thereof are expressed for<br>
providing interpretation bases of colors, shades, shapes or pattems or a<br>
combination thereof expressed in the data area; recognizing separately the<br>
20 data area and the reference area from the code image; determining the<br>
colors, shades, shapes or pattems or a combination thereof of each cell<br>
expressed in the data area based on the reference area; and extrading<br>
target data formed by recognizable characters including numbers and<br>
symbols, by decoding the code image by the code conversion table<br>
25 according to the determined colors, shades, shapes or pattems or a<br>
combination thereof of each cell in the data area.<br>
There is also provided a decoding apparatus comprising: a storage<br>
unit for storing a code conversion table in which recognizable characters<br>
including number and symbols are mapped to different colors, shades,<br>
30 shapes or patterns or a combination thereof; an input unit for receiving a<br>
code image which is encoded by the code conversion table having a data<br>
area, in which target data is expressed, and a reference area which<br>
provides interpretation bases for the data area; an information recognizing<br>
unit for recognizing separately the data area and the reference area from<br>
the code image, and determining colors, shades, shapes or patterns or a<br>
combination thereof of each cell expressed in the data area based on the<br>
s reference area; and a data extracting unit for extracting target data formed<br>
by recognizable characters including numbers and symbols by decoding<br>
the code image by the code conversion table according to colors, shades,<br>
shapes or pattems or a combination thereof of each cell in the data area.<br>
To achieve the third objective, there is provided a code image<br>
10 decoding method according to another embodiment of the present<br>
invention, including: (a) receiving a code image including a data area in<br>
which target data is encoded and expressed as an image in mlors, shades,<br>
shapes or pattems or a combination thereof and a parity area for<br>
determining whether the image formed in the data area is suitable for the<br>
15 target data; (b) discerning the data area and the parity area in the code<br>
image from each other; (c) recognizing colors, shades, shapes or patterns<br>
or a combination thereof from the images expressed in the data area and<br>
the parity area; (d) calculating a first parity value using the colors, shades,<br>
shapes or pattems or a combination thereof recognized from the image in<br>
20. the data area; (e) calculating a second parity value using the colors,<br>
shades, shapes or patterns or a combination thereof recognized from the<br>
image in the parity area, and comparing the second parity value with the<br>
first parity value; and (f) decoding the encoded image using the colors,<br>
shades, shapes or pattems or a combination thereof recognized from the<br>
2s data area and extracting target data made up of recognizable characters<br>
including numerals and symbols, if it is determined that there are no parity<br>
errors.<br>
There is also provided a code image decoding method comprising:<br>
(a) receiving a code image including a data area in which target data is<br>
w encoded and expressed as an image in colors, shades, shapes or patterns<br>
or a combination thereof a parity area for determining whether the image<br>
formed in the data area is suitable for the target data; (b) discerning the<br>
data area and the parity area in the code image from each other; (c)<br>
recognizing colors, shades, shapes or pattems or a combination thereof<br>
from the images expressed in the data area and the parity area; (d) setting<br>
parameters for normalizing the colors, shades, shapes or patterns or a<br>
combination thereof recognized from the code image in consideration of an<br>
environment where the code image has been read; (e) normalizing the<br>
colors, shades, shapes or pattems or a combination thereof recognized<br>
from the code image on the basis of the parameters, and obtaining a code<br>
value for the data area and the parity area; (f) calculating a first parity value<br>
using the code values for the data area; (g) calculating a second parity<br>
value using the code values for the parity area; (h) determining whether<br>
there are no parity errors, by comparing the first parity value with the<br>
second parity value; and (i) re-setting the parameters and repeating the<br>
above-described steps from the step (e), if parity errors are generated.<br>
To achieve the third objective, there is provided a code image<br>
decoding device including: a storage unit for storing a code conversion<br>
table on which different colors, shades, shapes or pattems ora combination<br>
thereof are mapped according to recognizable characters including<br>
numerals and symbols; an input unit for receiving a code image including<br>
a data area in which target data is encoded and expressed as an image in<br>
colors, shades, shapes or pattems or a combination thereof and a parity<br>
area for determining whether the image formed in the data area is suitable<br>
for the target data, the code image encoded according to the code<br>
conversion table; an information discerning unit for distinguishing between<br>
a data area and a parity area of the code image and discriminating between<br>
the colors, shades, shapes or patterns or a combination thereof of the cells<br>
expressed in the data area and the parity area; a parity comparison unit for<br>
calculating a first parity value depending on the colors, shades, shapes or<br>
patterns or a combination thereof recognized from the image of the data<br>
area, calculating a second parity value depending on the colors, shades,<br>
shapes or pattems or a combination thereof recognized from the image of<br>
the parity area, and comparing the second parity value with the first parity<br>
value; and a data extraction unit for extracting target data made up of<br>
recognizable characters including numerals and symbols by decoding the<br>
received code image depending on the colors, shades, shapes or patferns<br>
or a combination thereof recognized from the data area according to the<br>
s code conversion table, if it is determined from the comparison by the parity<br>
comparison unit that there is no parity error.<br>
Brief Description of the Drawinas<br>
FIGS. 1A through 1E are views illustrating the structure of a<br>
lo machine-readable code according to the present invention;<br>
FIG. 2A shows an example of expressing four colors using two bits,<br>
FIG. 26 shows an example of a code conversion table where various<br>
characters are converted into code images, FIG. 2C shows an example of<br>
a grayscale code, and FIGS. 20 and 2E show an example of a pattern that<br>
1s can be expressed on each of the cells of a code image;<br>
FIGS. 3A through 3F show various examples of the location of a<br>
parity area within a rectangular matrix-type code image;<br>
FIG. 4 shows the structure of a database which stores index<br>
information;<br>
20 FIG. 5 illustrates a process for obtaining target information using<br>
index information read from a code image;<br>
FIG. 6 is a flowchart illustrating a method of encoding information<br>
such as characters into a code image, according to an embodiment of the<br>
present invention;<br>
2s FIG. 7 shows an encoding system according to the present<br>
invention;<br>
FIG. 8A is a flowchart illustrating a method of decoding a code image<br>
into target information, according to an embodiment of the present<br>
invention, and FIG. 8B is a flowchart illustrating the step 80 of FIG. 8A in<br>
30 greater detail;<br>
FIG. 9 shows a decoding system according to the present invention;<br>
and<br>
FIG. 10 shows an example of an advertisement on which a code<br>
image is printed according to the present invention.<br>
FIGS. 1 IA through H show various examples of representing a code<br>
image according to the present invention,<br>
5<br>
Best mode for cawing out the Invention<br>
FIG. 1A shows an example of the structure of a code formed as an<br>
image so that target infonnation can be read by machines, according to the<br>
present invention. Referring to FIG. 1, this code includes at least a data<br>
to area having at least one cell. The code includes the data area 11 formed<br>
with at least one data cell which is encoded and expressed in different<br>
colors or shades depending on the content of information. Further, various<br>
shapes or patterns may be used for encoding information. Shapes of the<br>
cells may be are differently represented each other and patterns such as<br>
1s a line may be added within the cells.<br>
The code can further include a parity area 13, a reference area 15<br>
andlor a control area 17. The parity area 13 formed with parity cells for<br>
performing recognition error inspection with respect to the cells within the<br>
data area I I. The reference area 15 is formed with at least one reference<br>
a cell which provides a reference color or reference shade for judging the<br>
color or shade of me data cell formed in the data area 1 1. The control area<br>
17 is formed with at least one control cell which indicates a command or<br>
sewice capable of being provided using the information indicated in the<br>
data area 1 1. Hereinafter, one or more areas including the parity area, the<br>
25 reference area and the control area except the data area is referred to as<br>
"an auxiliary area" and a cell within the auxiliary area is referred to as "an<br>
auxiliary cell."<br>
Preferably, the code further includes a boundary area for defining<br>
the areas between the areas included in the code. Also, a boundary area<br>
30 can be further included between the cells included in each of the regions,<br>
in order to define cells. The boundary area can be made up of a line or cell<br>
having a specific color or pattern, and a boundary line or boundary area<br>
can be black or white. The areas can also be distinguished from each other<br>
by a certain range of a color or shade differently set for the cells of each of<br>
the data area, the parity area, the reference area and the control area, or<br>
by inserting an individual specific pattem into the cells of each of the areas.<br>
s Meanwhile, the boundary area may not be expressed in the code image for<br>
security of code information.<br>
The data area 11 is made up of at least one data cell in which a<br>
character or the like is encoded into an image. A data cell can be<br>
configured so as to represent information such as a single character, or a<br>
to set of data cells can be configured so as to represent one or more items of<br>
information. For example, a character A can be expressed as a single red<br>
cell or as two cells, for example, a red cell and a green cell.<br>
Target information contained in the data area 11 is made up of<br>
characters, numerals and symbols, and can be a variety of information such<br>
t5 as a name, an address, a telephone number, a facsimile number, the host<br>
address of a network, domain names and IP addresses used on the<br>
Internet, a URL, a protocol, or a document name, depending on the need<br>
of users.<br>
The parity area 13 is provided to be used upon decoding to<br>
20 determine whether colors or shades (and shape andfor pattem, if any)<br>
expressed in the cells are suitable for the content of target information.<br>
Parity data is obtained according to the code values corresponding to the<br>
colors or shades expressed in the data cells, and parity cells are formed by<br>
the colors or shades for the parity data. Various examples of the location<br>
25 of parity cells within a code image are shown in FIGS. 3A through 3F.<br>
The reference area 15 is used to set a reference color (or a<br>
reference shade, if necessary, a reference shape or a reference pattern) for<br>
recognizing the colors (or shades, shape or pattern) expressed in the cells<br>
in the data area 11 and/or the control area 17. The colors of the cells<br>
30 expressed in each of the areas are based on at least one model of a red<br>
blue green (RGB) color model, a hue saturation value (HSV) color model<br>
and the like. Also, when a code is formed in a black and white shade (gray<br>
scale), the inforrnation of each cell can be accurately ascertained on the<br>
basis of black andlor white expressed in the reference area 15.<br>
A color can be printed differently depending on the type of printer or<br>
the material used in the printing paper, and the same color can be<br>
s recognized somewhat differently depending on the characteristics of a<br>
scanner or camera. In consideration with this fact, the reference cells in the<br>
reference area 15 provide a standard for determining a color expressed on<br>
the data area. That is, even when a color is differently printed due to the<br>
difference in characteristics between output devices, or when a color is<br>
10 differently recognized due to the difference in characteristics between input<br>
devices such as a scanner, the color of each of the cells in the data area<br>
11 can be accurately recognized since the color difference between the<br>
reference area 15 and the data area 11 is f~ed. Therefore, the color of<br>
each of the cells can be obtained by the comparison with the reference<br>
1s color of the reference area 15 on the basis of the RGB model or HSV<br>
model, so that the information of a data cell can be accurately recognized<br>
even if an image input device or an image output device is changed. When<br>
a code image is input by a camera, shapes or patterns in the code image<br>
may be,distorted or tilted. Shapes or patterns expressed in the code image<br>
m may be correctly discerned based on the reference shape or reference<br>
pattern provided in the reference area.<br>
Users can receive various services depending on the type of<br>
application field using the target inforrnation of the data area 11. For<br>
example, if an lntemet home page address (that is, a URL) is expressed as<br>
25 a code image on a business card, a program can be provided so that a<br>
code image is decoded by a computer, and then a web browser of the<br>
computer or a server computer connected to the computer is executed to<br>
allow users to be connected to the home page. Also, if an Internet E-mail<br>
address is expressed as a code image on a business card, the code image<br>
30 is decoded by a computer, and then the mailing software of the computer<br>
is executed, to provide an environment where a mail can be sent to the Email<br>
address. In an another example, when the code image is input to a<br>
portable terminal such as a mobile phone, a phone call is made to a<br>
telephone number corresponding to the code image or a service for<br>
geographic information may be provided. Here, this automatic service<br>
fundion can be automatically executed by a separate program or by a<br>
5 decoding program depending on the type of target information. Also, a<br>
code image includes the control area 17 on which this command word is<br>
expressed as an image, so that the automatic service function can be<br>
executed by a decoding program using control information decoded by the<br>
control area 17.<br>
10 The control area 17 can include a command or metadata for<br>
controlling the target information of the data area. For example, the<br>
information expressed on the control area 17 can indude various metadata<br>
such as the sequence of decoding of the cells formed in the data area 1 1,<br>
the location of the reference cells of the reference area 15 that is a<br>
is standard of judgement of the colors of the data cells formed on the data<br>
area 11, the location or properties of the parity area 13, and the like.<br>
. Fig 1 B to Iâ‚¬are examples of expressing a data area and an<br>
auxiliary area in a code image. Here, the auxiliary area which is represent<br>
by hatched areas may include at least one area selected among a parity<br>
m area, a reference area and a control area.<br>
FIG. 2A shows an example of expressing data of two bits using four<br>
colors. If each cell can have one among four colors. 2-bit data can be<br>
expressed using one color cell. Hence, if 4 consecutive cells are defined<br>
to express one character, , that is, 256 characters, can be expressed. If<br>
25 a cell may expressed by one of four types of shapes, for example, a small<br>
rectangular, a large rectangular, a small circle and a large circle, while one<br>
color is used, data of two bits can be encoded. In this case, information of<br>
256 (8 bits) kinds can be expressed in a code image when a cell may be<br>
filled by one of four colors. FIG. 2B shows an example of a code<br>
XI conversion table where various characters (alphabet or special characters),<br>
numerals or figures are converted into color images. Here, one character<br>
is mapped to two color cells.<br>
In an encoding method using the code conversion table of FIG. 2B,<br>
various characters or the like are converted into code values, and then<br>
code images are produced in colors respectively allocated to the code<br>
values. In FIG. 2B, a code image is produced using 8 colors, and two<br>
5 consecutive cells are used to express one character or numeral. Code<br>
values "000" to "1 11" are allocated to 8 colors, respectively, and each<br>
character is encoded in two colors. For example, a number "3" is allocated<br>
as a code value "000 01 1 ", and encoded in a color (black) allocated to the<br>
code value "000" and a color (cyan) allocated to the code value "01 I", so<br>
lo that the number"3" is expressed using two consecutive cells of black and<br>
cyan. Various characters or numerals included in the target information are<br>
converted into code values according to the code conversion table shown<br>
in FIG. 28, and then colors corresponding to the code values can be<br>
expressed in a rectangular matrix, that is, a combination of rectangular<br>
15 cells.<br>
FIG. 2C shows an example of a code image produced using a<br>
grayscale code, according to the present invention. In the present<br>
invention, a character or numeral can be color-encoded and colordecoded<br>
using a color printer and a scanner. In FIG. 2C, a code image can be<br>
20 produced using a grayscale code, that is, shades ranging from black to<br>
white, depending on the purposes and circumstances of users.<br>
A grayscale code forms a code according to the brightness of white<br>
from black instead of a mixture ratio of red, green and blue. Thus, the<br>
reference area is formed of at least one reference shade among black,<br>
2s white and gray, and the cells formed in the data area have code values<br>
obtained due to the gray difference between their shades (or colors) and<br>
the reference shade of the reference area. If there is no reference area, a<br>
shade of each cell in the code image is detected, cells (cell group) having<br>
similar shades each otherwithin a predetermined criterion are grouped, and<br>
30 then the same code value is-assigned to the cells included in the same<br>
group. Next, using a parity area it is determined whether there is a<br>
decoding error. If an error, shades of the cells may be recalculated or<br>
criteria for forming cell groups are reestablished, and then it is determined<br>
whether an error is still happened. This gray code image can usually be<br>
applied to black printing media such as newspaper.<br>
FIGS. 2D and 2E show an example of a pattern that can be<br>
5 expressed in each of the cells of a code image. As can be seen from FIGS.<br>
2D and 2E, a method of adding a pattem to a color cell using a vector line<br>
in addition to color can be adopted to convert information into a code<br>
image. FIG. 2D shows an example of 4direction vector lines and 8-<br>
direction vector lines that can be expressed in a cell. If Uirection vector<br>
10 lines are used, patterns of four bits, that is, 16 different patterns, can be<br>
added to the color of each cell, as shown in FIG. 2E. Accordingly, when<br>
one character is expressed for one cell, and 8 colors, that is, colors of 3<br>
bits, are used, each cell can be expressed in 128 characters (characters of<br>
7 bits). Also, a cell can be divided in horizontal, vertical and diagonal<br>
15 directions, and the divided cell pieces can be expressed in different colors<br>
or shades.<br>
. In a code image according to an embodiment of the present<br>
invention, a data area and/or an auxiliary area may be expressed by<br>
shapes andlor patterns as well as colors or shades. Also, a data area<br>
20 and/or an auxiliary area may be expressed by at least one of colors,<br>
shades, shapes or patterns, or a combination thereof. For example,<br>
information may be expressed by various shapes or patterns in a data area<br>
and/or an auxiliary area while using only one color.<br>
FIGS 1 ?A though 11 H show various examples of representing a<br>
2s code image according the present invention. A cell may be variously<br>
expressed by one shape of a rectangular, a circle, an ellipse, a cross or<br>
web andlor a combination thereof.<br>
Size or shape of a code image or a cell included therein may be aptly<br>
selected according to contents or amounts of information to be expressed<br>
30 in the code image. FIG 11 H shows that a shape similar to a bar code also<br>
may be used in an embodiment of the present invention.<br>
FIGS. 3A through 3F show various examples of the location of the<br>
&amp;- parity area 13 of FIG. 1 within a rectangular matrix-type code image. Also,<br>
the configuration of these examples can be modified and applied to a code<br>
image having a circular shape or another shape. Area (Dn) except for the<br>
parity area (Pn) is a data area, a reference area or a control area.<br>
5 In FIG. 3A, parity cells each having parity information on the cells in<br>
the same row are located at the rightmost column. For example, the parity<br>
cell for cells Dl 1, 012. Dl3 and Dl4 is PI. In FIG. 38, parity cells each<br>
having parity information on the cells on the same row are aligned in a<br>
diagonal direction. In FIG. 3C, parity cells each having parity information<br>
lo on the cells on the same column are located at the lowermost row. In FIG.<br>
30, parity cells each having parity information on the cells on the same<br>
column are aligned in a diagonal direction.<br>
In FIG. 3E, parity cells Plr through P4r each having parity<br>
information on the cells in the same row are located at the rightmost<br>
1s column, and simultaneously, parity cells Plc through P4c each having<br>
parity information on the cells in the same column are aligned at the<br>
lowermost row. A parity cell Prc having parity information on the row parity<br>
cells and the column parity cells is further included. In FIG. 3F, a code<br>
includes the row parity cells Plr through P4r and the column parity cells<br>
20 PIC through P4c, as in FIG. 3E. Here, the row parity cells PI r through P4r<br>
are aligned in a diagonal direction. Conversely, the column parity cells PI c<br>
through P4c can be aligned diagonally.<br>
An example of a method of selecting a color for a parity cell will now<br>
be described. A parity cell has a code value obtained by performing a XOR<br>
2s operation with respect to the code values of the data cells (undoubtedly,<br>
reference cells and/or control cells can be included) on the same row or<br>
column. Various methods for generating parity data may be applied for<br>
encoding a code image according to the number of colors or shades to be<br>
expressed in the code image. For example, when two kinds of colors or<br>
30 shades are used, two parity methods, that is, an even parity method and an<br>
odd parity method may be available. When an even parity method is used,<br>
the result value of the XOR operation is directly the code value of a parity<br>
cell, so that the parity cell is expressed in a color for the obtained code<br>
value. When an odd parity method is used, the complement value (-) of<br>
each bit of the resultant value of the XOR operation is obtained, and the<br>
parity cell is formed in a color corresponding to the obtained complement<br>
5 value.<br>
A method of obtaining a color to be expressed in a parity cell using<br>
the code conversion table shown in FIG. 2A will now be described. If the<br>
colors of the data cells Dl 1, 012, Dl 3 and Dl4 are black, red, green and<br>
green, respectively, the code values of the data cells are 11,10,01 and 01,<br>
10 respectively. Here, 'XOR denotes an exclusive OR operation.<br><br>
11 XOR 10 XOR 01 XOR 01 = 01 (green)<br><br>
I IXOR 10 XOR 01 XOR 01 = 01 -&gt; -01 = 10 (red)<br>
1s As the number of colors or shades used in a code image is<br>
increased, it is more flexible to select one among various parity methods.<br>
When four types of colors or shades are used, four parity methods<br>
comprising modular parity methods as well as an even and odd parity<br>
method are available. The modular parity methods includes an even<br>
M modular parity method in which an even parity value obtained by the even<br>
parity method is added by two, the resultant value is divided by four and<br>
then the resultant value is set to a parity value and an odd modular parity<br>
method in which an odd parity value obtained by the odd parity method is<br>
added by two, the resultant value is divided by four and then the resultant<br>
a value is set to a parity value. In case of eight colors or shades, eight types<br>
of parity methods are available. In general, if the number of colors or<br>
shades used in a code image is assumed to N, the number of parity<br>
methods may be determined as follows:<br>
(an even parity value + 2 * i) % N, or<br>
30 (an odd parity value + 2 * i) % N<br>
where, i=0,1,2, . . . , log,N-I , N=2,4,8, . . . , and %: rnoddar.<br>
A plurality of parity methods may be simultaneously applied to one<br>
&amp;<br>
code image and thus type of code, type of decoding or direction for reading<br>
cells may be determined according to types of parity methods or locations<br>
expressed in the code image. Referring to FIG. 3E, an even parity method<br>
is applied to each row and column, but an odd parity method may applied<br>
s to a cell Prc. Referring to FIGS. 3A to 3C1 an even parity method is applied<br>
to the first column, but an odd parity method may applied to the remaining<br>
columns. Meanwhile, a shape or a pattern may also be used to express a<br>
parity value instead of colors or shades. Further, a combination of colors,<br>
shades, shapes andlor pattern is also available. For example, when a<br>
10 parity value is zero, a while rectangular All may be used or a black circle<br>
cell. A code image may further comprises a cell or an area in which<br>
inforrnation relating to a parity method applied to the code image is<br>
expressed.<br>
FIG. 6 is a flowchart illustrating a method of encoding information<br>
15 such as characters into a code image, according to an embodiment of the<br>
present invention. A method of converting inforrnation into a code image<br>
using encoding software will now be described. At least one character or<br>
numeral included in target information is converted into a code image<br>
formed of a predetermined shape, color or pattem or a combination of the<br>
m abovedescribed features using a predetermined code conversion table as<br>
shown in FIG. 2B.<br>
An encoding method may be a direct encoding method, an indirect<br>
(or index) encoding method or a mixed encoding method depending on the<br>
type of information encoded into a code image. In a direct encoding<br>
2s method, target information itself is directly encoded using a code<br>
conversion table, thereby producing a code image. In an indirect encoding<br>
method, index information (for example, the address of a database or a<br>
record number) for reference of target information is encoded into an image<br>
using a code conversion table. The mixed encoding method is a mixture of<br>
30 the two above-described methods.<br>
In the direct encoding method of encoding target information itself<br>
into a code image, a separate system or storage is not required. However,<br>
). when the amount of data of target information increases, the physical size<br>
of the code image increases.<br>
In the indirect encoding method, target information itself is not<br>
encoded, but information on the position of a storage medium is encoded.<br>
s This position information can be he pointer or memory address of a storage<br>
medium in which target information is stored, or the URL or IP address<br>
representing the position of target information. Thus, the indirect encoding<br>
method requires a separate system or a storage medium in which target<br>
inforrnation exists.<br>
10 In the mixed encoding method, some indispensable data among the<br>
entire target information is directly encoded, and the other data is indirectly<br>
encoded. For example, names and telephone numbers are encoded<br>
character by character, large data such as mail addresses or E-mail<br>
addresses is stored in a server, and the memory address of the data stored<br>
1s in the server is encoded to produce a code image. Also, it is preferable that<br>
fixed data such as names adopt the direct encoding method, and variable<br>
information capable of being changed at any time, such as, home page<br>
addresses, telephone numbers or E-mail addresses, is indirectly encoded.<br>
Even when the personal items of a user are changed, a person who has<br>
XI received a business card on which a code image of the user is expressed<br>
can always access the latest inforrnation even with the old business card<br>
if the user registers the changed items in the database of a server.<br>
FIG. 4 shows the structure of a database which stores index<br>
information required when an indirect encoding method is applied to an<br>
a encoding method according to the present invention. FIG. 5 illustrates a<br>
process for acquiring target inforrnation using index information read from<br>
a code image. In FIG. 5, a service pointer database 52 that stores pointer<br>
information capable of accessing real target information depending on<br>
index inforrnation is included together with an index database 51 as shown<br>
30 in FIG. 4. The pointer information indicates the position at which real target<br>
information 53 such as messages, images or moving pictures is stored.<br>
A unique index is allocated to each real target information (content),<br>
++ and the service code and the offset, which correspond to target information,<br>
are set and stored together. Here, the target information, which is the final<br>
inforrnation capable of being eventually used by users, includes various<br>
types of inforrnation such as web site addresses, E-mail addresses,<br>
s messages, images, moving pictures and music. A service code is<br>
designated depending on the type of service. For example, a web<br>
connection service and a telephone call service can be encoded into 0 "<br>
and Cl ", respectively. The offset relates to information on a position at<br>
which the service pointer database 52 can be accessed. For example, if<br>
l o index information is read from a code image, the index database 51 is<br>
searched to extract the service code, offset and target information for the<br>
index information. Pointer information stored in the service pointer<br>
database 52 is searched for depending on the offset. The positions of<br>
preset messages or image files are found depending on the pointer<br>
is inforrnation and the message or image is provided to users. For example,<br>
using a target data obtained by decoding a code image, a service type code<br>
is obtained from a first database and location information is obtained from<br>
a second database. Target information is obtained according to the<br>
location information, and then a service such as a message service, a<br>
20 moving image service, a web page access service, a telephone call service<br>
or an E-mail service which is determined by the service type code may be<br>
provided depending on the target inforrnation.<br>
An encoding process will now be described referring to FIG. 6. A<br>
code conversion table on which colors or shades (or gray levels) are<br>
2s mapped corresponding to recognizable characters including numerals and<br>
symbols, is established, in step 61. An example of the code conversion<br>
table is shown in FIG. 28, and a pattern (see FIG 2E) using a vector line<br>
can be used in the code conversion table.<br>
A user inputs target information to be converted into a code image,<br>
30 in step 62. Here, the user inputs his or her name, position, telephone<br>
number and facsimile number in order to encode, for example, personal<br>
items to be expressed on a business card, into a code image. It is common<br>
that a server stores information input by users in a database or file.<br>
Next, it is determined whether to apply the direct encoding method<br>
of directly encoding target information or the indirect encoding method of<br>
indirectly encoding information on the position at which target information<br>
s is stored in a data base, in step 63. If the direct encoding method is<br>
applied, the target inforrnation itself is set to be target data to be encoded,<br>
in step 64b. If the indirect encoding method is applied, the information on<br>
the position of the target information is set to be target data to be encoded,<br>
in step Ma. For example, if personal items (target inforrnation) themselves<br>
ro input by users are encoded, this corresponds to the direct encoding<br>
method. If database addresses at which the personal items are stored in<br>
a server, or indices associated with the addresses are encoded, this<br>
corresponds to the indirect encoding method. Also, a mixed encoding<br>
method, in which names are encoded by the direct encoding method and<br>
is the other personal items are encoded by the indirect encoding method, can<br>
be applied.<br>
The target data is encoded using a code conversion table, in step<br>
65. Then, a code value for each of the characters or numerals included in<br>
the target data is obtained, a color or shade for each data cell is determined<br>
20 by the code value to form an image of each data cell, and imaged data cells<br>
are aligned in the order (or in a determined way) of alignment of characters<br>
or the like of target data, thereby completing a data area.<br>
After the target data is encoded, at least one of parity inforrnation,<br>
reference information and control inforrnation may be selected as an<br>
2s auxiliary information to be expressed in a code image in step 66. .Further,<br>
a method of expressing the auxiliary inforrnation in the code image, for<br>
example, type of parity method, may be determined.<br>
If reference inforrnation is expressed in an auxiliary area of a code<br>
image, a reference area can be further set up by determining the shape,<br>
30 position or arrangement of reference cells in which a reference color or<br>
reference shade (and reference shape or reference pattern, if necessary)<br>
is to be expressed for providing a standard of interpretation of colors or<br>
shades expressed in the data cells of the data area. Also, a control area,<br>
in which control inforrnation where items associated with commands or<br>
services capable of being used using the target information included in the<br>
data area are set, can be further established.<br>
s Then, if parity information is expressed in an auxiliary area of a code<br>
image, a parity value is obtained from the code values of colors or shades<br>
(and shapes or patterns, if necessary) expressed in the data area or the<br>
like, and a color or shade for the parity value is set to be parity data, in step<br>
66. At this time, an area in which the parity cell is to be located is<br>
10 determined (see FIG. 1 and FIGS. 3A through 3F).<br>
When a data area and an auxiliary area are set up, the layout of a<br>
code image including the shape of the code image, the relative position and<br>
size of each of the areas, and the size of a cell unit is set. A code image<br>
made up of a data area and an auxiliary area is produced acmrding to the<br>
1s set layout, in step 67. The code image can be automatically output by the<br>
algorithm of a program, or manufactured by a graphic editor or by a manual<br>
operation according to a code conversion scheme. The code image formed<br>
in this way is expressed on a predetermined medium or stored in an image<br>
file.<br>
20 FIG. 7 shows an encoding system according to the present<br>
invention. In FIG. 7, a computer 77 receives target inforrnation, produces<br>
a code image through the above-described encoding process and prints the<br>
code image using a printer 78, so that the code image can be physically<br>
expressed on a medium 79a such as a business card or electronically<br>
25 provided in the form of a code image file 79b. Here, a medium on which a<br>
code image is expressed can be all media capable of expressing<br>
predetermined information, such as a business card, the exterior of<br>
products, the advertisement page of magazines and the like. Also, a code<br>
image can be output through a display device such as a monitor, stored in<br>
30 a computer file, or transmitted as an electrical signal to a communication<br>
line.<br>
FIG. 8A is a flowchart illustrating a decoding method to extract the<br>
original target information made up of characters or the like from a code<br>
image, according to an embodiment of the present invention. In order to<br>
decode a code image of the present invention, an image input device 92 for<br>
reading a code image 91a, such as a scanner, a digital camera, a CCD<br>
s camera, a sensor, a facsimile or the like, must be provided, or a code image<br>
must be provided in the form of a code image file 91 b so as to be directly<br>
used by a computer 93, as shown in FIG. 9. Also, the computer 93 (a<br>
personal computer or a server computer connected to personal computers)<br>
must be able to execute a program for decoding code images.<br>
10 - Refening back to FIG. 8A, a code image made up of a data area and<br>
: a parity area (including a reference area and a control area if they exist) is<br>
input to a user computer, in step 80. The user computer can directly<br>
receive the code image 91a expressed on a medium using an image input<br>
device, or can load the image file 91 b, which has already been made, into<br>
1s its memory using a storage device such as a disc or buffer. In the case of<br>
a code image formed by an indirect encoding method, the user computer<br>
must be connected to a server having a storage device in which index<br>
information is stored, or must include such a storage device.<br>
An image input by an image input device is processed by an edge<br>
m detection method or a noise image rejection method using predetermined<br>
parameters, thereby eliminating a background image and thus obtaining a<br>
code image. Sometimes, a code image may be read crookedly or aslant<br>
depending on the operating state of a scanner or the position on a medium<br>
at which the code image is printed. In this case, the code image may be<br>
25 decoded wrongly, Accordingly, the position or direction of the code image<br>
is corrected, in step 87. Even when the correction step is not performed,<br>
locations and inforrnation of each cell may be detected concerning the state<br>
of an input image.<br>
A data area and an auxiliary area (a parity area, a reference area<br>
30 and/or a control area) in the code image are discerned from each other<br>
using the information in a boundary area set between areas or using<br>
particular inforrnation in a cell, in step 82. If the auxiliary area includes at<br>
b- least two sub areas, these sub areas are discerned from each other. If<br>
there is the reference area in the code image, colors, shades, shapes<br>
and/or patterns are discriminated depending on information of the reference<br>
area. If there is the parity area in the code image, it is performed to detect<br>
s a decoding error.<br>
When a code image is recognized by a computer, a decoding<br>
process for extracting the original information from the code image is<br>
performed. Decoding denotes extraction of the original information from a<br>
code image according to what is defined in a code conversion table. Types<br>
lo of decoding methods include a direct decoding method and an indirect<br>
decoding method. In a direct decoding method, when a code image is<br>
decoded, actual target information such as names or addresses is directly<br>
extracted. In an indirect decoding method, a decoded result has index<br>
information, wtlich is a key value for accessing a database in which actual<br>
15 target information such as names or addresses is stored.<br>
Upon decoding, a process for finding shapes, colors, patterns and<br>
characters included in a code image is required, and a process for<br>
correcting distorted images is also required. Here, the colors can be<br>
discerned by at least one of an RGB (red, green, blue) model, an HSV (hue<br>
20 angle, saturation, value) model, a CMY (cyan, magenta, yellow) model and<br>
an HLS (hue angle, lightness, saturation) model.<br>
In order to achieve decoding, the code values of the cells within a<br>
data area and an auxiliary area are extracted, in step 83. if a reference<br>
area exists, a color (or shade, etc) is detected from a reference cell, and<br>
2s serves as a reference color (or reference shade) for interpreting the<br>
information in the data area or other areas. Colors are detected from the<br>
cells included in the data area, the parity area or the control area, and the<br>
color differences of the detected colors from the reference color are<br>
obtained and converted into the code values for the cells. If there is no<br>
30 reference area, the code values for the cells can be obtained depending on<br>
colors or shades interpreted by an image input device.<br>
If the parity area exists in a code image, the parity of each row or<br>
N column of the code image is checked as to whether it has errors, using the<br>
code values obtained from the parity area, that is, parity data, in step 84.<br>
This step will be described later in greater detail referring to FIG. 88. If<br>
necessary, direction or location of the code image may be also detected<br>
s depending on the parity data.<br>
The code value of each cell obtained through the abovedescribed<br>
process is converted into target data made up of recognizable characters<br>
including numerals and symbols according to a code conversion table (see<br>
FIG. 28). in step 85. The content of the target data obtained in step 85 is<br>
10 determined depending on the type of encoding method, in step 86. In step<br>
87a, if a code image is encoded by the indirect encoding method, that is,<br>
if target data obtained by decoding is index data, target information stored<br>
at a position on a storage device (database) determined by the target data<br>
is extracted, since the target data corresponds to the address or pointer of<br>
1s a storage device in which target information is stored. If the target data is<br>
not index data, the target data serves as desired target infomation, in step<br>
87b.<br>
It is determined whether a code image includes a control area in<br>
which items associated with commands or setvices capable of being<br>
x, executed using target information are set forth, in step 88. If a code image<br>
includes the control area, commands or sewices are provided depending<br>
on information set forth in the control area, in step 89a. Otherwise, a basic<br>
service designated in a program is provided, in step 89b.<br>
FIG. 88 is a flowchart illustrating the step 80 of FIG. 8A in greater<br>
2s detail. In FIG. 8B, parity is inspected on the basis of the code values<br>
extracted in step 84, and colors are corrected according to the result of the<br>
parity inspection.<br>
First, parameters for color interpretation are set in step 841. The<br>
parameters can be R, G and B in the RGB model, H, S and V in the HSV<br>
30 model, or a combination of the aforementioned features, and are set to<br>
normalize the code values of colors or shades recognized from a code<br>
image in consideration of the environment from which the code image has<br>
&amp; been read. Here, the parameters can be R, V and S values, that is, the R<br>
value obtained by the RGB model and the V and S values obtained by the<br>
HSV model. Generally, initial environmental parameters are set so as to-be<br>
suitable for the most-widely used illumination environment, such as,<br>
s fluorescent lamps or 3-wavelength lamps. Preferably, the parameters are<br>
set depending on the illumination environment when a white backgmund is<br>
photographed using an image input device, before a code image is input.<br>
For example, since red light is relatively strong under the illumination of a<br>
halogen lamp, parameters are set so as to remove an influence of red light<br>
l o from a halogen lamp. Then, an actually-read color is normalized by the<br>
parameters, thereby reducing the effect of illumination and obtaining a color<br>
which is close to the original color.<br>
Next, the R, G and B values of a color read from a code image are<br>
nmlized on the basis of the parameters R, V and S, in step 842. A code<br>
1s value for a color depending on the normalized R, G and B values is<br>
obtained using a code conversion table, in step 843. A parity value is<br>
calculated using the code value of the cells on each column and/or row<br>
expressed in a data area (including a reference area and a control area if<br>
they exist), in step 844. In step 845, the calculated parity value is<br>
compared with the parity data of a parity cell set in units of columns and<br>
rows of the data area, to determine whether there are parity errors. If a<br>
plurality of parity methods are applied to the code image, order of decoding<br>
cells included in the code image may be also easily detected besides a<br>
parity check described in the above.<br>
If a parity error is generated on a column or row, parameters for a<br>
new environment are set in step 846, and then the step returns to the color<br>
normalizing step 802. Parameters optimized to an illumination environment<br>
of high frequency, and their weighted values, are pre-set and stored in a<br>
3 decoding program or a database, so that users can select an environment<br>
parameter which is the most suitable for their environments. Generation of<br>
parity errors can be considered as generation of errors in color<br>
interpretation using the currently-set parameters. Accordingly, in this case,<br>
colors are again read using other parameters.<br>
The parameters are experimentally set in a parameter database so<br>
that a code image is distinguished from a background in an input image and<br>
5 a color read by an input optical device is corrected to the original color by<br>
analyzing the optical characteristics of the input optical device and its<br>
peripheral illumination circumstances. Thus, the effects of devices or an<br>
environment are excluded, so that colors can be recognized without errors.<br>
Two or more parameter groups each having other objective may be<br>
10 established. One may be a parameter gmup for distinguishing a code<br>
image from a background image and the other may be a parameter group<br>
for discerning colors or shades of the code image. For example, when<br>
colors are discerned on the basis of the RGB model under a red<br>
illumination environment, an R value is relatively high. Thus, the effects of<br>
1s environments can be excluded by reducing the R value read by an optical<br>
device depending on a predetermined weighted value. In a case of a code<br>
image received under a bright illumination environment, black and white are<br>
discerned from each other on the basis of the HSV model by increasing the<br>
weighted value of a V value. In a case of a code image received under a<br>
m dark illumination environment, colors are determined on the basis of the<br>
HSV model by increasing the weighted value of the V value which is used<br>
for discerning black and white from other colors and by increasing the<br>
weighted value of the S value.<br>
Upon re-setting parameters, the distribution of R, G, 6, H, S andtor<br>
25 V values obtained with respect to each of the cells of a code image by an<br>
optical device is ascertained, and parameters and their weighted values<br>
can be re-set with reference to the distribution.<br>
Meanwhile, when errors of reading data from a code image during<br>
decoding process continuously occur, a user may directly enter target data<br>
30 according to colors and so on expressed in the code image referring to a<br>
code conversion table and then a predetermined service may be provided<br>
to the user.<br>
FIG. 10 shows an example of an advertisement paper on which a<br>
code image is printed according to the present invention. Users who see<br>
the advertisement paper of FIG. 10 can obtain information on a code image<br>
by scanning (or photographing) the code image (a rectangular matrix-type<br>
s image displayed on the lower portion at the left and right sides of the<br>
advertisement paper) using an optical device such as a PC camera or a<br>
scanner.<br>
In the present invention, a computer-readable code image can be<br>
stored in recording media that can be read by a computer. The computerlo<br>
readable recording media may be any type of recording device that can be<br>
read by a computer system, such as, ROM, RAM, CD-ROM, magnetic<br>
tapes, floppy discs, optical data storage devices, and carrier waves (e.g.,<br>
transmissions over the Internet). Also, the computer readable recording<br>
media can be distributed on computer systems connected through a<br>
15 network and can store and execute a computer readable code in a<br>
distributed mode.<br>
As described above, various types of information can be expressed<br>
in a code image using colors, shades, shapes and/or pattens according to<br>
the present invention. The code system according to the present invention<br>
20 enables to encode more diversified and voluminous information compared<br>
to the other codes of the prior arts. Further, when a code image according<br>
to the present invention may include a parity area for parity inspection, malrecognition<br>
of colors due to the difference between input devices such as<br>
cameras or between the environments such as illumination conditions, can<br>
25 be easily detected and corrected. Thus, a more efficient decoding method<br>
and apparatus can be achieved using a code image according to the<br>
present invention.<br>
Industrial A~plicability<br>
30 According to an embodiment of the present invention, parity<br>
information together with target information is encoded into a code image<br>
according to a code conversion table, parity inspection is performed when<br>
the encoded code image is decoded, and environmental parameters are<br>
appropriately applied upon generation of parity errors, so that colors can<br>
be accurately recognized. In particular, even in an environment having<br>
normal brightness under a general fluorescent lamp, in a relatively dark or<br>
s bright environment, and in an environment where red light is strong such<br>
as an environment under a halogen lamp, information on a code can be<br>
accurately recognized. Also, when the code may include a reference area,<br>
the code reduces mis-recognition due to differences among operational<br>
conditions or machine models of output apparatuses or input apparatuses.<br><br><br><br><br>
We claim<br>
1. A code image encoding device (70) comprising:<br>
a storage unit for storing a code conversion table in which different colors,<br>
shades, shapes or patterns or a combination thereof are mapped according to<br>
recognizable characters including numerals and symbols;<br>
a data area formation unit (77) for receiving target data to be encoded and<br>
encoding the target data using the code conversion table to form an image to be<br>
expressed on a data area (1 1);<br>
a parity area formation unit for forming a parity area (13) for determining<br>
whether the image formed in the data area (1 1) is suitable for the target data upon<br>
decoding; and<br>
a code image formation unit (79) for forming a physical or electronic code<br>
image (79a, 79b) from the image formed on the data area (1 1) and the parity area<br>
(131,<br>
the encoding device characterized in that:<br>
each parity cell is formed by a color which is determined by parity data<br>
obtained from code value of at least one data cell.<br>
2. A code image decoding device (90) for decoding the encoded code image as<br>
claimed in claim 1, said decoding device comprising:<br>
a storage unit for storing a code conversion table on which different colors,<br>
shades, shapes or patterns or a combination thereof are mapped according to<br>
recognizable characters having numerals and symbols;<br>
an input unit (92) for receiving a code image (91a, 91 b), which is encoded<br>
according to the code conversion table, including a data area (1 1) in which target data<br>
is encoded and expressed as an image in colors, shades, shapes or patterns or a<br>
combination thereof and a parity area (1 3) for determining whether the image formed<br>
in the data area (1 1) is suitable for the target data; and<br>
an information discerning unit for distinguishing between a data area (1 1)<br>
and a parity area (13) of the code image and discriminating between the colors,<br>
shades, shapes or patterns or a combination thereof of the cells expressed in the data<br>
area (1 1) and the parity area (l3),<br>
the coding device characterized in that:<br>
each parity cell is formed by a color which is determined by parity data<br>
obtained from code value of at least one data cell, and<br>
the coding device further comprises:<br>
a parity comparison unit for calculating a first parity value depending<br>
on the colors, shades, shapes or patterns or a combination thereof recognized<br>
from the image of the data area (1 I), calculating a second parity value<br>
depending on the colors, shades, shapes or patterns or a combination thereof<br>
recognized from the image of the parity area(l3), and comparing the second<br>
parity value with the first parity value; and<br>
a data extraction unit for extracting target data made up of<br>
recognizable characters including numerals and symbols by decoding the<br>
received code image depending on the colors, shades, shapes or patterns or a<br>
combination thereof recognized from the data area (1 1) according to the code<br>
conversion table, if it is determined from the comparison by the parity<br>
comparison unit that there is no parity error.<br>
3. The code image encoding device as claimed in claim 1, wherein the storage<br>
unit and the data area formation unit is coupled to a reference area generating unit for<br>
setting a reference area in which base colors, base shades, base shapes or base<br>
patterns or base combination thereof for providing interpretation bases of colors,<br>
shades, shapes or patterns or a combination thereof to be expressed in the data area<br>
are expressed.<br>
4. The code image decoding device as claimed in claim 2, wherein<br>
the input unit receives a code image further including a reference area which<br>
provides interpretation bases for the data area; and<br>
the information discerning determines colors of each cell expressed in the<br>
data area based on the reference area.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDEwOTctZGVsLUNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-01097-del-Claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMDQtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Correspondence-Others-(04-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMDYtMDctMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Correspondence-Others-(06-07-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMDYtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Correspondence-Others-(06-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMTYtMDYtMjAwMykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Correspondence-Others-(16-06-2003).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMjYtMDMtMjAwMykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Correspondence-Others-(26-03-2003).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUNvcnJlc3BvbmRlbmNlLU90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Correspondence-Others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLURlc2NyaXRwaW9uIChDb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Descritpion (Complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLURyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tMS0oMDQtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-1-(04-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tMS0oMjYtMDMtMjAwMykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-1-(26-03-2003).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tMy0oMDQtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-3-(04-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tNS0oMjYtMDMtMjAwMykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-5-(26-03-2003).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLUdQQS0oMDQtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-GPA-(04-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLVBldGl0aW9uLTEzNy0oMDMtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Petition-137-(03-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLVBldGl0aW9uLTEzOC0oMDMtMDctMjAwNyktLnBkZg==" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Petition-138-(03-07-2007)-.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMDEwOTctREVMLVBldGl0aW9uLTEzOC0oMDMtMDctMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-01097-DEL-Petition-138-(03-07-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=SU4tUENULTIwMDItMTA5Ny1ERUwtQ29ycmVzcG9uZGVuY2UtT3RoZXJzLSgwNi0wNy0yMDEwKS5wZGY=" target="_blank" style="word-wrap:break-word;">IN-PCT-2002-1097-DEL-Correspondence-Others-(06-07-2010).pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="257734-extremely-insensitive-detonating-substance.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="257736-an-ophthalmic-solution.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>257735</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>IN/PCT/2002/01097/DEL</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>44/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>01-Nov-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>30-Oct-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>06-Nov-2002</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>COLORZIP MEDIA INC</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>211, YONSEI ENGINEERING RESEARCH COMPLEX, YONSEI UNIVERSITY, 134 SINCHON-DONG, SEODAEMUN-GU, SEOUL 120-749, REPUBLIC OF KOREA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>TACK-DON HAN</td>
											<td>922-201 MOK-DONG SHINSIGAJIE APT. 312, SINJEONG-DONG YANGCHEON-GU, SEOUL 121-140, REPUBLIC OF KOREA</td>
										</tr>
										<tr>
											<td>2</td>
											<td>CHEOL-HO CHEONG</td>
											<td>10/4, 62-9, YEONHEE 3-DONG SEODAEMUN-GU SEOUL 120-823, REPUBLIC OF KOREA</td>
										</tr>
										<tr>
											<td>3</td>
											<td>NAM-KYU LEE</td>
											<td>103-503 BYUCKSAN APT. GANGSUN MAEUL JUYUP-DONG, ILSAN-GU GYUNGGI-DO, GOYANG-CITY 411-743, REPUBLIC OF KOREA</td>
										</tr>
										<tr>
											<td>4</td>
											<td>EUN-DONG SHIN</td>
											<td>101-1207 GEUMGANG APT. SIHEUNG-DONG, GEUMCHEON-GU SEOUL 153-030, REPUBLIC OF KOREA</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06K 9/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2001/00742</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2001-05-08</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>2000-24706</td>
									<td>2000-05-09</td>
								    <td>Republic of Korea</td>
								</tr>
								<tr>
									<td>2</td>
									<td>2000-62597</td>
									<td>2000-10-24</td>
								    <td>Republic of Korea</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/257735-a-code-image-encoding-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:36:26 GMT -->
</html>
