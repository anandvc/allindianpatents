<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/225370-head-mounted-device-for-semantic-representation-of-the-user-surroundings by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:23:15 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 225370:HEAD MOUNTED DEVICE FOR SEMANTIC REPRESENTATION OF THE USER SURROUNDINGS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">HEAD MOUNTED DEVICE FOR SEMANTIC REPRESENTATION OF THE USER SURROUNDINGS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>HEAD MOUNTED DEVICE FOR SEMANTIC REPRESENTATION OF THE USER SURROUNDINGS A head mounted device for semantic representation of the user surroundings. The device comprises a cap (1) adapted to be fitted on the head of the user, an image capturing means (7) mounted on the cap, a computing platform (8) connected to the image capturing means, a feature data store (9) connected to the computing platform and an output module (10) connected to the computing platform. The feature data store comprises reference features which represent different entities existing in the surroundings and are associated with semantic description of the entities in the surroundings represented by them. The computing platform is designed to extract at least one feature from the images of the entities in the surroundings captured by the image capturing means, compare the extracted feature of the captured image with the reference features in the feature data store, identify the reference feature in the data store closest to the extracted feature of the captured image and provide an output i.e. the semantic description of the entities in the surroundings associated with the identified feature to the output module. (Fig 1) `</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM 2<br>
THE PATENTS ACT, 1970 <br>
(39 of 1970)<br>
As amended by the Patents (Amendment) Act, 2005<br>
&amp;<br>
The Patents Rules, 2003 <br>
As amended by the Patents (Amendment) Rules, 2005<br>
COMPLETE SPECIFICATION<br>
(See section 10 and rule 13)<br>
TITLE OF THE INVENTION<br>
Head mounted device for semantic representation of the user surroundings APPLICANTS<br><br>
Name Nationality<br>
Address	:<br>
INVENTORS<br>
Names<br>
Nationality<br>
Address<br><br>
Indian Institute of Technology, Bombay an autonomous research and educational<br>
institution established in India by a special<br>
Act of the Parliament of the Republic of India<br>
under the Institutes of Technology Act 1961<br>
Powai, Mumbai 400076, Maharashtra, India<br>
Chaudhuri Subhasis, Rajashekar and Prabhudesai Amit<br>
all Indian Nationals<br>
all of Indian Institute of Technology, Bombay, Department<br>
of Electrical Engineering, Powai, Mumbai 400076, Maharashtra,<br>
India<br><br>
PREAMBLE TO THE DESCRIPTION<br>
The following specification particularly describes the nature of this invention and the manner in which it is to be performed :<br><br>
FIELD OF INVENTION<br>
This invention relates to a head mounted device for semantic representation of the user surroundings.<br>
The term "semantic representation of the surroundings" as used in the specification means a verbal description of the surroundings whereby the user can form an image of the surroundings mentally or visualise or perceive the surroundings.<br>
The device can be used to aid a visually impaired person and give him a semantic description of the surroundings around him or traversed by him. The device can also be used to augment a robot navigation system whereby a remote operator gets a perception of the surroundings around the robot or traversed by the robot.<br>
BACKGROUND OF THE INVENTION<br>
US Publication No 2005/0208457 relates to a camera based object detection system for the visually impaired. The system comprises a digital camera mounted on the user to take images of objects on demand, real time algorithms connected to the camera to decipher attributes of the images, an announcement module connected to the algorithms to construct a sentence to describe the images and a computer based voice synthesizer connected to the module to verbally announce the sentence to the user. The system essentially enables the user to recognize or identify the objects in front of the user and navigate but does not give to the user a qualitative or semantic description or mental picture of the surroundings around him or traversed by him.<br>
2<br><br>
WO 03/107039 relates to an apparatus and method and also a system for aiding the visually impaired. It comprises means for sensing time/space characteristics and physical characteristics information about an object in a field of view, means for interpreting the time/space characteristics and physical characteristics information and for characterizing the object and audible information delivery device for audibly describing to the user the characterization of the object and the interpretation about the object. This also enables the user to recognize or identify the objects in front of the user and navigate but does not give a mental picture or perception of the surroundings around the user or he is traversing.<br>
OBJECTS OF INVENTION<br>
An object of the invention is to provide a head mounted device, which enables the user to perceive the surroundings around him or he is traversing accurately and reliably.<br>
An other object of the invention is to provide a head mounted device, which is light weight to be carried on the person of the user and is simple in construction and easy to operate.<br>
Another object of the invention is to provide a head mounted device, which is economical.<br>
Another object of the invention is to provide a head mounted device, which aids a visually impaired person wearing it by giving him a semantic description of the surroundings around him or traversed by him.<br>
3<br><br>
Another object of the invention is to provide a head mounted device, which can be used to augment a robot navigation system whereby a remote operator gets a perception of the surroundings around the robot or being traversed by the robot.<br>
DETAILED DESCRIPTION OF INVENTION<br>
According to the invention there is provided a head mounted device for semantic representation of the user surroundings, the device comprising a cap adapted to be fitted on the head of the user, an image capturing means mounted on the cap, a computing platform connected to the image capturing means, a feature data store connected to the computing platform and comprising reference features which represent different entities existing in the surroundings and are associated with semantic description of the entities<br>
9<br>
in the surroundings represented by them and an output module connected to the computing platform, the computing platform being designed to extract at least one feature from the images of the entities in the surroundings captured by the image capturing means, compare the extracted feature of the captured image with the reference features in the feature data store, identify the reference feature in the data store closest to the extracted feature of the captured image and provide an output ie the semantic description of the entities in the surroundings associated with the identified feature to the output module.<br>
The following is a detailed description of the invention with reference to the accompanying drawings, in which:<br>
4<br><br>
Fig 1 is a block diagram of a head mounted device for semantic representation of the user surroundings excluding the cap according to an embodiment of the invention;<br>
Fig 2 is a schematic view of the cap of the device of Fig 1; and<br>
Fig 3 is a schematic view of the cap and the image capturing means mounted on the cap.<br>
The device of the invention as illustrated in the accompanying drawings comprises a cap 1 provided with a pair of fastening straps 2 and 3. The strap 2 is provided with a buckle 4 whose hinged pin is marked 5. The strap 3 is provided with a series of pin holes 6. The cap 1 is worn on the head of a user and fastened to the head of the user by threading strap 3 through the buckle 4 and engaging pin 5 of the buckle in one of the pin holes 6 in the strap 3. An image capturing means comprising a non-calibrated digital camera 7 is mounted on the cap with support members 7a, 7b and 7c which are fixed on the cap. The outer surface of the cap is rendered reflective by coating the outer surface of the cap with a reflective material such as mercuric oxide in known manner. The reflective coating is marked la. Alternatively, the image capturing means comprises an omnidirectional camera mounted on the cap. 8 is a computing platform connected to the image capturing means. The cord connecting the image capturing means to the comprising platform is marked 7d. The computing platform comprises, for instance, a laptop PC. 9 is a feature data store connected to the computing platform. The feature data store comprises reference features which represent different entities like trees or buildings or water bodies or roads existing in the surroundings.  Each of the reference<br>
5<br><br>
features is associated with a semantic description of the entities in the surroundings represented by them. The feature data store is stored on a USB drive or flash memory stick or hard disk. 10 is an output module connected to the computing platform. The output module comprises, for instance, an audio system comprising a pair of speakers worn on the ears of the user like visually impaired person and connected to the output port of the laptop PC or a Braille board display connected to the output port of the laptop PC. In the case of a digital camera, snapshots of the images of the entities in the surroundings of the user reflected on the outer surface of the cap are taken by the camera. In the case of an omnidirectional camera, snapshots of the entities in the surroundings of the user are directly taken by the camera. Each of the images shot by the camera is divided into five sectors namely Right Top (RT), Front Right (FR), Left Top (LT), Left Bottom (LB) and Right Bottom (RB). The laptop PC extracts at least one feature of each the sectors of the captured image. Preferably the extracted feature is the colour component of the different entities in the surroundings as captured by the camera. The laptop PC compares the colour feature with the reference features stored on the data store. Color feature in the data store that best matches with the extracted features is identified. A semantic description of the entity in the surroundings associated with the identified feature is fed to the speakers or Braille board display, as the case may be, thereby enabling the user to relate to or visualise or perceive the surroundings he is in or traversed by him.<br>
The device of the invention can be used by a visually impaired person so as to enable him to perceive or visualise the surroundings around him or he is traveling accurately and reliably. The device can also be used to augment a robot navigation system whereby a<br>
6<br><br>
remote operator can get a perception of the surroundings around the robot or traversed by the robot. The components of the device of the invention are relatively cheap and, therefore, the device of the invention is economical. It is also simple in construction and easy to operate besides being light weight to be carried on the head of the user.<br>
EXAMPLE 1<br>
A typical device of the invention comprising an omnidirectional camera was tested on a visually impaired person by making him traverse on a road surrounded by woods and water body and buildings on both the sides. The visually impaired person took 15 snap shots of the surroundings at different locations. Each of the images shot by the camera was divided by the camera into five sectors namely Right Top (RT), Front Right (FR), Left Top (LT), Left Bottom (LB) and Right Bottom (RB). The color feature of each of the sectors of the captured image was extracted by the laptop PC. The color features extracted from each of the sectors of the captured image was compared with the reference features stored on the data store. Color features in the data store that best matched with the extracted features were identified and a semantic description of the features was fed to the Braille board. The data read by the visually impaired person on the Braille board was tabulated against actual data as shown in the following Table. It is quite clear from the Table that the estimated description (ED) matched with the true description (TD) thereby establishing that the device is accurate and reliable.<br>
7<br><br>
Table<br><br>
Photo					Sectors				<br>
Frame	RT	FR	LT	LB	RB<br>
	EC	TC	EC	TC	EC	TC	EC	TC	EC	TC<br>
1	WD	WD	WD	WD	WD	WD	BD	BD	WD	WD<br>
2	WD	WD	BD	BD	WD	WD	WD	WD	WD	WD<br>
3	WD	WD	BD	BD	WD	WD	WD	WD	WD	WD<br>
4	BD	BD	WD	WD	WD	WD	WD	WD	BD	BD<br>
5	WD	WD	WD	WD	WD	WD	WD	WD	BD	BD<br>
6	BD	BD	BD	BD	BD	BD	WD	WD	BD	BD<br>
7	BD	BD	BD	BD	BD	BD	WD	WD	BD	BD<br>
8	WD	WD	BD	WD	WD	WD	BD	BD	WD	WD<br>
9	WD	WD	BD	WD	BD	BD	BD	BD	WD	WD<br>
10	WD	WD	BD	BD	WD	WD	WD	WD	WD	WD<br>
11	WD	WD	WD	WD	BD	WD	WD	WD	WD	WD<br>
12	WD	WD	WD	WD	WD	WD	BD	BD	WD	WD<br>
13	WD	WD	WD	WD	WD	WD	BD	BD	WD	WD<br>
14	WD	WD	BD	WD	WD	WD	BD	BD	WD	WD<br>
15	WD	WD	WD	WD	WD	WD	WD	WD	WD	WD<br>
TC	=	True Category<br>
EC	=	Estimated Category<br>
WD	=	Woods<br>
BD	=	Building<br>
It is possible to have variations in the invention without deviating from the scope thereof. For instance the cap configuration can be different. The extracted feature of the captured image and the features in the reference data store need not be colour. Besides the feature<br>
8<br><br>
data store, the computing platform may comprise image processors. Such variations of the invention are to be construed and understood to be within the scope of the invention.<br><br>
We Claims:-<br>
1.	A head mounted device for semantic representation of the user surroundings, the device comprising a cap adapted to be fitted on the head of the user, an image capturing means mounted on the cap, a computing platform connected to the image capturing means, a feature data store connected to the computing platform and comprising reference features which represent different entities existing in the surroundings and are associated with semantic description of the entities in the surroundings represented by them and an output module connected to the computing platform, the computing platform being designed to extract at least one feature from the images of the entities in the surroundings captured by the image capturing means, compare the extracted feature of the captured image with the reference features in the feature data store, identify the reference feature in the data store closest to the extracted feature of the captured image and provide an output ie the semantic description of the entities in the surroundings associated with the identified feature to the output module.<br>
2.	A device as claimed in claim 1, wherein the image capturing means comprises a non-calibrated digital camera mounted on the cap, the outer surface of the cap being reflective.<br>
3.	A device as claimed in claim 1, wherein the image capturing means comprises an omni directional camera mounted on the cap.<br>
10<br><br>
4.	A device as claimed in any one of claims 1 to 3, wherein the computing platform comprises a laptop PC.<br>
5.	A device as claimed in any one of claims 1 to 4,wherein the extracted feature comprises the color component of the different entities existing in the surroundings as captured by the image capturing means.<br>
6.	A device as claimed in any one of claims 1 to 5,wherein the output module comprises an audio system or a Braille board display.<br>
7.	A device as claimed in anyone of claims 1 to 6, wherein the feature data store comprises feature data stored on a USB drive or flash memory stick or hard disk.<br>
8.	A head mounted device as claimed in anyone of claims 1 to 7, which is for use by a visually impaired person.<br>
9.	A head mounted device as claimed in anyone of claims 1 to 7, which is for use<br>
on a robot.<br>
Dated this 27th day of January 2006<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWFic3RyYWN0KDE2LTAyLTIwMDQpLmRvYw==" target="_blank" style="word-wrap:break-word;">133-mum-2006-abstract(16-02-2004).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUFCU1RSQUNUKDI3LTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">133-MUM-2006-ABSTRACT(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUFCU1RSQUNUKDUtOS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-MUM-2006-ABSTRACT(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUFCU1RSQUNUKENBTkNFTExFRCBQQUdFKS0oNS05LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-ABSTRACT(CANCELLED PAGE)-(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWFic3RyYWN0KGdyYW50ZWQpLSgxMS0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-abstract(granted)-(11-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWFic3RyYWN0LmRvYw==" target="_blank" style="word-wrap:break-word;">133-mum-2006-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">133-mum-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUNMQUlNUygyNy0xLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-CLAIMS(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUNMQUlNUyg1LTktMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-MUM-2006-CLAIMS(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWNsYWltcyhncmFudGVkKS0oMTEtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-claims(granted)-(11-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWNsYWltcyhncmFudGVkKS0oMTYtMDItMjAwNCkuZG9j" target="_blank" style="word-wrap:break-word;">133-mum-2006-claims(granted)-(16-02-2004).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWNsYWltcy5kb2M=" target="_blank" style="word-wrap:break-word;">133-mum-2006-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUNPUlJFU1BPTkRFTkNFKDExLTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-MUM-2006-CORRESPONDENCE(11-1-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUNPUlJFU1BPTkRFTkNFKDUtOS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-MUM-2006-CORRESPONDENCE(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWNvcnJlc3BvbmRlbmNlLXJlY2VpdmVkLXZlci0yMDAzMDYucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-correspondence-received-ver-200306.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWNvcnJlc3BvbmRlbmNlLXJlY2VpdmVkLXZlci0yNzAxMDYucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-correspondence-received-ver-270106.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LURFU0NSSVBUSU9OKENPTVBMRVRFKS0oMjctMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-MUM-2006-DESCRIPTION(COMPLETE)-(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LURFU0NSSVBUSU9OKENPTVBMRVRFKS0oNS05LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-DESCRIPTION(COMPLETE)-(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWRlc2NyaXB0aW9uKGdyYW50ZWQpLSgxMS0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-description(granted)-(11-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LURSQVdJTkcoMjctMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-MUM-2006-DRAWING(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LURSQVdJTkcoNS05LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-DRAWING(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWRyYXdpbmcoZ3JhbnRlZCktKDExLTExLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-mum-2006-drawing(granted)-(11-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">133-mum-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMSgyMi0yLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 1(22-2-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMSgyNy0xLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 1(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMSg1LTktMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 1(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMTgoMTUtNi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 18(15-6-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0gMig1LTktMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-form 2(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMihDT01QTEVURSktKDI3LTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 2(COMPLETE)-(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0gMihncmFudGVkKS0oMTEtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-form 2(granted)-(11-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0gMihncmFudGVkKS0oMTYtMDItMjAwNCkuZG9j" target="_blank" style="word-wrap:break-word;">133-mum-2006-form 2(granted)-(16-02-2004).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMihUSVRMRSBQQUdFKS0oMjctMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 2(TITLE PAGE)-(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMihUSVRMRSBQQUdFKS0oNS05LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 2(TITLE PAGE)-(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0gMih0aXRsZSBwYWdlKS0oZ3JhbnRlZCktKDExLTExLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-mum-2006-form 2(title page)-(granted)-(11-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0gMygyNy0wMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-form 3(27-01-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMygyNy0xLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 3(27-1-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gMyg1LTktMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 3(5-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLU1VTS0yMDA2LUZPUk0gOCgyOS01LTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">133-MUM-2006-FORM 8(29-5-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0tMi5kb2M=" target="_blank" style="word-wrap:break-word;">133-mum-2006-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">133-mum-2006-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMzLW11bS0yMDA2LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">133-mum-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="225369-aqueous-isotropic-liquid-laundry-detergent-composition.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="225371-a-process-for-preparing-2-2-6-dichlorophenyl-amino-benzeneacetic-acid-carboxymethyl-ester.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>225370</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>133/MUM/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>07/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>13-Feb-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>11-Nov-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>27-Jan-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INDIAN INSTITUTE OF TECHNOLOGY BOMBAY</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>POWAI MUMBAI 400 076</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>CHAUDHURI SUBHASIS</td>
											<td>INDIAN INSTITUTE OF TECHNOLOGY BOMBAY DEPARTMENT OF ELECTRICAL ENGINEERING POWAI MUMBAI 400 076</td>
										</tr>
										<tr>
											<td>2</td>
											<td>RAJASHEKAR</td>
											<td>INDIAN INSTITUTE OF TECHNOLOGY BOMBAY DEPARTMENT OF ELECTRICAL ENGINEERING POWAI MUMBAI 400 076 MAHARASHTRA INDIA</td>
										</tr>
										<tr>
											<td>3</td>
											<td>PRABHUDESAI AMIT</td>
											<td>INDIAN INSTITUTE OF TECHNOLOGY BOMBAY DEPARTMENT OF ELECTRICAL ENGINEERING POWAI MUMBAI 400 076 MAHARASHTRA INDIA</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F7/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td></td>
									<td></td>
								    <td>NA</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/225370-head-mounted-device-for-semantic-representation-of-the-user-surroundings by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:23:16 GMT -->
</html>
