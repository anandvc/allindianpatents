<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/235018-a-method-of-reducing-bandwidth-by-selectively-sending-media-information-over-a-communications-network by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 14:33:56 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 235018:A METHOD OF REDUCING BANDWIDTH BY SELECTIVELY SENDING MEDIA INFORMATION OVER A COMMUNICATIONS NETWORK</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A METHOD OF REDUCING BANDWIDTH BY SELECTIVELY SENDING MEDIA INFORMATION OVER A COMMUNICATIONS NETWORK</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A system and method for managing communication in an integrated services network ensures that media information is displayed on at least one of two terminals during a call without using any transmission bandwidth. This is achieved by haying at least one of the terminals pre-store the media information in a memory and then controlling the terminal to recall and display this information when certain events occur during the call. The media information may include animated information, images, and short-time video scripts. This information and broader band media such as streaming video may be displayed on the same terminal. The display of media information may also be controlled based on the past knowledge and experience callers have about one another and/or their communications equipment.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>WO 2004/030381 	PCT/KR2003/001893<br>
1<br>
SYSTEM AND METHOD FOR MULTIPLEXING MEDIA INFORMATION OVER<br>
A NETWORK USING REDUCED COMMUNICATIONS RESOURCES AND<br>
PRIOR KNOWLEDGE/EXPERIENCE OF A CALLED OR CALLING PARTY<br>
5	TECHNICAL FIELD<br>
		This invention generally relates to managing network communications,<br>
	and more particularly to a system and method for controlling the communication<br>
	of media information over an integrated services network.<br>
10<br>
	BACKROUND ART<br>
		In recent years, remarkable technical advances have been made in the<br>
	areas of wireless- and Internet-related communications. One application of this<br>
	technology focuses on providing bi-directional video conferencing (e.g., video<br>
	phone) services over wired and wireless networks. In order to provide real-time<br>
15	streaming video of reasonable quality, a transmission bandwidth of at least 64 K<br>
	bits per second is required. This is approximately eight times the bandwidth<br>
	required for voice communications, even if a highly efficient compression<br>
	scheme is implemented.<br>
		One of the most significant stumbling blocks to providing high-quality<br>
20	multimedia video-conferencing services is insufficient transmission bandwidth.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
2<br>
	Also, there is great doubt as to whether two-way video phone services will be of<br>
	interest to the public, even if these services can be provided at a reasonably<br>
	affordable price, to elicit public Interest and therefore to build a strong market<br>
	for the video conferencing industry, the inventor of the present invention has<br>
5	realized that social interactions between callers must be encouraged<br>
	sacrificing valuable transmission bandwidth. Taking this approach<br>
	increase minutes of usage and thus generate revenue sufficient to ensure the<br>
	continued advancement of the telecommunications industry.<br>
		The inventor of the present invention has also recognized that next-<br>
10	generation communications systems must provide a variety of multimedia<br>
	services including real-time streaming video and video-clip swapping, while<br>
	simultaneously conserving or reducing transmission bandwidth requirements<br>
	and other network resources. Present communications systems do note<br>
	adequately provide these services, and the services they do provide are<br>
15	implemented in an efficient manner. A need therefore exists for a system and<br>
	method for providing enhanced multimedia services to the public which at the<br>
	same time conserves or reduces network resources.<br>
		Further, it is noted that currently existing telecommunications systems<br>
	cannot deal with abstractions and emotions of callers that are natural to every<br>
20	day interaction. For example, the majority of callers know one another. They<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
3<br>
	know their characters, physical appearances, and other attributes through<br>
	past shared experiences and knowledge. Parties also often have knowledge<br>
	of other parties' mobile terminals, including the manner in which they are<br>
	equipped and their ability to support multimedia and other services. Existing<br>
5	communications systems do not use the prior knowledge and experience of<br>
	callers as a basis for reducing transmission bandwidth in providing<br>
	multimedia services in a communications system. These systems also do not<br>
	use prior knowledge and experience as a basis for reducing the costs<br>
	 associated with providing multimedia communications.<br>
10 		Further, it is noted that conventional communications systems are<br>
	required to transmit multimedia information over a network every time these<br>
	services are desired to be displayed on a receiving terminal. This frustrates<br>
	attempts to conserve transmission bandwidth and adversely affects the<br>
	quality of communications of other users.<br>
15 		There is, therefore, an additional need for a system and method that<br>
	manages communication of multimedia services more efficiently than<br>
	conventional systems, by ensuring that transmission bandwidth and other<br>
	network resources are not used every time one terminal desires another<br>
	terminal to display media information. There is also a need to provide a<br>
20	system and method of this type in a cost- effective manner.<br>
DISCLOSURE OF THE INVENTION<br>
		An object of the invention is to solve at least the above problems<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
4<br>
	and/or disadvantages and to provide at least the advantages described<br>
	hereinafter.<br>
		It is one object of the present invention to provide a system and<br>
	method for managing communication of media Information in a network more<br>
5	efficiently than conventional systems of this type.<br>
		It is another object of the present invention to achieve the <br>
	 aforementioned object by ensuring that transmission bandwidth and other<br>
	network resources are not used every time one terminal desired another<br>
	terminal to display media information.<br>
10 		It is another object of the present invention to achieve the<br>
	aforementioned objects in a cost-effective manner.<br>
		It is another object of the present invention to provide a system and<br>
	method for managing communication of media information in a network using<br>
	fewer network resources (including transmission bandwidth) than<br>
15	conventional systems, while simultaneously providing an equal or greater<br>
	array of multimedia services to customers.<br>
		It is another object of the present invention to provide a system and<br>
	method which allows a user at one terminal to control the display of<br>
	multimedia information based on an identity of a party at another terminal.<br>
20	It is an object of the present invention to provide a system and method<br>
	which manages the communication of media information in a network based<br>
	on prior knowledge and experience callers have with one another, and more<br>
	specifically to use this prior knowledge and experience as a basis for<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
5<br>
	reducing transmission bandwidth in providing multimedia services within a<br>
	network without sacrificing the quality of those services.<br>
		The foregoing and other objects of the invention are achieved by<br>
	providing, in one respect, a highly compressed pseudo-video system which<br>
5	manages the transmission and display of media information in an integrated<br>
	services network using fewer network resources than conventional systems.<br>
	The network may be a wireless network or the Internet, and the media<br>
	information may include real-time video streams, short-time video scripts,<br>
	images (e.g., snapshots), live animations, and still animations.<br>
10 		In accordance with one embodiment, the invention reduces<br>
	transmission bandwidth by having animation, image, and/or short-time video<br>
	script information pre-stored in memories located within or attached to the<br>
	communicating terminals, instead of transmitting this media information over<br>
	the network, the receiving terminal may therefore automatically retrieve and<br>
15	display the pre-stored media information in response to receiving a call from<br>
	another user or other events that may transpire during a call.<br>
		In accordance with another embodiment, the invention reduces<br>
	transmission bandwidth by combining and transmitting high-bandwidth media<br>
	such as streaming video and short-time video scripts to a receiving terminal,<br>
20	and then coordinating the display of that high-bandwidth media with lower-<br>
	bandwidth media. Since the lower-bandwidth media is pre-stored in the<br>
	receiving terminal, no transmission bandwidth is expended in order to be<br>
	display the lower-bandwidth media on the receiving terminal.<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
6<br>
		The present invention also allows for a shifting in the<br>
	telecommunication paradigm. In conventional systems, every communication<br>
	link relies on the following assumption: communications links are established<br>
	is independently from prior knowledge and experience of the communicating<br>
5	parties. Conventional systems, thus, strictly allocate network resources<br>
	based on communication protocols. The abstractions, imaginations, and<br>
	emotions of callers are never taken into consideration<br>
		The present invention takes the abstractions, imaginations, and<br>
	emotions of the callers as well as their past knowledge and experience with<br>
10	one another into consideration when managing the communication and<br>
	display of media information on user terminals. For example, using prior<br>
	knowledge and experience, the communicating parties can control the <br>
	amount of information they want to transmit based on how much they are<br>
	wiling to pay for various communication services.<br>
15 		Additional advantages, objects, and features of the invention will be<br>
	set forth in part in the description which follows and in part will become<br>
	apparent to those having ordinary skill in the art upon examination of the<br>
	following or may be learned from practice of the invention. The objects and<br>
	advantages of the invention may be realized and attained as particularly<br>
20	pointed out in the appended claims.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
7<br>
	BRIEF DESCRIPTION OF THE DRAWINGS<br>
		The invention will be described in detail with reference to the following<br>
	drawings in which like reference numerals refer to like elements wherein:<br>
		Fig. 1 is a diagram showing an example of a communications system<br>
5	in which the present invention may be implemented.<br>
		Fig. 2 is a diagram showing a mobile terminal which may be<br>
	configured to operate in accordance with the present invention.<br>
		Fig. 3 is a diagram showing an example of a control circuit which may<br>
	be used to display media information on a wireless terminal configured in<br>
10	accordance with the present invention.<br>
		Fig. 4 is a flow diagram showing steps included in a method for<br>
	controlling communication of media information in accordance with a first<br>
	embodiment of the present invention<br>
		Fig. 5 is a timing diagram showing an example of how the<br>
15	combined/multiplexed media information may be transmitted in accordance<br>
	with the present invention<br>
		Fig. 6 is a flow diagram showing steps included in a method of the<br>
	present invention for controlling the manner in which media information is<br>
	displayed based on the person who sent the information.<br>
20 		Fig. 7 is timing diagram showing how an optional step of the method of<br>
	the present invention may be performed.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
8<br>
		Fig. 8 is a diagram showing an example of a table entry which may be<br>
	stored in a memory of a receiving terminal for controlling the display of media<br>
	information in accordance with the present invention.<br>
		Fig. 9 is a diagram showing how the display of media information may<br>
5	be controlled on two terminals that communicate in accordance with the<br>
	present invention.<br>
	MODES FOR CARRYING OUT THE PREFERRED EMBODIMENTS<br>
		The present invention is a system and method for controlling<br>
10	communication of media information between two terminals in a network. In<br>
	one respect, the invention controls the manner in which different types of<br>
	media information are multiplexed and transmitted between the terminals. In<br>
	another respect, the invention controls the manner in which media<br>
	information is displayed or otherwise output on the terminals. This control<br>
15	may be performed based on past experience/knowledge one user may have<br>
	about the other, or based on a service option selected by one or both of the<br>
	users. The invention thus may be customized to meet the specific desires of<br>
	each user. Advantageously, the invention may also be implemented to<br>
	reduce network resources (Including the transmission bandwidth) that<br>
20	conventional methods would require in order to send media information<br>
	between terminals.<br>
		Fig. 1 shows an example of a communications system in which the<br>
	present invention may be implemented. The communications system<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
9<br>
	includes a network 1 for receiving and transmitting calls within a<br>
	predetermined geographic area. The network may be a wired or wireless<br>
	network operating in accordance with any one of a variety of communications<br>
	standards. To maximize customer subscriptions, a wired-version of the<br>
5	network may be implemented as a wide-area such as the internet. Preferably,<br>
	the network is integrated to include a plurality of access points or gateways 2<br>
	for connecting terminals through different networks. These terminals include<br>
	mobile terminals 3 such as mobile telephones, so-called web phones,<br>
	personal digital assistants (PDAs), and pocket computers to name a few. The<br>
10	network may also connect desktop or notebook personal computers 4 either<br>
	to each other or to the mobile terminals. Wireless content providers 5 and/or<br>
	network content providers 6 may be included as desired.<br>
		Fig. 2 shows a mobile terminal 10 which may be configured to operate<br>
	in accordance with the present invention. This terminal includes a speaker 11,<br>
15	a microphone 12, a keypad 13, and a display 14 for displaying media<br>
	information which has either been pre-stored in a memory of the terminal or<br>
	transmitted to the terminal through antenna 15, or both. The mobile terminal<br>
	also includes as an optional feature a camera 16 which has the ability of<br>
	capturing still images and/or acquiring real-time streaming video in a manner<br>
20	similar to a video phone or video-conferencing terminal. An external data port<br>
	17 such as a USB port may also be included for receiving and/or<br>
	downloading information including media information from another system 18<br>
	such as a personal computer. While the mobile terminal shown in Fig. 2 is<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
10<br>
	preferable for use with the present invention, those skilled in the art can<br>
	appreciate that other type of terminals may be used provided they have the<br>
	ability to output media information in a manner which will now be described.<br>
		Fig. 3 shows an example of a control circuit which may be used to<br>
5	display media information on a wireless terminal configured in accordance<br>
	with the present invention. This control circuit includes a processor 20<br>
	connected to the antenna (not shown), an optional caller ID unit 21, a<br>
	memory 22, a keyboard 23, a camera 24, and a data port 25. The caller ID<br>
	unit extracts identification information from a call indicating an identity of a<br>
10	caller. This information may include the caller's telephone number, name,<br>
	address, etc.<br>
		The memory may include an area for storing media information which<br>
	may either be displayed on the terminal itself or transmitted for display on<br>
	another terminal. The media information may be pre-stored In the terminal<br>
15	memory or received from another terminal for display. To control the display<br>
	of media information, the memory may include an on-board personal<br>
	information management (PIM) database. This database may operate based<br>
	on information derived from the caller ID unit, control information Input by a<br>
	user, information downloaded to the terminal from an external computing<br>
20	system, or any combination thereof. If desired, the P1M database may be<br>
	located in a personal computer or other external computing device which<br>
	interfaces to the terminal through the data port. The data port may also be<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
11<br>
	used to load media information into the memory of the terminal for<br>
	subsequent transmission or display.<br>
		The processor of the terminal may also be used to combine, or<br>
	multiplex, media data for transmission through its antenna. This media<br>
5	information may be stored in the on board memory, imported from the<br>
	external computing system, or both.<br>
		Prior to receiving a call, a user may set the parameters of operating<br>
	software 26 in the processor for controlling, inter alia, the manner media<br>
	information is to be displayed on the terminal. The user may also designate<br>
10	one or more media service options he or she would like to receive. These<br>
	options may control the type of media information to be received in order to<br>
	reduce service charges or, if cost is not an issue, enhance terminal operation<br>
	to receive and display broadband media. Service options may be negotiated<br>
	with the carrier directly or set by inputting information using the keyboard<br>
15	terminal.<br>
		When a call connection is established, the processor displays media<br>
	information based, for example, on the control parameters and/or service<br>
	options designated by the user. This media information may be stored in<br>
	memory 22, received from a transmitting terminal on display 28, or both. The<br>
20	manner in which media information is communicated between terminals for<br>
	display will now be discussed.<br>
		Fig. 4 is a flow diagram showing steps included in a method for<br>
	controlling communication of media information in accordance with a first<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
12<br>
	embodiment of the present invention. This embodiment combines, or<br>
	multiplexes, different types of media information in one terminal for<br>
	transmission to a receiving terminal within a same transmission period. The<br>
	method begins when the transmitting terminal initiates a call with the<br>
5	receiving terminal. (Block 30). As previously discussed, the call may be<br>
	initiated through a wireless network, the internet, or any other type of wired<br>
	network.<br>
		Once a call connection is established, the transmitting terminal<br>
	combines, or multiplexes, first media information and second media<br>
10	information in an output transmission stream. (Block 31). This media<br>
	information may be selected by a user, for example, through operation of a<br>
	terminal keypad in conjunction with a displayed menu. The media information<br>
	may take any one of a variety of forms, including the following:<br>
• streaming video (either pre-stored or real-time)<br>
15 	• short-time video script (e.g., a MPEG file)<br>
 • image (e.g., a JPEG file)<br>
• still animation (e.g., a graphical interchange format - GIF)<br>
• live animation (e.g., a moving GIF)<br>
		The types of media information listed above may be combined, or<br>
20	multiplexed, in any order, or this information may be combined based on the<br>
	transmitting terminal user's knowledge of media information that is pre-stored<br>
	in the receiving terminal. These features of the invention will be described in<br>
	greater detail below.<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
15<br>
	the invention is particularly desirable for purposes of customizing operation of<br>
	the terminal to each specific user.<br>
		While the invention has been described as storing media information<br>
	in a terminal memory, those skilled in the art can appreciate that the terminal<br>
5	may also be Interfaced to an external memory which stores and retrieves<br>
	media information in accordance with the present invention.<br>
		In accordance with another embodiment, the method of the present<br>
	invention controls the manner in which media information is displayed based<br>
	on the person who sent the information, Referring to Fig. 6, this method<br>
10	begins by receiving a call in a first terminal. (Block 40). Once a call<br>
	connection has been established, a second step of the method includes<br>
	extracting and processing caller identification information in the receiving<br>
	terminal to determine the identity of the transmitting terminal and therefore of<br>
	a user who likely placed the call. (Block 41). The extracted information may<br>
15	include any one or more of the telephone number of the second terminal, the<br>
	name of the owner of the terminal, his or her address, etc. If the terminal is<br>
	connected to the internet, this caller ID information may be comparable<br>
	information such as a website address.<br>
		A third step includes comparing the caller ID information (e.g., caller's<br>
20	telephone number) with information stored in a memory of the first terminal.<br>
	(Block 42). The stored information may include media information which<br>
	has been pre-stored in association with the telephone number of the<br>
	transmitting terminal. The media Information may be any of the types<br><br>
WO 2004/030381	PCT/KR2003/001893<br>
16<br>
	previously mentioned, and may even correspond to a characteristic of a user<br>
	of the transmitting terminal. Alternatively, the media information may be<br>
	transmitted to the receiving terminal and stored in memory in association with<br>
	the transmitting terminal's caller ID information for later retrieval.<br>
5 		In accordance with one particularly advantageous feature of the<br>
	invention, the pre-stored media information may be an avatar which is related<br>
	to a characteristic of the user of the transmitting terminal. In the graphics<br>
	world, an avatar is understood to be an animated icon, symbol, or character<br>
	which may be used, for example, to represent some characteristic or trait of a<br>
10	person. This characteristic may be a physical attribute of the person or may<br>
	relate to some non-physical feature. Examples of non-physical features<br>
	include a relationship one user may have with another and a user's<br>
	occupation. The avatar may also be based on one user's opinion of the other<br>
	formulated, for example, based on prior knowledge and experience.<br>
15 		A fourth step of the method includes outputting the stored media<br>
	information on the receiving terminal based on the identity of the transmitting<br>
	terminal. (Block 43). This involves retrieving the stored media information and<br>
	the displaying it for a predetermined period of time. If the media information is<br>
	a video script, for example, the script may be played until its conclusion.<br>
20	Alternatively, if the media information is an avatar, it may be displayed<br>
	intermittently or even constantly throughout the call.<br>
		In an optional but desirable step, an avatar representing a<br>
	characteristic of the user of the transmitting terminal is displayed before the<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
17<br>
	call is answered by a user of the receiving terminal. This may be<br>
	accomplished as follows.<br>
		When a call is received, an audible tone may sound to inform a user of<br>
	the receiving terminal of the incoming call. As previously discussed, the call<br>
5	may include information which identifies the transmitting party or his terminal,<br>
	for example, based on a telephone number or website address. When this<br>
	information received, a processor of the first terminal may search a memory<br>
	to locate an avatar which corresponds to the telephone number. This avatar<br>
	may then be automatically displayed (in lieu of, for example, the transmitting<br>
10	terminal's telephone number). The receiving terminal user may then instantly<br>
	recognize who the calling party is. For example, if the wife of a receiving<br>
	terminal user is calling, an avatar in the shape of a heart with her image may<br>
	be displayed. In another case, if an avatar indicative of an undesirable<br>
	person is displayed, the receiving terminal user has the option of not<br>
15	answering the call.<br>
		Another optional step is to allow the user to answer the call, but then<br>
	continue to display the avatar identifying the transmitting terminal user either<br>
	intermittently or continuously throughout the call. For example, if the only<br>
	media information to be displayed during the call is a heart-shaped avatar<br>
20	with her image, then this avatar may be displayed until conclusion of the call.<br>
	On the other hand, if streaming video or image information is to be displayed,<br>
	then the avatar may be replaced by this additional media information. If<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
17<br>
	call is answered by a user of the receiving terminal. This may be<br>
	accomplished as follows.<br>
		When a call is received, an audible tone may sound to inform a user of<br>
	the receiving terminal of the incoming call. As previously discussed, the call<br>
5	may include information which identifies the transmitting party or his terminal,<br>
	for example, based on a telephone number or website address. When this<br>
	information received, a processor of the first terminal may search a memory<br>
	to locate an avatar which corresponds to the telephone number. This avatar<br>
	may then be automatically displayed (in lieu of, for example, the transmitting<br>
10	terminal's telephone number). The receiving terminal user may then instantly<br>
	recognize who the calling party is. For example, if the wife of a receiving<br>
	terminal user is calling, an avatar in the shape of a heart with her image may<br>
	be displayed. In another case, if an avatar indicative of an undesirable<br>
	person is displayed, the receiving terminal user has the option of not<br>
15	answering the call.<br>
		Another optional step is to allow the user to answer the call, but then<br>
	continue to display the avatar identifying the transmitting terminal user either<br>
	intermittently or continuously throughout the call. For example, if the only<br>
	media information to be displayed during the call is a heart-shaped avatar<br>
20	with her image, then this avatar may be displayed until conclusion of the call.<br>
	On the other hand, if streaming video or image information is to be displayed,<br>
	then the avatar may be replaced by this additional media Information. If<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
18<br>
	desired, the avatar may then be redisplayed after the additional media<br>
	information concludes to provide continuous visual communication effects.<br>
		Fig. 7 is a timing diagram showing how this optional step of the<br>
	invention may be performed. In this timing diagram, the receiving terminal<br>
5	receives 20 seconds of video streaming data. After this data concludes, an<br>
	avatar representing a characteristic of the transmitting terminal user may be<br>
	displayed. As previously discussed, this avatar may be pre-stored in a<br>
	memory of the receiving terminal, or it may have been transmitted from the<br>
	 transmitting terminal and then stored in the receiving terminal memory for<br>
10	subsequent display. Whenever the receiving terminal displays the stored<br>
	avatar image, it is not necessary to allocate communication resources.<br>
		Fig. 8 shows an example of a table entry which may be stored in a<br>
	memory of the receiving terminal for controlling the display of media<br>
	information in accordance with the present invention. This table entry may be15 a data 	structure derived from a personal information management (PIM)<br>
	database located within or interfaced to the receiving terminal. The data<br>
	structure preferably includes a user identification field 50 and media<br>
	information identification field 60. The user identification field may include<br>
	information identifying a user (and/or his terminal) who either has called or<br>
20	may be expected to call the receiving terminal. The information includes the<br>
	name of a transmitting terminal user, his or her telephone number, and the<br>
	type of terminal (e.g., mobile phone, home phone, or office phone)<br>
	corresponding to the telephone number. If the user has an internet phone,<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
19<br>
	the phone number field may be replaced by a website address, otherwise<br>
	known as a Universal Resource Locator (URL).<br>
		The media information identification field is stored in association with<br>
	the user identification information and may include, for example, an address<br>
5	in either the same or an external memory in which the media information is<br>
	stored. This situation may arise, for example, when the media information is<br>
	an image file or video clip. Alternatively, or additionally, the media information<br>
	identification field may contain information defining one or more attributes of<br>
	an avatar which corresponds to the transmitting terminal user. If the avatar<br>
10	resembles a physical likeness of this user, the following sub-fields may be<br>
	included: hair style, face model, eye glasses, body, jacket, pants, shoes,<br>
	accessories, etc. A processor of the receiving terminal may use graphics<br>
	generation software to generate the avatar for display based on the<br>
	information in these fields.<br>
15 		The media information identification field may also include an animator<br>
	indicator sub-field (AIF) which includes a plurality of bits describing the avatar.<br>
	For example, a two-bit AIF field may indicate the following:<br>
0 0 - No avatar exists for the particular telephone number<br>
0 1 - Composite avatar<br>
20 10 - Composite avatar with gestures and body movement<br>
	11 - Non-composite avatar which can be accessed by the<br>
	special address field.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
20<br>
	In operation, the receiving terminal processor may access the AIF field and<br>
	generate the avatar accordingly.<br>
		The media information identification field may also include a code for<br>
	instructing the receiving terminal processor to activate audio (e.g., a bell) or<br>
5	other visual effects. Currently existing mobile terminals typically have more<br>
	than 1 megabits of memory space which can be used to store this code along<br>
	with a plurality of table entries for controlling the display of media information<br>
	on the receiving terminal.<br>
		The table entries of the present invention may be updated, modified,<br>
10	or otherwise maintained by connecting the receiving terminal to an external<br>
	computing system (e.g., a personal computer) via a data port, which, for<br>
	example, may be a universal serial bus (USB) port. This external system<br>
	may be loaded with software which allows it to generate custom-designed<br>
	avatars for each transmitting terminal user identified in the table. The avatars<br>
15	may be two- or three-dimensional representations of these users, if desired.<br>
		The memory storing the table entries of the present invention may also<br>
	store a plurality of default or factory-preset avatars which may be selected to<br>
	correspond to different users. The operating software of the receiving<br>
	terminal may be written to allow these avatars to be switched, modified, or<br>
20	deleted either automatically or in response to a receiving terminal user's<br>
	command. Avatars may be switched for display based on the telephone<br>
	number from which the transmitting terminal user is calling. For example, as<br>
	shown in Fig. 8, one user may have multiple telephone numbers. In this case,<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
21<br>
	a different avatar may be displayed based on the telephone number from<br>
	which the user is calling.<br>
		Fig. 9 shows one way in which communications may take place<br>
	between two mobile terminals 70 and 80 in accordance with the present<br>
5	invention. In this figure, terminal 70 initiated a call to terminal 80 through a<br>
	wireless network 90. When the terminal 80 receives the call, its processor<br>
	determines the identity of caller and then displays an avatar 85 in the shape<br>
	of a man which bears the likeness of caller who's name is Christopher. This<br>
	avater may have been transmitted to terminal 80 through the network or may<br>
10	have been created by the receiving terminal user based on his/her<br>
	experience and knowledge about the caller and pre-stored in a memory of<br>
	this terminal.<br>
		Terminal 70 also displays an avatar 75, representing his/her own<br>
	desired avatar image. This avatar may be created by the transmitter terminal<br>
15	user to portray him/herself. It may display in his/her terminal as a default<br>
	image when the terminal is on or may be transmitted over the network to the<br>
	receiver terminal as one of optional visual communication. In the example<br>
	shown, avatar 75 corresponds to a panda bear which affectionately was<br>
	selected to correspond to caller, Christophers desired representative image.<br>
20	At the receiver terminal, the avatar 85 corresponding to caller Christopher<br>
	may not be the same avatar 75 of the caller display. If desired, avatars 75<br>
	and 85 may be displayed throughout the call session.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
22<br>
		To make the conversation more animated, one terminal transmit a<br>
	control signal to the other terminal during the call to change an attribute of an<br>
	avatar, or to replace the avatar displayed on the receiving terminal with one<br>
	either transmitted from the transmitting terminal or pre-stored in the receiving<br>
5	terminal. A control signal of this type may, for example, cause the avatar on<br>
	the receiving terminal to display an emotion (crying, laughing, etc.) to<br>
	coincide with a mood or feeling of the transmitting terminal user. This may be<br>
	implemented, for example, by including a mood sub-field in the table entry of<br>
	Fig. 8. This sub-field may be a two-bit field for controlling the emotion on the<br>
10	face of the avatar. Updating this field will cause the processor to<br>
	automatically change the avatar in a corresponding manner.<br>
		As previously discussed, the table in a terminal memory may include<br>
	multiple entries for the same user. This may occur, for example, when the<br>
	user has multiple phone numbers. In this case, the same avatar may be<br>
15	displayed for all phone numbers corresponding to that user or different<br>
	avatars may be displayed, for example, depending on the number where the<br>
	user is calling from. Also, the receiving terminal may be equipped with image-<br>
	capture software that will allow a single frame (or image) from a received<br>
	video stream to be stored and subsequently displayed.<br>
20 The present invention outperforms conventional media<br>
	communications management systems in terms of performance and<br>
	convenience to the user. For example, the invention controls the<br>
	communication of media information between terminals using fewer network<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
23<br>
	resources than are conventionally required. These resources (which include<br>
	transmission bandwidth) are reduced by allowing a memory of the receiving<br>
	terminal to store media information that conventional systems must<br>
	necessarily transmit over the network. This memory may be located within<br>
5	the receiver or externally connected to it.<br>
		The present invention allows users to control the types of media<br>
	services that they would like to receive, thereby allowing the users to control<br>
	costs and the extent of media services to be received.<br>
		The present invention also allows users to combine, or multiplex,<br>
10	different types of media information having different transmission bandwidth<br>
	requirements within a single transmission period, thereby enhancing the<br>
	content of conversations between users for both personal and business<br>
	applications.<br>
With the foregoing in mind, the present invention may be used to<br>
15	implement at least the following communications scenarios.<br>
Visual Message Initiator (Transmitter) with Real-Time,<br>
Two-Way Video Stream Phone Capability Including Voice Conversation<br>
		Despite of the fact that many terminals today including mobile<br>
	terminals have the capability to display streaming video, many customers<br>
20	may not want to pay high rates carriers charge for these and other<br>
	broadband services. The present invention takes this into consideration by<br>
	giving users the option to control which media services they would like to<br>
	receive. For example, during a call set-up process, a user of the transmitting<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
24<br>
	terminal may negotiate options for a video stream service with the network.<br>
	This negotiation process may be performed using an intended visual<br>
	message transmitter. An appropriate service may then be selected from<br>
	various service options.<br>
5 		Exemplary service options include:<br>
a) full-bandwidth streaming video service (e.g., MPEG format)<br>
b) short-time streaming video service (e.g., MPEG format)<br>
c) Images<br>
d) Still animation<br>
10 	e) Live Animation<br>
		If full-bandwidth streaming video is selected, the transmitting terminal<br>
	may transmit continuous video output from the camera unit in the terminal.<br>
	This may continue until for the duration of the call or until the user switches<br>
	this function off.<br>
15 		If the short-time streaming video service is selected, the transmitting<br>
	terminal may transmit a short-time streaming video script for a predetermined<br>
	time period (e.g., 20 seconds) over a network. The receiving terminal may<br>
	capture and then display the video, and in the meantime may store the script<br>
	in an internal memory or external memory. A user of the receiving terminal<br>
20	may display this script repeatedly from an internal memory without requiring<br>
	any additional allocation of network resources. In addition, the video script<br>
	may be refreshed periodically during the call, for example, every 2 minutes.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
25<br>
		If the user selects the option for receiving images, images may be<br>
	transmitted to the receiving terminal once every predetermined time period<br>
	(e.g., every two minutes).<br>
		If the user selects the option for receiving animation, animated<br>
	 5 information such as, for example, an icon may be transmitted to the receiving<br>
	terminal, for example, in the manner shown in the timing diagrams of Figs. 5<br>
	or 7. As previously discussed, this icon may be an avatar created, for<br>
	example, by the transmitting party in the form of a character, symbol, or other<br>
	graphical representation of him or herself. The avatar may be created by<br>
10	software stored inside the transmitting terminal, or may be downloaded from<br>
	external software tools allowing the user to create his own avatar. Those<br>
	skilled in the art can appreciate that a physical resemblance is not necessary,<br>
	as the avatar may correspond to any desired graphic of the transmitting<br>
	user's choosing. A system capable of generating an avatar of this type is<br>
15	disclosed in U.S. Patent 6,384,829, the contents of which are incorporated<br>
	herein by reference.<br>
		In addition to still avatars, the animated information transmitted in<br>
	accordance with the present invention may be live animation or a moving<br>
	avatar, one type of which is known as an animated GIF. When the avatar<br>
20	resembles a character of some sort, its movement may cause the avatar to<br>
	appear to be speaking, moving forward and backward, laughing, crying, eyes<br>
	closing and opening, hand pointing, and etc. While in this example the<br>
	transmitting party is identified as creating and transmitting the avatar to the<br><br>
WO 2004/030381 	PCTYKR2003/001893<br>
26<br>
	receiving party, those skilled in the art can appreciate that the avatar may be<br>
	stored in and subsequently displayed on the receiving terminal. In this case,<br>
	the avatar may be automatically displayed based on recognition of caller ID<br>
	information by the receiving terminal, displayed in response to a control<br>
5	signal transmitted from the transmitting terminal to the receiving terminal,<br>
	displayed based on control information input by the receiving party himself, or<br>
	at any other time during the call session.<br>
		When displayed in response to a control signal from the transmitting<br>
	terminal, the control signal may cause different avatars to be displayed on<br>
10	the receiving terminal, for example, to commemorate an event (e.g., a happy<br>
	birthday GIF) or to resemble an emotion or mood the transmitting party is<br>
	feeling (e.g., a GIF resembling the transmitting part with a happy face).<br>
		When displayed based on control information input the user, the<br>
	avatar sent by the transmitting user may be ignored and replaced with an<br>
15	avatar of the receiving user's choosing. For example, if the receiving terminal<br>
	user does not like the transmitting terminal user, the receiving terminal may,<br>
	based on previously stored settings, cause an avatar of a dog to be displayed<br>
	in response to the detection of caller ID information. If desired, this avatar<br>
	may be displayed even when the transmitting party transmits no avatar to the<br>
20	receiving terminal.<br>
		If no media service is selected, no media information may be<br>
	displayed. In this case, no extra bandwidth is allocated for visual<br>
	communications between the transmitting and receiving terminals. All these<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
27<br>
	options include a simultaneous and continuous two-way voice conversation.<br>
	At the receiving terminal, a default avatar stored in the receiving terminal or a<br>
	avatar which corresponds to the caller id may be displayed.<br>
		In this exemplary embodiment of the invention, the transmitting<br>
5	terminal user (or call initiator) may select one of the aforementioned service<br>
	options or any combination of these options to control the display of media<br>
	information during a call session. This selection may be based on his or her<br>
	desire and willingness to pay for the service desired. Generally speaking, the<br>
	higher the bandwidth requirement, the more expensive the service option.<br>
10	Thus, live streaming video may be expected to be the most expensive and<br>
	still animation the least expensive.<br>
		Fig. 7, which has been previously discussed, shows an exemplary<br>
	scenario. To reiterate, in this scenario the call initiator sends a 20-second<br>
	short-time stream video every 2 minutes. During the first 2- minute period,<br>
	is the call initiator sends his avatar just one time if the receiving party indicates<br>
	that he want to receive the call initiator's avatar or if the transmitting party is<br>
	not sure whether the receiving terminal user has the call initiator's avatar<br>
	stored in a memory of the receiving terminal.<br>
		After the receiving terminal receives the transmitted avatar, the<br>
20	receiving terminal may store the avatar in a receiver-accessible memory,<br>
	which may be internal or external memory. The receiving terminal can then<br>
	subsequently display the avatar at the user's discretion.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
28<br>
		In another scenario, the call initiator does not transmit any media<br>
	information. In this case, the receiving terminal user may display an avatar<br>
	created and/or selected by this user to represent the caller. This avatar may<br>
	be stored in the receiving terminal's memory and re-called as previously<br>
5	discussed. Because the avatar was pre-stored in the receiver terminal, no<br>
	extra bandwidth allocation is required to display this avatar and thus network<br>
	resources are conserved.<br>
Real-Time, Two-Way Video Stream Phone Communications<br>
Including Voice Conversation for the Call Receiver<br>
10 		During a call set-up process, the network may indicate that there is a<br>
	particular service option request from the call initiator. The service options<br>
	at the receiver side can be same as for the transmitter side. Alternatively, one<br>
	of the terminals may have a different service option setting than the other, to<br>
	reflect that user's preference for either cost savings or enhanced media<br>
15	services. In this example, the service options are the same as in the first<br>
	example.<br>
		At the receiver, the service option request sent from the transmitting<br>
	terminal is checked against the receiver's parameter settings. These settings<br>
	may indicate the current software and hardware versions of the receiving<br>
20	terminal, and the willingness of a receiving terminal user to share the cost<br>
	of communicating or receiving media services indicated in the service option<br>
	request. If the requested services are acceptable to the receiving terminal<br>
	user, the transmitting terminal user (or call initiator) transmits the media<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
29<br>
	information to the receiving terminal in accordance with the service options<br>
	mentioned in the request.<br>
		For the avatar option, the receiving terminal does not need to receive<br>
	any information from the call initiator if the avatar of the call initiator has<br>
5	already been generated and stored in the receiver terminal's memory or PIM<br>
	database. In this case, the receiving terminal fetches and then displays the<br>
	particular avatar from the memory or PIM database based on the caller<br>
	initiator's phone number (Caller ID). This feature of the invention is<br>
	advantageous because it allows media information to be displayed on the<br>
10	receiver terminal without using any bandwidth resources of the network.<br>
		The system and method of the present invention may include a<br>
	number of additional features. For example, the invention may communicate<br>
	media information with voice communications (e.g., video teleconferencing,<br>
	video telephone applications, etc) or without voice communications (e.g.,<br>
15	real-time, instant messaging system, etc.). This may be accomplished, for<br>
	example, by transmitting voice signals over a circuit-switched logical channel<br>
	and the media information over one or more packet-switched logical<br>
	channels. Those skilled in the art can appreciate that other known methods<br>
	may also be used.<br>
20 		Other modifications and variations to the invention will be apparent to<br>
	those skilled in the art from the foregoing disclosure. Thus, while only certain<br>
	embodiments of the invention have been specifically described herein, it will<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
30<br>
	be apparent that numerous modifications may be made thereto without<br>
	departing from the spirit and scope of the invention.<br>
		The foregoing embodiments and advantages are merely exemplary<br>
	and are not to be construed as limiting the present invention. The present<br>
5	teaching can be readily applied to other types of apparatuses. The<br>
	description of the present invention is intended to be illustrative, and not to<br>
	limit the scope of the claims. Many alternatives, modifications, and<br>
	variations will be apparent to those skilled in the art. In the claims, means-<br>
	plus-function clauses are intended to cover the structures described herein<br>
10	as performing the recited function and not only structural equivalents but also<br>
	equivalent structures.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
31<br>
CLAIMS:<br>
		1. A method of reducing bandwidth in a communication network,<br>
	comprising:<br>
5 		sending a visual signal within a prescribed n-length transmission time<br>
	having at least one of:<br>
		a) a first video stream having a prescribed x-length<br>
	transmission time, wherein x is less than or equal to n,<br>
		b) a second video stream having a prescribed y-length<br>
10	transmission time, wherein y is less than x,<br>
		c) a still image, and<br>
		d) a virtual image;<br>
		receiving the video signal; and<br>
		displaying the received video signal during a prescribed m-length<br>
15	reception time in a prescribed display format, wherein the video signal is<br>
	transmitted through a wireless network.<br>
		2. The method of claim 1, wherein combination during the n-<br>
	length transmission time includes an idle state having none of a, b, c or d<br>
20	above within a remaining time period of the n-length transmission time.<br>
		3. The method of claim 2, wherein the idle state does not<br>
	allocate required communication resources during transmission.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
32<br>
		4. The method of claim 3, wherein a virtual image is displayed<br>
	at the receiver terminal during the idle state.<br>
5		 5. The method of claim 1, wherein the prescribed display format<br>
	includes a third video stream having a prescribed z-length time period..<br>
		6. The method of claim 5, wherein the third video stream is the<br>
	same as the second video stream if the video signal includes the second<br>
10	video stream.<br>
		7. The method of claim 5, wherein the third video stream is<br>
	different from the second video stream even though the video signal includes<br>
	the second video stream.<br>
15<br>
		8. The method of claim 7, wherein the third video stream is a<br>
	previously stored video stream.<br>
		9. The method of claim 1, wherein the received video signal is<br>
20	displayed by a mobile terminal.<br>
		10. The method of claim 1, wherein the first video stream is a full<br>
	bandwidth streaming video which is operating continuously.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
33<br>
		11. The method of claim 1, wherein the second video stream is a<br>
	short-time stream video.<br>
5 		12. The method of claim 1, wherein the snapshot of a virtual<br>
	image is an image of the calling party.<br>
		13. The method of claim 1, wherein the virtual image is an avatar.<br>
10 		14. The method of claim 8, wherein the avatar is an animated<br>
	avatar.<br>
15. 		A method of dynamically multiplexing different types of visual<br>
	information sent over a network, comprising:<br>
15 		establishing a call connection by a first mobile terminal of a calling<br>
	party;<br>
		multiplexing a plurality of first video signals provided by the first<br>
	mobile terminal during a call connection, wherein the first video signals<br>
	include an idle state, a first video stream, a first still image, and a first<br>
20	graphical representation/depiction; and<br>
		transmitting the multiplexed first video signals.<br>
		16. The method of claim 15, the network transmits a signal<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
34<br>
	indicative of the multiplex video signal to a second mobile terminal of the<br>
	called party, and the second mobile terminal display a video image based on<br>
	multiplexed second video signals.<br>
5 		17. The method of claim 16, wherein the multiplex second video<br>
	signals comprises at least one of a second video stream, a second still<br>
	image, and a second graphical representation/depiction.<br>
		18. The method of claim 17, wherein the first and second video<br>
10	streams are different.<br>
		19. The method of claim 17, wherein the first and second stil<br>
	images are different.<br>
15 		20. The method of claim 17, wherein the first and second<br>
	graphical representation/depiction are different.<br>
		21. The method of 20, wherein the second graphical<br>
	representation/depiction is stored in a memory of the second mobile terminal.<br>
20<br>
		22. The method of claim 21, wherein the second graphical<br>
	representation/depiction is based on called party=s past experience with the<br>
	calling party.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
35<br>
		23. The method of claim 21, wherein the second graphical<br>
	representation/depiction is replaced by . the first graphical<br>
	representation/depiction of the calling party.<br>
5<br>
		24. The method of claim 22, wherein the second graphical<br>
	representation/depiction elicit an image likeness and look and feel of the<br>
	calling party to the called party.<br>
10 		25. The method of claim 17, wherein the second video stream<br>
	includes an idle video state.<br>
		26. The method of claim 25, wherein in an idle video state, the<br>
	receiver terminal displays the second graphical representation.<br>
15<br>
		27. A method of imprinting/eliciting an image/likeness/look and<br>
	feel of the caller to a called party, comprising:<br>
		sending caller related information from a mobile terminal for visual<br>
	display in a first prescribed format; and<br>
20 		displaying on a display of the called party the caller related<br>
	information in a second prescribed display format, wherein the first<br>
	prescribed display format is different from the second prescribed display<br>
	format.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
36<br>
		28. The method of claim 27, wherein the display is a display of a<br>
	mobile terminal.<br>
5 		29. A method for communicating information, comprising:<br>
		initiating a call between a first terminal and a second terminal;<br>
		multiplexing first media information and second media information in<br>
	the first terminal; and<br>
		transmitting the multiplexed information with voice information from<br>
10	the first terminal to the second terminal.<br>
		30. The method of claim 29, wherein the first media information<br>
	and the second media information are selected from the group consisting of a<br>
	video stream, a short-time video script, a still image, moving animation, and<br>
15	still animation.<br>
		31. The method of claim 30, wherein said video stream includes<br>
	real-time streaming video.<br>
20 		32. The method of claim 29, wherein the first media information<br>
	is a video stream and the second media information is still animation.<br>
		33. The method of claim 29, wherein the multiplexed information<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
37<br>
	is transmitted during a first call period, and wherein different multiplexed<br>
	information is transmitted during a second call period.<br>
		34. The method of claim 29, further comprising:<br>
5 		controlling output of the multiplexed media information on the second<br>
	terminal, said controlling step including blocking output of one of the first<br>
	media information and the second media information.<br>
		35. The method of claim 34, further comprising:<br>
10 		controlling output of the multiplexed media information on the second<br>
	terminal, said controlling step including setting a service option of the second<br>
	terminal which controls types of media information to be output on the<br>
	second terminal.<br>
15		36. The method of claim 29, further comprising:<br>
		controlling output of the multiplexed media information on the second<br>
	terminal, said controlling step including replacing the first media information<br>
	with third media information stored in a memory of the second terminal.<br>
20 		37. The method of claim 36, wherein the first media information<br>
	and the third media information include different avatars.<br>
		38. A method for managing communications over a network,<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
38<br>
comprising:<br>
		receiving a call in a first terminal;<br>
		dentifying a second terminal from which the call was placed; and<br>
		retrieving media information from a memory of the first terminal<br>
5	based on the identity of the second terminal.<br>
		39. The method of claim 38, wherein the network includes a<br>
	wireless network.<br>
10		 40. The method of claim 38, wherein the network includes a wide<br>
	area network.<br>
		41. The method of claim 40, wherein the wide area network is<br>
	the Internet.<br>
15<br>
		42. The method of claim 38, wherein at least one of the first<br>
	terminal and the second terminal is a mobile terminal.<br>
		43. The method of claim 38, wherein at least one of the first<br>
20	terminal and the second terminal is equipped for communications over a wide<br>
	area network.<br>
		44. The method of claim 43, wherein the wide area network is<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
39<br>
the Internet.<br>
		45. The method of claim 38, further comprising:<br>
		storing information indicative of a telephone number of the second<br>
5	terminal in association with said media information.<br>
		46. The method of claim 45, wherein the identifying step<br>
	includes:<br>
		extracting information identifying the telephone number of the second<br>
10	terminal from said call; and<br>
		retrieving said media information from memory based on the<br>
	extracted telephone number information.<br>
		47. The method of claim 38, wherein the media information<br>
15	includes video information.<br>
		48. The method of claim 38, wherein the media information<br>
	includes image information.<br>
20 		49. The method of claim 38, wherein the media information<br>
	includes an avatar.<br>
		50. The method of claim 49, wherein the avatar resembles a<br><br>
WO 2004/030381 	PCTVKR2003/001893<br>
40<br>
characteristic of a caller using the second terminal.<br>
		51. The method of claim 38, wherein said memory stores a<br>
	plurality of avatars.<br>
5<br>
		52. The method of claim 51, further comprising:<br>
		receiving a control signal from the first terminal which selects one of<br>
	the avatars stored in said memory, wherein said retrieved media information<br>
	includes the selected avatar.<br>
10<br>
		53. The method of claim 51, wherein each of the stored avatars<br>
	exhibit a different emotion of the caller using the second terminal.<br>
		54. A method for managing communications over a network,<br>
15	comprising:<br>
		receiving a call in a first terminal;<br>
		identifying a second terminal from which the call was placed; and<br>
		outputting media information on the first terminal based on the<br>
	identity of the second terminal.<br>
20<br>
		55. The method of claim 54, wherein said outputting step<br>
	includes:<br>
		retrieving the media information from a memory of the second<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
41<br>
	terminal, said memory storing the media information in association with<br>
	information identifying the second terminal.<br>
		56. The method of claim 54, further comprising:<br>
5 		receiving first media information from the first terminal;<br>
	blocking output of the first media information; and<br>
		outputting second media information stored in a memory of the<br>
	second terminal in place of the first media information.<br>
10 		57. The method of claim 54, wherein the media information<br>
	includes a avatar.<br>
		58. The method of claim 56, wherein the first media information<br>
	is a first avatar and the second media information is a second avatar.<br>
15<br>
		59. The method of claim 58, wherein the second avatar is<br>
	selected or generated based on past knowledge of a user of the second<br>
	terminal.<br>
20 		60. The method of claim 58, wherein the second avatar includes<br>
	a characteristic which reflects a relationship or opinion a user of the second<br>
	terminal has concerning a user of the first terminal.<br><br>
WO 2004/030381 	PCT/KR2003/001893<br>
42<br>
		61. The method of claim 54, further comprising:<br>
		selecting a service option to control type of media information to be<br>
	output on the first terminal.<br>
5 		62. The method of claim 54, wherein the selecting step includes:<br>
	selecting a service option which displays low-bandwidth media<br>
	information and blocks display of high-bandwidth media information on the<br>
	first terminal.<br>
10<br><br>
A system and method for managing communication in an integrated services network ensures that media information<br>
is displayed on at least one of two terminals during a call without using any transmission bandwidth. This is achieved by haying<br>
at least one of the terminals pre-store the media information in a memory and then controlling the terminal to recall and display<br>
this information when certain events occur during the call. The media information may include animated information, images, and<br>
short-time video scripts. This information and broader band media such as streaming video may be displayed on the same terminal.<br>
The display of media information may also be controlled based on the past knowledge and experience callers have about one another<br>
and/or their communications equipment.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA2NjEta29sbnAtMjAwNS1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">00661-kolnp-2005-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjYxLUtPTE5QLTIwMDUtRk9STS0yNy5wZGY=" target="_blank" style="word-wrap:break-word;">661-KOLNP-2005-FORM-27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMDA2NjEta29sbnAtMjAwNS5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-00661-kolnp-2005.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="235017-a-method-of-configuring-a-lens-surface-and-a-lens-cone-gured-and-produced-by-the-method.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="235019-fluid-ejection-device-and-method-of-manufacturing-a-fluid-ejection-device.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>235018</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>661/KOLNP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>26/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>26-Jun-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>24-Jun-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>18-Apr-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>LG ELECTRONICS, INC.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>20, YOIDO-DONG, YOUNGDUNGPO-GU, SEOUL</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>YI BYUNG-KWAN</td>
											<td>JORDAN LIDGE COURT, SAN DIEGO 12772, CA 92130</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04Q 7/20</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2003/001893</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2003-09-16</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10/252,412</td>
									<td>2002-09-24</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/235018-a-method-of-reducing-bandwidth-by-selectively-sending-media-information-over-a-communications-network by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 14:33:57 GMT -->
</html>
