<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/221061-apparatus-for-processing-an-image-and-a-method-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:03:29 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 221061:APPARATUS FOR PROCESSING AN IMAGE AND A METHOD THEREOF</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">APPARATUS FOR PROCESSING AN IMAGE AND A METHOD THEREOF</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>An adaptive filter according to one embodiment includes an NN two-dimensional convolution, where N is an odd integer greater than one. Pixels of an image are filtered by moving the NN kernel across the image. At each pixel location, the kernel coefficients are determined by the image pixels within the NN region, such that the kernel coefficients may change from one pixel to the next. Such a filter may be implemented to use a lookup table to approximate a floating-point operation.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970) &amp;<br>
THE PATENTS RULES, 2003 COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
"ADAPTIVE FILTERS AND APPARATUS, METHODS, AND SYSTEMS<br>
FOR IMAGE PROCESSING"<br>
QUALCOMM INCORPORATED,<br>
an American company of 5775 Morehouse Drive , San Diego, California 92121-1714, United States of America<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br>
WO 2006/028559<br><br>
PCT/US2005/022838<br><br>
ADAPTIVE FILTERS AND APPARATUS, METHODS, AND<br>
SYSTEMS FOR IMAGE PROCESSING<br>
[0001]       The present Application for Patent claims priority to Provisional Application No. 60/583,779 entitled "An Edge Preserving and Flexible Adaptive Noise Filter for Imaging Applications" filed June 28, 2004 and assigned to the assignee hereof and hereby expressly incorporated by reference herein.<br>
FIELD OF THE INVENTION<br>
[0002]    This invention relates to signal processing, and in particular, digital image processing.<br>
BACKGROUND<br>
[0003]    Noise filtering is a very important operation in digital image processing. For example, the pixels in a signal produced by an image sensor such as a CCD (charge-coupled device) or CMOS (complementary metal-oxide-semiconductor) device may be corrupted by several types of noise, such as reset (or KTC) noise, photon shot noise, dark current, and thermal noise. The characteristics of this noise may be related to factors such as the particular fabrication process, local variations in the sensor or other circuitry such as amplifiers, and ambient conditions (e.g. temperature, level of illumination). The noise may include components that are characterizable, such as, but not limited to multiplicative noise, and/or components that are random.<br>
[0004]    During processing of the image signal, the noise may be amplified, and the visual quality of the final image may be reduced. Noise problems may be especially acute in particular situations, such as mobile imaging applications mat use compact sensor modules having small pixel areas (e.g. in cellular telephones, personal digital assistants (PDAs), or wearable devices such as wristwatches). Moreover, these situations may demand solutions that are computationally inexpensive.<br><br>
WO 2006/028559	PCT/US2005/022838<br>
[0005]   Noise problems may also arise in imaging applications that make use of<br>
nonvisible radiation. For example, high-frequency or impulsive noise may also be manifested as speckle in synthetic aperture radar (SAR) images, which are typically generated using microwave radiation.<br>
SUMMARY<br>
[0006]    According to one embodiment, a method of processing an image including a subject pixel comprises calculating a distance between the neighbor pixel and the subject pixel for each of a plurality of neighbor pixels in a neighborhood of the subject pixel. The method also comprises selecting, for each of the calculated distances and from among a plurality of mtervals, an interval that includes the calculated distance; and obtaining, for each of the plurality of neighbor pixels, a value weight based on the corresponding selected interval. The method includes calculating a value for the subject pixel based on values of the neighbor pixels, including weighting the value of each of the plurality of neighbor pixels by the corresponding value weight<br>
[0007]    According to another embodiment, an apparatus for processing an image including a subject pixel comprises a distance calculator configured to calculate a<br>
distance between the neighbor pixel and the subject pixel for each of a plurality of neighbor pixels in a neighborhood of the subject pixel. The apparatus includes an interval selector configured to select, for each of the calculated distances and from among a plurality of intervals, an interval that includes the calculated distance; and a value weight calculator configured to calculate, for each of the plurality of neighbor pixels, a value weight based on the corresponding selected interval. The apparatus also includes a pixel value calculator configured to calculate a value for the subject pixel based on values of the neighbor pixels by weighting the value of each of the plurality of neighbor pixels by the corresponding value weight. Further embodiments and devices and systems including and/or capable of performing such embodiments are disclosed herein.<br>
BRIEF DESCRIPTION OF THE DRAWINGS <br>
(0008]   FIGURE 1 shows a diagram of a method 100 according to an embodiment<br><br>
WO 2006/Î¸28559	PCT/US2005/022838<br>
4<br>
[0009]	FIGURE 2 shows examples of several pixel neighborhoods.<br>
[00010]	FIGURE 3 shows a diagram of an implementation T122 of task T120.<br>
[00011]	FIGURE 4 shows an example of a range being divided into intervals.<br>
[00012]	FIGURE 5 shows an example of a weighting function f.<br>
[00013] FIGURES 6a-6d show series of comparisons that may be performed in implementations of task T130.<br>
[00014] FIGURE 7 shows an example of a range being divided into intervals of different widths.<br>
[00015] FIGURES 8a and 8b show examples of base value tables.<br>
|00016] FIGURE 9 shows an example of a linear interpolation of f(D).<br>
[00017) FIGURES 10a and 10b show examples of tables F, S, and P.<br>
[00018] FIGURE 11 shows a diagram of an implementation T124 of task T120.<br>
[00019] FIGURES 12a and 12b show examples of tables that may be used in performing multiplicative division.<br>
[00020] FIGURE 13 shows a diagram of signal processing apparatus 200.<br>
[00021] FIGURE 14 shows a diagram of a system including apparatus 205.<br>
[00022] FIGURE 15 shows a diagram of an application of method 100.<br>
[00023] FIGURE 16 shows a diagram of a portion of a sensor having a Bayer filter.<br>
DETAILED DESCRD7TION<br>
[00024] One traditional method of noise reduction is to perform low-pass filtering. While such a method may be effective in removing high-frequency noise, it also tends to cause image blurring and a result mat appears out-of-focus. Another method is to perform an adaptive filtering. Adaptive filters may be used to preserve edges by<br><br>
WO 2006/028559	PCT/US2005/022838<br>
avoiding smoothing across an edge boundary. Such a filter may produce an image that<br>
looks sharp because edges remain sharp while noise is smoothed. However, currently existing adaptive filters are too computationally expensive to be practical in real-time or near-real-time imaging applications.<br>
[00025] Principles described herein may be applied to methods of modifying a value of a subject pixel based on values of neighboring pixels. Such a method may include weighting a value of a neighboring pixel in inverse nonlinear proportion to its distance from the subject pixel. Such a method may also be extended to obtain an image by adaptively filtering (e.g. convolving with an adaptive mask) an input image using new adaptive filtering techniques. The input image may represent uncompressed pixel data based on an image outputted by a CCD or CMOS sensor.<br>
[00026] Embodiments include effective and simple-to-implement methods and filters to perform noise reduction while preserving edges. Such embodiments may be implemented in a simple fashion using lookup tables. Such embodiments may also offer flexibility to the filter designer, as they may be implemented without being limited to a specific weighting function. Based on the noise characteristics, for example, such an embodiment may be reconfigured to use a different weighting function, e.g. in order to balance noise reduction and edge preservation behaviors.<br>
[00027] An adaptive filter according to one embodiment includes an N*N two-dimensional convolution, where N is an odd integer greater than one. Pixels of an image are filtered by moving the N*N kernel across the image. At each pixel location, the kernel coefficients are determined by the image pixels within the NxN region, such that the kernel coefficients may change from one pixel location to the next.<br><br>
[00028] A value of a pixel in an image may be represented as I(x,y), where x and y indicate the location of the pixel in the horizontal and vertical directions, respectively. The coefficients of the NxN kernel may be determined by an equation of the form<br><br><br>
WO  2006/028559	PCT/US2M5/022838<br>
{00029] The weighting function fused to determine the coefficients in the kernel may be monotonic and decreasing. The input to function f includes nonnegative numbers from zero to infinity (or some positive number w). The output of function f is a nonnegative number f -max when the input is zero, and a nonnegative number f -min 
[00030] From expression (A), it may be understood that at the center of the kernel (where i = j = 0), the weighting is greatest because w(0,0) = f(0) = f -max, and that the weighting is less when the pixel difference is large. In such fashion, the kernel is adaptive based on the pixels in the N x N region. When the kernel coefficients have been determined, their sum is computed for normalization (to be performed e.g. after the convolution).<br>
|00031] Typically, a weighting function f is a complex function such as a Gaussian, exponential, or polynomial function that may require time-consuming floating-point computation. Principles as disclosed herein may be applied to provide a good approximation of such floating-point computation while greatly reducing the<br>
computational complexity.<br>
[00032]  Implementations of methods and apparatus as disclosed herein may include a lookup table F1, which is an array of L sub-sampled values of function f; a lookup table Pi, which is an array of the L pixel value differences at which the function f is evaluated to obtain the corresponding entry in table F1, and a lookup table S1, which is an array of 1^1 entries that each indicate the slope of a line connecting F1[i] and F1[i+1] for i = {0,<br>
1, ... Lr-2}. Such lookup tables may be stored in local memory and/or in external memory, and as one large table or as multiple tables.<br>
[00033] If the absolute value of the pixel value difference is denoted by d, then f(d) may be computed by first determining the interval in table Pi to which d belongs. If d is determined to lie within interval k, then f(d) may be computed as f(d) = F1[k] + S1[k] x (d â P1[k]). By applying lookup tables as described above, the computation of f(d) may be greatly simplified and easily and efficiently implemented in fixed-point (e.g. integer) computation. Moreover, the weighting function f may be easily changed by loading<br><br>
WO 2006/Â»2Â»5S&gt;	PCT/US2005/022838<br>
different tables F1 and S1 (and P1 if desired). In such manner, filter design flexibility may be achieved.<br>
[00034] The normalization operation may be an integer division approximated by multiplication and shifting operations. The multipliers may be stored as a lookup table whose size may depend on the range of the normalization factor in the particular application. So long as f -min, f -max, and the kernel size do not change, the method or apparatus may use the same multiplier table even if the weighting function f is changed.<br>
[00035] Embodiments include a method that may be used to provide a simple-to-implement edge-preserving adaptive filter suitable for noise reduction in two-dimensional imaging applications. Such a method may be implemented to be highly flexible in that users may apply their own weighting functions as needed. Such a<br>
method may be implemented by a hardware configuration and/or in software for execution by a DSP (digital signal processing) unit or CPU (central processing unit). For example, a filter according to an embodiment may be implemented in hardware that is separate from a DSP unit or CPU.<br>
100036) Embodiments include methods and apparatus for adaptively fihering noise by<br>
using lookup tables to approximate a floating-point operation, wherein at least one lookup table contains sub-sampled values of at least one monotonically decreasing function and at least one lookup table contains pixel value differences.<br>
[00037] FIGURE 1 shows a diagram of a method 100 according to an embodiment. Task T200 assigns a weight to a pixel q. Task T300 iterates task T200 for each of a desired set of pixels Q in a neighborhood of a subject pixel C such that a weight is<br>
assigned to each of the pixels in Q. Method 100 may be implemented such that the set Q includes the subject pixel C, or it may be implemented such that set Q does not include C. Based on the values and assigned weights of the pixels in Q, task T400 calculates a new value for the subject pixel C.<br>
[00038] Weight assignment task T200 includes subtasks T 110 and T120. Task T 110 calculates a distance D between the pixel q and the subject pixel C. Task T120 assigns a weight f(D) to the pixel q that is based on the calculated distance D.<br><br>
WO2WW028559	-PCT/US2005/022838<br>
[00039] FIGURE 2 shows several examples of neighborhoods that may be used in<br>
implementations of methods and apparatus as described herein, in which the subject pixel is indicated by a large dot and the neighbor pixels are indicated by small dots. As shown in the diagram on the left in the top row of FIGURE 2, an eight-connected neighborhood may be used. Alternatively, as shown in the diagram on the right, a four-connected neighborhood may be used.<br>
[000401 Other sets of pixels may also be selected for the neighborhood, some examples of which are shown in the second row of FIGURE 2. Neighborhoods may be selected from e.g. 5x5 or 7x7 masks centered at the subject pixel, as shown in the third row of FIGURE 2. It is also possible that the selected neighborhood Q may include pixels that are in another image (e.g. corresponding to a different moment in time) than the subject pixel.<br>
(00041) The values of the pixels may be eight-bit unsigned integers in the range of 0 to 255. The principles described herein may also be applied to pixels having color values in the RGB space of more than eight bits (e.g. ten, twelve, fourteen). However, application of these principles is not limited to such pixel values, and in other cases (including other RGB cases) the pixel values may be signed integer or non-integer (fixed- or floating-point) values having fewer (e.g. four) or more (e.g. nine, twelve, fourteen, sixteen, seventeen, thirty-two) bits. It is also possible for some of the pixels to have different forms (e.g. for the values of the pixels in Q to differ in form from the value of pixel C), and task T400 may calculate a value that has a different form than the values of pixel C and/or the pixels in Q.<br>
[00042] For pixels having color values in a multi-component space that includes a luminance or intensity component (e.g. HSV, YIQ, YUV, YCrCb, YDrDb, YPrPb), a method as described herein may be performed on the luminance or intensity component only. Alternatively, such a method may be performed on more components of the pixel values (e.g. all of the components). Methods and/or apparatus may also be applied such that different components of a pixel color value are processed in separate channels, with the method and/or apparatus being applied separately to one (or each of more man one) of the channels. It is possible that different components of an image may be sampled at different resolutions (such that, for example, two pixels representing different Y samples may represent the same Cr sample).<br><br>
WO 2006/028559	PCT/US2005/022838<br>
[00043] Task T 110 calculates a distance D between the neighbor pixel q and the<br>
subject pixel C. For example, task T 110 may calculate a photometric or radiometric distance (distance between intensity values). In other implementations, task T 110 may calculate a geographic distance (distance between spatial values) and/or a temporal distance (distance between temporal values, which may correspond to the same or different spatial sampling points).<br>
[00044] For one-dimensional pixel values (each representing e.g. intensity of a luminance, chrominance, or color component), the distance between two pixels maybe measured as the difference (or the magnitude of the difference) between the pixel values. For multi-dimensional pixel values (each representing e.g. position in a two-dimensional (x, y) image plane), the distance between two pixels may be measured as the sum of the magnitude of the difference between the pixel values in each dimension (Manhattan distance, e.g. |x1 - X2I + y2 - y2|), or as the maximum of those magnitudes (chessboard distance, e.g. max{jx1 â 2\, h/i â y2|}), or as the geometric mean of those magnitudes (Euclidean distance, e.g. (x1 - x2f + |y1â y2f)1/2)- Examples of other distance metrics that may be used include squared Euclidean distance, Chebyshev distance (e.g. max{xi, - yi|}), and chamfer distance.<br>
[00045] As noted above, a distance may be calculated based on a difference between two values. In some applications, a more approximate calculation of distance may suffice instead. For example, a distance between two unsigned binary integer values may be approximated based on a difference between the positions of their most significant high bits.<br>
[00046] Task T120 assigns a weight f(D) to a neighbor pixel q based on the calculated distance D. It may be desirable for the function f to express a nonlinear inverse relationship between pixel value weight and pixel distance. The inverse relationship implies that values of more distant pixels are weighted less heavily, and the nonlinearity may be selected according to a desired discrimination between values of less distant and<br>
more distant pixels. One potential advantage of applying a nonlinear inverse relationship in an image filter is preservation of edges in a filtered image, although the embodiments disclosed herein are not limited to methods and apparatus having Ibis advantage.<br><br>
WO 2006/028559	PCT/US2005/022838<br>
10<br>
[00047] The weight-distance relationship f may have the form of a Gaussian, exponential, and/or polynomial expression. One example of an exponential relationship is f(x) = exp[-(x/k)2], where x denotes the distance and k denotes a process parameter. In the case where k = 2a, where o denotes a standard deviation, this equation also expresses a Gaussian relationship. One example of a polynomial relationship is f(x) = (1 + (x/k)2)-1. However, these particular relationships are merely examples, and it will be understood that any variation or other function that expresses a monotonic decreasing relationship between value weight and distance may be used. From the discussion below, it will also be understood that the function f need not be easily characterizable by<br>
any algebraic expression, and that the function may be implemented in an approximate fashion and indeed may be defined instead by selecting a number of inflection points (e.g. knots).<br>
[00048] FIGURE 3 shows a diagram of an implementation T122 of task T120 that includes tasks T130, T140, and T150. Task T130 selects an interval k that includes the calculated distance D. Task T140 retrieves a base value F[k] that is associated with interval k, and task T150 calculates a value weight f(D) for pixel q that is based on F[k].<br>
(00049) Task T 110 selects interval k from among a set K of intervals that represent portions of a range R. Range R may be the range of possible or expected values of distance D as calculated in task T 110 (or a selected portion of such range). In a case where task T l 10 calculates distance D as the magnitude of a difference between two unsigned 8-bit integers, for example, range R may be the range from 0 to 255.<br>
[00050] FIGURE 4 shows one example in which a range of expected distance values is divided into thirteen equal, adjacent, and nonoverlapping intervals. In other implementations, set K may include intervals that are nonequal, nonadjacent, and/or overlapping. In typical implementations, it may be desirable for the number of intervals in K to be eight, or ten, or sixteen, or twenty, although set K may have fewer (e.g. four) or more (even one hundred or more) intervals as desired for a particular application.<br>
(00051] The various intervals in K may be characterized by a set P of values. For example, the values in P may be endpoints of intervals in K. The sets of values {31,63, 95,127,159,191,223} and {32,64,96,128,160,192,224} are two examples of sets of endpoints that may be used to divide the range (0-255) into eight equal intervals (see,<br><br>
WO2006/028559	PCT/U2005/022838<br>
e.g., FIGURE 5, where f(x) = exp[â(x/128)2]). In these two examples, the endpoints of<br>
the outer intervals (0 and 255) are assumed, although in other cases it may be desired to set forth those points explicitly.<br>
[00052] Interval selection task T130 may include comparing the calculated distance D with one or more of the values in P. It may be desirable (e.g. for efficiency) to perform such an operation with the points in P being arranged in increasing or decreasing order as appropriate. FIGURE 6a shows an example of a series of comparisons that may be performed for a case where the n values of P are arranged in order of increasing<br>
magnitude, and FIGURE 6b shows an example of such a series as applied to the case P = {31,63, 95, 127, 159,191, 223}.<br>
[00053] It will be noted that in proceeding through the series of FIGURE 6b from the left, the operation may be terminated at the first comparison whose result is false. For example, if the result of the comparison (D &gt; 31?) is false, then it is known that D is in the interval (0-31). In such case, the location of the first false result (or the overall absence of a false result) indicates the interval k in which D resides. Alternatively, a method or apparatus may proceed through this series from the right, in which case the operation may be terminated at the first comparison whose result is true. In such case, the location of the first true result (or the overall absence of a true result) indicates the interval k in which D resides.<br>
[00054] FIGURE 6c shows an example of an alternate series of comparisons, and FIGURE 6d shows an example of such a series as applied to the case P = {32, 64,96, 128,160,192,224}. In this case, when proceeding through the series from the left, the operation may be terminated at the first comparison whose result is true, and when proceeding through the series from the right, the operation may be terminated at the first comparison whose result is false.<br>
[00055] It may be desirable in some implementations of task T130 to perform such a series of comparisons in parallel. In a processing architecture that is configured to execute single-instruction, multiple-data (SMD) instructions, for example, it maybe possible to perform the entire set of comparisons in one instruction cycle. The parallel comparison operation may be configured such that the resulting bit mask indicates the interval k in which D resides.<br><br>
WO 2006/028559	PCT/US2005/0228J8<br>
 12<br>
[00056] The intervals in K may be equal or nonequal, such that the points in P may be spaced equally or nonequally over range R. For example, it may be desirable for adjacent points in P to be closer together in regions of R where |df/dD| (for D e R) is large, as compared to regions of R where |df/dD| is small. Such a distribution may have the advantage of supporting a better approximation of a smooth function f, or of supporting an acceptable approximation of a smooth function f with comparatively few intervals, although the embodiments disclosed herein are not limited to smooth functions for to methods or apparatus having either of these advantages.<br>
[00057] FIGURE 7 shows an example in which the range of expected distance values as shown in FIGURE 4 is divided into seven intervals, some of which are larger than others. It will be understood that the points in P may be selected to promote accurate interpolation (e.g. piecewise linear interpolation) of function f within each interval.<br>
(00058) n otherimplementations, the values in P may include other points characterizing the intervals in K (e.g. midpoints of the intervals), and interval selection task T 130 may include calculating a distance between D and each of these values. In such case, task T130 may select the interval k which corresponds to the point in P that is closest to D (e.g. mm{|D - p|} V p 6 P).<br>
[00059] Task T140 retrieves a base value F[k] that is associated with interval k. FIGURE 8a shows one example 110 of a lookup table F indexed by k (for k from 1 to 8) from which task T140 may retrieve F[k]. In this example, table 110 stores the values F[k] for function f as shown in FIGURE 5, where each F[k] is the value of fat the lowest endpoint of the corresponding interval k. In other implementations as appropriate, each F[k] may be the value of fat the highest endpoint, or at some other point (e.g. midpoint), of the corresponding interval k.<br>
[00060] It may be desirable to obtain fixed-point (e.g. integer) values for F[k] rather than floating-point values. For example, FIGURE 8b shows another lookup table 120 that corresponds to the function f and intervals as shown in FIGURE 5 but which stores only integer values. The values of table 120 are approximations of the values of table 110, and each is obtained by multiplying the corresponding value of table 110 by 128 and rounding the result Use of such fixed-point values may permit arithmetic operations that are less computationally expensive (although possibly less precise) than<br><br>
WO 2006/028559	PCT/US20O5/O22838<br>
floating-point operations. In this case, when a calculation that makes use of F[k] as a factor is complete, the factor of 128 may be removed by executing a seven-bit right shift on the result.<br>
[00061] Task T 150 calculates a value weight f(D) that is based on the base value F[k]. In some applications, it may be sufficient to adopt F[k] as the value of f(D). In other implementations, task T150 calculates f (D) by calculating a correction to F[k] according to a distance between (a) the value at which F[k] was evaluated and (b) distance D. For example, f(D) may be interpolated from F[k] along a line connecting the endpoints of interval k.<br>
[00062] Task T150 may be implemented to calculate a linearly interpolated value of f(D) as a function of the terms F[k] and (L x G), where L denotes the slope of a line connecting the endpoints of interval k and G denotes a distance between (a) the value at which F[k] was evaluated and (b) distance D. In a case where F[k] is evaluated at the lesser endpoint of interval k, for example, task T150 may calculate f(D) according to an expression such as f(D) = F[k] + (L x (D - p)), where p is the point at which F[k] was evaluated. FIGURE 9 shows a diagram of such an interpolation, m a case where F[k] is evaluated at the greater endpoint of interval k, task T 150 may calculate f(D) according to an expression such as f(D) = F[k] - (L x (p - D)).<br>
[00063] Retrieval task T140 may also retrieve the values of L and p that correspond to interval k from lookup tables. FIGURE 10a shows an example of three lookup tables, all indexed by k, for function f as shown in FIGURE 5: base value table F, slope value table S, and evaluation point table P. For a case in which F[k] is evaluated at the lesser endpoint of each interval in K (as in FIGURE 10a), task T150 may calculate f(D) according to an expression such as f(D) = F[k] + (S[k] x (D - P[k])). For a case in<br>
which F[k] is evaluated at the greater endpoint of each interval in K, task T150 may calculate f(D) according to an expression such as f(D) = F[k] - (S[k] x (D - P[k])).<br>
[00064] FIGURE 11 shows a diagram of an implementation T124 of task T120 that includes tasks T130, T142, and T152. Implementation T142 of task T140 retrieves a base value F[k],a slope value S [k],anddistance value P[k] that are associated with interval k. Implementation T152 of task T150 calculates a value weight fl[D) for pixel q that is based on F[k], S[k], and P[k].<br><br>
WO 200A/028559	PCT/US20O5/022838<br>
14<br>
[00065] One or more of the tables F, S, and P may be implemented to permit<br>
computation of f(D) in a desired fashion. For example, FIGURE 10b shows another set of lookup tables that corresponds to the set as shown in FIGURE 10a but which stores only fixed-point values. Specifically, in this example the values of F[k] are multiplied by 128 (27) and the values of S[k] are multiplied by 4096 (212). In this case, f(D) may be calculated as f(D) = (F[k] + ( (S[k] x (D - P[k]) ) Â» 5) Â» 7, where Â»is the bitwise right shift operator.<br>
[00066] Tables F, S, and P may be implemented as separate tables, each being accessed independently of the other. Alternatively, one or more of these tables may be implemented together such that only one table access is required to retrieve more than one of the values F[k], S[k], and P[k]. In some implementations, for example, it may be less expensive to retrieve multiple values at once and separate them locally than to perform multiple memory accesses. In any case, a method or apparatus according to an embodiment may apply a different weighting function from one pixel to the next (and/or from one image to the next) by, for example, configuring task T140 to retrieve values from different sets of lookup tables, each set corresponding to a different weighting function f. Alternatively, a different weighting function may be applied by changing the contents of tables F and S (e.g. loading new tables F and S) to values suitable for the desired new weighting function.<br>
[00067]  In other embodiments, interpolation of f(D) from F[k] may be based on nonlinear functions (e.g. polynomials, splines). In such a case, task T150 maybe implemented to calculate a value weight f(D) based on distance D, base value F[k], a distance value P[k], and an interpolation parameter (S[k] retrieved from table S being one example of such a parameter).<br>
[00068] In further embodiments, task T 150 may calculate a slope or other interpolation parameter from evaluations of function fat endpoints (and possibly at other points) of interval k. For example, the slope of a line over an interval 32 bits wide may be easily calculated as [((value of f at greater endpoint) - (value of f at lesser endpoint)) Â» 5].<br>
[00069] m further implementations, base value F[k] is calculated at run-time. In such cases, the endpoints of interval k may be selected such that f(k) is easily calculated at those points.<br><br>
WO 2006/028559	PCT/US2005/022838<br>
[00070]Task T400 calculates a new value C for the subject pixel C. In some<br>
implementations, C may be based only on weighted values of the pixels in Q. For<br>
example, C may be calculated as a normalized sum of weighted values of the pixels in Q:<br><br>
where wq denotes the value weight f(D) as calculated for pixel q in task T200. It may be desirable in some embodiments to implement the summation of the weighted values as a dot product of a vector of the value weights wq and a corresponding vector of the pixel values q.<br>
[00071] Utilization of the value weights f(D) to calculate a new value for the subject pixel may also include one or more sorting or statistical operations. For example, it may be desired to calculate C using only a subset of the values of the pixels in Q. In one example of such a method, of a set Q of eight neighbor pixels, only the values of the four pixels having the highest weights are used in calculating C. In such cases, C may be calculated as a normalized sum of weighted values of the pixels in a selected subset V of Q:<br><br>
[00072] In other implementations, C may also be based on a separately weighted value of subject pixel C (e.g. for a case in which C i Q). For example, C may be calculated as:<br><br><br>
WO 2006/028559	PCT/US2005/022838<br>
where a is a weight value that may be constant for the application or may be selected<br>
based on, e.g., a characteristic of an image being filtered (e.g. standard deviation of the image or neighborhood, etc.).<br>
{00073] The values f(D) (e.g. as calculated by task Tl 50) may be modified before C is calculated. For example, the values f(D) may themselves be weighted according to a spatial pattern (e.g. a Sobel edge detection mask). In a further embodiment, C is calculated using value weights derived from more than one weighting function. For example. C may be calculated according to an expression of the form:<br><br>
where value weights w 1 are calculated (e.g. by task T200) using a function f and a distance measure (eg. photometric distance), value weights w2 are calculated (e.g. by task T200) using a different function f and/or distance measure (e.g. geographical distance), and b is a weight value that may be constant for the application or may be selected based on, e.g., a characteristic of an image being filtered (e.g. standard deviation of the image or neighborhood, etc.). The sets Vi and V2 may be the same or different subsets of Q, and one or both of these sets may be equal to Q.<br>
[00074] As shown in expressions (l)-(4), normalization may be performed by dividing each summation of weighted values by the sum of the value weights. Alternatively, normalization may be performed on each value weight individually. If only a subset V of the set Q is being used, it may be desirable to perform normalization after the subset V is selected.<br>
[00075] A division operation may be computationally expensive. Therefore, it may be desirable to simplify a division operation as used in normalization. In one such simplification, the division operation is implemented using multiplicative division (e.g. comprising multiplication and/or binary shift operations). For example, a division by 3 may be approximated using a multiplication by 85 (~ 256/3) followed by a right shift of 8(k&gt;g2 256). Task T400 may include performing a normalization operation by retrieving and applying such values. FIGURES 12a and 12b show examples of tables of<br><br>
WO 2M6/028559	PCT/US200S/022838<br>
18<br>
pixel value calculator 230 at different times. Such a processor may be a microprocessor or other digital signal processing unit and may be a stand-alone or embedded device. Such a processor may also be fabricated into an application-specific integrated circuit (ASIC) or application-specific standard product (ASSP), or programmed into a field-programmable gate array (FPGA) or similar device. In the context of a device or system including apparatus 200, such a processor may also be used to execute other sets of instructions, e.g. for activities not directly related to operation of apparatus 200.<br>
[00079] Method 100 may be performed by a dedicated array of logic elements (e.g. ASIC, ASSP, FPGA, etc.) or a dedicated portion of such an array. FIGURE 14 shows a diagram of a system including an apparatus 205 implemented in such an array. Apparatus 205 receives and filters an image signal from image sensor 310 and stores the filtered image in an external memory 330 (e.g. a semiconductor or magnetic random-access memory). Apparatus 205 may also communicate with an external DSP unit or other processor 320. For example, external processor 320 may load tables F, S, and/or P into storage element 240 (e.g. to change the function f being applied by apparatus 205) or cause such tables to be loaded, may perform pre- or post processing of the image processed by apparatus 205, and may control or otherwise configure apparatus 205.<br>
[00080] Apparatus 205 includes an implementation of apparatus 200 and local storage element 240 for lookup tables (e.g. tables F, S, P, and/or tables to support multiplicative division as disclosed herein). Storage element 240 (e.g. an array of semiconductor or magnetic memory cells, such as static or dynamic random-access memory) may reside on the same chip as, or on one or more different chips from, apparatus 200. Storage element 240 may also reside in the same package (e.g. a ball grid array (BGA), a thin shrink small outline plastic package (TSSOP), etc.) as apparatus 200. Other implementations of apparatus 205 may include a buffer between sensor 310 and apparatus 200 (e.g. such that values for the pixels in Q may be available for calculation of C). Apparatus 205 may include a portable housing (e.g. metal and/or plastic, as for a cellular telephone or camera) that houses the components, and may also include a portable power source such as a battery, fuel cell, or charge storage device such as a supercapacitor.<br><br>
WO 2006/028559	PCT/US2005/022838<br>
19<br>
[00081] Potential applications of the principles described herein include processing an image by performing an implementation of method 100 for some, many, or substantially all pixels of the image (e.g. with suitable modification with respect to pixels at the spatial image boundaries).<br>
[00082] In one such application as diagrammed in FIGURE 15, a filtered image 12 is obtained by applying an implementation of method 100 (e.g. using an apparatus 200) to each pixel in at least a portion of an image II, such that each pixel in 12 based on a neighborhood of the corresponding pixel in II. Such a method may be applied iteratively, e.g. as a convolution mask, possibly using different weighting functions f (and/or different sizes or configurations of neighborhood Q) for different subject pixels in image II and/or from one image to the next (e.g. in filtering a video sequence).<br>
[00083] Embodiments include apparatus configured to perform one or more methods as disclosed herein, devices including such an apparatus, and systems including such an apparatus or device. For example, such embodiments include cameras (still and/or video), portable communications devices such as cellular telephones, PDAs, wireless cameras, and wearable cameras. Such a device or system may include a sensor (e.g. a CMOS or CCD image sensor) configured to provide an image signal to such an apparatus, which is configured to filter the signal and provide a filtered image to a storage element (e.g. semiconductor or magnetic memory) and/or to a display (e.g. a liquid-crystal or other flat-panel display, or a cathode-ray tube display).<br>
[00084] An apparatus 200 may receive an image captured using a Bayer filter. FIGURE 16 shows one example of such a filter, which maybe used to derive several' component images (e.g. R, G, B) from a monochrome sensor. Subsequent to capture, the Bayer filtered image is processed using a de-mosaicing operation to obtain the component images. An implementation of method 100 or apparatus 200 may be applied to the raw sensor signal (e.g. with appropriate selection of set Q, such as limiting Q to pixels having the same color filter as the subject pixel) and/or to one or more of the component image signals after de-mosaicing.<br>
[00085] The foregoing presentation of me described embodiments is provided to enable any person skilled in the art to make or use the structures and methods claimed herein. Various modifications to these embodiments are possible, and the generic<br><br>
WO 2006/028559	PCT/US20O5/022838<br>
principles presented herein may be applied to other embodiments as well. For example, such principles may be applied to image signals obtained using non-visible radiation, such as radiation at microwave frequencies (e.g. synthetic aperture radar (SAR) images).<br>
[00086] An embodiment may be implemented in part or in whole as a hard-wired circuit, as a circuit configuration fabricated into an application-specific integrated circuit, or as a firmware program loaded into non-volatile storage or a software program loaded from or into a data storage medium as machine-readable code, such code being instructions executable by an array of logic elements such as a microprocessor or other digital signal processing unit. Embodiments of the invention also include computer programs containing one or more sets (e.g. sequences) of machine-executable instructions describing a method as disclosed herein, and data storage media (e.g. semiconductor or magnetic memory such as ROM or RAM, magnetic or optical disk) having such sets of instructions stored therein. Thus, the present invention is not intended to be limited to the embodiments shown above but rather is to be accorded the widest scope consistent with the principles and novel features disclosed in any fashion herein.<br><br>
W0 2Wtt/Â»28559	PCT/US2IMK/0228J8<br>
21\ CLAIMS<br>
1.	An apparatus for processing an image including a subject pixel, said<br>
apparatus comprising:<br>
a distance calculator configured to calculate, for each of a plurality of neighbor<br>
pixels in a neighborhood of the subject pixel, a distance between the neighbor pixel and the subject pixel;<br>
an interval selector configured to select, for each of the calculated distances and from among a plurality of intervals, an interval that includes the calculated distance;<br>
a value weight calculator configured to calculate, for each of the plurality of neighbor pixels, a value weight based on the corresponding selected interval; and<br>
a pixel value calculator configured to calculate a value for the subject pixel based on values of the neighbor pixels by weighting the value of each of the plurality of neighbor pixels by the corresponding value weight<br>
2.	The apparatus for processing an image according to<br>
said value weight calculator is configured to calculate, based on the corresponding calculated distance, a value weight according to a monotonically decreasing nonlinear relation between value weight and distance.<br>
3.	The apparatus for processing an image according to claim 1, wherein<br>
said distance calculator is configured to calculate the distance between the neighbor<br>
pixel and the subject pixel as a difference between an intensity value of the neighbor<br>
pixel and an intensity value of the subject pixel.<br>
4.	The apparatus for processing an image according to claim 1, wherein said interval selector is configured to select the interval that includes the calculated distance by comparing the calculated distance to an endpoint of each of a plurality of the intervals.<br>
5.	The apparatus for processing an image account to claim1, wherein<br>
said interval selector is configured to select the interval that includes the calculated<br><br>
WO 2006/028559	PCT/US2005/022838<br>
each set associated with a corresponding one of the plurality of intervals and including<br>
an interpolation parameter, a distance value, and a value of a monotonically decreasing nonlinear relation between value weight and distance at the corresponding distance value,<br>
wherein the value weight calculator is configured to calculate the value weight based on the set of values associated with the corresponding selected interval.<br>
11.	The apparatus for processing an image according to claim 10, wherein at least one of the distance calculator, the interval selector, the value weight calculator, and the pixel value calculator is fabricated in the same package as the storage element.<br>
12.	The apparatus for processing an image according to claim 10, said apparatus comprising:<br>
am image sensor configured to captive the image; and<br>
a housing configured to house the image sensor, the storage element, and a portable power source.<br>
13.	The apparatus for processing an image accordingto claim 10, wherein at least one of the distance calculator, the interval selector, the value weight calculator, and the pixel value calculator is implemented as a dedicated array of logic elements.<br>
14.	The apparatus for processing an image according to claim 10, said apparatus comprising a processor,<br>
wherein at least one of the distance calculator, the interval selector, the value weight calculator, and the pixel value calculator comprises a set of instructions executable by the processor.<br>
15.	An apparatus for processing an image including a subject pixel, said<br>
apparatus comprising:<br>
means for calculating, for each of a plurality of neighbor pixels in a neighborhood of the subject pixel, a distance between the neighbor pixel and the subject pixel;<br><br>
WO 2WW028559	PCT/US2005/022838<br>
means for selecting, for each of the calculated distances and from among a plurality of intervals, an interval that includes the calculated distance;<br>
means for obtaining, for each of the plurality of neighbor pixels, a value weight based on the corresponding selected interval; and<br>
means for calculating a value for the subject pixel based on values of the neighbor pixels, said calculating a value comprising weighting the value of each of the plurality of neighbor pixels by the corresponding value weight.<br>
16.       The apparatus for processing an image according to claim 15, said apparatus comprising:<br>
means for storing a plurality of sets of values, each set associated with a corresponding one of the plurality of intervals and including an interpolation parameter, a distance value, and a value of a monotonically decreasing nonlinear relation between value weight and distance at the corresponding distance value;<br>
an image sensor configured to capture the image; and<br>
a housing configured to house the image sensor, the means for storing, and a portable power source,<br>
wherein the means for obtaining a weight value is configured to calculate the value weight based on the set of values associated with the corresponding selected interval.<br>
17.       A method of processing an image including a subject pixel, said method comprising:<br>
(a)	for each of a plurality of neighbor pixels in a neighborhood of the subject pixel, calculating a distance between the neighbor pixel and the subject pixel;<br>
(b)	for each of the calculated distances, and from among a plurality of intervals, selecting an interval that includes the calculated distance;<br>
(c)	for each of the plurality of neighbor pixels, obtaining a value weight based on the corresponding selected interval; and<br><br>
WO 2006/028559	PCT/1JS2005/022838<br>
(d) calculating a value for the subject pixel based on values of the neighbor pixels, said calculating a value comprising weighting the value of each of the plurality of neighbor pixels by the corresponding value weight.<br>
18.	The method of processing an image according to claim 17, wherein said obtaining a value weight comprises calculating, based on the corresponding calculated distance, a value weight according to a monotonically decreasing nonlinear relation between value weight and distance.<br>
19.	The method of processing an image according to claim 17, wherein said calculating a distance includes calculating a difference between an intensity value of the neighbor pixel and an intensity value of the subject pixel.<br>
20.	The method of processing an image according to claim 17, wherein said selecting an interval that includes the calculated distance comprises comparing the calculated distance to an endpoint of each of a plurality of the intervals.<br>
21.	The method of processing an image according to claim 17, wherein said obtaining a value weight based on the corresponding selected interval includes reading a base value associated with the interval and calculating, based on the corresponding<br>
calculated distance, a correction to the base value.<br>
22.	The method of processing an image according to claim 21, said method<br>
comprising:<br>
loading a first set of entries characterizing a first monotonically decreasing nonlinear dependence of value weight on distance, wherein said reading a base value comprises reading from the first set;<br>
loading a second set of entries characterizing a second monotonically decreasing nonlinear relation between weight and distance, said second set being different than the first set and said second relation being different than, the first relation; and<br>
performing acts (a), (b), (c), and (d) on a second image including a subject pixel, wherein said act (c) as performed on the second image includes reading, from the indexed set, a base value associated with the interval and calculating, based on the corresponding calculated distance, a correction to the base value.<br><br>
WO 2006/028559	PCT/US2005/022838<br>
23.	The method of processing an image according to claim 21, wherein said calculating a correction to the base value includes reading an interpolation parameter associated with the interval.<br>
24.	The method of processing an image according to claim 23, wherein said calculating a correction to the base value includes reading a distance associated with the interval and calculating a correction to the base value based on (a) the interpolation parameter and (b) a difference between the calculated distance and the read distance.<br>
25.	The method of processing an image according to claim 23, wherein said obtaining a value weight comprises calculating, based on the corresponding calculated distance, a value weight according to a monotonically decreasing nonlinear relation between value weight and distance,<br>
wherein the interpolation parameter represents a slope of a line that approximates the monotonically decreasing nonlinear relation across the interval.<br>
26.	A data storage medium having machine-readable instructions describing the method according to claim 25.<br>
27.	The method of processing an image according to claim 17, said method comprising normalizing a sum of the weighted values of the plurality of neighbor pixels, said normalizing including:<br>
reading a value associated with a sum of the plurality of value weights;<br>
multiplying a sum of the weighted values of the plurality of neighbor pixels by the read value to obtain an intermediate value; and<br>
right-shifting the intermediate value.<br>
28.	A data storage medium having machine-readable instructions describing<br><br><br>
the method according to claim 17.<br>
Dated this 28th day of December, 2006<br><br>
ABSTRACT<br>
"ADAPTIVE FILTERS AND APPARATUS, METHODS, AND SYSTEMS<br>
FOR IMAGE PROCESSING"<br>
An adaptive filter according to one embodiment includes an NN two-dimensional convolution, where N is an odd integer greater than one. Pixels of an image are filtered by moving the NN kernel across the image. At each pixel location, the kernel coefficients are determined by the image pixels within the NN region, such that the kernel coefficients may change from one pixel location to the next. Such a filter may be implemented to use a lookup table to approximate a floating-point operation.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=KDE2NDItTVVNTlAtMjAwNiktQ09SUkVTUE9OREVOQ0UoMTYtNi0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">(1642-MUMNP-2006)-CORRESPONDENCE(16-6-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=KDE2NDItTVVNTlAtMjAwNiktRk9STSAyNigxNi02LTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">(1642-MUMNP-2006)-FORM 26(16-6-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWFic3RyYWN0KDEzLTYtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-abstract(13-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWFic3RyYWN0KDI5LTEyLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-abstract(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWFic3RyYWN0KDYtNS0yMDA4KS5kb2M=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-abstract(6-5-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWFic3RyYWN0KDYtNS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-abstract(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWFic3RyYWN0LmRvYw==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNhbmNlbGxlZCBwYWdlcyg2LTUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-cancelled pages(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNsYWltcygyOS0xMi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-claims(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNsYWltcyhncmFudGVkKS0oMTMtNi0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-claims(granted)-(13-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNsYWltcyhncmFudGVkKS0oNi01LTIwMDgpLmRvYw==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-claims(granted)-(6-5-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNsYWltcyhncmFudGVkKS0oNi01LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-claims(granted)-(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNsYWltcy5kb2M=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNvcnJlc3BvbmRlbmNlKDIyLTctMjAxMCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-correspondence(22-7-2010).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1NVU1OUC0yMDA2LUNPUlJFU1BPTkRFTkNFKDI0LTctMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">1642-MUMNP-2006-CORRESPONDENCE(24-7-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1NVU1OUC0yMDA2LUNPUlJFU1BPTkRFTkNFKDI1LTYtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">1642-MUMNP-2006-CORRESPONDENCE(25-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNvcnJlc3BvbmRlbmNlKDYtNS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-correspondence(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNvcnJlc3BvbmRlbmNlKGlwbyktKDE1LTktMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-correspondence(ipo)-(15-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNvcnJlc3BvbmRlbmNlKGlwbyktKDYtNi0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-correspondence(ipo)-(6-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWNvcnJlc3BvbmRlbmNlLXJlY2VpdmVkLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-correspondence-received.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS0oMjktMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-description(complete)-(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRlc2NyaXB0aW9uKGdyYW50ZWQpLSgxMy02LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-description(granted)-(13-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRyYXdpbmcoMjktMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-drawing(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRyYXdpbmcoNi01LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-drawing(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRyYXdpbmcoZ3JhbnRlZCktKDEzLTYtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-drawing(granted)-(13-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMSg1LTYtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 1(5-6-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMSg2LTUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 1(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMTMoMjQtNy0yMDA5KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 13(24-7-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMTMoNS02LTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 13(5-6-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1NVU1OUC0yMDA2LUZPUk0gMTYoMjQtOS0yMDEwKS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-MUMNP-2006-FORM 16(24-9-2010).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMTgoMjktMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 18(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMihjb21wbGV0ZSktKDI5LTEyLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 2(complete)-(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMihncmFudGVkKS0oMTMtNi0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 2(granted)-(13-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMihncmFudGVkKS0oNi01LTIwMDgpLmRvYw==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 2(granted)-(6-5-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMihncmFudGVkKS0oNi01LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 2(granted)-(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMih0aXRsZSBwYWdlKS0oY29tcGxldGUpLSgyOS0xMi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 2(title page)-(complete)-(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMih0aXRsZSBwYWdlKS0oZ3JhbnRlZCktKDEzLTYtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 2(title page)-(granted)-(13-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMjYoMjktMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 26(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMygxMC01LTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 3(10-5-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMygxNS01LTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 3(15-5-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMygxNi01LTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 3(16-5-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMygyOS0xMi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 3(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gMyg2LTUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 3(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0gNSg2LTUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form 5(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tMi5kb2M=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWliLTMwNC5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-ib-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWliLTMxMS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-ib-311.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWliLTMzMi5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-ib-332.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMTAoMjktMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-isa-210(29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMjAucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-isa-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMzcucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-isa-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS1zZXBlcmF0ZSBzaGVldC0yMzcucGRm" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-form-pct-isa-seperate sheet-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LXBjdC1zZWFyY2ggcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-pct-search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1NVU1OUC0yMDA2LVBPV0VSIE9GIEFUVE9STkVZKDI1LTYtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">1642-MUMNP-2006-POWER OF ATTORNEY(25-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LXNwZWNpZmljYXRpb24oYW1lbmRlZCktKDYtNS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-specification(amended)-(6-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY0Mi1tdW1ucC0yMDA2LXdvIGludGVybmF0aW9uYWwgcHVibGljYXRpb24gcmVwb3J0ICgyOS0xMi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1642-mumnp-2006-wo international publication report (29-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="221060-a-cyanotropane-compound-of-formula-i-and-process-thereof.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="221062-a-method-and-device-for-simulating-multiple-devices.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>221061</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1642/MUMNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>35/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>29-Aug-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>13-Jun-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>29-Dec-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>QUALCOMM INCORPORATED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>5775 MOREHOUSE DRIVE, SAN DIEGO, CALIFORNIA 92121-1714, USA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HUNG, SZEPO</td>
											<td>7741 CORTE MARIN, CARLSBAD CALIFORNIA 92009, USA</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06T5/20</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2005/028559</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-03-16</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/583, 779</td>
									<td>2004-06-28</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>11/043,276</td>
									<td>2005-01-25</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/221061-apparatus-for-processing-an-image-and-a-method-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:03:30 GMT -->
</html>
