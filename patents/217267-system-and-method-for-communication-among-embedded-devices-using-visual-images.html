<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/217267-system-and-method-for-communication-among-embedded-devices-using-visual-images by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 11:33:58 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 217267:&quot;SYSTEM AND METHOD FOR COMMUNICATION AMONG EMBEDDED DEVICES USING VISUAL IMAGES.&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;SYSTEM AND METHOD FOR COMMUNICATION AMONG EMBEDDED DEVICES USING VISUAL IMAGES.&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A system and method for wireless communication among embedded devices using visual images. More specifically, a signal receiving device uses a visual recording device to locate the signal display screen, of a signal transmitting device by employing an alternating image detection method. An image decoder embedded in the signal receiving device decodes the signal received by the visual recording device. In addition, a method is employed for automatically controlling the position and orientation of the signal display device and the visual recording device. Advantageously, communication among embedded devices can be effectuated without the emission of potentially harmful radiation.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>SYSTEM AND METHOD FOR COMMUNICATION AMONG EMBEDDED DEVICES<br>
USING VISUAL IMAGES<br>
BACKGROUND OF THE INVENTION<br>
1.	TECHNICAL FIELD<br>
The present invention relates generally to communications and, more specifically, to a system and<br>
method for wireless communications among computers and<br>
i<br>
other pervasive processing devices.<br>
2.	DESCRIPTION OF THE RELATED ART<br>
As processing devices become less expensive and more , compact, the all-purpose desktop computer is giving way to, a new generation of embedded or "smart" devices such as video phones, interactive kiosks, and embedded household devices such as intelligent refrigerators, smart TVs, and intelligent dishwashers. Embedded devices are devices embedded with computing capability, making these devices "intelligent".<br>
As embedded devices become more widely used, they need to be able to communicate and exchange information with<br>
each other. For example, a video phone must be able to transmit and receive information with other video phones for effective communication.<br>
Communication between computers is typically through *'a communication network, in which computers are connected to each other or to peripherals by hard wire. This technique has a number of disadvantages. For" example, cable connection interfaces such as parallel printer ports, are limited in the distance they can reliably transfer data. In addition, coaxial cables, which are used for longer distance hard wire communications, require a relatively expensive terminal interface and therefore are not widely', used for connecting peripheral devices to computers. Moreover, when computers are hard-wired, any movement or change in the physical locations of the computers requires rewiring and reinstallation.<br>
The prior art teaches communication between embedded devices similar to the communication between computers, as well as existing wireless communication techniques. For • example, U.S. Patent 5,613,070 discloses, a system for providing improved communication to data and computer communications network using parallel and serial communication buses and master and local routers. Communication through said network includes use of a master system board with a plurality of subsystem boards.<br>
U.S. Patent 5,369,755 discloses a computer communication' bus system using multiple content induced transaction overlap (CITO) communication channels having a plurality of data transmission lines and a plurality of transmission nodes connected to the communication bus. Each transmission node has a data source providing multi-bit data to be transmitted on the communication bus, a plurality of data transformers for encoding or transforming the multi-bit data into different multi-bit encoded data formats, and a plurality of CITO transmitters for transmitting the transformed data on different data transmission lines using a content induced transaction overlap (CITO) protocol. Using the CITO protocol, the CITO-transmitters transmit the same data on each of the transmission lines in a different order.<br>
Another form of: communication between embedded devices is wireless communication. Existing wireless technology includes microwave systems, infrared laser systems, or spread spectrum.,However, all these approaches have various disadvantages, including health concerns due to radiation emission and interference of signals.<br>
Microwave is the oldest technology for wireless communications. For decades, most major telecommunications companies have used microwave systems within their networks for transmission of telephone communications, data and<br>
video. However, this form of wireless communication has" significant disadvantages. For example, microwave signals travel in straight lines and dp not readily diffract around barriers such as large man-mad^ structures, hills and<br>
i	4-<br>
mountains Some attenuation occurs when microwave energy passes through trees and frame houses. In addition, exposure to microwaves (a form of radiation) poses a health hazard and can cause nerve, fetal and DNA damage, cataracts, behavioral disturbances, changes to blood chemistry and impaired immune defense.<br>
For example, U.S. Patent 4,933,682 discloses a point to point microwave communication service antenna pattern with anull in an interfering direction that includes a microwave antenna system at each point directed at the other point, the radiation pattern of the antenna system at at least one point has a substantial null in the direction^ of an antenna of another microwave communication service to avoid an exchange of signals with the other service, the antenna system provided at said one point includes two antenna elements having substantially equal directional radiation patterns, so oriented and spaced apart a distance that is at least several wave length of the operating frequency of the elements so that the radiation patterns of the elements overlap producing,a net radiation pattern that results from interference of the patterns and the net<br>
pattern has a substantial lobe in the direction of the other point of  said service and a substantial null in the direction of an antenna of the other microwave communication service.<br>
Another form of wireless communications is spread spectrum. Spread spectrum uses; de-restricted radio frequencies and comes in two fprms direct sequencing and frequency hopping. Direct sequencing involves the use of a
Frequency hopping transmissions seek open frequencies and hop from frequency to frequency at split second intervals according to a specific and complicated mathematical function. Although this form of spread spectrum is more secure than direct sequencing, transmissions are secure only<br>
If the mathematical function is kept out of the hands of unauthorized people or entities. In addition, radio frequency emission is a type of electromagnetic energy or radiation, and thus is a possible health risk and cause for concern due to radiation exposure.<br>
U.S. Patent 5,854,985 discloses, an adaptive omni-modal radio apparatus and method for describing a frequency and protocol agile wireless communication product, and chipset for forming the same, including a frequency agile transceiver, a.digital interface circuit for interconnecting the radio transceiver with external devices, protocol agile operating circuit for operating the radio transceiver in accordance with one of the transmission protocols as determined by a protocol signal -and an adaptive control circuit for accessing a selected wireless communication network and for generating the frequency control signal and the protocol control signal in response to a user defined criteria.<br>
U.S. Patent 5,761,621 discloses a network and method of operating a network of wireless service providers adapted to interact with a plurality of omni-modal wireless products within a given geographic area in a manner to permit the wireless service providers to "borrow" radio frequencies from other wireless service providers within the same geographic region.<br>
Another form of wireless communication is the infrared<br>
laser communication system, which is used in thousands of<br>
installations world-wide for cable-free transmission of<br>
data, voice and video at speeds from T-l through 622 Mbps.<br>
These systems can provide a transparent and cost effective<br>
connection between buildings at distances up to 6000 meters<br>
(3.69 miles). These free-space,; optical laser<br>
communications systems are wireless connections through the<br>
atmosphere  "'	<br>
communicating via electromagnetic radiation. Infrared laser systems work basically the same as fiber optic cable except<br>
the beam is transmitted through open space rather than glass fiber. The systems operate by taking a standard data or telecommunications signal, converting it into a digitals-format and transmitting it through free space. Two parallel beams are used, one for transmission and one for reception!<br>
The carrier used for the transmission of this signal is infrared and is generated by either a high power LED or a laser diode. The disadvantage of this form of wireless communication, however, is the possible health risk due to emission of radiation, especially in enclosed spaces where there are numerous devices communicating with each other<br>
via infrared, which have frequencies higher than those of<br>
microwaves.	<br>
U.S. Patent 5,247,380 discloses an infrared data communications network in which groups of personal computers and associated peripherals may communicate by infrared signals with each other. The system utilizes a error correction and a packet switched protocol which allows any terminal to select communications with any other terminal or terminals without degradation of the error rate. Error free transmission is maintained by means of error correcting encoding and a handshake protocol. The packet switched protocol permits any terminal to function as a store and forward repeater thus making the system less susceptible to beam blockage. <br>
As embedded devices become more commonplace, homes, and offices are becoming occupied by greater numbers of various<br>
intelligent appliances which need to communicate with each : other. Using current wireless communication techniques may be a health hazard because of the high output of emitting , rays in relatively small enclosed spaces. In larger amounts, microwave and spread spectrum radio waves in. enclosed spaces can interfere with each other Accordingly,. an efficient, "accurate and non-emitting wireless<br>
communication technique which allows embedded devices to communicate with each other is highly desirable.<br>
SUMMARY OF THE:INVENTION<br>
The present invention is directed to a system and method for wireless communication among embedded devices using visual images. In one aspect of the present invention, a communication system is provided comprising a" signal transmitting device having a sending CPU and a sending memory; a generated signal template for encoding e signal pattern to be transmitted; a signal display for displaying the signal pattern encoded by said generated signal template; a signal display controller for controlling position and orientation of said signal display; a signal receiving device for communicating' with said signal transmitting device having a receiving memory and a receiving CPU;a visual recording device for sensing the signal pattern of the signal display; an image decoder for decoding the signal pattern; and   a visual recording: device controller for automatically controlling the orientation and zoom of said visual recording device, wherein communication between said signal transmitting device and said signal receiving device is established by the visual recording device detecting and decoding visual images displayed by the signal display.<br>
More specifically, a generated signal template embedded in;<br>
the signal transmitting device encodes visual signal<br>
patterns to be transmitted, and an image decoder embedded .<br>
in the signal receiving device ^decodes the signal received'<br>
by the visual recording device.	II<br>
In another aspect of the present invention, a method of visual communication between a signal transmitting device and a signal receiving device is provided comprising the steps of  adjusting a signal display of said -signal  ; transmitting device and a visual recording device of said ; signal receiving device and using an alternating display  process to establish a visual connection between said signal display and said visual recording device; encoding a signal pattern using a generated, signal.template of said signal transmitting device; visually transmitting the signal pattern through free space from the signal display of said1signal transmitting device; receiving an image of the signal pattern using the visual recording device of said signal receiving device; and decoding the signal pattern using an image decoder of the signal receiving device.<br>
In yet another aspect of the present invention, a sending controller automatically controls the position and orientation of the signal display such that the signal<br>
display establishes a visual connection with the visual recording device.<br>
In yet another aspect of the present invention, a receiving device controller automatically controls the orientation and zoom of the visual recording device. More specifically,- the pan, tilt and zoom of the visual recording device is automatically adjusted to view the signal display of the .signal transmitting device.<br>
in yet another aspect of the present invention, the signal receiving device locates the signal display of the signal transmitting device by detecting changing images displayed by the signal display. More specifically, the signal receiving device asks the signal transmitting device to alternate its signal display within a certain period of time The signal receiving device then locates the signal display by determining the largest area of an alternating image.<br>
An object of the invention is an improved system and method for wireless communication among embedded devices without harmful radiation.<br>
These and other aspects, features and advantages of the present invention will be described or become apparent from the following detailed description of the preferred embodiments, which is to-be read in connection with the accompanying drawings.<br>
BRIEF DESCRIPTION OF THE FIGURES<br>
FIG. 1 is a block diagram of a system architecture for<br>
providing communication between a signal transmitting device and a signal receiving device according to an embodiment of the present invention.<br>
FIG. 2 is a flow chart of a communication process for signal transmitting device T (170) according to an aspect of the present invention.,<br>
FIG. 3 is a flow chart of a communication process fo* signal receiving device R (175) according to an aspect of the present invention.<br>
FIG. 4 is a flow chart depicting an example of the process of step 201 of FIG. 2 in which the position and orientation of T" s signal display is determined according to an aspect of.the present invention.<br>
FIG. 4A is a flow chart depicting an example of the process of step 455 of FIG. 4 in which all possible candidate directions are generated.<br>
FIG. 5  is a flow chart depicting an example of the process of step 301 of FIG. 3 in which the position, orientation and zoom of the visual recording device of device R is determined according to an aspect of the present invention.<br>
FIG. 6 is a flow chart depicting an. example of the process of step 301 in which the pan, tilt, and zoom of the visual recording device of device R is automatically adjusted to view the signal display of T.<br>
FIG. 7 is a flow chart depicting an example of the process of step 671 of FIG. 6 in which a next viewing direction and angle size for device R is selected.<br>
FIG. 8 is a flow chart depicting.an example of the<br>
process of step 755 of FIG. 7 in which a viewing angle size<br>
for the visual recording device of device R is<br>
automatically selected.	<br>
FIG. 9 is a flow chart depicting an example of the process of step 775 of FIG. 7 in which a viewing direction for a given angle size of the visual recording device of device R is automatically selected according to an aspect of the present invention.<br>
FIG. 10 is a flow chart depicting an example of the process of step 657 of FIG. 6 in which changing images are detected to find the signal display of device T according to an aspect of the present invention.<br>
FIG. 11 is a flow chart depicting an example of an encoding strategy determination process of step 255 in FIG. 2 in which device T communicates with device R to determine<br>
T's signal encoding mechanism according to one aspect of the present invention.<br>
FIG. 12 is an exemplary illustration of the encoding strategy of FIG. 11.<br>
FIG. 13 is a flow chart depicting an example of the process of step 355 of FIG. 3 for building a position and radius size look-up table according to one aspect of the present invention.<br>
FIG. 14 is an exemplary illustration of a position and radius size look-up table of FIG. 13 according to an aspect of the present invention.<br>
FIG. 15 is a flow chart depicting an example of a visual communication process for device T and device R according to an aspect of the present invention.<br>
FIG 16 is a flow chart depicting an example of a visual communication signal decoding process for device R of step<br>
1555 of FIG. 15 according to an aspect of the present invention.<br>
FIG. 17 is an exemplary illustration of step 1655 of FIG. 16 according to an aspect of the present invention.<br>
FIG. 18 is an exemplary illustration of step 1675 of FIG. 16 according to an aspect of the present invention.<br>
DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS<br><br>
It is to be understood that the exemplary system modules and method steps described herein may be implemented in various forms of hardware, software, firmware, special purpose processors, or a combination thereof. Preferably, the present invention is implemented in software as an application program tangibly embodied on one or more program storage devices. The application program may be executed by any,machine, device or platform comprising suitable architecture. It is to be further understood that, because some of the constituent system modules and method steps depicted in the accompanying Figures are preferably implemented in software, the actual connections between the system components (or the process steps) may differ depending upon the manner in which the present invention is programmed. Given the teachings herein, one of ordinary skill in the<br>
related art will be able to contemplate these and similar implementations or configurations of the present invention.<br>
Referring now to FIG. 1, a block diagram illustrates :a system architecture for providing communication between a signal transmitting device and a signal receiving device according to an embodiment of the present invention. Signal<br>
transmitting device T 170 includes a sending CPU 151 and a signal display 150 that can display various patterns<br>
corresponding to signals to be transmitted to signal receiving device R 175. Generated signal template 155 generates these signal patterns to be transmitted, which are stored in sending memory 160. Sending controller 157 controls the position and orientation of the signal display 150.<br>
When transmission of the signal takes place, visual recording device 105, which includes a receiving CPU 125, takes a picture of an image 152 displayed by signal display 150. Receiving controller 117 controls the position and orientation of the visual recording device 105. The sending controller 157 and the receiving controller 117 enable adjustments to be made so that a visual connection can be established between the visual recording device and the signal display; in other words, so that the visual recording device and the signal display can locate each other. Frame grabber 110 then sends the image to receiving memory 145, where it is stored, as a stored image 135. An image analysis process is then commenced by image decoder 115 in which the signal is decoded.<br>
FIG. 2 is a flow chart depicting an example of a communication prpcess for signal transmitting device T in which T communicates with R according to one aspect of the present invention. This process includes the step of device<br>
T communicating with device R to determine the position and orientation of device T's signal display (201). The communication process of step 201 can be executed using existing wireless technology, or can be done manually by a person. In step 255, device T communicates with device R to determine T" s signal encoding strategy. After device T has; determined the position and orientation of its signal display and its signal encoding mechanism, it then performs a visual communication process 275, in which a signal is transmitted from T to R.<br>
FIG. 3 is a flow chart depicting an example of a communication process for signal receiving device R in which<br>
R communicates with T according to one aspect of the present invention. This process includes the step of device R communicating with device T to determine the position, orientation and zoom of device R's visual recording device (301). The communication process of step 301 can be carried out using existing wireless communication technology or can be done manually by a person. In step 355, device R communicates with device T to determine R's signal decoding mechanism. Following these steps, device.R performs a visual communication process (375) with device T, in which R receives and decodes a signal from T.<br>
The flow diagram of FIG. 4 depicts an example of the process of step 201 for determining position and orientation of the signal display 150 of T to enable a communication<br>
channel with device R according to an aspect of the present invention. Initially, the position of the signal transmitting device T is determined such that there are no occlusions (i.e., physical obstacles) between the signal transmitting device T and the signal receiving device R (step 401). Next, the orientation of the signal display 150 of the signal transmitting device T is adjusted so that the signal display of signal transmitting device T almost directly faces signal receiving device R (step 405). Various orientations are tried each time. A next candidate display orientation of the signal display of device T is then created (step 455). After a display orientation is selected, signal display 150 alternates its display, for example, between black and white and asks device R to detect the area of the alternating display or "changing blob"; at the same time, device R will detect the area of the alternating display based on the images taken by its visual recording device (step 465).<br>
The orientation of the signal display T when the area of the alternating display is largest is recorded by device<br>
R.(step 475). It is then ascertained whether enough orientations have been tried (step 485). If not, go back to step 455 and repeat the process thereon. If enough orientations have been tried, the orientation of the signal transmitting device T where the area calculated by the signal receiving device was largest is recorded by T (step 495). This is the orientation in which the signal display of T is perpendicular to the line connecting the center of the signal display of T and the center of the visual recording device of the signal receiving device R.<br>
An example of a detailed description depicting the process of step 455 is illustrated in FIG. 4A. FIG. 4A illustrates the process of generating all possible candidate directions (each candidate direction is then tried individually by the process depicted in FIG. 4 above). For example, if the orientation of the signal' display of T is <p> in step 405, all candidate directions are given by the exemplary process described as follows. (It is to be appreciated that the direction </p>
<p> can also be a candidate direction). First, the orientations of p* and t* are changed by 15 degrees; thus,<br>
p= -15°, t= -15° (step 403). Candidate directions are therefore- represented by </p>
<p t> (step 407) . Next, p is increased in increments of 1 degree (step 457) It is then ascertained whether p &gt; 15° (step 467). If no, then the process from step 407 is repeated. If yes, then Ap = 0 (step 477).<br>
Next, At is increased in increments of 1 degree (step 487). After each increase, it is ascertained whether At &gt; 15° (step 497) . If no, then the; process from step 407 is repeated. If yes, than all possible candidates have been created, and the process proceeds to step 495 of FIG. 4.<br>
Referring now to FIG. 5, a flow chart depicts an example of the process of step 301 of FIG. 3 in which the position, orientation and zoom,of the visual recording device of device R is determined according to an aspect of the present invention. Initially, the position of device R is determined such that there is no object occluding device R and device T (step 501). Next, the direction of the visual recording device of the signal receiving device R is adjusted such that it points to the center of the signal display of device T, and the zoom of the visual recording device is adjusted such that it gets a complete view of the signal transmitting device T (step 515), "complete view"<br>
here can mean a view that is not necessarily centered. The direction of the visual recording device is re-adjusted so that the center of the signal display of device T appears at the center of the image taken by the visual recording device of R (step 555). The zoom of the visual recording device is then re-adjusted so that an adequately sized view of the signal display of device T is attained ("adequately sized" or "adequate size" herein meaning that encoded information shown by the signal display is displayed at a size large enough to be analyzed by the visual recording device R).<br>
Referring now to FIG. 6 a flow chart depicts an example of the process of ,step!301 in which the pan, tilt and zoom of the visual recording device of R is automatically adjusted to view the signal display of T in an aspect of the present invention.<br>
Initially, device R (175) , sends signals to device T (170) asking T to alternate the color of T's signal display (150), for example, between black and white within a certain period of time, for example, every 5 seconds (step 601). Next, the angle of the visual recording device of R is set to be a first visual angle size (615). In addition, the viewing direction of the visual recording device of R is set to be the first direction (step 655). The images<br>
grabbed from the visual recording device of R are then examined to identify<br>
the alternating display of signal device T, or "changing blob" within the images (step 657). Device R then determines whether the alternating display of device T can be found from the images (step 659).<br>
If the signal display of device T cannot be found, a new viewing angle size and viewing direction can be selected for the visual recording device of R (step 671). It is then determined whether any occlusions are detected (step 677). If an occlusion is detected, step 501 is repeated. If there are no occlusions, then the process goes back to step 657 and repeats the steps thereon.<br>
If the signal display of device T is found, the viewing direction of the visual recording device of R can be adjusted so that the center of the signal display of T is at the center of the image grabbed from the visual recording device<br>
of R, and the zoom is adjusted so that the image of the signal display of T is large enough; "large enough" meaning for example, that the image of the display screen is at least 75% of the entire image being captured by the visual recording device of R, and that the image of the display screen is completely within the entire image captured by the visual recording device of R (step 675). Following this<br>
step, the process goes back to step 355 and repeats the steps thereon.<br>
For device R to find the signal display of T, R's visual recording device should ;try a variety of different viewing directions and viewing;angles. Referring now to FIG. 7, a<br>
flow chart depicts ah example of the process of step 671 of FIG. 6 in which a next viewing direction and angle size for<br>
device R is selected in an aspect of the present invention. As an illustration, for the current angle size <w> of the visual recording device R, the current viewing direction of the visual recording device is <p> (step 701) . Here for example, w represents the width of the visual recording device angle size, h represents the height of the visual recording device angle size; t, (tilt) is the angle between the vertical direction that is pointing up and the viewing-direction of the visual recording device, and p (pan) is the counterclockwise angle between the north direction (on a 2 dimensional plane) and the viewing direction of the visual recording device. Next, it is determined whether all possible viewing directions have been tried (step 715).<br>
If all;possible viewing directions have been tried, then a next viewing angle size <w> is chosen (step 755)<br>
It<br>
is then determined if all possible viewing angle sizes have<br>
been tried .(step 777) . If yes, then the result is that an<br>
occlusion has been detected (795). If no, then a next<br>
viewing angle size <w> is tried, the viewing direction<br>
being the<br>
initial viewing direction <p> (step 779).<br>
If all viewing directions ;have not been tried, then a next viewing direction </p>
<p> is chosen (step 775) . The<br>
angle size remains <w> and the viewing direction is <p><br>
(step 791).1<br>
In one aspect of the present invention, the angle size of the visual recording device of R is automatically selected. Referring now- to FIG. 8, a flow chart depicts an example of the process of step 755 of FIG. 7 in which a next viewing angle size for the visual recording device of R is<br>
automatically selected. Initially, the visual recording device of R determines an adequate size of a changing blob caused by the signal display of T (step 801). This determination can be made "off line," meaning that this step can be performed individually without going through<br>
the other steps in the process. For a largest angle size of the visual recording device of R, an acceptance distance range N0 and F0 between the visual recording device of R and the signal display of T is then determined (step 815). The acceptance distance range is the range in which the signal display of T can be identified and its encoded information analyzed; it is necessary to have an adequately sized view of the signal display. N0 represents the nearest distance at] which an adequately sized view of the signal display can be obtained, and F0 represents the farthest distance at which ah adequately sized view of the signal display can be obtained ("adequately sized" again meaning a size large enough such that the encoded information of the signal display can be analyzed). To illustrate, for a given acceptance distance range of the signal display of X for the visual recording device of Y, if X is outside this range then it will not be able to be detected by the visual recording device of Y with a very high degree of certainty. For example, for a fixed visual recording device angle size of Y, if the signal display of X is too close to Y, then the image of the display of X might be too large to put into the image screen of the visual recording device of Y. Thus, the distance between X and Y should be large enough so that Y can get a good view of X (i.e., the image of the. display of X should not be too large). The acceptance<br>
distance range can be calculated or experimentally obtained off line if the size of the signal display of T is known.<br>
Next, a candidate or the "ith" angle size of the visual recording device is determined ; (step 855). This can be automatically obtained using a formula that considers No, Fo, and the initial angle size of the visual recording device. The object of this angle size selection process is to choose a set of angle sizes or zoom such that they can cover the whole distance of the environment .without overlap. To cover the whole distance means that regardless of where T is, there will be one angle size of R that can get an "adequately sized" view of T. For example, for a given distance from the signal display, it is desirable to choose as few angle sizes ("zooms") as possible which still enable the visual recording device to get an adequately sized view of the signal display, i.e.,"adequately sized view", again meaning that the entire.image of the signal display is visible and at a size large enough such that the encoded information of the signal display can be analyzed.<br>
The following formulas can be used in selecting the ith<br>
angle size of the visual recording device, where [w,h] =? angle size and [w0,h0] represents an initial given angle<br>
In this way, we can get a set of angle sizes [w0,h0], [w^hj ,  [wq,hq] . The next angle size<br>
(Equation Removed)<br>
of the visual recording device is selected from the candidate angle sizes obtained from the above formulas (step 875).<br>
As shown above in step 775 of FIG.. 7, if all viewing directions of the visual recording device of R have not been tried, a new viewing direction can be selected. In one aspect of the present invention, a next viewing direction can be automatically selected by R. Referring now to FIG. 9, a flow<br>
chart depicts a method of automatically selecting the viewing direction, pan, and tilt of the visual recording device of R for a given camera angle size [w,h].<br>
For illustrative purposes, the first tilt selected is horizontal and the first pan can point in any direction P0 (step 900). The visual recording device of R is panned clockwise in the amount p(t); this p(t) can be a calculated<br>
amount. If the new value p(t) passed the original value P0, then the value of the pan for the current tilt (horizontal) is exhausted; if the value p(t) did not pass P0, then p(t) will be the next pan (step 901).  .<br>
In step 905, it is determined whether all pan directions have been exhausted. If yes, than it is then determined if the current tilt is horizontal (step 915) . If the current<br>
tilt is horizontal, the tilt is moved up for h/2; this is the next tilt (step 951). If the current tilt is not horizontal, it is then determined if the tilt is above horizontal (step 950). If the current tilt is above horizontal, the next tilt will be that which is below the horizontal and symmetrical to the current tilt (step 955). If the current tilt is below the horizontal, in step 971 a previous tilt that is symmetrical to the current tilt and<br>
above the horizontal is determined. The tilt is moved up for h/2 with respect to the previous tilt; if this tilt passes a vertical direction with respect to the original horizontal position, then the tilt is<br>
exhausted. If this tilt does not pass the said vertical direction, than it will be the next tilt value. It is then determined if the tilt is exhausted (step 975). In the case that the tilt is not exhausted, than step 901 is repeated to select a next pan, and the process thereon is then repeated. If the tilt is exhausted, then the process goes ? back to step 791 (step 976).<br>
The following equation can be used as an example of how to calculate the amount p(t), where p represents a pan for a given tilt t (step 901):<br>
(Equation Removed)<br>
In order for the visual recording device of R to detect the signal display of T, a method is employed in the present invention in which the signal display of T alternates its display, for example, between black and white, and an image difference is calculated for every consecutive alternating signal<br>
'display image. The image differences are then converted into black or white images and the visual recording device of R searches for and collects these alternating image difference "blobs". A blob is a group of adjoining pixels each having an identical pixel value. Referring now to FIG. 10, a flow chart depicts an example of a process of step 657 of FIG. 6, in which device R identifies and verifies an alternating image difference blob from the signal display -, of T.<br>
First, device R asks the signal transmitting device T<br>
to alternate its signal display between black and white within a certain period of time, for example 5 seconds (step 1001). The visual recording device of R then collects a number of images within an allotted time, for example, it collects 5 images every 4.5 seconds (step 1011). An image difference between each of the 5 consecutive images is then calculated; the result here would be 4 image differences (step 1015). To illustrate the process of calculating the image difference, for a given black and white image with resolution of 100X100 (having a total of 10,000 pixels), each pixel is identified by a coordinate (x,y), where 1 
of 0 means the pixel is black and a value of 255 means the pixel is white. For example, the center pixel of the image, 50X50, may have an image intensity of 0. The center pixel [50,50] for another image may have an image intensity of 255. Therefore, the difference between the/center pixels of the two images in this example is 255. For two images A and B, the image difference will be image C, where the intensities of any pixels of C will be the difference of the intensities of  corresponding pixels of A and B.<br>
If the images collected by the visual recording device are in color, then the image differences will also be in color. In this case, the pixel coordinate (x,y) has 3 component values for each of the colors red, green and blue, e.g.,(r,g,b). Each of the colors red, green and blue' has an intensity range of 0-255. For any coordinate (x,y), the image difference for two images at (x,y) will be (<br>
|r1-r2|, | g1-g2| , |b1-b2|). The resulting image C is still a color image, where (r,g,b) is the intensity for (x,y) at the first image and (r2,g2,b2) is the intensity for (x,y) at the second image.<br>
These color images are then changed into black and white images based on the intensity value for each pixel (step 1055). For example, it can be specified that when the image difference is greater than 55, the pixel is given a color of white; otherwise, it is black.<br>
For  example  to  illustrate,   if:<br>
(Equation Removed)<br>
(x,y) for the difference image is 0; otherwise it is 255. The alternating image differences or changing blobs are then collected, and the changing blob having the largest area is the image of the signal display of T (step 1075).<br>
FIG. 11 is the encoding strategy determination process for signal transmitting device T in one aspect of the present invention, as depicted in step 255 of FIG. 2. For illustrative purposes, the resolution of the display device of T is set to 50X50. This is denoted it as: A[50][50] (step 1101) . Next, the horizontal and vertical values of A[50][50] are divided by 10. The result is A[5][5], which has a total of 25 individual blocks 1201, as illustrated in FIG. 12. In this example, the intensity values of the pixels within each block are the same; they are either (255,255,255) or (0,0,0) (step 1105). Since each block has, for example, 2 different values here, black or white, the total information that can be encoded by the signal display is 225<br>
 (step 1115). Next, the information to be transmitted is assigned to one of the patterns represented by A[50] [50] (step 1155). The pattern for the assigned information is then displayed (step 1160).<br>
Referring now to FIG.,13, a. flow chart depicts an example of a method of building a position and radius look-up table in one aspect of the present invention. This flow chart is an example of a detailed method of determining the signal decoding mechanism of device R, as depicted in step 355. Initially, a block is selected from the signal display of T (step 1301). The intensity of the other blocks of the signal display of T are kept constant, while the intensity of the selected block is alternated (step 1305). The visual recording device of device R then grabs the images and uses the changing blob detection method (described in FIG. 10) to<br>
detect the blocks whose intensities are being alternated (step 1315). The center of the "changing blob" or alternating image, is found, and a circle is drawn around the blob such that all the pixels within the circle belong to the blob (step 1355). The center of the circle will be the center for the block in which it resides, and the radius of the circle will be the radius recorded in the position and radius look-up table. FIG. 14 depicts an<br>
exemplary illustration of the position and radius look-up table. In one preferred embodiment of the present invention, the radius of the circles should be no more than 0.35 of the length of one block.<br>
FIG. 15 is a flow chart depicting an example of a visual communication process for device T and device R as shown in steps 275 and 375 according to one aspect of the present invention. Initially, signal transmitting device T determines a signal S to be transmitted (step 1501). Device T then encodes the signal S into a two-dimensional pattern matrix I[m,n](r,g,b), where I = intensity, [m,n] represents the<br>
position of a pixel, and (r,g,b) represents red, green and blue respectively, (step 1505). Device T then displays the information presented by I[m,n](r,g,b) (step 1515) . Next, signal receiving device R takes an image of the information<br>
displayed by device T (step 1555). In step 1575, device R then decodes the signal by analyzing the image taken by the visual recording device of R.<br>
Referring now to FIG. 16, a flow chart depicts an example of a visual communication signal decoding process of device R as discussed in step 1575 of FIG. 15. In an<br>
illustrative example, the visual recording device of R takes an image B[w,h] which contains a displayed graphic user<br>
interface (GUI) from device T. The variables [w,h] represent width and height, respectively. As an example, the width and height of image B[w,h] is 150X150 (step 1601). Device R then determines the positions of the centers of the images-of all the blocks of the display of device T with the position and radius look-up table(step 1605). Circles are ; then drawn centered at the centers determined in step 1605 above; the radius of these circles should be read from the. position and radius look-up table (step 1615).<br>
For each circle, device R calculates the average image intensities among each pixel within the circle. The average image intensity is then calculated for every circle. These average intensities are taken as the average intensities of their respective blocks (step 1655). Device R then changes the average intensities of all the blocks into black and white intensities, each represented by (b_w_i). If a b_w_i is less than a certain amount, for example 50, it can be determined that the original block is encoded as blacky-otherwise, it is encoded as white (step 1675). The signal S transmitted from T is then decoded by device R by decoding <br>
"the above black and white pattern formed in step 1675 (step 1695).<br>
FIG. 17 depicts an exemplary illustration of step 1655, in which 1701 represents an entire view seen by the visual recording device R. 1705 depicts an exemplary image of the display screen of T, and the grey scale blocks 1710 depict blocks with their respective calculated average image intensities as discussed in step 1655.<br>
FIG. 18 depicts an exemplary illustration of step 1675, in which the average intensities of all the blocks is converted into black or white intensities. For example, blocks 1701 from FIG. 17 were changed to black here (1801),<br>
from greyscale in FIG. 17, since their b_w_i was less than 50.<br>
In one embodiment of the present invention, embedded devices can be devised in which existing- radio frequency communication technology coexists with the communication system- of the present invention. For example, an embedded device can use existing technology, e.g., spread spectrum, to make the initial contact with another embedded device, and when lack of occlusion has been determined between the embedded devices, they can then switch over to communication using visual images as described in the present invention. In another example, embedded devices may<br>
employ existing wireless communication technology when transmitting especially large amounts of data, but can then switch back to using the communication system of the present invention when transmitting smaller amounts of data. Advantageously, this reduces the overall amount of radiation a user is exposed to.<br>
It is to be, appreciated by those of ordinary skill in the art that the present invention may preferably employ mirrors to enable communication among embedded devices around occlusions or obstructions. In another embodiment of the present invention, embedded devices may transmit signals around moving obstructions, such as people walking around a room in the signal path of embedded devices.<br>
In another embodiment of the present invention, an embedded device, for example a computer, can have both a signal transmitting device and a signal receiving device.<br>
Although illustrative embodiments of the present invention have been described herein with reference to the accompanying drawings, it is to be understood that the present invention is not limited to those precise embodiments, and that various other changes and modifications may be affected therein by one skilled in the art without departing from the scope or spirit of the invention. All such changes and modifications are intended<br>
to be included within the scope of the invention as defined by the appended claims.<br>
WHAT IS CLAIMED IS:<br>
1. A communication system comprising:<br>
a signal transmitting device having<br>
a sending CPU and a sending memory;<br>
a generated signal template for generating a signal pattern to be transmitted;<br>
a signal display for displaying the signal pattern generated by said generated signal template;<br>
a signal display controller for controlling position and orientation of said signal display; a signal receiving device for communicating with said signal transmitting device having<br>
a receiving memory and a receiving CPU;<br>
a visual recording device for sensing the signal pattern of the signal display;<br>
an image decoder for decoding the signal pattern; and<br>
a visual recording device controller for automatically controlling the orientation and zoom of said visual recording device, wherein communication between said signal transmitting device and said signal receiving device is established by the visual recording device detecting and decoding visual images displayed by the signal display.'<br>
2. The system of claim 1, wherein a plurality of mirrors are used to transmit signal patterns between a signal transmitting device and a signal receiving device having obstructions between them.<br>
3.	A method of visual communication between a signal<br>
transmitting device and a signal receiving device<br>
comprising the steps of:<br>
adjusting a signal display of said signal transmitting device,and a visual recording device of said signal receiving device and using an alternating display process to establish a visual connection between said .signal display and said visual recording device;<br>
encoding a signal pattern using a generated signal template of said signal transmitting device;<br>
visually transmitting the signal pattern through free space from the signal display of said signal transmitting device;<br>
receiving an image of the signal pattern using the visual recording device of said signal receiving device; and<br>
decoding the signal pattern using an image decoder of the signal receiving device.<br>
4.	The method of claim 3, wherein the step of decoding<br>
includes the steps of:<br>
dividing the image of the signal pattern into a plurality of blocks;<br>
determining the centers of said blocks using a position and radius look-up table;<br>
creating a plurality of circles within said blocks having corresponding centers and radiuses determined by the position and radius look-up table;<br>
calculating average image intensities within said circles;<br>
using average image intensities within said circles as average image intensities of respective blocks of each of said circles;<br>
determining a plurality of black and white intensities from said average intensities of respective blocks of each of said circles using predetermined values; and  <br>
decoding a pattern created by said black and white intensities.<br>
5.   The method of claim 3, wherein the alternating display process comprises the steps of:<br>
alternating an image on the signal display of a. sending device within an allotted time;<br>
collecting a plurality of alternating images by a visual recording device of a receiving device within an allotted time;<br>
calculating image differences of consecutive alternating images;<br>
changing said image differences into black and white images based on pixel values; and<br>
collecting a plurality of blobs for each of said image differences using the visual recording device, wherein the blob having a largest area value represents the signal display.<br>
6.	The method of claim 3 wherein the step of adjusting the<br>
visual recording device includes the steps of:<br>
automatically adjusting pan and tilt of the visual recording device; and<br>
automatically adjusting an angle size of the recording device.<br>
7.	The method of claim 4, wherein the radiuses of said circles are 35% of the length of their respective blocks.<br>
8.	The method of claim 5, wherein the blobs are groups of adjoining pixels each having an identical pixel value.<br>
9.	The method of claim-6, wherein the step of automatically, adjusting the pan and tilt for a visual recording device comprises the steps of:<br>
selecting a first tilt and a first pan position;<br>
panning for a position that does not overlap said first pan position;<br>
checking if panning positions have been exhausted;<br>
determining whether the first tilt is in a horizontal position if all panning positions have been exhausted; and<br>
determining a new tilt by moving the first tilt upwards for the value of h/2  if the first tilt is in a horizontal position.<br>
10.	The method of claim 9, wherein if all panning positions have not been exhausted, the step of panning for a position that does not overlap the first pan position is repeated.<br>
11.	The method of claim 9, wherein if the first tilt is above the horizontal position, the new tilt will be below the horizontal position and symmetric, to the first tilt.<br>
12.	The method of claim 9, wherein if the first tilt is below the horizontal position, including the steps of:<br>
determining that the first tilt is not above the horizontal position;<br>
finding a previous tilt that is symmetric to the first tilt and is above the horizontal position;<br>
creating a possible tilt by moving the first tilt upwards for h/2  with respect to said previous tilt; and<br>
determining if said possible tilt passes a vertical direction with respect to the horizontal position.<br>
13.	The method of claim 12, wherein if said possible tilt passes the vertical position, then all tilts are exhausted.<br>
14.	The method of claim 12, wherein if said possible tilt does not pass the vertical position, then said possible tilt is a next tilt.<br>
15.	A program storage device readable by machine, tangibly embodying a program of instructions executable by machine to perform method steps for communication between processing devices comprising the steps of:<br>
generating a signal pattern using a generated signal template;<br>
displaying the signal pattern on a signal display;<br>
adjusting a visual recording device and said signal display and using an alternating display process to<br>
establish a visual connection between the processing devices;<br>
acquiring an image of the signal pattern using the visual recording device; and<br>
decoding the signal pattern with an image decoder.<br>
16.  The program storage device of claim 15, wherein the instructions for decoding includes instructions for:<br>
dividing the image of the signal pattern into a plurality of blocks;<br>
determining the centers of said blocks using a position and radius look-up table;<br>
creating a plurality of circles within said blocks having corresponding centers and radiuses determined by the position and radius look-up table;<br>
calculating average image intensities within,said circles;<br>
using average image intensities within said circles as average image intensities of respective blocks of said circles;<br>
determining a plurality of black and white intensities from said average intensities of respective blocks of said circles using predetermined values; and<br>
decoding a pattern created by said black and white intensities.<br>
17.	The program storage device of claim 15, wherein the<br>
alternating display process comprises the steps of:<br>
alternating an image on the signal display of a sending device within an allotted time;<br>
collecting a plurality of alternating images by a visual recording device of a receiving device within an allotted time;<br>
calculating image differences of consecutive alternating images;<br>
changing said image differences into black and white images based on pixel values; and<br>
collecting a plurality of blobs for each of said image differences with the visual recording device, wherein<br>
the blob having a largest area value represents the signal display.<br>
18.	The program storage device of claim 15, wherein the<br>
instructions for performing the step of adjusting the<br>
visual recording device and said signal display includes<br>
instructions for:<br>
automatically adjusting the pan and tilt of the visual recording device; and<br>
automatically adjusting the angle size of the recording device.<br>
19. The program storage device of claim 16, wherein the radiuses of said circles are.35% of the length of their respective blocks.<br>
'20. The program storage device of claim 17, wherein the blobs are groups of adjoining pixels each having an identical pixel value.<br>
21. The program storage device of claim 18, wherein the instructions for performing the step of automatically adjusting the pan and tilt for a visual recording device includes instructions for performing the steps of:<br>
selecting a first tilt and a first pan position;<br>
panning for a position that does not overlap said first pan position;<br>
checking if panning positions have been exhausted;<br>
determining whether the first.tilt is in a horizontal position if all panning positions have been exhausted; and<br>
determining a new tilt by moving the first tilt upwards for the value of h/2  if the first tilt is in a horizontal position.<br>
22.	The program storage device of claim 21, wherein if all panning positions have not been exhausted, the instructions for performing the step of panning for a position that does' not overlap the first pan position are repeated.<br>
23.	The program storage device of claim 21, wherein if the first tilt is above the horizontal position, the new tilt will be below the horizontal position and symmetric to the1' first tilt.<br>
24.	The program storage device of claim 21, wherein if the first tilt is below the horizontal position, including instructions for performing the steps of:<br>
determining that the first tilt is not above the horizontal position;<br>
finding a previous tilt that is symmetric to the first tilt and is above the horizontal position;<br>
creating a possible tilt by moving the first tilt Upwards for h/2  with respect to said previous tilt;<br>
determining if said possible tilt passes a vertical direction with respect to the horizontal position.<br>
25.	The program storage, device of claim 24, wherein if said possible tilt passes the vertical position, then all tilts are exhausted.<br>
26.	The program storage device of claim 24, wherein if said possible tilt does not pass the vertical position, then said possible tilt is a next tilt.<br><br><br><br><br><br><br><br><br><br><br>
We Claim:<br>
1.       A communication system comprising:-<br>
a signal transmitting device (170) having: -<br>
a sending CPU (151) arid sending memory (160).<br>
a generated signal template (155) for generating signal pattern to be<br>
transmitted;<br>
a signal display (150) for displaying the signal pattern generated by<br>
said generated signal template.<br>
a  signal  display controller     (157)  for controlling position and<br>
orientation of said signal display.<br>
a signal receiving device (175) for communicating with said signal<br>
transmitting device having: -<br>
a receiving memory (145) arid receiving CPU (125)<br>
a visual recording device (105) for sensing the signal pattern of the<br>
signal display.<br>
an image decoder (115) for decoding the signal pattern; and<br>
visual  recording   devices   controller  (117)   for  automatically  controlling  the<br>
orientation    and    zoom    of   said   visual    recording    devices,    wherein   the<br>
communication between said signal transmitting device and signal receiving<br>
device is established by the visual recording devices detecting and decoding<br>
visual images by the signal display.<br>
2.	The system as shown in claim 1, wherein a plurality of mirrors as used to transmit signal patterns between said signal-transmitting device and said signal-receiving device having obstruction between them.<br>
3.	A method of visual communication between a signal transmitting (170) device and a signal receiving device (175) for implementing the system as claimed in claim 1 comprising the step of:-<br>
adjusting a signal display of said signal transmitting (170) and a visual recording device (150) of said signal receiving device and using an alternating display process to establish a visual connection between said signal display and said visual recording device.<br>
encoding a signal pattern (155) using generated signal template of said signal-transmitting device.<br>
visually transmitting the signal pattern through free space from the signal display of said signal-transmitting device.<br>
receiving an image of the signal pattern using the visual recording device (105) of said signal receiving device, and decoding the signal pattern using an image decoder (115) of the signal-receiving device.<br>
The method as claimed in 3, wherein the step of decoding comprises the steps of: -<br>
dividing the image of the signal pattern into a plurality of blocks,<br>
determining the centers of said blocks using a position and radius look-up table<br>
creating plurality of circles within said blocks having corresponding centers and radiuses determined by the position and radius looks up table.<br>
calculating average image intensities within said circles<br>
using average image intensities within said circles as average image intensities of respective blocks of each of said circles.<br>
determining plurality of black and white intensities from said average intensities of respective blocks of each of said circles using predetermined values and<br>
decoding (115) a pattern created by said black &amp; white intensities.<br>
The method as claimed in claim 3, wherein the alternating display process comprises the steps of: -<br>
Alternating an image of the signal display of a sending device within an allotted time.<br>
Collecting plurality of alternating images by a visual recording device of receiving device within an allotted time.<br>
Calculating images differences of consecutive alternating images<br>
Changing said images differences into black &amp; white images based on pixels values and<br>
collecting plurality of blobs for each of said image differences using the visual recording device* wherein the blob having a largest area value represents the signal display.<br>
6.	The method as claimed in claim 3 wherein the step of adjusting the<br>
visual recording device comprises following steps: -<br>
Automatically adjusting pah and tilt of the visual recording device and<br>
automatically adjusting am \n angle size of the recording device<br>
7.	The method as claims in claim 4, wherein the radiuses of said circles are 35% of the length of their respective blocks.<br>
8.	The method as claimed in claim 5, wherein the blobs are groups of adjoining pixels each having an identical pixels value.<br>
9.	The method as claimed in claim 6, wherein the step of automatically adjusting the pan and tilt for a visual recording device comprises the steps of<br>
selecting a first tilt and a first pan position,<br>
panning for a position that does not overlap said first pan position,<br>
checking if panning position have been exhausted.<br>
determining whether the first tilt is in a horizontal position if all panning positions have been exhausted, and<br>
determining new tilt by moving the first tilt upwards for value of h/2 if the first tilt is in a horizontal position.<br>
10.	The method as claimed in claim 9, wherein if all panning positions have not been exhausted, the step of panning for a position that does not overlap the first pan position is repeated.<br>
11.	The method as claimed in claim 9 wherein if the first tilt is above the horizontal position, the hew tilt will be below the horizontal position and symmetric to the first tilt.<br>
12.	The method as claimed in claim 9 wherein if the first tilt is below the horizontal position comprising the steps of: -<br>
determining that the first tilt is not above the horizontal position;<br>
finding a previous tilt that is symmetric to the first tilt and is above the horizontal position.<br>
creating a possible tilt by moving the first tilt upwards for h/2 with respect to said previous tilt, and<br>
determining if said possible tilt passes a vertical direction with respect to the horizontal position.<br>
13.	The method as claimed in-claim 12, wherein if said possible tilt passes the vertical position, then all tilts are exhausted.<br>
14.	The method as claimed in claim 12, wherein if said possible tilt does not pass the vertical position, then said possible tilt is a next tilt.<br></p></w></p></w></w></p></w></p></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">820-del-2001-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">820-del-2001-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWNvbXBsZXRlIHNwZWNpZmljYXRpb24gKGdyYW5kZWQpLnBkZg==" target="_blank" style="word-wrap:break-word;">820-del-2001-complete specification (granded).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWNvcnJlc3BvbmRlbmNlLXBvLnBkZg==" target="_blank" style="word-wrap:break-word;">820-del-2001-correspondence-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLURFTC0yMDAxLURlc2NyaXB0aW9uIChDb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">820-DEL-2001-Description (Complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">820-del-2001-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWZvcm0tMTkucGRm" target="_blank" style="word-wrap:break-word;">820-del-2001-form-19.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLURFTC0yMDAxLUZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">820-DEL-2001-Form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODIwLWRlbC0yMDAxLXBldGl0aW9uLTEzOC5wZGY=" target="_blank" style="word-wrap:break-word;">820-del-2001-petition-138.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="217266-a-control-network-system-for-textile-machines.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="217268-a-process-for-preparing-oxidation-products-of-cyclohexane.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>217267</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>820/DEL/2001</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>38/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>19-Sep-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>26-Mar-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>31-Jul-2001</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INTERNATIONAL BUSINESS MACHINES CORPORATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>ARMONK,NEW YORK 10504,U.S.A</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>YE YIMING</td>
											<td>30 LAKE STREET,APT.61,WHITE PLAINS,NY 10603,U.S.A</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06K 7/10</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>09/640,284</td>
									<td>2000-08-16</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/217267-system-and-method-for-communication-among-embedded-devices-using-visual-images by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 11:33:59 GMT -->
</html>
