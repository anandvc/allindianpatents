<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/268906-method-and-apparatus-for-processing-an-audio-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:29:40 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 268906:METHOD AND APPARATUS FOR PROCESSING AN AUDIO SIGNAL</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR PROCESSING AN AUDIO SIGNAL</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method for processing an audio signal, comprising the steps of extracting an ancillary signal for generating the audio signal and an extension signal included in the ancillary signal from a received bit stream, reading length information for the extension signal, skipping decoding of the extension signal or not using a result of the decoding based on the length information, and generating the audio signal using the ancillary signal. Accordingly, in case of processing the audio signal by the present invention, it is able to reduce a corresponding load of operation to enable efficient processing and enhance a sound quality.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Method and Apparatus for Processing an Audio Signal<br>
TECHNICAL FIELD<br>
The present invention relates to a method and<br>
apparatus for processing an audio signal. Although the<br>
present invention is suitable for a wide scope of<br>
applications, it is particularly suitable for processing a<br>
residual signal.<br>
BACKGROUND ART<br>
Generally, an audio signal includes a downmix signal<br>
and an ancillary data signal. And, the ancillary data<br>
signal can include a spatial information signal and an<br>
extension signal. In this case, the extension signal means<br>
an additional signal necessary to enable a signal to be<br>
reconstructed close to an original signal in generating a<br>
multi-channel signal by upmixing the downmix signal. For<br>
instance, the extension signal can include a residual<br>
signal. The residual signal means a signal corresponding to<br>
a difference between an original signal and a coded signal.<br>
In multi-channel audio coding, the residual signal is<br>
usable for the following cases. For instance, the residual<br>
signal is usable for compensation of an artistic downmix<br>
signal or specific channel compensation in decoding. And,<br><br>
the residual signal is usable for both of the compensations<br>
as well. So, it is able to reconstruct an inputted audio<br>
signal into a signal closer to an original signal using the<br>
residual signal to enhance sound quality.<br>
DISCLOSURE OF THE INVENTION<br>
TECHNICAL PROBLEM<br>
However, if a decoder performs decoding on an<br>
extension signal unconditionally, although a sound quality<br>
may be improved according to a type of the decoder,<br>
complexity is raised and an operational load is increased.<br>
Moreover, since header information for an audio<br>
signal is not variable in general, the header information<br>
is inserted in a bit stream once only. But in case that the<br>
header information is inserted in the bit stream once only,<br>
if an audio signal needs to be decoded from a random timing<br>
point for broadcasting or VOD, it may be unable to decode<br>
data frame information due to the absence of the header<br>
information.<br>
TECHNICAL SOLUTION<br>
Accordingly, the present invention is directed to a<br>
method and apparatus for processing an audio signal that<br>
substantially obviate one or more of the problems due to<br><br>
limitations and disadvantages of the related art.<br>
An object of the present invention is to provide a<br>
method and apparatus for processing an audio signal, by<br>
which a processing efficiency of the audio signal is<br>
enhanced by skipping decoding of an extension signal.<br>
Another object of the present invention is to provide<br>
a method and apparatus for processing an audio signal, by<br>
which decoding of an extension signal is skipped using<br>
length information of the extension signal.<br>
Another object of the present invention is to provide<br>
a method and apparatus for processing an audio signal, by<br>
which an audio signal for broadcasting is reproducible from<br>
a random timing point.<br>
A further object of the present invention is to<br>
provide a method and apparatus for processing an audio<br>
signal, by which the audio signal is processed according to<br>
level information.<br>
ADVANTAGEOUS EFFECTS<br>
The present invention provides the following effects<br>
or advantages.<br>
First of all, in case of performing decoding, the<br>
present invention selectively decodes an extension signal<br>
to enable more efficient decoding. In case of performing<br><br>
decoding on an extension signal, the present invention is<br>
able to enhance a sound quality of an audio signal. In case<br>
of not performing decoding on an extension signal, the<br>
present invention is able to reduce complexity. Moreover,<br>
i even if decoding is performed on an extension signal, the<br>
present invention is able to enhance a sound quality by<br>
decoding a predetermined low frequency part only and also<br>
reduce a load of operation. Besides, in case of using an<br>
audio signal for broadcasting or the like, the present<br>
i invention is able to process an audio signal from a random<br>
timing point in a manner of identifying a presence or non-<br>
presence of header information within the audio signal.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
i  The accompanying drawings, which are included to<br>
provide a further understanding of the invention and are<br>
incorporated in and constitute a part of this specification,<br>
illustrate embodiments of the invention and together with<br>
the description serve to explain the principles of the<br>
 invention.<br>
In the drawings:<br>
FIG. 1 is a block diagram of an audio signal encoding<br>
apparatus and an audio signal decoding apparatus according<br>
to an embodiment of the present invention;<br><br>
FIG. 2 is a schematic block diagram of an extension<br>
signal decoding unit 90 according to an embodiment of the<br>
present invention;<br>
FIG. 3 and FIG. 4 are diagrams to explain fixed bits<br>
assignment of length information for an extension signal<br>
according to an embodiment of the present invention;<br>
FIG. 5 and FIG. 6 are diagrams to explain variable<br>
bits assignment of length information for an extension<br>
signal by depending on a length type according to an<br>
embodiment of the present invention;<br>
FIG. 7 and FIG. 8 are diagrams to explain adaptive<br>
bits assignment of length information for an extension<br>
signal by depending on a real length of the extension<br>
signal according to an embodiment of the present invention;<br>
FIG. 9 is a diagram of a bit stream structure<br>
configuring an audio signal with a downmix signal, an<br>
ancillary signal, and an extension signal according to an<br>
embodiment of the present invention;<br>
FIG. 10 is a diagram of a bit stream structure<br>
configuring an audio signal with an ancillary signal<br>
including an extension signal and a downmix signal<br>
according to an embodiment of the present invention;<br>
FIG. 11 is a diagram of a bit stream structure<br>
configuring an independent audio signal with a downmix<br><br>
signal or an ancillary signal according to an embodiment of<br>
the present invention;<br>
FIG. 12 is a diagram of a broadcasting streaming<br>
structure configuring an audio signal with a downmix signal<br>
and an ancillary signal according to an embodiment of the<br>
present invention;<br>
FIG. 13 is a flowchart of a method of processing an<br>
extension signal using length information of the extension<br>
signal in accordance with identification information<br>
indicating whether a header is included within an ancillary<br>
signal in case if using an audio signal for broadcasting or<br>
the like according to an embodiment of the present<br>
invention; and<br>
FIG. 14 is a flowchart of a method of decoding an<br>
extension signal selectively using length information of<br>
the extension signal in accordance with a level of a bit<br>
stream according to an embodiment of the present invention.<br>
BEST MODE FOR CARRYING OUT THE INVENTION<br>
Additional features and advantages of the invention<br>
will be set forth in the description which follows, and in<br>
part will be apparent from the description, or may be<br><br>
learned by practice of the invention. The objectives and<br>
other advantages of the invention will be realized and<br>
attained by the structure particularly pointed out in the<br>
written description and claims thereof as well as the<br>
appended drawings.<br>
To achieve these and other advantages and in<br>
accordance with the purpose of the present invention, as<br>
embodied and broadly described, a method for processing an<br>
audio signal according to the present invention includes<br>
the steps of extracting an ancillary signal for generating<br>
the audio signal and an extension signal included in the<br>
ancillary signal from a received bit stream, reading length<br>
information of the extension signal, skipping decoding of<br>
the extension signal or not using a result of the decoding<br>
based on the length information, and generating the audio<br>
signal using the ancillary signal.<br>
To further achieve these and other advantages and in<br>
accordance with the purpose of the present invention, a<br>
method for processing an audio signal includes the steps of<br>
acquiring sync information indicating a location of an<br>
ancillary signal for generating the audio signal and a<br>
location of an extension signal included in the ancillary<br>
signal, skipping decoding of the extension signal or not<br>
using a result of the decoding based on the sync<br><br>
information, and generating the audio signal using the<br>
ancillary signal.<br>
To further achieve these and other advantages and in<br>
accordance with the purpose of the present invention, an<br>
apparatus for processing an audio signal includes a signal<br>
extracting unit extracting an ancillary signal for<br>
generating the audio signal and an extension signal<br>
included in the ancillary signal from a received bit stream,<br>
an extension signal length reading unit reading length<br>
information of the extension signal, a selective decoding<br>
unit skipping decoding of the extension signal or not using<br>
a result of the decoding based on the length information,<br>
and an upmixing unit generating the audio signal using the<br>
ancillary signal.<br>
To further achieve these and other advantages and in<br>
accordance with the purpose of the present invention, an<br>
apparatus for processing an audio signal includes a sync<br>
information acquiring unit acquiring sync information<br>
indicating a location of an ancillary signal for generating<br>
the audio signal and a location of an extension signal<br>
included in the ancillary signal, a selective decoding unit<br>
skipping decoding of the extension signal or not using a<br>
result of the decoding based on the sync information, and<br>
an upmixing unit generating the audio signal using the<br><br>
ancillary signal.<br>
It is to be understood that both the foregoing<br>
general description and the following detailed description<br>
are exemplary and explanatory and are intended to provide<br>
further explanation of the invention as claimed.<br>
MODE FOR INVENTION<br>
Reference will now be made in detail to the preferred<br>
embodiments of the present invention, examples of which are<br>
illustrated in the accompanying drawings.<br>
FIG. 1 is a block diagram of an audio signal encoding<br>
apparatus and an audio signal decoding apparatus according<br>
to an embodiment of the present invention.<br>
Referring to FIG. 1, an encoding apparatus includes a<br>
downmixing unit 10, a downmix signal encoding unit 20, an<br>
ancillary signal encoding unit 30, an extension signal<br>
encoding unit 40, and a multiplexing unit 50.<br>
In case that multi-source audio signals XI, X2, ..., Xn<br>
are inputted to the downmixing unit 10, the downmixing unit<br>
10 generates a downmix signal by downmixing the multi-<br>
source audio signals. The downmix signal includes a mono<br>
signal, a stereo signal, or a multi-source audio signal.<br>
The source includes a channel and is described as the<br>
channel for convenience. In the specification of the<br><br>
present invention, explanation is made with reference to a<br>
mono or stereo downmix signal. Yet, the present invention<br>
is not limited to the mono or stereo downmix signal. The<br>
encoding apparatus is able to use an artistic downmix<br>
signal provided from an outside selectively and directly.<br>
In the course of downmixing, an ancillary signal can be<br>
generated from a multi-channel audio signal and an<br>
extension signal corresponding to additional information<br>
can be generated as well. In this case, the ancillary<br>
signal can include a spatial information signal and an<br>
extension signal. The generated downmix, ancillary and<br>
extension signals are encoded by the downmix signal<br>
encoding unit 20, the ancillary signal encoding unit 30,<br>
and the extension signal encoding unit 4 0 and are then<br>
transferred to the multiplexing unit 50, respectively.<br>
In the present invention, the ^spatial information'<br>
means the information necessary for the encoding apparatus<br>
to transfer a downmix signal generated from downmixing<br>
multi-channel signals to the decoding apparatus and<br>
necessary for the decoding apparatus to generate multi-<br>
channel signals by upmixing the downmix signal. The spatial<br>
information includes spatial parameters. The spatial<br>
parameters include CLD (channel level difference)<br>
indicating an energy difference between channels, ICC<br><br>
(inter-channel coherences) meaning a correlation between<br>
channels, CPC (channel prediction coefficients) used in<br>
generating three channels from two channels, etc. And, the<br>
^extension signal' means additional information necessary<br>
to enable a signal to be reconstructed closer to an<br>
original signal in generating multi-channel signals by<br>
upmixing the downmix signal by the decoding apparatus. For<br>
instance, the additional information includes a residual<br>
signal, an artistic downmix residual signal, an artistic<br>
tree extension signal, etc. In this case, the residual<br>
signal indicates a signal corresponding to a difference<br>
between an original signal and an encoded signal. In the<br>
following description, it is assumed that the residual<br>
signal includes a general residual signal or an artistic<br>
downmix residual signal for compensation of an artistic<br>
downmix signal.<br>
In the present invention, the downmix signal encoding<br>
unit 2 0 or the downmix signal decoding unit 70 means a<br>
codec that encodes or decodes an audio signal not included<br>
with an ancillary signal. In the present specification, a<br>
downmix audio signal is taken as an example of not included<br>
with the ancillary signal the audio signal. And, the<br>
downmix signal encoding unit 20 or the downmix signal<br>
decoding unit 70 is able to include MP3, AC-3, DTS, or AAC.<br><br>
If a codec function is performed on an audio signal, the<br>
downmix signal encoding unit 20 and the downmix signal<br>
decoding unit 70 can include a codec to be developed in the<br>
future as well as a previously developed codec.<br>
The multiplexing unit 50 can generate a bit stream by<br>
multiplexing a downmix signal, an ancillary signal, and an<br>
extension signal and then transfer the generated bit stream<br>
to the decoding apparatus. In this case, both of the<br>
downmix signal and the ancillary signal can be transferred<br>
in a bit stream format to the decoding apparatus.<br>
Alternatively, the ancillary signal and the downmix signal<br>
can be transferred in independent bit stream formats to the<br>
decoding apparatus, respectively. Details of the bit<br>
streams are explained in FIGs. 9 to 11.<br>
In case that it is unable to use previously<br>
transferred header information since an audio signal starts<br>
to be decoded from a random timing point instead of being<br>
decoded from the beginning like a bit stream for<br>
broadcasting, it is able to decode the audio signal using<br>
another header information inserted in the audio signal. In<br>
case of header information is lost in the course of<br>
transferring an audio signal, decoding should start from<br>
any timing point of receiving a signal. So, header<br>
information can be inserted in an audio signal at least<br><br>
once. If header information exists in a front part of an<br>
audio signal only once, it is unable to perform decoding<br>
due to the absence of the header information in case of<br>
receiving an audio signal at a random timing point. In this<br>
case, header information can be included according to a<br>
preset format (e.g., temporal interval, spatial interval,<br>
etc.). It is able to insert identification information<br>
indicating a presence or non-presence of header information<br>
in a bit stream. And, an audio signal is able to<br>
selectively include a header according to the<br>
identification information. For instance, an ancillary<br>
signal is able to selectively include a header according to<br>
the header identification information. Details of the bit<br>
stream structures are explained in FIGs. 9 to 12.<br>
The decoding apparatus includes a demultiplexing unit<br>
60, a downmix signal decoding unit 70, an ancillary signal<br>
decoding unit 80, an extension signal decoding unit 90, and<br>
an upmixing unit 100.<br>
The demultiplexing unit 60 receives a bit stream and<br>
then separates an encoded downmix signal, an encoded<br>
ancillary signal, and an encoded extension signal from the<br>
received bit stream. The downmix signal decoding unit 7 0<br>
decodes the encoded downmix signal. And, the ancillary<br>
signal decoding unit 8 0 decodes the encoded ancillary<br><br>
signal.<br>
Meanwhile, the extension signal can be included in<br>
the ancillary signal. It is necessary to efficiently decode<br>
the extension signal to efficiently generate multi-channel<br>
audio signals. So, the extension signal decoding unit 90 is<br>
able to selectively decode the encoded extension signal. In<br>
particular, the encoded extension signal can be decoded or<br>
the decoding of the encoded extension signal can be skipped.<br>
Occasionally, if the decoding of the extension signal is<br>
skipped, the encoded signal can be reconstructed to be<br>
closer to an original signal and coding efficiency can be<br>
raised.<br>
For instance, if a level of the decoding apparatus is<br>
lower than that of a bit stream, the decoding apparatus is<br>
unable to decode the received extension signal. So, the<br>
decoding of the extension signal can be skipped. Even if<br>
the decoding of the extension signal is available because<br>
the level of the decoding apparatus is higher than that of<br>
the bit stream, the decoding of the extension signal is<br>
able to be skipped by another information obtained from the<br>
audio signal. In this case, for instance, the another<br>
information may include information indicating whether to<br>
execute the decoding of the extension signal. This is<br>
explained in detail with reference to FIG. 14 later.<br><br>
And for instance, in order to omit the decoding of<br>
the extension signal, length information of the extension<br>
signal is read from the bit stream and the decoding of the<br>
extension signal is able to be skipped using the length<br>
information. Alternatively, it is able to skip the decoding<br>
of the extension signal using sync information indicating a<br>
position of the extension signal. This is explained in<br>
detail with reference to FIG. 2 later.<br>
The length information of the extension signal can be<br>
defined in various ways. For instance, fixed bits can be<br>
assigned, or variable bits can be assigned according to a<br>
predetermined length information type, or bits suitable for<br>
a length of a real extension signal can be adaptively<br>
assigned while the length of the extension signal is read.<br>
Details of the fixed bits assignment are explained in FIG.<br>
3 and FIG. 4. Details of the variable bits assignment are<br>
explained in FIG. 5 and FIG. 6. And, details of the<br>
adaptive bits assignment are explained in FIG. 7 and FIG. 8.<br>
The length information of the extension signal can be<br>
located within an ancillary data area. In this case, the<br>
ancillary data area indicates an area where additional<br>
information necessary to reconstruct a downmix signal into<br>
an original signal exists. For instance, a spatial<br>
information signal or an extension signal can be taken as<br><br>
an example of the ancillary data. So, the length<br>
information of the extension signal can be located within<br>
the ancillary signal or an extension area of the ancillary<br>
signal.<br>
In particular, the length information of the<br>
extension signal is located within a header extension area<br>
of the ancillary signal, a frame data extension area of the<br>
ancillary signal, or both of the header extension area and<br>
the frame data extension area of the ancillary signal.<br>
These are explained in detail with reference to FIGs. 9 to<br>
11 later.<br>
FIG. 2 is a schematic block diagram of an extension<br>
signal decoding unit 90 according to an embodiment of the<br>
present invention.<br>
Referring to FIG. 2, the extension signal decoding<br>
unit 90 includes an extension signal type information<br>
acquiring unit 91, an extension signal length reading unit<br>
92, and a selective decoding unit 93. And, the selective<br>
decoding unit 93 includes a level deciding unit 94, an<br>
extension signal information acquiring unit 95, and an<br>
extension signal information skipping unit 96. The<br>
extension signal decoding unit 90 receives a bit stream for<br>
an extension signal from the demultiplexing unit 60 and<br>
then outputs a decoded extension signal. Occasionally, the<br><br>
extension signal decoding unit 90 may not output an<br>
extension signal or can output an extension signal by<br>
padding a bit stream for the extension signal with zeros<br>
completely. For the case of not outputting an extension<br>
signal, a method of skipping the decoding of the extension<br>
signal is usable. The extension signal type acquiring unit<br>
91 acquires information indicating a type of an extension<br>
signal from a bit stream. For instance, the information<br>
indicating the type of the extension signal can include a<br>
residual signal, an artistic downmix residual signal, an<br>
artistic tree extension signal, or the like. In the present<br>
invention, the residual signal is a generic term of a<br>
general residual signal or an artistic downmix residual<br>
signal for compensation of an artistic downmix signal. The<br>
residual signal is usable for compensation of an artistic<br>
downmix signal in multi-channel audio signals or specific<br>
channel compensation in decoding. Optionally, the two cases<br>
are usable as well. If the type of the extension signal is<br>
decided by the extension signal type information, the<br>
extension signal length reading unit 92 reads a length of<br>
the extension signal decided by the type information of the<br>
extension signal. This can be achieved regardless of<br>
whether to perform the decoding of the extension signal.<br>
Once the length of the extension signal is read, the<br><br>
selective decoding unit 93 selectively performs decoding on<br>
the extension signal. This can be decided by the level<br>
deciding unit 94. In particular, the level deciding unit 94<br>
selects whether to execute the decoding of the extension<br>
signal by comparing a level of a bit stream to a level of a<br>
decoding apparatus. For instance, if the level of the<br>
decoding apparatus is equal to or higher than that of the<br>
bit stream, the decoding apparatus acquires information for<br>
the extension signal via the extension signal information<br>
acquiring unit 95 and then decodes the information to<br>
output the extension signal. The outputted extension signal<br>
is transferred to an upmixing unit 100 to be used in<br>
reconstruct an original signal or generating an audio<br>
signal. Yet, if the level of the decoding apparatus is<br>
lower than that of the bit stream, it is able to skip the<br>
decoding of the extension signal via the extension signal<br>
information skipping unit 96. In this case, it is able to<br>
skip the decoding of the extension signal based on the<br>
length information read by the extension signal length<br>
reading unit 92. Thus, in case that the extension signal is<br>
used, the reconstruction can be achieved to get closer to<br>
the original signal to enhance a sound quality. If<br>
necessary, it is able to reduce a load of operation of the<br>
decoding apparatus by omitting the decoding of the<br><br>
extension signal.<br>
As an example of the method of omitting the decoding<br>
of the extension signal in the extension signal information<br>
skipping unit 96, in case of using the length information<br>
of the extension signal, bit or byte length information of<br>
the extension signal can be inserted in data. And, the<br>
decoding can keep proceeding by skipping a bit field of the<br>
extension signal as many as a value obtained from the<br>
length information. Methods of defining the length<br>
 information of the extension signal shall be explained with<br>
reference to FIGs. 3 to 8.<br>
As another example of the method of omitting the<br>
decoding of the extension signal, it is able to skip the<br>
decoding of the extension signal based on sync information<br>
indicating a position of the extension signal. For instance,<br>
it is able to insert a sync word having predetermined bits<br>
in the point where the extension signal ends. The decoding<br>
apparatus keeps searching the bit field of the residual<br>
signal until finding a sync word of the extension signal.<br>
 Once finding the sync word, the decoding apparatus stops<br>
the search process and then keeps performing the decoding.<br>
In particular, it is able to skip the decoding of the<br>
extension signal until the sync word of the extension<br>
signal is found. As another example of a decoding method<br><br>
according to the selection, in case of performing the<br>
decoding of the extension signal, it is able to perform the<br>
decoding after parsing the extension signal. When the<br>
decoding of the extension signal is performed, the sync<br>
word of the extension signal is read but may not be<br>
available.<br>
FIG. 3 and FIG. 4 are diagrams to explain fixed bits<br>
assignment of length information for an extension signal<br>
according to an embodiment of the present invention.<br>
The length information of the extension signal can be<br>
defined by a bit or byte unit. If the length information is<br>
decided by the byte unit, this means that the extension<br>
signal is assigned bytes. FIG. 3 shows a method of defining<br>
length information for an extension signal in a simplest<br>
way. And, FIG. 4 shows the method shown in FIG. 3<br>
schematically. A syntax element for indicating the length<br>
information of the extension signal is defined and<br>
predetermined bits are assigned to the syntax element. For<br>
instance, 'bsResidualSignalLength' is defined as the syntax<br>
element and 16 bits are assigned as fixed bits. Yet, this<br>
method may consume a relatively considerable amount of bits.<br>
So, the methods shown in FIG. 5, FIG. 6, FIG. 7, and FIG. 8<br>
are explained as follows.<br>
FIG. 5 and FIG. 6 are diagrams to explain variable<br><br>
bits assignment of length information for an extension<br>
signal by depending on a length type according to an<br>
embodiment of the present invention.<br>
FIG. 5 shows a method of defining one more syntax<br>
element for defining how many bits are used for<br>
'bsResidualSignalLength' to further reduce bit consumption.<br>
And, FIG. 6 schematically illustrates the method shown in<br>
FIG. 5. For instance, . ^bsResidualSignalLengthtype' is newly<br>
defined as a length type. If a value of the<br>
'bsResidualSignalLengthtype' is zero, four bits are<br>
assigned to the ^bsResidualSignalLength'. If a value of the<br>
xbsResidualSignalLengthtype' is 1, eight bits are assigned<br>
to the ^bsResidualSignalLength' . If a value of the<br>
^bsResidualSignalLengthtype' is 2, twelve bits are assigned<br>
to the 'bsResidualSignalLength' . If a value of the<br>
vbsResidualSignalLengthtype' is 3, sixteen bits are<br>
assigned to the 'bsResidualSignalLength'. In this case, the .<br>
assigned bits are exemplary. So, bits different from the<br>
above-defined bits can be assigned. To reduce the bit<br>
consumption more than those of the above methods, the<br>
method shown in FIG. 7 and FIG. 8 is provided.<br>
FIG. 7 and FIG. 8 are diagrams to explain adaptive<br>
bits assignment of length information for an extension<br>
signal by depending on a real length of the extension<br><br>
signal according to an embodiment of the present invention.<br>
If an extension signal is inputted, a length<br>
information value of the extension signal can be read up to<br>
an initially determined value. If the length information<br>
value equals to a predetermined value, it is able to read<br>
additionally up to a further determined value. If the<br>
length information value equals to another predetermined<br>
value, it is able to read additionally up to another<br>
further determined value. In this case, if the length<br>
information value is not another predetermined value, the<br>
corresponding value is outputted as the length information<br>
value as it is. Thus, the length information of the<br>
extension signal is adaptively read according to a real<br>
data length, whereby the bit consumption can be maximally<br>
reduced. The example shown in FIG. 7 or FIG. 8 is explained.<br>
In FIG. 7, a residual signal is taken as an example<br>
of the extension signal. If a residual signal is inputted,<br>
four bits of the residual signal length are read. If a<br>
length information value (bsResidualSignalLength) is 24-l<br>
(=15) , eight bits are further read as a value of<br>
bsResidualSignalLengthl. If the length information value<br>
(bsResidualSignalLength) is (24-l) + (28-l) (=15+255), twelve<br>
bits are further read as a value of bsResidualSignalLength2.<br>
In the same manner, if the length information value<br><br>
(bsResidualSignalLength)  is  (24-l) + (28-l) + (212-1)<br>
(=15+255+4095), sixteen bits are further read as a value of<br>
bsResidualSignalLength3.<br>
FIG. 8 schematically illustrates another example of<br>
the adaptive bits assignment of length information for an<br>
extension signal.<br>
In FIG. 8, if an extension signal is inputted, four<br>
bits are preferentially read. If a value resulting from<br>
reading length information is smaller than four bits, the<br>
corresponding value becomes the length information. Yet, if<br>
a value resulting from reading length information is<br>
greater than four bits, eight bits are further read in<br>
addition. If the additionally read value is smaller than<br>
eight bits, a total read length information value<br>
corresponds to 12 (=4 + 8) . Yet, if the additionally read<br>
value is greater than eight bits, sixteen bits are further<br>
read in addition again. This is explained in detail as<br>
follows. First of all, if length information is inputted,<br>
four bits are read. A real length information value ranges<br>
0~14. If the length information value becomes 24-l (=15),<br>
the extension signal is further read in addition. In this<br>
case, the extension signal can be additionally read up to<br>
28-2 (=254) . Yet, if the length information value<br>
corresponds to a value smaller than 24-l (=15), a value of<br><br>
the read 0~(24-2) (=14) is outputted as it is. Once the<br>
length information value becomes (24-l) + (28-l) , the<br>
extension signal is further read in addition. In this case,<br>
the extension signal can be additionally read up to (216-1).<br>
Yet, if the length information value corresponds to a value<br>
smaller than 216-1, a value of the read 0~(216-l) (=14) is<br>
outputted as it is. In this case, as mentioned in the<br>
foregoing description, the assigned bits are exemplary for<br>
explanation. So, another bits different from the above-<br>
defined bits can be assigned.<br>
Meanwhile, the length information of the extension<br>
signal can be length information of the extension signal<br>
header or length information of the extension signal frame<br>
data. So, the length information of the extension signal<br>
can be located in a header area and/or a frame data area.<br>
Bit stream structures for this are explained with reference<br>
to FIGs. 9 to 12.<br>
FIG. 9 and FIG. 10 show embodiments of the present<br>
invention, in which a bit stream structure configuring an<br>
audio signal with a downmix signal, an ancillary signal,<br>
and an extension signal is shown.<br>
An audio signal includes a downmix signal and an<br>
ancillary signal. As an example of the ancillary signal, a<br>
spatial information signal can be taken. Each of the<br><br>
downmix signal and the ancillary signal is transferred by a<br>
frame unit. The ancillary signal can include header<br>
information and data information or can include data<br>
information only. Thus, in the file/general streaming<br>
structure configuring one audio signal, the header<br>
information precedes and is followed by the data<br>
information. For instance, in case of a file/general<br>
streaming structure configuring one audio signal with a<br>
downmix signal and an ancillary signal, a downmix signal<br>
header and an ancillary signal header can exist as the<br>
header information in a front part. And, downmix signal<br>
data and ancillary signal data can configure one frame as<br>
the data information behind the front part. In this case,<br>
by defining an extension area of the ancillary data, it is<br>
able to locate an extension signal. The extension signal<br>
can be included within the ancillary signal or can be used<br>
as an independent signal. FIG. 9 shows a case that the<br>
extension signal is used as the independent signal and FIG.<br>
10 shows a case that the extension signal is located in the<br>
extension area within the ancillary signal. So, in case<br>
that there exists the extension signal, in the file/general<br>
streaming structure, an extension signal header can exist<br>
as header information in the front part as well as the<br>
downmix header and the spatial information header. Behind<br><br>
the front part, extension signal data can be further<br>
included as data information as well as the downmix signal<br>
data and the ancillary signal data to configure one frame.<br>
Since the extension signal can be selectively decoded, it<br>
can be located at a last part of the frame or can<br>
consecutively exist right behind the ancillary signal. The<br>
length information explained in FIGs. 3 to 8 can exist<br>
within the header area of the extension signal and/or the<br>
data area of the extension signal. In this case, the length<br>
information existing within the header area (extension<br>
signal header) indicates the length information of the<br>
extension signal header, and the length information<br>
existing within the data area (extension signal data)<br>
indicates the length information of the extension signal<br>
data. Thus, the length information existing each of the<br>
areas is read from a bit stream and the decoding apparatus<br>
is able to skip the decoding of the extension signal based<br>
on the length information.<br>
FIG. 11 is a diagram of a bit stream structure<br>
configuring an independent audio signal with a downmix<br>
signal or an ancillary signal according to an embodiment of<br>
the present invention.<br>
An audio signal includes a downmix signal and an<br>
ancillary signal. As an example of the ancillary signal, a<br><br>
spatial information signal can be taken. The downmix signal<br>
and the ancillary signal can be transferred as independent<br>
signals, respectively. In this case, the downmix signal has<br>
a structure that a downmix signal header (downmix signal<br>
header®) as header information is located at a front part<br>
and that downmix signal datas (downmix signal data ©, ©,<br>
© , ..., © ) as data information follow the downmix signal<br>
header. Likewise, the ancillary signal has a structure that<br>
an ancillary signal header (ancillary signal header ©) as<br>
header information is located at a front part and that<br>
ancillary signal datas (ancillary signal data ®, ©, ..., ®)<br>
as data information follow the ancillary signal header.<br>
Since the extension signal can be included within the<br>
ancillary signal, a structure that the extension signal<br>
follows the ancillary signal data can be provided. So, an<br>
extension signal header © follows the ancillary signal<br>
header ® and the extension signal data © follows the<br>
ancillary signal data © . Likewise, the extension signal<br>
data © follows the ancillary signal data ©. In this case,<br>
length information of the extension signal can be included<br>
in each of the extension signal header ® , the extension<br>
signal data ©, and/or the extension signal data ©, ..., and<br>
Meanwhile, unlike the file/general streaming<br><br>
structure, in case that it is unable to use previously<br>
transferred header information since an audio signal is<br>
decoded from a random timing point instead of being decoded<br>
from the beginning, it is able to decode the audio signal<br>
using another header information included in the audio<br>
signal. In case of using an audio signal for broadcasting<br>
or the like or losing header information in the course of<br>
transferring an audio signal, decoding should start from<br>
any moment of receiving a signal. So, it is able to improve<br>
coding efficiency by defining identification information<br>
indicating whether the header exits. A streaming structure<br>
for broadcasting is explained with reference to FIG. 12 as<br>
follows.<br>
FIG. 12 is a diagram of a broadcasting streaming<br>
structure configuring an audio signal with a downmix signal<br>
and an ancillary signal according to an embodiment of the<br>
present invention.<br>
In case of a broadcast streaming, if header<br>
information exists in a front part of an audio signal once<br>
only, it is unable to execute decoding due to the absence<br>
of header information in case of receiving an audio signal<br>
at a random timing point. So, the header information can be<br>
inserted in the audio signal once at least. In this case,<br>
the header information can be included according to a<br><br>
preset format (e.g., temporal interval, spatial interval,<br>
etc.). In particular, the header information can be<br>
inserted in each frame, periodically inserted in each frame<br>
with a fixed interval, or non-periodically inserted in each<br>
frame with a random interval. Alternatively, the header<br>
information can be inserted once according to a fixed time<br>
interval (e.g., 2 seconds).<br>
A broadcast streaming structure configuring one audio<br>
signal has a structure that at least once header<br>
information is inserted between data informations. For<br>
instance, in case of a broadcast streaming structure<br>
configuring one audio signal, a downmix signal comes first<br>
and an ancillary signal follows the downmix signal. Sync<br>
information for distinguishing between the downmix signal<br>
and the ancillary signal can be located at a front part of<br>
the ancillary signal. And, identification information<br>
indicating whether header information for the ancillary<br>
signal exists can be located. For instance, if header<br>
identification information is 0, a next read frame only has<br>
a data frame without header information. If the header<br>
identification information is 1, a next read frame has both<br>
header information and a data frame. This is applicable to<br>
the ancillary signal or the extension signal. These header<br>
informations may be the same of the header information<br><br>
having been initially transferred or can be variable. In<br>
case that the header information is variable, new header<br>
information is decoded and data information transferred<br>
after the new header information is then decoded according<br>
to the decoded new header information. In case that the<br>
header identification information is 0, a transferred frame<br>
only has a data frame without header information. In this<br>
case, to process the data frame, previously transferred<br>
header information can be used. For instance, if the header<br>
identification information is 1 in FIG., 12, an ancillary<br>
signal header © and an extension signal header © can exist.<br>
Yet, if a next incoming frame has no header information<br>
since the header identification information set to 0, it is<br>
able to use information of the extension signal header ©<br>
previously transferred to process extension signal data ©.<br>
FIG. 13 is a flowchart of a method of processing an<br>
extension signal based on length information of the<br>
extension signal in accordance with identification<br>
information indicating whether a header is included within<br>
an ancillary signal in case of using an audio signal for<br>
broadcasting or the like according to an embodiment of the<br>
present invention.<br>
Referring to FIG. 13, an ancillary signal for an<br>
audio signal generation and an extension signal included in<br><br>
the ancillary signal are extracted from a received bit<br>
stream (1301). The extension signal can be included within<br>
the ancillary signal. Identification information indicating<br>
whether a header is . included in the ancillary signal is<br>
extracted (1303). For instance, if the header<br>
identification information is 1, it indicates that an<br>
ancillary signal header is included in the ancillary signal.<br>
If the header identification information is 0, it indicates<br>
that an ancillary signal header is not included in the<br>
ancillary signal. In case that the extension signal is<br>
included in the ancillary signal, if the header<br>
identification information is 1, it indicates that an<br>
extension signal header is included in the extension signal.<br>
If the header identification information is 0, it indicates<br>
that an extension signal header is not included in the<br>
extension signal. It is decided that whether a header is<br>
included in the ancillary signal according to the header<br>
identification information (1305). If the header is<br>
included in the ancillary signal, length information is<br>
extracted from the header (1307). And, it is able to skip<br>
decoding of the extension signal based on the length<br>
information (1309). In this case, the header plays a role<br>
in enabling each ancillary signal and/or each extension<br>
signal to be interpreted. For instance, the header<br><br>
information can include information for a residual signal,<br>
length information for a residual signal, sync information<br>
indicating a location of a residual signal, a sampling<br>
frequency, a frame length, the number of a parameter band,<br>
tree information, quantization mode information, ICC<br>
(inter-channel correlation), parameter smoothing<br>
information, gain information for a clipping-prevention,<br>
QMF (quadrature mirror filter) associated information, etc.<br>
Moreover, if the header is not included in the ancillary<br>
signal according to the header identification information,<br>
it is able to skip decoding of the extension signal based<br>
on the previously extracted length information for the<br>
header (1311).<br>
FIG. 14 is a flowchart of a method of decoding an<br>
extension signal selectively based on length information of<br>
the extension signal according to an embodiment of the<br>
present invention.<br>
A profile means that technical elements for algorithm<br>
in a coding process are standardized. In particular, the<br>
profile is a set of technical elements necessary to decode<br>
a bit stream and corresponds to a sort of a sub-standard. A<br>
level defines a range of the technical elements, which are<br>
prescribed in the profile, to be supported. In particular,<br>
the level plays a role in defining capability of a decoding<br><br>
apparatus and complexity of a bit stream. In the present<br>
invention, level information can include definitions for<br>
the profile and level. A decoding method of an extension<br>
signal can selectively vary according to the level<br>
information of the bit stream and the level information of<br>
the decoding apparatus. For instance, even if the extension<br>
signal exists in a transferred audio signal, decoding of<br>
the extension signal may be or may not be executed as a<br>
result of deciding the level information. Moreover,<br>
although the decoding is executed, a predetermined low<br>
frequency part can be used only. Besides, it is able to<br>
skip the decoding of the extension signal as many as length<br>
information of the extension signal in order not to execute<br>
the decoding of the extension signal. Alternatively,<br>
although the extension signal is entirely read, the<br>
decoding cannot be executed. Furthermore, a portion of the<br>
extension signal is read, decoding can be performed on the<br>
read portion only, and the decoding cannot be performed on<br>
the rest of the extension signal. Alternatively, the<br>
extension signal is entirely read, a portion of the<br>
extension signal can be decoded, and the rest of the<br>
extension signal cannot be decoded.<br>
For instance, referring to FIG. 14, an ancillary<br>
signal for generating an audio signal and an extension<br><br>
signal included in the ancillary signal can be extracted<br>
from a received bit stream (1410) . And, information for the<br>
extension signal can be extracted. In this case, the<br>
information for the extension signal may include extension<br>
data type information indicating a data type of the<br>
extension signal. For instance, the extension data type<br>
information includes residual coding data, artistic downmix<br>
residual coding data, artistic tree extension data, or the<br>
like. So, the type of the extension signal is decided and<br>
it is able to read length information of the extension<br>
signal from an extension area of the audio signal (1420) .<br>
Subsequently, a level of the bit stream is decided. This<br>
can be decided with reference to following information. For<br>
instance, if the type of the extension signal is the<br>
residual coding data, the level information for the bit<br>
stream can include the number of output channels, a<br>
sampling rate, a bandwidth of a residual signal, and the<br>
like. So, if the above-explained level informations of the<br>
bit stream are inputted, they are compared to level<br>
information for a decoding apparatus to decide whether the<br>
extension signal will be decoded (1430). In this case, a<br>
level of the decoding apparatus can be previously set. In<br>
general, the level of the decoding apparatus should be<br>
equal to or greater than a level of the audio signal. This<br><br>
is because the decoding apparatus should be able to decode<br>
the transferred audio signal entirely. Yet, in case that<br>
limitation is put on the decoding apparatus (e.g., in case<br>
that the level of the decoding apparatus is smaller than<br>
that of the audio signal), decoding is occasionally<br>
possible. Yet, a corresponding quality may be degraded. For<br>
instance, if the level of the decoding apparatus is lower<br>
than that of the audio signal, the decoding apparatus may<br>
be unable to decode the audio signal. Yet, in some cases,<br>
the audio signal can be decoded based on the level of the<br>
decoding apparatus.<br>
In case that the level of the decoding apparatus is<br>
decided lower than that of the bit stream, it is able to<br>
skip the decoding of the extension signal based on the<br>
length information of the extension signal (1440). On the<br>
other hand, in case that the level of the decoding<br>
apparatus is equal to or higher than that of the bit stream,<br>
it is able to execute the decoding of the extension signal<br>
(1460). Yet, although the decoding of the extension signal<br>
is executed, the decoding can be performed on a<br>
predetermined low frequency portion of the extension signal<br>
only (1450) . For instance, there is a case that since the<br>
decoding apparatus is a low power decoder, if the extension<br>
signal is entirely decoded, efficiency is degraded, or<br><br>
since the decoding apparatus is unable to decode the entire<br>
extension signal a predetermined low frequency portion of<br>
the extension signal is usable. And, this is possible if<br>
the level of the bit stream or the level of the decoding<br>
apparatus meets a prescribed condition only.<br>
INDUSTRIAL APPLICABILITY<br>
Accordingly, various environments for encoding and<br>
decoding signals exist in general and there can exist<br>
various methods of processing signals according to the<br>
various environment conditions. In the present invention, a<br>
method of processing an audio signal is taken as an example,<br>
which does not restrict the scope of the present invention.<br>
In this case, the signals include audio signals and/or<br>
video signals.<br>
While the present invention has been described and<br>
illustrated herein with reference to the preferred<br>
embodiments thereof, it will be, apparent to those skilled<br>
in the art that various modifications and variations can be<br>
made therein without departing from the spirit and scope of<br>
the invention. Thus, it is intended that the present<br>
invention covers the modifications and variations of this<br>
invention that come within the scope of the appended claims<br>
and their equivalents.<br><br>
What is Claimed is:<br>
1.	A method for processing an audio signal,<br>
comprising the steps of:<br>
extracting an ancillary signal for generating the<br>
audio signal and an extension signal included in the<br>
ancillary signal from a received bit stream;<br>
reading length information for the extension signal;<br>
skipping decoding of the extension signal or not<br>
using a result of the decoding based on the length<br>
information; and<br>
generating the audio signal using the ancillary<br>
signal.<br>
2.	The method of claim 1, wherein the extension<br>
signal is a residual signal.<br>
3.	The method of claim 1 or claim 2, wherein the<br>
length information of the extension signal is assigned<br>
fixed bits.<br>
4.	The method of claim 1 or claim 2, wherein the<br>
length information of the extension signal is assigned<br>
variable bits according to length type information of the<br><br>
extension signal.<br>
5.	The method of claim 1 or claim 2, wherein the<br>
length information of the extension signal is assigned<br>
adaptive bits according to a length of the extension signal.<br>
6.	A method of processing an audio signal,<br>
comprising the steps of:<br>
acguiring sync information indicating a location of<br>
an ancillary signal for generating the audio signal and a<br>
location of an extension signal included in the ancillary<br>
signal;<br>
skipping decoding of the extension signal or not<br>
using a result of the decoding based on the sync<br>
information; and<br>
generating the audio signal using the ancillary<br>
signal.<br>
7.	The method of claim 6, wherein the sync<br>
information indicates a start point and/or an end point of<br>
the extension signal.<br>
8.	The method of claim 6, wherein the extension<br>
signal is a residual signal.<br><br>
9.	An apparatus for processing an audio signal,<br>
comprising:<br>
a signal extracting unit extracting an ancillary<br>
signal for generating the audio signal and an extension<br>
signal included in the ancillary signal from a received bit<br>
stream;<br>
an extension signal length reading unit reading<br>
length information of the extension signal;<br>
a selective decoding unit skipping decoding of the<br>
extension signal or not using a result of the decoding<br>
based on the length information; and<br>
an upmixing unit generating the audio signal using<br>
the ancillary signal.<br>
10.	An apparatus for processing an audio signal,<br>
comprising:<br>
a sync information acquiring unit acquiring sync<br>
information indicating a location of an ancillary signal<br>
for generating the audio signal and a location of an<br>
extension signal included in the ancillary signal;<br>
a selective decoding unit skipping decoding of the<br>
extension signal or not using a result of the decoding<br>
based on the sync information; and<br><br>
an upmixing unit generating the audio signal using the<br>
ancillary signal.<br><br>
A method for processing an audio signal, comprising the steps of extracting an ancillary signal for generating the audio signal and an extension signal included in the ancillary signal from a received bit stream, reading length information for the extension signal, skipping decoding of the extension signal or not using a result of the decoding based on the length information, and generating the audio signal using the ancillary signal. Accordingly, in case of processing the audio signal by the present invention, it is able to reduce a corresponding load of operation to enable efficient processing and enhance a sound quality.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=+9pNqPK0eHC53PgFY2x3Uw==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=+9pNqPK0eHC53PgFY2x3Uw==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="268905-methods-systems-and-apparatus-for-object-invocation-across-protection-domain-boundaries.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="268907-apparatus-and-method-for-connection-re-establishment-in-mobile-communication-system-environment.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>268906</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2325/KOLNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>39/2015</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>25-Sep-2015</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>22-Sep-2015</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>11-Jun-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>LG ELECTRONICS INC.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>20, YOIDO-DONG, YOUNGDUNGPO-GU, SEOUL</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>PANG HEE SUCK</td>
											<td>101, 4/7, #14-10, YANGJAE-DONG, SEOCHO-GU, SEOUL 137-130</td>
										</tr>
										<tr>
											<td>2</td>
											<td>LIM JAE HYUN</td>
											<td>609, PARKVILLE OFFICETEL, # 1062-20, NAMHYEON-DONG, GWANAK-GU, SEOUL 151-801</td>
										</tr>
										<tr>
											<td>3</td>
											<td>OH HYEN O</td>
											<td>306-403, HANSIN APT., GANGSEON-MAEUL 3-DANJI, JUYEOP 1-DONG, ILSAN-GU, GOYANG-SI, GYEONGGI-DO 411-744</td>
										</tr>
										<tr>
											<td>4</td>
											<td>JUNG YANG WON</td>
											<td>2-803, YEOKSAM HANSHIN APT., DOGOK-DONG, GANGNAM-GU, SEOUL 135-270</td>
										</tr>
										<tr>
											<td>5</td>
											<td>KIM DONG SOO</td>
											<td>502, WOOLIM VILLA, #602-265, NAMHYEON-DONG, GWANAK-GU, SEOUL 151-801</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H03M 7/30</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2007/000866</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2007-02-16</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10-2007-0013364</td>
									<td>2007-02-08</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/803825</td>
									<td>2006-06-02</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>3</td>
									<td>60/791907</td>
									<td>2006-04-14</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>4</td>
									<td>60/775775</td>
									<td>2006-02-23</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/268906-method-and-apparatus-for-processing-an-audio-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:29:41 GMT -->
</html>
