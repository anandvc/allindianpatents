<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/225762-method-for-displaying-multimedia-data by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:22:22 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 225762:METHOD FOR DISPLAYING MULTIMEDIA DATA</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD FOR DISPLAYING MULTIMEDIA DATA</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>An apparatus and a method for displaying audio and video data, and a storage medium for storing the method thereon. The apparatus for displaying audio and video data constituting multimedia data described in MPV format, ascertains whether an asset selected by a user comprises a single video data and at least one or more audio data, extracts reference information to display the video data and the audio data and then displays the extracted video data, using the reference information, and extracts at least one or more audio data from the reference information and then sequentially displays them according to a predetermined method while the video data is being displayed.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM 2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970)<br>
&amp;<br>
THE PATENTS RULES, 2003<br>
COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
'APPARATUS AND METHOD FOR DISPLAYING AUDIO AND VIDEO<br>
DATA, AND STORAGE MEDIUM RECORDING THEREON A PROGRAM TO<br>
EXECUTE THE DISPLAYING METHOD'<br>
SAMSUNG ELECTRONICS CO. LTD., 416 Maetan-dong, Yeongtong-gu, Suwon-si, Gyeonggi-do, Republic of Korea,<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br><br>
Technical   Field<br>
[1]	The present invention relates to an apparatus and a method for displaying audio<br>
and video data (hereinafter referred to as 'AV data') and a storage medium on which a program to execute the displaying method is recorded, and more particularly to, management of audio and video data among multimedia data in the format of Multi-Photo Video or MusicPhoto Video (both of which are hereinafter referred to as 'MPV') and provision of the same to users.<br>
Background   Art<br>
[2]	MPV is an industrial standard specification dedicated to multimedia titles,<br>
published by the Optical Storage Technology Association (hereinafter referred to as 'OSTA'), an international trade association established by optical storage makers in 2002. Namely, MPV is a standard specification to provide a variety of music, photo and video data more conveniently or to manage and process the multimedia data. The definition of MPV and other standard specifications are available for use through the official web site ("www.osta.org') of OSTA.<br>
[3]	Recently, media data comprising digital pictures, video, digital audio, text and the<br>
like are processed and played by means of personal computers (PC). Devices for playing the media content, e.g., digital cameras, digital camcorders, digital audio players (namely, digital audio data playing devices such as Moving Picture Experts Group Layer-3 Audio (MP3), Window Media Audio (WMA) and so on) have been in frequent use, and various kinds of media data have been produced in large quantities accordingly.<br>
[4]	However, personal computers have mainly been used to manage multimedia data<br>
produced in large quantities; in this regard file-based user experience has been requested. In addition, when multimedia data is produced on a specified product, attributes of the data, data playing sequences, and data playing methods are produced depending upon the multimedia data. If they are accessed by the personal computers, the attributes are lost and only the source data is transferred. In other words, there is a<br>
-2.-<br><br>
WO 2005/029490		PCT7KR2004/002309<br>
very weak interoperability relative to data and attributes of the data between household electric goods, personal computers and digital content playing devices.<br>
5.                     An example of the weak interoperability will be described. A picture is captured using a digital camera, and data such as the sequence for an attribute slide show, determined by use of a slideshow function to identify the captured picture on the digital camera, time intervals between pictures, relations between pictures whose attributes determined using a panorama function are taken, and attributes determined using a consecutive photoing function are stored along with actual picture data as the source data. At this time, if the digital camera transfers pictures to a television set using an AV cable, a user can see multimedia data whose respective attributes are represented. However, if the digital camera is accessed via a personal computer using a universal serial bus (USB), only the source data is transferred to the computer and the pictures' respective attributes are lost.<br>
6.                  As described above, it is shown that the interoperability of the personal computer for metadata such as attributes of data stored in the digital cameral is very weak. Or, there is no interoperability of the personal computer to the digital camera.<br>
7.                   To strengthen the interoperability relative to data between digital devices, the standardization for MPV has been in progress.<br>
8.                   MPV specification defines Manifest, Metadata and Practice to process and play sets of multimedia data such as digital pictures, video, audio, etc. stored in storage median (or device) comprising an optical disk, a memory card, a computer hard disk, or exchanged according to the Internet Protocol (IP).<br>
9.                  The standardization for MPV is currently overseen by the OSTA (Optical Storage Technology Association) and I3A (International Imaging Industry Association), and the MPV takes an open specification and mainly desires to make it easy to process, exchange and play sets of digital pictures, video, digital audio and text and so on.<br>
10.                 MPV is roughly classified into MPV Core-Spec (0.90WD) and Profile.<br>
11.                 The core is composed of three basic factors such as Collection, Metadata and Identification.<br>
12.	The Collection has Manifest as a Root member, and it comprises Metadata, Album, MarkedAsset and AssetList, etc. The Asset refers to multimedia data described <br>
according to the MPV format, being classified into two kinds: Simple media asset <br>
(e.g., digital pictures, digital audio, text, etc.) and Composite media asset (e.g., digital picture combined with digital audio (StillWithAudio), digital pictures photoed consecutively (StillMultishotSequence), panorama digital pictures<br>
3<br><br>
WO 2005/029490		PCT/KR2004/002309<br><br>
(StillPanoramaSequence), etc.). FIG. 1 illustrates examples of StillWithAudio, Still-MultishotSequence, and StillPanoramaSequence.<br>
[13]	Metadata adopts the format of extensible markup language (XML) and has five<br>
kinds of identifiers for identification.<br>
[14]	1. LastURL is a path name and file name of a concerned asset (Path to the object),<br>
[15]	2. Instance lD is an ID unique to each asset (unique per object: e.g., Exif 2.2),<br>
[16]	3. Document ID is identical to both source data and modified data,<br>
[17]	4. Content ID is created whenever a concerned asset is used for a specified purpose,<br>
and<br>
[18]	5. id is a local variable within metadata.<br>
[19]	There are seven profiles: Basic profile, Presentation profile, Capture/Edit profile,<br>
Archive profile, Internet profile, Printing profile and Container profile.<br>
[20]	MPV supports management of various file associations by use of XML metadata<br>
so as to allow various multimedia data recorded on storage media to be played. Especially, MPV supports JPEG (Joint Photographic Experts Group), MP3, WMA(Windows Media Audio), WMV (Windows Media Video), MPEG-1 (Moving Picture Experts Group-1), MPEG-2, MPEG-4, and digital camera formats such as AVI (Audio Video Interleaved) and Quick Time MJPEG (Motion Joint Photographic Experts Group) video. MPV specification-adopted discs are compatible with BO9660 level 1, Joliet, and also multi-session CD (Compact Disc), DVD (Digital Versatile Disc), memory cards, hard discs and Internet, thereby allowing users to manage and process more various multimedia data. <br>
Disclosure   of   Invention<br>
Technical   Problem<br>
[21]	However, new formats of various multimedia data not defined in MPV format<br>
specification, namely new formats of assets are in need, and an addition of a function to provide the multimedia data is on demand.<br>
Technical   Solution<br>
[22]	Accordingly, the present invention is proposed to provide formats of new<br>
multimedia data in addition to various formats of multimedia data defined in the current MPV formats, and increase the utilization of various multimedia data by proposing a method to provide multimedia data described according to MPV formats to users in a variety of ways.<br>
[23]	According to an exemplary embodiment of the present invention, there is provided<br>
an apparatus for displaying audio and video data constituting multimedia data<br><br><br><br>
                                                                       4<br><br>
WO 2005/029490<br><br><br><br>
PCT/KR2004/002309<br><br>
described in MPV format, wherein the apparatus ascertains whether an asset selected by a user comprises a single audio data and at least one or more video data, extracts reference information to display the audio data and the video data and then displays the audio data extracted, by use of the reference information, and extracts at least one or more video data from the reference information and then sequentially displays them according to a predetermined method while the audio data is being output. The displaying operation may allow the video data to be displayed according to information on display time to determine the playback times of respective video data while the audio data is being displayed and information on volume control to adjust the volume generated when the audio data and the video data are being played.<br>
[24]	According to another exemplary embodiment of the present invention, there is<br>
provided an apparatus for displaying audio and video data constituting multimedia data described in MPV format, wherein the apparatus ascertains whether an asset selected by a user comprises a single video data and at least one or more audio data, extracts reference information to display the video data and the audio data and then displays the video data extracted, using the reference information, and extracts at least one or more audio data from the reference information and then sequentially displays them according to a predetermined method while the video data is being displayed. The displaying method may allow the audio data to be displayed according to information on display time to determine the playback times of respective audio data while the video data is being displayed and information on volume control to adjust the volume generated when the audio data are being played.<br>
[25]	According to a another exemplary embodiment of the present invention, there is<br>
provided a method for displaying audio and video data constituting multimedia data described in MPV format, comprising ascertaining whether an asset selected by a user comprises a single audio data and at least one or more video data, extracting reference information to display the audio data and the video data, extracting and displaying the audio data using the reference information, and extracting and sequentially displaying at least one or more video data from the reference information according to a predetermined method while the audio data is being displayed.<br>
[26]	The displaying method may allow the video data to be displayed according to in-<br>
formation on display time to determine the playback times of respective video data while the audio data is being displayed and information on volume control to adjust the volume generated when the audio data and the video data are being played. At this time, the display time information may comprise information on start time when the<br>
-5-<br><br>
WO 2005/029490		PCT/KR2004/002309<br>
video data starts to be played" and information on playback time to indicate the playback time of the video data.<br>
[27]	The extraction and sequential display step comprises synchronizing first time in-<br>
formation to designate the time for playing the audio data and second time information to designate the time for playing the at least one or more video data, extracting first volume control information to adjust the volume generated while the audio data is being played and second volume control information to adjust the volume while the at least one or more video data are being displayed, and supplying the audio data and the video data through a display medium by use of the time information and the volume control information.<br>
[28]	According to a still further exemplary embodiment of the present invention, there<br>
is provided a method for displaying audio and video data constituting multimedia data described in MPV format, comprising ascertaining whether an asset selected by a user comprises single video data and at least one or more audio data, extracting reference information to display the video data and the audio data, extracting and displaying the video data using the reference information, and extracting and sequentially displaying at least one or more audio data from the reference information according to a predetermined method while the video data is being displayed.<br>
[29]	The displaying method may allow the audio data to be output according to in-<br>
formation on display time to determine the playback times of respective audio data while the video data is being displayed and information on volume control to adjust the volume generated when the video data and the audio data are being played. At this time, the display time information may comprise information on start time when the audio data starts to be played" and information on playback time to indicate the playback time of the video data.<br>
[30]	The extraction and sequential display step may comprise synchronizing first time<br>
information to designate the time for playing video data and second time information to designate the time for playing the at least one or more audio data, extracting first volume control information to adjust the volume generated while the video data is being played and second volume control information to adjust the volume while the at least one or more audio data are being displayed, and supplying the video data and the audio data through a display medium by use of the time information and the volume control information.<br>
[31]	According to a still further exemplary embodiment of the present invention, there<br>
is provided a storage medium recording thereon a program for displaying multimedia<br>
6<br><br>
WO 2005/029490		PCT7KR2004/002309<br>
data described in MPV format, wherein the program ascertains whether an asset selected by a user comprises a single audio data and at least one or more video data, extracts reference information to display the audio data and the video data and then displays the audio data extracted, using the reference information, and extracts at least one or more video data from the reference information and then displays them sequentially according to a predetermined method while the audio data is being output.<br>
[32]	According to a still further exemplary embodiment of the present invention, there<br>
is provided a storage medium recording thereon a program for displaying multimedia data described in MPV format, wherein the program ascertains whether an asset selected by a user comprises a single video data and at least one or more audio data, extracts reference information to display the video data and the audio data and then displays the video data extracted, using the reference information, and extracts at least one or more audio data from the reference information and then sequentially displays them according to a predetermined method while the video data is being displayed.<br>
Description   of  Drawings<br>
[33]	FIG. 1 is an exemplary view illustrating different kinds of assets described in a<br>
MPV specification;<br>
[34]	FIG. 2 is an exemplary view schematically illustrating a structure of an 'Au-<br>
dio With Video' asset according to an aspect of the present invention;<br>
[35]	FIG. 3 is an exemplary view illustrating a <videowithaudioref> element<br>
according to an aspect of the present invention;<br>
[36]	FIG. 4 is an exemplary view illustrating an <audiowithvideoref> element<br>
according to an aspect of the present invention;<br>
[37]	FIG. 5 is an exemplary view illustrating a <videodurseq> element according to an<br>
aspect of the present invention;<br>
[38]	FIG. 6 is an exemplary view illustrating a <startseq> element according to an<br>
aspect of the present invention;<br>
[39]	FIG. 7 is an exemplary view illustrating a <videovolumseqi> element according    to<br>
an aspect of the present invention;<br>
[40]	FIG. 8 is an exemplary view illustrating an <audiovolume> element according to<br>
an aspect of the present invention;<br>
[41]	FIG. 9 is an exemplary diagram illustrating a type of an <audiowithvideo><br>
element according to an aspect of the present invention;<br>
[42]	FIG. 10 is an exemplary diagram illustrating a structure of an 'VideoWithAudio'<br>
asset according to an aspect of the present invention;<br>
-7~<br><br>
WO 2005/029490		PCT/KR2004/002309<br>
[43]	FIG. 11 is an exemplary view illustrating an <audiodurseq> element according to<br>
an aspect of the present invention;<br>
[44]	FIG. 12 is an exemplary view illustrating an <audiovolumeseq> element<br>
according to an aspect of the present invention;<br>
[45]	FIG. 13 is an exemplary view illustrating <videovolume> element according to an<br>
aspect of the present invention;<br>
[46]	FIG. 14 is an exemplary diagram illustrating a type of an <videowithaudio><br>
element according to an aspect of the present invention;<br>
[47]	FIG. 15 is an exemplary view illustrating an AudioRefGroup according to an<br>
aspect of the present invention;<br>
[48]	FIG. 16 is an exemplary view illustrating a VideoRefGroup according to an aspect<br>
of the present invention;<br>
[49]	FIG. 17 is a flow chart illustrating a process of playing the 'Audio With Video' asset<br>
according to an aspect of the present invention; and<br>
[50]	FIG. 18 is a block diagram of an apparatus for displaying audio and video data,<br>
according to an exemplary embodiment of the present invention.<br>
Mode   for   Invention<br>
[51]	Hereinafter, an apparatus and a method for displaying audio and video data, which<br>
are based on MPV formats, according to an aspect of the present invention, will be described in more detail with reference to the accompanying drawings.<br>
[52]	In the present invention, XML is used to provide multimedia data according to<br>
MPV format. Thus, the present invention will be described according to XML schema.<br>
[53]	More various multimedia data are provided herein by proposing new assets of 'Au-<br>
dioWithVideo' and 'VideoWithAudio' not provided by OSTA. To describe the new assets, the following terms are used: 'smpv' and 'mpv' refer to a 'namespace' in XML, wherein the former indicates a namespace relative to a new element proposed in the present invention and the latter indicates a namespace relative to an element proposed by the OSTA. The definitions and examples of these new assets will be described.<br>
[54]	1. Audio with Video asset<br>
[55]	This 'AudioWithVideo' asset comprises a combination of a single audio asset with<br>
at least one or more video assets. To represent this asset in XML, it may be referred to as an element of <audiowithvideo>. Where a user enjoys at least one or more moving picture contents while listening to a song, this will constitute an example of this asset. At this time, the time interval to play multiple moving picture contents can be controlled, and also the volume from the moving picture contents and that from the<br>
8 <br>
WO 2005/029490		PC17KR2004/002309<br>
song can be controlled.<br>
[56]	The audio asset and the video asset are treated as elements in XML documents,<br>
that is, XML files. The audio asset may be represented as <audiopart> and  and the video asset may be represented as <videopart> and .<br>
[57]	The <audiopart> element indicates a part of the audio asset. As a sub-element of<br>
the <audiopart>, <start>, <stop>, <dur> can be defined. Among the three sub-elements, a value of at least one sub-element must be designated.<br>
[58]	<start> sub-element may be defined as <element name="SMPV:start"></element>
type='xs:long' minOccurs='0'/&gt;, indicating the start time relative to a part of the entire play time of the audio asset, referenced in the unit of seconds. Given no value thereto, the start time is calculated as in [SMPV:start] = [SMPV:stop] - [SMPV:dur] based on <stop> and <dur>. Where values of <stop> or <dur> are not designated, the value of <start> is 0.<br>
[59]	<stop> sub-element may be defined as <element name="SMPV:stop"></element>
type='xs:long' minOccurs='0'/&gt;, indicating the stop time relative to a part of the entire play time of the audio asset referenced in the unit of seconds. Given no value thereto, the stop time is calculated as in [SMPV:stop] = [SMPV:start] + [SMPV:dur] based on <start> and <dur>. Where a value of <dur> is not designated but a value of <start> is designated, the value of <stop> is equal to the stop time of an asset referenced. Where a value of <start> is not designated but  is designated, the value of <stop> is equal to the value of .<br>
[60]	SMPV:dur&gt; sub-element may be defined as <element name="SMPV:dur"></element>
type='xs:long' minOccurs='07&gt;, indicating the actual play time of the audio asset referenced. Where a value of <dur> is not given, tins time is calculated as in [SMPV:dur] = [SMPV:stop] - [SMPV:start].<br>
[61 ]	The <videopart> element indicates a part of the video asset. The same method of<br>
defining the <audiopart> element can be employed in defining the <videopart> element.<br>
[62]	FIG. 2 is an exemplary view schematically illustrating a structure of 'Au-<br>
dio With Video' asset according to an aspect of the present invention.<br>
[63]	Referring to this figure, the <audiowithvideo element comprises a plurality of></audiowithvideo>
elements respectively having 'mpv' or 'smpv' as namespace.<br>
[64]	Elements having 'mpv' as namespace are described in the official homepage of<br>
9<br><br>
WO 2005/029490		PCT/KR2004/002309<br><br>
OSTA (www.osta.org) proposing MPV specification, description thereof will be omitted herein. Accordingly, only elements having 'smpv' as namespace will be described below.<br>
[65]	(1) <audiopartref><br>
[66]	This element references the <audiopart> element.<br>
[67]	(2) <videopartref><br>
[68]	This element references the <videopart> element.<br>
[69]	(3) <videowithaudioref><br>
[70]	This element references the <videowithaudio> element, which is illustrated in<br>
FIG. 3.<br>
[71]	(4) <audiowithvideoref><br>
[72]	This element references the <audiowithvideo element which is illustrated in></audiowithvideo>
FIG. 4.<br>
[73]	(5) <videodurseq><br>
[74]	A value of this element indicates the play time of respective video data, being<br>
represented in the unit of seconds and indicating a relative time value. The play time may be presented in decimal points. Where a value of this element is not set, it is regarded that the play time is not set, and thus, the total play time of any concerned video data is assumed to be equal to the value of the <videodurseq> element.<br>
[75]	The total play time of any concerned video data may be determined depending<br>
upon a reference type of the video data referenced in the video asset.<br>
[76]	Namely, the total play time of a concerned video data is equal to the total play time<br>
of the video data referenced when the reference type is 'VideoRef.' Where the reference type is 'VideoPartRef,' it is possible to obtain the total play time of the concerned video data using an attribute value of the <videopart> element referenced. Where the reference type is 'AudioPartRef,' the reference type relative to the audio data should be identified in the referenced <audiowithvideo> element. To be specific, where the reference type relative to the audio data is 'AudioRef,' the total play time of the concerned video data is equal to the total play time of the audio data, and where the reference type relative to the audio data is 'AudioPartRef,' the total play time of the concerned video data can be obtained by an attribute value of the referenced  element Further, where the reference type is 'VideoWithAudioRef,' only the video asset is extracted from the <videowithaudio> element, and the total play time of the video data referenced as 'VideoRef in the extracted video asset is regarded as the total play time of the concerned video data.<br>
10<br><br>
WO 2005/029490		PCT/KR2004/002309<br>
[77]	A value of the <videodurseq> element will be described in brief.<br>
[78]<br>
VideoDurSeq = <clock-value>(";"<clock-value>)	(1)<br>
clock-value = (<seconds> | <unknown-dur>)	(2)<br>
unknown-dur=the empty string	(3)<br>
seconds = <decimal number>(.<decimal number>)	(4)<br>
[79]	Formula (1) means that a value of the <videodurseq> element is represented as<br>
'clock-value,' and play times of respective video type are identified by means of';' where there are two or more video data.<br>
[80]	Formula (2) means that 'clock-value' in Formula (1) is indicated as 'seconds' or<br>
unknown-dur.'<br>
[81]	Formula (3) means that Unknown-dur' in Formula (2) indicates no setting of 'clock-<br>
value.'<br>
[82]	Formula (4) means that 'seconds' in Formula (2) is indicated as a decimal and<br>
playback time of the concerned video data can be indicated by means of a decimal point.<br>
[83]	For example, where 'clock-value' is '7.2,' this means that the playback time of the<br>
concerned video data is 7.2 seconds. As another example, where 'clock-value' is '2:10.9,' this means that there are two video data concerned, one of which is played for 2 seconds and the other of which is placed for 10.9 seconds. As a further example, where 'clock-value' is ';5.6,' this means that there are two video data concerned, one of which is played for the total playback time of the concerned content because its playback time is not set, and the other of which is played for 5.6 seconds. FIG. 5 illustrates the <videodurseq> element.<br>
[84]	(6) <startseq><br>
[85]	A value of <startseq> element indicates a point in time when each of video data<br>
starts to play back. The point in time is in the unit of seconds, indicating a relative time value based on the start times of the respective video data. The playback start time may be indicated as a decimal point. For example, where a value of the <startseq> element is not set, the value is assumed to be 0 seconds. Namely, the concerned video data is played from the playback start time thereof. If the value of <startseq> element is larger than the total playback time of the concerned video data, it causes the concerned video data to play after the playback thereof ends: in this case, the value of <startseq><br>
-11 <br>
WO 2005/029490		PCT/KR2004/002309<br>
element is assumed to be 0.<br>
[86]	If <videodurseq> element and <startseq> element are both defined within 
dioWithVideo&gt; element, the value of summing <videodurseq> element and  element should be equal to or less than the total playback time of the concerned video data. If not so, the value of <videodurseq> element becomes the deduction of the value of <startseq> element from the total playback time of the concerned video data. FIG. 6 illustrates the <startseq> element.<br>
[87]	(7) <videovolumseq><br>
[88]	A value of <videovolumeseq> element indicates the volume size of the concerned<br>
video data by percentage. Thus, where the value of <videovolumeseq> element is 0, the volume of the concerned video data becomes 0. If the value of <videovolumeseq> element is not set, die concerned video data is played with the volume as originally set.<br>
[89]	While a plurality of video data are played, values of the <videovolumeseq><br>
element, as many as the played video data, are set. However, if a single value is set, all of the video data played are played with the volume having the single value as set. FIG. 7 illustrates die <videovolumeseq> element.<br>
[90]	(8) <audiovolume><br>
[91]	A value of <audiovolume> indicates the volume size of the concerned audio data<br>
in percentage. When the value of <audiovolume> element is not set, it is assumed to be 100. FIG. 8 illustrates the <audiovolume> element<br>
[92]	FIG. 9 is an exemplary diagram illustrating a type of an <audio with video></audio>
element according to an aspect of the present invention.<br>
[93]	An exemplary method for providing an asset of <audiowithvideo using the></audiowithvideo>
above-described elements will be described.<br>
[94]<br>
[Example 1] <audiowithvideo><br><audioref>A0007</audioref><br>V 1205<br><videoref>V1206</videoref><br><startseq>;3</startseq> ^SMPV:AudioWithVideo&gt;<br>
12<br><br>
WO 2005/029490		PCT/KR2004/002309<br>
[95]	Example 1 illustrates a method of playing the <audiowithvideo asset using one></audiowithvideo>
audio asset referenced as 'A0007' and two video assets referenced as 'V1205' and 'V1206' respectively. In this example, since a value of <startseq> element is not set with respect to the video asset whose value is referenced as 'V1205,' the value is assumed to be 0 seconds. Namely, the video asset referenced as 'V1205' is being played from the point in time when the audio asset referenced as 'A0007 starts to play to the time when the video asset referenced as 'V1206' starts to play. Meanwhile, since a value of the <startseq> element is set to be 3 with respect to the video asset whose value is referenced as 'VI206,' the video asset referenced as 'VI206' is being played in three seconds after the point in time when the video asset referenced as 'V1206' starts to play.<br>
[96]<br>
[Example 2]<br><audiowithvideo><br><audioref>A0001 </audioref><br><videoref>V 1001 </videoref><br><videoref>V 1002</videoref><br><videoref>V 1003</videoref><br><smpv: videodurseq>2;; 10<br><startseq>;3;0</startseq><br><videovolumeseq>50</videovolumeseq><br><audiovolume>50</audiovolume><br></smpv:></audiowithvideo><br>
[97]	Example 2 illustrates a method of playing an AudioWithVideo asset using one<br>
audio asset referenced as 'A0001' and three video assets referenced as 'V1001,' 'V1002' and 'V1003' respectively. In this example, the video asset referenced as 'V0001' is played for two seconds. The video asset referenced as 'V1002' starts to play after playback of the video asset referenced as 'V1001' ends and after three seconds have passed since the video asset referenced as 'V1001' starts to play. The video asset referenced as 'V1003' is being played for ten seconds after playback of the video asset<br>
-13-<br><br>
WO 2005/029490<br><br><br><br>
PCT/KR2004/002309<br><br>
referenced as 'V1002' ends.<br>
[98]	The three video assets are played with the volume sizes of 50% of their original<br>
volumes, and the audio asset is also played with the volume size of 50% of its original<br>
volume. [99]<br>
[Example 3]<br><audiowithvideo><br><audioref>A0001 </audioref><br><videopartref>VPl 001 </videopartref><audiowithvideoref>AV 1002<br></audiowithvideoref></audiowithvideo><br>
[100]	2. 'VideoWithAudio' Asset<br>
[101]	This 'VideoWithAudio' asset comprises a combination of a single video asset with<br>
at least one or more audio assets. To represent this asset in XML, it may be referred to as an element of <videowithaudio>. The audio asset and the video asset are treated as elements in XML documents. The audio asset may be represented as <audiopart> or <audio>, and the video asset may be represented as <videopart> or 
[102]	FIG. 10 is an exemplary diagram illustrating a structure of an 'VideoWithAudio'<br>
asset according to an aspect of the present invention. Referring to a diagram of the  Element comprises a plurality of elements respectively having 'mpv' or 'smpv' as namespace.<br>
[103]	Elements having 'mpv' as namespace are described in the official homepage of<br>
OSTA (www.osta.org) proposing MPV specification, therefore description thereof will be omitted herein. Accordingly, only elements having 'smpv' as namespace will be described below. In this regard, since the AudioWithVideo asset has already described herein, duplicated description will be omitted.<br>
[104]	(1) <audiodurseq><br>
[105]	Values of the <audiodurseq> element indicates playback times of the respective<br>
audio data. The playback time may be indicated in the unit of seconds, indicating a relative time value. The playback time may be indicated using a decimal point. Where the value of <audiodurseq> is not set, it is assumed that the playback time is not set,<br>
14<br><br>
wo<br><br>
2005/029490<br><br><br><br>
PCT/KR2004/002309<br><br>
and the total playback time of the concerned audio data is regarded as the value of  element. A value of the <audiodurseq> element will be briefly described. [106]<br>
AudioDurSeq = <clock-value>(";"<clock-value>)	(5)<br>
clock-value = (<seconds> | <unknown-dur>)	(6)<br>
unknown-dur=the empty string	(7)<br>
seconds = <decimal number>(.<decimal number>).	(8)<br>
[107]	Formula (5) means that a value of <audiodurseq> element is indicated by 'clock-<br>
value,' and where there are two audio data, respective playback times of the audio data are identified by use of';'<br>
[108]	Formula (6) means that 'clock-value' in Formula (5) is indicated in 'seconds' or<br>
unknown-dur.'<br>
[109]	Formula (7) means that Unknown-dur' in Formula (6) indicates no setting of 'clock-<br>
value.'<br>
[110]	Formula (8) means that 'seconds' in Formula (6) is indicated as a decimal and<br>
playback time of the concerned video data can be indicated by means of a decimal point.<br>
[Ill]	For example, when 'clock-value' is '12.2,' this means that the playback time of the<br>
concerned audio data is 12.2 seconds. As another example, where 'clock-value' is '20;8.9,' this means that there are two audio data concerned, one of which is played for 20 seconds and the other of which is placed for 8.9 seconds. As a further example, where 'clock-value' is ';565â€™, this means mat there are two audio data concerned, one of which is played for the total playback time of the concerned content because its playback time is not set, and the other of which is played for 565 seconds. FIG. 11 briefly illustrates the <audiodurseq> element.<br>
[112]	(2) <audiovolumeseq><br>
[113]	A value of the <audiovolumeseq> element indicates the volume size of die<br>
concerned audio data in percentage. If the value of <audiovolumeseq> element is not set, the concerned audio data is played with the volume as originally set.<br>
[114]	While a plurality of audio data are played, values of the <audiovolumeseq><br>
elements, as many as the played audio data, are set. However, if a single value is set, all of the audio data played are played with the volume having the single value as set.<br>
-15-<br><br>
WO 2005/029490<br><br>
15<br><br>
PCT/KR2004/002309<br><br>
FIG. 12 illustrates the <audiovolumeseq> element.<br>
[115]	(3) <videovolume><br>
[116]	A value of <videovolume> indicates the volume size of the concerned video data<br>
in percentage. Where the value of <videovolume> element is not set, it is assumed to be 100. That is, it is played with the originally set volume of the concerned video data. FIG. 13 briefly describes the <videovolume> element.<br>
[117]	FIG. 14 is an exemplary diagram illustrating a type of a <videowithaudio><br>
element according to an aspect of the present invention.<br>
[118]	According to an exemplary aspect of the present invention, reference groups for<br>
reference of assets may be defined.<br>
[119]	'AudioRefGroup' to reference audio assets and 'VideoRefGroup' to reference video<br>
assets may be defined.<br>
[120]	At this time, the AudioRefGroup comprises elements of <audioref> and 
SMPV:AudioPartRef&gt;.<br>
[121]	Also, the VideoRefGroup comprises elements of <videoref>, 
SMPV:VideoPartRef&gt;, <videowithaudioref> and . FIGs. 15 and 16 describe the 'AudioRefGroup' and the 'VideoRefGroup.'<br>
[122]	FIG. 17 is a flow chart illustrating a process of playing the 'Audio With Video' asset<br>
according to an aspect of the present invention.<br>
[123]	A user executes the software capable of executing any file written according to the<br>
MPV format and selects 'AudioWithVideo' asset in a certain album SI700. Then, a thread or a child processor is generated, which collects information on audio assets and video assets.<br>
[124]	Reference information concerning audio asset constituting the 'AudioWithVideo'<br>
asset selected by the user is extracted SI705. And information on the audio asset is extracted by use of the reference information from an asset list S1710. At this time, information on playback time and information on volume of the audio asset are obtained S1715 and S1720.<br>
[125]	On the other hand, another thread or a child processor extracts a video asset list to<br>
be combined with the audio asset SI725 and information on all of the video assets from the asset list S1730. Then, either of them determines a scenario to play the video assets using the information, that is, the sequence of the respective video data and time for playing the respective video data S1735. Even though scenarios with respect to all of the video assets to be combined with the audio asset in the step S1735 are<br>
16<br><br>
WO 2005/029490		PCT/KR2004/002309<br><br>
determined, the total playback time of all of the video assets may be longer than the playback time of the audio asset. In this case, the total playback time of the video assets is adapted to the playback time of the audio asset. At this time, the playback time information obtained in the step S1715 is used in S1740. Accordingly, a part of the video assets to be played may not be played after the playback time of the audio asset has ended. After completion of the step S1740, the volume generated from the respective video data is adjusted S1745.<br>
[126]	After the audio asset and the video assets constituting the 'AudioWithVideo' asset<br>
are obtained to display the 'AudioWithVideo' asset, contents to represent the 'AudioWith Video' asset using the information is played SI750.<br>
[127]	FIG. 18 illustrates an exemplary embodiment of an apparatus for performing a<br>
process of displaying audio and video data such as, for example, the process shown in FIG. 17. The apparatus 1800 shown in FIG. 18 includes an ascertaining unit 1810 and an extractor 1820. The ascertaining unit 1810 receives an input by a user and ascertains whether an asset selected by the user includes audio and video data. The extractor 1820 then extracts reference information to display the audio and video data, outputs the extracted audio data using the reference information, extracts the video data from the reference information, and displays the video data while the audio data is being output. The video data can be sequentially displayed according to a predetermined method.<br>
[128]	Multimedia data provided in MPV format can be described in the form of XML<br>
documents, which can be changed to a plurality of application documents according to stylesheets applied to the XML documents. In the present invention, the stylesheets to change an XML document to an HTML document has been applied, whereby a user is allowed to manage audio and video data through a browser. In addition, the stylesheets to change the XML document to a WML (Wireless Markup Langage) or cHTML (Compact HTML) document may be applied, thereby allowing the user to access audio and video data described in the MPV format through mobile terminals such as a personal digital assistant (PDA), a cellular phone, a smart phone and so on.<br>
Industrial   Applicability<br>
[129]	As described above, the present invention provides users with a new form of<br>
multimedia data assets in combination with audio data and video data, thereby allowing the users to generate and use more various multimedia data described in the MPV format.<br>
[130]	Although the present invention has been described in connection with the exem-<br>
-17-<br><br>
WO 2005/029490	17<br>
	                                           PCT/KR2004/002309<br><br>
plaryembodiments thereof shown in the accompanying drawings, the drawings are<br>
mere examples of the present invention. It can also be understood by those skilled in<br>
the art that various changes, modifications and equivalents thereof can be made<br>
thereto. Accordingly, the true technical scope of the present invention should be<br>
defined by the appended claims.<br>
-18-<br><br>
WO 2005/029490<br><br><br>
WE CLAIMS<br><br>
PCT/KR2004/002309<br><br>
[1]	An apparatus for displaying aidio and video data constituting multimedia data<br>
described in multiphoto video (MPV) format, said apparatus comprising: an ascertaining unit that ascertains whether an asset selected by a user comprises a single audio data and at least one piece of video data,<br>
an extractor that extracts reference information to display the audio data and the at least one video data and then outputs the extracted audio data, using the reference information, and extracts said at least one video data from the reference information and then sequentially displays said at least one video data according to a predetermined method while the audio data is being output.<br>
[2]	The apparatus as claimed in claim 1, wherein the predetermined method allows<br>
the at least one video data to be displayed according to information on display time, to determine playback times of respective video data while the audio data is being output and information on volume control to adjust volume generated when the audio data and the at least one video data are being played.<br>
[3]	An apparatus for displaying audio and video data constituting multimedia data<br>
described in multiphoto video (MPV) format, said apparatus comprising: an ascertaining unit that ascertains whether an asset selected by a user comprises a single video data and at least one piece of audio data,<br>
an extractor that extracts reference information to display the video data and me at least one piece of audio data and then displays the video data extracted, using the reference information, and extracts the at least one audio data from the reference information and then sequentially outputs said at least one piece of aidio data according to a predetermined method while the video data is being displayed.<br>
[4]	The apparatus as claimed in claim 3, wherein the predetermined method allows<br>
the at least one piece of audio data to be displayed according to information on display time, to determine the playback times of respective audio data while the video data is being displayed and information on volume control to adjust volume generated when the at least one piece of audio data is being played.<br>
[5]	A method for displaying audio and video data constituting multimedia data<br>
described in multiphoto video (MPV) format, comprising: (a) ascertaining whether an asset selected by a user comprises a single audio data and at least one piece of video data;<br>
-19-<br><br>
WO 2005/029490<br><br><br><br>
PCT/KR2004/002309<br><br>
(b)	extracting reference information to display the audio data and the at least one piece of video data;<br>
(c)	extracting and displaying the audio data using the reference information; and<br>
(d)	extracting and sequentially displaying said at least one piece of video data from the reference information according to a predetermined method while the audio data is being output.<br>
[6]	The method as claimed in claim 5, wherein the predetermined method allows the<br>
at least one piece of video data to be displayed according to information on display time, to determine the playback times of respective video data while the audio data is being output and information on volume control to adjust volume generated when the audio data and the at least one piece of video data is being played.<br>
[7]	The method as claimed in claim 6, wherein the display time information<br>
comprises information on a start time when the at least one piece of video data starts to be played" and information on playback time to indicate the playback time of the at least one piece of video data.<br>
[8]	The method as claimed in claim 5, wherein the step (d) comprises:<br>
synchronizing first time information to designate the time for playing the audio<br>
data and second time information to designate the time for playing the at least<br>
one piece of video data;<br>
extracting first volume control information to adjust a first volume generated<br>
while the audio data is being played and second volume control information to<br>
adjust a second volume while the at least one piece of video data are being<br>
displayed; and<br>
supplying the audio data and the at least one piece of video data through a<br>
display medium using the time information and the volume control information.<br>
[9]	A method for displaying audio and video data constituting multimedia data<br>
described in multiphoto video (MPV) format, comprising:<br>
(a)	ascertaining whether an asset selected by a user comprises a single video data and at least one piece of audio data;<br>
(b)	extracting reference information to display the video data and the at least one piece of audio data;<br>
(c)	extracting and displaying the video data using the reference information; and<br>
(d)	extracting and sequentially displaying said at least one piece of audio data from the reference information according to a predetermined method while the<br>
20<br><br>
WO 2005/029490<br><br><br><br>
PCT7KR2004/002309<br><br>
video data is being displayed.<br>
[10]	The method as claimed in claim 9, wherein the predetermined method allows the<br>
at least one piece of audio data to be displayed according to information on display time, to determine the playback times of respective audio data while the video data is being displayed and information on volume control to adjust volume generated when the video data and the at least one piece of audio data are being played.<br>
[11]	The method as claimed in claim 10, wherein the display time information<br>
comprises information on a start time when the at least one piece of audio data starts to be played" and information on playback time to indicate the playback time of the at least one piece of audio data.<br>
[12]	The method as claimed in claim 9, wherein the step (b) comprises:<br>
synchronizing first time information to designate the time for playing video data<br>
and second time information to designate the time for playing the at least one<br>
piece of audio data;<br>
extracting first volume control information to adjust a first volume generated<br>
while the video data is being played and second volume control information to<br>
adjust a second volume while the at least one piece of audio data are being<br>
displayed; and<br>
supplying the video data and the audio data through a display medium using the<br>
time information and the volume control information.<br>
[13]	A storage medium comprising a recordable medium operable to record thereon a<br>
program for displaying multimedia data described in multiphoto video (MPV) format, wherein the program ascertains whether an asset selected by a user comprises a single audio data and at least one piece of video data, extracts reference information to display the audio data and the at least one piece of video data and then displays the audio data extracted, using the reference information, and extracts at least one piece of video data from the reference information and then displays the at least one piece of video data sequentially according to a predetermined method while the audio data is being output.<br>
[14]	A storage medium comprising a recordable medium operable to record thereon a<br>
program for displaying multimedia data described in multiphoto video (MPV) format, wherein the program ascertains whether an asset selected by a user comprises a single video data and at least one piece of audio data, extracts reference information to display the video data and the at least one audio data<br>
21<br><br>
and then displays the video data extracted, using the reference information, and extracts at least one piece of audio data from the reference information and then sequentially display the at least one piece of audio data according to a predetermined method while the video data is being displayed.<br>
[15]	An apparatus for displaying audio and video data constituting multimedia<br>
data described in multiphoto video (MPV) format substantially as herein described with reference to the accompanying drawings.<br>
[16]	A method for displaying audio and video data constituting multimedia data<br>
described in multiphoto video (MPV) format substantially as herein described with reference to the accompanying drawings.<br>
[17]	A storage medium substantially as herein described with reference to the<br>
accompanying drawings.<br>
Dated this 21st day of April, 2006	<br>
(G. DEEPAK SRINIWÂ£Â§)<br>
OF K &amp; S PARTNERS<br>
AGENT FOR THE APPLICANTS<br>
-22-<br><br>
ABSTRACT<br>
An apparatus and a method for displaying audio and video data, and a storage medium for storing the method thereon. The apparatus for displaying audio and video data constituting multimedia data described in MPV format, ascertains whether an asset selected by a user comprises a single video data and at least one or more audio data, extracts reference information to display the video data and the audio data and then displays the extracted video data, using the reference information, and extracts at least one or more audio data from the reference information and then sequentially displays them according to a predetermined method while the video data is being displayed.<br>
23<br></videowithaudioref></videoref></audioref></videowithaudio></videovolume></videovolume></videovolume></videovolume></audiovolumeseq></audiovolumeseq></audiovolumeseq></audiovolumeseq></audiovolumeseq></audiodurseq></audiodurseq></decimal></decimal></unknown-dur></seconds></clock-value></clock-value></audiodurseq></audiodurseq></audiodurseq></audiodurseq></videopart></audio></audiopart></videowithaudio></startseq></startseq></audiowithvideo></audiovolume></audiovolume></audiovolume></audiovolume></videovolumeseq></videovolumeseq></videovolumeseq></videovolumeseq></videovolumeseq></videovolumseq></startseq></startseq></videodurseq></videodurseq></startseq></videodurseq></startseq></startseq></startseq></startseq></startseq></videodurseq></videodurseq></decimal></decimal></unknown-dur></seconds></clock-value></clock-value></videodurseq></videowithaudio></audiowithvideo></videopart></videodurseq></videodurseq></audiowithvideoref></videowithaudio></videowithaudioref></videopart></videopartref></audiopart></audiopartref></videopart></audiopart></videopart></dur></stop></start></stop></start></dur></dur></start></stop></start></dur></stop></dur></stop></start></dur></stop></start></audiopart></audiopart></videopart></audiopart></audiowithvideo></videowithaudio></videovolume></audiovolumeseq></audiodurseq></audiowithvideo></audiovolume></videovolumseqi></startseq></videodurseq></audiowithvideoref></videowithaudioref></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtYWJzdHJhY3QoMTMtMDgtMjAwOCkuZG9j" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-abstract(13-08-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtYWJzdHJhY3QoMTMtMDgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-abstract(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtQUJTVFJBQ1QoMTMtOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-ABSTRACT(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY2FuY2VsbGVkIHBhZ2VzKDEzLTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-cancelled pages(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtQ0FOQ0xMRUQgUEFHRVMoMjQtNC0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-CANCLLED PAGES(24-4-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtQ0xBSU1TKDEzLTgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-CLAIMS(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY2xhaW1zKGdyYW50ZWQpKDEzLTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-claims(granted)(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY2xhaW1zKGdyYW50ZWQpLSgxMy0wOC0yMDA4KS5kb2M=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-claims(granted)-(13-08-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY29ycmVzcG9uZGFuY2UtcmVjZWl2ZWQucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-correspondance-received.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY29ycmVzcG9uZGVuY2UoMjEtMDgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-correspondence(21-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtQ09SUkVTUE9OREVOQ0UoMjEtOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-CORRESPONDENCE(21-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtQ09SUkVTUE9OREVOQ0UoMjYtMDgtLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-CORRESPONDENCE(26-08--2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtY29ycmVzcG9uZGVuY2UoaXBvKS0oMjgtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-correspondence(ipo)-(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtQ09SUkVTUE9OREVOQ0UxMy04LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-CORRESPONDENCE13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtREVTQ1JJUFRJT04oQ09NUExFVEUpLSgxMy04LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-DESCRIPTION(COMPLETE)-(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZHJhd2luZygxMy0wOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-drawing(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRFJBV0lORygxMy04LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-DRAWING(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAxKDEzLTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 1(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRk9STSAxKDEzLTgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-FORM 1(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAxKDIxLTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 1(21-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRk9STSAxKDIxLTgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-FORM 1(21-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRk9STSAxKDI2LTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-FORM 1(26-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAxMygxMy0wOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 13(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAxOCgyMi0wOS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 18(22-09-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAyKDEzLTgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 2(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAyKGdyYW50ZWQpLSgxMy0wOC0yMDA4KS5kb2M=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 2(granted)-(13-08-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAyKGdyYW50ZWQpLSgxMy0wOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 2(granted)-(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRk9STSAyKFRJVExFIFBBR0UpLSgxMy04LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-FORM 2(TITLE PAGE)-(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAyNigxMy0wOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 26(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRk9STSAzKDEpLSgyNC00LTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-FORM 3(1)-(24-4-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAzKDEzLTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 3(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtRk9STSAzKDIpLSgxMy04LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-FORM 3(2)-(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAzKDIwLTEwLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 3(20-10-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSAzKDI0LTA0LTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 3(24-04-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybSA1KDI0LTA0LTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form 5(24-04-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybS0yLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybS01LnBkZg==" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybS1wY3QtaXNhLTIxMCgxMy0wOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form-pct-isa-210(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtZm9ybTIuZG9j" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-form2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtTk9UQVJJWkVEIENFUlRJRklDQVRFIE9GIEVNUExPWU1FTlQgQUdSRUVNRU5UKDIxLTgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-NOTARIZED CERTIFICATE OF EMPLOYMENT AGREEMENT(21-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtT1RIRVIgRE9DVU1FTlQoMjYtMDgtLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-OTHER DOCUMENT(26-08--2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LW11bW5wLTIwMDYtcGV0aXRpb24gdW5kZXIgcnVsZSAxMzcoMTMtMDgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">467-mumnp-2006-petition under rule 137(13-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtUEVUSVRJT04gVU5ERVIgUlVMRSAxMzcoMTMtOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-PETITION UNDER RULE 137(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDY3LU1VTU5QLTIwMDYtUE9XRVIgT0YgQVRUT1JORVkoMTMtOC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">467-MUMNP-2006-POWER OF ATTORNEY(13-8-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="225761-method-and-apparatus-for-managing-defect-in-a-recording-medium.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="225763-fragranced-solid-cosmetic-compositions-based-on-a-destructurized-starch-delivery-system.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>225762</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>467/MUMNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>07/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>13-Feb-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>28-Nov-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>24-Apr-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>SAMSUNG ELECTRONICS CO., LTD.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>416 Maetan-dong, Yeongtong-gu, Suwonsi, Gyeonggi-do,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>KIM, Du-il</td>
											<td>#108-1403 Dongsuwon LG Village, Mangpodong, Yeongtong-gu, Suwon-si, Gyeonggi-do,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>KIM, Young-yoon</td>
											<td>862-33 Bangbae 4-dong, Seocho-gu, Seoul,</td>
										</tr>
										<tr>
											<td>3</td>
											<td>PORTNYKH Valdimir</td>
											<td>17 Temple Road, Croydon, Surrey, CR01HU,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G11B20/10</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2004/002309</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-09-10</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10-2003-0079852</td>
									<td>2003-11-12</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/505,623</td>
									<td>2003-09-25</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/225762-method-for-displaying-multimedia-data by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:22:23 GMT -->
</html>
