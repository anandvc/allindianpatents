<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/223268-method-and-apparatus-for-transcoding-between-hybrid-video-bitstreams by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 06:21:53 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 223268:METHOD AND APPARATUS FOR TRANSCODING BETWEEN HYBRID VIDEO BITSTREAMS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR TRANSCODING BETWEEN HYBRID VIDEO BITSTREAMS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method and apparatus performing transcoding between bitstreams coded by hybrid video codecs which uses fewer resources than decoding/decompressing the original bitstream and recoding/recompressing it to the second format. According to a specific embodiment, the method can exploits the similarity of the standard video compression algorithms to, where possible, convert encoded parameters in the incoming bitstreams directly into encoded parameters which constitute compliant data for the outgoing bitstream.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
BACKGROUND OF THE INVENTION<br>
The present invention relates generally to telecommunication techniques. More particularly, the invention provides a method and system for transcoding between hybrid video CODEC bit streams. Merely by way of example, the invention has been applied to a telecommunication network environment, but it would be recognized that the invention has a much broader range of applicability.<br>
As time progresses, telecommunication techniques have also improved. There are now several standards for coding audio and video signals across a communications link.<br>
These standards allow terminals to interoperate with other terminals that support the same sets of standards. Terminals that do not support a common standard can only interoperate if an additional device, a transcoder, is inserted between the devices. The transcoder translates the coded signal from one standard to another.<br>
I frames are coded as still images and can be decoded in isolation from other frames.<br>
P frames are coded as differences from the preceding I or P frame or frames to exploit similarities in the frames.<br>
Some hybrid video codec standards such as the MPEG-4 video codec also supports "Not Coded' frames which contain no coded data after the frame header. Details of certain examples of standards are provided in more detail below.<br>
Certain standards such as the H. 261, H. 263, H. 264 and MPEG-4-video codecs both decompose source video frames into 16 by 16 picture element (pixel) macroblocks. The H. 261, H. 263 and MPEG-4-video codecs subdivide each macroblock is divided into six<br><br>
8 by 8 pixel blocks. Four of the blocks correspond to the 16 by 16 pixel luminance values for the macroblock and the remaining two blocks to the sub-sampled chrominance components of the macroblock. The H. 264 video codec subdivides each macroblock into twenty four 4 by 4 pixel blocks, 16 for luminance and 8 for sub-sampled chrominance.<br>
Hybrid video codecs generally all convert source macroblocks into encoded macroblocks using similar techniques. Each block is encoded by first taking a spatial transform then quantizing the transform coefficients. We will refer to this as transform encoding. The H. 261, H. 263 and MPEG-4-video codecs use the discrete cosine transform (DCT) at this stage. The H. 264 video codec uses an integer transform.<br>
The non-zero quantised transform coefficients are encoded using run length and variable length coding. This second stage will be referred to as VLC (Variable Length Coding) encoding. The reverse processes will be referred to as VLC decoding and transform decoding respectively. Macroblocks can be coded in three ways;<br>
"Intra coded"macroblocks have the pixel values copied directly from the source frame being coded.<br>
"Inter coded"macroblocks have pixel values that are formed from the difference between pixel values in the current source frame and the pixel values in the reference frame. The values for the reference frame are derived by decoding the encoded data for a previously encoded frame. The area of the reference frame used when computing the difference is controlled by a motion vector or vectors that specify the displacement between the macroblock in the current frame and its best match in the reference frame. The motion vector (s) is transmitted along with the quantised coefficients for inter frames. If the difference in pixel values is sufficiently small, only the motion vectors need to be transmitted.<br><br>
Generally all the hybrid video codecs often have differences in the form of motion vectors they allow such as, the number of motion vectors per macroblock, the resolution of the vectors, the range of the vectors and whether the vectors are allowed to point outside the reference frame. The process of estimating motion vectors is termed"motion estimation". It is one    of   the   most    computationally    intensive    parts    of   a    hybrid    video    encoder.<br>
"Not coded"macroblocks are macroblocks that have not changed significantly from the previous frame   and   no   motion   or   coefficient   data   is   transmitted   for   these   macroblocks.<br>
The types of macroblocks contained in a given frame depend on the frame type. For the frame types of interest to this algorithm, the allowed macroblock types are as follows; [0016] I frames can contain only Intra coded macroblocks.<br>
P frames can contain Intra, Inter and"Not coded"macroblocks.<br>
Prior to transmitting the encoded data for the macroblocks, the data are compressed using lossless variable length coding (VLC encoding).<br>
Another area where hybrid video codecs differ is in their support for video frame sizes. MPEG-4 and H. 264 support arbitrary frame sizes, with the restriction that the width and height as multiples of 16, whereas H. 261 and baseline H. 263 only supports limited set of frame sizes. Depending upon the type of hybrid video codecs, there can also be other limitations.<br>
A conventional approach to franscoding is known as tandem transcoding. A tandem transcoder will often fully decode the incoming coded signal to produce the data in a raw (uncompressed) format then re-encode the raw data according to the desired target standard to produce the compressed signal. Although simple, a tandem video transcoder is considered a"brute-<br><br>
force" approach and consumes significant amount of computing resources. Another alternative to tandem transcoding comprises the use of information in the motion vectors in the input bitstream to estimate the motion vectors for the output bitstream. Such alternative approach also has      limitations       and       is       also      considered      a      brute       force      technique.<br>
From the above, it is desirable to have improved ways of converting between different telecommunication      formats      in      an      efficient      and      cost      effective      manner.<br>
BRIEF SUMMARY OF THE INVENTION<br>
According  to   the   present   invention,   techniques   for  telecommunication   are   provided.<br>
More particularly, the invention provides a method and system for transcoding between hybrid video CODEC bitstreams. Merely by way of example, the invention has been applied to a telecommunication network environment, but it would be recognized that the invention has a much broader range of applicability.<br>
A hybrid codec is a compression scheme that makes use of two approaches to data compression: Source coding and Channel coding. Source coding is data specific and exploits the nature of the data. In the case of video, source coding refers to techniques such as transformation (e. g. Discrete Cosine Transform or Wavelet transform) which extracts the basic components of the pixels according to the transformation rule. The resulting transformation coefficients are typically quantized to reduce data bandwidth (this is a lossy part of the compression). Channel coding on the other hand is source independent in that it uses the statistical property of the data regardless of the data means. Channel coding examples are statistical coding schemes such as Huffman and Arithmetic Coding. Video coding typically uses Huffman coding which replaces<br><br>
the data to be transmitted by symbols (e. g. strings of 0'and1) based on the statistical occurrence of the data. More frequent data are represented by shorter strings, hence reducing the amount of bits to be used to represent the overall bitstream.<br>
Another example of channel coding is run-length encoding which exploits the repetition of data elements in a stream. So instead of transmitting N consecutive data elements, the element and its repeat count are transmitted. This idea is exploited in video coding in that the DCT coefficients in the transformed matrix are scanned in a zigzag way after their quantization. This means that higher frequency components which are located at the lower right part of the transformed matrix are typically zero (following the quantization) and when scanned in a zigzag way from top left to bottom right of matrix, a string of repeated zeros emerges. Run-length encoding reduces the amount of bits required by the variable length coding to represent these repeated zeros. The Source and Channel techniques described above apply to both image and video coding.<br>
An additional technique that used in hybrid video codecs is motion estimation and compensation. Motion estimation and compensation removes time-related redundancies in successive video frames. This is achieved by two main approaches in motion estimation and compensation. Firstly, pixel blocks that have not changed (to within some threshold defining "change") are considered to be the same an a motion vector is used to indicate how such a pixel block has moved between two consecutive frames. Secondly, predictive coding is used to reduce the amount of bits required by a straight DCT, quantization, zigzag, VLC encoding on a pixel block by doing this sequence of operation of the difference between the block in question and the closest matching block in the preceding frame, in addition to the motion vector required to indicate any change in position between the two blocks. This leads to a significant reduction in the amount of bits required to represent the block in question. This predictive coding approach has many variations that consider one or multiple predictive frames (process repeated<br><br>
a number of times, in a backward and forward manner). Eventually the errors resulting from the predictive coding can accumulate and before distortion start to be significant, an intra-coding (no predictive mode and only pixels in present frame are considered) cycle is performed on a block to encode it and to eliminate the errors accumulated so far.<br>
According to an embodiment of the present invention, techniques to perform transcoding between two hybrid video codecs using smart techniques are provided. The intelligence in the transcoding is due to the exploitation of the similarity of the general coding principles utilized by hybrid video codecs, and the fact that a bitstream contain the encoding of video sequence can contain information that can greatly simplify the process of targeting the bitstream to another hybrid video coding standard. Tandem video transcoding by contrast decodes the incoming bitstream to YUV image representation which is a pixel representation (luminance and chrominance representation) and re-encode the pixels to the target video standard. All information in the bitstream about Source coding or Channel coding (pixel redundancies, time-related redundancies, or motion information) is unused.<br>
According to an alternative embodiment, the present invention may reduce the computational complexity of the transcoder by exploiting the relationship between the parameters available from the decoded input bitstream and the parameters required to encode the output bitstream. The complexity may be reduced by reducing the number of computer cycles required to transcode a bitstream and/or by reducing the memory required to transcode a bitstream.<br>
When the output codec to the transcoder supports all the features (motion vector format, frames sizes and type of spatial transform) of the input codec, the apparatus comprises a VLC decoder for the incoming bitstream, a semantic mapping module and a VLC encoder for the output bitstream. The VLC decoder decodes the bitstream syntax. The semantic mapping module converts the decoded symbols of the first codec to symbols suitable for encoding in the second codec format. The syntax elements are then VLC encoded to form the output bitstream.<br><br>
When the output codec to the transcoder does not support all the features (motion vector format, frames sizes and type of spatial transform) of the input codec, the apparatus the apparatus comprises a decode module for the input codec, modules for converting input codec symbols to valid output codec values and an encode module for generating the output bitstream.<br>
The present invention provides methods for converting input frames sizes to valid output codec frame sizes. One method is to make the output frame size larger than the input frame size and to fill the extra area of the output frame with a constant color. A second method is to make the output frame size smaller than the input frame size and crop the input frame to create the output frame.<br>
The present invention provides methods for converting input motion vectors to valid output motion vectors.<br>
If the input codec supports multiple motion vectors per macroblock and the output codec does not support the same number of motion vectors per macroblock, the number of input vectors are converted to match the available output configuration. If the output codec supports more motion vectors per macroblock than the number of input motion vectors then the input vectors are duplicated to form valid output vectors, e. g. a two motion vector per macroblock input can be converted to four motion vectors per macroblock by duplicating each of the input vectors. Conversely, if the output codec supports less motion vectors per macroblock than the input codec,   the   input   vectors   are   combined   to   form   the   output   vector   or   vectors.<br>
If the input codec supports P frames with reference frames that are not the most recent decoded frame and the output codec does not, then the input motion vectors need to be scaled so the motion       vectors       now       reference       the       most       recent       decoded       frame.<br>
If the resolution of motion vectors in the output codec is less than the resolution of motion vectors in the input codec then the input motion vector components are converted to<br><br>
the nearest valid output motion vector component value. For example, if the input codec supports quarter pixel motion compensation and the output codec only supports half pixel motion compensation, any quarter pixel motion vectors in the input are converted to the nearest half pixel values.<br>
If the allowable range for motion vectors in the output codec is less than the allowable range of motion vectors in the input codec then the decoded or computed motion vectors are checked and, if necessary, adjusted to fall in the allowed range.<br>
The apparatus has an optimized operation mode for macroblocks which have input motion vectors that are valid output motion vectors. This path has the additional restriction that the input and output codecs must use the same spatial transform, the same reference frames and the same quantization. In this mode, the quantized transform coefficients and their inverse transformed pixel values are routed directly from the decode part of the transcoder to the encode part, removing the need to transform, quantize, inverse quantize and inverse transform in the encode part of the transcoder.<br>
The present invention provides methods for converting P frames to I frames. The method used is to set the output frame type to an I frame and to encode each macroblock as an intra macroblock     regardless     of     the     macroblock     type     in     the     input     bitstream.<br>
The present invention provides methods forconverting"Not Coded'Trames to P frames or discarding them from the transcoded bitstream.<br>
An embodiment of the present invention is a method and apparatus for transcoding between MPEG-4 (Simple Profile) and H. 263 (Baseline) video codecs.<br>
In yet an alternative specific embodiment, the invention provides method of providing for reduced usage of reducing memory in an encoder or transcoder wherein the a range of motion<br><br>
vectors is provided limited to within the a predetermined neighborhood of the a macroblock being encoded. The method comprises determining one or more pixels within a reference frame for motion compensation and encoding the macroblock while the range of motion vectors has been provided within the one or more pixels provided within the predetermined neighborhood of the macroblock being encoded. The method also comprises storing the encoded macroblock into     a     buffer     while     the     buffer     maintains     other     encoded     macroblocks.<br>
The objects, features, and advantages of the present invention, which to the best of our knowledge are novel, are set forth with particularity in the appended claims. The present invention, both as to its organization and manner of operation, together with objects and advantages, may best be understood by reference to the following description, taken in connection with the accompanying drawings.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
Figure 1 is a simplified block diagram illustrating a transcoder connection from a first hybrid video codec to a second hybrid video codec where the second codec supports features of the first     codec      according      to      an      embodiment      of     the      present      invention.<br>
Figure 2 is a simplified block diagram illustrating a transcoder connection from H. 263 to MPEG-4       according       to       an       embodiment       of      the       present       invention.<br>
Figure 3 is a simplified block diagram illustrating a transcoder connection from a hybrid video codec to second hybrid video codec according to an embodiment of the present invention.<br>
Figure 4 is a simplified block diagram illustrating an optimized mode of a transcoder connection from a hybrid video codec to second hybrid video codec according to an embodiment of the present invention.<br><br>
Figure 5 is a simplified diagram illustrating how the reference frame and macroblock buffer are used during H.   263   encoding  according  to  an  embodiment  of the  present  invention.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
According to the present invention, techniques for telecommunication are provided. More particularly, the invention provides a method and system for transcoding between hybrid video CODEC bitstreams. Merely by way of example, the invention has been applied to a telecommunication network environment, but it would be recognized that the invention has a much broader range of applicability.<br>
A method and apparatus of the invention are discussed in detail below. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. The case of Simple Profile MPEG-4 and Baseline H. 263 are used for illustration purpose and for examples. The methods described here are generic and apply to the transcoding between any pair of hybrid video codecs. A person skilled in the relevant art will recognize that other steps, configurations and arrangements can be used without departing from the spirit and scope of the present invention.<br>
Fig. 1 is a block diagram of the preferred embodiment for transcoding between two codecs where the first codec (the input bitstream) supports a subset of the features of the second codec (the output bitstream) according to an embodiment of the present invention. This diagram is merely an example and should not unduly limit the scope of the claims herein. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The input bitstream is decoded by a variable length decoder 1. Any differences in the semantics of the decoded symbols in the first video codec and their semantics in the second video codec are resolved by the semantic conversion module 2. The coefficients are variable<br><br>
length coded to form the output bitstream 3. The output of stage 1 is a list of codec symbols, such as macroblock type, motion vectors and transform coefficients. The output of stage 2 is previous list with any modifications required to make the symbols conformant for the second codec. The output of stage 3 is the bitstream coded in the second codec standard.<br>
Fig. 2 is a block diagram of the preferred embodiment for transcoding a baseline H. 263 bitstream to a MPEG-4 bitstream according to an embodiment of the present invention. This diagram is merely an example and should not unduly limit the scope of the claims herein. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The input bitstream is decoded by a variable length decoder 4. If the macroblock is an intra coded macroblock, the decoded coefficients are inverse intra predicted 6. Intra prediction of the DC DCT coefficient is mandatory. The transcoder may choose whether to use optional intra AC coefficient prediction. This process is the inverse of the intra prediction specified in the MPEG-4 standard. The coefficients are variable length coded to form the output bitstream 8.<br>
When transcoding a H. 263 bitstream to a MPEG-4 bitstream, the transcoder will insert MPEG-4 VisualObjectSequence, VisualObject and VideoObjectLayer headers in the output bitstream before the first transcoded video frame. The semantic conversion module 2 inserts VisualObjectSequence, VisualObject and VideoObjectLayer before the first symbol in the input list.<br>
When transcoding a H. 263 bitstream to a MPEG-4 bitstream, the picture headers in the H. 263 bitstream   are   converted   to   VideoObjectPlane   headers   in   the   transcoded   bitstream.<br>
The semantic conversion module 2 replaces every occurrenceof Picture header"by "VideoObjectPlane header".<br><br>
When transcoding a H. 263 bitstream to a MPEG-4 bitstream, if the H. 263 bitstream contains GOB headers, they are converted to video packet headers in the output bitstream. The semantic conversion module 2 replaces every occurrence of GOBheader"by"video packet header".<br>
FIG. 3 is a block diagram of the preferred embodiment for transcoding between two hybrid<br>
video codecs when the output codec to the transcoder does not support the features (motion<br>
vector format, frames sizes and type of spatial transform) of the input codec according to an<br>
embodiment of the present invention. This diagram is merely an example and should not unduly<br>
limit the scope of the claims herein. One of ordinary skill in the art would recognize many<br>
variations, alternatives, and modifications. The incoming bitstream is variable length decoded 9<br>
to produce a list of codec symbols such as macroblock type, motion vectors and transform<br>
coefficients. The ttansform coefficients are inverse quantised 10 and then an inverse transform<br>
11 converts the coefficients to the pixel domain, producing a decoded image for the current<br>
macroblock. For inter coded macroblock, this image is added 12 to the motion compensated<br>
macroblock	image	recovered	from	the	reference	frame	14.<br>
This     comprises     a     standard     decoder     for     the     input     hybrid     video     codec.<br>
Some output video codec standards allows the decoder to support only a subset of the frame sizes supported by the input codec. If the input frame size is not supported by output codec, the transcoder outputs the largest legal output frame that entirely contains the input frame and performs frame size conversion 15. The output frame is centered on the input frame. If the input frame is an I frame, the areas of the output frame that are outside the input frame are coded as a suitable backgroimd color. If the input frame is a P frame, areas of the output frame that are outside the input frame are coded as not coded macroblocks.<br>
An alternative method to achieve frame size conversion is for the transcoder to output the<br><br>
largest legal output frame size that fits entirely within the input frame. The output frame is centered in the input frame. In this case, the frame size conversion module 15 will crop the input frame, discarding any input macroblocks that fall outside the output frame boundaries.<br>
There are four features of motion vectors that may be supported by the input codec but not supported by output codec. They are differences in the number of motion vectors per macroblock, differences in the reference frame used for the motion compensation, differences in the resolutions of the motion vector components, differences in the allowed range of the motion vectors. In each case, the motion vector conversion unit 16 of the transcoder must choose a valid   output   motion    vector    thaf'best    approximates"the    input    motion    information.<br>
These conversions may result in either loss of image quality and/or an increase in the outgoing bitstream size.<br>
When the input motion vector (s) is different from the output motion vector (s), it is necessary to re-compute the macroblock error coefficients during the encode stage using the encoder reference frame 25.<br>
If the input codec supports multiple motion vectors per macroblock and the output codec does not support the same number of motion vectors per macroblock, the number of input vectors are converted to match the available output configuration. If the output codec supports more motion vectors per macroblock than the number of input motion vectors then the input vectors are duplicated to form valid output vectors, e. g. a two motion vector per macroblock input can be converted to four motion vectors per macroblock by duplicating each of the input vectors. Conversely, if the output codec supports less motion vectors per macroblock than the input codec, the input vectors are combined to form the output vector or vectors. For example, when a MPEG-4 to H. 263 transcoder encounters an input macroblock with 4 motion vectors, it must combine     the      4      vectors      to      obtain      a      single      output      motion     vector.<br><br>
One method for combining motion vectors is to use the means of the x and y components of the input vectors.<br>
Another method is to take the medians of the x and y components of the input vectors.<br>
The conversion from multiple input motion vectors to a required number of output motion vectors is always performed first and the resulting vector (s) are used as the input for the following conversions if they are required.<br>
If the input codec supports P frames with reference frames that are not the most recent decoded frame and the output codec does not, then the input motion vectors need to be scaled so the motion vectors now reference the most recent decoded frame. The scaling is performed by dividing each component of the input vector by the number of skipped reference frames plus one.<br>
If the resolution of motion vectors in the output codec is less than the resolution of motion vectors in the input codec then the input motion vector components are converted to the nearest valid output motion vector component value. For example, if the input codec supports quarter pixel motion compensation and the output codec only supports half pixel motion compensation, any quarter pixel motion vectors in the input are converted to the nearest half pixel values.<br>
When the transcoder encounters input motion vectors with one or both components outside the range allowed for the output codec it must convert the vector to an allowed output value. A similar situation arises when the input motion vectors can point to areas outside the video frame boundary and the output motion vectors are restricted to pointing within the image. In both cases   the   algorithm   selects   a   valid   output   vector   based   on   the   input   vector.<br>
One method of conversion is to clamp the output motion vector component to the closest allowable value. For example, MPEG-4 motion vectors can be larger than the H. 263 range of-16 to 15.5 pixels. In this case the x component of the computed H. 263 vector,/. I, is given by<br><br><br>
A second method of conversion is to make the output vector the largest valid output vector with the same direction as the input vector.<br>
After frame size and motion vector conversion, the decoded macroblock pixels are spatially transformed 19, after having the motion compensated reference values 25 subtracted 17 for inter macroblocks. The transform coefficients are quantised 20 and variable length encoded 21 before being transmitted. The quantised transform coefficients are inverse quantised 22 and converted to the pixel domain by an inverse transform 23. For intra macroblocks, the pixels are stored directly in the reference frame store 25. Inter macroblocks are added 24 to the motion compensated  reference   pixels   before   being   stored   in   the   reference   frame   store   25.<br>
Fig. 4 is a block diagram of an optimized mode of the preferred embodiment for transcoding between two hybrid video codecs when the output codec to the transcoder does not support the features (motion vector format, frames sizes and type of spatial transform) of the input codec according to an embodiment of the present invention. This diagram is merely an example and should not unduly limit the scope of the claims herein. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The optimized mode is only available when the input and output codecs use the same spatial transform, the same reference frames and the same quantization. The optimized mode is used for inter macroblocks which have input motion vectors that are legal output motion vectors. In the optimized mode, the output of the inverse quantizer 10 and the inverse spatial transform 11 are, after frame size conversion, fed directly to the variable length encoder 21 and the frame store update 24 respectively. This mode is significantly more efficient because it does not use the encode side spatial transform 19, quantizer 20, inverse quantizer 22 and inverse transform 23 modules. If the<br><br>
decoder motion compensation 12 and encoder motion compensation 24 employ different rounding conventions is necessary to periodically run each frame through the full transcode path shown in Fig. 3 to ensure that there is no visible drift between the output of the original bitstream and the transcoder output.<br>
The H. 263 standard specifies that each macroblock must be intra coded at least once every 132 frames. There is no similar requirement in the MPEG-4 standard. In our method, to ensure that each macroblock satisfies the H. 263 intra coding constraint, the transcoder tracks the number of frames since the lastMPEG-4 I frame and, if there are more than 131 P frames in the MPEG-4 stream since the  lastl  frame,  forcibly encodes the  decoded  P  frame  as  an I  frame.<br>
If the input codec supports"Not Coded"frames and the output codec does not the pparatus will convert the frame. One method of conversion is for the transcoder to entirely drop the frame from the transcoded bitstream. A second method of conversion is for the transcoder to fransmit the   frame   as   a   P   frame   with   all   macroblocks   coded   as"not   coded"   macroblocks.<br>
The reference frame stores 14,25 are normally implemented as two separate frames in conventional decoders and encoders. One is the reference frame (the previous encoded frame) and one is the current encoded frame. When the codec motion vectors are only allowed to take a restricted range of values it is possible to reduce these storage requirements. In our method, we reduce the storage requirements substantially by recognizing that the only reference frame macroblocks that are used when a macroblock is encoded are its neighbors within     the      range      of     the      maximum      allowed      motion      vector      values.<br>
FIG 5 illustrates the macroblock buffering procedure using a QCIF sized frame 26 with its underlying 9 by 11 grid of macroblocks being encoded in baseline H. 263 as an example. This diagram is merely an example and should not unduly limit the scope of the claims herein. One<br><br>
of ordinary skill in the art would recognize many variations, alternatives, and modifications. The macroblocks immediately surrounding 28 the macroblock currently being encoded 27 contain pixels in the reference frame that may be used for motion compensation during the encoding. The macroblocks preceding the macroblock being coded 27 have already been encoded 29. The maximum range of baseline H. 263 motion vectors of - 16 to 15.5 pixels. Instead of storing the current image, we maintain a macroblock buffer 30 that can hold the number of macroblocks in an image row plus 1. After each macroblock is coded, the oldest macroblock in the buffer is written to its location in the reference image and the current macroblock is written in to the buffer.<br>
The buffer can also store whether or not each macroblock in the buffer is coded or "not coded". In the case of not coded"macroblocks, our method will skip writing these macroblocks into the buffer and writing them back out to the reference frame as the macroblock pixel values are unchanged from those in the reference frame.<br>
The previous description of the preferred embodiment is provided to enable any person skilled in the art to make or use the present invention. The various modifications to these embodiments will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other embodiments without the use of the inventive faculty. Thus, the present invention is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.<br><br><br>
WE CLAIM :<br>
1.	An apparatus for transcoding a video bitstream coded from a first hybrid video codec to a<br>
bitstream coded for a second hybrid video codec, the apparatus comprising ;<br>
a variable length decoder to decode the incoming video bitstream from the first hybrid video codec, the variable length decoder being adapted to output a decoded bitstream<br>
a unit to perform semantic conversion of the decoded symbols, the semantic conversion processing a portion of the decoded bitstream to adapt the decoded bitstream to be compatible with the second hybrid video codec; and<br>
a variable length encoder to encode the outgoing bitstream from the output of the unit to the second hybrid video codec.<br>
2.	The apparatus as claimed in claim 1 wherein the first video codec is baseline H. 263 and the second video codec is MPEG-4 and wherein the semantic conversion in the unit comprise an inverse intra AC prediction of a plurality of intra macroblock coefficients based upon one or more predetermined parameters.<br>
3.	The apparatus as claimed in claim 2 wherein the one or more predetermined parameters to perform the intra AC prediction is provided on a macroblock by macroblock basis and a processing is provided on the macroblock by macroblock basis.<br>
4.	A method for transcoding a video bitstream coded from a first hybrid video codec to a bitstream coded to a second hybrid video codec comprising:<br>
decoding of the input bitstream comprising a plurality of macroblocks from the first hybrid codec on a macroblock by macroblock basis among the plurality of macroblocks,<br>
determining if an input frame size of the plurality of macroblocks is supported by the second hybrid codec;<br>
converting the input frame size to be supported by the second hybrid codec if the input<br><br>
frame size is not supported by the second hybrid codec ; determining if one or more of a plurality of input motion vectors is supported by the second hybrid codec ;<br>
converting the one or more input motion vectors to be supported by the second hybrid codec if the one or more input motion vectors is not supported by the second hybrid codecs to form resulting transcodeddata ; and<br>
encoding of the transcoded data of the plurality of macroblocks on a macroblock by macroblock basis.<br>
5.	The method as claimed in claim 4 wherein the first video codec is Simple Profile MPEG 4 and the second video codec is Baseline H. 263.<br>
6.	The method as claimed in claim 4 wherein the input video frames that are not a valid output frame size are converted by setting the output frame size to the smallest valid output frame size that is larger than the input frame size and; for intra frames, encoding the additional macroblocks in the output frame as a fixed value, for inter frames, encoding the additional macroblocks       in       the       output       frame       as       "not       coded"       macroblock..<br>
7.	The method as claimed in claim 4 wherein the input video frames that are not a valid output frame size are converted by setting the output frame size to the largest valid output frame size that is smaller than the input frame size and cropping macroblocks from the input frame that do not fit in the output frame.<br>
8.	The method as claimed in claim 4 wherein the input macroblocks with multiple motion vectors are converted to a larger number of output motion vectors by replicating the motion vectors.<br>
9.	The method as claimed in claim 4 wherein the input macroblocks with multiple motion<br><br>
vectors are converted to a smaller number of output motion vectors by one or more processes comprising an arithmetic mean or a median process.<br>
10.	The method as claimed in claim 4 wherein the input motion vectors that reference a different reference frame than the output codec reference frame are scaled to form the output motion vectors.<br>
11.	The method as claimed in claim 4 wherein the input motion vectors that use a higher resolution than that supported by the output codec are rounded to the nearest valid output motion vector.<br>
12.	The method as claimed in claim 4 wherein the input motion vectors that are outside the range of valid output motion vectors are converted by clipping the components to the largest allowed output values.<br>
13.	The method as claimed in claim 4 wherein the input motion vectors that are outside the range of valid output motion vectors are converted by choosing the largest valid output vector with the same direction as the input vector.<br>
14.	The method as claimed in claim 4 wherein the determining, converting, determining, and converting are provided by computer codes.<br>
15.	The method as claimed in claim 9 wherein MPEG-4 macroblocks with 4 motion vectors are converted to a single motion vector by averaging the 4 vectors by one or more processes comprising an arithmetic mean or a median process.<br>
16.	The method as claimed in claim 12 wherein the MPEG-4 motion vectors that are outside<br><br>
the range of valid H. 263 motion vectors are converted by clipping the components to the largest allowed H. 263 values.<br>
17.	The method as claimed in claim 13 wherein the MPEG-4 motion vectors that are outside the range of valid H. 263 motion vectors are converted by choosing the largest valid H. 263 vector with the same direction as the MPEG-4 vector.<br>
18.	The method as claimed in claim 12 wherein the MPEG-4 motion vectors that point outside the video frame are converted by clipping the components of the vectors to the frame edge.<br>
19.	A method of transcoding the first hybrid codec and the second hybrid codec have a same spatial transform, same reference frames and quantization, same inter macroblocks with input motion vectors that are valid output motion vectors comprising :<br>
decoding of an input bitstream macroblock;<br>
determining if an input frame size of the plurality of macroblocks is supported by the second hybrid codec;<br>
converting the input frame size to be supported by the second hybrid codec if the input frame size is not supported by the second hybrid codec;<br>
performing a VLC encoding process one one or more of a plurality of quantized transform coefficients from the decoded input bitstream macroblock,<br>
using one or more of the macroblock pixel values from the decoded input bitstream macroblock to update an encoder reference frame.<br>
20.	The method as claimed m claim 19 comprising skipping at a predetermined frequency<br>
an optimized mode to prevent build up of a drift in a transcoding process of at least determining,<br>
converting, and performing..<br><br>
21.	The method as claimed in claim 19 wherein the first video codec is Simple Profile MPEG 4 and the second video codec is Baseline H. 263.<br>
22.	The method as claimed in claim 4 comprising converting selected input P frames into I frames.<br>
23.	The method as claimed in claim 4  comprising removing MPEG-4"Not Coded"frames from the decoded bitstream.<br>
24.     The method as claimed in claim 4 comprising converting one or more of MPEG-4"Not Coded"frames into an H. 263 P frame with each macroblock coded as a"notcoded"macroblock.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGFic3RyYWN0LWR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 abstract-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGFic3RyYWN0LmpwZw==" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 abstract.jpg</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGNsYWltcy1kdXBsaWNhdGUucGRm" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 claims-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGNvcnJlc3BvbmRlbmNlLXBvLnBkZg==" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 correspondence-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGRlc2NyaXB0aW9uIChjb21wbGV0ZSktZHVwbGljYXRlLnBkZg==" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 description (complete)-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGRyYXdpbmdzLWR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 drawings-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IGZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IG90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IHBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 pct.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIwMC1jaGVucC0yMDA1IHBldGl0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">0200-chenp-2005 petition.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="223267-optical-connector-assembly-coupling-device-and-method-for-aligning-such-a-coupling-device-and-waveguide-structure.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="223269-a-process-for-making-paper-or-paper-board.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>223268</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>200/CHENP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>47/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>21-Nov-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>09-Sep-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>16-Feb-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>DILITHIUM NETWORKS PTY LIMITED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>Level 7, 3 Smail Street, Broadway, NSW 2007,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>BROWN, Stephen, F</td>
											<td>26 Cobham Avenue, West Ryde, NSW 2114,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>JABRI, Marwan, A</td>
											<td>Level 7, 3 Smail Street, Broadway, NSW 2007,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/12</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2003/022175</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2003-07-15</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/431,054</td>
									<td>2002-12-04</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>10/620,329</td>
									<td>2003-07-14</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>3</td>
									<td>60/417,831</td>
									<td>2002-10-10</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>4</td>
									<td>60/396,689</td>
									<td>2002-07-17</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>5</td>
									<td>60/396,891</td>
									<td>2002-07-17</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/223268-method-and-apparatus-for-transcoding-between-hybrid-video-bitstreams by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 06:21:54 GMT -->
</html>
