<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/216042-method-and-apparatus-for-performing-high-quality-fast-predictive-motion-search by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:12:54 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 216042:&quot;METHOD AND APPARATUS FOR PERFORMING HIGH QUALITY FAST PREDICTIVE MOTION SEARCH&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;METHOD AND APPARATUS FOR PERFORMING HIGH QUALITY FAST PREDICTIVE MOTION SEARCH&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method and apparatus for performing motion search in a video encoder system using motion vectors representing the difference in coordinates of a macroblock of data in a current frame of video data and coordinates of a related macroblock of data in a reference frame of video data. A plurality of motion vector predictors (620) is obtained where the motion vector predictors represent approximations of possible motion vectors for a current macroblock. A search pattern (630) is defined. Each motion vector predictor of the plurality of motion vector predictors is searched around using the search pattern. A final motion vector (660) is then determined. (FIG. - 6)</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>METHOD AND APPARATUS FOR PERFORMING A PREDICTIVE<br>
MOTION SEARCH IN A VIDEO ENCODER SYSTEM<br>
BACKGROUND OF THE INVENTION<br>
Technical Field<br>
The present invention relates to a method and apparatus for performing<br>
predictive motion search in a video encoder system, and in particular to block-base<br>
motion estimation as applied to video image compression.<br>
Background Art<br>
Presently, motion estimation is a key component of many video compression<br>
techniques. The purpose of motion estimation is to reduce temporal redundancy<br>
between frames of a video sequence. A motion estimation algorithm predicts image<br>
data for an image frame using one or more previously coded image frames or future<br>
frames. A difference image is computed by taking the arithmetic difference between<br>
the original pixel data and the corresponding predicted pixel data. A difference image<br>
with large variations indicates little or no temporal redundancy between the image<br>
frames. Whereas, a difference image with small variations indicates a high degree of<br>
temporal redundancy between the image frames. The difference image represents a<br>
reduced temporal redundancy representation of the image frames, which yields better<br>
coding efficiency.<br>
One type of motion estimation algorithm is a block-based motion estimation<br>
algorithm. Block-based motion estimation algorithms operate on blocks of image<br>
data. A block of image data in a current frame is predicted by a block of data from a<br>
previous image frame. The motion estimation algorithm outputs a motion vector for<br>
the block of image data that specifies the location of the best block match from the<br>
previous image frame. In video compression methods, this motion vector information<br>
is compressed and transmitted or stored along with the compressed difference data.<br>
International video compression standards such as H.263, MPEG-2, and<br>
MPEG-4 allow block-based motion estimation by providing a syntax for specifying<br>
motion vectors. These standards do not require specific motion estimation<br>
algorithms. Within these compression standards, motion estimation is computed on a<br>
base block size of 16 x 16 pixels denoted as a macroblock. There are allowances to<br>
operate on block sizes of 8 x 8 pixels to estimate motion for smaller image regions.<br>
Motion Estimation is one of the most processor intensive units in a video<br>
encoding system. There are a number of existing block-based motion estimation<br>
techniques which try to strike a compromise between computational complexity and<br>
motion vector efficiency.<br>
Full search motion estimation (FSME) exhaustively compares a block in the<br>
current image frame to each pixel position located within a search window of a<br>
previously processed frame. The goodness of the block match at each pixel position<br>
is determined by measuring its corresponding distortion. A typical distortion measure<br>
used by block matching metrics is the sum of absolute difference (SAD) metric:<br><br>
Where, Bc is the block in the current image frame and Bp is a block in the previous<br>
image frame. The indices m and n index the pixels within a block of N rows and M<br>
columns. A small SAD value corresponds to a good block match and a large SAD<br>
value corresponds to a poor block match. Unfortunately, full search motion<br>
estimation becomes prohibitive as the search window is increased.<br>
Presently, there are several low complexity motion algorithms. All off these<br>
algorithms suffer from either offering poorer quality or from not offering enough<br>
reduction in computational complexity. There are also a few motion estimation<br>
algorithms proposed that offer somewhat improved quality at relatively reduced<br>
complexity.<br>
One possible approach is a zonal based approach. First, a motion vector<br>
predictor (PMV) is calculated as a best matching motion vector. Then, a motion<br>
vector search following a zonal pattern around the PMV is performed. This is<br>
followed by similar zonal search around a zero motion vector. At every step, there is<br>
a criterion to end the search if a good enough criterion is obtained. Unfortunately, this<br>
approach does not give consistently good results over a wide range of video<br>
sequences.<br>
A motion estimation algorithm called PMVFAST is very similar to the above<br>
described zonal approach. However, instead of a zonal search pattern, an iterative<br>
diamond search pattern is use. Large or small diamond search patterns can be used<br>
depending upon certain criteria. Unfortunately, this approach gives a very similar<br>
result when compared to the zonal approach.<br>
SUMMARY OF THE INVENTION<br>
A method and apparatus for performing a fast predictive motion search in a<br>
video encoder system using block-based motion estimation. The method may include<br>
obtaining a plurality of motion vector predictors, where the motion vector predictor<br>
can represent approximations of possible motion vectors for a current macroblock.<br>
The method may also include defining a search pattern, searching around each motion<br>
vector predictor of the plurality of motion vector predictors using the search pattern,<br>
and determining a final motion vector.<br>
BRIEF DESCRIPTION OF THE ACCOMPANYING DRAWINGS<br>
Fig. 1 is an exemplary block diagram of a video compression system,<br>
according to one embodiment;<br>
Fig. 2 is an exemplary depiction of a neighborhood of a current macroblock<br>
according to one embodiment;<br>
Fig. 3 is an exemplary search pattern used during a first stage of a preferred<br>
embodiment;<br>
Fig. 4 is an exemplary search pattern used in a capture mode during a first<br>
stage of a preferred embodiment;<br>
Fig. 5 is an exemplary illustration of a search pattern used during a second<br>
stage of a preferred embodiment;<br>
Fig. 6 is an exemplary flowchart outlining the operation of the present<br>
invention according to a preferred embodiment; and<br>
Fig. 7 is an exemplary block diagram of a fast predictive motion search motion<br>
estimation circuit according to one embodiment.<br>
DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS<br>
The present invention gives an improved performance over a wide range of<br>
video sequences. There are several improvements and new algorithmic innovations<br>
that result in better quality. In fact, when averaged over several video sequences, the<br>
present invention out-performs even the traditional full search algorithm in terms of<br>
achieved video compression efficiency.<br>
All the methods used in prior art focus on optimizing the block match, while,<br>
among other benefits, the present invention can explicitly take into account the<br>
number of bits needed to encode the video sequence. The present invention can also<br>
take advantage of the nature of motion encountered in real life video capture.<br>
Presently, with the wireless market taking off, there will be more requirements<br>
to enable video encoding technology on hand-held devices. Most of these devices do<br>
not have the processing capability to perform the intense computations of motion<br>
estimation. Thus, the high quality, low complexity motion estimation algorithm<br>
provided by the present invention can be extremely useful in such devices.<br>
According to one embodiment, the present invention can be performed in two<br>
stages. In the first stage several predictor motion vectors can be considered and a<br>
search around each of the candidates can be performed using a fixed search pattern.<br>
During the course of the first stage, if it is found that a good match is unlikely to be<br>
achieved, a new set of candidate motion vectors can be selected and a new search can<br>
be performed. This can be done to capture the motion of any new object that appears<br>
in the scene. In the second stage, the best result of the first stage can be considered<br>
and a new search using a moving, weighted, spiral search pattern can be performed to<br>
arrive the best block match.<br>
Fig. 1 is an exemplary block diagram of a video compression system 100 for a<br>
video encoder according to one embodiment. The video compression system 100 can<br>
include a fast predictive motion search motion estimation circuit 110, a motion<br>
compensation circuit 115, an adder 120, a discrete cosine transform circuit (DCT)<br>
125, a quantizer 130, a variable length code (VLC) encoder 135, an inverse quantizer<br>
140, an inverse discrete cosine transform circuit (IDCT) 145, another adder 150, and a<br>
previous frame circuit 155.<br>
In operation, motion estimation is computed for blocks of image data from a<br>
current image frame using one or more previously processed image frames. The<br>
motion estimation circuit 110 outputs a motion vector corresponding to a processed<br>
block. The motion compensation circuit 115 forms a prediction block from the<br>
previous frame using the computed motion vectors. A difference image is computed<br>
by the adder 120 by subtracting the predicted image data from the current image<br>
frame. This difference image is transformed using the DCT circuit 125. Whereas the<br>
motion estimation circuit 110 and the motion compensation circuit 115 serve to<br>
reduce the temporal redundancy between image frames, the DCT circuit 125 serves to<br>
reduce the spatial redundancy within a frame. The DCT coefficients are subsequently<br>
are subject to reduced precision by the quantizer 140. The quantizer 140 increases<br>
compression while introducing numerical loss. The quantized DCT coefficients are<br>
then encoded by the VLC encoder 135 and transmitted in a compressed video<br>
bitstream along with the motion vectors. The local reconstruction loop is comprised<br>
of the inverse quantizer 140, the IDCT 145, and the adder 150. The inverse quantizer<br>
140 reconstructs the DCT coefficients. The IDCT 145 transforms the DCT<br>
coefficients back into the spatial domain to form a quantized difference image. The<br>
reconstructed frame is computed by the adder 150 by adding the motion compensated<br>
data to the quantized difference image. This reconstructed data is then stored in the<br>
previous frame circuit 155 for use in processing subsequent image frames.<br>
The operation of the fast predictive motion search motion estimation circuit<br>
110 can consist of two stages. In the first stage, a small search can be done around<br>
several motion vector predictors. These motion vector predictors (MVP) can be<br>
obtained from other motion vectors (MV). For initial definitions, an MV is the<br>
difference in co-ordinates of a block of data in the current frame of video data and the<br>
block of data in the reference frame to which it is matched. An MV has two<br>
components: X and Y. The value of an MV is described as an ordered pair (X, Y).<br>
MVPs are MVs that are used as a good "guess" of the best MV when performing a<br>
match. A macroblock (MB) is a 16x16 block of data within a video frame. A MB<br>
can also refer to a blocks of data of different sizes as well (e.g. 8x8, 4x8, 4x4, 16x8<br>
etc.) without loss of generality.<br>
One motion vector predictor can be based on a zero motion vector. A motion<br>
vector predictor being based on a particular motion vector can define the motion<br>
vector predictor as equal to the particular motion vector. The zero motion vector<br>
being a motion vector with the coordinates of (0,0). A second motion vector predictor<br>
can be based on a motion vector of the co-located macroblock in the previous frame.<br>
Fig. 2 is an exemplary illustration of the location of a current macroblock and<br>
neighboring macroblocks used to determine additional motion vectors. Thus, a third<br>
motion vector predictor can be based on the motion vector of the macroblock to the<br>
left of the current macroblock. A fourth motion vector predictor can be based on the<br>
motion vector of the macroblock to the top of or above the current macroblock. A<br>
fifth motion vector predictor can be based on the motion vector of the macroblock<br>
above and to the right of the current macroblock. A sixth motion vector predictor can<br>
be based on the median motion vector of the third, fourth, and fifth motion vector<br>
predictors. This median motion vector predictor can be computed independently for<br>
the X and Y components of the motion vector.<br>
A seventh motion vector predictor can be based on an estimated global motion<br>
vector. This global motion vector is estimated by the motion estimation circuit 110 as<br>
the average of all final motion vectors of the previous frame for which a difference<br>
metric was below a certain threshold THRESH1. The difference metric can be a sum<br>
of absolute difference metric, a sum of squares difference metric, a modified sum of<br>
absolute difference metric, or any other useful metric. In the preferred embodiment,<br>
the value of THRESH1 chosen is:<br>
THRESH1 = SAD1 + OFFSET,<br>
Where OFFSET may nominally be set to 500<br>
Where SAD1 is given by the equation:<br><br>
Here m and n are indexes of the pixel. M and N are the dimensions of the<br>
block. For an example macroblock, M = N= 16. The global motion vector may also<br>
be determined by other means such as motion sensors on video cameras, other<br>
algorithms, or any other means for determining a global motion vector.<br>
Further motion vector predictors can be determined based on the result of<br>
motion estimation done for the same macroblock, but on a different previously coded<br>
frame.<br>
Thus, the motion estimation circuit 110 can determine the global motion<br>
vector by using an average of all final motion vectors in a previous frame for which a<br>
difference metric is below a specified threshold. In particular, the motion estimation<br>
circuit 110 can determine the global motion vector by calculating a difference metric<br>
for each of final motion vectors in a previous frame, comparing the difference metric<br>
for each of the final motion vectors in the previous frame with a predetermined<br>
threshold, and determining the global motion vector based on the each of the final<br>
motion vectors in a previous frame with a difference metric that is below the<br>
threshold.<br>
All MVs within a small region around each MVP can be searched. Then, the<br>
MV with the lowest Modified Sum of Absolute Differences (MS AD) metric can be<br>
chosen as the candidate MV for the second stage. The MSAD metric is defined<br>
below.<br>
Thus, the motion estimation circuit 110 can perform a predictive motion<br>
search by obtaining a plurality of motion vector predictors, the motion vector<br>
predictors representing approximations of possible motion vectors for a current<br>
macroblock, defining a search pattern, searching around each motion vector predictor<br>
of the plurality of motion vector predictors using the search pattern, and determining a<br>
final motion vector. The motion estimation circuit can further calculate a difference<br>
metric representing a quality of a macroblock match, where the difference metric can<br>
be a sum of absolute differences metric, a sum of squares of differences metric, or any<br>
other metric useful in motion estimation.<br>
An example search pattern around each MVP is shown in Fig. 3. As shown,<br>
the search pattern can extend more in the horizontal direction than in the vertical<br>
direction. This can take advantage of the fact that in most real life video data, there is<br>
more motion and variations in motion in the horizontal direction.<br>
If, after evaluating the first 6 motion vectors, the best MV has a MSAD metric<br>
higher than a threshold THRESH2, the first stage can go into capture mode.<br>
In the preferred embodiment, THRESH2 is given by:<br>
THRESH2 = 4* MMSADAVG,<br>
MMSADAVG = Average of all MMSADS (i.e. MSADS of best MVs) of the<br>
previous frame.<br>
In the capture mode, additional MVPs can be considered such as those<br>
depicted in Fig. 4. For example, the 8 points can be:<br>
(-12,0) (12, 0) (0, -8) (0, 8) (-6,4) (6,4) (6, -4) (-6, -4)<br>
A search around each of the MVPs is performed using the same search pattern<br>
depicted in Fig. 3. In the preferred embodiment, only 4 out of the 8 MVPs can be<br>
considered for a macroblock. For the first macroblock, the first 4 are considered. For<br>
the next macroblock the other 4 MVPs are considered and so on. This can be done to<br>
reduce the number of computations.<br>
The aim of the capture mode is to detect any new object that moves rapidly<br>
into the screen. In such a scenario, the MVPs based on neighborhood motion vectors<br>
would fail. Using the 8 new points improves the chance of getting a good motion<br>
vector match. The 8 points can be chosen to favor the horizontal direction since there<br>
often is more motion in this direction.<br>
Thus, the motion estimation circuit 110 can search around each motion vector<br>
predictor of the plurality of motion vector predictors using the search pattern,<br>
determine a best motion vector having a difference metric higher than a<br>
predetermined threshold, and perform a search pattern around a new set of motion<br>
vector predictors.<br>
In the first stage, when the search pattern around a MVP is being evaluated, an<br>
early exit criterion can be employed to terminate the search for that MVP. The search<br>
can be terminated if the MSAD obtained for the MV is higher than the current<br>
minimum MSAD (MMSAD) by a threshold THRESH3, i.e., if (MSAD1 &gt; (MMSAD +<br>
THRESH3)). Where MSAD1 is the MSAD obtained for MVPi, MMSAD is the<br>
minimum of all the MSAD values obtained until this point for the current MB. In<br>
particular, it is the MSAD of the best MV. In the preferred embodiment, the value of<br>
THRESH3 can be chosen to be around 768.<br>
Thus, the motion estimation circuit 110 can perform a search pattern on the<br>
motion vector predictors, determine a current difference metric for a current motion<br>
vector, compare the current difference metric to a previous minimum difference<br>
metric, set a new minimum difference metric if the current difference metric is below<br>
the previous minimum difference metric, and terminate the search pattern if the<br>
difference metric exceeds the previous minimum metric by a predetermined amount.<br>
Then, among all the MVs searched in the first stage, the MV that gives the<br>
lowest MSAD metric is chosen and this becomes a starting point for the second stage.<br>
In the second stage, the best MV from the first stage (i.e. the one giving the<br>
lowest MSAD) is chosen and a search is performed around this MV. For example,<br>
the search can be performed in a pattern as depicted in Fig. 5. The search pattern can<br>
start from the center and can spiral out in a sequence as shown in Fig. 5 as a sequence<br>
of numbers. As soon as a better MV is found (i.e. MV which gives a lower MSAD),<br>
the search pattern is re-centered around the new MV and the spiral search pattern<br>
starts over. This process continues until one of 3 conditions are met:<br>
CONDITION 1: The MSAD is below a threshold THRESH4, given by:<br>
THRESH4=A*Q + B<br>
Where Q is the quantization step size used by the encoder for the<br>
current MB, A and B are constants. In the preferred embodiment, A = 8<br>
and B = 0.<br>
CONDITION 2: The maximum number of candidates, N, have already been<br>
considered in stage 2. In the preferred embodiment, N = 30.<br>
CONDITION 3: These is no improvement in the minimum MSAD (MMSAD)<br>
during the last M candidate MVs. Here Mis a function of the index of<br>
the position of the last MV candidate in the spiral search pattern. For<br>
example, the search starts from index 0. It then spirals around points 1,<br>
2,3.....Whenever a better MV is found, the spiral search pattern gets<br>
re-centered around this new MV and the index starts from 0 once<br>
again. This index is used to determine the value of M. In the preferred<br>
embodiment, M is chosen from the set of values {4, 4, 4, 4, 4, 4, 4, 4,<br>
4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9} based on the<br>
index.<br>
The best MV at the end of the second stage is chosen as the best MV for the<br>
macroblock. This MV can be further refined for half-pixel, quarter-pixel or higher<br>
accuracy in a subsequent stage using well known techniques.<br>
As mentioned above, the search pattern can be chosen to give wider coverage<br>
to the horizontal direction than the vertical direction.<br>
The MSAD metric can be a useful part of the invention. While the modified<br>
sum of differences metric gives preferred results, any difference metric can be<br>
interchangeably used in every embodiment of the present invention requiring a sum of<br>
absolute differences metric, a modified sum of differences metric, or any other<br>
difference metric. The MSAD metric is a function of the sum of absolute differences<br>
(SAD) described above, the candidate MV being evaluated, and the predictor motion<br>
vector (PMV). The PMV is generally used by the video encoder during the encoding<br>
of the final motion vector. The final motion vector is encoded as a difference with<br>
respect to PMV, which is different from a MVP. For example, it can be a unique MV<br>
defined within H.261, H.263, MPEG-1, MPEG-2 and MPEG-4 standards for the<br>
purpose of encoding motion vectors. The SAD is the metric used in classical motion<br>
estimation algorithms as described above.<br>
For a macroblock with a given PMV and for a candidate motion vector MV,<br>
MSAD is given by<br>
MSAD = SAD + Bias<br>
Where the bias id any value that is based on a difference metric between MV<br>
and PMV. For example,<br><br>
Where SAD is the classical metric used for the matching blocks defined<br>
earlier, MVx and MVy are the X and Y components of the candidate motion vector,<br>
PMVx and PMVy are the X and Y components of PMV, and C is a constant. In the<br>
preferred embodiment, C is approximately 5. The PMV generally stays fixed for all<br>
the candidates in an MB, while the MV changes.<br>
The MSAD metric is independent of the motion estimation algorithm and can<br>
be used to advantage in practically all algorithms. The benefit of the new metric is the<br>
reduced number of bits needed to encode motion vectors by biasing the algorithm<br>
towards PMV thus improving the overall compression efficiency.<br>
The MSAD for the zero motion vector, MV = (0, 0), is treated as a special<br>
case. The zero MV could potentially lead to improved compression efficiency. But<br>
this can happen only if the resultant macroblock is coded in the "not coded" mode<br>
within H.261, H.263, MPEG-1, MPEG-2 and MPEG-4 standards. This can be taken<br>
into account by biasing the SAD in the case where it is below a certain threshold:<br>
If (SAD<thresh5></thresh5>
MSAD = SAD - THRESH6<br>
Else<br><br>
Endif<br>
C, PMVx and PMVy are as described earlier.<br>
THRESH5 = D*Q + E<br>
THRESH6 = F<br>
Where Q is the quantization step size. D, E and F are constants. In a preferred<br>
embodiment D is approximately 128, E - 0, and F is approximately 100.<br>
Thus, the motion estimation circuit 110 can calculate a difference metric,<br>
calculate a bias based on a predictor motion vector and a candidate motion vector, and<br>
determine a modified difference metric based on the difference metric and the bias.<br>
During the search process, it can be likely that search regions of different<br>
MVPs may overlap leading to repeated candidate motion vectors. A log can be<br>
maintained of all the candidates evaluated already and they are ignored if they have<br>
been considered already.<br>
The search sequences depicted are the ones used in the preferred embodiment.<br>
They have been optimized to get a good match in the quickest possible time over a<br>
wide range of video sequences. It is possible to use alternative search patterns as well.<br>
The disclosed invention does not make any assumptions on the motion vector<br>
range. Any restriction on the motion vector values can be applied on the candidates<br>
and, if they are beyond the allowed range, they can be discarded.<br>
In the second stage of the preferred embodiment, the spiral search pattern can<br>
be re-centered on obtaining a new best matched candidate MV. Thus, the next point<br>
that needs to be evaluated may not be known apriori. The next candidate to be<br>
evaluated potentially depends on the result of evaluating the current candidate. Hence<br>
it may becomes difficult to implement several candidate MSAD calculations in<br>
parallel (which some hardware architectures may want to do). To alleviate this, the<br>
re-centering of the search pattern can be done after evaluating a set of candidates,<br>
allowing the set to be processed in parallel.<br>
Fig. 6 is an exemplary flowchart 600 outlining the operation of the motion<br>
estimation circuit 110 according to one embodiment. In step 610, the flowchart<br>
begins. In step 620, the motion estimation circuit 110 obtains a plurality of motion<br>
vector predictors. In step 630, the motion estimation circuit 110 defines a search<br>
pattern. In step 640, the motion estimation circuit 110 searches around each motion<br>
vector predictor. In step 650, the motion estimation circuit 110 determines a final<br>
motion vector. In step 660, the motion estimation circuit 110 outputs the final motion<br>
vector.<br>
Fig. 7 is an exemplary block diagram of a fast predictive motion search motion<br>
estimation circuit 110 according to one embodiment. The motion estimation circuit<br>
110 can include a motion vector predictor storage circuit 710, a search pattern<br>
definition circuit 720, a plurality of motion vectors search circuit 730, and a final<br>
motion vector determination circuit 740. The motion estimation circuit 110 can also<br>
include a global motion vector determination circuit 750, a capture mode circuit 760,<br>
a pattern termination circuit 770, and a modified sum of absolute differences circuit<br>
780. The circuits operate in accordance with their like functions described above.<br>
According to another related embodiment, a fast predictive motion search<br>
method can be performed by two stages. In the first stage, the 7 MVP candidates can<br>
be computed as described above. Then, for each MVP, all MV candidates can be<br>
evaluated according to the search pattern in Fig. 3 and the exit criteria can be<br>
employed to break out of the MVP or go into the capture mode. Next, if in the<br>
capture mode, the search can be performed at and around the MVP depicted in Fig. 4<br>
using the same search pattern in Fig. 3 and the same exit criteria. Then, in the second<br>
stage, the best MV from the first stage can be chosen and a search can be performed<br>
in a spiral fashion depicted in Fig. 5. The spiral can be re-centered and reset the index<br>
can be reset to zero whenever a better match is found. Finally, the process can be<br>
continued until one of the three exit criteria are found.<br>
According to another related embodiment, the present invention provides a<br>
method for performing a fast predictive motion search in a video encoder system<br>
using block-based motion estimation. The method can include determining a plurality<br>
of motion vector predictors, performing a search pattern on at least one of the<br>
plurality of motion vector predictors, determining a best motion vector having a<br>
difference metric higher than a predetermined threshold, and performing a new search<br>
pattern around a new set of motion vector predictors. The step of performing a new<br>
search pattern can further perform a new search pattern around a new set of motion<br>
vector predictors based on a best motion vector. The new search pattern can be biased<br>
more in the horizontal direction than the vertical direction.<br>
According to another related embodiment, the present invention can provide a<br>
method for performing a fast predictive motion search in a video encoder system<br>
using block-based motion estimation. The method can include performing a search<br>
pattern around a motion vector predictor, determining a current difference metric for a<br>
current motion vector, comparing the current difference metric to a previous<br>
minimum difference metric, setting a new minimum difference metric if the current<br>
difference metric is below the previous minimum difference metric, and terminating<br>
the search pattern if the difference metric exceeds the previous minimum metric by a<br>
predetermined amount.<br>
According to another related embodiment, the present invention can provide a<br>
method for performing fast predictive motion search in a video encoder system using<br>
motion vectors representing the difference in coordinates of a macroblock of data in a<br>
current frame of video data and coordinates of a related macroblock of data in a<br>
reference frame of video data. The method can include defining a search pattern that<br>
is more extensive in a horizontal direction than in a vertical direction, performing a<br>
candidate search based on the defined search pattern, and determining a final motion<br>
vector.<br>
The disclosed invention can achieve a high degree of compression efficiency<br>
while keeping the complexity low. The complexity can be similar to the complexity<br>
of APDZS and PMVFAST. However, the achieved quality is higher. When<br>
compared with the standard full search algorithm, which is the accepted reference in<br>
the industry, the present invention achieves about 0.6% better compression efficiency<br>
for a fixed video quality. This number was obtained after averaging over 24 different<br>
QCIF video sequences.<br>
One application for this invention is in real time video encoders on hand held<br>
devices. The typical bandwidth of such encoded video is in the range 32 kbps to 512<br>
kbps and the typical video frame size is QCIF and CIF.<br>
The method of this invention is preferably implemented on a programmed<br>
processor. However, the video compression system 100, fast predictive motion search<br>
motion estimation circuitry 110, and other elements may also be implemented on a<br>
general purpose or special purpose computer, a programmed microprocessor or<br>
microcontroller and peripheral integrated circuit elements, an ASIC or other<br>
integrated circuit, a hardware electronic or logic circuit such as a discrete element<br>
circuit, a programmable logic device such as a PLD, PLA, FPGA or PAL, or the like.<br>
In general, any device on which resides a finite state machine capable of<br>
implementing the flowcharts shown in the Figures and the methods described may be<br>
used to implement the processor functions of this invention.<br>
While this invention has been described with specific embodiments thereof, it<br>
is evident that many alternatives, modifications, and variations will be apparent to<br>
those skilled in the art. For example, various components of the embodiments may be<br>
interchanged, added, or substituted in the other embodiments. Accordingly, the<br>
preferred embodiments of the invention as set forth herein are intended to be<br>
illustrative, not limiting. Various changes may be made without departing from the<br>
spirit and scope of the invention.<br>
WE CLAIM :<br>
1. A method for performing a predictive motion search in a video encoder<br>
system using motion vectors representing the difference in coordinates of a<br>
macroblock of data in a current frame of video data and coordinates of a related<br>
macroblock of data in a reference frame of video data, comprising:<br>
obtaining at least three motion vector predictors,<br>
the motion vector predictors representing approximations of<br>
possible motion vectors for a current macroblock;<br>
defining a search pattern;<br>
after obtaining all of said at least three motion vector predictors, searching<br>
around each motion vector predictor of the at least three motion vector predictors<br>
using the search pattern; and<br>
determining a final motion vector.<br>
2. The method as claimed in claim 1, comprising calculating a difference<br>
metric representing a quality of a macroblock match.<br>
3. The method as claimed in claim 2, wherein the difference metric is at least<br>
one of a sum of absolute differences metric and a sum of squares of differences<br>
metric.<br>
4. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors includes an estimated global motion vector.<br>
5. The method as claimed in claim 4, wherein the estimated global motion<br>
vector is an average of all final motion vectors in a previous frame for which a<br>
difference metric is below a specified threshold.<br>
6. The method as claimed in claim 4, wherein the estimated global motion<br>
vector is determined by:<br>
calculating a difference metric for final motion vectors in a previous frame;<br>
comparing the difference metric for the final motion vectors in the previous<br>
frame with a predetermined threshold; and<br>
determining the global motion vector based on the each of the final<br>
motion vectors in a previous frame with a difference metric that is below the<br>
threshold.<br>
7. The method as claimed in claim 1, wherein the step of searching<br>
comprises:<br>
searching around each motion vector predictor of the at least three motion<br>
vector predictors using the search pattern;<br>
determining a best motion vector having a difference metric higher than a<br>
predetermined threshold; and<br>
performing a search pattern around a new set of motion vector predictors.<br>
8. The method as claimed in claim 1, wherein the step of searching<br>
comprises:<br>
performing a search pattern on the motion vector predictors;<br>
determining a current difference metric for a current motion vector;<br>
comparing the current difference metric to a previous minimum difference<br>
metric;<br>
setting a new minimum difference metric if the current difference metric is<br>
below the previous minimum difference metric; and<br>
terminating the search pattern if the difference metric exceeds the<br>
previous minimum metric by a predetermined amount.<br>
9. The method as claimed in claim 1, comprising:<br>
calculating a difference metric;<br>
calculating a bias based on a predictor motion vector and a candidate<br>
motion vector; and<br>
determining a modified difference metric based on the difference metric<br>
and the bias.<br>
10. The method as claimed in claim 1, wherein the step of defining a search<br>
pattern comprises defining a search pattern that is more extensive in a horizontal<br>
direction than in a vertical direction.<br>
11. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors include a zero motion vector.<br>
12. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors include a motion vector of a co-located macroblock from a<br>
previous frame.<br>
13. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors include a motion vector of a macroblock located to the left of<br>
the current macroblock.<br>
14. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors include a motion vector of a macroblock located above the<br>
current macroblock.<br>
15. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors include a motion vector of a macroblock located above and to<br>
the right of the current macroblock.<br>
16. The method as claimed in claim 1, wherein the at least three motion<br>
vector predictors include a median motion vector resulting from the median<br>
horizontal and vertical coordinates of<br>
a motion vector of a macroblock located to the left of the current<br>
macroblock,<br>
a motion vector of a macroblock located above the current macroblock,<br>
and<br>
a motion vector of a macroblock located above and to the right of the<br>
current macroblock.<br>
17. An apparatus for performing fast predictive motion search in a video<br>
encoder system using motion vectors representing the difference in coordinates<br>
of a macroblock of data in a current frame of video data and coordinates of a<br>
related macroblock of data in a reference frame of video data, comprising:<br>
a current image macroblock input;<br>
a fast predictive motion search motion estimation circuit coupled to the<br>
current image macroblock input, including<br>
a motion vector predictor storage circuit,<br>
a search pattern definition circuit configured to define a search<br>
pattern,<br>
an at least three motion vector predictors search circuit<br>
coupled to the motion vector predictor storage circuit and the search pattern<br>
definition circuit, the at least three motion predictor vector predictors search<br>
circuit configured to search around each motion vector predictor of at least three<br>
of a current macroblock using the search pattern after obtaining the at least three<br>
motion vector predictors, and<br>
a final motion vector determination circuit; and<br>
a motion vector output.<br>
18. The apparatus as claimed in claim 17, comprising:<br>
a motion compensation circuit coupled to the fast predictive motion search<br>
motion estimation circuit; and<br>
an adder coupled to the current image macroblock input and coupled to<br>
the motion compensation circuit.<br>
19. The apparatus as claimed in claim 18, comprising:<br>
a discrete cosine transform circuit coupled to the adder; and<br>
a quantizer coupled to the discrete cosine transform circuit.<br>
20. The apparatus as claimed in claim 17, wherein the fast predictive motion<br>
search motion estimation circuit includes a global motion vector determination<br>
circuit.<br>
21. The apparatus as claimed in claim 17, wherein the fast predictive motion<br>
search motion estimation circuit includes a capture mode circuit.<br>
22. The apparatus as claimed in claim 17, wherein the fast predictive motion<br>
search motion estimation circuit includes a search pattern termination if a<br>
difference metric exceeds a previous minimum metric by a predetermined<br>
amount circuit.<br>
23. The apparatus as claimed in claim 17, wherein the fast predictive motion<br>
search motion estimation circuit includes a modified sum of absolute differences<br>
determination circuit.<br>
24. The apparatus as claimed in claim 17, wherein the motion vector predictor<br>
storage circuit stores a plurality of motion vector predictors.<br>
25. The apparatus as claimed in claim 24, wherein the plurality of motion<br>
vector predictors include a zero motion vector.<br>
26. The apparatus as claimed in claim 25, wherein the plurality of motion<br>
vector predictors include a motion vector of a co-located macroblock from a<br>
previous frame.<br>
27. The apparatus as claimed in claim 25, wherein the plurality of motion<br>
vector predictors include a median motion vector resulting from the median<br>
horizontal and vertical coordinates of<br>
a motion vector of a macroblock located to the left of the current<br>
macroblock,<br>
a motion vector of a macroblock located above the current macroblock,<br>
and<br>
a motion vector of a macroblock located above and to the right of the<br>
current macroblock.<br>
28. A mobile communication device comprising an apparatus for performing<br>
fast predictive motion search in a video encoder system using motion vectors<br>
representing the difference in coordinates of a macroblock of data in a current<br>
frame of video data and coordinates of a related macroblock of data in a<br>
reference frame of video data, comprising:<br>
a current image macroblock input;<br>
a fast predictive motion search motion estimation circuit coupled to the<br>
current image macroblock input, including<br>
a motion vector predictor storage circuit,<br>
a search pattern definition circuit configured to define a search<br>
pattern,<br>
a plurality of motion vector predictors search circuit coupled to the<br>
motion vector predictor storage circuit and the search pattern definition circuit,<br>
the plurality of the motion vector predictors search circuit configured to search<br>
around each motion vector predictor of a plurality of motion vector predictors of a<br>
current macroblock using the search pattern after obtain the plurality of motion<br>
vector predictors, and<br>
a final motion vector determination circuit; and<br>
a motion vector output.<br>
A method and apparatus for performing motion search in a video<br>
encoder system using motion vectors representing the difference in<br>
coordinates of a macroblock of data in a current frame of video data and<br>
coordinates of a related macroblock of data in a reference frame of video<br>
data. A plurality of motion vector predictors (620) is obtained where the<br>
motion vector predictors represent approximations of possible motion vectors<br>
for a current macroblock. A search pattern (630) is defined. Each motion<br>
vector predictor of the plurality of motion vector predictors is searched around<br>
using the search pattern. A final motion vector (660) is then determined.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1hc3NpZ25tZW50LnBkZg==" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1jb3JyZXNwb25kZW5jZS5wZGY=" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1leGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1ncGEucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1sZXR0ZXIgcGF0ZW50LnBkZg==" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-letter patent.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1wYS5wZGY=" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-pa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1yZXBseSB0byBleGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3LWtvbG5wLTIwMDUtZ3JhbnRlZC1zcGVjaWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">257-kolnp-2005-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="216041-a-polyethylene-polymer-composition.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="216043-a-polynucleotide-vaccine.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>216042</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>00257/KOLNP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>10/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>07-Mar-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>06-Mar-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>23-Feb-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>MOTOROLA, INC</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>1303, EAST ALGONQUIN ROADM, SCHAUMBURG, USA.</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>GANDHI BHAVAN</td>
											<td>62 EAST DEPOT STREET, VERMON HILLS, USA.</td>
										</tr>
										<tr>
											<td>2</td>
											<td>SUBRAMANIYAN RAGHYAVAN</td>
											<td>1919 PRAIRIE SQUARE # 216, SCHAUMBURG, USA.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>D04B 15/48</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2003/023286</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2003-07-25</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10/212/940</td>
									<td>2002-08-06</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/216042-method-and-apparatus-for-performing-high-quality-fast-predictive-motion-search by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:12:55 GMT -->
</html>
