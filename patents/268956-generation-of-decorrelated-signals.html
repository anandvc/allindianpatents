<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/268956-generation-of-decorrelated-signals by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:34:39 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 268956:GENERATION OF DECORRELATED SIGNALS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">GENERATION OF DECORRELATED SIGNALS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>In a case of transient audio input signals, in a multi-channel audio reconstruction, uncorrelated output signals are generated from an audio input signal in that the audio input signal is mixed with a representation of the audio input signal delayed by a delay time such that, in a first time interval, a first output signal corresponds to the audio input signal, and a second output signal corresponds to the delayed representation of the audio input signal, wherein, in a second time interval, the first output signal corresponds to the delayed representation of the audio input signal, and the second output signal corresponds to the audio input signal.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Description<br>
The present invention involves an apparatus and a method of<br>
generating decorrelated signals and in particular the<br>
ability of deriving decorrelated signals from a signal<br>
containing transients such that reconstructing a four-<br>
channel audio signal and/or a future combination of the<br>
decorrelated signal and the transient signal will not<br>
result in any audible signal degradation.<br>
Many applications in the field of audio signal processing<br>
require generating a decorrelated signal based on an audio<br>
input signal provided. As examples thereof, the stereo<br>
upmix of a mono signal, the four-channel upmix based on a<br>
mono or stereo signal, the generation of artificial<br>
reverberation or the widening of the stereo basis may be<br>
named.<br>
Current methods and/or systems suffer from extensive<br>
degradation of the quality and/or the perceivable sound<br>
impression when confronted with a special class of signals<br>
(applause-like signals). This is specifically the case when<br>
the playback is effected via headphones. In addition to<br>
that, standard decorrelators use methods exhibiting high<br>
complexity and/or high computing expenditure.<br>
For emphasizing the problem, Figs. 7 and 8 show the use of<br>
decorrelators in signal processing. Here, brief reference<br>
is made to the mono-to-stereo decoder shown in Fig. 7.<br>
Same comprises a standard decorrelator 10 and a mix matrix<br>
12. The mono-to-stereo decoder serves for converting a fed-<br>
in mono signal 14 to a stereo signal 16 consisting of a<br>
left channel 16a and a right channel 16b. From the fed-in<br>
mono signal 14, the standard decorrelator 10 generates a<br><br>
decorrelated signal 18 (D) which, together with the fed-in<br>
mono signal 14, is applied to the inputs of the mix matrix<br>
12. In this context, the untreated mono signal is often<br>
also referred to as a "dry" signal, whereas the<br>
decorrelated signal D is referred to as a "wet" signal.<br>
The mix matrix 12 combines the decorrelated signal 18 and<br>
the fed-in mono signal 14 so as to generate the stereo<br>
signal 16. Here, the coefficients of the mix matrix 12 (H)<br>
may either be fixedly given, signal-dependent or dependent<br>
on a user input. In addition, this mixing process performed<br>
by the mix matrix 12 may also be frequency-selective. I.e.,<br>
different mixing operations and/or matrix coefficients may<br>
be employed for different frequency ranges (frequency<br>
bands). For this purpose, the fed-in mono signal 14 may be<br>
preprocessed by a filter bank so that same, together with<br>
the decorrelated signal 18, is present in a filter bank<br>
representation, in which the signal portions pertaining to<br>
different frequency bands are each processed separately.<br>
The control of the upmix process, i.e. of the coefficients<br>
of the mix matrix 12, may be performed by user interaction<br>
via a mix control 20. In addition, the coefficients of the<br>
mix matrix 12 (H) may also be effected via so-called "side<br>
information", which is transferred together with the fed-in<br>
mono signal 14 (the downmix) . Here, the side information<br>
contains a parametric description as to how the multi-<br>
channel signal generated is to be generated from the fed-in<br>
mono signal 14 (the transmitted signal). This spatial side<br>
information is typically generated by an encoder prior to<br>
the actual downmix, i.e. the generation of the fed-in mono<br>
signal 14.<br>
The above-described process is normally employed in<br>
parametric (spatial) audio coding. As an example, the so-<br>
called "Parametric Stereo" coding (H. Purnhagen: "Low<br>
Complexity Parametric Stereo Coding in MPEG-4", 7th<br>
International Conference on Audio Effects (DAFX-04),<br><br>
Naples, Italy, October 2004) and the MPEG Surround method<br>
(L. Villemoes, J. Herre, J. Breebaart, G. Hotho, S. Disch,<br>
H. Purnhagen, K. KjSrling: "MPEG Surround: The forthcoming<br>
ISO standard for spatial audio coding", AES 28th<br>
International Conference, Pitea, Sweden, 2006) use such a<br>
method.<br>
One typical example of a Parametric Stereo decoder is shown<br>
in Fig. 8. In addition to the simple, non-frequency-<br>
selective case shown in Fig. 7, the decoder shown in Fig. 6<br>
comprises an analysis filter bank 30 and a synthesis filter<br>
bank 32. This is the case, as here decorrelating is<br>
performed in a frequency-dependent manner (in the spectral<br>
domain) . For this reason, the fed-in mono signal 14 is<br>
first split into signal portions for different frequency<br>
ranges by the analysis filter bank 30. I.e., for each<br>
frequency band its own decorrelated signal is generated<br>
analogously to the example described above. In addition to<br>
the fed-in mono signal 14, spatial parameters 34 are<br>
transferred, which serve to determine or vary the matrix<br>
elements of the mix matrix 12 so as to generate a mixed<br>
signal which, by means of the synthesis filter bank 32, is<br>
transformed back into the time domain so as to form the<br>
stereo signal 16.<br>
In addition, the spatial parameters 34 may optionally be<br>
altered via a parameter control 36 so as to generate the<br>
upmix and/or the stereo signal 16 for different playback<br>
scenarios in a different manner and/or optimally adjust the<br>
playback quality to the respective scenario. If the spatial<br>
parameters 34 are adjusted for binaural playback, for<br>
example, the spatial parameters 34 may be combined with<br>
parameters of the binaural filters so as to form the<br>
parameters controlling the mix matrix 12. Alternatively,<br>
the parameters may be altered by direct user interaction or<br>
other tools and/or algorithms (see, for example: Breebart,<br>
Jeroen; Herre, Jurgen; Jin, Craig; Kjorling, Kristofer;<br>
Koppens, Jeroen; Plogisties, Jan; Villemoes, Lars: Multi-<br><br>
Channel Goes Mobile: MPEG Surround Binaural Rendering. AES<br>
29th International Conference, Seoul, Korea, 2006 September<br>
2 - 4) .<br>
The output of the channels L and R of the mix matrix 12 (H)<br>
is generated from the fed-in mono signal 14 (M) and the<br>
decorrelated signal 18 (D) as follows, for example:<br><br>
Therefore, the portion of the decorrelated signal 18 (D)<br>
contained in the output signal is adjusted in the mix<br>
matrix 12. In the process, the mixing ratio is time-varied<br>
based on the spatial parameters 34 transferred. These<br>
parameters may, for example, be parameters describing the<br>
correlation of two original signals (parameters of this<br>
kind are used in MPEG Surround Coding, for example, and<br>
there are referred to, among other things, as ICC) . In<br>
addition, parameters may be transferred, which transfer the<br>
energy ratios of two channels originally present, which are<br>
contained in the fed-in mono signal 14 (ICLD and/or ICD in<br>
MPEG Surround). Alternatively, or in addition, the matrix<br>
elements may be varied by direct user input.<br>
For the generation of the decorrelated signals, a series of<br>
different methods have so far been used.<br>
Parametric Stereo and MPEG Surround use all-pass filters,<br>
i.e. filters passing the entire spectral range but having a<br>
spectrally dependent filter characteristic. In Binaural Cue<br>
Coding (BCC, Faller and Baumgarte, see, for example: C.<br>
Faller: "Parametric Coding Of Spatial Audio", Ph.. D. thesis,<br>
EPFL, 2004) a "group delay" for decorrelation is proposed.<br>
For this purpose, a frequency-dependent group delay is<br>
applied to the signal by altering the phases in the DFT<br>
spectrum of the signal. That is, different frequency ranges<br><br>
are delayed for different periods of time. Such a method<br>
usually falls under the category of phase manipulations.<br>
In addition, the use of simple delays, i.e. fixed time<br>
delays, is known. This method is used for generating<br>
surround signals for the rear speakers in a four-channel<br>
configuration, for example, so as to decorrelate same from<br>
the front signals as far as perception is concerned. A<br>
typical such matrix surround system is Dolby ProLogic II,<br>
which uses a time delay from 20 to 40 ms for the rear audio<br>
channels. Such a simple implementation may be used for<br>
creating a decorrelation of the front and rear speakers as<br>
same is substantially less critical, as far as the<br>
listening experience is concerned, than the decorrelation<br>
of left and right channels. This is of substantial<br>
importance for the "width" of the reconstructed signal as<br>
perceived by the listener (see: J. Blauert: "Spatial<br>
hearing: The psychophysics of human sound localization";<br>
MIT Press, Revised edition, 1997).<br>
The popular decorrelation methods described above exhibit<br>
the following substantial drawbacks:<br>
spectral coloration of the signal (comb-filter<br>
effect)<br>
reduced "crispness" of the signal<br>
disturbing echo and reverberation effects<br>
unsatisfactorily perceived decorrelation and/or<br>
unsatisfactory width of the audio mapping<br>
repetitive sound character.<br>
Here, the invention has shown that it is in particular<br>
signals having high temporal density and spatial<br>
distribution of transient events, which are transferred<br>
together with a broadband noise-like signal component, that<br>
represent the signals most critical for this type of signal<br>
processing. This is in particular the case for applause-<br>
like signals possessing the above-mentioned properties.<br><br>
This is due to the fact that, by the decorrelation, each<br>
single transient signal (event) may be smeared in terms of<br>
time, whereas at the same time the noise-like background is<br>
rendered spectrally colored due to comb-filter effects,<br>
which is easy to perceive as a change in the signal's<br>
timbre.<br>
To summarize, the known decorrelation methods either<br>
generate the above-mentioned artefacts or else are unable<br>
to generate the required degree of decorrelation.<br>
It is especially to be noted that listening via headphones<br>
is generally more critical than listening via speakers. For<br>
this reason, the above-described drawbacks are relevant in<br>
particular for applications that generally require<br>
listening by means of headphones. This is generally the<br>
case for portable playback devices, which, in addition,<br>
have a low energy supply only. In this context, the<br>
computing capacity which has to be spent on the<br>
decorrelation is also an important aspect. Most of the<br>
known decorrelation algorithms are extremely<br>
computationally intensive. In an implementation these<br>
therefore require a relatively high number of calculation<br>
operations, which result in having to use fast processors,<br>
which inevitably consume large amounts of energy. In<br>
addition, a large amount of memory is required for<br>
implementing such complex algorithms. This, in turn,<br>
results in increased energy demand.<br>
Particularly in the playback of binaural signals (and in<br>
listening via headphones) a number of special problems will<br>
occur concerning the perceived reproduction quality of the<br>
rendered signal. For one thing, in the case of applause<br>
signals, it is particularly important to correctly render<br>
the attack of each clapping event so as not to corrupt the<br>
transient event. A decorrelator is therefore required,<br>
which does not smear the attack in time in terms of time,<br>
i.e. which does not exhibit any temporally dispersive<br><br>
characteristic. Filters described above, which introduce<br>
frequency-dependent group delay, and all-pass filters in<br>
general are not suitable for this purpose. In addition, it<br>
is necessary to avoid a repetitive sound impression as is<br>
caused by a simple time delay, for example. If such a<br>
simple time delay were used to generate a decoded signal,<br>
which was then added to the direct signal by means of a mix<br>
matrix, the result would sound extremely repetitive and<br>
therefore unnatural. Such a static delay in addition<br>
generates comb-filter effects, i.e. undesired spectral<br>
colorations in the reconstructed signal.<br>
A use in simple time delays in addition results in the<br>
known precedence effect (see, for example: J. Blauert:<br>
"Spatial hearing: The psychophysics of human sound<br>
localization"; MIT Press, Revised edition, 1997). Same<br>
originates from the fact that there is an output channel<br>
leading in terms of time and an output channel following in<br>
terms of time when a simple time delay is used. The human<br>
ear perceives the origin of a tone or sound or an object in<br>
that spatial direction from which it first hears the noise.<br>
I.e., the signal source is perceived in that direction in<br>
which the signal portion of the temporally leading output<br>
channel (leading signal) happens to be played back,<br>
irrespective of whether the spatial parameters actually<br>
responsible for the spatial allocation indicate something<br>
different.<br>
It is the object of the present invention to provide an<br>
apparatus and a method of decorrelating signals which<br>
improves the signal quality in the presence of transient<br>
signals.<br>
This object is achieved by a decorrelator according to<br>
claim 1 and a method of generating decorrelated signals<br>
according to claim 16.<br><br>
Here, the present invention is based on the finding that,<br>
for transient audio input signals, decorrelated output<br>
signals may be generated in that the audio input signal is<br>
mixed with a representation of the audio input signal<br>
delayed by a delay time such that, in a first time<br>
interval, a first output signal corresponds to the audio<br>
input signal and a second output signal corresponds to the<br>
delayed representation of the audio input signal, wherein,<br>
in a second time interval, the first output signal<br>
corresponds to the delayed representation of the audio<br>
input signal and the second output signal corresponds to<br>
the audio input signal.<br>
In other words, two signals decorrelated from each other<br>
are derived from an audio input signal such that first a<br>
time-delayed copy of the audio input signal is generated.<br>
Then the two output signals are generated in that the audio<br>
input signal and the delayed representation of the audio<br>
input signal are alternately used for the two output<br>
signals.<br>
In a time-discrete representation, this means that the<br>
series of samples of the output signals are alternately<br>
used directly from the audio input signal and from the<br>
delayed representation of the audio input signal. For<br>
generating the decorrelated signal, here a time delay is<br>
used which is frequency-independent and therefore does not<br>
temporally smear the attacks of the clapping noise. In the<br>
case of a time-discrete representation, a time delay chain<br>
exhibiting a low number of memory elements is a good trade-<br>
off between the achievable spatial width of a reconstructed<br>
signal and the additional memory requirements. The delay<br>
time chosen is preferred to be smaller than 50 ms and<br>
especially preferred to be smaller than or equal to 30 ms.<br>
Therefore, the problem of the precedence is solved in that,<br>
in a first time interval, the audio input signal directly<br>
forms the left channel, whereas, in the subsequent second<br><br>
time interval, the delayed representation of the audio<br>
input signal is used as the left channel. The same<br>
procedure applies to the right channel.<br>
In a preferred embodiment, the switching time between the<br>
individual swapping processes is selected to be longer than<br>
the period of a transient event typically occurring in the<br>
signal. I.e., if the leading and the subsequent channel are<br>
periodically (or randomly) swapped at intervals (of a<br>
length of 100 ms, for example), a corruption of the<br>
direction locating due to . the sluggishness of the human<br>
hearing apparatus may be suppressed if the choice of the<br>
interval length is suitably made.<br>
According to the invention, it is therefore possible to<br>
generate a broad sound field which does not corrupt<br>
transient signals (such as clapping) and in addition<br>
neither exhibits a repetitive sound character.<br>
The inventive decorrelators use an extremely small number<br>
of arithmetic operations only. In particular, only one<br>
single time delay and a small number of multiplications are<br>
required to inventively generate decorrelated signals. The<br>
swapping of individual channels is a simple copy operation<br>
and requires no additional computing expenditure. Optional<br>
signal-adaptation and/or post-processing methods also only<br>
require an addition or a subtraction, respectively, i.e.<br>
operations that may typically be taken - over by already<br>
existing hardware. Therefore, only a very small amount of<br>
additional memory is required for implementing the delaying<br>
means or the delay line. Same exists in many systems and<br>
may be used along with them, as the case may be.<br>
In the following, preferred embodiments of the present<br>
invention are explained in greater detail referring to the<br>
accompanying drawings, in which<br>
Fig. 1 shows an embodiment of an inventive decorrelator;<br><br>
Fig. 2 shows an illustration of the inventively<br>
generated decorrelated signals;<br>
Fig. 2a shows a further embodiment of an inventive<br>
decorrelator;<br>
Fig. 2b shows embodiments of possible control signals for<br>
the decorrelator of Fig. 2a;<br>
Fig. 3 shows a further embodiment of an inventive<br>
decorrelator<br>
Fig. 4 shows an example of an apparatus for generating<br>
decorrelated signals;<br>
Fig. 5 shows an example of an inventive method for<br>
generating output signals;<br>
Fig. 6 shows an example of an inventive audio decoder;<br>
Fig. 7 shows an example of an upmixer according to prior<br>
art; and<br>
Fig. 8 shows a further example of an upmixer/decoder<br>
according to prior art.<br>
Fig. 1 shows an example of an inventive decorrelator for<br>
generating a first output signal 50 (L, ) and a second<br>
output signal 52 (R'), based on an audio input signal 54<br>
(M) .<br>
The decorrelator further includes delaying means 56 so as<br>
to generate a delayed representation of the audio input<br>
signal 58 (M_d). The decorrelator further comprises a mixer<br>
60 for combining the delayed representation of the audio<br>
input signal 58 with the audio input signal 54 so as to<br>
obtain the first output signal 50 and the second output<br><br>
signal 52. The mixer 60 is formed by the two schematically<br>
illustrated switches, by means of which the audio input<br>
signal 54 is alternately switched to the left output signal<br>
50 and the right output signal 52. Same also applies to the<br>
delayed representation of the audio input signal 58. The<br>
mixer 60 of the decorrelator therefore functions such that,<br>
in a first time interval, the first output signal 50<br>
corresponds to the audio input signal 54 and the second<br>
output signal corresponds to the delayed representation of<br>
the audio input signal 58, wherein, in a second time<br>
interval, the first output signal 50 corresponds to the<br>
delayed representation of the audio input signal and the<br>
second output signal 52 corresponds to the audio input<br>
signal 54.<br>
That is, according to the invention, a decorrelation is<br>
achieved in that a time-delayed copy of the audio input<br>
signal 54 is prepared and that then the audio input signal<br>
54 and the delayed representation of the audio input signal<br>
58 are alternately used as output channels. I.e., the<br>
components forming the output signals (audio input signal<br>
54 and delayed representation of the audio input signal 58)<br>
are swapped in a clocked manner. Here, the length of the<br>
time interval for which each swapping is made, or for which<br>
an input signal corresponds to an output signal, is<br>
variable. In addition, the time intervals for which the<br>
individual components are swapped may have different<br>
lengths. This means then that the ratio of those times in<br>
which the first output signal 50 consists of the audio<br>
input signal 54 and the delayed representation of the audio<br>
input signal 58 may be variably adjusted.<br>
Here, the preferred period of the time intervals is longer<br>
than the average period of transient portions contained in<br>
the audio input signal 54 so as to obtain good reproduction<br>
of the signal.<br><br>
Suitable time periods here are in the time interval of<br>
10 ms to 200 ms, a typical time period being 100 ms, for<br>
example.<br>
In addition to the switching time intervals, the period of<br>
the time delay may be adjusted to the conditions of the<br>
signal or may even be time variable. The delay times are<br>
preferably found in an interval from 2 ms to 50 ms.<br>
Examples of suitable delay times are 3, 6, 9, 12, 15 or<br>
3 0 ms.<br>
The inventive decorrelator shown in Fig. 1 for one thing<br>
enables generating decorrelated signals that do not smear<br>
the attack, i.e. the beginning, of transient signals and in<br>
addition ensure a very high decorrelation of the signal,<br>
which results in the fact that a listener perceives a<br>
multi-channel signal reconstructed by means of such a<br>
decorrelated signal as a particularly spatially extended<br>
signal.<br>
As can be seen from Fig. 1, the inventive decorrelator may<br>
be employed both for continuous audio signals and for<br>
sampled audio signals, i.e. for signals that are present as<br>
a sequence of discrete samples.<br>
By means of such a signal present in discrete samples, Fig.<br>
2 shows the operation of the decorrelator of Fig.. 1.<br>
Here, the audio input signal 54 present in the form of a<br>
sequence of discrete samples and the delayed representation<br>
of the audio input signal 58 is considered. The mixer 60 is<br>
only represented schematically as two possible connecting<br>
paths between the audio input signal 54 and the delayed<br>
representation of the audio input signal 58 and the two<br>
output signals 50 and 52. In addition, a first time<br>
interval 70 is shown, in which the first output signal 50<br>
corresponds to the audio input signal 54 and the second<br>
output signal 52 corresponds to the delayed representation<br><br>
of the audio input signal 58. According to the operation of<br>
the mixer, in the second time interval 72, the first output<br>
signal 50 corresponds to the delayed representation of the<br>
audio input signal 58 and the second output signal 52<br>
corresponds to the audio input signal 54.<br>
In the case shown in Fig. 2, the time periods of the first<br>
time interval 70 and the second time interval 72 are<br>
identical, while this is not a precondition, as explained<br>
above.<br>
In the case represented, it amounts to the temporal<br>
equivalent of four samples, so that at a clock of four<br>
samples, a switch is made between the two signals 54 and 58<br>
so as to form the first output signal 50 and the second<br>
output signal 52.<br>
The inventive concept for decorrelating signals may be<br>
employed in the time domain, i.e. with the temporal<br>
resolution given by the sample frequency. The concept may<br>
just as well be applied to a filter-bank representation of<br>
a signal in which the signal (audio signal) is split into<br>
several discrete frequency ranges, wherein the signal per<br>
frequency range is usually present with reduced time<br>
resolution.<br>
Fig. 2a shows a further embodiment, in which the mixer 60<br>
is configured such that, in a first time interval, the<br>
first output signal 50 is to a first proportion X(t) formed<br>
from the audio input signal 54 and to a second proportion<br>
(l-X(t)) formed from the delayed representation of the<br>
audio input signal 58. Accordingly, in the first time<br>
interval, the second output signal 52 is to a proportion<br>
X(t) formed from the delayed representation of the audio<br>
input signal 58 and to a proportion (l-X(t)) formed from<br>
the audio input signal 54. Possible implementations of the<br>
function X(t), which may be referred to as a. cross-fade<br>
function, are shown in Fig. 2b. All implementations have in<br><br>
common that the mixer 60 functions such that same combines<br>
a representation of the audio input signal 58 delayed by a<br>
delay time with the audio input signal 54 so as to obtain<br>
the first output signal 50 and the second output signal 52<br>
with time-varying portions of the audio input signal 54 and<br>
the delayed representation of the audio input signal 58.<br>
Here, in a first time interval, the first output signal 50<br>
is formed, to a proportion of more than 50%, from the audio<br>
input signal 54, and the second output signal 52 is formed,<br>
to a proportion of more than 50%, from the delayed<br>
representation of the audio input signal 58. In a second<br>
time interval, the first output signal 50 is formed of a<br>
proportion of more than 50% of the delayed representation<br>
of the audio input signal 58, and the second output signal<br>
52 is formed of a proportion of more than 50% of the audio<br>
input signal.<br>
Fig. 2b shows possible control functions for the mixer 60<br>
as represented in Fig. 2a. Time t is plotted on the x axis<br>
in the form of arbitrary units, and the function X(t)<br>
exhibiting possible function values from zero to one is<br>
plotted on the y axis. Other functions X(t) may also be<br>
used which do not necessarily exhibit a value range of 0 to<br>
1. Other value ranges, such as from 0 to 10, are<br>
conceivable. Three examples of functions X(t) determining<br>
the output signals in the first time interval 62 and the<br>
second time interval 64 are represented.<br>
A first function 66, which is represented in the form of a<br>
box, corresponds to the case of swapping the channels, as<br>
described in Fig. 2, or the switching without any cross-<br>
fading, which is schematically represented in Fig. 1.<br>
Considering the first output signal 50 of Fig. 2a, same is<br>
completely formed by the audio input signal 54 in the first<br>
time interval 62, whereas the second output signal 52 is<br>
completely formed by the delayed representation of the<br>
audio input signal 58 in the first time interval 62. In the<br>
second time interval 64, the same applies vice versa,<br><br>
wherein the length of the time intervals is not mandatorily<br>
identical.<br>
A second function 58 represented in dashed lines does not<br>
completely switch the signals over and generates first and<br>
second output signals 50 and 52, which at no point in time<br>
are formed completely from the audio input signal 54 or the<br>
delayed representation of the audio input signal 58.<br>
However, in the first time interval 62, the first output<br>
signal 50 is, to a proportion of more than 50%, formed from<br>
the audio input signal 54, which correspondingly also<br>
applies to the second output signal 52.<br>
A third function 69 is implemented such that it is of such<br>
a nature that, at cross-fading times 69a to 69c, which<br>
correspond to the transient times between the first time<br>
interval 62 and the second time interval 64, which<br>
therefore mark those times at which the audio output<br>
signals are varied, same achieves a cross-fade effect. This<br>
is to say that, in a begin interval and an end interval at<br>
the beginning and the end of the first time interval 62,<br>
the first output signal 50 and the second output signal 52<br>
contain portions of both the audio input signal 58 and the<br>
delayed representation of the audio input signal.<br>
In an intermediate time interval 69 between the begin<br>
interval and the end interval, the first output signal 50<br>
corresponds to the audio input signal 54 and the second<br>
output signal 52 corresponds to the delayed representation<br>
of the audio input signal 58. The steepness of the function<br>
69 at the cross-fade times 69a to 69c may be varied in far<br>
limits so as to adjust the perceived reproduction quality<br>
of the audio signal to the conditions. However, it is<br>
ensured in any case that, in a first time interval, the<br>
first output signal 50 contains a proportion of more than<br>
50% of the audio input signal 54 and the second output<br>
signal 52 contains a proportion of more than 50% of the<br>
delayed representation of the audio input signal 58, and<br><br>
that, in a second time interval 64, the first output signal<br>
50 contains a proportion of more than 50% of the delayed<br>
representation of the audio input signal 58 and the second<br>
output signal 52 contains a proportion of more than 50% of<br>
the audio input signal 54.<br>
Fig. 3 shows a further embodiment of a decorrelator<br>
implementing the inventive concept. Here, components<br>
identical or similar in function are designated with the<br>
same reference numerals as in the preceding examples.<br>
In general, what applies in the context of the entire<br>
application is that components identical or similar in<br>
function are designated with the same reference numerals so<br>
that the description thereof in the context of the<br>
individual embodiments may be interchangeably applied to<br>
one another.<br>
The decorrelator shown in Fig. 3 differs from the<br>
decorrelator schematically presented in Fig. 1 in that the<br>
audio input signal 54 and the delayed representation of the<br>
audio input signal 58 may be scaled by means of optional<br>
scaling means 74, prior to being supplied to the mixer 60.<br>
The optional scaling means 74 here comprises a first scaler<br>
76a and a second scaler 76b, the first sealer 76a being<br>
able to scale the audio input signal 54 and the second<br>
sealer 76b being able to scale the delayed representation<br>
of the audio input signal 58.<br>
The delaying means 56 is fed by the audio input signal<br>
(monophonic) 54. The first sealer 76a and the second sealer<br>
76b may optionally vary the intensity of the audio input<br>
signal and the delayed representation of the audio input<br>
signal. What is preferred here is that the intensity of the<br>
lagging signal (G_lagging), i.e. of the delayed<br>
representation of the audio input signal 58, be increased<br>
and/or the intensity of the leading signal (G_leading),<br>
i.e. of the audio input signal 54, be decreased. The change<br><br>
in intensity may here be effected by means of the following<br>
simple multiplicative operations, wherein a suitably chosen<br>
gain factor is multiplied to the individual signal<br>
components:<br>
L'=M*G_leading<br>
R'=M_d*G_lagging.<br>
Here the gain factors may be chosen such that the total<br>
energy is obtained. In addition, the gain factors may be<br>
defined such that same change in dependence on the signal.<br>
In the case of additionally transferred side information,<br>
i.e. in the case of multi-channel audio reconstruction, for<br>
example, the gain factors may also depend on the side<br>
information so that same are varied in dependence on the<br>
acoustic scenario to be reconstructed.<br>
By the application of gain factors and by the variation of<br>
the intensity of the audio input signal 54 or the delayed<br>
representation of the audio input signal 58, respectively,<br>
the precedence effect (the effect resulting from the<br>
temporally delayed repetition of the same signal) may be<br>
compensated by changing the intensity of the direct<br>
component with respect to the delayed component such that<br>
delayed components are boosted and/or the non-delayed<br>
component is attenuated. The precedence effect caused by<br>
the delay introduced may also partly be compensated for by<br>
volume adjustments (intensity adjustments), which are<br>
important for spatial hearing.<br>
As in the above case, the delayed and the non-delayed<br>
signal components (the audio input signal 54 and the<br>
delayed representation of the audio input signal 58) are<br>
swapped at a suitable rate, i.e.:<br>
L' = M and R' = M_d in a first time interval and<br>
L' = M_d and R' = M in a second time interval.<br><br>
If the signal is processed in frames, i.e. in discrete time<br>
segments of a constant length, the time interval of the<br>
swapping (swap rate) is preferably an integer multiple of<br>
the frame length. One example of a typical swapping time or<br>
swapping period is 100 ms.<br>
The first output signal 50 and the second output signal 52<br>
may directly be output as an output signal, as shown in<br>
Fig. 1. When the decorrelation occurs on the basis of<br>
transformed signals, an inverse transformation is, of<br>
course, required after decorrelation. The decorrelator in<br>
Fig. 3 additionally comprises an optional post-processor 80<br>
which combines the first output signal 50 and the second<br>
output signal 52 so as to provide at its output a post-<br>
processed output signal 82 and a second post-processed<br>
output signal 84, wherein the post-processor may comprise<br>
several advantageous effects. For one thing, it may serve<br>
to prepare the signal for further method steps such as a<br>
subsequent upmix in a multi-channel reconstruction such<br>
that an already existing decorrelator may be replaced by<br>
the inventive decorrelator without having to change the<br>
rest of the signal-processing chain.<br>
Therefore, the decorrelator shown in Fig. 7 may fully<br>
replace the decorrelators according to prior art or<br>
standard decorrelators 10 of Figs. 7 and 8, whereby the<br>
advantages of the inventive decorrelators may be integrated<br>
into already existing decoder setups in a simple manner.<br>
One example of a signal post-processing as it may be<br>
performed by the post-processor 80 is given by means of the<br>
following equations which describe a center-side (MS)<br>
coding:<br>
M=0.707*(L'+R' )<br>
D=0.707*(L'-R' ) .<br><br>
In a further embodiment, the post-processor 80 is used for<br>
reducing the degree of mixing of the direct signal and the<br>
delayed signal. Here, the normal combination represented by<br>
means of the above formula may be modified such that the<br>
first output signal 50 is substantially scaled and used as<br>
a first post-processed output signal 82, for example,<br>
whereas the second output signal 52 is used as a basis for<br>
the second post-processed output signal 84. The post-<br>
processor and the mix matrix describing the post-processor<br>
may here either be fully bypassed or the matrix<br>
coefficients controlling the combination of the signals in<br>
the post-processor 80 may be varied such that little or no<br>
additional mixing of the signals will occur.<br>
Fig. 4 shows a further way of avoiding the precedence<br>
effect by means of a suitable correlator. Here, the first<br>
and second scaling units 76a and 76b shown in Fig. 3 are<br>
obligatory, whereas the mixer 60 may be omitted.<br>
Here, in analogy to the above-described case, either the<br>
audio input signal 54 and/or the delayed representation of<br>
the audio input signal 58 is altered and varied in its<br>
intensity. In order to avoid the precedence effect, either<br>
the intensity of the delayed representation of the audio<br>
input signal 58 is increased and/or the intensity of the<br>
audio input signal 54 is decreased, as can be seen from the<br>
following equations:<br>
L'=M*G_leading<br>
R'=M_d*G_lagging.<br>
Here, the intensity is preferably varied in dependence on<br>
the delay time of the delaying means 56 so that a larger<br>
decrease of the intensity of the audio input signal 54 may<br>
be achieved with shorter delay time.<br>
Advantageous combinations of delay times and the pertaining<br>
gain factors are summarized in the following table:<br><br><br>
The scaled signals may then be arbitrarily mixed, for<br>
example by means of one of a center-side encoder described<br>
above or any of the other mixing algorithms described<br>
above.<br>
Therefore, by the scaling of the signal, the precedence<br>
effect is avoided, by reducing the temporally leading<br>
component in its intensity. This serves to generate a<br>
signal, by means of mixing, which does not temporally smear<br>
the transient portions contained in the signal and in<br>
addition does not cause any undesired corruption of the<br>
sound impression by means of the precedence effect.<br>
Fig. 5 schematically shows an example of an inventive<br>
method of generating output signals based on an audio input<br>
signal 54. In a combination step 90, a representation of<br>
the audio input signal 54 delayed by a delay time is<br>
combined with the audio input signal 54 so as to obtain a<br>
first output signal 52 and a second output signal 54,<br>
wherein, in a first time interval, the first output signal<br>
52 corresponds to the audio input signal 54 and the second<br>
output signal corresponds to the delayed representation of<br>
the audio input signal, and wherein, in a second time<br>
interval, the first output signal 52 corresponds to the<br>
delayed representation of the audio input signal and the<br>
second output signal 54 corresponds to the audio input<br>
 signal.<br>
Fig. 6 shows the application of the inventive concept in an<br>
audio decoder. An audio decoder 100 comprises a standard<br>
decorrelator 102 and a decorrelator 104 corresponding to<br>
 one of the inventive decorrelators described above. The<br>
audio decoder 100 serves for generating a multi-channel<br><br>
output signal 106 which in the case shown exemplarily<br>
exhibits two channels. The multi-channel output signal is<br>
generated based on an audio input signal 108 which, as<br>
shown, may be a mono signal. The standard decorrelator 102<br>
corresponds to the decorrelators known in prior art, and<br>
the audio decoder is made such that it uses the standard<br>
decorrelator 102 in a standard mode of operation and<br>
alternatively uses the decorrelator 104 with a transient<br>
audio input signal 108. Thus, the multi-channel<br>
representation generated by the audio decoder is also<br>
feasible in good quality in the presence of transient input<br>
signals and/or transient downmix signals.<br>
Therefore, it is the basic intention is to use the<br>
inventive decorrelators when strongly decorrelated and<br>
transient signals are to be processed. If there is the<br>
chance of recognizing transient signals, the inventive<br>
decorrelator may alternatively be used instead of a<br>
standard decorrelator.<br>
If decorrelation information is additionally available (for<br>
example an ICC parameter describing the correlation of two<br>
output signals of a multi-channel downmix in MPEG Surround<br>
standard) , same may additionally be used as a decisive<br>
criterion for deciding which decorrelator to use. In the<br>
case of small ICC values (such as values smaller than 0.5,<br>
for example) outputs of the inventive decorrelators (such<br>
as of the decorrelator of Figs. 1 and 3) may be used, for<br>
example. For non-transient signals (such as tonal signals)<br>
standard decorrelators are therefore used so as to ensure<br>
the optimum reproduction quality at any time.<br>
I.e., the application of the inventive decorrelators in the<br>
audio decoder 100 is signal-dependent. As mentioned above,<br>
there are ways of detecting transient signal portions (such<br>
as LPC prediction in the signal spectrum or a comparison of<br>
the energies contained in the low-frequency spectral domain<br>
in the signal to those in the high spectral domain) . In<br><br>
many decoder scenarios, these detection mechanisms already<br>
exist or may be implemented in a simple manner. One example<br>
of already existing indicators are the above-mentioned<br>
correlation or coherence parameters of a signal. In<br>
addition to the simple recognition of the presence of<br>
transient signal portions, these parameters may be used to<br>
control the intensity of the decorrelation of the output<br>
channels generated.<br>
Examples of the use of already existing detection<br>
algorithms for transient signals are MPEG Surround, where<br>
the control information of the STP tool is suitable for<br>
detection and the inter-channel coherence parameters (ICC)<br>
 may be used. Here, the detection may be effected both on<br>
 the encoder side and on the decoder side. In the former<br>
case, a signal flag or bit would have to be transmitted,<br>
which is evaluated by the audio decoder 100 so as to switch<br>
to and fro between the different decorrelators. If the<br>
 signal-processing scheme of the audio decoder 100 is based<br>
 on overlapping windows for the reconstruction of the final<br>
audio signal and if the overlapping of the adjacent windows<br>
(frames) is large enough, a simple switching among the<br>
different decorrelators may be effected without the result<br>
of the introduction of audible artefacts.<br>
If this is not the case, several measures may be taken to<br>
enable an approximately inaudible transition among the<br>
different decorrelators. For one thing, a cross-fading<br>
technique may be used, wherein both decorrelators are first<br>
) used in parallel. The signal of the standard decorrelator<br>
102 is in the transition to the decorrelator 104 slowly<br>
faded out in its intensity, whereas the signal of the<br>
decorrelator 104 is simultaneously faded in. In addition,<br>
hysteresis switch curves may be used in the to-and-fro<br>
 switching, which ensure that a decorrelator, after the<br>
switching thereto, is used for a predetermined minimum<br>
amount of time so as to prevent multiple direct to-and-fro<br>
switching among the various decorrelators.<br><br>
In addition to the volume effects, other perception<br>
psychological effects may occur when different<br>
decorrelators are used.<br>
This is particularly the case as the inventive<br>
decorrelators are able to generate a specifically "wide"<br>
sound field. In a downstream mix matrix, a certain amount<br>
of a decorrelated signal is added to a direct signal in the<br>
four-channel audio reconstruction. Here, the amount of the<br>
decorrelated signal and/or the dominance of the<br>
decorrelated signal in the output signal generated<br>
typically determines the width of the sound field<br>
perceived. The matrix coefficients of this mix matrix are<br>
typically controlled by the above-mentioned correlation<br>
parameters transferred and/or other spatial parameters.<br>
Therefore, prior to the switching to an inventive<br>
decorrelator, the width of the sound field may at first be<br>
artificially increased by altering the coefficients of the<br>
mix matrix such that the wide sound impression arises<br>
slowly before a switch is made to the inventive<br>
decorrelators. In the other case of the switching from the<br>
inventive decorrelator, the width of the sound impression<br>
may likewise be decreased prior to the actual switching.<br>
Of course, the above-described switching scenarios may also<br>
be combined to achieve a particularly smooth transition<br>
between different decorrelators.<br>
To summarize, the inventive decorrelators have a number of<br>
advantages as compared to the prior art, which particularly<br>
come to bear in the reconstruction of applause-like<br>
signals, i.e. signals having a high transient signal<br>
portion. On the one hand, an extremely wide sound field is<br>
generated without the introduction of additional artefacts,<br>
which is particularly advantageous in the case of<br>
transient, applause-like signals. As has repeatedly been<br>
shown, the inventive decorrelators may easily be integrated<br><br>
in already existing playback chains and/or decoders and may<br>
even be controlled by parameters already present in these<br>
decoders so as to achieve the optimum reproduction of a<br>
signal. Examples of the integration into such existing<br>
decoder structures have previously been given in the form<br>
of Parametric Stereo and MPEG Surround. In addition, the<br>
inventive concept manages to provide decorrelators making<br>
only extremely small demands on the computing power<br>
available, so that, for one thing, no expensive investing<br>
in hardware is required and, for the other thing, the<br>
additional energy consumption of the inventive<br>
decorrelators is negligible.<br>
Although the preceding discussion has mainly been presented<br>
with respect to discrete signals, i.e. audio signals, which<br>
are represented by a sequence of discrete samples, this<br>
only serves for better understanding. The inventive concept<br>
is also applicable to continuous audio signals, as well as<br>
to other representations of audio signals, such as<br>
parameter representations in frequency-transformed spaces<br>
of representation.<br>
Depending on the conditions, the inventive method of<br>
generating output signals may be implemented in hardware or<br>
in software. The implementation may be effected on a<br>
digital storage medium, in particular a floppy disk or a<br>
CD, with electronically readable control signals, which may<br>
cooperate such with a programmable computer system that the<br>
inventive method of generating audio signals is effected.<br>
In general, the invention therefore also consists in a<br>
computer program product with a program code for performing<br>
the inventive method stored on a machine-readable carrier<br>
when the computer program product runs on a computer. In<br>
other words, the invention may, therefore, be realized as a<br>
computer program with a program code for performing the<br>
method when the computer program runs on a computer.<br><br>
1.	Decorrelator for generating output signals (50, 52)<br>
based on an audio input signal (54), comprising:<br>
a mixer (60) for combining a representation of the<br>
audio input signal delayed by a delay time (58) with<br>
the audio input signal (54) so as to obtain a first<br>
(50) and a second (52) output signal having time-<br>
varying portions of the audio input signal (54) and<br>
the delayed representation of the audio input signal<br>
(58), wherein<br>
in a first time interval (70), the	first output<br>
signal (50) contains a proportion of more than 50<br>
percent of the audio input signal	(54) and the<br>
second output signal (52) contains	a proportion<br>
of more than 50 percent of	the delayed<br>
representation of the audio input	signal (58),<br>
and wherein<br>
in a second time interval (72), the first output<br>
signal (50) contains a proportion of more than 50<br>
percent of the delayed representation of the<br>
audio input signal (58), and the second output<br>
signal (52) contains a proportion of more than 50<br>
percent of the audio input signal (54).<br>
2.	Decorrelator of claim 1, wherein, in the first time<br>
interval (70) the first output signal corresponds to<br>
the audio input signal (54), and the second output<br>
signal (52) corresponds to the delayed representation<br>
of the audio input signal (58), wherein<br>
in the second time interval (72), the first output<br>
signal (50) corresponds to the delayed representation<br>
of the audio input signal (58) and the second output<br><br>
signal (52) corresponds to the audio input signal<br>
(54) .<br>
3.	Decorrelator of claim 1, wherein, in a begin interval<br>
and an end interval at the beginning and at the end of<br>
the first time interval (70), the first output signal<br>
and the second output signal (52) contain portions of<br>
the audio input signal (54) and the delayed<br>
representation of the audio input signal (58), wherein<br>
in an intermediate interval between the begin interval<br>
and the end interval of the first time interval, the<br>
first output signal corresponds to the audio input<br>
signal (54), and the second output signal (52)<br>
corresponds to the delayed representation of the audio<br>
input signal (58); and wherein<br>
in a begin interval and in an end interval at the<br>
beginning and at the end of the second time interval<br>
(70), the first output signal and the second output<br>
signal (52) contain portions of the audio input signal<br>
(54) and the delayed representation of the audio input<br>
signal (58), wherein<br>
in an intermediate interval between the begin interval<br>
and the end interval of the second time interval, the<br>
first output signal corresponds to the delayed<br>
representation of the audio input signal (58), and the<br>
second output signal (52) corresponds to the audio<br>
input signal (54) .<br>
4.	Decorrelator of any one of claims 1 to 3, wherein the<br>
first and second time intervals are temporally<br>
adjacent and successive.<br>
5.	Decorrelator of any one of claims 1 to 4, further<br>
comprising a delaying means (56) so as to generate the<br>
delayed representation of the audio input signal (58)<br><br>
by time-delaying the audio input signal (54) by the<br>
delay time.<br>
6.	Decorrelator of any one of claims 1 to 5, further<br>
comprising scaling means (74) so as to alter an<br>
intensity of the audio input signal (54) and/or the<br>
delayed representation of the audio input signal (58).<br>
7.	Decorrelator of claim 6, wherein the scaling means<br>
(74) is configured to scale the intensity of the audio<br>
input signal (54) in dependence on the delay time such<br>
that a larger decrease in the intensity of the audio<br>
input signal (54) is obtained with a shorter delay<br>
time.<br>
8.	Decorrelator of any one of the preceding claims,<br>
further comprising a post-processor (80) for combining<br>
the first (50) and the second output signal (52) so as<br>
to obtain a first (82) and a second (84) post-<br>
processed output signal, both the first (82) and the<br>
second (84) post-processed output signal comprising<br>
signal contributions from the first (50) and second<br>
(52) output signals.<br>
9.	Decorrelator of claim 8, wherein the post-processor<br>
(80) is configured to form the first post-processed<br>
output signal M (82) and the second post-processed<br>
output signal D (84) from the first output signal L'<br>
(50) and the second output signal R' (52) such that<br>
the following conditions are met:<br>
M = 0. 707 x (L' + R' ) , and<br>
D = 0.707 x (L' - R' ) .<br>
10.	Decorrelator of any one of the preceding claims,<br>
wherein the mixer (60) is configured to use a delayed<br>
representation of the audio input signal (58) the<br><br>
delay time of which is greater than 2 ms and less than<br>
50 ms.<br>
11.	Decorrelator of claim 7, wherein the delay time<br>
amounts to 3, 6, 9, 12, 15 or 30 ms.<br>
12.	Decorrelator of any one of the preceding claims,<br>
wherein the mixer (60) is configured to combine an<br>
audio input signal (54) consisting of discrete samples<br>
and a delayed representation of the audio input signal<br>
(58) consisting of discrete samples by swapping the<br>
samples of the audio input signal (54) and the samples<br>
of the delayed representation of the audio input<br>
signal (58).<br>
13.	Decorrelator of any one of the preceding claims,<br>
wherein the mixer (60) is configured to combine the<br>
audio input signal (54) and the delayed representation<br>
of the audio input signal (58) such that the first and<br>
second time intervals have the same length.<br>
14.	Decorrelator of any one of the preceding claims,<br>
wherein the mixer (60) is configured to perform the<br>
combination of the audio input signal (54) and the<br>
delayed representation of the audio input signal (58)<br>
for a sequence of pairs of temporally adjacent first<br>
(70) and second (72) time intervals.<br>
15.	Decorrelator of claim 15, wherein the mixer (60) is<br>
configured to refrain, with a predetermined<br>
probability, for one pair of the sequence of pairs of<br>
temporally adjacent first (70) and second (72) time<br>
intervals, from the combination so that, in the pair<br>
in the first (70) and second (72) time intervals, the<br>
first output signal (50) corresponds to the audio<br>
input signal (54) and the second output signal (52)<br>
corresponds to the delayed representation of the audio<br>
input signal (58).<br><br>
16.	Decorrelator of claims 14 or 15, wherein the mixer<br>
(60) is configured to perform the combination such<br>
that the time period of the time intervals in a first<br>
pair of a first (70) and a second (72) time interval<br>
from the sequence of time intervals differs from a<br>
time period of the time intervals in a second pair of<br>
a first and a second time interval.<br>
17.	Decorrelator of any one of the preceding claims,<br>
wherein the time period of the first (70) and the<br>
second (72) time intervals is larger than the double<br>
average time period of transient signal portions<br>
contained in the audio input signal (54).<br>
18.	Decorrelator of any one of the preceding claims,<br>
wherein the time period of the first (70) and second<br>
(72) time intervals is larger than 10 ms and less than<br>
200 ms.<br>
19.	Method of generating output signals (50, 52) based on<br>
an audio input signal (54), comprising:<br>
combining a representation of the audio input signal<br>
delayed by a delay time (58) with the audio signal<br>
(54) so as to obtain a first (50) and a second (52)<br>
output signal having time-varying portions of the<br>
audio input signal (54) and the delayed representation<br>
of the audio input signal (58), wherein<br>
in a first time interval (70), the first output signal<br>
(50) contains a proportion of more than 50 percent of<br>
the audio input signal (54), and the second output<br>
signal (52) contains a proportion of more than 50<br>
percent of the delayed representation of the audio<br>
input signal (58), and wherein<br><br>
in a second time interval (72), the first output<br>
signal (50) contains a proportion of more than 50<br>
percent of the delayed representation of the audio<br>
input signal (58), and the second output signal (52)<br>
contains a proportion of more than 50 percent of the<br>
audio input signal (54).<br>
20. Method of claim 19, wherein, in the first time<br>
interval (70), the first output signal corresponds to<br>
the audio input signal (54), and the second output<br>
signal (52) corresponds to the delayed representation<br>
of the audio input signal (58), wherein<br>
in the second time interval (72), the first output<br>
signal (50) corresponds to the delayed representation<br>
of the audio input signal (58), and the second output<br>
signal (52) corresponds to the audio input signal<br>
(54) .<br>
21. Method of claim 19, wherein, in a begin interval and<br>
in an end interval at the beginning and at the end of<br>
the first time interval (70), the first output signal<br>
and the second output signal (52) contain portions of<br>
the audio input signal (54) and the delayed<br>
representation of the audio input signal (58), wherein<br>
in an intermediate interval between the begin interval<br>
and the end interval of the first time interval, the<br>
first output signal corresponds to the audio input<br>
signal (54), and the second output signal (52)<br>
corresponds to the delayed representation of the audio<br>
input signal (58); and wherein<br>
in a begin interval and in an end interval at the<br>
beginning and at the end of the second time interval<br>
(70), the first output signal and the second output<br>
signal (52) contain portions of the audio input signal<br><br>
(54) and the delayed representation of the audio input<br>
signal (58), wherein<br>
in an intermediate interval between the begin interval<br>
and the end interval of the second time interval, the<br>
first output signal corresponds to the delayed<br>
representation of the audio input signal (58), and the<br>
second output signal (52) corresponds to the audio<br>
input signal (54).<br>
22.	Method of any one of claims 19 to 21, additionally<br>
comprising:<br>
delaying the audio input signal (54) by the delay time<br>
so as to obtain the delayed representation of the<br>
audio input signal (58) .<br>
23.	Method of any one of claims 19 to 22, additionally<br>
comprising:<br>
altering the intensity of the audio input signal (54)<br>
and/or the delayed representation of the audio input<br>
signal (58).<br>
24.	Method of any one of claims 19 to 23, additionally<br>
comprising:<br>
combining the first (50) and the second (52) output<br>
signal so as to obtain a first (82) and a second (84)<br>
post-processed output signal, both the first (82) and<br>
the second (84) post-processed output signals<br>
containing contributions of the first and the second<br>
output signals.<br>
25.	Audio decoder for generating a multi-channel output<br>
signal based on an audio input signal (54),<br>
comprising:<br><br>
a decorrelator of any one of claims 1 to 18; and<br>
a standard decorrelator, wherein<br>
the audio decoder is configured to use, in a standard<br>
mode of operation, the standard decorrelator, and to<br>
use, in the case of a transient audio input signal<br>
(54), the inventive decorrelator.<br>
26. Computer program with a program code for performing<br>
the method of any one of claims 19 to 24 when the<br>
program runs on a computer.<br><br>
In a case of transient audio input signals, in a multi-channel audio reconstruction, uncorrelated output signals are generated from an audio input signal in that the audio input signal is mixed with a representation of the audio input signal delayed by a delay time such that, in a first<br>
time interval, a first output signal corresponds to the audio input signal, and a second output signal corresponds to the delayed representation of the audio input signal, wherein, in a second time interval, the first output signal<br>
corresponds to the delayed representation of the audio input signal, and the second output signal corresponds to the audio input signal.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=XbQG2KZVrx5KM5qjbZDqdA==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=XbQG2KZVrx5KM5qjbZDqdA==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="268955-a-method-for-decoding-an-audio-signal.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="268957-process-and-apparatus-for-hot-forging-synthetic-ceramic.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>268956</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1596/KOLNP/2009</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>40/2015</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>02-Oct-2015</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>24-Sep-2015</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>28-Apr-2009</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E. V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C, 80686 MUNICH</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JUERGEN HERRE</td>
											<td>HALLERSTR. 24 91054 BUCKENHOF</td>
										</tr>
										<tr>
											<td>2</td>
											<td>HARALD POPP</td>
											<td>OBERMICHELBACHER STR. 18 90587 TUCHENBACH</td>
										</tr>
										<tr>
											<td>3</td>
											<td>JAN PLOGSTIES</td>
											<td>PESTALOZZISTR. 44 91052 ERLANGEN</td>
										</tr>
										<tr>
											<td>4</td>
											<td>HARALD MUNDT</td>
											<td>ESCHENWEG 34 91058 ERLANGEN</td>
										</tr>
										<tr>
											<td>5</td>
											<td>SASCHA DISCH</td>
											<td>TURNSTR. 7 90763 FUERTH</td>
										</tr>
										<tr>
											<td>6</td>
											<td>KARSTEN LINZMEIER</td>
											<td>ELISE-SPAETH-STR. 4 91058 ERLANGEN</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04S 5/00, H04S 1/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2008/002945</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2008-04-14</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10 2007 018 032.4-55</td>
									<td>2007-04-17</td>
								    <td>Germany</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/268956-generation-of-decorrelated-signals by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:34:40 GMT -->
</html>
