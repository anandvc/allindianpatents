<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/270571-method-to-control-access-between-network-endpoints-based-on-trust-scores-calculated-from-information-system-component-analysis by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 04:07:49 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 270571:METHOD TO CONTROL ACCESS BETWEEN NETWORK ENDPOINTS BASED ON TRUST SCORES CALCULATED FROM INFORMATION SYSTEM COMPONENT ANALYSIS.</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD TO CONTROL ACCESS BETWEEN NETWORK ENDPOINTS BASED ON TRUST SCORES CALCULATED FROM INFORMATION SYSTEM COMPONENT ANALYSIS.</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Signatures are generated for modules in a computer system. The signatures can be assembled into an integrity log. The signatures are compared with signatures in a database in an integrity validator. Once signatures are either validated or invalidated, a trust score can be generated. The trust score can then be used to determine whether the computer system should be granted access to a resource using a policy.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>WO 2006/058313	PCT/US2005/043035<br>
1<br>
METHOD TO CONTROL ACCESS BETWEEN NETWORK ENDPOINTS BASED<br>
ON TRUST SCORES CALCULATED FROM INFORMATION SYSTEM<br>
COMPONENT ANALYSIS<br>
FIELD OF THE INVENTION<br>
This invention pertains to computer module validation, and more particularly to<br>
determining the integrity of a computer before granting the computer access to network<br>
resources.<br>
BACKGROUND OF THE INVENTION<br>
Where once computer networks were scarce, computer networks are now quite<br>
common. Most businesses have computers that are networked together: large businesses can<br>
have hundreds or even thousands of computers connected by a network. Computer networks<br>
are also beginning to penetrate the home: as each person in a household wants their own<br>
computer, the computers need to be networked to share resources: for example, the<br>
connection to the Internet. Companies that manufacture equipment to support computer<br>
networking such as routers have responded by making the equipment easier to install and use.  .<br><br>
WO 2006/058313	PCT/US2005/043035<br>
2<br>
Frequently, a user needs to do little more than, say, plug their computers into a router, power<br>
the router up, and forget about the equipment.<br>
But that self-same ease to network installation has made computers more vulnerable.<br>
Viruses, worms, Trojan horses, and logic bombs are being written with ever-increasing<br>
frequency. And the Internet, along with the networks connected to the Internet, has made the<br>
proliferation of these dangers easier and more likely to occur.<br>
For users, being hit with a virus or one of its kin is, at the very least, annoying. At<br>
best, a user has to spend the time necessary to identify which computers on his personal<br>
network are infected with the virus, and then disinfect the computers. At worst, being<br>
infected with a virus might require erasing the hard drive and rebuilding the software from<br>
scratch. This might require the user to lose all of the data stored on the infected computers.<br>
For personal users, the data on their computers might be irreplaceable and priceless<br>
(for example, family photos, or personal documents). But life would go on. But for<br>
businesses, such loss of data could be devastating. Even with a proper archive policy in<br>
place, the time required to rebuild computer systems and the business network could cost<br>
thousands of dollars or more, both in lost revenue and in the costs of actually rebuilding the<br>
computers and the network, Then there is the potential loss of goodwill in having to close<br>
while the computers and the network are rebuilt.<br>
Accordingly, a need remains for a way to identify computers that are in a potentially<br>
improper state before the computers are given access to network resources, to address these<br>
and other problems associated with the prior art.<br>
SUMMARY OF THE INVENTION<br>
The invention includes methods and apparatuses for constructing a database of valid<br>
module signatures, for validating a module, and for validating a computer. To validate a<br>
computer, an apparatus receives signatures generated for modules in the computer. The<br>
signatures can be assembled into an integrity log. The apparatus attempts to validate that<br>
each signature is correct by comparing the signatures with a database. After the signatures<br>
are validated or not, the apparatus generates a trust score based upon which signatures<br>
received from the computer were validated.<br>
The foregoing and other features, objects, and advantages of the invention will<br>
become more readily apparent from the following detailed description, which proceeds with<br>
reference to the accompanying drawings.<br><br>
WO 2006/058313	PCT/US2005/043035<br>
3<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
FIG. 1 shows a system including an integrity validator to perform computer<br>
validation.<br>
FIG. 2 shows more details about the integrity validator of FIG. 1 used to perform<br>
computer validation.<br>
FIG. 3 shows more details about the database of FIG. 2.<br>
FIG. 4 shows a flowchart of the procedure used by the integrity validator of FIG. 1 to<br>
assemble the database of FIG. 2.<br>
FIGs. 5A-5B show a flowchart of the procedure used by the integrity validator of FIG.<br>
1 to validate an individual module signature.<br>
FIG. 6 shows a flowchart of the procedure used by a computer system, such as the<br>
computer system of FIG. 1, to assemble an integrity log to validate the computer system<br>
using the integrity validator of FIG. 1.<br>
FIGs. 7A-7B show a flowchart of the procedure used by the integrity validator of FIG.<br>
1 to validate a computer system.<br>
FIG. 8 shows a flowchart of the procedure used by the integrity validator of FIG. 1 to<br>
grant or deny a computer system, such as the computer system of FIG. 1, access to a network<br>
resource.<br>
DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT<br>
FIG. 1 shows a system including an integrity validator to perform computer<br>
validation. In FIG. 1, computer system 105 is connected to external network 110. Computer<br>
system 105 is shown as including computer 115, monitor 120, keyboard 125, and mouse 130.<br>
But a person skilled in the art will recognize that other components can be included with<br>
computer system 105: for example, other input/output devices, such as a printer. In addition,<br>
FIG. 1 does not show some of the conventional internal components of computer system 105<br>
for example, a central processing unit, memory, etc. Further, computer system 105 could be<br>
replaced by other machines, such as a notebook computer, dedicated terminal, or Personal<br>
Digital Assistant (PDA), among other possibilities.<br>
External network 110, as its name suggests, is a network that is external to the<br>
organization. In contrast, internal network 135 is a network that is internal to the<br>
organization. Integrity validator 140 is interposed between external network 110 and internal<br>
network 135 to validate computers that are outside the organization but are requesting access<br>
to a resource internal to the organization, such as resource 145. Resource 145 could be any<br><br>
WO 2006/058313	PCT/US2005/043035<br>
4<br>
type of resource: for example, a network drive, directory, or file, or a web page, to name<br>
some examples. To support such validation, computer system 105 includes integrity log<br>
generator 150, which assembles the integrity log for the computer system. Integrity validator<br>
140 can then use the integrity log to validate computer system 105.<br>
An integrity log is a set of signatures for various modules on computer system 105.<br>
In one embodiment, these signatures are hashes of the various modules, and can be generated<br>
using hash function 155, such as MD5, SHA-1, or SHA-256. In one embodiment, integrity<br>
log generator 150 can be a device driver that loads early in the system boot sequence<br>
(preferably, before any other drivers have been loaded). Integrity log generator 150 can then<br>
identify each module that is accessed or loaded during the system boot sequence, and<br>
generate a signature for these modules. In another embodiment, integrity log generator 150<br>
can be an executable that can scan the entire system for all potential modules. A person<br>
skilled in the art will recognize other ways in which integrity log generator 150 can operate.<br>
In one embodiment, integrity log generator 150 generates signatures only for<br>
modules, such as device drivers and executable modules, that are actually loaded. In another<br>
embodiment, integrity log generator 150 generates signatures for such modules and for all<br>
supporting modules: for example, dynamic link libraries (DLLs). A person skilled in the art<br>
will recognize other modules for which integrity log generator 150 can generate signatures,<br>
and other ways in which integrity log generator 150 can operate.<br>
From the above description, it might appear that integrity log generator 150 operates<br>
only on software modules. While software modules typically comprise the majority of<br>
modules for which integrity log generator 150 generates signatures, a person skilled in the art<br>
will recognize that integrity log generator 150 can generate signatures for hardware modules<br>
as well. For example, integrity log generator 150 can generate signatures for firmware or<br>
hardware modules, such as that used in the Basic Input/Output System (BIOS) of the<br>
comp uter system, howeverstored (e.g.,in flash memory, read only memory (ROM)<br>
programmable read-only memory (PROM), erasable programmable read-only memory<br>
(EPROM), electrically-erasable programmable read-only memory (EEPROM), ferroelectric<br>
random access memory (FRAM), magnetoresistive random access memory (MRAM), etc.).<br>
Once the signatures are generated, integrity log generator 150 then assembles the<br>
signatures into an integrity log. The integrity log can also include identifiers for the modules<br>
from which the signatures were generated. Different identifiers can include:<br>
•   The absolute path and file name of the module.<br><br>
WO 2006/058313	PCT/US2005/043035<br>
5<br>
•	The manufacturer of the module.<br>
•	The product or component in which the module resides. Put another way, the<br>
identifier can identify the product or component with which the module interacts.<br>
•	The version and/or patch level of the module or the product or component in which<br>
the module resides, so as to be able to distinguish different versions of the same<br>
module.<br>
A person skilled in the art will recognize other types of identifiers that can be used.<br>
In one embodiment, integrity validator 140 is used only to validate computer systems<br>
that are not directly connected to internal network 135. In this embodiment, there is an<br>
implicit assumption that computer systems connected to internal network 135 are known to<br>
be safe and validated. This is not necessarily an unreasonable assumption, as computer<br>
systems internal to an organization are typically controlled by the organization. Thus, the<br>
likelihood of infection by a virus or similar agent is reduced relative to computer systems<br>
outside the control of the organization. By making this assumption, computer systems<br>
internal to the organization are granted faster access to requested resources, as there is no<br>
need to validate such computer systems.<br>
Nevertheless, in a second embodiment, even computer systems that are directly<br>
connected to internal network 135 (and thus are not requesting resources through external<br>
network 110) are also validated when they request access to resources. While potentially<br>
delaying access to requested resources, such validation provides greater security, in that<br>
malicious agents can be detected even on computer systems internal to the organization.<br>
 In the embodiment shown in FIG. 1, integrity validator 140 is shown as directly<br>
connected to internal network 135. This embodiment works well when computer systems<br>
internal to the organization include modules that are not available to the general public: for<br>
example, if the modules are products under development or are classified (e.g., by the<br>
-government)  This embodiment will also work for organizations that use only commercially<br>
available modules, but this embodiment would require the organization to include integrity<br>
validator 140 as part of its system. In another embodiment, useful when the organization<br>
uses only commercially available modules, integrity validator 140 can be a publicly<br>
accessible integrity validator, rather than one dedicated to the organization. Such an integrity<br>
validator would be connected to external network 110, as integrity validator 160. Integrity<br>
validator 160 operates similarly to integrity validator 140, except that the integrity log is<br>
forwarded to integrity validator 160 via external network 110.<br><br>
WO 2006/058313	PCT/US2005/043035<br>
6<br>
As discussed above, in one embodiment, integrity validator 140 operates to validate<br>
network access to resources from within the organization. While it is possible for integrity<br>
validator 140 to store signatures for every potential module on a computer system, in another<br>
embodiment, integrity validator 140 only stores signatures for modules that are specific to the<br>
organization. For modules that are standard modules (or otherwise unrecognized by integrity<br>
validator 140), integrity validator 140 forwards the signatures to integrity validator 160 (via<br>
external network 110) for validation. In this manner, integrity validator 140 does not need to<br>
be updated as new modules are introduced: validation of these modules can be handled by<br>
integrity validator 160.<br>
Where computer system 105 is not directly connected to internal network 135,<br>
integrity validator 140 can operate whether resource 145 is requested in either an encrypted<br>
or unencrypted form, and whether resource 145 is requested using an encrypted or<br>
unencrypted channel. For example, resource 145 might be a web page that is password-<br>
protected. Or, resource 145 might be requested over a virtual private network (VPN) used to<br>
secure access to resources, A person skilled in the art will recognize other ways in which<br>
access to resource 145 can be managed.<br>
FIG. 2 shows more features of the integrity validator of FIG. 1 used to perform<br>
computer validation. In FIG. 2, integrity validator 140 is shown in greater detail, but a person<br>
skilled in the art will recognize that the details shown can apply to any integrity validator: for<br>
example, integrity validator 160. In addition, a person skilled in the art will recognize that<br>
FIG. 2 does not represent data flow through integrity validator 140.<br>
Integrity validator 140 includes database 205. Database 205 is shown in greater detail<br>
in FIG. 3. FIG. 3 shows database 205 represented as table 305, although a person skilled in<br>
the art will recognize other forms database 205 can take. Table 305 includes numerous<br>
entries, of which entries 310, 315, and 320 are shown. Each entry includes amodule and a<br>
corresponding signature. For example, entry 320 shows a signature for the virtual memory<br>
manager DLL of the Windows® XP operating system. (The signature shown for entry 320 is<br>
not a real signature, but rather a random number that represents a signature.) While entries<br>
310,315, and 320 describe modules that are used with versions of the Windows operating<br>
system by Microsoft Corporation, a person skilled in the art will recognize that embodiments<br>
of the invention are equally applicable to other operating systems: for example, versions of<br>
the Linux® operating system. (Microsoft and Windows are registered trademarks of<br>
Microsoft Corporation in the United States and other countries; Linux is a registered<br>
trademark of Linus Torvalds.)<br><br>
WO 2006/058313	PCT/US2005/043035<br>
7<br>
As noted above, the entries in table 305 include identifiers for the various modules.<br>
By including module identifiers in table 305, a signature provided for module validation can<br>
be compared to the signature expected for that module, to verify that the module is properly<br>
validated. Table 305 shows only one module identifier - the path and file name of the<br>
module - but a person skilled in the art will recognize that table 305 can use other module<br>
identifiers, or any combination of module identifiers.<br>
In another embodiment, table 305 includes only valid signatures, without module<br>
identifiers. In that case, a signature provided for module validation is compared with all<br>
signatures in database 205 until a match is found. If a match is found anywhere in database<br>
205, then the module is considered validated; otherwise, the module is not considered<br>
validated. Provided that the function chosen to compute the signatures (that is, the hash<br>
function) has a low probability of collision, the risk of the signature of an unvalidated module<br>
matching a signature in the database is likely not significant. But by including module<br>
identifiers in database 205, this risk can be effectively eliminated.<br>
Returning to FIG. 2, integrity validator 140 includes other elements. Receiver 210 is<br>
responsible for receiving information transmitted to integrity validator 140. For example,<br>
receiver 210 can receive an integrity log from a computer system to be validated, a signature<br>
to be added to database 205 for a newly validated module, or a replacement signature to<br>
replace an older signature for an existing module in database 205. Transmitter 215 is<br>
responsible for transmitting information from integrity validator 140. For example,<br>
transmitter 215 can transmit a trust score to a computer system, or can forward signatures to<br>
another integrity validator (if integrity validator 140 cannot validate the modules<br>
corresponding to those signatures).<br>
Validator 220 is responsible for validating signatures received by integrity log<br>
validator 140. Validator 220 takes one or more signatures, determines which signatures are<br>
valid, and returns an indication of which signatures are valid and which are not. Validator<br>
220 can be as simple as a comparator to compare the received signature(s) with signatures in<br>
database 205 and indicate whether the signature(s) can be matched to signatures in database<br>
205. Validator 220 can also implement a more complicated technique to validate signature, if<br>
desired.<br>
Trust score generator 225 is responsible for generating a trust score for a computer<br>
system. A trust score is an indication of whether a computer system is trustworthy. Trust<br>
scores can be generated in many different ways. In one embodiment, the trust score is the<br>
ratio of the number of validated modules on the computer system to the total number of<br><br>
WO 2006/058313	PCT/US2005/043035<br>
8<br>
modules on the computer system (validated or not). In another embodiment, the trust score<br>
can be scaled to a number between 0 and 1000, where 0 represents a completely<br>
untrustworthy computer system, and 1000 represents a completely trustworthy computer<br>
system. In yet another embodiment, critical modules can be weighted more highly than other<br>
modules, so that a computer system with more validated critical modules can score more<br>
highly than a computer system with few validated critical modules, even if the second<br>
computer system has more total modules validated. (The definition of "critical" is not<br>
intended to refer to modules that are absolutely necessary as much as modules that are<br>
identified as important to the organization. Thus, one organization might consider the files<br>
relating to the operating system to be "critical", whereas another organization might consider<br>
modules that are custom developed internally (for whatever purpose) to be "critical".)<br>
There are other ways in which trust score generator 225 can calculate the trust score.<br>
In another embodiment, trust score generator can factor in the position of the various<br>
validated modules within the integrity log: for example, modules that are listed earlier in the<br>
integrity log can be considered more important than modules that occur later in the integrity<br>
log. In another embodiment, trust score generator 225 can factor in the module identifier in<br>
calculating the trust score. Modules manufactured by one manufacturer can be considered<br>
more important than modules manufactured by another manufacturer. For example, consider<br>
modules that work in conjunction with an application. Modules manufactured by the<br>
application manufacturer can be considered more important than modules manufactured by<br>
third-party manufacturers.<br>
In yet another embodiment, the version and/or patch level of the module can be a<br>
factor in calculating the trust score. For example, given a module that has several versions,<br>
more recent versions can be considered more important than older versions. If the validated<br>
module is outdated, the resulting trust score can be lower than an otherwise-identical<br>
computer system with a more current yersion of the same module.<br>
Integrity validator 140 can also include policy 230. Policy 230 can indicate how and<br>
under what conditions a computer system can be permitted access to a resource, such as<br>
resource 145 of FIG. 1. In one embodiment, policy 230 includes threshold score 235. To be<br>
granted access to the resource, the computer system should have a trust score at least as high<br>
as threshold score 235; if the trust score for the computer system does not meet or exceed<br>
threshold score 235, then the computer system is denied access to the resource.<br>
In another embodiment, policy 230 can include multiple threshold scores. For<br>
example, in FIG, 2, policy 230 is shown as including two threshold scores 235 and 240. If<br><br>
WO 2006/058313	PCT/US2005/043035<br>
9<br>
the trust score for the computer system is at least as high as threshold score 235, then the<br>
computer system can be granted full access to the resource. If the trust score for the<br>
computer is less than threshold score 235 but at least as high as threshold score 240, then the<br>
computer system can be granted partial access to the resource. And if the trust score for the<br>
computer system is smaller than threshold score 240, the computer system can be denied<br>
access to the resource (although the computer system can be redirected to a help resource to<br>
determine why the computer system has such a low trust score).<br>
While policy 230 is described above in terms of one resource and up to two threshold<br>
scores, a person skilled in the art will recognize that policy 230 can be defined in other ways.<br>
For example, policy 230 can describe different policies for different resources on the same<br>
network. Or permission to access the resource can be determined in ways other than straight<br>
comparisons between the trust score of the computer system and one or more threshold<br>
scores. In addition, while policy 230 is a policy for accessing resources for a particular<br>
organization, if integrity validator 140 is, in fact, used by multiple organizations (e.g.,<br>
integrity validator 140 is connected to the external network as integrity validator 160), then<br>
integrity validator 140 can store policies for multiple organizations.<br>
While FIG. 2 shows integrity validator 140 as including both the features used to<br>
generate a trust score and policy 230, a person skilled in the art will recognize that integrity<br>
validator 140 does not need to combine these features. For example, integrity validator 140<br>
can be responsible for generating the trust score, and policy management (based on the<br>
generated trust score) can be handled elsewhere.<br>
FIG. 4 shows a flowchart of the procedure used by the integrity validator of FIG. 1 to<br>
assemble the database of FIG. 2. In FIG. 4, at step 405, a module is identified. As FIG. 4 is<br>
concerned with assembling the database used to validate computer systems, module<br>
identification is likely a manual process: for example, a module manufacturer can submit a<br>
module for signature generation and addition to the database. But a person skilled in the art<br>
will recognize that module identification can be automated. At step 410, a signature is<br>
generated for the identified module. At step 415, the signature is added to the database.<br>
Finally, at step 420, an identifier for the module can be added to the database and associated<br>
with the signature, to aid in later module validation. As shown by arrow 425, step 420 is<br>
optional, and can be omitted.<br>
FIGs. 5A-5B show a flowchart of the procedure used by the integrity validator of FIG.<br>
1 to validate an individual module signature. In FIG. 5A, at step 505, the integrity validator<br>
receives a signature, and potentially an identifier, for a module. At step 510, the signature is<br><br>
WO 2006/058313	PCT/US2005/043035<br>
10<br>
compared with the database. If a module identifier is provided, then it can be used to reduce<br>
the search space of the database. At step 515, the integrity validator determines whether the<br>
signature was found in the database. If so, then at step 520 the signature was validated.<br>
If the integrity validator did not find the signature in the database, then at step 525 the<br>
integrity validator determines if there is another database (or integrity validator) that can<br>
validate the signatures. If not, then at step 530, the signature is rejected as invalid, and<br>
processing ends. Otherwise, then at step 535 the integrity validator forwards the signature to<br>
the other database (or integrity validator). At step 540, the integrity validator determines<br>
whether the signature was found in the other database. If so, then processing returns to step<br>
520, and the signature is validated. Otherwise, processing returns to step 525 to determine if<br>
there is another database (or integrity validator) to which the signature can be forwarded.<br>
FIG. 6 shows a flowchart of the procedure used by a computer, such as the computer<br>
of FIG, 1, to assemble an integrity log to validate the computer using the integrity validator of<br>
FIG. 1. At step 605, the integrity log generator identifies modules on the computer system.<br>
At step 610, the integrity log generator generates signatures for the modules. At step 615, the<br>
integrity log generator can optionally assemble the signatures into an integrity log. As shown<br>
by arrow 620, step 615 is optional; the signatures do not need to be assembled into an<br>
integrity log. Finally, at step 625, the integrity log generator transmits the signatures, and<br>
optionally the module identifiers, to an integrity validator for validation.<br>
FIGs. 7A-7B show a flowchart of the procedure used by the integrity validator of FIG.<br>
1 to validate a computer. In FIG. 7A, at step 705, the integrity validator receives signatures,<br>
and optionally, module identifiers, for validation. At step 710, the integrity selects a<br>
signature for validation. The signature selected can be the next one in sequence, or can be<br>
selected according to some other criteria. At step 715, the integrity validator attempts to<br>
validate the signature, as described above with reference to FIGs. 5A-5B.<br>
  At step 720 (FIG. 7B), the integrity validator determines whether the signature was<br>
validated. If so, then at step 725 the integrity validator adds the signature to the set of<br>
signatures that are found in the database; otherwise, at step 730 the integrity validator adds<br>
the signature to the set of signatures that are not found in the database. Either way, at step<br>
735, the integrity validator checks to see if there are any signatures remaining to validate. If<br>
so, then processing returns to step 710 on FIG. 7A. Otherwise, at step 740, the integrity<br>
validator generates a trust score. As discussed above with reference to FIG. 2, the trust score<br>
can weight certain signatures more highly than others in generating the trust score.<br><br>
WO 2006/058313	PCT/US2005/043035<br>
11<br>
As discussed above, step 715 refers to FIGs. 5A-5B in how to validate signatures for a<br>
computer system. As discussed above, FIGs. 5A-5B describes processing a single signature,<br>
and forwarding the signature to another integrity validator in case the first integrity validator<br>
cannot validate the signature. While this approach works well for individual signatures, with<br>
multiple signatures, such as in an integrity log, an alternative embodiment processes as many<br>
signatures as possible using the first integrity validator, and forwarding the unvalidated<br>
signatures to a second integrity validator as a group.<br>
FIG. 8 shows a flowchart of the procedure used by the integrity validator of FIG. 1 to<br>
grant or deny a computer, such as the computer of FIG. 1, access to a network resource. In<br>
FIG. 8, at step 805, the integrity validator generates a trust score for a computer system, as<br>
discussed above with reference to FIGs. 7A-7B. At step 810, the integrity validator accesses<br>
a policy for the desired resource. At step 815, the integrity validator compares the trust score<br>
with the policy. Finally, at step 820, the.integrity validator uses the policy to determine an<br>
appropriate level of access to the resource for the computer system.<br>
The following discussion is intended to provide a brief, general description of a<br>
suitable machine in which certain aspects of the invention may be implemented. Typically,<br>
the machine includes a system bus to which is attached processors, memory, e.g., random<br>
access memory (RAM), read-only memory (ROM), or other state preserving medium, storage<br>
devices, a video interface, and input/output interface ports. The machine may be controlled,<br>
at least in part, by input from conventional input devices, such as keyboards, mice, etc., as<br>
well as by directives received from another machine, interaction with a virtual reality (VR)<br>
environment, biometric feedback, or other input signal. As used herein, the term "machine"<br>
is intended to broadly encompass a single machine, or a system of communicatively coupled<br>
machines or devices operating together. Exemplary machines include computing devices<br>
such as personal computers, workstations, servers, portable computers, handheld devices,<br>
telephones, tablets, etc., as well as transportation devices, such as private or public<br>
transportation, e.g., automobiles, trams, cabs, etc.<br>
The machine may include embedded controllers, such as programmable or non-<br>
programmable logic devices or arrays, Application Specific Integrated Circuits, embedded<br>
computers, smart cards, and the like. The machine may utilize one or more connections to<br>
one or more remote machines, such as through a network interface, modem, or other<br>
communicative coupling. Machines may be interconnected by way of a physical and/or<br>
logical network, such as an intranet, the Internet, local area networks, wide area networks,<br>
etc. One skilled in the art will appreciated that network communication may utilize various<br><br>
WO 2006/058313	PCT/US2005/043035<br>
12<br>
wired and/or wireless short range or long range carriers and protocols, including radio<br>
frequency (RF), satellite, microwave, Institute of Electrical and Electronics Engineers (IEEE)<br>
545.11, Bluetooth, optical, infrared, cable, laser, etc.<br>
The invention may be described by reference to or in conjunction with associated data<br>
including functions, procedures, data structures, application programs, etc. which when<br>
accessed by a machine results in the machine performing tasks or defining abstract data types<br>
or low-level hardware contexts. Associated data may be stored in, for example, the volatile<br>
and/or non-volatile memory, e.g., RAM, ROM, etc., or in other storage devices and their<br>
associated storage media, including hard-drives, floppy-disks, optical storage, tapes, flash<br>
memory, memory sticks, digital video disks, biological storage, etc. Associated data may be<br>
delivered over transmission environments, including the physical and/or logical network, in<br>
the form of packets, serial data, parallel data, propagated signals, etc., and maybe used in a<br>
compressed or encrypted format. Associated data may be used in a distributed environment,<br>
and stored locally and/or remotely for machine access.<br>
Having described and illustrated the principles of the invention with reference to<br>
illustrated embodiments, it will be recognized that the illustrated embodiments may be<br>
modified in arrangement and detail without departing from such principles, and may be<br>
combined in any desired manner. And although the foregoing discussion has focused on<br>
particular embodiments, other configurations are contemplated, hi particular, even though<br>
expressions such as "according to an embodiment of the invention" or the like are used<br>
herein, these phrases are meant to generally reference embodiment possibilities, and are not<br>
intended to limit the invention to particular embodiment configurations. As used herein,<br>
these terms may reference the same or different embodiments that are combinable into other<br>
embodiments.<br>
Consequently, in view of the wide variety of permutations to the embodiments<br>
de scribed herein, this detailed description and accompanying material is intended to be<br>
illustrative only, and should not be taken as limiting the scope of the invention. What is<br>
claimed as the invention, therefore, is all such modifications as may come within the scope<br>
and spirit of the following claims and equivalents thereto.<br><br>
Claims as Amended under Article 34<br>
Int'l Patent Application No. PCT/US2005/043035<br>
MJM Docket No. 8404-008<br>
METHOD TO CONTROL ACCESS BETWEEN NETWORK ENDPOINTS BASED<br>
ON TRUST SCORES CALCULATED FROM INFORMATION SYSTEM<br>
COMPONENT ANALYSIS<br>
1.	An apparatus, comprising:<br>
a database arranged to store a first plurality of signatures for a first plurality of<br>
modules;<br>
a receiver to receive a second plurality of signatures corresponding to a second<br>
plurality of modules in a machine;<br>
a validator operative to compare at least a received one of the second plurality of<br>
signatures with the one or more of plurality of signatures in the database, to identify a first<br>
subset of the second plurality of modules for which the corresponding signatures are found in<br>
the database, and to identify a second subset of the second plurality of modules for which the<br>
corresponding signatures are not found in the database; and<br>
a trust score generator to generate a trust score for the machine based on the first<br>
subset of the second plurality of modules for which the corresponding signatures are found in<br>
the database and the second subset of the second plurality of modules for which the<br>
corresponding signatures are not found in the database.<br>
2.	An apparatus according to claim 1, wherein the first plurality of signatures for<br>
the first plurality of modules includes a first plurality of hashes for the plurality of modules.<br>
3.	An apparatus according to claim 1, wherein:<br>
the apparatus further comprises a transmitter to transmit the signatures corresponding<br>
to the second subset of the second plurality of modules for which the corresponding<br>
signatures are not found in the database to a second database of signatures;<br>
the receiver is operative to receive from the second database a second trust score; and<br>
the trust score generator is operative to generate the trust score based on the first<br>
subset of the plurality of modules for which the corresponding signatures are found in the<br>
database and the second trust score.<br>
Application No. PCTVUS2005/043035	13	MJM Docket No. 8404-008<br><br>
4.	An apparatus according to claim 1, wherein:<br>
the database is arranged to store a first plurality of identifiers for the first plurality of<br>
modules:<br>
the receiver is operative to receive a second plurality of identifiers for the second<br>
plurality of modules in the machine; and<br>
the validator is operative to compare the second plurality of signatures with the<br>
plurality of signatures in the database using the second plurality of identifiers for the plurality<br>
of modules in the machine.<br>
5.	An apparatus according to claim 1, further comprising a policy to control<br>
access to a resource, the policy including a threshold score to receive full access to the<br>
resource.<br>
6.	An apparatus according to claim 5, the policy further comprising a second<br>
threshold score to receive partial access to the resource.<br>
7.	An apparatus according to claim 1, wherein the receiver is operative to receive<br>
a signature of a module to add to the database.<br>
8.	A system, comprising:<br>
a network;<br>
a resource connected to the network;<br>
a computer connected to the network, including an integrity log generator to generate<br>
an integrity log including a first plurality of signatures for a first plurality of modules; and<br>
an apparatus connected to the network, including:<br>
a database arranged to store a second plurality of signatures for a second<br>
plurality of modules;<br>
a receiver to receive from the computer the integrity log;<br>
a trust score generator to generate a trust score based on a comparison of the<br>
integrity log with the first plurality of signatures; and<br>
a policy to control access to the resource, the policy including a threshold<br>
score to receive full access to the resource;<br>
wherein access to the resource by the computer is controlled by the policy.<br>
Application No. PCT/US2005/043035	(^t	MJM Docket No. 8404-008<br><br>
9.	A system according to claim 8. wherein:<br>
the system includes a second apparatus, the second apparatus including a second<br>
database arranged to store a third plurality of signatures for a third plurality of modules; and<br>
the apparatus includes a transmitter to transmit the signatures corresponding to a<br>
subset of the first plurality of modules for which the corresponding signatures are not found<br>
in the database to the second apparatus.<br>
10.	A system according to claim 9, further comprising a second network, the<br>
apparatus and the second apparatus connected to the second network.<br>
11.	A method, comprising:<br>
receiving a first plurality of signatures corresponding to a plurality of modules in the<br>
machine;<br>
comparing the first plurality of signatures for the plurality of modules with a second<br>
plurality of signatures in a database;<br>
identifying a first subset of the plurality of modules for which the corresponding<br>
signatures are found in the database and a second subset of the plurality of modules for which<br>
the corresponding signatures are not found in the database; and<br>
generating a trust score for the machine based on the first subset of the plurality of<br>
modules for which the corresponding signatures are found in the database and a second<br>
subset of the plurality of modules for which the corresponding signatures are not found in the<br>
database.<br>
12.	A method according to claim 11, further comprising controlling access to a<br>
resource on a network based on the trust score.<br>
13.	A method according to claim 12, wherein controlling access to a resource on a<br>
network based on the trust score includes:<br>
accessing a policy for access to the resource on the network; and<br>
using the policy to control access to the resource based on the trust score.<br>
14.	A method according to claim 13, wherein using the policy to control access to<br>
the resource based on the trust score includes granting full access to the resource if the trust<br>
score exceeds a threshold score according to the policy.<br>
Application No. PCT/US2005/043035	15"	MJM Docket No. 8404-008<br><br>
15.	A method according to claim 13, wherein using the policy to control access to<br>
the resource based on the trust score includes granting partial access to the resource if the<br>
trust score is higher than a first threshold score but lower than a second threshold score<br>
according to the policy.<br>
16.	A method according to claim 13, wherein using the policy to control access to<br>
the resource based on the trust score includes denying access to the resource if the trust score<br>
is lower than a threshold score according to the policy.<br>
17.	A method according to claim 11, wherein generating a trust score includes<br>
weighting at least a first module more highly than at least a second module in generating the<br>
trust score.<br>
18.	A method according to claim 11, wherein receiving a first plurality of<br>
signatures includes receiving an integrity log including the first plurality of signatures<br>
corresponding to the plurality of modules.<br>
19.	A method according to claim 11, wherein:<br>
the method further comprises:<br>
forwarding the signatures corresponding to the second subset of the plurality<br>
of modules for which the corresponding signatures are not found in the database to a<br>
second database of signatures; and<br>
receiving from the second database a third subset of the plurality of modules<br>
for which the corresponding signatures are found in the second database and a fourth<br>
subset of the plurality of modules for which the corresponding signatures are not<br>
found in the second database; and<br>
generating a trust score includes generating the trust score based on the first subset of<br>
the plurality of modules for which the corresponding signatures are found in the database and<br>
the third subset of the plurality of modules for which the corresponding signatures are found<br>
in the third database.<br>
Application No. PCT/US2005/043035	16	MJM Docket No. 8404-008<br><br>
20.	A method according to claim 11, wherein:<br>
receiving a first plurality of signatures corresponding to a plurality of modules<br>
includes receiving the first plurality of signatures and a plurality of identifiers for the plurality<br>
of modules; and<br>
comparing the first plurality of signatures for the plurality of modules with a second<br>
plurality of signatures in a database includes comparing the first plurality of signatures for the<br>
plurality of modules with the second plurality of signatures in the database using the plurality<br>
of identifiers for the plurality of modules.<br>
21.	An apparatus according to claim 1, further comprising a transmitter to transmit<br>
said trust score to the machine.<br>
22.	A system according to claim 8. wherein the apparatus further includes a<br>
transmitter to transmit said trust score to the computer.<br>
23.	A method according to claim 11, further comprising transmitting the trust<br>
score to the machine.<br>
Application No. PCTYUS2005/043035	17	MJM Docket No. 8404-008<br><br>
Signatures are generated for modules in a computer system. The signatures can be assembled into an integrity<br>
log. The signatures are compared with signatures in a database in an integrity validator. Once signatures are either validated or<br>
invalidated, a trust score can be generated. The trust score can then be used to determine whether the computer system should be<br>
granted access to a resource using a policy.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=3mM0W30sax9S6SVJTEHpGg==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=3mM0W30sax9S6SVJTEHpGg==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="270570-process-for-producing-alkenes-from-oxygenates-by-using-supported-heteropolyacid-catalysts.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="270572-audio-encoding-system.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>270571</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1954/KOLNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>01/2016</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>01-Jan-2016</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>31-Dec-2015</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>30-May-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>SIGNACERT, INC.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>707, SW WASHINGTON STREET, FLOOR 7, PORTLAND, OR</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>STARNES, WILLIAM WYATT</td>
											<td>1536, SW ELIZABETH COURT, PORTLAND, OREGON 97201</td>
										</tr>
										<tr>
											<td>2</td>
											<td>BLECKMANN, DAVID MAURITS</td>
											<td>1907, SE 34TH AVENUE, PORTLAND, OREGON 97214</td>
										</tr>
										<tr>
											<td>3</td>
											<td>ANDERSEN, BRADLEY DOUGLAS</td>
											<td>15318, SW TURNAGAIN DRIVE, TIGARD, OREGON 97224</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04L 9/00, G06F 7/04</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2005/043035</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-11-28</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/631,449</td>
									<td>2004-11-29</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/637,066</td>
									<td>2004-12-17</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>3</td>
									<td>60/631,450</td>
									<td>2004-11-29</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/270571-method-to-control-access-between-network-endpoints-based-on-trust-scores-calculated-from-information-system-component-analysis by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 04:07:50 GMT -->
</html>
