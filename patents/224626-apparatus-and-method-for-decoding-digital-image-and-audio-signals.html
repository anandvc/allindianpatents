<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/224626-apparatus-and-method-for-decoding-digital-image-and-audio-signals by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:34:46 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 224626:APPARATUS AND METHOD FOR DECODING DIGITAL IMAGE AND AUDIO SIGNALS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">APPARATUS AND METHOD FOR DECODING DIGITAL IMAGE AND AUDIO SIGNALS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>APPARATUS AND METHOD FOR DECODING DIGITAL IMAGE AND AUDIO SIGNALS The present invention relates to an apparatus and a method for decoding of encoded signals representing at least image information from a storage medium. A storage device is configured to receive the storage medium. A decoder is configured to receive the compressed encrypted encoded signals from the storage medium, and send the signals to a decryptor. The decryptor is configured to decrypt the compressed encrypted encoded signals, and send the signals to a decompressor. The decompressor is configured to receive the compressed encoded signals from the decryptor and to decompress the compressed encoded signals to enable display of the image.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
The present invention relates to encoding digital and audio images. More specifically, the present invention relates to an apparatus and a method for decoding digital image and audio information in a digital cinema system. The invention further relates to the encoding, compression, storage, decryption, decompression, deayption, and controlled playback of electronic audio/visual programming from a central facility to multiple display projectors or presentation systems.<br>
II.  Description of the Related Art<br>
For several decades, the motion picture industry has depended on the duplication, distribution, and projection of celluloid film for delivering creative programming material to geographically diverse theaters around the country and the world. To a large extent, the methods and mechanisms for the distribution of film material has remained relatively unchanged.<br>
The current film duplication and distribution process is illustrated in FIG. 1. Film duplication typically starts with an exceptional quality camera negative. At a film studio 50, a film editor 52 produces a master film copy after the process for producing the original film has taken place. From this master film copy, a film duplication element 54 produces what is referred as a distribution negative, from which distribution prints (known as "posihves") are produced in quantities. Depending on the size of the release or number of copies desired for distributing the film, there may be more intermediate steps or multiple copies produced at each stage. The film positives are distributed by courier and other physical means to various theaters, as exemplified by a theater 56. At the theater 56, the movie is displayed by projecting images from the film onto a display surface using a film projector 58.   In this traditional system, a<br><br>
onto a display surface using a film projector 58. In this traditional system, a multiple track audio program is generally created by an audio editing system 51 and printed along with the motion picture images on the film so that this soundtrack can be played back on a theater sound system 57 in time synchronization with the motion picture in a theater projection system.<br>
Although the distribution process shown in FIG. 1 works well, there are inherent limitations. Due to the use of celluloid material for the film and the bandwidth limitations of the film media, there are restrictions on the ability to provide high fidelity multi-channel audio programming. Then, there is the high expense of making a large number of film duplicates, which can cost several hundreds of dollars for each feature length film. There is also the expense, complexity, and delay associated with physically distributing large canisters of celluloid film to a large and growing number of theater locations. Also, a growing trend in the motion picture theater industry is the development of so called "multiplex" theater locations in which multiple projection auditoriums are located or clustered together at a single theater location. Each projection auditorium may show a motion picture at the same time as other motion pictures are being shown in the other projection auditoriums in the multiplex complex.<br>
Because of the large number of duplicates made, it becomes increasingly difficult to prevent illegal duplication and theft of the material. It is estimated that revenues lost due to piracy and theft account for billions of dollars lost each year by the motion picture industry. Further, duplicated film material tends to degrade over time due to dust collection, wear-and-tear, thermal variances, and other known factors. Finally, management cost and other expenses are involved in the eventual destruction of the film material, which may contain regulated hazardous material.<br>
New and emerging technologies are making it possible to provide alternative approaches to the ongoing film distribution problems. For example, satellite transmission methods are now available, although they are not currently commercially viable for the distribution of high quality audio/visual (AV) material. Since the distribution of film programming is essentially a special type<br><br>
of broadcast to a continent-wide region, a satellite distribution method with inherent advantages to such wide area broadcasting would seem ultimately appropriate for film distribution. However, in order to transmit a quality AV signal in "real-time," the data rate requirement (in bits per second) is on the order of 1.5 billion bits per second. This high data rate requires the capacity equivalent of an entire satellite to transmit even a single program, which is prohibitively experisive. Moreover, alternative distribution technologies have not been able to offer the image quality and projection brightness available using celluloid film. Competing technologies typically involve audio/visual (AV) signals recorded on various magnetic or optical media for display on video monitors, television, or projection equipment. These technologies do not offer the quality of film due to bandwidth limitations.<br>
In addition to the ability to transmit the necessary information via satellite, the received information must be displayed using a high quality projector, which has not previously been available. Moreover, implementation of a satellite based transmission and receiver system is costly and a radical change from current methods of film distribution and display. It is perceived that such a radical change may not be initially commercially acceptable.<br>
Also, advances in digital technology have led to a revolutionary' distribution concept whereby programming material is to electronically stored in a digitized format, rather than on an optical film media. The digitized images may be distributed on various magnetic media or compact optical discs, or transmitted over wired, fiber optic, wireless, or satellite communication systems. A variety of DVD-ROM storage formats exist having storage capacities ranging from about 4.5 gigabytes (GB) to about 18 GB. The DVD-ROM storage formats that have a storage capacity greater than about 9 GB are implemented on dual-sided disks. As such, high storage capacity DVD-ROM disks must be manually turned over to access the stored information from the second side of the disk.<br>
An average two hour movie having an average image compressed bit rate of about 40 Mbps for the image track and about eight Mbps for audio and control information requires approximately 45 GB of storage space. Thus, even if a high<br><br>
storage capacity DVD-ROM disk is implemented, a two-hour movie requires use of multiple DVD-ROM disks for adequate capacity.<br>
Further, for playback, the average two-hour DVD-ROM movie requires information to be output at about 6 megabytes per second, or about 48 Mbps. Although some DVD-ROM devices exist advertise an 8 MB/sec transfer rate, the quality and rehability of such devices is unknown. Thus, there is no guarantee that such DVD-ROM devices can reliably sustain a 6 MB/sec transfer rate.<br>
in order to reduce the data rate requirement for the storage of high quality electronic images, compression algorithms are being developed. One digital dynamic image compression technique capable of offering significant compression while preserving the quality of image signals utilizes adaptively sized blocks and sub-blocks of encoded discrete cosine transform (DCT) coefficient data. This technique will hereinafter be referred to as the adaptive block size discrete cosine transform (ABSDCT) method. The adaptive block sizes are chosen to exploit redundancy that exists for information within a frame of image data. The technique is disclosed in U.S. Pat. No. 5,021,891, entitled "Adaptive Block Size Image Compression Method And System," assigned to the assignee of the present invention and incorporated herein by reference, DCT techniques are also disclosed in U.S. Pat. No. 5,107,345, entitled "Adaptive Block Size Image Compression Method And System," assigned to the assignee of the present invention and incorporated herein by reference. Further, the use of the ABSDCT technique in combination with a Discrete Quadtree Transform technique is discussed in U.S. Pat No. 5,452,104, entitled "Adaptive Block Size Image Compression Method And System," also assigned to the assignee of the present invention and incorporated by reference herein. The systems disclosed in these patents utilize intraframe encoding, wherein each frame of an image sequence is encoded without regard to the content of any other frame.<br>
Distribution of film information using a digital electronic format actually increases the potential for rapid, low-cost duplication without quality degradation. However, along with the "ease of duplication" associated with digital  technology,  there  exists  encryption  techniques  to  ensure  that  the<br><br>
information is encoded in a way that prevents useful information from being distributed to unauthorized parties.<br>
Technologies such as the ABSDCT compression technique, advanced projection equipment, and electronic encryption methods offer the possibility of a "digital cinema" system. Generally defined, digital cinema refers to the electronic distribution and display of laigh quality film programming which has been converted to a digital electronic representation for storage, trai^smission, and display purposes. A digital cinema system would overcome many of the limitations of the current film distribution process. A digital system would not be subject to the quality degradation over time experienced by celluloid film. Further, a digital system virtually eliminates the theft and illegal duplication of celluloid film, and further offers the possibility of implementing security measures within the digital system itself. However, a complete digital cinema system has not been developed by the motion picture industry or related arts.<br>
Several issues and problems remain to be solved. New digital cinema systems require improved forms of protection to prevent theft from theaters. Theater complexes with multiple auditoriums have grown larger in an effort to provide a greater economic return, resulting in more complicated presentation schedules, and a larger number of locations showing a given film. This could require many additional electronic copies to be forwarded to theaters for presentation using current techniques, with associated complexity and operating costs.<br>
Distribution channels and mechanisms are still defined by the older celluloid film copying and distribution techniques discussed above. New techniques are needed to lake full advantage of proposed digital cinema processing, to reduce copying, provide faster releases to market, and updating products in release, while providing increased scheduling and distribution flexibility at reasonable cost. At the same time, some film producers, studios, and theater managers would like to have increased centralized control over releases and distribution, and to be able to expand into newer markets. For example, it is desirable to be able to supply films and other audio-visual<br><br>
presentations with alternative sound tracks to address increasing markets for multi-lingual or alternative language audiences, in a more cost effective manner. What is needed is the integration of certain technology into an apparatus and method for the encoding, encryption, storage, and management of digital image and audio programming. These goals are achieved by the present invention in the manner described below.<br><br>
SUMMARY OF THE INVENTION<br>
The present invention is an apparatus and method in which encoded signals representing an image and conveyed thereto in compressed and encrypted form on a storage medium are processed to enable display of the image, the apparatus comprising a storage device configured to receive the storage medium; and a decoder configured receive the compressed encrypted encoded signals from the storage medium, The decoder further comprises a decryptor configured to decrypt the compressed encrypted encoded signals; and a decompressor configured to receive the compressed encoded signals from the decryptor and to decompress the compressed encoded signals to enable display of the image, the decompressor using an inverse adaptive block sized discrete cosine transform compression technique. The method of the invention is a method in which encoded signals representing an image and conveyed thereto in compressed and encrypted form on a storage medium are processed to enable display of the image, the method comprising the steps of retrieving compressed encrypted encoded signals from the storage medium; decrypting the compressed encrypted encoded signals to produce compressed encoded signals; and decompressing the compressed encoded signals to enable display of the image, the act of decompressing using an inverse adaptive block sized discrete cosine transform compression technique.<br>
Accordingly, the apparatus and method provide for the decoding, decryption and decompression of image and/or audio information, generally in the form of programming material. At a central facihty or hub, the programming material is digitally compressed, encrypted and stored to be ready for distribution of that material to large screen displays of the program at one or more auditoriums or theater locations. The programming material generally comprises motion picture images, time synchronized audio programming, and/or other related information, such as visual cue tracks for sight-impaired audiences, subtitling for foreign language and/or hearing impaired audiences, advertisements or multimedia time cue tracks.   The program material may be<br><br>
lengthy in duration (such as a feature length motion picture), of a shorter duration (such as a motion picture trailer or commercial advertisement) or a still image (such as for an advertisement or announcement). The audio and other related programs need not be time synchronized or stored with the image information, such as the case with background audio programming and advertisements.<br>
At the central hub, the program information is processed for distribution. A source generator, located either at the central hub or an alternative site, may be utilized to generate electronic audio and image signals from an analog or digital input. The source generator may comprise a telecine for generating the electronic image signal and an audio reader for generating the electronic audio signal. Alternatively, the electronic signal may be provided directly from an electronic camera or other electronic source, such as a computer-based image generation system.<br>
The electronic image and audio signals then undergo processing by a compressor/encryptor. Again, the compressor/encryptor may be located either at the central hub or at the same facility as the source generator, for example, a production studio. A known dynamic compression teclinology may be used to store the image and audio information onto a storage medium. A compression tecl\nique such as the ABSDCT method described in 5,452,104, 5,107,345, and 5,021,891 may be used. The storage medium may be any type of high capacity electronic tape, magnetic, or optical storage device, such as CDs, DVDs or hard drives, or network attached storage. Further, some information may instead be transmitted over wired, fiber optic, wireless, or satellite communication systems. The audio signal may be compressed using the above methods or a standard digital audio compression algorithm and stored on similar devices.<br>
Tlie encryption technique involves the use of time-varying elech-onic key values and/or digital control word sequence, which is provided to authorized receivers or projectors. In addition, a digital signature or "watermark" may be added to the image and/or audio signal. The watermark is not perceptible to the normal viewing  audience,  but  may  be  used   to  idcntif}'  a  source  of an<br><br>
unauthorized copy of a program when analyzed under non-real-time or still frame playback. Decryption information necessary to decrypt the image and/or audio information is generated at individual decrypter units using secret auditorium specific keys and secure information sent to the theater. Generally, the image and audio signals are separately encrypted. By treating the image and audio portions as separate programs, different audio programs may be combined with image programs for various reasons, such as varying languages.<br>
The compressed and encrypted signals are also stored on a storage medium, or provided transmitted from the central hub. If transmitted, the modulation/transmission technique may add forward error correction information and modulate the data stream for transmission. The transmission may be over any type of wired or wireless communication, such as terrestrial cable, optic, satellite, the Internet or other methods.<br>
The central hub further comprises a network manager. The network manager may include control processors to manage total operation in both the encoder and the theater subsystem, including control of the storage, playback/display, security, and overall monitor/control and network management functior\s. The network manager is capable of operating under centrally or distributed fully automatic control, semi-automatic control or with manual intervention.<br>
Under control of the network manager, the programming material and additional control information are stored and transferred to the theater subsystems. The network manager also includes control methods for notifying the theater subsystems of the identity of trar\smitted programs. In addition, a control method is provided to control each theater subsystem's selective storage of the received programming.<br>
At the theater subsystem, a storage device receives the storage medium(s) from the hub. A playback module reads the information from the storage medium, monitors the stored information for errors and requests retransmission of any portions of information that contain errors. The theater subsystem, such as the theater manager, utilizes a communication path (from the theater system<br><br>
to the central hub) to request retransmission.' The communication path may use the telephone network, a satellite channel, the Internet or any type of communication method.<br>
Under the control of the theater manager, the storage device in the theater subsystem may provide for local centralized storage of the programming material. The storage device may contain storage mediums such as DVD disks, removable hard drives, or a 0BOD) Just a Bunch of Drives module. The storage device may store several programs at one time. The storage device may be connected via a local area network (LAN) (electronic or optical) in such a way that any program may be played back and presented on any authorized projector. Also, the same program may be simultaneously played back on two or more projectors. Programming material is routed from the storage device to the designated auditorium(s) via a local area netv^^ork (LAN) v^hich may use various LAN architectures. For purposes of this description, this description assumes the use of a LAN that incorporates a central network switcli architecture. However, other types of LAN architectures are possible with this subsystem.<br>
After the programming material is sequenced by the playback module, a<br>
decoder decompresses and decrypts, or descrambles, the programming material.<br>
The decompression and decryption algorithms depend on the compression and<br>
encryption      techniques     employed      at      the      central      hub.	The<br>
decompressed/decrypted informahon is displayed using a projector in the auditorium, while the audio signal is presented using an electronic sound subsystem.<br>
The theater manager generally controls all aspects of projection operations, including storage of the received programming, decompression and decryption of the programming signals, and display of the programming material. The theater manager may also control the period of time and/or the number of play backs that are allowed for each program. Alternatively, control of the presentation process may be located locally at the projector, a remote control unit, or under control of the central hub or other centralized element. In<br><br>
addition, the theater manager may be configured to integrate projection operations with other theater operations, such as concessions, ticketing, promotions, signage, environmental controls, lighting, sound system operation, etc. Also, each theater subsystem may include multiple auditorium modules sharing common storage and control functions for flexible and cost efficient presentation options.<br>
The use of digital encryption provides a built-in security measure. Cryptographic techniques are employed to provided end-to-end encrypted data transfer. That is, the image and/or audio information is encrypted at the source generator and is decrypted at the theater subsystem during playback. In addition to the electronic security measures, physical security measures may provide additional protection of the programming material.<br>
Physical security measures may be especially important for protecting the<br>
decompressed/decrypted signals from a "wiretap" prior to display by the<br>
projector    in     the    theater    subsystem.	In    an    embodiment,     the<br>
decryption/decompression function is housed in a secure, self-contained chassis which is physically attached to or embedded inside the projector in a manner in which it is generally not removable without authorization access and which physically prevents probing of the decrypted signals. In addition, intrusion into the secured environment or chassis may cause a process to be commenced that deletes or erases cryptographic key information and otherwise deletes or changes any digital data available at the project feed point to prevent copying.<br>
Accordingly, an apparatus and method is provided for the decoding, decompression and decryption of digital and audio information, as well as management functions to monitor and control such an apparatus.<br><br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The features, objects, and advantages of the present invention will become more apparent from the detailed description set forth below when taken in conjunction with the drawings in which like reference characters identify correspondingly throughout and ^^'herein:<br>
FIG. 1 is a block diagram of a traditional film distribution system;<br>
FIG. 2 is a high-level block diagram of an embodiment of the digital cinema apparatus of the present invention;<br>
FIG. 3 is a block diagram of a film-based source generator;<br>
FIG. 4 is a block diagram of a compressor/encryptor;<br>
FIG. 5 is a block diagram of a network manager;<br>
FIG. 6 is a block diagram illustrating a hub internal network and central hub redundancy;<br>
FIGS. 7A-E are block diagrams of a storage device;<br>
FIG. 8 is a block diagram of a storage module using multiple disk players in serial and a playback player;<br>
FIG. 9 is a block diagram of a storage device using multiple disk players in parallel and a playback player;<br>
FIG. 10 is a block diagram of a storage device using a disk cartridge and a playback player;<br>
FIG. 11 is a block diagram of a theater subsystem using removable hard drives as the storage device;<br>
FIG. 12 is a block diagram of a theater manager; and<br>
FIG. 13 is a block diagram of a theater subsystem using a JBOD module as the storage device.<br>
DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS<br><br>
The present invention comprises an apparatus and method, sometimes referred to herein as "digital cinema", for the electronic decoding, decompression and decryption of audio/visual programming, such as motion pictures in theater systems, theaters, theater complexes, and/or presentation systems.<br>
Digital cinema incorporates innovation in image and audio compression, projection technology, encryption methodology, and many other areas. Digital cinema is designed to replace the current method of physical distribution of celluloid film to each play back or projection location such as theaters or remote auditoriums. Digital cinema eliminates the need for duplication of celluloid film, and offers the potential for exceptional audio/visual quality as well as built-in security measures. Programs may be transmitted to theaters and stored on storage devices, such as removable hard drives (RHD) or digital versatile disks (DVD), for display at later times.<br>
While the invention is equally applicable to presentation of image and audio information to a variety of presentation locations such as outdoor amphitheaters, drive-in complexes, civic auditoriums, schools, specialty restaurants, and so forth, an exemplary theater or theater complex is used for purposes of clarity in the discussion below. Those skilled in the art will readily understand how the present invention is applied to other types of locations.<br>
A digital cinema apparatus 100 of the invention is illustrated in FIG. 2. The digital cinema apparatus 100 comprises two main systems: at least one central facility or hub 102 and at least one presentation or theater subsystem 104. The hub 102 and the theater subsystem 104 are of a similar design to that of pending US Patent Application Serial No. 09/075,152 filed on May 8,1998, assigned to the san: â–  assignee as the present invention, and is incorporated by reference herein.<br>
In an embodiment, image and audio information are compressed and stored on a storage mc dium, and distributed from the hub 102 to the theater subsystem 104. Generally, one theater subsystem 104 is utilized for each theater or presentation location in a network of presentation locations that is to receive<br><br>
image or audio information, and includes some centralized equipment as well as certain equipment employed for each presentation auditorium.<br>
In the central hub 102, a source generator 108 receives film material and generates a digital version of the film. The digital information is compressed and encrypted by a compressor/encryptor (CE) 112, and stored on a storage medium by a hub storage device 116. A network manager 120 monitors and sends control information to the source generator 108, the CE 112, and the hub storage device 116. A conditional access manager 124 provides specific electronic keying information such that only specific theaters are authorized to show specific programs.<br>
In the theater subsystem 104, a theater manager 128 controls a theater manager 132. Based on control information received from the theater manager 132, a theater storage device 136 transfers compressed information stored on the storage medium to a playback module 140. The playback module 140 receives the compressed information from the theater storage device 136, and prepares the compressed information to a predetermined sequence, size and data rate. The playback module 140 outputs the compressed information to a decoder 144. The decoder 144 inputs compressed information from the playback module 140 and performs decryption, decompression and formatting, and outputs the information to an projector 148 and a soimd module 152. The projector 148 plays the information on a projector and the sound module 152 plays sound information on a sound system, both under control of the theater manager 132.<br>
In operation, the source generator 108 provides digitized electronic image and/or programs to the system. Typically, the source generator 108 receives film material and generates a magnetic tape containing digitized information or data. The film is digitally scanned at a very high resolution to create the digitized version of the motion picture or other program. Typically, a "telecine" process generates the image information while well-known digital audio conversion processing generates the audio portion of the program. The images being processed need not be provided from a film, but can be single picture or still frame type images, or a series of frames or pictures, including those shown<br><br>
as motion pictures of varying length. These images can be presented as a series or set to create what are referred to as image programs. In addition, other material can be provided such as visual cue tracks for sight-impaired audiences, subtitling for foreign language and/or hearing impaired audiences, or multimedia time cue tracks. Similarly, single or sets of sounds or recordings are used to form desired audio programs.<br>
Alternatively, a high definition digital camera or other known digital image generation device or method may provide the digitized image information. The use of a digital camera, which directly produces the digitized image information, is especially useful for live event capture for substantially immediate or contemporaneous distribution. Computer workstatioris or similar equipment can also be used to directly generate graphical images whicli are to be distributed.<br>
The digital image information or program is presented to the compressor/encryptor 112, which compresses the digital signal using a preselected known format or process, reducing the amount of digital information necessary to reproduce the original image with very high quality. In a preferred embodiment, a ABSDCT technique is used to compress the image source. Tlie ABSDCT compression technique is disclosed in U.S. Pat. Nos. 5,021,891, 5,107,345, and 5,452,104 mentioned above. The audio information may also be digitally compressed using standard techniques and may be time synchronized with the compressed image information. The compressed image and audio information is then encrypted and/or scrambled using one or more secure electronic methods.<br>
The network manager 120 monitors the status of compressor/encryptor 112, and directs the compressed information from the compressor/encryptor 112 to the hub storage device 116. The hub storage device 116 is comprised of one or more storage mediums (shown in Fig. 8). The storage medium(s) may be any type of high capacity data storage device, such as a digital versatile disk (DVD) or a removable hard drive (RHD) and as described further herein. Upon storage of the compressed information onto the storage medium, the storage medium is<br><br>
physically transported to the theater subsystem 104, and in particular, to the theater storage device 136.<br>
In alternative embodiments, the compressed image and audio information are each stored in a non-contiguous or separate manner independent of each other. That is, a means is provided for compressing and storing audio programs associated with image information or programs but segregated in time. There is no requirement when using the present invention to process the audio images at the same time. A predefined identifier or identification mechanism or scheme is used to associate corresponding audio and image programs with each other, as appropriate. Tliis allows linking of one or more preselected audio programs with at least one preselected image program, as desired, at a time of presentation, or during a presentation event. Tliat is, while not initially time synchronized with the compressed image information, the compressed audio is linked and synchronized at presentation of the program.<br>
Further, maintaining the audio program separate from the image program allows for synchronizing multiple languages from audio programs to the image program, without having to recreate the image program for each language. Moreover, maintaining a separate audio program allows for support of multiple speaker configurations without requiring interleaving of multiple audio tracks with the image program.<br>
In addition to the image program and the audio program, a separate promotional program, or promo program, may be added to the system. Typically, promotional material changes at a greater frequency than the feature program. Use of a separate promo program allows promotional material to be updated without requiring new feature image programs. The promo program comprises information such as advertising (slides, audio, motion or the like) and trailers shown in the theater. Because of the high storage capacity of storage mediums such as DVD or RHD, thousands of slides or pieces of advertising may be stored. The high storage volume allows for customization, as specific slides, advertisements or trailers may be shown at specific theaters at targeted customers.<br><br>
Although FIG. 2 illustrates the compressed information in the storage device 116 and physically transporting storage medium(s) to the theater subsystem 104, it should be understood that the compressed information, or portions thereof, may be transmitted to the theater storage device 136 using any of a number wireless or wired trarismission methods. Transmission methods include satellite transmission, well-known multi-drop, Internet access nodes, dedicated telephone lines, or point-to-point fiber optic networks.<br>
Embodiments of the processing blocks of the central hub 102 are illustrated in FIGS. 2-9 and described herein. The source generator 108 is illustrated in FIG. 3. In FIG. 3, the source generator 108 digitizes a film image source 156 such as a 35 mm motion picture film, and stores the digitized version on a magnetic tape. The source generator 108 comprises a high definition (HD) "telecine" apparatus or process 164 for receiving the film source 156 and for generating digitized images from the film source 156. The telecine processing is well known within the motion picture industry, and any one of several commercially available services or devices may be used to implement this process. However, in a preferred embodiment, high resolution telecine processing is used such as is currently available with equipment produced by CINTEL or Philips BTS, as is known in the art. The resolution and specific choices of equipment used are determined according to cost and other well known factors when a service is being designed. Alternative resolutions can also be used depending on the target audience, projection equipment available, and location, including a desire to reduce data rates for certain satellite transfers.<br>
If the original film 156 is a standard format 35 mm source, the process is performed on the image using a telecine process at 24 frames per second. The digitized output of the telecine process may be stored using a high data rate magnetic tape recorder or immediately compressed and/or encrypted and stored using a lower data rate tape recorder, or other known image storage system and media.<br>
Since the telecine only processes the image, the audio portion of the input source is processed independently of the image. If the audio source is in analog<br><br>
format, it is typically provided on a magnetic tape 168 to an audio reader 172 for digitizing. Li one embodiment, up to twelve channels of digitized audio are combined with the digitized image by a multiplexer 176. The multiplexed signal is stored with the image program on a storage medium such as a high density digital video tape recorder 180 or a similar high capacity digital storage system. Alternatively, as mentioned above, the audio programming may be stored and processed separately from the image programming, but with time synchronization information included to allow for properly time aligned combination with the image program at the projection auditorium playbaci
Although shown as part of the central hub 102, it should be understood that the source generator 108 may be located in a facility other than the central hub 102. Other facilities may be just as suitable for generating the digitized signal from a tape, magnetic or an optical source. Alternatively, the source generator 108 may consist of a digital camera with a magnetic or optical storage device built in or other digital means of image generation (such as for computer generated graphics or special effects) which directly produces digital source material. The source generator 108 may also consist of a digitization system for shll images, such as an optical scanner or an image converter used for 35 mm photographic slides or prints. Therefore, regular or specialized studios such as for special effects, or other facilities participating in the preparation and presentation of an image program can generate the desired digitized material which is then transferred to the hub 102 for further processing or transmission.<br>
A block diagram of the compressor/encrj'ptor 112 is illustrated in FIG. 4. Similar to the source generator 108, the compressor/encryptor system 112 may be part of the central hub 102 or located in a separate facility. For example, the compressor/encryptor 112 may be located with the source generator 108 in a film or television production studio. In addition, the compression process for either image or audio information or data may be implemented as a variable rate process.<br><br>
The compressor/encryptor 112 receives a digital provided by the source generator 108. The digital image and audio information may be stored in frame buffers (not shown) before further processing.<br>
The digital image signal is passed to an image compressor 184. In a preferred embodiment, the image compressor 184 processes a digital image signal using the ABSDCT technique described in U.S. Pat. Nos. 5,021,891, 5,107,345, and 5,452,104 mentioned above.<br>
In the ABSDCT technique, the color input signal is generally in a YIQ format, with Y being the luminance, or brightness, component, and I and Q being the chrominance, or color, components. Other formats such as the YUV or RGB formats may also be used. Because of the low spatial sensitivity of the eye to color, the ABSDCT technique sub-samples the color (I and Q) components by a factor of two in each of the horizontal and vertical directions. Accordingly, four luminance components and two chrominance components are used to represent each spatial segment of image input.<br>
Each of the luminance and chrominance components is passed to a block interleaver. Generally, a 16x16 block is presented to the block interleaver, which orders the image samples within the 16x16 blocks to produce blocks and composite sub-blocks of data for discrete cosine transform (DCT) analysis. The DCT operator is one method of converting a time-sampled signal to a frequency representation of the same signal. By converting to a frequency representation, the DCT techniques have been shown to allow for very high levels of compression, as quantizers can be designed to take advantage of the frequenc}' distribution characteristics of an image. In a preferred embodiment, one 16x16 DCT is applied to a first ordering, four 8x8 DCTs are applied to a second ordering, 16 4x4 DCTs are applied to a third ordering, and 64 2x2 DCTs are applied to a fourth ordering.<br>
The DCT operation reduces the spatial redundancy inherent in the image source. After the DCT is performed, most of the image signal energy tends to be concentrated in a few DC coefficients.<br><br>
For the 16x16 block and each sub-block, the transformed coefficients are analyzed to determine the number of bits required to encode the block or sub-block. Then, the block or the combination of sub-blocks which requires the least number of bits to encode is chosen to represent the image segment. For example, two 8x8 sub-blocks, six 4x4 sub-blocks, and eight 2x2 sub-blocks may be chosen to represent the image segment.<br>
The chosen block or combination of sub-blocks is then properly arranged in order. The DCT coefficient values may then undergo further processing such as, but not limited to, frequency weighting, quantization, and coding (such as variable length coding) using known techniques, in preparation for transmission. The compressed image signal is then provided to at least one image encryptor 188.<br>
The digital audio signal is generally passed to an audio compressor 192. In a preferred embodiment, the audio compressor 192 processes multi-channel audio information usiiig a standard digital audio compression algorithm. The compressed audio signal is provided to at least one audio encryptor 196. Alternatively, the audio information may be transferred and utilized in an imcompressed, but still digital, format.<br>
The image encryptor 192 and he audio encryptor 196 encrypts the compressed image and audio signals, respectively, using any of a number of known encryption techniques. The image a^rd audio signals may be encrypted using the same or different techniques. In a preferred embodiment, an encryption technique, which comprises real-time digital sequence scrambling of both image and audio programming, is usea.<br>
At the image and audio encryplors 192 and 196, the programming material is processed by a scrambler/tncryptor circuit that uses time-var^^ing electronic keying information (typically changed several times per second). The scrambled program iiiformation can then be stored or trar\smitted, such as over the air in a wireless link, without being decipherable to anyone who does not possess the associated electronic keying information used to scramble the program material or digital data.<br><br>
Referring back to Fig. 4, in addition to scrambling, the image encryptor 192 may add a "watermark," which is usually digital in nature, to the image programming. This involves the ir\sertion of a location specific and/or time specific visual identifier into the program sequence. That is, the watermark is constructed to indicate the authorized location and time for presentation, for more efficiently tracking the source of illicit copying when necessary. The watermark may be programmed to appear at frequent, but pseudo-random periods iii the playback process and would not be visible to the viewing audience. The watermark is perceptually unnoticeable during presentation of decompressed image or audio information at what is predefined as a normal rate of transfer. However, the watermark is detectable when the image or audio iiiformation is presented at a rate substantially different from that normal rate, such as at a slower "non-real-time" or still frame playback rate. If an unauthorized copy of a program is recovered, the digital watermark information can be read by authorities, and the theater from which the copy was made can be determined. Such a watermark technique may also be applied or used to identify the audio programs.<br>
The compressed and encrypted image and audio signals are both presented to a multiplexer 200. At the multiplexer 200, the image and audio information is multiplexed together along with time synchronization information to allow the image and audio streamed information to be played back in a time aligned manner at the theater subsystem 104. The multiplexed signal is then processed by a program packetizer 204, which packetizes the data to form the program stream. By packetizing the data, or forming "data blocks," the program stream may be monitored during decompression at the theater subsystem 104 (FIG. 2) for errors in receiving the blocks during decompression. Requests may be made by the theater manager 128 of the theater subsystem 104 to acquire data blocks exhibiting errors. Accordingly, if errors exist, only small portions of the program need to be replaced, instead of an entire program. Requests of small blocks of data may be handled over a wired or wireless link. This provides for increased reliability and efficiency.<br><br>
In an alternate embodiment of the present invention, the image and audio portions of a program are treated as separate and distinct programs. Thus, instead of using the multiplexer 200 to multiplex the image and audio signals, the image signals are separately packetized. In this embodiment, the image program may be transported exclusive of the audio program, and vice versa. As such, the image and audio programs are assembled into combined programs only at playback time. This allows for different audio programs to be combined with image programs for various reasons, such as varying languages, providing post-release updates or program changes, to fit within local community standards, and so forth. This ability to flexibly assign audio different multi-track programs to image programs is very useful for minimizing costs in altering programs already in distribution, and in addressing the larger multi-cultural markets now available to the film industry.<br>
The compressors 184 and 192, the encryptors 188 and 196, the multiplexer 200, and the program packetizer 204 may be implemented by a compression/encryption module (CEM) controller 208, a software-controlled processor programmed to perform the functions described herein. That is, they can be configured as generalized function hardware including a variety of programmable electronic devices or computers that operate under software or firmware program control. They may alternatively be implemented using some other technology, such as through an ASIC or through one or more circuit card assemblies. That is, constructed as specialized hardware.<br>
The image and audio program stream is sent to the hub storage device 116. The CEM controller 208 is primarily responsible for controlling and monitoring the entire compressor/encryptor 112. The CEM controller 208 may be implemented by programming a general purpose hardware device or computer to perform the required functions, or by using specialized hardware. Network control is provided to CEM controller 208 from the network manager 120 (FIG. 2) over a hub internal network, as described herein. The CEM controller 208 communicates with the compressors 184 and 192, the encryptors 188 and 196, the multiplexer 200, and the packetizer 204 using a known digital<br><br>
interface and controls the operation of these elements. The CEM controller 208 may also control and monitor the storage module 116, and the data transfer between these devices.<br>
The storage device 116 is preferably constructed as one or more RHDs, DVDs disks or other high capacity storage mediums, which in general is of similar design as the theater storage device 116 in theater subsystem 104 (FIG. 2). However, those skilled in the art will recognize that other media may be used in some applications. The storage device 116 receives the compressed and encrypted image, audio, and control data from the program packetizer 204 during the compression phase. Operation of the storage device 116 is managed by the CEM controller 208.<br>
Referring now to FIG. 5, a network manager 120 is illustrated. The network manager 120 controls and manages the hub 102, and optionally, the entire digital ciiiema system 100, including control and monitoring of the components of one or more theater systems 104. The control may be centralized such that the network manager 120 manages the total operation of the system, including control of the transfer, playback/display, security, and overall network management functions. Alternatively, a distributed management system, in which processors in the presentation or theater systems control some of the theater functions, may be implemented.<br>
The network manager 120 comprises at least one network management processor 212, which is the central controller or "brain" for the digital cinema system 100. The network manager 120 is, in general, based on a standard platform workstation, or similar programmable data processing hardware. The network management processor 212 manages the scheduling and security aspects of the hub 102. Under control of the network manager 120, control information or updates to programs may be transmitted from the hub 102 in advance of the time for display of the programming to the theater subsystem 104. The network management processor 212 also controls the transmission or transfer rate of the programs to the theater subsystem 104. The transmission rate may be fixed or varied depending on the type of program and the design of the<br><br>
transfer channel or path. For example, this may depend on the transfer rates for a particular data link. Also, the data rate of the compression coding of the programming material may vary for different programs, offering varying quality levels of compression.<br>
The network management processor 212 interfaces to the other components of the hub over a hub internal network, which is typically implemented using a standard multi-drop network architecture. However, other known network designs and types including optical based links can be used. In a preferred embodiment, an Ethernet hub 216 of the network management system 112 supports the hub internal network, as discussed herein with reference to FIG. 6.<br>
The network manager 120 may also comprise a modem 220, which provides an interface to the network of theaters over the Internet or the PSTN, and generally comprises of a set of dialup telephone modems, cable or sateUite modems, ISDN or cellular link controllers, or other known means. Modem 220 interfaces to the network management processor 212 via a modem server function. The modem 220 serves as the receiver of a return link commui\ication path from the theaters to the central hub 102. For example, the theater manager 128, illustrated in FIG. 7, monitors the quality of the decompression process of the theater subsystem 104 and provides a quality report to network management system 120. The return path may be utilized by the theaters to request retransmission of program data blocks with errors from central hub 102. Furthermore, extra presentations of programs, or changes or updates in program material can be requested using this link, in alternative embodiments, the return path may be provided through a satellite channel or another low data rate communication method or via the Internet. In this case, other known means or devices for interfacing are implemented, as appropriate, instead of the modem 220.<br>
A user interface 224 allows a user to have direct control over the network manager 112, and accordingly, the entire hub 102 and/or the theater subsystem 104. The user may monitor the status of the hub 102 and direct the timing of the<br><br>
various modules of the hub 102. Further, the user interface 224 allows for configuration of the various embodiments of the storage device 116, including the type of storage medium to be used, and how and where programs are to be stored on the storage mediums. The user interface 224 is typically a personal computer having a monitor and keyboard interface.<br>
Referring now to FIG. 6, a block diagram of hub internal network 228 is illustrated. Hub internal network 228 is the communication backbone for central hub 102. Hub internal network 228 may be extended internally as an Ethernet Local Area Network (LAN) running an IP protocol suite. Thus, hub internal network 228 physically interconnects the compressor/encryptor 112, the storage device 116, the network manager 120, the conditional access manager 124, and, optionally, the theater manager 128 of the theater subsystem 104 to an ethernet hub 232. Also, the hub internal network 228 may include redundant or backup components to meet availabihty requirements in the event of primary component failure. As appropriate to the specific functional partitioning of local and remote functions, an external interface may also be provided to connect central hub 102 to an external computer network or communication system, if desired.<br>
As illustrated in Fig. 2, the theater subsystem 104 is constructed with at least one and generally multiple theater manager 132 controlled by the theater manager 128. For example, in some commercial markets theaters are constructed as theater complexes having many auditoriunis at a single site, often referred to as cineplex or multiplex theaters. The stored compressed information can be transferred to one or multiple ones of the auditorium modules 132 within a single theater complex.<br>
The auditorium module 132 comprises the theater storage device 136, the playback module 140, the decoder 144, and the projector 148 and the sound module 152. In operation, the theater storage device 136 contains compressed information on the storage medium. Various embodiments of the storage device 136 are illustrated in Fig. 7. Generall)', the storage medium is physically transported from the hub 102 to the theater subsystem 104, although it is<br><br>
contemplated that portions of information may be transmitted from the hub 102 to the theater subsystem 104. The storage medium may be one or more DVD disks 236 (Figs. 7A and 7C), one or more removable hard drives 240 (Fig. 7B), an internal hard drive (IHD) 244 in the playback module (Fig. 7D), a JBOD Qust a Bunch of Drives) module 248 (Fig. 8) comprising many memory elements or any combination thereof.<br>
In an embodiment using DVDs as the storage medium, multiple DVD disks 236 may be used. This embodiment is illustrated in Fig 7A. An average two hour movie having an image compressed bit rate of about 40 Mbps for the image track and about eight Mbps for audio and control information requires approximately 45 GB of storage space. Current DVD-ROM storage formats range from about 4.5 GB to about 18 GB. Storage capacities greater than about 9 GB are on dual-sided disks that must be turned over to read the second side of the disk. Thus, even if a high storage capacity DVD-ROM disk is implemented, a two hour movie requires use of multiple DVD-ROM disks for adequate capacity.<br>
As described earlier, it is preferable to separate image information from audio information. This embodiment is illustrated in Fig. 7C. The image program 252 is stored on a separate storage medium than the audio program 256. The storage medium may be DVD disks or RHDs. There is no requirement when using the present invention to process audio programs at the same time. Maintaining the audio program separate from the image program allows for synchronizing multiple languages from audio programs to the image program, without having to recreate the image program for each language. Moreover, maintaining a separate audio program allows for support of multiple speaker configurations without requiring interleaving of multiple audio tracks with the image program.<br>
In addition to the image program 252 and the audio program 256, a separate promotional program 260, or promo program, may be added to the system. Use of a separate promo program 260 allows promotional material to be updated without requiring new feature image programs 252.    The promo<br><br>
program 260 may comprise advertising, trailer, control, and/or keying information for the theater subsystem 104.<br>
Use of the removable hard disk as the storage medium offers several advantages, such as ease of duplication and the likelihood of a lower error rate. This embodiment is illustrated in Fig 7B. Stored information on the hard disk 240 is easily replicated by writing information onto disks in a standard personal computer (PC) environment. Further, because of the large storage capacity of removable hard drives, fewer removable hard drives are necessary. Use of hard drives, in comparison to other storage mediums, lowers the likelihood of handling errors. Also, a removable hard drive is more likely to hold data integrity in case of encountering a harsh environment, such as rough handling during shipping, or exposure to dust, dirt, noise or other foreign matter.<br>
In another embodiment illustrated in Fig. 7D, an internal hard disk (IHD) 244 and modem 264 are utilized in addition to other storage mediums. Storage of information on the IHD 244 via the modem 264 allows for information to be sent directly to the theater over existing communications systems, such as telephone lines, ISDN, cable modem, or DSL links. For example, updates to advertising and trailer information may be sent via phone lines and stored on the IHD 244. Updated slides may optionally be presented in the theater directly from the IHD 244, rather than from the promotional program disk. Sending updates of advertising and trailer information via the modem 264 connection results in significant cost savings, as the cost of pressing and distributing additional promotional program disks is avoided.<br>
Another function of the IHD 244 is that of a data integrity system. The IHD 244 checks information stored on the storage medium for data integrity before being sent to the playback module. The data integrity system checks for an electronic signature for each block of data. If any CRC block fails in the check procedure, or if the data block is missing, the playback module uses the modem connection to request that the blocks of data in error be resent. Upon request, the requested blocks of data are stored on the IHD 244. When the playback module is playing the program, the playback module accesses the IHD 244 to<br><br>
play the requested block(s) of data at the appropriate time. For efficiency and data rate concerns, it is most useful to access a relatively few number of data blocks. If the error checking system discovers that large numbers of blocks of data are corrupted, an error message indicator lets a user determine if the amoimt of data in question warrants physical distribution of data disks.<br>
Use of the IHD 244 and modem 264 is also beneficial for the distribution of cryptographic keying material. Cryptographic keying material and other control information is sent from the conditional access manager 124 to the IHD 244 by either physically sending the data in a separate storage medium, or using the modem 264. In turn, operational status, history, and other information may be transferred to the conditional access manager 124. Although control information is transmitted from the central hub 102, and although the theater subsystem 104 is capable of receiving all transmitted information, the theater subsystem 104 selectively demodulates and stores only received programming intended for the particular theater module 104.<br>
Given sufficient capacity of the IHD 244, or by using the JBOD module 348, image programs, audio programs and/or promo programs may be uploaded from the storage medium to the IHD. Use of the IHD 244 allows the playback module to support double-feature and other multiple program scheduling. Further, a given feature may be shown on multiple screens by uploading the program(s) to multiple playback modules such that the feature is played from the IHD 244 of each playback module.<br>
Jn an alternate embodiment illustrated in Fig. 7E, a local area network (LAN) interface 268 may replace the modem interface 264 illustrated in Fig. 7D. In addition to accomplishing the functions with respect to the modem interface 264 described above, the LAN interface 268 may connect to one or more playback modules and/or to the theater manager 128. A user interface (not shown) is connected into the LAN interface 268 and/or the theater manager 128 such that the user may remotely control and monitor functions such as scheduling, control, and fault monitoring of each playback module, decoder module, or image and sound modules.   Further, it is contemplated that the<br><br>
network manager 120 may be connected into the LAN interface 268. The LAN interface 268 also allows for programs to be transferred between playback modules.<br>
An embodiment using multiple DVD disks 272a, 272b, ... 272n as the storage medium and a set of single-play DVD disk players 276a, 276b,... 276n is illustrated in Fig 8. The set of single-play DVD disk players 276a, 276b, ... 276n is played in a serial mode, in a predetermined sequence, playing the stored information on its respective disk. The stored information is fed, via a switch 280, into a buffer 284, such as the FIFO RAM buffer 284 illustrated in Fig 8. The FIFO-RAM buffer 284 is of a sufficient capacity such that the decoder 144, and subsequently the projector 148, is not overloaded or underloaded with portions of information. In a preferred embodiment, the FIFO-RAM buffer 284 has a capacity of about 100 to 200 MB. Use of the FIFO-RAM buffer 284 is especially significant when the DVD disks 272a, 272b, ... 272n are read in the serial mode. When the DVD disks are read in serial mode, there may be a several second delay when switching from one disk to another.<br>
The stored data is then fed into the decoder 144 through a fiber channel interface 288. The switch 280, buffer 284 and fiber channel interface are controlled by the playback module CPU 292.<br>
The set of single-play DVD disk players 276a, 276b, ... 276n may also be played in a parallel mode, as illustrated in Fig. 9. In parallel mode, multiple DVD disk players 276a, 276b,... 276n play back different portions of compressed information, and the portions are later recombined in the playback module 140. The portions of compressed information are read from the DVD disk players 276a, 276b,... 276n to a parallel read/destriping mechanism 296, which properly sequences the portions of compressed information. In a preferred embodiment, the destriping mechanism 296 is a software module accessible by the playback module 140. As illustrated in Fig, 9, the destriping mechanism 296 is a software module accessed by the CPU 292 of the playback module 140. The destriping mechanism 296 may be resident in the CPU 292. The destriping mechanism 296 also performs error checking functions to ensure error-free playback. Portions of<br><br>
the compressed information may contain redundant information in case parts of the disk are unreadable or if some compressed information is corrupted. In such cases, the destriping mechanism 296 is able to use the redundant information to recreate any corrupted information. The redundant information and sequence information may be stored on a separate DVD disk, and read in parallel along with other disks of compressed information 272a, 272b,... 272n.<br>
In an alternate embodiment to either of the embodiments illustrated in Figs. 8 and 9, a DVD disk cartridge may be used in place of the set of single-play DVD disks. Illustrated in Fig. 10, The DVD disk cartridge 300 is similar in operation to known CD disk cartridges. Multiple disks are inserted into the DVD disk cartridge 300. Software control resident in the storage device 136, the playback module 140, or the CPU 292 assures that the disks are properly installed and that the disks are accessed in the proper sequence. The multiple disks are be fed into a single DVD player. A switch mechanism 304, such as that in Fig. 8, controls which DVD disk is inserted into the DVD player. In the DVD disk cartridge embodiment, either serial or parallel playback may also be implemented.<br>
Figure 11 illustrates operation of the auditorium module 132 losing one or more removable hard drives (RHDs) 308. For speed, capacity, and convenience reasons, it may be desirable to use more than one RHD 308. When reading data sequentially, some RHDs have a "prefetching" feature that anticipates a following read command based upon a recent history of commands. This prefetching feature is useful in that the time required to read sequential information off the disk is reduced. However, the time needed to read nonÂ¬sequential information off the disk may be increased if the RHD receives a command that is unexpected. In such a case, the prefetching feature of the RHD may cause the random access memory of the RHD to be full, thus requiring more time to access the information requested. Accordingly, having more than one RHD is beneficial in that a sequential stream of data, such as an image program, may be read faster. Further, accessing a second set of information on a separate RHD disk, such as audio programs, trailers, control information, or advertising.<br><br>
is advantageous in that accessing such information pn a single RHD is more time consuming.<br>
Thus, compressed information is read from one or more RHDs 308 into a buffer 284. The FIFO-RAM buffer 284 in the playback module 140 receives the portions of compressed information from the storage device 136 at a predetermined rate. The FIFO-RAM buffer 284 is of a sufficient capacity such that the decoder 144, and subsequently the projector 148, is not overloaded or underloaded with information. In a preferred embodiment, the FIFO-RAM buffer 284 has a capacity of about 100 to 200 MB. Use of the FIFO-RAM buffer 284 is especially significant as there may be a several second delay when switching from one drive to another.<br>
The portions of compressed information is output from the FIFO-RAM buffer into a network interface 288, which provides the compressed information to the decoder 144. In a preferred embodiment, the network interface 288 is a fiber charmel arbitrated loop (FC-AL) interface.<br>
In an alternate embodiment not specifically illustrated, a switch network controlled by the theater manager 128 receives the output data from the playback module 140 and directs the data to a given decoder 144. Use of the switch network allows programs on any given playback module 140 to be transferred to any given decoder 144.<br>
When a program is to be viewed, the program information is retrieved from the storage device 136 and transferred to the auditorium module 132 via the theater manager 128. The decoder 144 decrypts the data received from the storage device 136 using secret key information provided only to authorized theaters, and decompresses the stored information using the decompression algorithm which is inverse to the compression algorithm used at source generator 108. The decoder 144 converts the decompressed image information to a standard video format used by the projection system (which may be either an analog or digital format) and the image is displayed through an electronic projector 148. The audio information is also decompressed and provided to the auditorium's sound system 152 for playback with the image program.<br><br>
A block diagram of the decoder 144 is also illustrated in FIG. 11. The decoder 144 processes a compressed/encrypted program to be visually projected onto a screen or surface and audibly presented using the sound system 152. The decoder 144 is controlled by its controller 312 or via the theater manager 128, and comprises at lest one depacketizer 316, the controller, or CPU 312, a buffer 314, an image decryptor/decompressor 320, and an audio decryptor/decompressor 324. The buffer may temporarily store information for the depacketizer 316. All of the may be implemented on one or more circuit card assemblies. The circuit card assemblies may be installed in a self-contained enclosure that mounts on or adjacent to the projector 148. Additionally, a cryptographic smart card 328 may be used which interfaces with controller 312 and/or image decryptor/decompressor 320 for transfer and storage of unit-specific cr&gt;'ptographic keying information.<br>
The depacketizer 316 identifies and separates the individual control, image, and audio packets that arrive from the playback module 140, the CPU 312 and/or the theater manager 128. Control packets may be sent to the theater manager 128 while the image and audio packets are sent to the image and audio decr)'ption/decompression systems 320 and 324, respectively. Read and write operations tend to occur in bursts. Therefore, large buffers 314 are used to stream data smoothly from the depacketizer 316 directly to the projection equipment.<br>
The theater manager 128 configures, manages the security of, operates, and monitors the theater subsystem 104. This includes the external interfaces, image and audio decryption/decompression modules 320 and 324, along with projector 148 and the .sound module 152. Control information comes from the playback module 140, the CPU 312, the theater manager system 128, a remote control port, or a local control input, such as a control panel on the outside of the auditorium module 132 housing or chassis. Tlie decoder CPU 312 may also manage the electronic keys assigned to each auditorium module 132, PreÂ¬selected electronic cryptographic keys assigned to auditorium module 132 are used in conjunction with the electronic cryptographic key information that is<br><br>
embedded in the image and audio data to decrypt the image and audio information before the decompression process. In a preferred embodiment, decoder CPU 312 uses a standard micro-processor running embedded in the software of each auditorium module 132, as a basic functional or control element.<br>
In addition, the decoder controller 312 is preferably configured to work or communicate certain information with theater manager 128 to maintain a history of presentations occurring in each auditorium. Information regarding this presentation history is then available for transfer to the hub 102 using the return link, or through a transportable medium at preselected times.<br>
The image decryptor/decompressor 320 takes the image data stream from depacketizer 316, performs decryption, and reassembles the original image for presentation on the screen. The output of this operation generally provides standard analog RGB signals to digital cinema projector 148. Typically, decryption and decompression are performed in real-time, allowing for real-time playback of the programming material.<br>
The image decryptor/decompressor 320 decrypts and decompresses the image data stream to reverse the operation performed by the image compressor 184 and the image encryptor 188 of the hub 102. Each auditorium module 132 may process and display a different program from other auditorium modules 132 in the same theater subsystem 104 or one or more auditorium modules 132 may process and display the same program simultaneously. Optionally, the same program may be displayed on multiple projectors, the multiple projectors being delayed in time relative to each other.<br>
The decryption process uses previously provided unit-specific and program-specific electronic cryptographic key information in conjunction with the electronic keys embedded in the data stream to decrypt the image information. (The decryption process has previously been described with reference to FIG. 4.) Each theater subsystem 104 is provided with the necessary cryptographic key information for all programs authorized to be shown on each auditorium module 132.<br><br>
A multi-level cryptographic key manager is used to authorize specific presentation systems for display of specific programs. This multi-level key manager typically utilizes electronic key values which are specific to each authorized theater manager 128, the specific image and/or audio program, and/or a time varying cryptographic key sequence within the image and/or audio program. An "auditorium specific" electroruc key, typically 56 bits or longer, is programmed into each auditorium module 132.<br>
This programming may be implemented using several techniques to transfer and present the key information for use. For example, the return link discussed above may be used through a link to transfer the cryptographic information from the conditional access manager 124. Alternatively, smart card technology such as smart card 328, pre-programmed flash memory cards, and other known portable storage devices may be used.<br>
For example, the smart card 328 may be designed so that this value, once loaded into the card, cannot be read from the smart card memory. Physical and electronic security measures are used to prevent tampering with this key information and to detect attempted tampering or compromise. The key is stored in such a way that it can be erased in the event of detected tampering attempts. The smart card circuitry includes a microprocessor core including a software implementation of an encryption algorithm, typically Data Encryption Standard (DES). The smart card can input values provided to it, encrypt (or decrypt) these values using the on-card DES algorithm and the pre-stored auditorium specific key, and output the result. Alternatively, the smart card 328 may be used simply to transfer encrypted electronic keying information to circuitry in the theater subsystem 104 which would perform the processing of this key information for use by the image and audio decryption processes.<br>
Image program data streams undergo dynamic image decompression using an inverse ABSDCT algorithm or other image decompression process symmetric to the image compression used in the central hub compressor/encryptor 112. If image compression is based on the ABSDCT algorithm the decompression process includes variable length decoding, inverse<br><br>
frequency weighting, inverse differential quad-tree transformation, IDCT, and DCT block combiner deinterleaving. The processing elements used for decompression may be implemented in dedicated specialized hardware configured for this function such as an ASIC or one or more circuit card assemblies. Alternatively, the decompression processing elements may be implemented as standard elements or generalized hardware including a variety of digital signal processors or programmable electronic devices or computers that operate under the control of special function software or firmware programming. Multiple ASICs may be implemented to process the image information in parallel to support high image data rates.<br>
The decompressed image data goes through digital to analog conversion, and the analog signals are output to projector the 148. Alternatively, a digital interface may be used to convey the decompressed digital image data to the projector 148 obviating the need for the digital-to-analog process.<br>
The audio decryptor/decompressor 324 takes the audio data stream from the depacketizer 316, performs decryption, and reassembles the original audio for presentation on a theater's speakers or audio sound system 152. The output of this operation provides standard line level audio signals to the sound system 152.<br>
Similar to the image decryptor/decompressor 320, the audio decryptor/decompressor 324 reverses the operation performed by the audio compressor 192 and the audio encryptor 196 of the hub 102. Using electronic keys from the cryptographic smart card 328 in conjunction with the electronic keys embedded in the data stream, the decryptor 324 decrypts the audio information. The decrypted audio data is then decompressed.<br>
Audio decompression is performed with an algorithm symmetric to that used at the central hub 102 for audio compression. Multiple audio channels, if present, are decompressed. The number of audio channels is dependent on the midtiphonic sound system design of the particular auditorium, or presentation system. Additional audio channels may be transmitted from the central hub 102 for enhanced audio programming for purposes such as multi-language audio<br><br>
tracks and audio cues for sight impaired audiences. The system may also provide additional data tracks synchronized to the image programs for purposes such as multimedia special effects tracks, subtitling, and special visual cue tracks for hearing impaired audiences.<br>
As discussed earlier, audio and data tracks may be time synchronized to the image programs or may be presented asynchronously without direct time synchronization. Image programs may consist of single frames (i.e., still images), a sequence of single frame still images, or motion image sequences of short or long duration.<br>
If necessary, the audio channels are provided to an audio delay element, which inserts a delay as needed to synchronize the audio with the appropriate image frame. Each channel then goes through a digital to analog conversion to provide what are known as "line level" outputs to sound system 152. That is, the appropriate analog level or format signals are generated from the digital data to drive the appropriate sound system. Tlie line level audio outputs typically use standard XLR or AES/EBU connectors found in most theater sound systems.<br>
The projector 148 presents the electronic representation of a program on a screen. The high quality projector is based on advanced technology, such as liquid crystal light valve (LCLV) methods for processing optical or image information. The projector 148 receives an image signal from image decryptor/decompressor 320, typically in standard Red-Green-Blue (RGB) video signal format. Information transfer for control and monitoring of the projector 148 is typically provided over a digital serial interface from the controller 312.<br>
Referring back to FIG. 11, the decoder chassis 144 includes a fiber charmel interface 288, the depacketizer 316, the decoder controller or CPU 312, the image decrj^Jtor/decompressor 320, the audio decryptor/decompressor 324, and the cryptographic smart card 328. The decoder chassis 144 is a secure, self-contained chassis that also houses the encryption smart card 328 interface, internal power supply and/or regulation, cooling fans (as necessary), local control panel, and external interfaces. The local control panel may use any of various known input devices such as a membrane switch flat panel with embedded LED indicators.<br><br>
The local control panel typically uses or forms part of a hinged access door to allow entry into the chassis interior for service or maintenance. This door has a secure lock to prevent unauthorized entry, theft, or tampering of the system. During installation, the smart card 328 containing the encryption keying information (the auditorium specific key) is installed inside the decoder chassis 144, secured behind the locked front panel. The cryptographic smart card slot is accessible only inside the secured front panel. The RGB signal output from the image decryptor/decompressor 320 to the projector 148 is connected securely within the decoder chassis 144 in such a way that the RGB signals cannot be accessed while the decoder chassis 144 is mounted to the projector housing. Security interlocks may be used to prevent operation of the decoder 144 when it is not correctly installed to the projector 148.<br>
The sound system 152 presents the audio portion of a program on the theater's speakers. In a preferred embodiment, the sound system 152 receives up to 12 channels of standard format audio signals, either in digital or analog format, from the audio decryptor/decompressor 324<br>
In another embodiment, the playback module 140 and the decoder 144 are integrated into a single playback-decoder unit 332. Combining the playback module 140 and the decoder module 148 results in cost and access time savings in that only a single CPU (292 or 312) is needed to serve the functions of both the playback module 140 and the decoder 144. Combination of the playback module 140 and the decoder 144 also does not require the use of a fiber channel interface 288.<br>
If multiple viewing locations are desired, information on any storage device 136 is configured to transfer compressed information of a single image program to different auditoriums with preselected programmable offsets or delays in time relative to each other. These preselected programmable offsets are made substantially equal to zero or very small when a single image program is to be presented to selected multiple auditoriums substantially simultaneously. At other times, these offsets can be set anywhere from a few minutes to several hours, depending on the storage configuration and capacity, in order to provide<br><br>
very flexible presentation scheduling. This allows a theater complex to better address market demands for presentation events such as first run films.<br>
Fig. 13 illustrates another embodiment of the invention. The user interface 344 allows direct control over the decoder 144, along with the projector 148 and audio system 152. The JBOD (Just a Bunch of Drives) 348 comprises magentic storage mediums, such as a bank of hard disk drives, that store encrypted/compressed encoded signals for scheduled playback periods in designated auditoriums, The JBOD 348 is designed to be scaleable to efficiently support the storage requirements of each theater. Further, each JBOD 348 includes built-in redundancy to prevent loss of stored programming iiiformation in the event of a storage unit failure. Each JBOD 348 may be, for example, a rackÂ¬mounted system that is expandable to accommodate the varying storage requirements of each theater system. The use of the JBOD 348 allows the theater manager 128 to dynamically route program showings to the various screens in a theater complex, and to schedule pre-feature programming. This is accomplished in a highly flexible manner useful to respond quickly to changing needs or market demands.<br>
In a preferred embodiment, each JBOD 348 is designed with a capacity for storage equal to that needed to store programs for its auditorium location. Thus, more than one feature may be shown on the same screen in the same day (double feature). In addition, adequate storage is provided so that future programs may be stored prior to their showing authorization date while still storing the currently "authorized for showing" programs. This amount of available storage capacity allows for programs to be authorized for future showing to be transmitted hours, days or weeks prior to the authorization to playback and display such programs without affecting the ability to playback and display the presently authorized programs. It has been estimated that in terms of digital data storage capacity, on the order of about 120 GigaBytes of storage capacity per auditorium is used in this type of arrangement. This capacity is assuming the use of curreiat compression and image technology, which may change to allow reduced requirements in the near future.<br><br>
Disk storage space is dynamically allocated for each program loaded into the JBOD 348. This concept works for larger theaters with multiple screens because the short and long programs average out to a nominal length, typically of around two hours. As a guideline for single screen theaters, the storage capacity should be sufficient to store the longest programs.<br>
The JBOD 348 is also configured or configurable to operate in a "striping" mode where received information is striped across the array and temporarily stored in a RAM buffer 349. That is, received data that is to be stored is directed in part to different ones of the drives during storage. Part of the input data is transferred to one drive while a subsequent portion is transferred to the next drive and so forth. After sufficient latency time to allow a drive to write data, a given drive can again be scheduled to receive input data. Therefore, received data is segregated into smaller components or segments, each of which is stored at the maximum (or a high) rate allowed by each drive on separate drives, taking advantage of input buffering or memory storage available in the drive input channel. This allows slower transfer rate devices to essentially pull in data in parallel and, therefore, accomplish a very high transfer rate. This type of storage also provides error protection redundancy.<br>
The storage of data on drives, or other storage devices, utilizes parity information that allows the program to be reconstituted upon retrieval. That is, a means is provided for linking the program portions together again at time of retrieval or presentation.<br>
In a preferred embodiment, each JBOD 348 is based on a Redundant Array of Inexpensive Devices (RAID) array design with recovery capability of an entire data file if a disk drive in the array fails. The JBOD 348 provides status and warning indicators to assist in trouble shooting or fault isolation. Remote status, control, and diagnostics may be available with this type of design.<br>
The theater manager 128 is illustrated in FIG. 12. The theater manager 128 provides operational control and monitoring of the entire presentation or theater subsystem 104, or one or more auditorium modules 132 within a theater complex.  The theater manager 128 may also use a program control means or<br><br>
mechanism for creating program sets from one or more received individual image and audio programs, which are scheduled for presentation on an auditorium system during an authorized interval,<br>
The theater manager 128 comprises a theater manager processor 336 and may optionally contain at least one modem 340, or other device that interfaces with a return link, for sending messages back to central hub 102. The theater manager 128 may include a visual display element such as a monitor and a user interface device such as a keyboard, which may reside in a theater complex manager's office, ticket booth, or any other suitable location that is convenient for theater operations.<br>
The theater manager processor 336 is generally a standard commercial or business grade computer. Referring to FIG. 12 with reference to FIG. 2, the theater manager processor 336 communicates with the network manager 120 and conditional access manager 124. In a preferred embodiment, the modem 340 is used to communicate with the central hub 102. The modem 340 is generally a standard phone line modem that resides in or is connected to the processor, and connects to a standard two-wire telephone line to communicate back to the central hub 102. In alternative embodiments, communications between the theater manager processor 336 and the central hub 102 may be sent using other low data rate communications methods such as Internet, private or public data networking, wireless, or satellite communication systems. For these alternatives, the modem 340 is configured to provide the appropriate interface structure.<br>
Referring back to Fig. 2, the theater manager 128 allows each auditorium module 132 to communicate with each storage device 136. A theater management module interface may include a buffer memory such that information bursts may be transferred at high data rates from the theater storage device 136 using the theater manager interface 126 and processed at slower rates by other elements of the auditorium module 132.<br>
Information communicated between the theater manager 128 and the network manager 120 and/or the conditional access manager 124 include requests for retransmission of portions of information received by the theater<br><br>
subsystem 104 that exhibiting uncorrectable bit errors, monitor and control information, operations reports and alarms, and cryptographic keying information. Messages communicated may be cryptographically protected to provide eavesdropping type security and/or verification and authentication.<br>
The theater manager 128 may be configured to provide fully automatic operation of the presentation system, including control of the playback/display, security, and network management functions. The theater manager 128 may also provide control of peripheral theater functions such as ticket reservations and sales, concession operations, and environmental control. Alternatively, manual intervention may be used to supplement control of some of the theater operations. The theater manager 128 may also interface with certain existing control automation systems in the theater complex for control or adjustment of these functions. The system to be used will depend on the available technology and the needs of the particular theater, as would be known.<br>
Through either control of theater manager 128 or the network manager 120, the invention generally supports simultaneous playback and display of recorded programming on multiple display projectors. Furthermore, under control of theater manager 128 or the network manager 120, authorization of a program for playback multiple times can often be done even though theater subsystem 104 only needs to receive the programming once. Security management may control the period of time and/or the number of playbacks that are allowed for each program.<br>
Through automated control of the theater manager 128 by the network management module 112, a means is provided for automatically storing, and presenting programs. In addition, there is the ability to control certain preselected network operations from a location remote from the central facility using a control element. For example, a television or film studio could automate and control the distribution of films or other presentations from a central location, such as a studio office, and make almost immediate changes to presentations to account for rapid changes in market demand, or reaction to presentations, or for other reason understood in the art.<br><br>
Referring back to FIG. 2, the theater subsystem 104 may be connected with the auditorium module 132 using the theater interface network 126. The theater interface network 126 comprises of a local area network (electric or optical) which provides for local routing of programming at the theater subsystem 104. The programs are stored in each storage device 136 and are routed through the theater interface network 126 to one or more of the auditorium system(s) 132 of the theater subsystem 104. The theater interface network 126 may be implemented using any of a number of standard local area network architectures which exhibit adequate data transfer rates, cormectivity, and reliability such as arbitrated loop, switched, or hub-oriented networks.<br>
Still referring to FIG. 2, each storage device 136 provides for local storage of the programming material that it is authorized to playback and display. In an embodiment, the storage system is centralized at each theater system. The theater storage device 136 allows the theater subsystem 104 to create presentation events in one or more auditoriums and may be shared across several auditoriums at one time.<br>
Depending upon capacity, the theater storage device 136 may store several programs at a time. The theater storage device 136 may be connected using a local area network in such a way that any program may be played back and presented on any authorized presentation system (i.e., projector). Also, the same program may be simultaneously played back on two or more presentation systems.<br>
Accordingly, an apparatus and method is provided for the decoding, decompression and decryption of image and/or audio information. Tlie apparatus and method allows for the flexible scheduling of feature films and advertisements, the integration of audio and image signals, and easy implementation of security measures, among other features and advantages.<br>
The previous description of the preferred embodiments is provided to enable any person skilled in the art to make or use the present invention. The various modifications to these embodiments will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to<br><br>
other embodiments without the use of the inventive faculty. Thus, the present invention is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.<br><br><br>
WE CLAIM:<br>
1	An apparatus in which encoded image and audio signals representing an image<br>
program and a plurality of audio programs associated with the image program in compressed and encrypted form on at least one storage medium are processed to enable display of the image program, the apparatus comprising: a storage device configured to receive a plurality of storage media distributively storing the compressed encrypted encoded image and audio signals in portions, wherein the portions comprise redundant information associated with the compressed encrypted image signal; and a decoder configured to receive the portions of the compressed encrypted encoded image and audio signals from the plurality of storage media and to recombine the respective portions of the image and audio signals, said decoder comprising: a first decryptor configured to receive the compressed encrypted encoded image signals from the plurality of storage media and to decrypt the compressed encrypted encoded image signals; a first decompressor configured to receive the compressed encoded image signals from the first decryptor and to decompress the compressed encoded image signals to enable display of the image program; a second decryptor configured to receive the compressed encrypted encoded audio signals from the plurality of storage media and to decrypt the compressed encrypted encoded audio signals; and a second decompressor configured to receive the compressed encoded audio signals from the second decryptor and to decompress the compressed encoded audio signals to selectively play a selected one of the plurality of audio programs in synchronization with the associated image program.<br>
2. The apparatus as claimed in claim 1, wherein the decoders are configured to decrypt and decompress the encoded image and audio signals in a noncontiguous manner independent of each other.<br><br>
3.	The apparatus as claimed in claim 1, wherein at least one of the first and second decompressors is configured to decompress the compressed encoded signals using an inverse adaptive block sized discrete cosine transform compression technique,<br>
4.	The apparatus as claimed in claim 1, wherein the second decompressor is configured to decompress the compressed encoded audio signals at a variable rate.<br>
5.	The apparatus as claimed in claim 1, wherein the encoded image signals form at least one image program, and comprising an identifier used to link one or more audio programs with at least one image program.<br>
6.	The apparatus as claimed in claim 1, wherein the encoded image and audio signals are conveyed onto the plurality of storage medium as data packets, the decompressor comprising a depacketizer configured to extract the encoded image and audio signals from the data packets.<br>
7.	The apparatus as claimed in claim 1, wherein the storage device is configured to receive an apparatus specific key, wherein the first and second decryptors are configured to decrypt the compressed encrypted encoded image and audio signals under conditions determined by the apparatus specific key.<br>
8.	The apparatus as claimed in claim 7, wherein the apparatus specific key is stored on a key storage medium separate from the encoded image or audio signals.<br>
9.	The apparatus as claimed in claim 8, wherein the key storage medium is a smart card.<br>
10.	The apparatus as claimed in claim 8, wherein the key storage medium is a magnetic disk.<br><br>
11.	The apparatus as claimed in claim 7, wherein the apparatus specific key is transmitted.<br>
12.	The apparatus as claimed in claim 7, comprising means for indicating a time interval over which the apparatus specific key is valid and for assuring that the apparatus specific key is only used during that interval.<br>
13.	The apparatus as claimed in claim 12, wherein the apparatus specific key is overwritten from the key storage medium after the time interval expires.<br>
14.	The apparatus as claimed in claim 1, wherein the encoded signals comprise at least one watermark, wherein the watermark is perceptually unnoticeable during presentation of the image program or the selected audio program at a predefined normal rate of transfer, but is detectable when the image program or the seelcted audio program is presented at a rate substantially different from the normal rate.<br>
15.	The apparatus as claimed in claim 14, wherein the watermark is configured to identify presentation time and location information associated with the encoded image signals or audio program after decompression.<br>
16.	The apparatus as claimed in claim 1, comprising a theater manager, wherein the theater manager is configured to send control information to and receives status information from the storage device and the decoder.<br>
17.	The apparatus as claimed in claim 1, wherein the apparatus is configured to establish a link, wherein the link is configured to send and receive information external from the apparatus.<br>
18.	The apparatus as claimed in claim 17, wherein the information comprises control and status information.<br><br>
19.	The apparatus as claimed in claim 17, wherein the information comprises updates to the image program and/or the audio programs.<br>
20.	The apparatus as claimed in claim 17, wherein the link comprises a dedicated telephone data link.<br>
21.	The apparatus as claimed in claim 17, wherein the link comprises a dialup telephone data link.<br>
22.	The apparatus as claimed in claim 17, wherein the link comprises a packet type data link.<br>
23.	The apparatus as claimed in claim 17, wherein the link comprises an Internet based link.<br>
24.	The apparatus as claimed in claim 17, wherein the link comprises a wireless data link.<br>
25.	The apparatus as claimed in claim 17, wherein the link comprises a satellite based data link.<br>
26.	The apparatus as claimed in claim 1, wherein the storage media comprises at least one optical storage medium.<br>
27.	The apparatus as claimed in claim 26, wherein the storage media comprise multiple optical storage media, and wherein the image signals and the audio signals are stored non-sequentially on the multiple optical storage media.<br><br>
28.	The apparatus as claimed in claim 26, wherein the audio signals are stored on separate optical storage media than the image signals.<br>
29.	The apparatus as claimed in claim 26, comprising encoded signals representing promotional information, and wherein the encoded signals representing promotional information is stored on separate optical storage media than the image and audio signals.<br>
30.	The apparatus as claimed in claim 26, wherein the optical storage media comprises at least one DVD disk.<br>
31.	The apparatus as claimed in 1, wherein the storage media comprises at least one magnetic storage medium.<br>
32.	The apparatus as claimed in claim 31, wherein the storage media comprises multiple magnetic storage media, and wherein the image and audio signals are stored non-sequentially on the multiple magnetic storage media.<br>
33.	The apparatus as claimed in claim 31, wherein the audio signals are stored on separate magnetic storage media than the encoded image signals.<br>
34.	The apparatus as claimed in claim 31, comprising encoded signals representing promotional information, wherein the encoded signals representing promotional information is stored on a separate magnetic storage media than the encoded image or audio signals or the encoded at least one audio program.<br>
35.	The apparatus as claimed in claim 31, wherein the magnetic storage media comprises at least one removable hard drive.<br><br>
36.	The apparatus as claimed in claim 31, wherein the magnetic storage media comprise at least one just a bunch of drives (JBOD) module, wherein the JBOD module comprises at least one storage component.<br>
37.	The apparatus as claimed in claim 1, comprising a buffer to synchronize the playback of the image program and the selected audio program.<br>
38.	The apparatus as claimed in claim 1, wherein the storage device comprises means for using identifier information to link different preselected portions of encoded image signals or encoded at least one audio program to different ones of the storage mediums.<br>
39.	The apparatus as claimed in claim 1, wherein the storage device comprises means for providing parallel striping information such that image signals or the audio signals may be accessed at a desired data transfer rate and to provide error protection redundancy.<br>
40.	The apparatus as claimed in claim 1, wherein at least two of the storage device, the decryptors, and the decompressors are interconnected by at least one local area network interface.<br>
41.	The apparatus as claimed in claim 40, wherein the network interface comprises an Ethernet network.<br>
42.	The apparatus as claimed in claim 1, wherein the encoded image signals are provided in the form of at least one image program, wherein the image program is in the form of either a single still frame or series of frames shown as motion pictures of varying length.<br><br>
43.	The apparatus as claimed in claim 1, wherein the encoded image and audio signals stored on the storage media are copied onto second storage media, such that multiple presentation of the image program and the selected audio program is facilitated.<br>
44.	The apparatus as claimed in claim 43, wherein updates to the encoded image signals    and    audio    signals    are    stored    onto   the    second    storage    media.<br>
45.	The apparatus as claimed in claim 44, wherein the second storage media is an internal hard drive.<br>
46.	The apparatus as claimed in claim 1, comprising means for archiving and maintaining a history of the playback of the image program and the selected audio program.<br>
47.	The apparatus as claimed in claim 1, wherein the encoded signals comprise encoded signals representing a cue track, wherein the cue track indicates a specific portion of a program where information may be linked.<br>
48.	The apparatus as claimed in claim 1 comprising a player, wherein the player is configured to distribute the encoded signals at preselected programmable offsets in time relative to each other.<br>
49.	The apparatus as claimed in claim 48, wherein the preselected programmable offsets are substantially zero such that the encoded image signals are processed to enable muhiple displays of the image at substantially the same time.<br>
50.	The apparatus as claimed in claim 1, comprising a projector configured to enable display of the image represented by the image signals.<br><br>
51.	The apparatus as claimed in claim 1, comprising an audio player configured to play the selected audio program in synchronization with display of the image program.<br>
52.	A method in which encoded image and audio signals representing an image program and a plurality of audio programs associated with the image program in compressed and encrypted form on at least one storage medium are processed to enable display of the image program, the method comprising: retrieving compressed encrypted encoded image and audio signals in portions from a plurality of storage media; wherein the portions comprise redundant information associated with the compressed encrypted image signal; recombining the respective portions of the compressed encrypted encoded image and audio signals; decrypting the compressed encrypted encoded image and audio signals to produce compressed encoded image and audio signals; decompressing the compressed encoded image and audio signals; and displaying the image program in synchronization with a selected one of the associated plurality of audio programs.<br>
53.	The method as claimed in claim 52, wherein said decrypting and decompressing the image and audio signals occur in a noncontiguous manner independent of each other.<br>
54.	The method as claimed in claim 52, wherein said decompressing uses an inverse adaptive block sized discrete cosine transform compression technique.<br>
55.	The method as claimed in claim 52, wherein said decompressing occurs at a variable rate.<br>
56.	The method as claimed in claim 52, comprising: grouping the encoded image<br>
signals to form at least one image program; and linking one or more audio programs<br>
with the at least one image program.<br><br>
57.	The method as claimed in claim 52, wherein the image and audio signals are stored on the storage media as data packets, and wherein said decompressing comprises extracting the image and audio signals from the data packets.<br>
58.	The method as claimed in claim 52, comprising retrieving a specific key, and wherein said decrypting occurs under conditions determined by the specific key.<br>
59.	The method as claimed in claim 58, wherein the specific key is stored on a key storage medium separate from the image encoded signals or the audio program.<br>
60.	The method as claimed in claim 59, wherein the key storage medium comprises a smart card.<br>
61.	The method as claimed in claim 59, wherein the key storage medium comprises a magnetic storage medium.<br>
62.	The method as claimed in claim 59, wherein the key storage medium comprises an optical storage medium.<br>
63.	The method as claimed in claim 58, wherein the specific key is transmitted.<br>
64.	The method as claimed in claim 58, comprising indicating a time interval over which the specific key is valid and for assuring that the specific key is used only during that time interval.<br>
65.	The method as claimed in claim 64, comprising overwriting the specific key from the key storage medium after the time interval expires.<br><br>
66.	The method as claimed in claim 52, comprising providing at least one watermark, wherein the watermark is perceptually unnoticeable during presentation of the image program or the audio program at a predefined normal rate of transfer, but is detectable when the image program or audio program is presented at a rate substantially different from the normal rate.<br>
67.	The method as claimed in claim 66, wherein the watermark identifies presentation time and location information associated with the decompressed image program or the audio program after said decompressing.<br>
68.	The method as claimed in claim 52, comprising providing a theater manager, wherein the theater manager sends and receives status and control information regarding said storing, decrypting and decompressing.<br>
69.	The method as claimed in claim 65, comprising establishing a link to send and receive information.<br>
70.	The method as claimed in claim 69, wherein the information comprises status and control information.<br>
71.	The method as claimed in claim 69, wherein the information comprises updates to the encoded image program and/or the audio programs.<br>
72.	The method as claimed in claim 69, wherein the link comprises a dedicated telephone data link.<br>
73.	The method as claimed in claim 69, wherein the link comprises a dialup telephone data link.<br><br>
74.	The method as claimed in claim 69, wherein the link comprises a packet type data link.<br>
75.	The method as claimed in claim 69, wherein the link comprises an Internet based link.<br>
76.	The method as claimed in claim 69, wherein the link comprises a wireless data link.<br>
77.	The method as claimed in claim 69, wherein the link comprises a satellite based data link.<br>
78.	The method as claimed in claim 53, wherein the storage media comprises at least one magnetic storage medium.<br>
79.	The method as claimed in claim 78, wherein the storage media comprises multiple magnetic storage media, and wherein image and audio signals are stored non-sequentially on the multiple magnetic storage media.<br>
80.	The method as claimed in claim 78, wherein the audio signals are stored on separate magnetic storage media than the encoded image signals.<br>
81.	The method as claimed in claim 78, comprising retrieving encoded signals representing promotional information, and wherein the encoded signals representing promotional information is stored on separate magnetic storage media than the encoded image signals or the audio signals.<br>
82.	The method as claimed in claim 78, wherein the storage media comprises at least one DVD disk.<br><br>
83.	The method as claimed in claim 78, wherein the storage media comprises at least one removable hard drive.<br>
84.	The method as claimed in claim 78, wherein the storage media comprise at least one just a bunch of drives (JBOD) module.<br>
85.	The method as claimed in claim 78, comprising buffering the image and audio signals to synchronize the image program and the selected audio program during playback.<br>
86.	The method as claimed in claim 52, comprising linking different preselected portions of encoded image signals or the audio signals to different ones of the storage mediums.<br>
87.	The method as claimed in claim 52, comprising providing parallel striping information such that encoded image signals or the audio signals may be accessed at a desired    data    transfer    rate    and   to   provide    error   protection    redundancy.<br>
88.	The method as claimed in claim 52, comprising providing at least one local area network interface.<br>
89.	The method as claimed in claim 88, wherein the network mterface comprises an Ethernet network.<br>
90.	The method as claimed in claim 88, wherein the encoded image signals are provided in the form of at least one image program, wherein the image program is in the form of either a single still frame or series of frames shown as motion pictures of varying length.<br><br>
91.	The method as claimed in claim 52, comprising copying the encoded image and audio signals onto second storage media such that multiple presentations of the encoded image program and the selected audio program is facilitated.<br>
92.	The method as claimed in claim 91, comprising storing updates to the encoded image and audio signals onto the second storage media.<br>
93.	The method as claimed in claim 52, comprising archiving and maintaining a history of the playback of the encoded image program and the selected audio programs.<br>
94.	The method as claimed in claim 52, comprising indicating a specific portion of the encoded image and audio signals where information may be linked.<br>
95.	The method as claimed in 52, comprising displaying the image program.<br>
96.	The method of Claim 52, comprising distributing the signals at preselected programmable offsets in time relative to each other.<br>
97.	The method as claimed in claim 96, wherein the preselected programmable offsets are substantially zero such that the encoded image signals are processed to enable multiple displays of the image program at substantially the same time.<br>
98.	The method as claimed in claim 95, comprising playing the selected audio program in synchronization with display of the image program.<br>
99.	An apparatus in which encoded image and audio signals representing an image program and a plurality of audio programs associated with the image program in compressed and encrypted form on at least one storage medium are processed to<br><br>
enable display of the image program, the apparatus comprising: means for retrieving compressed encrypted encoded image and audio signals in portions from a plurality of storage media, wherein the portions comprise redundant information associated with the compressed encrypted image signal; means for recombining the respective portions of the compressed encrypted encoded image and audio signals; means for receiving the compressed encrypted encoded image and audio signals from the decryptor and to decompress the compress encoded image and audio signals; and means for receiving the compressed encoded image and audio signals; and means for displaying the image program in synchronization with a selected one of the associated plurality of audio programs.<br>
100.	The apparatus as claimed in claim 99, wherein the means for decompressing<br>
uses an inverse adaptive block sized discrete cosine transform compression technique.<br>
101.	The apparatus as claimed in claim 99, wherein the means for decompressing is<br>
configured to decompress the compressed encoded audio program at a variable rate.<br>
102.	The apparatus as claimed in claim 99, wherein the image and audio signals are<br>
conveyed onto the storage media as data packets, wherein the means for<br>
decompressing comprises means for depacketizing the encoded image and audio<br>
signals from the data packets.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgYWJzdHJhY3QgZHVwbGljYXRlLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che abstract duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgYXNzaWdubWVudC5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgY2xhaW1zIGR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che claims duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgY29ycmVzcG9uZGVuY2Ugb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgY29ycmVzcG9uZGVuY2UgcG8ucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che correspondence po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZGVzY3JpcHRpb24gKGNvbXBsZXRlKSBkdXBsaWNhdGUucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che description (complete) duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZm9ybS0xOS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che form-19.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZm9ybS0yNi5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgcGN0IHNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che pct search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgcGN0LnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che pct.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDgxNy1jaGUgcGV0aXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-0817-che petition.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="224625-a-process-for-preparing-trione-bis-oxime-ether-derivatives-and-a-ketal.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="224627-a-transmission-method-in-a-communications-system.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>224626</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>IN/PCT/2002/817/CHE</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>49/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>05-Dec-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>21-Oct-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>31-May-2002</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>QUALCOMM INCORPORATED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>5775 Morehouse Drive, San Diego, California 92121-1714,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>FAUS, Juan</td>
											<td>9545 Laurentian Drive, San Diego, California 92129,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>RATZEL, John</td>
											<td>12823 Pimpernel Way, San Diego, California 92129,</td>
										</tr>
										<tr>
											<td>3</td>
											<td>MORLEY, Steven, A</td>
											<td>540 Lost Oak Lane, Escondido, California 92025,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/167</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US00/32686</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2000-11-30</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/168,605</td>
									<td>1999-12-02</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>09/563,880</td>
									<td>2000-05-03</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/224626-apparatus-and-method-for-decoding-digital-image-and-audio-signals by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:34:47 GMT -->
</html>
