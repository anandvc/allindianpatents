<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/223869-improved-wireless-control-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 04:27:35 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 223869:IMPROVED WIRELESS CONTROL DEVICE.</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">IMPROVED WIRELESS CONTROL DEVICE.</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The present invention relates to a wireless control device (10) including a small, lightweight housing (22) worn by an operator (20). for example on the operator&#x27;s wrist, and a controlled device (24). for example a personal computer. Several optical emitters (32). preferably light emitting diodes operating in the infrared range, and several optical detectors (36) are provided on the housing. At least one x-axis emitter-detector pair operates to detect an x-direction of a pointing motion or gesture, and at least one y-axis emitter-detector pair operates to detect a y-dircction of a pointing motion or gesture. This motion can then be used to cause a response in the controlled device (24). For example, angles of the operator&#x27;s hand at the wrist can be interpreted to induce motion of a cursor on a computer display. The device may also include a motion sensor (40), an environmental condition sensor (42). or a voice recognition sensor (43), and can also be adapted for gesture recognition and image scanning applications.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>IMPROVED WIRELESS CONTROL DEVICE<br>
CROSS-REFERENCE TO RELATED APPLICATIONS<br>
This application is related to U.S. Patent Application Serial No.<br>
09/035,983, filed March 6,1998, now U.S. Patent No. 6,097,374, claiming<br>
priority of U.S. Provisional Patent Application Serial No. 60/040,502, and U.S.<br>
Patent Application Serial No. 09/689,659, filed October 13,2000, claiming<br>
priority of U.S. Provisional Patent Application Serial No. 60/159,611, all of<br>
which are hereby fully incorporated by reference.<br>
DESCRIPTION<br>
BACKGROUND OF THE INVENTION<br>
Field of the Invention<br>
The present invention generally relates to portable selective data<br>
capture and selective control devices providing an interface between a user and<br>
a controlled device and, more particularly, to arrangements for providing data<br>
or control input to devices such as a data processor, musical instrument,<br>
communication device or the like while allowing freedom of movement and<br>
minimal interference with other activities for a user.<br>
Background Description<br>
Most mechanical and electrical devices capable of multiple functions<br>
require and provide for user control for selection between those functions and<br>
initiation and termination of the function selected. In general, multiple buttons in<br>
the nature of a keypad or keyboard of arbitrary extent has been the<br>
arrangement of choice for communicating user selection and/or control to the<br>
device. In recent years, other arrangements such as pointing devices and voice-<br>
responsive systems have come into relatively widespread use. Further, some<br>
systems have provided for control and/or selection to be provided by collected<br>
data such as physiological information concerning the user. For example, eye<br>
movement or nervous system activity (e.g. EEG, EKG, blood pressure, electro-<br>
neural muscle activity and the like) can be monitored to develop signals which<br>
can be used in the same manner as key strokes for selection or control.<br>
However, alternative input arrangements have generally been implemented as<br>
stand-alone systems which are useable alone or as a supplement to keyboards<br>
in a mutually exclusive fashion.<br>
However, keyboards are not generally well-adapted for long periods of<br>
operation by a human user and alternative arrangements such as those alluded<br>
to above generally involve some degree of inconvenience, slow response,<br>
substantial user training and accommodation and/or significant data processing<br>
resources. So-called ergonomic design features provide only marginal<br>
improvements in accommodating human use. Moreover, while some portable<br>
or wearable devices are known, they are generally dedicated to a single type of<br>
input to a single apparatus, such as the separate keyboard and mouse or other<br>
pointing arrangement of a personal computer. For example, an arrangement is<br>
known in which a rolling member such as is used in a mouse is mounted on the<br>
underside of a keyboard and pointing controlled by sliding the entire keyboard<br>
along a surface, compromising convenience of both pointing and data entry<br>
functions.<br>
A notable exception is disclosed in the above-incorporated U. S. Patent<br>
6,097,374 grained to the inventor of the present invention. As disclosed<br>
therein, a small and lightweight housing is preferably worn on the wrist and<br>
includes a plurality of directional light-emitting devices. The housing supports a<br>
substantially linear array of directional light receptors extending generally parallel<br>
to the direction of light emission and receives light substantially orthogonal<br>
thereto; thus providing a matrix of locations which can be monitored and<br>
distinguished from each other when a finger or other appendage is moved to<br>
any location in the matrix defined by the directional light emitters and receptors.<br>
This arrangement also includes motion sensors in at least two directions<br>
for controlling a pointing device in response to hand motion (e.g. orientation,<br>
velocity and the like) for controlling a pointing arrangement or providing other<br>
input parameters such as volume or tempo to a musical instrument digital<br>
interface (MIDI) and, if desired, a microphone and associated circuitry for<br>
receiving voice or other audible signal input. All information developed by these<br>
arrangements is communicated to another device or base station such as a<br>
personal computer or musical instrument by a modulated light or radio wave<br>
communication link much in the nature of a remote control arrangement for a<br>
television or other appliance.<br>
However, even this related device, like other existing devices, is<br>
inherently limited in its capabilities. For example, the use of motion sensors<br>
such as accelerometers or gyroscopes to track hand motion in a pointing<br>
application requires broad, exaggerated hand motions in order to control the<br>
cursor. Consequently, the hand must be supported by the arm to facilitate the<br>
range of motion required for the pointing application. This can become<br>
extremely uncomfortable and tiring to the user. Furthermore, it does not<br>
provide the fine sense of cursor control that one would attain by using a<br>
conventional computer mouse. Additionally, existing devices are generally<br>
limited to character-level data entry, and this data entry is extremely sensitive to<br>
hand orientation. This further restricts the usefulness of existing devices.<br>
SUMMARY OF THE INVENTION<br>
It is therefore an object of the present invention to provide<br>
enhancements for the invention disclosed and claimed in the above-<br>
incorporated U.S. Patent No. 6,097,379 in structure, information capture,<br>
function, and adaptability to a greatly increased variety of applications.<br>
It is another object of the invention to provide the function of. the<br>
invention of U.S. Patent No. 6,097,379 and additional functions with increased<br>
accommodation of other activities of a user.<br>
It is still another object of the present invention to provide a wireless<br>
control device that will allow the user to comfortably and precisely control a<br>
pointing application.<br>
A further object of the present invention is to provide a wireless control<br>
device capable of detecting and interpreting gestures performed by the user.<br>
Yet another object of the present invention is to provide a wireless<br>
control device capable of receiving input independent of the position of the user<br>
or of a part of the user's body.<br>
Yet another object of the present invention is to provide an input device<br>
capable of intrinsically sterile and safe operation.<br>
Still another object of the present invention is to provide an input device<br>
capable of detecting additional degrees of freedom and corresponding<br>
additional types of input information.<br>
In order to accomplish these and other objects of the invention, there is<br>
provided a small, lightweight housing worn by an operator and a controlled<br>
device, for example a personal computer. Several optical emitters, preferably<br>
light emitting diodes operating in the infrared range, and several optical<br>
detectors are provided on the housing. The emitters and detectors can be<br>
provided in a single plane for go/no-go operation of the device. Alternatively,<br>
the emitters and detectors can be disposed in two planes on the housing so that<br>
the device can resolve hand position and orientation instead of only key<br>
closures and motion or orientation of the device. At least one x-axis emitter-<br>
detector pair operates to detect an x-direction of a pointing motion or gesture,<br>
and at least one y-axis emitter-detector pair operates to detect a y-direction of<br>
a pointing motion or gesture. In the preferred embodiment of the invention, the<br>
housing is worn on the operator's wrist and the emitter-detector pairs detect the<br>
angle of the operator's hand at the wrist. This motion can then be used to cause<br>
a response in the controlled device. For example, the pointing motion or<br>
gesture can correspond to the movement of a cursor on a computer display as if<br>
the operator were using a conventional computer mouse. This optical pointing<br>
embodiment can operate in either a joystick-like fashion or a mouse-like<br>
pointing stroke fashion. The housing may also optionally include a motion<br>
detector, such as an accelerometer or gyroscope, an environmental condition<br>
sensor, or a voice recognition sensor.<br>
The present invention can also be used for gesture recognition, for<br>
example by combining time domain analysis of hand positions and orientations<br>
with image recognition capabilities. Hand motions can be resolved into a series<br>
of hand images over time, which can then be correlated with a pre-programmed<br>
library of gestures, such as gestures stored as images in a content-addressable<br>
memory functioning as a lookup table. Gesture recognition allows the present<br>
invention to be used not only for character-level data entry, but also for word-<br>
and phrase-level data entry. Furthermore, the gesture recognition can be made<br>
context sensitive so that the same gesture performed in different contexts leads<br>
to a different response by the same controlled device, or even to a response in<br>
an entirely different controlled device. Gesture recognition capabilities can also<br>
be used to implement a demand mode whereby the device can be switched on<br>
and off as the user desires.<br>
It is also contemplated to employ the present invention to scan images in<br>
two or three dimensions. This overscanning feature can be used to cause the<br>
device to learn and adapt to the particular physiological geometries of the user<br>
rather than requiring the user to adapt to the device's physical characteristics. It<br>
can also be used to scan objects of interest other than parts of the user's body<br>
for real-time or archival use.<br>
Since the device allows data entry and cursor control without any<br>
contact with a physical device, the present invention is well suited to use in<br>
sterile environments. Furthermore, the absence of mechanical interaction<br>
eliminates the possibility of sparking and makes the present invention suitable<br>
for use in combustible environments. Additionally, the device avoids the<br>
development of certain medical conditions, such as carpal tunnel syndrome or<br>
repetitive stress injuries, and can be adapted for use by those with various<br>
physical handicaps.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The foregoing and other objects, aspects and advantages will be better<br>
understood from the following detailed description of preferred embodiments of<br>
the invention with reference to the drawings, in which:<br>
Figure 1 is an illustrative application of the invention.<br>
Figure 2 illustrates some principal elements of the invention.<br>
Figure 3 illustrates the embodiment of the invention used for optical<br>
pointing.<br>
Figure 4 illustrates the use of the invention for gesture recognition.<br>
Figure 5 illustrates the tracking optics embodiment of the invention.<br>
DETAILED DESCRIPTION OF PREFERRED<br>
EMBODIMENTS OF THE INVENTION<br>
Referring now to the drawings, and more particularly to Figures and<br>
2, there is shown an exemplary and generalized application of the improved<br>
wireless control device 10. An operator 20 wears a small, lightweight housing<br>
22 on at least one wrist or other convenient location on the body. The wrist is<br>
preferred as being proximate to the fingers which would ordinarily be used to<br>
operate a keyboard. However the invention may be adapted freely in<br>
accordance with its basic principles of operation as desired to accommodate<br>
the operator as a manner of convenience, physical handicap, or the like. A<br>
controlled device 24 is provided and includes a sensor 26 for light or any other<br>
form of energy suitable for transmission of a coded signal. Controlled device<br>
24, hereinafter referred to as a base station for generality, preferably also<br>
includes a transducer 28, such as a display or an audio annunciator such as a<br>
beeper or speech synthesizer, to confirm receipt of a coded signal 30 and<br>
recognition of its content. Alternatively, annunciation could be in housing 22<br>
and could respond to a light signal from base unit 24 (e.g. housing 22 could emit<br>
a beep when a signal is received).<br>
As shown generally in Figure 2 and explained in greater detail in the<br>
above-referenced related patents and applications, light emitters 32 on housing<br>
22, which are preferably light emitting diodes ("LEDs") operating in the infrared<br>
range, project well-defined beams of energy 34 over a limited solid angle<br>
generally parallel to the palm of the operator's hand. The solid angle of the<br>
beams is preferably limited such that the illuminated regions will not overlap at a<br>
distance from housing 22 that is closer than the fingertips of the operator. Thus,<br>
movement of the operator's hand, such as movement of a finger in a motion<br>
similar to pressing a key on a keyboard, will cause the tip of the operator's<br>
finger to be illuminated by a beam 34. This illumination is reflected 34a from the<br>
operator's fingertip and detected by a detector 36, also on housing 22. Thus,<br>
by correlation of reflected beams of light 34a with emitted beams of light 34, the<br>
placement of any finger or other object can be not only detected but also<br>
differentiated from any other location, and an appropriate coded signal 30 can<br>
be sent from housing 22 to base station 24. Coded signal 30 can be sent by<br>
one of light emitters 32 or by a separate signal emitter 38.<br>
While it is preferred, for simplicity, to energize light emitters 32 in<br>
succession in a time-multiplexed fashion, it will be recognized by one skilled in<br>
the art that reflected beams 34a can be distinguished by other expedients such<br>
as frequency modulation or pulse width coding, Depending upon the intended<br>
use of device 10, housing 22 may optionally include a motion sensor 40, such as<br>
an accelerometer or gyroscope, for detecting motion of a body part of operator<br>
20 in space, and an environmental condition sensor 42. Environmental<br>
condition sensor 42 can be adapted to measure any number of environmental or<br>
physiological conditions, including, but not limited to, blood pressure, humidity,<br>
temperature, and air pressure, as required by particular applications of device<br>
10. A voice recognition sensor 43 may also be provided.<br>
Figure 3 illustrates an embodiment of device 10 adapted for optical<br>
pointing, such as for movement of a cursor on a computer screen, much like the<br>
manner of the mouse familiar to personal computer users (that is, based on the<br>
angle of the hand at the wrist). However, one skilled in the art will appreciate<br>
that the optical pointing applications of the present invention are not limited to<br>
cursor pointing. At least one x-axis emitter-detector pair 44 and at least one y-<br>
axis emitter-detector pair 46 are provided on housing 22. The emitter in x-axis<br>
emitter-detector pair 44 is oriented to illuminate the knife edge of the hand (that<br>
is, the edge of the hand opposite the pinky finger) in fan shaped x-axis beam 48.<br>
Similarly, the emitter in y-axis emitter-detector pair 46 is oriented so as to<br>
illuminate the heel of the hand in fan shaped y-axis beam 50. The use of fan<br>
shaped beams 48 and 50 reduces the effects of perpendicular motion of the<br>
hand surface on the measurement of wrist angles as described below. This<br>
illumination is reflected from the hand and back towards the detectors of<br>
emitter-detector pairs 44 and 46: light reflected off the knife edge of the hand is<br>
detected by the detector in x-axis pair 44, while light reflected by the heel of the<br>
hand is detected by the detector in y-axis pair 46. Device 10 then interprets the<br>
magnitude of reflected beams 48 and 50 as a particular hand position in the<br>
above-described fashion, and can initiate corresponding cursor movement<br>
accordingly.<br>
The angle of the hand at the wrist determines the magnitude of the<br>
reflection of beams 48 and SO detected by the detectors of pairs 44 and 46,<br>
respectively, and the magnitude detected in turn determines the direction and<br>
duration of the responsive cursor motion. For example, when operator 20<br>
angles his hand outward at the wrist (that is, in the direction of arrow a,<br>
decreasing the angle between the pinky finger and the forearm), the magnitude<br>
of the reflection detected by x-axis pair 44 increases, and a corresponding<br>
motion of the cursor in the x-direction occurs. Similarly, when operator 20<br>
angles his hand upward at the wrist (that is, into the plane of the paper in the<br>
direction of arrow b, decreasing the angle between the back of the hand and the<br>
forearm), the magnitude of the reflection detected by y-axis pair 46 decreases,<br>
causing a corresponding movement of the cursor in the y-direction.<br>
A variety of methods can be employed to eliminate unintentional<br>
movement of the cursor while device 10 is in use. For example, the magnitude<br>
of the reflected beams 48 and SO is time-averaged in order to reduce<br>
background noise such as inadvertent, minor movements of the hand.<br>
Additionally, a threshold can be set in the x-, y-, and z-directions, below which<br>
no motion is passed to the cursor, further reducing the likelihood that the cursor<br>
will respond to minor movements of the hand. Audio or voice actuation, or a<br>
particular arm movement (e.g. as if reaching for a mouse) could be employed<br>
alternatively or in combination to employ the demand mode discussed below.<br>
Proper responses to particular movements or gestures can be developed by<br>
using any adaptive arrangement as will be familiar to one skilled in the art.<br>
Correlation techniques are used to yield consistent results while<br>
measuring amplitude while rejecting ambient interference and system noise. For<br>
example, susceptibility to harmonic interference, such as flourescent lamps, can<br>
be reduced, for example, by using a pseudo-random sequence to drive the<br>
active LED emitter being scanned and to decode the magnitude of the reflected<br>
light, determining the average "on" amplitude versus the average "off'<br>
amplitude.<br>
By utilizing optical emitter-detector pairs 44 and 46 to detect movement<br>
of the hand instead of accelerometers or gyroscopes to detect arm motion, the<br>
present invention achieves many advantages over existing devices. For<br>
example, broad, exaggerated hand movements are no longer necessary to<br>
induce cursor motion on the computer screen, as optical pointing gives the user<br>
a finer sense of control by making cursor motion sensitive to the angle of the<br>
hand at the wrist. Accordingly, the present invention can be utilized with the<br>
forearm in a resting position rather than being used to support the hand in space.<br>
This is not only less fatiguing and more convenient for the user, but also gives<br>
the user much more precise control over the cursor, as would be the case with<br>
a conventional computer mouse, while allowing motion sensors, if included, to<br>
provide additional input data for any desired purpose. Precision is further<br>
enhanced by the fact that optical emitter-detector pairs 44 and 46 are not<br>
sensitive to the Earth's gravity, and consequently elevation, as acceleroraeters<br>
and gyroscopes are. Furthermore, the optical pointing embodiment of the<br>
present invention is significantly less expensive than existing devices utilizing<br>
accelerometers or gyroscopes. However, one skilled in the art will recognize<br>
that, in those applications where it is desirable to track whole-hand motion<br>
rather than just the angle of the hand at the wrist, accelerometers or gyroscopes<br>
can be used in conjunction with the optical pointing embodiment of the current<br>
invention to achieve even greater versatility as alluded to above.<br>
As described above, the optical pointing embodiment of the present<br>
invention operates in a joystick-like mode. That is, the hand has a home<br>
position, and deviation from the home position in the x- or y-directior. starts a<br>
corresponding motion of the cursor that will not cease until the hand is returned<br>
to the home position. While the hand does have a naturally comfortable home<br>
position, this joystick-like optical pointing method is inherently demanding on<br>
the user, as it requires accurate timing and precise actions to ensure that the<br>
mouse cursor comes to rest at the desired point on the computer screen.<br>
Accordingly, the present invention can also be adapted to operate in a<br>
mouse-like fashion by generating pointing strokes. Pointing stroke operation<br>
converts the motion vectors generated by deflection from any random rest<br>
position of the hand to any desired ending position of the hand into a stroke of<br>
cursor motion on the computer screen. ,For example, assume that the user's<br>
hand is in the position shown in Figure 2, which may or may not correspond to<br>
the home position described above, at a time t1. Further suppose that the user<br>
then deflects his hand in the direction of arrow a into a different position at time<br>
t2. Device 10 resolves the respective magnitudes of reflected beam 48 at times<br>
t1, and t2 into hand positions at times t1, and t2 as described above, and then into<br>
a motion vector for the hand from time t1, to time t2. The motion vector is then<br>
resolved into a corresponding stroke of motion that decays to zero at the ending<br>
position rather than continuing until the hand is returned to the home position,<br>
and causes a cursor motion on the computer screen that mimics the hand motion<br>
from time t1, to time t2, as though a finger or stylus in the hand were directing the<br>
motion of the cursor on the screen. That is, the cursor will move in the direction<br>
corresponding to the direction of hand deflection by an amount corresponding<br>
to the amount of hand deflection and will then stop. Once calibrated to an<br>
individual user, pointing stroke operation offers an even more direct and<br>
comfortable sense of control over cursor motion.<br>
Pointing stroke operation can be made even more practical with the<br>
"demand mode" described below. For example, while the joystick-like pointing<br>
mode described above allows for unlimited movement of the cursor in any<br>
direction by simply holding one's hand in a deflected position, one skilled in the<br>
art will recognize that pointing stroke operation is limited to the range af motion<br>
of the user's hand. Demand mode will allow the user to generate a pointing<br>
stroke in a particular direction, switch optical pointing off, return his hand to a<br>
more comfortable or neutral position, switch optical pointing back on, and<br>
generate a second stroke in the same direction. This is analogous to lifting a<br>
computer mouse from its rolling surface to re-center it in a more comfortable or<br>
useful position to effectively increase the size of the rolling surface.<br>
The present invention can also be used for gesture recognition by<br>
combining time domain analysis of hand and finger positions and orientations<br>
with image recognition capabilities. The method by which device 10 recognizes<br>
gestures is substantially similar to the method described above for mouse-like<br>
pointing stroke operation. For example, suppose that the user's fingers are in<br>
the position illustrated by Figure 4 at time t1. Emitter 32 emits beam 34, which<br>
is reflected by a Fingertip 52. Detector 36 then detects reflected beam 34a and,<br>
in the manner described above, device 10 determines the position and<br>
orientation of the finger at time t1. Suppose that the user then deflects his finger<br>
downwards in the direction of arrow c so that fingertip 52 is in a new location at<br>
time t2. Once again using the method described above, device 10 resolves the<br>
position and orientation of the finger at time t2. The user may then return his<br>
finger to the original position and orientation or move it into an entirely new<br>
position and orientation at time t3 for device 10 to resolve, and so on.<br>
These resolutions of finger position and orientation over time are then<br>
compiled and correlated with a pre-programmed library of gesture images such<br>
as those stored in a content-addressable memory functioning as a lookup table,<br>
and device 10 is able to recognize the gesture madeâ€”in the above example, a<br>
"finger-wagging" gesture. The pre-programmed library of gestures may include<br>
standardized gestures (e.g. American Sign Language gestures) as well as user-<br>
specific gestures captured and recorded during a machine-training phase (e.g.<br>
the finger-wagging described above). Gestures captured and recorded during a<br>
machine-training phase will inherently be programmed to the user's specific<br>
hand size, shape, and motion sets.<br>
Gesture recognition capabilities can be made even more powerful by<br>
coupling the resolution of hand positions and orientations as described above<br>
with the resolution of hand motion. Hand motion can be resolved by using the<br>
optical pointing embodiment described above, or, where tracking of whole-<br>
hand motion is desired, by including gyroscopes, accelerometers, or other<br>
motion sensors 40 or environmental sensors 42 in device 10. By combining<br>
time-domain analysis of hand positions and orientations with time-domain<br>
analysis of hand motion, numerous image recognition processes are available for<br>
application in decoding gestures.<br>
The gesture recognition method described above allows the present<br>
invention to be used not only for character-level entry of data (such as<br>
keyboard typing or telephone dialing), but also for word- and phrase-level entry<br>
of data (such as that employed by American Sign Language). For example, the<br>
gesture recognition embodiment of the present invention can be used to<br>
transcribe or annunciate, in real time, American Sign Language communications.<br>
Furthermore, inflection may be added to the transcription or annunciation of<br>
gestures based on the height above the ground at which the gesture is<br>
performed: a lower position could signify a lower inflection tone, while a higher<br>
position indicates greater emphasis or higher inflection.<br>
Gesture recognition methods may also be made context-sensitive so<br>
that the same gesture may have many different effects depending upon the<br>
context in which it is performed. For example, the finger-wagging gesture<br>
described above could be used to answer a ringing telephone in one context<br>
and toggle a light switch in another context. As another example, raising or<br>
lowering one's arm may control radio volume in one context and ambient<br>
lighting brightness in another. The user may select between contexts in any<br>
number of ways. For example, where housing 22 includes a voice recognition<br>
sensor 43, the user may speak the desired context (e.g. "radio" when gestures<br>
are intended to control the radio and "lights" when gestures are intended to<br>
control the lights). However, other methods of selecting context are within the<br>
scope of this invention.<br>
Gesture recognition can also be used to implement the demand mode<br>
mentioned above for mouse-like optical pointing. By programming a particular<br>
gesture or gestures to activate and deactivate device 10, the user can turn any<br>
given operational mode, or the entire device, on and off as required or desired.<br>
Demand mode can also be employed to activate and deactivate combination<br>
modes or contexts.<br>
Another feature that can be added to the present invention is the optical<br>
tracking, or "overscanning," feature illustrated in Figure 5. This feature ensures<br>
that a particular digit is always correctly identified by device 10. For example,<br>
optical tracking will ensure that index finger 54 is always recognized as index<br>
finger 54 regardless of hand orientation or position.<br>
Overscanning is accomplished by beginning a scan at one extreme 56 of<br>
the hand's deviation in one direction and terminating the scan at the opposite<br>
extreme position 58. Overscanning may be done with many discrete emitters<br>
32 and detectors 36, or by raster scanning. Where many discrete emitters 32<br>
and detectors 36 are utilized, overscanning is accomplished by employing more<br>
emitters 32 and detectors 36 than necessary to resolve individual fingers or by<br>
beginning and ending a continuously scanned source outside the rest-position<br>
extremes 56 and 58 of the hand's perimeter. Overscanning may also be<br>
implemented by incorporating a physically movable optical member, such as a<br>
rotating or pivoting mirror, or electrically steerable optical member into housing<br>
22. In this latter embodiment, emitter 32 and detector 36 move in tandem to<br>
scan the region, allowing a single electronic receiver circuit to scan the desired<br>
region. It will be apparent to one skilled in the art that the above methods can<br>
easily be extended into the third dimension for full active imaging.<br>
Once the overscan is complete, the optical pointing vector generated by<br>
tracking the hand's angle relative to the wrist as described above and illustrated<br>
in Figure 3 is used to calculate the hand's offset within the scanned region.<br>
Device 10 can thereby determine which finger has been moved into the path of<br>
an emitted beam of light. Since this feature allows the present invention to learn<br>
the user's hand geometry rather than requiring the user to accommodate to the<br>
invention's characteristics, user interaction with device 10 is greatly simplified.<br>
For example, the optical tracking feature allows device 10 to be used<br>
simultaneously for both mouse control and keyboard typing, whereas the<br>
keyboard typing features of a device without the optical tracking feature would<br>
easily become "confused" when the hand was deflected to move the mouse<br>
cursor.<br>
Three dimensional scans of the user's hand may also provide input<br>
images for gesture recognition as described above. Alternatively, directing the<br>
emitters 32 and detectors 36 towards an arbitrary nearby surface instead of the<br>
user's hand can be used to provide real-time imaging of an object of interest<br>
other than the user's hand. For example, device 10 can be used to actively<br>
capture images of objects for interpretation by system software or, by<br>
employing optical character recognition, to read and annunciate text in order to<br>
assist visually impaired users. As another example, a doctor could direct the<br>
emitters 32 to capture an image of a patient during an operation for real time or<br>
archival use, enter notes into a computerized log using device 10, and continue<br>
with the operation without re-scrubbing as would be required if a camera were<br>
used or physical keys were struck.<br>
Housing 22 may also include a second plane of emitters 32 and<br>
detectors 36 in order to resolve hand position in two dimensions. The first<br>
dimension is resolved as the finger passes through the first plane of emitters 32<br>
and detectors 36, while the second dimension is resolved once the finger passes<br>
entirely through the first plane and into the second. This enhances the go/no-go<br>
nature of existing wearable computer devices to allow for resolution of hand<br>
position and orientation instead of merely detecting key closures. Alternatively,<br>
device 10 could illuminate each finger from several different angles and use<br>
parallax to resolve hand position in two dimensions, though the former method<br>
is preferred to the latter.<br>
The present invention is capable of intrinsically safe and sterile<br>
operation. As described above, the present invention allows data entry and<br>
cursor control without any contact with a physical device. Accordingly, device<br>
10 is well-suited to use in sterile environments, such as operating rooms.<br>
Device 10 can also be used in highly combustible environments because the<br>
absence of mechanical interaction eliminates the possibility of sparking that<br>
could ignite the environment.<br>
As can be seen from the foregoing, the present invention creates a<br>
concert of input information having many degrees of freedom at any instant and<br>
which can be sampled over time. The present invention thereby provides a<br>
sense of control that is presently unavailable. For example, the device is<br>
capable of detecting finger position and orientation, individually, in combination,<br>
and relative to each other, such as in turning a knob, the distance between the<br>
operator's fingertip and wrist, the angle of the hand at the wrist in the x- and y-<br>
directions, arm position in the x-, y-, and z-directions, arm pitch, roll, and yaw,<br>
environmental and physiological conditions, voice input, two dimensional image<br>
inputs, such as bar code readings, three dimensional image inputs, and<br>
numerous other types of input. With this many types of input data, only a very<br>
few time-related data sets are necessary to implement the above-described<br>
applications effectively, as additional data makes it easier to distinguish<br>
"signatures" associated with, for example, a particular gesture. Furthermore, by<br>
carefully selecting the data compiled to produce a result, the device may be<br>
used for character-level input, such as a computer keyboard, combinatorial-<br>
level input, such as a stenographic keyboard, word- or phrase-level input, such<br>
as American Sign. Language, joystick control, mouse control, pitch or tone<br>
control, control over environmental settings (e.g. thermostats, dimmer switches,<br>
television or stereo volume controls), and many others.<br>
While the invention has been described in terms of several preferred<br>
embodiments, those skilled in the art will recognize that the invention can be<br>
practiced with modification within the spirit and scope of the appended claims.<br>
WE CLAIM :<br>
1. A wireless control device. comprising :<br>
a base station having a sensor:<br>
a housing worn on a bock of an operator, said housing having a plurality of optical emitters and<br>
a plurality of optical detectors :<br>
at least one optical emitter and at least one optical detector forming at least one x-axis emitter-<br>
detector pair for delecting an x-direction of a pointing motion or gesture :<br>
at least one optical emitter and at least one optical detector forming at leasl one y-axis emitter-<br>
detector pair for detecting a y -direction of a pointing motion or gesture : and.<br>
means for distinguishing between optical beams emitted Iron said plurality of optical emitters<br>
when reflected from a body part of the operator or another object and detected by said optical detectors.<br>
2. The wireless control device as claimed in claim 1. wherein said optical emitters are light<br>
emitting diodes and said optical beams are beams of infrared light.<br>
3. The wireless control device as claimed in claim 1. wherein said x and y-axis emitter-detector<br>
pairs detect motion of the body part adjacent to a body part on which said housing is worn.<br>
4. The wireless control device as claimed in claim 3. wherein said housing is worn on a wrist of<br>
the operator and said x- and y-axis emitter-deleclor pairs pairs detect motion of a hand of the operator.<br>
5. The wireless control device as claimed in claim 4. wherein said emitters in said at least one x-<br>
axis emitter-detector pair illuminate a knife edge of the hand of the operator. said detectors in said at<br>
least one x-axis emitter-detector pair delect beams reflected from the knife edge of the hand of the<br>
operator, said emitters in said at least one y-axis emitter-detector pair illuminate a heel of the hand of<br>
the operator, and said detectors in said at least one y-axis emiller-detector pair detect beams reflected<br>
from the heel of the hand of the operator.<br>
6. The wireless control device as claimed in claim 5. wherein said emitters illuminate the knife<br>
edge and the heel of the hand of the operator in fan shaped beams.<br>
7. The wireless control device as claimed in claim 1. wherein said housing has an environmental<br>
condition sensor.<br>
8. The wireless control device as claimed in claim 1. wherein said housing has a \oice recognition<br>
sensor.<br>
9. The wireless control device as claimed in claim 1. wherein said x- and y-directions of said<br>
pointing motions or gestures correspond to x- and y-axis movement of a cursor on a display.<br>
10. The wireless control device as claimed in claim 1. wherein said x- and y-axis emitter-detector<br>
pairs detect said x- and y-directions of said pointing motion or gesture in a joystick fashion.<br>
11. The wireless control device as claimed in claim 1. comprising means for resolving at least one<br>
of position orientation, and motion of the body part of the operator over time.<br>
12. The wireless control device as claimed in claim 11. wherein said x- and y-axis emitter-detector<br>
pairs delect said x- and y-directions of said pointing motion or gesture in a mouse-like fashion.<br>
13. 1 he wireless control device as claimed in claim 11. wherein said means lor resolving motion of<br>
the body part of the operator over time is an acceleromeler or a gyroscope.<br>
14. The wireless control device as claimed in claim 11. comprising means for recognizing a<br>
plurality of gestures performed by the operator.<br>
15. The wireless control device as claimed in claim 14. wherein said gestures comprise American<br>
Sign Language gestures. Native American Sign Language gestures, or gestures comprising any other<br>
gesture-based method of communication.<br>
16. The wireless control device as claimed in claim 14. wherein said mean-; for recognizing a<br>
plurality of gestures is context-sensitive.<br>
17. The wireless control device as claimed in claim 1. comprising demand means for toggling said<br>
device between an on stale and an off state.<br>
18. The wireless control device as claimed in claim 1. comprising scanning means tor identifying an<br>
object.<br>
19. The wireless control device as claimed in claim 18. wherein the object is the body part of the<br>
operator.<br>
20. The wireless control device as claimed in claim 19. wherein said scanning means starts a scan at<br>
one extreme of motion of the body part of the operator and ends said scan at an opposite extreme of<br>
motion of the body part of the operator.<br>
21. The wireless control device as claimed in claim 18. wherein said scanning means comprises a<br>
physically movable optical member.<br>
22. The wireless control device as claimed in claim 21. wherein said phvsically movable optical<br>
member comprises a rotating or pivoting member.<br>
23. The wireless control device as claimed in claim 21. wherein said physically movable optical<br>
member comprises at least one electrically steerable emitter-detector pair.<br>
24. The wireless control device as claimed in claim 18. wherein said scanning means scans the<br>
object in three dimensions.<br>
25. The wireless control device as claimed in claim 1. wherein said optical emitters and said optical<br>
detectors are disposed on said housing in two planes.<br>
The present invention relates to a wireless control device (10) including a small,<br>
lightweight housing (22) worn by an operator (20). for example on the operator's wrist,<br>
and a controlled device (24). for example a personal computer. Several optical emitters<br>
(32). preferably light emitting diodes operating in the infrared range, and several optical<br>
detectors (36) are provided on the housing. At least one x-axis emitter-detector pair<br>
operates to detect an x-direction of a pointing motion or gesture, and at least one y-axis<br>
emitter-detector pair operates to detect a y-dircction of a pointing motion or gesture.<br>
This motion can then be used to cause a response in the controlled device (24). For<br>
example, angles of the operator's hand at the wrist can be interpreted to induce motion<br>
of a cursor on a computer display. The device may also include a motion sensor (40), an<br>
environmental condition sensor (42). or a voice recognition sensor (43), and can also be<br>
adapted for gesture recognition and image scanning applications.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LUtPTE5QLTIwMDQtKDA3LTAyLTIwMTIpLUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">444-KOLNP-2004-(07-02-2012)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LUtPTE5QLTIwMDQtKDA3LTAyLTIwMTIpLVBBLUNFUlRJRklFRCBDT1BJRVMucGRm" target="_blank" style="word-wrap:break-word;">444-KOLNP-2004-(07-02-2012)-PA-CERTIFIED COPIES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LUtPTE5QLTIwMDQtRk9STSAxNS5wZGY=" target="_blank" style="word-wrap:break-word;">444-KOLNP-2004-FORM 15.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1hc3NpZ25tZW50LnBkZg==" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1jb3JyZXNwb25kZW5jZS5wZGY=" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1leGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1ncGEucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1yZXBseSB0byBleGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDQ0LWtvbG5wLTIwMDQtZ3JhbnRlZC1zcGVjaWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">444-kolnp-2004-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="223868-a-process-for-the-isolation-of-5-methyl-isoxazole-3-methyl-carboxylate-from-the-plant-tragia-involucrata.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="223870-an-isolated-polypeptide.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>223869</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>444/KOLNP/2004</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>39/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>26-Sep-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>23-Sep-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>02-Apr-2004</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>HARMONIC RESEARCH INC</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>5208 SUDLEY ROAD, MANASSAS, VA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HOWARD ROBERT B</td>
											<td>5208 SUDLEY ROAD, MANASSAS, VA 20109</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G09G 5/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US02/28318</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2002-09-06</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>09/947,564</td>
									<td>2001-09-07</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/223869-improved-wireless-control-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 04:27:36 GMT -->
</html>
