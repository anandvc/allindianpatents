<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/278251-system-and-method-for-generating-and-reproducing-image-file-including-2d-image-and-3d-stereoscopic-image by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 22:52:29 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 278251:SYSTEM AND METHOD FOR GENERATING AND REPRODUCING IMAGE FILE INCLUDING 2D IMAGE AND 3D STEREOSCOPIC IMAGE</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">SYSTEM AND METHOD FOR GENERATING AND REPRODUCING IMAGE FILE INCLUDING 2D IMAGE AND 3D STEREOSCOPIC IMAGE</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>An apparatus includes a storage unit to receive and store an image file, a processor to parse a media data field of the image file including one or more image data samples and to parse a media header field including an image type data field indicating whether each of the one or more image data samples is one of 2 dimensional (2D) image data and 3 dimensional (3D) stereoscopic image data to generate an image corresponding to one of a 2D image and a 3D stereoscopic image based on the image type data field of the image file, and a display unit to display the generated image according to the image type data field of the image file.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>SYSTEM AND METHOD FOR GENERATING AND REPRODUCING<br>
IMAGE FILE INCLUDING 2D IMAGE AND 3D STEREOSCOPIC<br>
IMAGE<br>
BACKGROUND OF THE INVENTION<br>
Field of the Invention<br>
The present invention relates to a system and a method for generating and<br>
reproducing an image file that includes a two-dimensional (2D) image and a<br>
three-dimensional (3D) stereoscopic image based on 2D image media standards.<br>
More particularly, the present invention relates to a file format capable of<br>
alternatively generating and reproducing a 2D image and a 3D stereoscopic<br>
image, and a system and a method for alternatively generating and reproducing a<br>
2D image and a 3D stereoscopic image using the file format.<br>
Description of the Related Art<br>
File format standards used for storing 2D images are known in the art. In<br>
general, the Moving Picture Experts Group (MPEG), which is an international<br>
standards organization in the field of multimedia, has published MPEG-2,<br>
MPEG-4, MPEG-7 and MPEG-21 standards, since its first standardization of<br>
MPEG-1 in 1988. Because a variety of standards have been developed, a need to<br>
generate one profile by combining different standard technologies has arisen. In<br>
response to this need, MPEG-A (MPEG Application: ISO/ICE 230000)<br>
multimedia application standardization activities have been carried out for storing<br>
and reproducing 2D images.<br>
However, to date, a file format for storing a 3D stereoscopic image has not<br>
yet been standardized. Furthermore, a file format structure that includes both 2D<br>
and 3D stereoscopic images in a general portable terminal, or a system and a<br>
method for generating and reproducing such images using the structure of such<br>
file format has not yet been realized. This is important because when generating<br>
an image file in the form of a 3D stereoscopic image, a user cannot help but<br>
watch a non-3D stereoscopic image in the image file as a 3D stereoscopic image,<br>
so as to cause eyestrain on the user. Here, for example, such image may be an<br>
image in which the entire image is configured with characters.<br>
 <br>
<br>
SUMMARY OF THE INVENTION<br>
An aspect of the present invention is to address at least the above-<br>
mentioned problems and/or disadvantages and to provide at least the advantages<br>
described below. Accordingly, an aspect of the present invention is to provide a<br>
file format for generating, storing, and reproducing a 3D stereoscopic image.<br>
Another aspect of the present invention is to provide a file format for a 3D<br>
stereoscopic image based on a file format used to generate, store, and reproduce<br>
an existing 2D image.<br>
Yet another aspect of the present invention is to provide a system and a<br>
method for generating and reproducing a 3D stereoscopic image file by using a<br>
file format for a 3D stereoscopic image.<br>
In particular, the present invention provides a file format that includes<br>
both 3D stereoscopic image and 2D image so that the user can watch the 3D<br>
stereoscopic image and 2D image according to the file format. A file format in<br>
accordance with the present invention provides for storing both 2D and 3D<br>
stereoscopic images within one image file. For instance, a 3D stereoscopic image<br>
may be generally provided within one 3D stereoscopic image for news contents,<br>
for example, and the 2D image may be provided in the image including only a<br>
caption, so as to provide the user with convenience.<br>
In accordance with an aspect of the present invention, an apparatus<br>
includes a storage unit to receive and store an image file, a processor to parse a<br>
media data field of the image file including one or more image data samples and<br>
to parse a media header field including an image type data field indicating<br>
whether each of the one or more image data samples is one of 2 dimensional (2D)<br>
image data and 3 dimensional (3D) stereoscopic image data to generate an image<br>
corresponding to one of a 2D image and a 3D stereoscopic image based on the<br>
image type data field of the image file, and a display unit to display the generated<br>
image according to the image type data field of the image file.<br>
In accordance with another aspect of the present invention, a computer-<br>
implemented method includes receiving an image file, parsing a media data field<br>
of the image file including one or more image data samples, parsing a media<br>
header field including an image type data field indicating whether each of the one<br>
or more image data samples is one of 2 dimensional (2D) image data and 3<br>
 <br>
<br>
dimensional (3D) stereoscopic image data, and generating an image<br>
corresponding to one of a 2D image and a 3D stereoscopic image based on the<br>
image type data field of the image file.<br>
In accordance with yet another aspect of the present invention, a computer<br>
readable medium having stored thereon a data structure includes a media data<br>
field including one or more image data samples, and a media header field<br>
including an image type data field indicating whether each of the one or more<br>
image data samples is one of 2 dimensional (2D) image data and 3 dimensional<br>
(3D) stereoscopic image data.<br>
Other aspects, advantages, and salient features of the invention will<br>
become apparent to those skilled in the art from the following detailed<br>
description, which, taken in conjunction with the annexed drawings, discloses<br>
exemplary embodiments of the invention.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The above and other aspects, features and advantages of certain exemplary<br>
embodiments of the present invention will be more apparent from the following<br>
description taken in conjunction with the accompanying drawings, in which:<br>
FIG. 1 is a block diagram illustrating a storage format of a 2D image file<br>
according to prior art;<br>
FIG. 2A is a block diagram illustrating a storage format of an image file<br>
according to an exemplary embodiment of the present invention;<br>
FIG. 2B is a block diagram illustrating a storage format of an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 2C is a block diagram illustrating a storage format of an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 2D is a block diagram illustrating a storage format of an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 2E_is a block diagram illustrating a storage format of an image file<br>
 according to another exemplary embodiment of the present invention;<br>
FIG. 2F is a block diagram illustrating a storage format of an image file<br>
according to another exemplary embodiment of the present invention;<br>
 <br>
<br>
FIG. 2G is a block diagram illustrating a storage format of an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 2H is a block diagram illustrating a storage format of an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 3 is a block diagram illustrating an image file generating apparatus<br>
according to an exemplary embodiment of the present invention;<br>
FIG. 4 is a block diagram illustrating an image file reproducing apparatus<br>
according to an exemplary embodiment of the present invention;<br>
FIG. 5 is a flowchart illustrating a method for generating an image file<br>
according to an exemplary embodiment of the present invention;<br>
FIG. 6 is a flowchart illustrating a method for reproducing an image file<br>
according to an exemplary embodiment of the present invention;<br>
FIG. 7 is a flowchart illustrating a method for reproducing an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 8 is a flowchart illustrating a method for reproducing an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 9 is a flowchart illustrating a method for reproducing an image file<br>
according to another exemplary embodiment of the present invention;<br>
FIG. 10 is a flowchart illustrating a method for reproducing an image file<br>
according to another exemplary embodiment of the present invention; and<br>
FIG. 11 is a flowchart illustrating a method for implementing random<br>
access according to the present invention.<br>
Throughout the drawings, it should be noted that like reference numbers<br>
are used to depict the same or similar elements, features and structures.<br>
DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS<br>
The following description with reference to the accompanying drawings is<br>
provided to assist in a comprehensive understanding of exemplary embodiments<br>
of the invention as defined by the claims and their equivalents. It includes<br>
various details to assist in that understanding but these are to be regarded as<br>
merely exemplary. Accordingly, those of ordinary skill in the art will recognize<br>
that various changes and modifications of the embodiments described herein can<br>
be made without departing from the scope and spirit of the invention.<br>
 <br>
Before describing a format for storing a three-dimensional (3D)<br>
stereoscopic image according to an exemplary embodiment of the present<br>
invention, a storage format of a two-dimensional (2D) image file based on a<br>
conventional International Standards Organization (ISO) standard will be<br>
described. FIG. 1 is a diagram illustrating a file format of a 2D image based on<br>
the conventional ISO 14496-12 standard. Referring to FIG. 1, the 2D image file<br>
format 100 includes a file area ftyp 110 of a top level, a moov area 120, and an<br>
mdat area 130. The mdat area 130 is a data area of the file format and includes<br>
actual image data 132 within an image track 131 and voice data 134 within a<br>
voice track 133. Each of the tracks includes respective image data and voice data<br>
stored in a frame unit.<br>
The moov area 120 corresponds to a header area of the file format and has<br>
an object based structure. The moov area 120 includes all pieces of information<br>
needed to reproduce a file, including content information (e.g., a frame rate, a bit<br>
rate, image size, etc.) and synchronization information used to support a<br>
reproduction function of fast-forward/rewind (FF/REW). In particular, the moov<br>
area 120 includes information, such as the number of frames within the image<br>
data and voice data, a size of each frame, etc., thereby making it possible to<br>
restore and reproduce image data and voice data by parsing the moov area 120<br>
during reproduction.<br>
Unlike the prior art, exemplary embodiments of the present invention<br>
include a storage format of an image file that provides for both 2D and 3D<br>
stereoscopic images, and a system for generating and reproducing image files<br>
using the storage format of the present invention. In particular, exemplary<br>
embodiments of the present invention are characterized in that each part of the<br>
image file may be implemented in the form of a 2D image or 3D stereoscopic<br>
image according to the characteristics of the content. For example, in sections<br>
that include many characters, displaying the section as a 3D stereoscopic image<br>
causes eyestrain on the user. Therefore, the section is stored and reproduced as a<br>
2D image. The part requiring rhythmical movement or three-dimensional effect<br>
is stored and reproduced as a 3D stereoscopic image. Accordingly, the format of<br>
the image file appropriate for the characteristic of the contents is implemented.<br>
Hereinafter, a storage format of the image file adapted to include 2D<br>
images and 3D stereoscopic images according to an exemplary embodiment of<br>
the present invention will be described with reference to FIGs. 2A and 2B. As<br>
 <br>
<br>
mentioned above, according to exemplary embodiments of the present invention,<br>
image files 201 and 202 including the 2D image and the 3D stereoscopic image<br>
include a box (i.e., field) with information on the image file regarding the 2D<br>
image and the 3D stereoscopic image.<br>
In accordance with the present invention, the box including information<br>
on the image file regarding the 2D image file and the 3D stereoscopic image may<br>
be inserted into a file area, moov area, or track area directly or as part of a meta<br>
box, or may be inserted into a sample table box (e.g., "stbl" box) that includes<br>
information of a sample in the track area. The sample refers to a basic unit for<br>
dividing the image within the file format, such as a frame.<br>
FIG. 2A illustrates a storage format of an image file in which 3D<br>
stereoscopic image file is included in one image stream. As shown in FIG. 2A,<br>
data structure 201 of the image file includes a top level file area Ftyp 210, Moov<br>
area 220 corresponding to a header area, an Mdata area 240 corresponding to a<br>
data area, and a Metadata area 230. Here, the Mdata area 240 includes an image<br>
track 241 and a voice track 245 where image data is stored in the image track 241<br>
and voice data is stored in the voice track 245. The image track 241 includes first<br>
image data for a 2D image (denoted as "1") and second and third image data for a<br>
3D stereoscopic image (denoted as "2" and "3"). Here, the second image data<br>
and the third image data may be left view image data and right view image data of<br>
a single subject, respectively. For example, if the left view and right view image<br>
data representing a single subject photographed from a left view and a right view<br>
are interleaved and displayed, a user can see a three-dimensional effect.<br>
FIG. 2A illustrates an example in which each fragment 242, 243, and 244<br>
includes data samples of 3D stereoscopic image data, 2D image data, and 3D<br>
stereoscopic image data, respectively. The sequence of the image data is defined<br>
as 2D image or 3D stereoscopic image according to the characteristic of each part<br>
of a particular content. Further, if a storage scheme of the second image data and<br>
the third image data of a 3D stereoscopic image stored in the fragments 242 and<br>
244 is predetermined in accordance with the present invention, the image file can<br>
be generated and reproduced in any manner desired. For example, FIG. 2A<br>
shows an example of a method in which the 3D stereoscopic image fragments 242<br>
and 244 include each second image data (i.e., sample 2) and the third image data<br>
(i.e., sample 3) alternatively stored where each sample is a frame unit.<br>
Alternatively, there may be a scheme in which the second image data and the<br>
 <br>
<br>
third image data are stored side-by-side as a frame unit, or the image data may be<br>
divided into small data to be stored in an interleaving manner as a frame unit.<br>
The voice data 246, 247, and 248 included in the voice track 245 are the<br>
voice data for each fragment 242, 243, and 244, respectively. The voice data are<br>
synchronized with the image data of the fragments 242, 243, and 244 to be<br>
reproduced.<br>
The Moov area 220 corresponds to the header area of the data structure<br>
and includes information 221 regarding the image track and information 222<br>
regarding the voice track. The information 221 regarding the image track<br>
includes general information used to reproduce a file including content<br>
information, such as a frame rate, a bit rate, image size, etc., and synchronization<br>
information used to support a reproduction function, such as fast-forward/rewind<br>
(FF/REW). In particular, the Moov area 220 includes information, such as the<br>
total number of frames of the image data within the image track 241 and voice<br>
data within the voice track 245, size of each frame, etc. Therefore, it is possible<br>
to restore and reproduce image data and voice data by parsing the Moov area 220<br>
during reproduction.<br>
The present invention includes a box including identification information<br>
indicating if each frame generated by the first image data, second image data, and<br>
third image data is for a 2D image or a 3D stereoscopic image. As shown in FIG.<br>
2A, the Moov area 230 includes a box 231 that represents if each image data<br>
stored in the frame unit within the image file includes image data for a 2D image<br>
or image data for a 3D stereoscopic image. In an exemplary embodiment, a flag<br>
may be assigned to each frame and set so as to represent the image characteristic<br>
of the frame. The identification information includes, for example, information<br>
on the number of fragments containing sequential frames for a 2D image and for a<br>
3D stereoscopic image. Accordingly, the image file can be restored and<br>
reproduced in the form of a 2D image or 3D stereoscopic image using such<br>
information. The description of the restoration and reproduction of the image file<br>
in the form of a 2D image or 3D stereoscopic image is exemplified in Tables 1<br>
and 2 below.<br>
[Table 1 ]<br>
 <br>
 <br>
 <br>
As shown in Tables 1 and 2, and FIG. 2A, the first fragment 242 includes<br>
the second image data and the third image data for the 3D stereoscopic image, the<br>
second fragment 243 includes the first image data for the 2D image, and the third<br>
fragment 244 includes the second image data and the third image data for the 3D<br>
stereoscopic image. Here, the identification information 231 indicates the<br>
sample_count and the flag shown in Table 2. Accordingly, the image stored in the<br>
fragments 242, 243, and 244 can be restored and reproduced by referring to<br>
information 231 indicating whether the stored image in the data structure 201 is a<br>
2D image or a 3D stereoscopic image. The identification information includes<br>
information for decoding the second image data and the third image data and<br>
information for synthesizing the second image data and the third image data, and<br>
the information 231 is referenced during reproduction.<br>
Another exemplary embodiment of the present invention will be described<br>
with reference to FIG. 2B. FIG. 2B is a block diagram illustrating a storage<br>
format of a 3D stereoscopic image file according to another exemplary<br>
embodiment of the present invention. In the exemplary embodiment shown in<br>
FIG. 2B, there are two of image tracks rather than one image track as shown in<br>
FIG. 2A. Data structure 202 of the 3D stereoscopic image file includes a top<br>
level file area Ftyp 250, a Moov area 260 corresponding to the header area, an<br>
Mdata area 280 corresponding to the data area, and a Metadata area 270. Those<br>
descriptions that are substantially the same as that of FIG. 2A are not repeated for<br>
conciseness.<br>
 <br>
<br>
Briefly, information 261 and 262 on a first image track and a second<br>
image track, and information 263 on a voice track are substantially the same as<br>
information 221 and 222 of FIG. 2A, fragments 293, 294, and 295 are<br>
substantially the same as the fragments 242, 243 and 244, voice track 289<br>
including voice data 290, 291, and 292 is substantially the same as voice track<br>
245 including voice data 246, 247 and 248, and information 272 is substantially<br>
the same as the information 231. A first image track 281 includes second image<br>
data 282 and 284 corresponding to an image from one viewing angle (e.g., a left<br>
view image) and first image data 283 corresponding to a 2D image. A second<br>
image track 285 includes third image data 286 and 288 corresponding to an image<br>
from a different viewing angle (e.g., a right view image) and first image data 287<br>
corresponding to a 2D image. That is, the left view image data and the right view<br>
image data are stored in different image tracks, respectively, and the first image<br>
data 283 and the first image data 287 correspond to an identical image.<br>
Accordingly, identification information 272 indicating that the image is a 2D<br>
image or a 3D stereoscopic image also includes information on which of the two<br>
2D image data (i.e., between the first image data 283 and first image data 287) is<br>
to be used for the 2D image, in addition to the afore-mentioned information. That<br>
is, the image data to be used for the 2D image can be determined according to<br>
information on which image track between the first image track 281 and the<br>
second image track 285 is set as a main image track.<br>
Table 3 represents an information box serving as a standard for the storage<br>
format of the image file including a 2D image and a 3D stereoscopic image in<br>
accordance with the present invention. The standards are generally defined in<br>
compliance with ISO/IEC 14496-12 ISO base media format.<br>
[Table 3]<br>
 <br>
 <br>
-<br>
 <br>
 <br>
 <br>
The image information box (e.g., "svmi" box) may be a box storing<br>
stereo/mono information on each sample included in the image file (ES).<br>
Accordingly, the container including the image information box (e.g., "svmi"<br>
box) may be the meta box or sample table box (e.g., "stbl" box). A container<br>
refers to a higher level of box including the current box. Therefore, the container<br>
including the image information box (e.g., "svmi" box) may be the Metadata area<br>
270 as shown in FIG. 2B and Table 4A shown below, and also may be included<br>
in the sample table box (e.g., "stbl" box) as shown in Table 4B below.<br>
Accordingly, the parts newly added in the container are represented in Tables 3,<br>
6, 8, and 9, shown below. According to the present invention, the container<br>
including the image information box (e.g., "svmi" box) refers to the meta box or<br>
sample table box (e.g., "stbl" box). However, it is to be understood that it may be<br>
moved freely to a more appropriate location of any one of the table of boxes on<br>
ISO/IEC 14496-12 ISO base media file format.<br>
[Table 4A]<br>
 <br>
 <br>
<br>
<br>
 <br>
Table 4B represents the table of boxes in which the image information<br>
box (e.g.,, "svmi" box) may be inserted into a sub "stbl" box container, for<br>
example, in the file structure of ISO/IEC 23000-11 stereoscopic video application<br>
format. Further, every image information box (e.g., "svmi" box) according to an<br>
exemplary embodiment of the present invention may be included in the file area,<br>
moov area, or track area.<br>
[Table 4B]<br>
 <br>
 <br>
<br>
 <br>
 <br>
<br>
 <br>
FIGs. 2B to 2F illustrate a storage format of an image file according to<br>
various exemplary embodiments of the present invention.<br>
FIG. 2B illustrates a storage format of an image file in the case where a<br>
3D stereoscopic image file includes two image streams (e.g., a left image and a<br>
right image stored in separate image streams) in which a box containing the<br>
information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a moov area (i.e., Moov 260).<br>
FIG. 2C illustrates a storage format of an image file in the case where a<br>
3D stereoscopic image file includes one image stream in which a box containing<br>
the information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a file area (i.e., Ftyp 210).<br>
FIG. 2D illustrates a storage format of an image file in the case where a<br>
3D stereoscopic image file includes two image streams (i.e. a left image and a<br>
right image is stored in separate image streams) in which a box containing the<br>
information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a file area (i.e., Ftyp 250).<br>
FIG. 2E illustrates a storage format of an image file in the case where a<br>
3D stereoscopic image file includes one image stream in which a box containing<br>
the information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a track area (i.e., Track 221).<br>
FIG. 2F illustrates a storage format of an image file in the case where a 3D<br>
stereoscopic image file includes two image streams (i.e. a left image and a right<br>
image is stored in separate image streams) in which a box containing the<br>
information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a respective track area (i.e., Track 261 and Track<br>
262).<br>
FIGs. 2A to 2F illustrate exemplary embodiments of the present<br>
application in which the image information box (e.g., "svmi" box) including the<br>
information on the image file that contains both 2D image and 3D stereoscopic<br>
image is included in a meta box, so as to be inserted into the file area, moov area,<br>
and track area.<br>
FIGs. 2G and 2H illustrate exemplary embodiments in which an image<br>
information box (e.g., "svmi" box) including information on an image file that<br>
 <br>
<br>
contains both 2D image and 3D stereoscopic image is inserted into a sample table<br>
box (e.g., "stbl" box) that includes sample information of the image file in a track<br>
area. For purposes of explanation, a sample refers to a basic unit for dividing the<br>
image within the file format, such as a frame).<br>
FIG. 2G illustrates a storage format of an image file in the case where a<br>
3D stereoscopic image file includes one image stream in which a box containing<br>
the information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a sample stable box (e.g., "stbl" box).<br>
FIG. 2H illustrates a storage format of an image file in the case where a<br>
3D stereoscopic image file includes two image streams (i.e. a left image and a<br>
right image is stored in separate image streams) in which a box containing the<br>
information of the 2D image and the 3D stereoscopic image according to the<br>
present invention is added to a sample stable box (e.g., "stbl" box).<br>
As illustrated in FIGs. 2A to 2H, the image information box (e.g., "svmi"<br>
box) may be added to the file level and track level of the existing image file<br>
format, not to the moov level, so that the image file can be generated by the<br>
various image file formats.<br>
Hereinafter, alternative exemplary embodiments of the present invention<br>
different from the exemplary embodiment of Tables 2 and 3, and a newly<br>
modified image information box (e.g., "svmi" box) will be introduced.<br>
In an exemplary embodiment in the case where the contents include both<br>
2D image and 3D stereoscopic image, syntax and semantics of the modified<br>
image information box are described as shown in Table 6.<br>
[Table 6]<br>
 <br>
[Table 5]<br>
 <br>
 <br>
<br>
 <br>
 <br>
 <br>
The contents of Table 5 using the syntax of Table 6 is represented as Table<br>
7.<br>
[Table 7]<br>
If the entry_count is defined as the semantics of Table 3, there is a<br>
problem of failing to recognize the fragment construction within the current entry.<br>
Accordingly, in an exemplary embodiment, the syntaxvalue of the item count is<br>
included so as to solve the above problem. That is, when the entrycount is<br>
defined according to the semantics of Table 6, only if the contents include the flag<br>
value discriminating that stereo is first or mono is first, the stereo_flag syntax can<br>
be omitted, which is defined as follows.<br>
[Table 8]<br>
 <br>
 <br>
<br>
<br>
 <br>
If the value of the image sequence information (isstereofirst) is 1, the<br>
contents is constructed in a sequence of S→ M→ S→ M→ ..., where "S" is stereo<br>
and "M" is mono, and if the value of image sequence information (is_stereo_first)<br>
is 0, the contents is constructed in a sequence of M→ S→ M→ S→ ... .<br>
In yet another exemplary embodiment, the sample_count syntax is<br>
excluded. In this case, it can be recognized whether each fragment is stereo or<br>
mono but fails to recognize how many number of frames is stereo or mono.<br>
Therefore, the number of stereo or mono frames can be determined using the<br>
values of the syntax of an item location box defined on the ISO media file format<br>
and the syntax of the sub-boxes of the sample table box (e.g., "stbl" box).<br>
 <br>
 <br>
[Table 9]<br>
 <br>
<br>
 <br>
<br>
Further, when a terminal performs random access to the contents, it is<br>
shifted to a desired location while sequentially reading the size of frame from the<br>
beginning using the values of the sample size box (e.g., "stsz" box). If the<br>
sample_count syntax value of the image information box (e.g., "svmi" box)<br>
defined in the present invention is used, the number of frames of each fragment<br>
and start address and size of each fragment in the item location box (e.g., "iloc"<br>
box) can be recognized. Therefore, random access to a predetermined location is<br>
more effectively accomplished using those values.<br>
Next, an exemplary system for generating and reproducing image files<br>
using data structures 201 to 208 of the image files shown in FIGs. 2A to 2H will<br>
be described. The system generally includes an image file generating apparatus<br>
and an image file reproducing apparatus. First, the image file generating<br>
apparatus according to an exemplary embodiment of the present invention will be<br>
described with reference to FIG. 3.<br>
As shown in FIG. 3, an image file generating apparatus according to the<br>
present invention includes a first camera 311, a second camera 312, an input unit<br>
320, an image signal processing unit 330, a storage unit 340, an encoding unit<br>
350, and a file generating unit 360. The first camera 311 photographs a subject<br>
from a left view or a right view and then outputs second image data. The second<br>
camera 312 photographs the subject from a view different from that of the first<br>
camera 311 and then outputs third image data. It is to be understood that multiple<br>
views from different angles may be used without departing from the scope of the<br>
present invention. Then, first image data 310 for the 2D image is input together<br>
with the second image data and the third image data through the input unit 320.<br>
The first image data, the second image data, and the third image data are<br>
pre-processed by the image signal processing unit 330. Here, the pre-processing<br>
operation includes conversion of an analog external image value, i.e., analog<br>
values of light and color components generated by a charge coupled device<br>
(CCD) or a complimentary metal-oxide semiconductor (CMOS) type sensor, for<br>
example, into a digital value.<br>
The storage unit 340 stores the first image data, the second image data,<br>
and the third image data pre-processed by the image signal processing unit 330,<br>
and provides the stored image data to the encoding unit 350. FIG. 3 shows the<br>
storage unit 340, but it does not separately show a storage construction for<br>
 <br>
<br>
buffering between the elements shown in FIG. 3 that may be included. The<br>
encoding unit 350 encodes the first image data, the second image data, and the<br>
third image data from the storage unit 340. The encoding operation performed by<br>
the encoding unit 350 is the encoding of data, which can be skipped as occasion<br>
demands.<br>
The file generating unit 360 generates an image file 370 by using the first<br>
image data, the second image data, and the third image data encoded by the<br>
encoding unit 350. In this case, the first image data, the second image data, and<br>
the third image data are stored in the data area (e.g., the mdata area) and<br>
information used to generate the first image data (i.e., 2D image) and the second<br>
image data and the third image data (i.e., 3D stereoscopic image) is stored in the<br>
header are (e.g., the moov area and the metadata area). The generated image file<br>
370 is input and transmitted to the stereoscopic image file reproducing apparatus,<br>
and then the image file reproducing apparatus generates and reproduces the 2D<br>
image and the 3D stereoscopic image from the image file 370. Hereinafter, an<br>
exemplary image file reproducing apparatus will be described.<br>
FIG. 4 is a block diagram illustrating an image file reproducing apparatus<br>
according to an exemplary embodiment of the present invention. As shown in<br>
FIG. 4, the image file reproducing apparatus includes a file parsing unit 420, a<br>
decoding unit 430, a storage unit 440, a reproducing unit 450, and a display unit<br>
460.<br>
The file parsing unit 420 receives and parses the image file 410 (e.g.,<br>
image file 370 from FIG. 3) generated by the file generating unit 360 of the image<br>
file generating apparatus, for example. In this case, the file parsing unit 420<br>
parses information stored respectively in the moov area and the metadata area and<br>
then extracts the first image data, the second image data, and the third image data<br>
stored in the mdata area.<br>
The decoding unit 430 decodes the extracted first image data, second<br>
image data, and third image data. In an exemplary embodiment, the decoding is<br>
performed in the case where the image file generating apparatus encodes the data<br>
using the encoding unit 350. That is, if the encoding is skipped by the file<br>
generating apparatus, the decoding is skipped by the file reproducing apparatus.<br>
Then, the decoded data are stored in the storage unit 440.<br>
The reproducing unit 450 reproduces the 2D image generated from the<br>
first image data stored in the storage unit 440, and the 3D stereoscopic image is<br>
 <br>
<br>
synthesized from the second image data and third image data stored in the storage<br>
unit 440 in accordance with the identification information. Then, the display unit<br>
460 displays the reproduced 2D image and 3D stereoscopic image. The display<br>
unit 460 may employ a barrier liquid crystal display (LCD). In an exemplary<br>
embodiment, the barrier LCD is turned off if the fragment of the image file is a<br>
2D image, and the barrier LCD is turned on if the fragment of the image file is a<br>
3D stereoscopic image so that the image can be displayed properly.<br>
Next, an exemplary method for generating and reproducing an image file<br>
by using the data structures of the image file in accordance with the present<br>
invention will be described.<br>
FIG. 5 is a flowchart illustrating a method for generating an image file<br>
according to an exemplary embodiment of the present invention. As shown in<br>
FIG. 5, the method includes an inputting step S510, a pre-processing step S520,<br>
an encoding step S530, and a file generating step S540.<br>
In step S510, a first image data for generating a 2D image, and second<br>
image data and third image data for generating a 3D stereoscopic image are input.<br>
For example, a subject is photographed from a left view and/or a right view and<br>
the second image data and third image data are output. In step S520, the first<br>
image data, the second image data, and the third image data input in step S510 are<br>
pre-processed, and the image data generated by the CCD or CMOS-type sensor<br>
are converted from analog values to digital values. In step S530, the pre-<br>
processed first image data, the second image data, and the third image data are<br>
encoded according to a predetermined encoding scheme. Step S530 may be<br>
skipped as occasion demands. In step S540, the image file is generated by using<br>
the first image data, the second image data, and the third image data encoded in<br>
the encoding unit 350. In this case, the image file may be generated according to<br>
any one of the data structures of the image file described in FIGs. 2 A to 2H.<br>
FIG. 6 is a flowchart illustrating a method for reproducing an image file in<br>
accordance with an exemplary embodiment of the present invention. As shown in<br>
FIG. 6, a method for reproducing the image file includes a file parsing step S610,<br>
a decoding step S620, a reproducing step S630, and a display step S640.<br>
In step S610, a first image data, a second image data, and a third image<br>
data are extracted by using information stored in a moov area and a metadata area<br>
of an image file generated in accordance with the present invention. In particular,<br>
the image data are extracted using the identification information described above.<br>
 <br>
<br>
In step S620, the first image data, the second image data, and the third image data<br>
are decoded. If an encoding step was skipped in generating the image file, the<br>
decoding step S620 is also skipped. In step S630, the first image data, the second<br>
image data, and the third image data decoded in step S620 are synthesized into a<br>
2D image and a 3D stereoscopic image to be reproduced. Then, in step S640, the<br>
2D image and the 3D stereoscopic image generated in step S630 are displayed on<br>
the display unit 460. Again, the display unit 460 may employ a barrier LCD<br>
where the barrier LCD is turned off if the fragment of the image file is a 2D<br>
image, and the barrier LCD is turned on if the fragment of the image file is a 3D<br>
stereoscopic image so that the image can be properly displayed.<br>
FIGs. 7 to 10 illustrate operation of a terminal from parsing to reproducing<br>
an image file according to various exemplary embodiments of the present<br>
invention.<br>
FIG. 7 describes an exemplary embodiment that includes parsing and<br>
reproducing an image file generated in accordance with the present invention.<br>
The embodiment of FIG. 7 relates to an image file format including an image<br>
information box (e.g., "svmi" box) shown in Table 3. The image information box<br>
(e.g., "svmi" box) includes a plurality of fields. A main function of the fields is<br>
to provide information indicating whether each frame of the image file is a 2D<br>
image or a 3D stereoscopic image, the information providing a flag value to<br>
control the activation or non-activation of a display (e.g., LCD).<br>
As shown in FIG. 7, file box (e.g., "ftyp" box) in an image file is parsed in<br>
step S710. In an exemplary embodiment, the ftyp box is provided according to a<br>
conventional ISO/IEC 14496-12 standard. In steps S720 to S740, respectively, a<br>
moov box, a track box, and a meta box of the image file are parsed. In an<br>
exemplary embodiment, the moov box and the track box may also be provided<br>
according to the conventional ISO/IEC 14496-12 standard. In step S750, each<br>
field of the image information box (e.g., "svmi" box) of the image file in<br>
accordance with the present invention is parsed to determine if each frame within<br>
the image track contains a 2D image or a 3D stereoscopic image. The<br>
information is mainly provided through the field of the samplecount and the<br>
entry_count.<br>
Here, the entry_count refers to the number of fragments within the image<br>
file. For example, 6 image may be stored in the image file in the following<br>
sequence: a 3D stereoscopic image (1), a 3D stereoscopic image (2), a 3D<br>
 <br>
<br>
stereoscopic image (3), a 2D image (1), a 2D image (2), and another 3D<br>
stereoscopic image (4). In this example, each of the images is referred to as a<br>
fragment. However, it is to be understood that a unit of the fragment can be a<br>
frame, a set of frames having a sequential value, or an interval by which a 3D<br>
stereoscopic image and a 2D image is divided. The sample_count refers to the<br>
number of sequential frames included in each fragment.<br>
Accordingly, the entrycount is identified to determine the number of<br>
fragments within the image, and the samplecount is identified to determine the<br>
total number of frames included in each fragment. Then, the stereoflag is<br>
identified and flag information of the set of the frames included in the current<br>
frame, i.e. the corresponding fragment, is identified. Through the flag<br>
information, whether the corresponding fragment is a 3D stereoscopic image or a<br>
2D image may be determined. Then, each identified frame is decoded in the form<br>
of a 3D stereoscopic image or 2D image in step S760.<br>
In step S770, according to the parsed information of the stereo_flag within<br>
the image information box (e.g., "svmi" box), a barrier LCD is controlled such<br>
that if the value is "1," the barrier LCD is activated, and if the value is "0," the<br>
barrier LCD is not activated. That is, in the case of a 3D stereoscopic image, the<br>
value of the stereo_flag may be set as "1" so that the barrier LCD is activated so,<br>
and in the case of a 2D image, the value of the stereoflag may be set as "0" so<br>
that the barrier LCD is not activated, thereby allowing the barrier LCD to be<br>
controlled. In the meantime, the decoded frame is reproduced and displayed on<br>
the activated or non-activated barrier LCD so that the user can see the image.<br>
FIG. 8 is a flowchart illustrating a method for reproducing an image file<br>
according to another exemplary embodiment of the present invention. As shown<br>
in FIG. 8, file box (e.g., "ftyp" box) of the image file is parsed in step S810.<br>
Then, moov box, track box, and meta box of the image file are parsed in steps<br>
S820, S830, and S840, respectively. Next, each field of the image information<br>
box (e.g., "svmi" box) of the image file in accordance with the present invention<br>
is parsed to determine if each frame within the image track contains a 2D image<br>
or a 3D stereoscopic image in step S850.<br>
The entry_ count in the present exemplary embodiment is different from<br>
that of the previous exemplary embodiment. The entry_count in the present<br>
exemplary embodiment refers to the number of fragments in which the type of the<br>
fragment (i.e., 2D or 3D) is shifted from stereo-to-mono or from mono-to-stereo.<br>
 <br>
<br>
Using the previous image file example, even if 6 images of the 3D stereoscopic<br>
image (1), the 3D stereoscopic image (2), the 3D stereoscopic image (3), the 2D<br>
image (1), the 2D image (2), and the 3D stereoscopic image (4) are included in a<br>
single image file in sequence, the image is divided based on the type shift of the<br>
3D stereoscopic image and 2D image. Accordingly, the entry_count is 3 (i.e., 3D<br>
image fragments (l)-(3), 2D image fragments (l)-(2), and 3D image fragment<br>
(4)). The entrycount is identified to determine the number of fragments within<br>
the image, and the samplecount is identified to determine the total number of<br>
frames included in each fragment. Then, the stereofiag is identified and the flag<br>
information on the set of the frames included in the current frame, i.e. the<br>
corresponding fragment, is identified. Through the flag information, whether the<br>
corresponding fragment is the 3D stereoscopic image or 2D image may be<br>
determined. Next, the itemcount is identified so as to identify the number of<br>
fragments within each entry (within each interval of stereo and mono) of the<br>
image identified in the entry_count. A unit of the fragment can be a frame, a set<br>
of frames having sequential values, or an interval by which the 3D stereoscopic<br>
image and 2D image is divided. The steps of decoding and displaying the image<br>
(steps S860 and S870) are identical to the operation of the terminal of the<br>
previous exemplary embodiment shown in FIG. 7.<br>
FIG. 9 illustrates a method for parsing and reproducing an image file<br>
according to another exemplary embodiment of the present invention. As shown<br>
in FIG. 9, file box (e.g., "ftyp" box) is parsed in the image file in step S910.<br>
Then, moov box, track box, and meta box of the image file are parsed in steps<br>
S920, S930, and S940, respectively. Next, each field of the image information<br>
box (e.g., "svmi" box) of image file in accordance with the present invention is<br>
parsed to determine if each frame within the image track contains a 2D image or a<br>
3D stereoscopic image in step S950.<br>
The entry_count in the present exemplary embodiment is the same as that<br>
of the exemplary embodiment of FIG. 8. That is, the entrycount in this<br>
exemplary embodiment also refers to the number of fragments in which the type<br>
of the fragment is shifted from stereo-to-mono or from mono-to-stereo. The<br>
entry_count is identified, the number of fragments within the image is identified,<br>
and the encoding sequence (is_left_first) is identified, so as to identify which<br>
image interval between the 3D stereoscopic image and 2D image is first<br>
constructed in the corresponding image. For example, the value of the encoding<br>
 <br>
<br>
sequence (is_left_first) may be set to "1" to indicate that the contents are arranged<br>
in S→M→S→M sequence, and the value may be set to "0" to indicate that the<br>
contents are arranged in M→S→M→S sequence. Then, the samplecount is<br>
identified to determine the total number of frames included in each fragment.<br>
Next, the item_count is identified so as to identify the number of fragments<br>
within each entry (within each interval between stereo and mono) of the image<br>
identified from the entry_count. A unit of the fragment can be a frame, a set of<br>
frames having sequential values, or an interval by which the 3D stereoscopic<br>
image and 2D image is divided. Then, each identified frame is decoded as a 3D<br>
stereoscopic image or a 2D image in step S960. Next, the barrier LCD is<br>
controlled with the information obtained through parsing the encoding sequence<br>
(isstereofirst) within the image information box. The encoded frame is<br>
reproduced and displayed on the activated or non-activated barrier LCD so as to<br>
allow the user to watch the image in step S970.<br>
FIG. 10 is a flowchart illustrating a method for reproducing an image file<br>
according to another exemplary embodiment of the present invention. As shown<br>
in FIG. 10, file box (e.g., "ftyp" box) in the image file is parsed in step S1010.<br>
Then, moov box, track box, and meta box of the image file are parsed in steps<br>
S1010, S1020, and S1030, respectively. Next, each field of the image<br>
information box (e.g., "svmi" box) of the image file in accordance with the<br>
present invention is parsed to determine if each frame within the image track<br>
contains a 2D image or a 3D stereoscopic image in step S1050.<br>
The entry_count in the current exemplary embodiment is the same as that<br>
of the exemplary embodiment of FIG. 7 in which it refers to the number of<br>
fragments within the image file. Using the previous image file example, even if 6<br>
images of the 3D stereoscopic image (1), the 3D stereoscopic image (2), the 3D<br>
stereoscopic image (3), the 2D image (1), the 2D image (2), and the 3D<br>
stereoscopic image (4) are included in a single image file in sequence, each image<br>
includes a plurality of frames, in which each image is referred as the fragment.<br>
As described above, a unit of a fragment can be a frame, a set of frames having<br>
sequential values, or an interval by which the 3D stereoscopic image and 2D<br>
image is divided. The sample_count refers to the number of sequential frames<br>
included in each fragment. The entry_count is identified to determine the number<br>
of fragments within the image, and the stereo_flag is identified and the flag<br>
information of the set of the frames included in each fragment is identified.<br>
 <br>
<br>
Through the flag information, whether the corresponding fragment is the 3D<br>
stereoscopic image or 2D image may be determined. Then, the item location box<br>
(e.g., "iloc" box) is identified, the start address and the size of the fragment are<br>
identified, and the sample size in the sample size box (e.g., "stsz" box) is<br>
identified, so as to identify how many frames are included in each fragment in<br>
step S1060. The steps of decoding and displaying the image (steps S1070 and<br>
S1080) are identical to the operation of the terminal of the first exemplary<br>
embodiment shown in FIG. 7.<br>
FIG. 11 is a flowchart illustrating a method for implementing random<br>
access of an image file according to the present invention. FIG. 11 illustrates the<br>
operation of a terminal where a random access order is generated during decoding<br>
and reproducing an image, such as when a play bar is shifted to an image of a<br>
time zone desired to be watched during reproducing a one-hour image, for<br>
example.<br>
In step S1100, time stamp information is identified from a box including<br>
the time stamp (e.g., "TimeStamp") information so as to identify the frame to be<br>
random-accessed (i.e., a random access point, hereinafter referred to as "RAP").<br>
In step S1110, the entrycount of the image information box (e.g., "svmi" box) is<br>
identified and the number of fragments within the image is identified. At this<br>
time, a unit of the fragment can be a frame, a set of frames having sequential<br>
values, or an interval by which a 3D stereoscopic image and a 2D image is<br>
divided. In steps S1120 and S1130, respectively, the samplecount is identified,<br>
the fragment including the RAP is identified, and the item location box (e.g.,<br>
"iloc" box) is identified, so as to identify the start address of the corresponding<br>
fragment through the information, such as offset of the corresponding fragment.<br>
In steps S1140 and S1150, respectively, the samplesize is identified in the<br>
sample size box (e.g., "stsz" box) and the samplesize is added one-by-one from<br>
the start address of the corresponding fragment identified in the item location box<br>
(e.g., "iloc" box) so as to find out the RAP. Then, decoding of the RAP is started<br>
according to the random access order in step S1160. If the random access order is<br>
generated, a conventional method determines the RAP through calculating the<br>
samplesize of the entire image. However, according to the present invention,<br>
only the sample within the fragment including the RAP need be calculated.<br>
FIG. 11 illustrates only an exemplary embodiment using the entrycount<br>
and samplecount. However, it is to be understood that the random access<br>
 <br>
<br>
operation of the present invention may be applied to other exemplary<br>
embodiments. Further, steps for identifying the itemcount, or the like, may be<br>
added or excluded depending on the exemplary embodiment within the scope of<br>
the logical flow in the operation of a terminal without departing from the scope of<br>
the present invention. Still further, details of interpreting the image information<br>
box (e.g., "svmi" box) or the operation of a terminal may be varied depending on<br>
the location of the image information box, the location of the parameter within the<br>
box, or the like, without departing from the scope of the present invention.<br>
Details of the steps for parsing the file format and the operation of the<br>
terminal which are not specifically described here may be implemented based on<br>
ISO/IEC 14496-12 and ISO/IEC 23000-11 standards and may be used in<br>
conjunction with the various embodiments of the present invention.<br>
As described above, the present invention defines a data structure of an<br>
image file that can include both 2D image and 3D stereoscopic image by using<br>
verified standard technology of 2D images so as to simply the verification process<br>
serving as a new standard. Accordingly, the present invention allows both 2D<br>
image and 3D stereoscopic image to be implemented within a single image file as<br>
necessary. In particular, the system and method for using the image file format<br>
according to the present invention allows images not required to be viewed in the<br>
form of the 3D stereoscopic image (i.e., 2D images within an image file for<br>
displaying 3D stereoscopic image) to be displayed according so as to release<br>
eyestrain of the user. Further, the present invention has an advantage in that the<br>
contents mixed with 3D stereoscopic image and 2D image can be effectively<br>
reproduced by controlling the barrier LCD of the terminal on or off using the<br>
image information box (e.g., "svmi" box).<br>
While the invention has been shown and described with reference to<br>
certain exemplary embodiments thereof, it will be understood by those skilled in<br>
the art that various changes in form and details may be made therein without<br>
departing from the spirit and scope of the invention as defined by the appended<br>
claims and their equivalents.<br>
 <br>
<br>
We Claim:<br>
1. A computer-implemented method, comprising:<br>
receiving an image file;<br>
parsing a media data field of the image file including one or more image<br>
data samples;<br>
parsing a media header field including an image type data field indicating<br>
whether each of the one or more image data samples is one of 2 dimensional (2D)<br>
image data and 3 dimensional (3D) stereoscopic image data; and<br>
generating an image corresponding to one of a 2D image and a 3D<br>
stereoscopic image based on the image type data field of the image file.<br>
2	. The computer-implemented method of claim 1, wherein the header<br>
field includes a track field and the image type data field is located in the track<br>
field.<br>
3	. The computer-implemented method of claim 2, wherein the track<br>
field includes a track-level metadata field and the image type data field is located<br>
in the track-level metadata field.<br>
4. The computer-implemented method of claim 2, wherein the track<br>
field includes a sample table field and the image type data field is located in the<br>
sample table field.<br>
5 . The computer-implemented method of claim 1, wherein the image<br>
type data field includes a flag designating each of the one or more image data<br>
samples as one of the 2D image data and the 3D stereoscopic image data.<br>
6. The computer-implemented method of claim 5 further comprising:<br>
controlling a barrier liquid crystal display (LCD) based on the flag to turn<br>
on if the flag is set as 3D stereoscopic image data and to turn off if the flag is set<br>
as 2D image data.<br>
3. The computer-implemented method of claim 1, wherein the image<br>
type data field includes a sample count field indicating a numerical count of the<br>
image data samples of the same type in sequence.<br>
8. The computer-implemented method of claim 1, wherein the image<br>
type data field includes an entry count field indicating a numerical count of<br>
transitions between the image data samples that are 2D image data and 3D<br>
stereoscopic image data.<br>
 <br>
9. The computer-implemented method of claim 1, wherein the media<br>
data field includes at least one image track.<br>
10. The computer-implemented method of claim 9, wherein the image<br>
track includes a plurality of the 3D stereoscopic image data samples, each of the<br>
plurality of the 3D stereoscopic image data samples representing a different<br>
viewing angle image.<br>
11. The computer-implemented method of claim 10, wherein each of<br>
the plurality of the 3D stereoscopic image data samples represents one of a left<br>
view image and a right view image, and the plurality of the 3D stereoscopic<br>
image data samples are arranged alternating between the left view image and the<br>
right view image.<br>
12. The computer-implemented method of claim 11, wherein each of<br>
the plurality of the 3D stereoscopic image data samples represents a frame.<br>
13. The computer-implemented method of claim 11, wherein two of the<br>
plurality of the 3D stereoscopic image data samples represent a frame, such that<br>
each frame consists of the left view image and the right view image arranged in a<br>
side-by-side manner.<br>
14.	The computer-implemented method of claim 9, wherein the media<br>
data field includes a first image track and a second image track.<br>
15.	The computer-implemented method of claim 14, wherein<br>
the first image track includes a plurality of the 3D stereoscopic image data<br>
samples, each of the plurality of the 3D stereoscopic image data samples<br>
representing a left viewing angle image, and<br>
the second image track includes a plurality of the 3D stereoscopic image<br>
data samples, each of the plurality of the 3D stereoscopic image data samples<br>
representing a right viewing angle image.<br>
16. An apparatus, comprising:<br>
a storage unit to receive and store an image file;<br>
 <br>
a processor to parse a media data field of the image file including one or<br>
more image data samples and to parse a media header field including an image<br>
type data field indicating whether each of the one or more image data samples is<br>
one of 2 dimensional (2D) image data and 3 dimensional (3D) stereoscopic image<br>
data to generate an image corresponding to one of a 2D image and a 3D<br>
stereoscopic image based on the image type data field of the image file; and<br>
a display unit to display the generated image according to the image type<br>
data field of the image file.<br>
17. The apparatus of claim 16, wherein the image type data field<br>
includes a flag designating each of the one or more image data samples as one of<br>
the 2D image data and the 3D stereoscopic image data.<br>
18. The apparatus of claim 17, wherein the display unit includes a<br>
barrier liquid crystal display (LCD), and the processor controls the display unit<br>
based on the flag to turn on the barrier LCD if the flag is set as 3D stereoscopic<br>
image data and to turn off the barrier LCD if the flag is set as 2D image data.<br>
 <br>
<br>
An apparatus includes a storage unit to receive and store an image file, a<br>
processor to parse a media data field of the image file including one or more<br>
image data samples and to parse a media header field including an image type<br>
data field indicating whether each of the one or more image data samples is one<br>
of 2 dimensional (2D) image data and 3 dimensional (3D) stereoscopic image<br>
data to generate an image corresponding to one of a 2D image and a 3D<br>
stereoscopic image based on the image type data field of the image file, and a<br>
display unit to display the generated image according to the image type data field<br>
of the image file.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=tyCIFONxhMTId+DbDPRs0A==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=tyCIFONxhMTId+DbDPRs0A==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="278250-a-method-for-designing-mini-resource-unit-and-transmission-for-a-distributed-resource-unit-in-consideration-of-space-frequency-block-code.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="278252-anti-vibration-apparatus.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>278251</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2501/KOLNP/2010</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>53/2016</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>23-Dec-2016</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>19-Dec-2016</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>09-Jul-2010</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>SAMSUNG ELECTRONICS CO. LTD.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>416, MAETAN-DONG, YEONGTONG-GU, SUWON-SI, GYEONGGI-DO 442-742, KOREA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HWANG, SEO-YOUNG</td>
											<td>#301, 544-10 GOKBANJEONG-DONG, GWONSEON-GU, SUWON-SI, GYEONGGI-DO 441-400, KOREA</td>
										</tr>
										<tr>
											<td>2</td>
											<td>LEE, GUN-III</td>
											<td>#103-1701 WORLD MERIDIAN APT. 297, YEOMCHANG-DONG, GANGSEO-GU, SEOUL 157-040, KOREA</td>
										</tr>
										<tr>
											<td>3</td>
											<td>SONG, JAE-YEON</td>
											<td>#B-805 SEONGBO APT., YEOKSAM-DONG, GANGNAM-GU SEOUL 135-795, KOREA</td>
										</tr>
										<tr>
											<td>4</td>
											<td>KIM, YONG-TAE</td>
											<td>#103-301 SAMSUNG BANGBAE RAEMIAN APT., 2626, BANGBAE 2-DONG, SEOCHO-GU, SEOUL 137-062, KOREA</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 13/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2008/007213</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2008-12-05</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10-2008-0004086</td>
									<td>2008-01-14</td>
								    <td>Republic of Korea</td>
								</tr>
								<tr>
									<td>2</td>
									<td>10-2007-0127564</td>
									<td>2007-12-10</td>
								    <td>Republic of Korea</td>
								</tr>
								<tr>
									<td>3</td>
									<td>10-2008-0000532</td>
									<td>2008-01-03</td>
								    <td>Republic of Korea</td>
								</tr>
								<tr>
									<td>4</td>
									<td>10-2008-0012002</td>
									<td>2008-02-05</td>
								    <td>Republic of Korea</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/278251-system-and-method-for-generating-and-reproducing-image-file-including-2d-image-and-3d-stereoscopic-image by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 22:52:30 GMT -->
</html>
