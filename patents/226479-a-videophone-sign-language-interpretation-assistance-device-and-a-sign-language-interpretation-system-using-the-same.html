<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/226479-a-videophone-sign-language-interpretation-assistance-device-and-a-sign-language-interpretation-system-using-the-same by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 04:10:41 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 226479:A VIDEOPHONE SIGN LANGUAGE INTERPRETATION ASSISTANCE DEVICE AND A SIGN LANGUAGE INTERPRETATION SYSTEM USING THE SAME .</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A VIDEOPHONE SIGN LANGUAGE INTERPRETATION ASSISTANCE DEVICE AND A SIGN LANGUAGE INTERPRETATION SYSTEM USING THE SAME .</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A sign language video presentation device, a sign language video input/output device, and a sign language interpretation system using the same enabling a deaf-mute person to get explanation by sign language while viewing the outer world by freely shifting his/her sight line are provided. The sign language video presentation device includes a display device (12) for displaying a sign language video, a fixing device (13) for fixing the display device (12) in front of the eyes of the deaf-mute person, and a videophone connection device (16) for supplying the display device (12) with a sign language video being received by a videophone terminal (10). The sign language video input/output device includes a sign language imaging camera (14) for picking up the sign language of the deaf-mute person to the sign language video presentation device and a waist fixing device (15) for fixing the sign language imaging camera (14) at the waist of the deaf-mute person, so that the sign language of the deaf-mute person picked up by the sign language imaging camera (14) is supplied to the video telephone terminal (10). The sign language interpretation system (100) provides a sign language interpretation service when a deaf-mute person converses with a non-deaf-mute person by using the sign language video input/output device.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Technical Field<br>
The present invention relates to a videophone sign language interpretation assistance<br>
device and a sign language interpretation system using the same used by a deaf-mute<br>
person when the deaf-mute person remotely obtains sign language interpretation by a<br>
sign language interpreter by using a videophone, and in particular to a videophone sign<br>
language interpretation assistance device and a sign language interpretation system<br>
using the same preferable when a deaf-mute person converses on the road with a non-<br>
deaf-mute person incapable of using sign language.<br>
Background Art<br>
A deaf-mute person who is hearing and speaking impaired wishing to communicate on<br>
the road with a non-deaf-mute person incapable of using sign language has to use<br>
communications in writing or find a person capable of using sign language. Fluent<br>
conversation is difficult by way of communications in writing. Moreover, for<br>
communications using sign language, a very small number of non-deaf persons can use<br>
sign language. These problems present a high barrier in the social life of a deaf-mute<br>
person.<br>
A conversation using sign language over a videophone is available at a practical level<br>
with the advancement of communications technologies. It is possible to provide a sign<br>
language interpretation service via a videophone.<br>
 Fig. 10 is a conceptual diagram showing a case where a deaf-mute person away from<br>
home converses with a non-deaf-mute person incapable of using sign language, by way<br>
of a sign language interpretation service using a prior art videophone terminal such as a<br>
cellular phone equipped with a videophone function. As shown in Fig. 10, a deaf-mute<br>
person A sets a videophone terminal 10 while watching a video display section 10a of<br>
the videophone terminal 10 so that his/her sign language is picked up in an imaging<br>
section 10b. At the same time, the deaf-mute person A asks a non-deaf-mute person B<br>
as a conversation partner to wear a headset 10c for audio input/output of the<br>
videophone terminal 10, then calls a videophone terminal 20 of a sign language<br>
interpreter C in charge of a sign language interpretation service. Before starting sign<br>
language interpretation, the sign language interpreter C sets a videophone terminal 20<br>
while watching a video display section 10a of the videophone terminal 20 so that<br>
his/her sign language will appear in an imaging section 20b, and wears his/her headset<br>
20c for audio input/output.<br>
While the sign language of the deaf-mute person A is not directly understood by the<br>
non-deaf-mute person B, the video of the sign language is picked up by an imaging<br>
section 10b of the videophone terminal 10, transmitted to the videophone terminal 20<br>
and displayed on the video display section 20a, so that the sign language interpreter C<br>
can translate the sign language of the deaf-mute person A into a voice while watching<br>
the video and the voice of the sign language interpreter C is collected by the<br>
microphone of the headset 20c, transmitted to the videophone terminal 10, and output<br>
to the earphone of the headset 10c. The non-deaf-mute person B listens to the voice of<br>
the sign language interpreter C to understand the sign language of the deaf-mute person<br>
A.<br>
While the voice of the non-deaf-mute person B is not directly heard by the deaf-mute<br>
person A, his/her voice is collected by the microphone of the headset 10c of the<br>
videophone terminal 10, transmitted to the videophone terminal 20, and output to the<br>
earphone of the headset 20c. The sign language interpreter C can translate the voice of<br>
the non-deaf-mute person B while hearing his/her voice into the sign language, the sign<br>
language of the sign language interpreter is picked up by the imaging section 20b and<br>
transmitted to the videophone terminal 10 and displayed on the display section 10a.<br>
The deaf-mute person A watches the sign language of the sign language interpreter C to<br>
understand the voice of the non-deaf-mute person.<br>
In this way, by using a videophone, the deaf-mute person A and the non-deaf-mute<br>
person B can communicate with each other by calling the sign language interpreter C,<br>
even when they are away.<br>
While an example has been described where the sign language interpreter uses a same<br>
videophone terminal of the cellular phone type as that used by the deaf-mute person and<br>
the non-deaf-mute person, a sign language interpretation center which provides a sign<br>
language interpretation service may be constructed and a desktop-type videophone<br>
terminal may be used to provide a sign language interpretation service.<br>
However, when the single videophone terminal is used by a deaf-mute person and a<br>
non-deaf-mute person to obtain a sign language interpretation service, the deaf-mute<br>
person must keep watching the display section of the videophone terminal while the<br>
sign language interpreter is translating the voice of the non-deaf-mute person into sign<br>
language, without watching the expression or gesture of the non-deaf-mute person as a<br>
conversation partner at the same time. This makes quick conversation difficult and<br>
presents a problem that a deaf-mute person cannot adequately understand the intention<br>
or feeling of a non-deaf-mute person.<br>
Such a problem of the deaf-mute person's sight line occurs when sign language<br>
interpretation is provided, as well as in many cases where the deaf-mute person is given<br>
explanation with sign language.<br>
For example, assume a case where a deaf-mute person is riding in a sightseeing bus.<br>
During explanation with sign language by a guide, as soon as the guide draws attention<br>
of the passengers to the right (left) by using sign language when the bus is at a historic<br>
site, the deaf-mute person shifts his/her eyes from the sign language, and fails to get the<br>
explanation of the historic site.<br>
Similarly, despite explanation with sign language on a sightseeing spot or in an<br>
exhibition, a deaf-mute person cannot see a real object while listening to the<br>
explanation, so that he/she may fail to appreciate the scene or fail to get an impression<br>
which should be given.<br>
An unimpaired person can hear the explanation given so that he/she can shift his/her<br>
sight line. A deaf-mute person must keep watching the person performing sign<br>
language and is thus handicapped to a great extent.<br>
Thus, a main object of the invention is to provide a videophone sign language<br>
interpretation assistance device and a sign language interpretation system using the<br>
same which allow a deaf-mute person to use a videophone to obtain sign language<br>
interpretation by a sign language interpreter while viewing the outer world by freely<br>
shifting his/her sight line.<br>
Disclosure of the Invention<br>
The invention according to one aspect is a videophone sign language interpretation assistance device used<br>
by a deaf-mute person when the deaf-mute person remotely obtains sign language interpretation by a sign<br>
language interpreter in a conversation with a non-deaf-mute person by using a videophone, the<br>
videophone sign language interpretation assistance device comprising: display means fixed on the head of<br>
a deaf-mute person for displaying the video of a sign language interpreter received by a videophone<br>
terminal before the eyes of the deaf-mute person while allowing the deaf-mute person to view the outer<br>
world including the expression of the conversation partner; hand imaging means fixed at the waist of said<br>
deaf-mute person for picking up the hands of the deaf-mute person to acquire a sign language video; first<br>
communications means for receiving a video signal from the videophone terminal and supplying the<br>
video signal to the display means as well as transmitting a video signal acquired by the hand imaging<br>
means to the videophone terminal; audio input/output means for non-deaf-mute person for<br>
inputting/outputting the voice of a non-deaf-mute person; and second communications means for<br>
receiving an audio signal from the videophone terminal and supplying the audio signal to the audio<br>
input/output means as well as transmitting an audio signal acquired by the non-deaf-mute person audio<br>
input/output means to the videophone terminal; characterized in that the deaf-mute person can obtain sign<br>
language interpretation by a sign language interpreter while freely changing his/her sight line, orientation<br>
or position by using the display device and the hand imaging means and that the non-deaf-mute person<br>
can obtain voice translation by the sign language interpreter by using the audio input/output means.<br>
The invention according to preferred embodiment is the videophone sign language interpretation<br>
assistance device according to first aspect characterized in that at least one of the first communications<br>
means and the second communications means includes radio communications means for performing radio<br>
communications with the videophone terminal and both a deaf-mute person and a non-deaf-mute person<br>
can obtain sign language interpretation by a sign language interpreter while traveling freely.<br>
The invention further preferred embodiment is a sign language interpretation system for providing sign<br>
language interpretation in a conversation between a deaf-mute person and a non-deaf-mute person where<br>
the videophone sign language interpretation assistance device according to first aspect is connected to the<br>
videophone terminal of the deaf-mute person and the videophone terminal of the deaf-mute person and<br>
the videophone terminal of a sign language interpreter are interconnected, characterized in that the sign<br>
language interpretation system comprises terminal connection means equipped with a sign language<br>
interpreter registration table where the terminal number of the videophone terminal used by a sign<br>
language interpreter is registered, the terminal connection means including a function to accept a call<br>
from the videophone terminal of a deaf-mute person, a function to extract the terminal number of the<br>
videophone terminal of a sign language interpreter from the sign language interpreter registration table,<br>
and a function to call the videophone terminal of the sign language interpreter by using the extracted<br>
terminal number of the sign language interpreter, and that connection from the videophone terminal of the<br>
deaf-mute person to the terminal connection means automatically connects to the videophone terminal of<br>
the sign language interpreter.<br>
The invention according to another preferred embodiment is the sign language interpretation system,<br>
characterized in that selection information for selecting a sign language interpreter is registered in the sign<br>
language interpreter registration table, that the terminal connection means includes a function to acquire<br>
the conditions for selecting a sign language interpreter from the videophone terminal of a deaf-mute<br>
person and a function to extract the terminal number of a sign language interpreter who satisfies the<br>
acquired selection conditions for the sign language interpreter from the sign language interpreter<br>
registration table, and that a desired sign language interpreter can be selected from the videophone<br>
terminal of the deaf-mute person.<br>
The invention according to a further preferred embodiment is the sign language interpretation system<br>
according to another preferred embodiment, the sign language interpretation system equipped with a term<br>
registration table for registering a term used during sign language interpretation, characterized in that the<br>
terminal connection means includes a function to register a term in the term registration table by way of<br>
operation from a videophone terminal, a function to select a term to be used from the terms registered in<br>
the term registration table by way of operation from a videophone terminal, a function to generate a telop<br>
of the selected term, and a function to synthesize the generated telop onto a video to be transmitted to the<br>
opponent terminal so as to display, in a telop, on the videophone terminal of the opponent terminal a term<br>
hard to explain with sign language during sign language interpretation or a word hard to pronounce.<br>
As the sign language interpreter registration table includes an availability flag to register whether a<br>
registered sign language interpreter is available, and the connection means references an availability flag<br>
in the sign language interpreter registration table to extract the terminal number of an available sign<br>
language interpreter, it is possible to automatically select an available sign language interpreter, thereby<br>
eliminating useless calling and providing a more flexible and efficient sign language interpretation<br>
system.<br>
The above object, other objects, characteristics and advantages of the invention will be<br>
apparent from the following detailed description of the embodiments of the invention<br>
made referring to drawings.<br>
Brief Description of the Drawings<br>
Fig. 1 is a block diagram of a sign language video input/output device according to an<br>
embodiment of the invention;<br>
Fig. 2 is a system block diagram of a sign language interpretation system according to<br>
an embodiment of the invention;<br>
Fig. 3 is a processing flowchart of a controller in a sign language interpretation system<br>
according to an embodiment of the invention;<br>
Fig. 4 shows an example of a sign language interpreter registration table;<br>
Fig. 5 shows an example of a screen for prompting input of sign language interpreter<br>
selection conditions;<br>
Fig. 6 shown an example of a screen for displaying list of sign language interpreter<br>
candidates;<br>
Fig. 7 is a system block diagram of a sign language interpretation system according to<br>
another embodiment of the invention;<br>
Fig. 8 shows an example of a connection table;<br>
Fig. 9 is a processing flowchart of a controller in a sign language interpretation system<br>
according to another embodiment of the invention; and<br>
Fig. 10 is a conceptual diagram showing a case where a sign language interpretation<br>
service is obtained by using a prior art videophone terminal.<br>
Beat Mode for Carrying Out the Invention<br>
Fig. 1 is a block diagram of a sign language video input/output device according to an<br>
embodiment of the invention. This embodiment shows a case where a deaf-mute<br>
person A who is away from home uses a videophone to call a sign language interpreter<br>
C in order to have a conversation with a non-deaf-mute person B incapable of using<br>
sign language.<br>
In Fig. 1, a numeral 10 represents a videophone terminal for sign language<br>
interpretation recipients (hereinafter referred to as a sign language interpretation<br>
recipients terminal) used by a deaf-mute person A or a non-deaf-mute person B in order<br>
to obtain a sign language interpretation service. A numeral 20 represents a videophone<br>
terminal for sign language interpreters (hereinafter referred to as a sign language<br>
interpreter terminal) used by a sign language interpreter.<br>
The sign language interpretation recipients terminal 10 comprises, as equipment for a<br>
deaf-mute person A, a display device 12 for displaying a sign language video, a fixture<br>
13 for setting the display device 12 in front of the eyes of the deaf-mute person, a sign<br>
language imaging camera 14 for picking up the sign language of the deaf-mute person,<br>
a waist fixture 15 for fixing the sign language imaging camera 14 at the waist of the<br>
deaf-mute person, and a sign language video input/output device including the display<br>
device 12 and a videophone connection device 16 for connecting the sign language<br>
imaging camera 14 to the videophone terminal 10. The sign language interpretation<br>
recipients terminal 10 also comprises, as equipment for a non-deaf-mute person B, a<br>
headset for audio input/output 18.<br>
The sign language interpreter terminal 20 also comprises a video display section 20a for<br>
displaying a video, an imaging section 20b for picking up the sign language of a sign<br>
language interpreter, and a headset for audio input/output 20c.<br>
The display device 12 uses for example a small-sized liquid crystal display having a<br>
sufficient resolution to display a sign language video. The display device 12 enlarges a<br>
video so that a deaf-mute person can recognize sign language displayed with the fixture<br>
13 attached. On the surface of the display device 12 is attached a convex lens so that<br>
sign language displayed on the display device 12 is substantially brought into focus<br>
while the deaf-mute person is viewing the outer world such as the conversation partner<br>
and the scenery. This allows the deaf-mute person to normally recognize the sign<br>
language displayed on the display device 12 while viewing the outer world.<br>
The fixture 13 has a spectacle frame structure which can be fixed to the ears and nose<br>
of a deaf-mute person. Near the frame in front of the eyes of the deaf-mute person is<br>
attached the display device 12 for viewing of sign language without impairing the sight<br>
of the outer world. While the display device 12 is provided in lower left position in<br>
front of the eyes of the deaf-mute person in this example, it may be provided anywhere<br>
as long as it does not impair the sight of the outer world.<br>
While the display devices 12 are provided on the same right and left positions of the<br>
fixture 13 so as to more clearly recognize the displayed sign language in this example,<br>
the display unit 12 may be provided on either side of the fixture 13 as long as the deaf-<br>
mute person can recognize the displayed sign language.<br>
The fixture 13 is used to set the display device 12 in front of the eyes of the deaf-mute<br>
person, so that the display device 12 may be fixed to a hollow frame. Or, a transparent<br>
plate may be provided in a frame and the display unit 12 may be stuck to the<br>
transparent plate. In case the deaf-mute person has myopia, hyperopia, astigmatism, or<br>
presbyopia and thus needs a corrective lens, a corrective lens may be provided in a<br>
frame and the display device 12 may be stuck to the corrective lens.<br>
The sign language imaging camera 14 which may be a small-sized CCD camera is fixed<br>
to the waist fixture 15. In this practice, the sign language imaging camera 14 is set to an<br>
angle of view wide enough to pick up the sign language of the deaf-mute person while<br>
it is fixed to the waist fixture 15.<br>
The waist fixture 15 is for example a belt to fix at the waist of a deaf-mute person. Any<br>
waist fixture may be used whose buckle has an arm for fixing the sign language<br>
imaging camera 14 to allow the sign language imaging camera 14 to be set in an<br>
orientation where the sign language of the deaf-mute person can be picked up. This<br>
makes it possible to stably pick up the sign language of the deaf-mute person by using<br>
the sign language imaging camera 14 even when the deaf-mute person changes his/her<br>
position or orientation.<br>
The videophone connection device 16 is a device which connects the display device 12<br>
and the sign language imaging camera 14 with the external device connecting terminal<br>
of the videophone terminal 10. The videophone connection device 16 supplies a video<br>
signal being received by the videophone terminal 10 to the display device 12 as well as<br>
supplies a video signal from the sign language imaging camera 14 to the videophone<br>
terminal 10. Thus the display device 12 serves as an external video display device of<br>
the videophone terminal 10 and the sign language imaging camera 14 serves as an<br>
external video input device of the videophone terminal 10.<br>
Next, the operation for a conversation between the deaf-mute person A and the non-<br>
deaf-mute person B via the sign language interpreter C by using such a sign language<br>
video input/output device will be described.<br>
The deaf-mute person A wears the fixture 13 and the waist fixture 15 and connects the<br>
videophone connection device 16 to the external device connection terminal of the sign<br>
language interpretation recipient terminal 10.<br>
The non-deaf-mute person B wears the headset 18 and connects the headset 18 to the<br>
audio input/output terminal of the sign language interpretation recipient terminal 10.<br>
In this state, the deaf-mute person A or the non-deaf-mute person B calls the sign<br>
language interpreter terminal 20 used by a sign language interpreter from the sign<br>
language interpretation recipient terminal 10.<br>
The sign language interpreter C accepts the request for sign language interpretation,<br>
sets the sign language interpreter videophone terminal 20 while watching the video<br>
display section 20a so that his/her sign language will appear in the imaging section 20b,<br>
and wears the headset 20a and connects it to the audio input/output terminal of the sign<br>
language interpreter videophone terminal 20.<br>
When the deaf-mute person A performs sign language, its video is picked up by the<br>
sign language imaging camera 14, transmitted from the sign language interpretation<br>
recipient terminal 10 to the sign language interpreter terminal 20, and displayed in the<br>
video display section 20a. The sign language interpreter C can watch the sign language<br>
of the deaf-mute person A displayed in the video display section 20a and translate the<br>
sign language into a voice. The voice translated into by the sign language interpreter C<br>
is collected by the microphone of the headset 20c, transmitted from the sign language<br>
interpreter terminal 20 to the sign language interpretation recipient terminal 10, and<br>
output to the earphone of the headset 18. The non-deaf-mute person B listens to the<br>
voice translated into by the sign language interpreter C to understand the sign language<br>
of the deaf-mute person A.<br>
On the other hand, the voice of the non-deaf-mute person B is collected by the<br>
microphone of the headset 18, transmitted from the sign language interpretation<br>
recipient terminal 10 to the sign language interpreter terminal 20, and output to the<br>
earphone of the headset 20c. The sign language interpreter C listens to the voice of the<br>
non-deaf-mute person B and translates it into sign language. The sign language<br>
translated into by the sign language interpreter C is picked up by the imaging section<br>
20b, transmitted from the sign language interpreter terminal 20 to the sign language<br>
interpretation recipient terminal 10, and displayed on the display device 12. The deaf-<br>
mute person A watches the sign language translated into by the sign language<br>
interpreter C to understand the voice of the non-deaf-mute person B.<br>
The sign language translated into by the sign language interpreter C is displayed on the<br>
display device 12 fixed by the fixture 13 in front of the eyes of the deaf-mute person A.<br>
Thus the deaf-mute person A can converse with the non-deaf-mute person B while<br>
freely shifting his/her sight line. The deaf-mute person A can watch the sign language<br>
translated into by the sign language interpreter C while checking the expression of the<br>
non-deaf-mute person B or watch the sign language translated into by the sign language<br>
interpreter C while checking an object as a target of conversation with the non-deaf-<br>
mute person B. This provides a quick conversation and deeper understanding of the<br>
opponent's intention.<br>
The sign language of the deaf-mute person A is picked up by the sign language imaging<br>
camera 14 fixed with the waist fixture 15 and is thus captured stably even when the<br>
deaf-mute person A changes his/her position or orientation. This assumes the extreme<br>
freedom of the behavior of the deaf-mute person A.<br>
While the fixture 13 for fixing the display device 12 in front of the eyes of a deaf-mute<br>
person uses a spectacle frame structure in the above embodiment, the fixture 13 may<br>
comprise a hair band fixed on the head equipped with an arm for supporting the display<br>
device 12, or may have any structure as long as it can fix the display device 12 in front<br>
of the eyes of the deaf-mute person.<br>
While the sign language imaging camera 14 comprises the waist fixture 15 fixed at the<br>
waist of the deaf-mute person in the above embodiment, the sign language imaging<br>
camera 14 may use any type of fixing means as long as it can pick up the sign language<br>
of the deaf-mute person and provides the same effect of the invention.<br>
While the videophone connection device 16 connects the display device 12 and the sign<br>
language imaging device 14 with the external device connecting terminal of the<br>
videophone terminal 10 via wires in the above embodiment, a radio communications<br>
device for wirelessly transmitting/receiving a video signal may be provided on each of<br>
the external device connecting terminal of the videophone terminal 10, the fixture 13<br>
and the waist fixture 15. This eliminates the need for cabling the videophone terminal<br>
10, the fixture 13, and the waist fixture 15, which provides extreme ease of handling.<br>
In case the videophone terminal 10 comprises a wireless interface conforming to a<br>
Standard such as Bluetooth® for communicating with an external device, a<br>
communications device conforming to the same Standard should be provided on each<br>
of the fixture 13 and the waist fixture 15. By doing so, it is possible to communicate a<br>
video signal without physically connecting anything to the videophone terminal 10 as<br>
long as the communications devices provided on the fixture 13 and the waist fixture 15<br>
are within the service area of the wireless interface of the videophone terminal 10,<br>
which adds to the ease of handling.<br>
A radio communications device for communicating an audio signal by radio may be<br>
provided on the headset 18 for non-deaf-mute persons also to communicate with the<br>
sign language interpretation recipient terminal 10 in a cableless fashion. In this case, an<br>
audio input/output channel may be provided on the videophone connection device 16 to<br>
perform audio communications as well as video signal communications. This allows<br>
the non-deaf-mute person B to move freely as long as he/she is within the service area<br>
of the radio communications device.<br>
As mentioned earlier, in case the videophone terminal 10 comprises a wireless interface<br>
conforming to a Standard to communicate with an external device such as Bluetooth®,<br>
a communications device of the same Standard should be used on the headset 18.<br>
While audio input/output uses a headset for the non-deaf-mute person B also in the<br>
above embodiment, the non-deaf-mute person B does not use sign language so that<br>
he/she may use a hand microphone and an external loudspeaker. For a videophone<br>
terminal of the cellular phone type, he/she may directly hold the main unit with his/her<br>
hands to perform audio communications with the sign language interpreter C.<br>
While the above embodiment describes a videophone terminal of the telephone type,<br>
especially a videophone terminal of a cellular phone type, the invention is not limited<br>
thereto but a videophone terminal of the IP type to connect to the Internet may be<br>
equally used.<br>
While the above embodiment describes a sign language video input/output device<br>
comprising both a display device 12 for displaying a sign language video and a sign<br>
language imaging camera 14 for picking up sign language, a sign language video<br>
presentation device comprising a display device 12 for displaying sign language video,<br>
a fixture 13 for fixing the display device 12 in front of the eyes of a deaf-mute person,<br>
and a videophone connection device 16 for supplying a sign language video being<br>
received by a videophone terminal 10 to the display device 12 may allow a deaf-mute<br>
person to get explanation by sign language via a videophone while viewing the outer<br>
world by freely shifting his/her sight line, which provides the effect of the invention.<br>
A sign language video need not necessarily be received by a videophone but a<br>
dedicated video signal receiver may be used. For example, a transmitter for<br>
transmitting as a sign language video the explanation in the sightseeing guidance or<br>
exhibition on a sightseeing spot may be provided and the sign language video may be<br>
received by a sign language video presentation device. By doing so, same as the audio<br>
guidance or explanation for a non-deaf-mute person, a deaf-mute person gets guidance<br>
or explanation by sign language while freely shifting his/her sight line, and a deaf-mute<br>
person can enjoy sightseeing or a study tour, same as a non-deaf-mute person.<br>
Next, a sign language interpretation system will be described which allows selection of<br>
a sign language interpreter satisfying the object of a conversation in case a deaf-mute<br>
person converses with a non-deaf-mute person by using a sign language video<br>
input/output device according to the invention.<br>
Fig. 2 is a system block diagram of a sign language interpretation system according to<br>
an embodiment of the invention. In this embodiment, a deaf-mute person and a non-<br>
deaf-mute person uses the sign language video input/output device to propose a sign<br>
language interpretation service from a single videophone terminal.<br>
In Fig. 2, a numeral 100 represents a sign language interpretation system installed in a<br>
sign language interpretation center which provides a sign language interpretation<br>
service. The sign language interpretation system 100 interconnects, via a public<br>
telephone line 30, a sign language interpretation recipient terminal 10 used by a deaf-<br>
mute person A and a non-deaf-mute person B and a sign language interpreter terminal<br>
20 used by a sign language interpreter C to provide a sign language interpretation<br>
service in a conversation between the deaf-mute person and the non-deaf-mute person.<br>
In this embodiment, both the sign language interpretation recipient terminal 10 and the<br>
sign language interpreter terminal 20 are videophone terminals of the telephone type<br>
connected to a public telephone line, and in particular wireless videophone terminals of<br>
the cellular phone type which can be carried on the road.<br>
Such a videophone terminal connected to a public line may be ani ISDN) videophone<br>
terminal based on ITU-T recommendation H.320, the invention is not limited thereto<br>
and may use a videophone terminal which employs a unique protocol.<br>
The sign language interpretation system 100 comprises a line interface for the sign<br>
language interpretation recipient terminal to connect to a sign language interpretation<br>
recipient terminal (hereinafter referred to as an I/F) 120 and a line I/F for the sign<br>
language interpreter terminal 140 to connect to a sign language interpreter terminal. To<br>
each I/F are connected a multiplexer/demultiplexer 122,, 142 for<br>
multiplexing/demultiplexing a video signal, an audio signal or a data signal, a video<br>
CODEC (coder/decoder) 124, 144 for compressing/expanding a video signal, and an<br>
audio CODEC 126, 146 for compressing/expanding an audio signal. Each line I/F,<br>
each multiplexer/demultiplexer, and each video CODEC rir each audio CODEC<br>
perform call control, streaming control compression/expansion of a video/audio signal<br>
in accordance with a protocol used by each terminal.<br>
To the video input of the videcr CODEC for the sign language interpretation recipient<br>
terminal 124 is connected a video synthesizer 128 for synthesizing the video output of<br>
the video CODEC for the sign language interpreter terminal 144 and the output of the<br>
telop memory for the sign language interpretation recipient terminal 130.<br>
To the audio input of the audio CODEC for the sign language interpretation recipient<br>
126 is connected the audio output of the audio CODEC for the sign language interpreter<br>
terminal 146.<br>
To the video input of the video CODEC for the sign language interpreter terminal 144<br>
is connected a video synthesizer 148 for synthesizing the video output of the video<br>
CODEC for the sign language interpretation recipient terminal 124 and the output of<br>
the telop memory for the n sign language interpreter terminal 150.<br>
To the audio input of the audio CODEC for the sign language interpreter person<br>
terminal 146 is connected the audio output of the audio CODEC for the sign language<br>
interpretation recipient terminal 126.<br>
The sign language interpretation system 100 is equipped with a sign language<br>
interpreter registration table 182 where the terminal number of a terminal for sign<br>
language interpreters used by a sign language interpreter is registered and includes a<br>
controller 180 connected to each of the line I/Fs 120, 140, multiplexers/demultiplexers<br>
122, 142, video synthesizers 128, 148, and telop memories 132, 152. The sign<br>
language interpretation system 100 provides a function to connect a sign language<br>
interpretation recipient terminal and a sign language interpreter terminal by way of a<br>
function to accept a call from a sign language interpretation recipient terminal, a<br>
function to extract the terminal number of a sign language interpreter from the sign<br>
language interpreter registration table 182, a function to call the extracted terminal<br>
number, and also provides a function to switch a video/audio synthesis method used by<br>
video/audio synthesizers and a function to generate a telop and transmit the telop to a<br>
telop memory.<br>
The contents of each telop memory 132, 152 can be set from the controller 180. When<br>
a sign language interpretation service with a videophone is established, a message for<br>
each terminal is set to each telop memory 132, 152, and a command is issued to each<br>
video synthesizer 128, 148 to select a signal of each telop memory 132, 152. Thus a<br>
necessary message is transmitted to each terminal and a sign language interpretation<br>
connection is established.<br>
In case there is a term which is hard to explain using sign language or a word which is<br>
hard to pronounce in a sign language interpretation service with a videophone, it is<br>
possible to register in advance the term in the term registration table 184 of the<br>
controller 180 in association with the number of the dial pad on each terminal. By<br>
doing so, it is possible to detect a push on the dial pad on each terminal during a sign<br>
language interpretation service, extract the term corresponding to the number of the dial<br>
pad pressed from the term registration table, generate a text telop, and set the text telop<br>
to each telop memory, thereby displaying the term on each terminal.<br>
With this configuration, a term which is hard to explain using sign language or a word<br>
which is hard to pronounce is transmitted to the opponent party by way of a text telop,<br>
thus providing a quicker and more to-the-point sign language interpretation service.<br>
Next, a processing flow of the controller 180 for providing a sign language<br>
interpretation service is shown.<br>
Prior to processing, information to select a sign language interpreter and the terminal<br>
number of a terminal used by each sign language interpreter are registered in the sign<br>
language interpreter registration table 182 of the controller 180 from an appropriate<br>
terminal (not shown). Fig. 4 shows an example of registration item to be registered in<br>
the sign language interpreter registration table 182. The information to select a sign<br>
language interpreter refers to information used by the user to select a desired sign<br>
language interpreter, which includes a sex, an age, a habitation, a specialty, and the<br>
level of sign language interpretation. The habitation assumes a case where the user<br>
desires a person who has geographic knowledge on a specific area and, in this example,<br>
a ZIP code is used to specify an area. The specialty assumes a case where, in case the<br>
conversation pertains to a specific field, the user desires a person who has expert<br>
knowledge on the field or is familiar with the topics in the field. In this example, the<br>
fields a sign language interpreter is familiar with are classified into several categories to<br>
be registered, such as politics, law, business, education, science and technology,<br>
medical care, language, sports, and hobby. The specialties are diverse, so that they may<br>
be registered hierarchically and searched through at a level desired by the user when<br>
selected.<br>
In addition, qualifications of each sign language interpreter may be registered in<br>
advance for the user to select a qualified person as a sign language interpreter.<br>
The terminal number to be registered is the telephone number of the terminal, because<br>
in this example a videophone terminal to connect to a public telephone line is assumed.<br>
In the sign language interpreter registration table 182 is provided an availability flag to<br>
indicate whether sign language interpretation can be accepted. A registered sign<br>
language interpreter can call the sign language interpretation center from his/her<br>
terminal and enter a command by using a dial pad to set/reset the availability flag.<br>
Thus, a sign language interpreter registered in the sign language interpreter registration<br>
table can set the availability flag only when he/she is available for sign language<br>
interpretation, thereby eliminating useless calling and allowing the user to select an<br>
available sign language interpreter without delay.<br>
Fig. 3 shows a processing flowchart of the controller 180. In the sign language<br>
interpretation system 100, a sign language interpretation recipient terminal makes a call<br>
to a telephone number on the line I/F of the sign language interpretation recipient<br>
terminal to call a sign language interpreter terminal, thereby establishing a videophone<br>
connection via sign language interpretation.<br>
As shown in Fig. 3, it is first detected that the line I/F for the sign language<br>
interpretation recipient terminal 120 is called (S100). Next, the calling terminal<br>
displays a screen to prompt input of the selection conditions for a sign language<br>
interpreter shown in Fig. 5 (S102). The sign language interpreter selection conditions<br>
input by the caller are acquired (S104). The sign language interpreter selection<br>
conditions input by the caller are sex, age bracket, area, specialty and sign language<br>
level. A corresponding sign language interpreter is selected based on the sex, age,<br>
habitation, specialty, and sign language level registered in the sign language interpreter<br>
registration table. The area is specified by using a ZIP code and a sign language<br>
interpreter is selected starting with the habitation closest to the specified area. For any<br>
selections, in case it is not necessary to specify a condition, N/A may be selected.<br>
Next, a sign language interpreter with availability flag set is selected from among the<br>
sign language interpreters satisfying the selection conditions acquired referring to the<br>
sign language interpreter registration table 182. The calling terminal displays a list of<br>
sign language interpreter candidates shown in Fig. 6 to prompt input of the selection<br>
number of a desired sign language interpreter (S106). The selection number of the sign<br>
language interpreter input by the caller is acquired (S108) and the terminal number of<br>
the selected sign language interpreter is extracted from the sign language interpreter<br>
registration table and the terminal is called (S110). When the sign language interpreter<br>
terminal has accepted the call (S112), a sign language interpretation service starts<br>
(S114).<br>
In case the sign language interpreter terminal selected in S112 does not accept the call,<br>
whether a next candidate is available is determined (S116). In case a next candidate is<br>
available, execution returns to S110 and the procedure is repeated. Otherwise the<br>
calling terminal is notified as such and the call is released (S118).<br>
While in case the selected sign language interpreter terminal does not accept the call,<br>
the caller is notified as such and the call is released in the above embodiment, a sign<br>
language interpretation reservation table to register a calling terminal number may be<br>
provided and the caller may be notified on a later response from the selected sign<br>
language interpreter to set a sign language interpretation service.<br>
While the sign language interpretation system 100 comprises a line I/F, a<br>
multiplexer/demultiplexer, a video CODEC, an audio CODEC, a video synthesizer, an<br>
audio synthesizer and a controller in the above embodiment, these components need not<br>
be implemented by individual hardware (H/W) but the function of each component may<br>
be implemented based on software running on a computer.<br>
While the sign language interpreter terminal 20, same as the sign language<br>
interpretation recipient terminal 10, is located outside the sign language interpretation<br>
center and called from the sign language interpretation center over a public telephone<br>
line to provide a sign language interpretation service in the above embodiment, the<br>
invention is not limited thereto but part or all of the sign language interpreters may be<br>
provided in the sign language interpretation center to provide a sign language<br>
interpretation service from the sign language interpretation center.<br>
In the above embodiment, a sign language interpreter can present a sign language<br>
interpretation service anywhere he/she may be, as long as he/she has a terminal which<br>
can be connected to a public telephone line. Thus the sign language interpreter can<br>
provide a sign language interpretation service by using the availability flag to make<br>
efficient use of free time. By doing so, it is possible to stably operate a sign language<br>
interpretation service accompanied by a problem of difficult reservation of a sign<br>
language interpreter. In particular, the number of volunteer sign language interpreters<br>
is increasing nowadays. A volunteer who is available only irregularly can provide a<br>
sign language interpretation service by taking advantage of a limited free time.<br>
Fig. 7 is a system block diagram of a sign language interpretation system according to<br>
another embodiment of the invention, This embodiment shows a system configuration<br>
example assuming that each terminal used by sign language interpretation recipient and<br>
a sign language interpreter is an IP (Internet Protocol) type videophone terminal to<br>
connect to the Internet equipped with a web browser.<br>
In Fig. 7, a numeral 200 represents a sign language interpretation system installed in a<br>
sign language interpretation center to provide a sign language interpretation service.<br>
The sign language interpretation system 200 connects a sign language interpretation<br>
recipient terminal 40 used by a deaf-mute person and a non-deaf-mute person and any<br>
of the sign language interpreter terminals used by a sign language interpreter 231, 232,<br>
... via the Internet 50 in order to provide a sign language interpretation service for the<br>
conversation between the deaf-mute person and the non-deaf-mute person.<br>
While the sign language interpretation recipient terminal 40 and the sign language<br>
interpreter terminals 231, 232,... each comprises a general-purpose processing device<br>
(a) such as a personal computer having a video input I/F function, an audio input/output<br>
I/F function and a network connection function, the processing device equipped with a<br>
keyboard (b) and a mouse (c) for input of information as well as a display (d) for<br>
displaying a web page screen presented by a web server 210 and a videophone screen<br>
supplied by a communications server 220, a television camera (e) for imaging the sign<br>
language of a sign language interpreter, and a headset (f) for performing audio<br>
input/output for the sign language interpreter, the processing device has IP videophone<br>
software and a web browser installed in this example, a dedicated videophone terminal<br>
may be used instead.<br>
The videophone terminal connected to the Internet may be an IP videophone terminal<br>
based on ITU-T recommendation H.323, the invention is not limited thereto but may<br>
use a videophone terminal which employs a unique protocol.<br>
The Internet may be of a wireless LAN type. The videophone terminal may be a<br>
cellular phone or a portable terminal equipped with a videophone function and also<br>
including a web access function.<br>
The sign language interpretation system 200 comprises: a communications server 220<br>
including a connection table 222 for setting the terminal addresses of a sign language<br>
interpretation recipient terminal and a sign language interpreter terminal as well as a<br>
function to interconnect the terminals registered in the connection table 222 and<br>
synthesize a video and an audio received from each terminal and transmit the<br>
synthesized video and audio to each terminal; a web server 210 including a sign<br>
language interpreter registration table 212 for registering the selection information,<br>
terminal address and availability flag of a sign language interpreter as mentioned<br>
earlier, as well as a function to select a desired sign language interpreter based on an<br>
access from a calling terminal by using a web browser and set the calling terminal and<br>
sign language interpreter terminal in the connection table 222 of the communication<br>
server 220; a router 250 for connecting the web server 210 and the communications<br>
server 220 to the Internet; and a plurality of sign language interpreter terminals 231,<br>
232,..., 23N connected to the communications server 220 via a network.<br>
Fig. 8 shows an example of a connection table 222. As shown in Fig. 8, the terminal<br>
address of a calling terminal and the terminal address of a sign language interpreter<br>
terminal are registered as a set in the connection table 222. This provides a single sign<br>
language interpretation service. The connection table 222 is designed to register a<br>
plurality of such terminal address set depending on the throughput of the<br>
communications server 220, thereby simultaneously providing a plurality of sign<br>
language interpretation services.<br>
While the terminal address registered in the connection table 222 is an address on the<br>
Internet and is generally an IP address, the invention is not limited thereto but for<br>
example a name given by a directory server may be used.<br>
The communications server 220 performs packet communications using a<br>
predetermined protocol with the sign language interpretation recipient terminal and sign<br>
language interpreter terminal set to the connection table 222 and provides, by way of<br>
software processing, the functions similar to those provided by a<br>
multiplexer/demultiplexer 122, 142, a video CODEC 124, 144, an audio CODEC 126,<br>
146, a video synthesizer 128, 148, in the above sign language interpretation system 100.<br>
With this configuration, same as the sign language interpretation system 100,<br>
prescribed videos and audios are communicated between a sign language interpretation<br>
recipient terminal and a sign language interpreter terminal, and a sign language<br>
interpretation service is established for the conversation between the deaf-mute person<br>
and the non-deaf-mute person.<br>
While the sign language interpretation system 100 uses the controller 180 and the telop<br>
memories 132, 152 to extract a term registered in the term registration table 184 during<br>
a sign language interpretation service based on an instruction from a terminal and<br>
displays the term as a telop on the terminal, the same function may be provided by way<br>
of software processing by the communications server 220 in this embodiment also. A<br>
term specified by each terminal may be displayed as a popup message on the other<br>
terminal by way of the web server 210. Or, a telop memory may be provided in the<br>
communications server 220 so that a term specified by each terminal via web browser<br>
will be written into the telop memory via the web server 210 and displayed as a text<br>
telop on each terminal.<br>
While the sign language interpretation system 100 uses the controller 180 to<br>
interconnect a sign language interpretation recipient terminal and a sign language<br>
interpreter terminal, the connection procedure is made by the web server 210 in this<br>
embodiment because each terminal has a web access function.<br>
Fig. 9 is a processing flowchart of a connection procedure by the web server 210. A<br>
sign language interpretation recipient wishing to receive a sign language interpretation<br>
service accesses the web server 210 in the sign language interpretation center by using<br>
a web browser to log in from a sign language interpretation recipient terminal, which<br>
starts the acceptance of the sign language interpretation service.<br>
As shown in Fig. 9, the web server 210 first acquires the terminal address of a caller<br>
(S200) and sets the terminal address to the connection table 222 (S202). Next, the web<br>
server delivers a screen to prompt input of the selection conditions for a sign language<br>
interpreter similar to that shown in Fig. 5 to the calling terminal (S204). The sign<br>
language interpreter selection conditions input by the caller are acquired (S206).<br>
Next, a sign language interpreter with availability flag set is selected from among the<br>
sign language interpreters satisfying the selection conditions acquired from the sign<br>
language interpreter registration table 212. The web server 210 delivers a list of sign<br>
language interpreter candidates similar to that shown in Fig. 6 to the calling terminal to<br>
prompt input of the selection number of a desired sign language interpreter (S208). The<br>
selection number of the sign language interpreter input by the caller is acquired and the<br>
terminal address of the selected sign language interpreter is acquired from the sign<br>
language interpreter registration table 212 (S210). Based on the acquired terminal<br>
address of the sign language interpreter, the web server 210 delivers a calling screen to<br>
the sign language interpreter terminal (S212). In case the call is accepted by the sign<br>
language interpreter (S214), the terminal address of the sign language interpreter is set<br>
to the connection table 222 (S216) and the sign language interpretation service<br>
starts(S218).<br>
In case the sign language interpreter terminal does not accept the call in S214, whether<br>
a next candidate is available is determined (S220). In case a next candidate is<br>
available, the web server delivers a message to prompt the caller to select another<br>
candidate (S222) to the calling terminal, then execution returns to S210. In case<br>
another candidate is not found, the web server notifies the calling terminal as such<br>
(S224) and the call is released.<br>
While in case the selected sign language interpreter terminal does not accept the call,<br>
the caller is notified as such and the call is released in the above embodiment, a sign<br>
language interpretation reservation table to register a calling terminal address may be<br>
provided and the caller may be notified on a later response from the selected sign<br>
language interpreter to set a videophone conversation.<br>
While the sign language interpreter terminal is located in the sign language<br>
interpretation system 200 of the sign language interpretation center in the above<br>
embodiment, the invention is not limited thereto but some or all of the sign language<br>
interpreter terminals may be provided outside the sign language interpretation center<br>
and connected via the Internet.<br>
In the above embodiment, the configuration of the sign language interpretation system<br>
has been described for a case where a videophone terminal used by a. sign language<br>
interpretation recipient or a sign language interpreter is a telephone-type videophone<br>
terminal connected to a public telephone line and a case where the videophone terminal<br>
is an IP-type videophone terminal connected to the Internet, the telephone-type<br>
videophone terminal and the IP-type videophone terminal can communicate with each<br>
other by arranging a gateway to perform protocol conversion therebetween. A sign<br>
language interpretation system conforming to one protocol may be provided via the<br>
gateway to support a videophone terminal which conforming to the other protocol.<br>
In this way, the sign language interpretation system allows the user to enjoy or provide<br>
a sign language interpretation service anywhere he/she may be, as long as he/she has a<br>
terminal which can be connected to a public telephone line or the Internet. A sign<br>
language interpreter does not always have to visit a sign language interpretation center<br>
but can present a sign language interpretation from his/her home or a facility or site<br>
where a videophone terminal is located, or provide a sign language interpretation<br>
service by using a cellular phone or a portable terminal equipped with a videophone<br>
function.<br>
A person with the ability of sign language interpretation may wish to register in the<br>
sign language interpreter registration table in the sign language interpretation center in<br>
order to provide a sign language interpretation service anytime when it is convenient to<br>
him/her. From the viewpoint of the operation of the sign language interpretation center,<br>
it is not necessary to summon sign language interpreters to the center. This allows<br>
efficient operation of the sign language interpretation center both in terms of time and<br>
costs. In particular, the number of volunteer sign language interpreters is increasing<br>
nowadays. The sign language interpretation service can be provided from a sign<br>
language interpreter's home, which facilitates reservation of a sign language interpreter.<br>
Industrial Applicability<br>
As mentioned above, according to the invention, a deaf-mute person is able to get<br>
explanation by sign language while viewing the outer world by freely shifting his/her<br>
sight line.<br>
WE CLAIM :<br>
1. A videophone sign language interpretation assistance device used by a deaf-mute<br>
person when the deaf-mute person remotely obtains sign language interpretation by a sign<br>
language interpreter in a conversation with a non-deaf-mute person by using a videophone,<br>
said videophone sign language interpretation assistance device comprising :<br>
display means fixed to the head of a deaf-mute person for displaying a video of a sigh<br>
language interpreter received by a videophone terminal in front of the eyes of the deaf-<br>
mute person while enabling the deaf-mute person to view the outer world including the<br>
expression of the conversation partner;<br>
hand imaging means fixed at the waist of said deaf-mute person for capturing images of<br>
the hands of the deaf-mute person to acquire a sign language video;<br>
first communications means for receiving a video signal from said videophone terminal<br>
supplying the video signal to said display means and transmitting a video signal acquired by<br>
said hand imaging means to said videophone terminal;<br>
audio input/output means for non-deaf-mute person for inputting/outputting the voice<br>
of a non-deaf-mute person; and<br>
second communications means for receiving an audio signal from said videophone<br>
terminal supplying the audio signal to said non-deaf-mute person audio input/output means<br>
and transmitting an audio signal acquired by said non-deaf-mute person audio input/output<br>
means to said videophone terminal;<br>
such that the deaf-mute person can obtain sign language interpretation by a sign<br>
language interpreter while freely changing his/her sight line, orientation or position by using<br>
said display device and said hand imaging means and the non-deaf-mute person can obtain<br>
voice translation by the sign language interpreter by using said audio input/output means.<br>
2. The videophone sign language interpretation assistance device as claimed in claim 1<br>
wherein at least one of said first communications means and said second<br>
communications means includes radio communications means for performing radio<br>
communications with said videophone terminal such that both of the deaf-mute person<br>
and the non-deaf-mute person can obtain sign language interpretation by a sign language<br>
interpreter while traveling freely.<br>
3. A sign language interpretation system for providing sign language interpretation<br>
service in a conversation between a deaf-mute person and a non-deaf-mute person<br>
where the videophone sign language interpretation assistance device as claimed in claims<br>
1 or 2 is connected to the videophone terminal of the deaf-mute person and the<br>
videophone terminal of said deaf-mute person and the videophone terminal of a sign<br>
language interpreter are interconnected wherein<br>
said sign language interpretation system comprises terminal connection means including<br>
a sign language interpreter registration table in which the terminal number of the<br>
videophone terminal used by a sign language interpreter is registered.<br>
said terminal connection means including a function to accept: a call from the<br>
videophone terminal of a deaf-mute person, a function to extract the terminal number of<br>
the videophone terminal of a sign language interpreter from the sign language<br>
interpreter registration table, and a function to call the videophone terminal of the sign<br>
language interpreter by using the extracted terminal number of the sign language<br>
interpreter such that connection from the videophone terminal of the deaf-mute person<br>
to said terminal connection means automatically connects to the videophone terminal of<br>
the sign language interpreter.<br>
4. The sign language interpretation system as claimed in claim 3 wherein selection information<br>
for selecting a sign language interpreter is registered in said sign language interpreter<br>
registration table<br>
said terminal connection means includes a function to acquire the conditions for<br>
selecting a sign language interpreter from the videophone terminal of a deaf-mute<br>
person and a function to extract the terminal number of a sign language interpreter who<br>
satisfies said acquired selection conditions for the sign language interpreter from said<br>
sign language interpreter registration table,<br>
such that a desired sign language interpreter can be selected from the videophone<br>
terminal of the deaf-mute person.<br>
5. The sign language interpretation system as claimed in claim 3 or 4 , wherein said sign<br>
language interpretation system includes a term registration table for registering a term<br>
used during sign language interpretation, and<br>
said terminal connection means includes a function to register a term in said term<br>
registration table via operation from a videophone terminal, a function to select a term<br>
to be used from the terms registered in said term registration table via operation from a<br>
videophone terminal, a function to generate a telop of said selected term, and a function<br>
to synthesize said generated telop onto a video to be transmitted to the to the opponent<br>
party;<br>
such that a term that is difficult to explain with sign language during sign language<br>
interpretation or a word that is difficult to pronounce is displayed in a telop on the<br>
videophone terminal of the opponent party.<br>
A sign language video presentation device, a sign language video input/output device,<br>
and a sign language interpretation system using the same enabling a deaf-mute person<br>
to get explanation by sign language while viewing the outer world by freely shifting<br>
his/her sight line are provided. The sign language video presentation device includes a<br>
display device (12) for displaying a sign language video, a fixing device (13) for fixing<br>
the display device (12) in front of the eyes of the deaf-mute person, and a videophone<br>
connection device (16) for supplying the display device (12) with a sign language video<br>
being received by a videophone terminal (10). The sign language video input/output<br>
device includes a sign language imaging camera (14) for picking up the sign language<br>
of the deaf-mute person to the sign language video presentation device and a waist<br>
fixing device (15) for fixing the sign language imaging camera (14) at the waist of the<br>
deaf-mute person, so that the sign language of the deaf-mute person picked up by the<br>
sign language imaging camera (14) is supplied to the video telephone terminal (10).<br>
The sign language interpretation system (100) provides a sign language interpretation<br>
service when a deaf-mute person converses with a non-deaf-mute person by using the<br>
sign language video input/output device.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1jb3JyZXNwb25kZW5jZS5wZGY=" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1leGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDIucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1ncGEucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1yZXBseSB0byBleGFtaW5hdGlvbiByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NjM2LWtvbG5wLTIwMDUtZ3JhbnRlZC1zcGVjaWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">636-kolnp-2005-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="226478-a-surgical-jig-for-bone-surgery.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="226480-drapeable-absorbent-article.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>226479</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>636/KOLNP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>51/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>19-Dec-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>17-Dec-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>13-Apr-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>GINGANET CORPORATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>4-38 MINATO-MACHI 1-CHOME, NANIWAKU, OSAKA-SHI, OSAKA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>SAHASHI, NOZOMU</td>
											<td>26-3, BESSHO-CHO 3-CHOME, KISHIWADASHI, OSAKA 596-0045</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/14</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/JP2003/011758</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2003-09-16</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>JP 2002-269851</td>
									<td>2002-09-17</td>
								    <td>Japan</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/226479-a-videophone-sign-language-interpretation-assistance-device-and-a-sign-language-interpretation-system-using-the-same by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 04:10:42 GMT -->
</html>
