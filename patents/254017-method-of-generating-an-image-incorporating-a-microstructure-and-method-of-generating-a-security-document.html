<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/254017-method-of-generating-an-image-incorporating-a-microstructure-and-method-of-generating-a-security-document by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:08:39 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 254017:METHOD OF GENERATING AN IMAGE INCORPORATING A MICROSTRUCTURE AND METHOD OF GENERATING A SECURITY DOCUMENT</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD OF GENERATING AN IMAGE INCORPORATING A MICROSTRUCTURE AND METHOD OF GENERATING A SECURITY DOCUMENT</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to the field of images incorporating information both at the global level and at the microstructure level and to methods of generating such images. There is provided a method of generating an image incorporating a microstructure, including the steps of obtaining an original image; generating a microstructure; and rendering a region or the whole said original image with said microstructure. According to the invention the operation of generating the microstructure includes an automatic synthesis of microstructure elements as a microstructure dither matrix, from original microstructure shapes, and the synthesis of said dither matrix includes applying mathematical morphology operators to the microstructure shapes. The invention enables truly automatic synthesis of microstructure elements, and permits very efficient generation of images incorporating a microstructure that are difficult to counterfeit. The generated images incorporating a microstructure may advantageously be used as a security feature in documents.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
METHOD OF GENERATING AN IMAGE INCORPORATING A MICROSTRUCTURE<br>
AND METHOD OF GENERATING A SECURITY DOCUMENT<br>
BACKGROUND OF THE INVENTION<br>
The present invention relates generally to images incorporating information both at<br>
the global level and at the microstructure level and to a method of generating such<br>
images. The information at the microstructure level offers, in particular, protection<br>
against counterfeiting and may be used as a security feature in documents. The<br>
invention also relates to documents comprising security features, and to a method of<br>
generating such documents, which may include for example, value bearing<br>
commercial instruments, certificates, coupons and personal identification<br>
instruments.<br>
The term 'images' used herein shall be understood in the broad sense to mean any<br>
visual representation of matter that may be printed or displayed on a display, for<br>
example text, pictures, photographs, drawings and so on.<br>
A microstructure may comprise microstructure elements such as a text, a logo, an<br>
ornament, a symbol or any other microstructure shape. When seen from a certain<br>
distance, mainly the global image is visible. When seen from nearby, mainly the<br>
microstructure is visible. At intermediate distances, both the microstructure and the<br>
global image are visible.<br>
Several attempts have already been made in the prior art to generate images<br>
incorporating information at the microstructure level, where from far away mainly the<br>
global image is visible and from nearby mainly the microstructure is visible. A prior art<br>
method hereinafter called "Artistic Screening" was disclosed in US patent No.<br>
6,198,545 and in the article by V. Ostromoukhov, R.D.Hersch, "Artistic Screening",<br>
Siggraph95, Computer Graphics Proceedings, Annual Conference Series, 1995, pp.<br>
219-228. This method requires however significant efforts by graphic designers in<br>
order to create the microstructure and is limited to bi-level images, i.e. images in<br>
black-white or a single color and white.<br><br>
A prior art method for incorporating a microstructure into an image by computing<br>
color differences is disclosed in European Patent application 99 114 740.6. This<br>
method does not modify the thickness of the microstructure according to the local<br>
intensity of the image.<br>
Another method hereinafter called "Multicolor Dithering" is disclosed in the article by<br>
V. Ostromoukhov, R.D. Hersch, "Multi-Color and Artistic Dithering", Siggraph'99,<br>
Computer Graphics Proceedings, Annual Conference Series, 1999, pp. 425-432. The<br>
method allows to synthesize color images incorporating as screen dots a fine<br>
microstructure capable of representing various shapes such as characters, logos,<br>
and symbols and provides therefore strong anti-counterfeiting features. The<br>
publication also presents an iterative technique for equilibrating a dither array, which<br>
is however slow and cumbersome and does not always converge to yield a satisfying<br>
result. A disadvantage of the aforementioned and other known methods is the<br>
significant effort required to synthesize dither matrices incorporating the desired<br>
microstructure shapes. These efforts require the skills of a computer scientist for<br>
building 3D functions, discretizing them, renumbering the resulting dither values and<br>
applying to them an equilibration process.<br>
An additional method for creating microstructures within an image relies on a large<br>
dither matrix whose successive threshold levels represent the microstructure and<br>
uses standard dithering to render the final image (see Oleg Veryovka and John<br>
Buchanan, Halftoning with Image-Based Dither Screens, Graphics Interface<br>
Proceedings, years 1988-1999, Ed. Scott MacKenzie and James Stewart, Morgan<br>
Kaufmann Publ. or http://www. graphicsinterface.org/proceedings/1999/106/). In this<br>
paper, the authors show how to build a dither matrix from an arbitrary grayscale<br>
texture or grayscale image. They mainly apply histogram equilibration to ensure a<br>
uniform distribution of dither threshold levels. Texture control is obtained by error-<br>
diffusion. However, while their method allows to incorporate text within the<br>
microstructure, the typographic character shapes do not vary according to intensity,<br>
i.e. the character shapes do not become thin or fat depending on the local intensity.<br>
Their method is restricted to black-white or single color target images. The authors<br><br>
do not provide a method to construct a dither matrix starting from a bi-level bitmap<br>
incorporating the microstructure shapes.<br>
A further method of embedding a microstructure within an image is described in<br>
provisional US patent application No. 60/312,170 (filed August 14, 2001, inventor<br>
Huver Hu, available at Web site http://www.amgraf.com/), which teaches how to<br>
transform a grayscale seed image or a bi-level seed image into an array of dot<br>
ranking values (similar to a dither matrix) to be used by a PostScript Interpreter for<br>
synthesizing the final image incorporating the microstructure. This method is however<br>
limited to black-white or to single color output images (bi-level images). In addition,<br>
the seed image is preferably a grayscale image (Fig 10 of patent application No.<br>
60/312,170). With bi-level seed images, the generated microstructure is limited to<br>
rather simple shapes (Fig. 13 of patent application No. 60/312,170), since shapes<br>
grow at increasing darkness levels from a user specified growth center to the shape<br>
given by the bi-level seed image. The shape does not grow beyond 60% darkness:<br>
darker levels are produced by the growth of a separate superimposed geometric<br>
mask (e.g. a triangle, visible on all dark parts of the wedges in FIGS. 2, 12 and 13 of<br>
patent application No. 60/312,170). Furthermore, a manual interactive intervention is<br>
required to transform a seed image into an array of dot ranking values.<br>
Another approach for embedding information within a color image relies on the<br>
modification of brightness levels at locations specified by a mask representing the<br>
information to embed, while preserving the chromaticity of the image (see US patent<br>
5,530, 759). However, since the embedded information is not really used to construct<br>
the global image, it cannot be considered a microstructure. If the embedded<br>
information incorporates large uniform surfaces, the global image may be subject to<br>
significant changes and the embedded information may become visible from a large<br>
distance. In addition, the mask is fixed, i.e. its shape does not vary as a function of<br>
the local intensity or color.<br>
One further related invention disclosed in US patent 5,995,638 teaches a method for<br>
authenticating documents comprising a basic screen made of microstructures and a<br>
revealing screen for creating moire intensity profiles of verifiable shapes. US patent<br><br>
application 09/902445 describes a similar method, where however the basic screen<br>
and the revealing screen may undergo geometric transformations, yielding screens of<br>
varying frequencies.<br>
The incorporation of microstructures in images has applications not only in the field of<br>
generation of artistic images, but also in the field of generation of documents that<br>
require protection against counterfeiting. It is known to incorporate microstructures as<br>
a security feature in certain printed commercial instruments, such as bank notes,<br>
using professional printers and printing techniques on special substrates.<br>
A primary consideration in the generation of printed commercial instruments, such as<br>
bank notes, vouchers, transportation tickets, entertainment event tickets and other<br>
tickets, coupons or receipts bearing or representing a commercial value, is to provide<br>
sufficient safeguards against forgery. The required degree of difficulty in producing a<br>
forgery will depend above all on the value, the duration of validity and the generality<br>
of the commercial instrument. For example, bank notes which are not related to any<br>
specific event and remain valid for many years, require security features that are<br>
extremely difficult to reproduce. On the other hand, tickets of relatively limited<br>
duration, for example transportation tickets, such as train tickets valid on a certain<br>
day for a certain destination, or theatre tickets for a specific show, require lower level<br>
security features, as long as they ensure that the instrument is difficult to reproduce<br>
in the remaining time to the event or requires excessive technical means or human<br>
effort in comparison to the value of the commercial instrument.<br>
Verification of the authenticity of many commercial instruments is often based on a<br>
visual control. Although it is easy to provide commercial instruments with unique<br>
security features, such as encrypted bar codes or other codes, their verification<br>
entails the use of electronic processing means that are unpractical or inefficient in<br>
many situations.<br>
In commercial instruments relying primarily on a visual control of authenticity, a<br>
common security feature is the provision of special substrates that are difficult or too<br>
costly to reproduce for a potential forger in relation to the underlying value of the<br><br>
commercial instrument. A disadvantage of the use of special substrates or special<br>
printing techniques is that they do not allow the generation of commercial instruments<br>
at sites that are not under the issuer's control, whether directly or indirectly.<br>
In view of the wide-spread use of communications networks, such as the internet or<br>
local area networks, there is a demand for enabling the generation of visually<br>
verifiable printed commercial instruments, such as transportation tickets and<br>
entertainment event tickets, at the buyer's site, for example at home with a PC and<br>
standard printer.<br>
In international patent application WO 00/67192, a method of generating a<br>
commercial instrument with certain visually verifiable security features for printing on<br>
a standard printer is described. In the aforementioned application, data relevant to<br>
the commercial instrument are manipulated in accordance with predetermined rules<br>
to generate a pattern which is visually recognizable to an informed person. The<br>
security against forgery of an instrument generated according to the latter method<br>
relies on the potential forger's ignorance of the predetermined rules.<br>
Reliance on predetermined rules has a number of disadvantages. Firstly, the rules<br>
must be communicated to persons responsible for controlling authenticity, which<br>
becomes impractical where many controllers are involved. Secondly, the rules must<br>
result in features that are visually recognizable, with the consequence that a potential<br>
forger could, on the basis of a number of commercial instruments, be able to deduce<br>
the rules with a sufficient degree of approximation to generate forgeries using<br>
different data. In this regard, it should be noted that the relatively sophisticated image<br>
creation and editing software widely available and for use on PC provide the forger<br>
with fairly powerful tools to reproduce images and text manipulated in order to<br>
emulate visually recognizable patterns provided on authentic commercial instruments<br>
on the basis of predetermined rules as described in international application WO<br>
00/67192.<br>
SUMMARY OF THE INVENTION<br><br>
An object of this invention is to provide images incorporating a microstructure that<br>
may be generated efficiently.<br>
Another object of this invention for certain applications is to provide images that are<br>
difficult to counterfeit, in particular for use in documents as a security feature.<br>
It is advantageous in certain applications to provide images incorporating a<br>
microstructure that may be rapidly generated.<br>
It is advantageous in certain applications to provide images incorporating a<br>
microstructure that have a high resolution or a high visual quality.<br>
It is advantageous in certain applications to provide images incorporating a<br>
microstructure, that can be animated.<br>
It is also an object of this invention to provide a method of generating such images,<br>
and a method of generating documents comprising such images. It is also an object<br>
of this invention to provide a computer system to generate such images.<br>
Another object of this invention is to provide a security document, such as a<br>
commercial instrument or certificate, and a method of generation thereof, that is<br>
difficult to forge yet enables visual verification of the authenticity thereof, and that can<br>
be printed with non-professional printing systems, such as standard PC printers, or<br>
displayed on an electronic display.<br>
It is advantageous to provide a security document with security features that are easy<br>
to verify visually by a verifying person, without the need for providing such person<br>
with restricted information on hidden or coded security features or other information<br>
unavailable to uninformed persons.<br>
It is advantageous to provide a method for generating security documents that is able<br>
to generate personal and/or event specific instruments rapidly, for example<br>
comprising information relating to a specific person, destination or event.<br><br>
It is further advantageous to provide a method that enables the printing, or<br>
downloading for display on a portable device screen, of secure commercial<br>
instruments by a customer with access to data processing and database means<br>
through a communications network such as the internet.<br>
Objects of this invention have been achieved by providing a method of generating an<br>
image incorporating a microstructure according to claim 1.<br>
Disclosed herein is a method of generating an image incorporating a microstructure,<br>
including<br>
-	obtaining an original image;<br>
-	generating a microstructure; and<br>
-	rendering a region or the whole said original image with said microstructure;<br>
wherein the operation of generating the microstructure includes an automatic<br>
synthesis of microstructure elements from original microstructure shapes. The<br>
microstructure shapes are in an embodiment described originally in the form of a bi-<br>
level bitmap. The automatic synthesis from bitmaps enables very efficient creation of<br>
images on the fly, which may incorporate different microstructure shapes, for<br>
example based on information specific to the content of a document in which the<br>
image is used. In addition, thanks to a parametrized transformation carried out at<br>
microstructure image rendering time, different instances of the same microstructure<br>
image can be rendered on the fly. An important advantage of the presented<br>
automatic dither array synthesis method is its ability to ensure that the microstructure<br>
incorporated into an image or a security document remains visible at nearly ail<br>
intensity levels (from 10% to 90% darkness in most cases). A high quality and<br>
secure image incorporating a microstructure can thus be generated.<br>
Objects of this invention have been achieved by providing a method of generating an<br>
image incorporating a microstructure according to claim 3.<br>
Also disclosed herein is a method of generating an image incorporating a<br>
microstructure, including<br><br>
-	obtaining an original image;<br>
-	generating a microstructure; and<br>
-	rendering said original image with said microstructure;<br>
wherein the microstructure includes a low frequency microstructure generated from<br>
low frequency microstructure elements, and a high frequency microstructure<br>
generated from high frequency microstructure elements, whereby the low frequency<br>
microstructure elements are larger than the high frequency microstructure elements.<br>
The two levels of microstructure advantageously provides an image that is very<br>
difficult to forge. It is also possible to have further levels of microstructure<br>
incorporated in the image.<br>
The microstructure may be composed of text, graphic elements and symbols. The<br>
microstructure whose shapes vary according to intensity and color protects the<br>
security document's elements such as text, photographs, graphics, images, and<br>
possibly a background motif. Since the security document is built on top of the<br>
microstructure, document elements and microstructure elements cannot be erased or<br>
modified without introducing discontinuities in the security document. Furthermore,<br>
thanks to transformations having the effect of warping the microstructure into<br>
different orientations and sizes across the security document, individual<br>
microstructure elements cannot be simply copied and inserted elsewhere.<br>
The present disclosure also teaches how to equilibrate an image incorporating a<br>
microstructure (hereinafter also called: "microstructure image") or a security<br>
document with the help of a high-frequency dither array. This high-frequency dither<br>
array may incorporate a second level microstructure providing an additional level of<br>
protection.<br>
Further disclosed herein are microstructure images and security documents with a<br>
microstructure rendered in black/white, color, or possibly rendered partly with non-<br>
standard inks, or special inks such as fluorescent inks, phosphorescent inks, metallic<br>
inks, iridescent inks or ultra-violet inks. A mask whose shape expresses a visual<br>
message (e.g. a bold text string or a symbol) may specify the part of the target<br>
document to be rendered with a special ink. Under given observation conditions (e.g.<br><br>
type of light, viewing angle), the special ink is hidden. Under other observation<br>
conditions, the special ink has the effect of making the mask shape (e.g. the text or<br>
symbol) clearly visible. For example at a certain viewing angle, the part covered by<br>
the special ink is hidden and when seen from another angle, it becomes apparent.<br>
Further disclosed herein is an animated microstructure image formed by a<br>
microstructure evolving over time, where from far away mainly the image is visible<br>
and from nearby mainly the evolving microstructure is visible. Such an animated<br>
microstructure image is displayed as a succession of image instances, each image<br>
instance differing from previous image instances by the microstructure evolution. This<br>
microstructure evolution is determined by a parametrized transformation, whose<br>
parameters change smoothly as a function of time.<br>
Further disclosed herein is a method allowing to combine an original image,<br>
respectively a conventionally halftoned original image with a microstructure image,<br>
thereby providing within the target image more or less weight to the microstructure.<br>
This allows to create target images, where thanks to a multi-valued mask, the relative<br>
weight of the microstructure may at certain places, slowly reduce and disappear. In<br>
the case of an animated microstructure image, the mask specifies the part of the<br>
image to be rendered with an animated microstructure and the part which is being left<br>
without microstructure. With a multi-valued mask, the appearance of the<br>
microstructure can be tuned to be strong or on the contrary at the limit of what can be<br>
perceived by a human eye at a normal observation distance. In addition, mask values<br>
evolving over time yield apparent changes in the embedded microstructure<br>
appearance properties such as the visibility, location or spatial extension of the<br>
embedded microstructure within the image.<br>
In a preferred embodiment, original microstructure shapes are embedded within a<br>
bilevel bitmap, and the microstructure is embodied by a dither array. Starting from the<br>
bitmap incorporating the microstructure shapes, the dither array can be automatically<br>
generated. A black-white or color target image (or security document) is synthesized<br>
by dithering an original image with the dither array and by possibly equilibrating the<br>
resulting dithered original image.<br><br>
Also disclosed herein is a computing system for synthesizing security documents<br>
comprising a an interface operable for receiving a request for synthesizing a security<br>
document, a software preparation module operable for preparing data files from<br>
document information and a document production module operable for producing the<br>
security document. The preparation of data files may comprise the generation of an<br>
original document image, of microstructure shapes and possibly of transformation<br>
parameters. Producing the security document system comprises the synthesis of a<br>
microstructure and the synthesis of the security document with that microstructure.<br>
Further disclosed herein is a computing system for synthesizing images comprising<br>
an interface operable for receiving a request for synthesizing a microstructure image<br>
and comprising a software production module operable for producing the<br>
microstructure image. The request comprises an original image and microstructure<br>
shapes. The microstructure image is produced by the production module by first<br>
synthesizing a microstructure and then by synthesizing the microstructure image<br>
incorporating that microstructure.<br>
Further disclosed herein is a computing system capable of displaying a target image<br>
with an embedded microstructure evolving over time, where from far away mainly the<br>
image is visible and from nearby mainly the evolving microstructure is visible. The<br>
computing system comprises a server computing system and a client computing and<br>
display system. The client computing and display system receives from the server<br>
computing system as input data an original color image, microstructure data and<br>
microstructure evolution parameters. The client computing and display system<br>
synthesizes and displays the target image with the embedded microstructure on the<br>
fly.<br>
Other objects of this invention have been achieved by providing a method of<br>
generating a security document according to claims 34 or 35.<br>
Disclosed herein is a method of generating a security document for printing or<br>
display, including the steps of:<br><br>
-	selecting , retrieving or composing an original image;<br>
-	selecting or retrieving information specific to a person, an event or transaction<br>
to which said security document relates;<br>
-	generating a microstructure comprising readable microstructure elements<br>
providing information on said person, event or transaction;<br>
-	rendering said original image with said microstructure image.<br>
The microstructure may advantageously be generated as a dither matrix,<br>
automatically synthesized from microstructure shapes such as bitmap elements.<br>
The microstructure may be rendered with the image by rendering methods described<br>
above or by a halftoning process, whereby the pixels of the dither matrix are<br>
compared with the pixels of the background image and, for example, if the pixel of<br>
the background image has a grey level greater than the inverse grey level of the<br>
dither matrix, then the pixel is printed as white, otherwise it is printed as black. The<br>
rendering of the microstructure and image may further comprise a step of balancing<br>
the halftoned image.<br>
Advantageously, in view of the rendering process, the event or transaction specific<br>
information is extremely difficult to separate out of the background or original image<br>
and is therefore difficult to replace with other information in view of producing<br>
forgeries. The microstructure dither matrix may advantageously comprise letters<br>
and/or numbers, such that the event or transaction specific information may be<br>
provided in the form of words or numbers. This enables information, such as the<br>
date, the price, the destination, the seat number, personal identification, credit card<br>
number, ticket transaction number or any other information specific to the event or<br>
transaction to form part of the microstructure image. The microstructure dither matrix<br>
may also comprise other characters, graphical elements, logos and other special<br>
designs.<br>
The original image may advantageously comprise a photographic representation or<br>
portrait of the customer, in addition to a background image that may be changed from<br><br>
time to time, the images being merged or superposed. The original image may<br>
further comprise written ticket transaction information.<br>
Further objects and advantageous aspects of this invention will be apparent from the<br>
following detailed description of embodiments of this invention with reference to the<br>
accompanying figures, in which:<br>
BRIEF DESCRIPTION OF THE ACCOMPANYING DRAWINGS :<br><br>
FIG. 1A shows a dither matrix, where the microstructure is given by the sequence of<br>
 dither threshold levels, represented in the figure as gray levels;<br>
FIG. 1B shows an enlargement of a part of the dither matrix of FIG. 1A demonstrating<br>
how the dither threshold levels define the microstructure;<br>
FIG. 2 shows uniform intensity patches dithered with the dither matrix of FIG. 1;<br>
FIG. 3 shows an image overlaid with a warping grid;<br>
FIG. 4 shows a mask specifying the parts of the image to be rendered with<br>
microstructures (in black);<br>
FIG. 5 shows one instance of a microstructure image obtained by multicolor dithering<br>
of the original image shown in FIG. 3;<br>
FIG. 6 shows other instances of a microstructure image;<br>
FIG. 7A shows schematically a comparison between an input intensity signal (or<br>
image) P(x) and a dither threshold value G(x) and according to that comparison, the<br>
setting of a foreground or background color;<br>
FIG. 7B shows relative intensities da, db, dc, and dd of colors Ca, Cb, Cc, and Cd;<br>
FIG. 7C shows the conversion of relative intensities da, db dc, and dd of colors Ca, Cb<br>
, Cc, and Cd into corresponding surface coverages;<br>
FIG. 8 shows a diagram of elements useful for creating images with transformed<br>
microstructures;<br>
FIG 9A shows schematically an original image;<br>
FIG. 9B shows schematically a dither matrix paving an original dither matrix space;<br>
FIG. 10A shows a warping grid laid out in a transformed dither matrix space;<br>
FIG. 10B shows the grid of FIG. 10A, warped and laid out on top of the target image;<br>
FIG. 11A shows a mask specifying the part of the target image to be rendered;<br><br>
FIG. 11B shows one instance of the target image rendered with a transformed<br>
microstructure;<br>
FIG. 12 shows the warping transform Tw(x,y) mapping from target image space to the<br>
transformed dither matrix space and the transformation Tt(u,v) mapping from the<br>
transformed dither matrix space into the original dither matrix space;<br>
FIG. 13A shows a rectangular grid and the warped rectangular grid specifying the<br>
warping transform between target image space and transformed microstructure<br>
space;<br>
FIG. 13B shows a microstructure in the transformed microstructure space;<br>
FIG. 13C shows the same microstructure in the target image space, warped by the<br>
warping transformation defined according to FIG. 13A;<br>
FIG. 14A shows a one-dimensional color CMY image with cyan, magenta and yellow<br>
color intensities varying as function of their position on the x-axis;<br>
FIG. 14B shows schematically comparisons between the CMY input intensities of the<br>
image of FIG. 14A and a dither threshold value G(x) and according to these<br>
comparisons, the setting of the resulting basic colors (cyan, magenta and yellow);<br>
FIG. 14C shows the colors resulting from the superposition of the basic colors set<br>
according to the comparison of FIG. 14A;<br>
FIG. 15A shows a one-dimensional color CMY image with cyan, magenta and yellow<br>
color intensities varying as function of their position on the x-axis;<br>
FIG. 15B shows schematically the comparison between the cyan input intensity of<br>
the image of FIG. 15A and a dither threshold value G(x) and according to this<br>
comparison, the setting of the resulting basic cyan color;<br>
FIG. 16A shows a dispersed-dot two-dimensional dither matrix;<br>
FIG 16B shows the one-dimensional dithering of constant mask values p(x) with 1D<br>
dither matrix values D(x) and the resulting spatial distribution of microstructure image<br>
color values C and original image resampled color values Cr;<br>
FIG. 17 show the application of a thinning operator to a bitmap with typographic<br>
character A and the resulting ordered list L1 of coordinate sets S1, S2, S3<br>
representing successively erased discrete contours and the remaining skeleton;<br>
FIGS. 18A and 18B show the thinning steps allowing to obtain the skeleton of<br>
character A;<br>
FIGS. 19A and 19B show the dual bitmap of discrete character A;<br><br>
FIGS. 20A and 20B show the thinning steps allowing to obtain the skeleton of the<br>
dual bitmap;<br>
FIGS. 21 and 22 illustrate the two first steps of the alternated dilation algorithm;<br>
FIG. 23 shows the thinning steps applied to the dual bitmap (dual bitmap thinning);<br>
FIG. 24 shows an example of an image rendered without equilibration;<br>
FIG. 25 illustrates the application of a low-pass filter on the dithered image and the<br>
comparison with the original picture yielding a deltamap;<br>
FIG. 26 is a flow diagram showing the equilibration of a dithered picture by post-<br>
processing;<br>
FIG. 27 shows an example of a high frequency artistic microstructure used to<br>
equilibrate the low frequency microstructure;<br>
FIG. 28 illustrates the low-frequency (LF) dither array, the high frequency (HF) dither<br>
array and the mixed dither array;<br>
FIG. 29A shows the resulting mixed dither array and its application to dither a gray<br>
wedge;<br>
FIG. 29B shows an enlargement of a constant intensity patch dithered with the<br>
resulting mixed dither matrix, at a 50% midtone;<br>
FIG. 30 shows an original image;<br>
FIG. 31 shows the same image dithered only with the low-frequency dither matrix;<br>
FIG. 32 shows the same image, dithered and equilibrated by post processing;<br>
FIG. 33A illustrates dither matrix synthesis by alternated dilation and a corresponding<br>
dithered gray wedge;<br>
FIG. 33B illustrates dither matrix synthesis by dual erosion and a corresponding<br>
dithered gray wedge;<br>
FIG. 34 shows an example of a wedge where from a darkness of 25%, the<br>
background grows and starts surrounding the foreground shape (Hebrew letters),<br>
leaving even at a high darkness a small white gap between shape foreground and<br>
shape background;<br>
FIG. 35A shows a mask incorporating a visual message;<br>
FIG. 35B shows a microstructure image at observation conditions where the mask<br>
shape within the microstructure image is clearly revealed;<br>
FIG. 36 shows a diploma incorporating a microstructure containing the name of the<br>
document holder and the name of the issuing institution;<br><br>
FIG. 37 shows a computing system comprising a preparation software module<br>
operable for the preparation and a production software module operable for the<br>
production of a security document;<br>
FIG. 38 shows a computing system comprising a production software module<br>
operable for the production of a microstructure image;<br>
FIG. 39 shows a server computing system transferring to a client computing and<br>
display system an input color image, a dither matrix, an animation transformation, a<br>
warping transformation, a set of basic colors and a mask layer;<br>
FIG. 40 shows a server system interacting with a designer program or a designer<br>
applet running on a client computer;<br>
FIG. 41 shows a Web page incorporating an animated microstructure image;<br>
FIG. 42 is a schematic illustration of a distributed data processing system for<br>
implementing a method of generating a printed commercial instrument according to<br>
this invention;<br>
FIG. 43 is a flow-chart describing in a simplified manner various steps of a method<br>
according to an embodiment of this invention;<br>
FIG. 44 is a schematic illustration similar to Fig. 42 of an enterprise server system for<br>
implementing a method of generating a printing commercial instrument according to<br>
this invention;<br>
FIG. 45 is a schematic illustration similar to Figures 42 and 42 of a local or stand-<br>
alone server system for implementing a method of generating a printing commercial<br>
instrument according to this invention;<br>
FIG. 46 is a flow-chart illustrating a procedure for creating a commercial instrument<br>
image according to this invention;<br>
FIG. 47 is an illustration of the transformation of a microstructure image to a<br>
microstructure dither matrix (graphically represented);<br>
FIG. 48 is an illustration of a process of rendering a contextual image and a dither<br>
matrix by a halftoning process;<br>
FIG. 49 is an illustration of the balancing of a halftoned microstructure image with the<br>
contextual image to form an image for printing according to this invention;<br>
Figures 50a to 50g are various graphical representations of alphanumerical character<br>
of a microstructure dither matrix according to this invention;<br><br>
FIG. 51 is a flow-chart illustrating a procedure for visual verification of a printed<br>
commercial instrument according to this invention;<br>
FIG. 52 is an illustration of an example of a printed commercial instrument generated -<br>
with a method according to this invention;<br>
FIG. 52a is a detailed view of part of the image of Fig. 52;<br>
FIG. 52b is a detailed view of part of the image of Fig. 52a; and<br>
FIG. 53 is an illustration representing an example of the application of a<br>
microstructure dither matrix on an image.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
The present invention discloses security documents and methods for generating<br>
them, where the document information (text, photograph, graphics, images,<br>
background, hereinafter called "document elements") is formed by microstructures<br>
having shapes varying with the intensity of the document elements. In addition, the<br>
microstructure itself may comprise valuable information, such as the name of the<br>
document holder, the type of the document, its validity or any other information<br>
relevant to check the authenticity of the document (for example a code expressing<br>
open or hidden document information). The same microstructure may continuously<br>
cover several document elements of the same security document. Its continuity<br>
makes therefore the replacement of individual document elements by faked elements<br>
very difficult to achieve.<br>
The methods described in the present invention can also be used to generate artistic<br>
images, graphic designs or posters incorporating at least two layers of information,<br>
one at the global level and one at the local level.<br>
Furthermore, since these methods can generate multiple instances of the same<br>
global image by simply varying the microstructure according to a parameter<br>
dependent transformation, images with different microstructures or images with a<br>
microstructure evolving over time can be synthesized, as disclosed in the parent<br>
patent application US 09/902,227 (filed July 11, 2001, by R.D. Hersch and B.<br>
Wittwer, due assignee: EPFL).<br><br>
In the following description of the invention, documents or document elements to be<br>
rendered with microstructures are called "document images" or simply "images". We<br>
use the words "document", "document image" and "image" interchangeably. A<br>
document, a document image or simply an image are represented, at least partly, as<br>
an array of pixels, each pixel having one intensity value (gray) or several intensity<br>
values (color, e.g. CMY intensities). A target document incorporating a<br>
microstructure, is called "security document", "target image", "microstructure image"<br>
or when the context allows it, simply "image". Within a security document, or within a<br>
target image, at least part of the security document, respectively of the target image,<br>
is formed by a microstructure.<br>
The term "local intensity" is generic and means either one local intensity or several<br>
local intensities as is the case with images having multiple channels such as color<br>
images. Often we use the term "darkness" instead of intensity when examples printed<br>
in black and white are shown. In these cases, the darkness indicates the relative<br>
percentage of the printed part, i.e. the black ink. It is equivalent to the term "basic<br>
color intensity" which also gives the relative percentage of a corresponding basic<br>
color appearing on the support (e.g. a printed basic color).<br>
The term "image" however characterizes not only documents, but also images used<br>
for various purposes, such as illustrations, graphics and ornamental patterns<br>
reproduced on various media such as paper, displays, or optical media such as<br>
holograms, kinegrams, etc... Both input and target images may have a single<br>
intensity channel (e.g. black-white or single color) or multiple intensity channels (e.g<br>
color images). In addition, target images may incorporate non-standard colors (i.e<br>
colors different from cyan, magenta, yellow and black), for example fluorescent inks,<br>
ultra-violet inks as well as any other special inks such as metallic or iridescent inks.<br>
In principle, the Artistic Screening method described in the section "Background of<br>
the invention" can be applied for generating images incorporating information at the<br>
microstructure level. It generates microstructures whose shapes vary according to<br>
the local intensity. However, since Artistic Screening is restricted to bi-level images<br><br>
and requires a significant design effort in order to create contours of artistic screen<br>
elements at different intensities, the preferred method for synthesizing images with<br>
embedded microstructures is based either on standard dithering or on the Multicolor<br>
Dithering method cited above.<br>
Hereinafter, the term dithering without the adjective "standard" or "multicolor" refers<br>
to both standard dithering and Multicolor Dithering. Standard as well as Multicolor<br>
Dithering make use of a dither matrix, whose distribution of dither threshold values<br>
represents the microstructure that will be part of the resulting target image (FIG. 1A<br>
and FIG. 1B). Both standard dithering and Multicolor Dithering reproduce an input<br>
image (also called original or global image) in such a way that when seen from<br>
nearby, mainly the microstructure embedded into the global image is visible, whereas<br>
when seen from far away, mainly the global image is visible (FIG. 5).<br>
Hereinafter the terms "dither matrix" and "dither array" are used interchangeably. A<br>
dither array is composed of "cezls" incorporating "dither threshold values" or simply<br>
"dither values". As known in the art, small and middle size dither matrices tile the<br>
target image plane. However, the dither matrices used in the present invention may<br>
be very large, possibly as large or larger than the target image.<br>
The term "automatic dithering" refers to the full process of (i) creating automatically a<br>
dither matrix from an image or bitmap incorporating the microstructure shapes, (ii)<br>
rendering a target dithered image by either standard dithering or multicolor dithering,<br>
and (iii) possibly applying a postprocessing step for target image equilibration<br>
Some techniques used in the present invention, such as a parameter dependent<br>
transformation Tt specifying instances of the microstructure and a warping<br>
transformation Tw are also used in the parent co-pending patent application US<br>
09/902,227, filed July 11, 2001, by R.D. Hersch and B. Wittwer. However, this parent<br>
co-pending application is centered on the generation of animated microstructure<br>
images, i.e. image sequences and animations, whereas the present invention deals<br>
mainly with still images and security documents incorporating a microstructure.<br>
However, the method for automatic synthesis of dither matrices disclosed in the<br><br>
present invention also greatly facilitate the creating of images with an animated<br>
microstructure.<br>
Standard dithering<br>
Standard dithering converts an intensity into a surface percentage. An intensity P(x)<br>
of foreground color C is compared with a dither threshold value G(x) and according to<br>
the comparison (see FIG. 7A), if P(x) &gt;G(x), the corresponding location x is set-to the<br>
foreground color and if P(x) 
example of a large dither matrix incorporating the microstructure "GET READY"; FIG.<br>
1B shows an enlarged part of it and FIG. 2 represents the reproduction of uniform<br>
single color images at 20%, 40%, 60% and 80% foreground color intensity (the<br>
foreground color is represented as black). For more explanations on standard<br>
dithering, see H.R. Kang, Digital Color Halftoning, SPIE Press and IEEE Press,<br>
chapter 13, 213-231.<br>
Multicolor dithering<br>
Multicolor Dithering is an extension of standard dithering. In Multicolor Dithering, a<br>
color C is rendered by a barycentric combination of several basic colors, for example<br>
the combination of 4 colors Ca, Cb, Cc, and Cd . Their respective relative weights are<br>
da, db, dc and dd (FIG. 7B). Multicolor Dithering converts these relative weights into<br>
relative surface coverages. Multi-color dithering consists of determining the position<br>
of threshold value G in respect to intervals 0..da, da..( da+ db), (da+ db)..( da+ db+ dc),<br>
(da+ db+ dc)..1, (see FIG. 7C). According to the interval within which G is located, the<br>
dithered target image color C(x,y) will take value Ca, Cb , Cc , or Cd (see FIG. 7C,<br>
color values along the x-axis). More precisely, if 0
da+ db), C(x,y) = Gb; if (da+ db)
de)
Cb, Cc, and Cd located at the vertices of a tetrahedron according to their increasing<br>
CIE-LAB lightness values L*.<br><br>
The method for generating images formed by microstructures requires the definition<br>
of the following elements (see FIG. 8):<br>
-	an original image (also called global image);<br>
-	an original microstructure, preferably embodied as a dither matrix;<br>
-	color information necessary for rendering the target microstructure image (optional);<br>
-	an instance dependent transformation Tt specifying instances of the microstructure<br>
evolving as a function of a parameter t;<br>
-	a warping transformation Tw specifying a warping between the instantiated or initial<br>
microstructure and the warped microstructure (optional);<br>
and optionally a mask specifying the global image portions which are to be rendered<br>
with microstructures as well as a possible blending between original image and pure<br>
microstructure image, the blending allowing to specify microstructure appearance<br>
properties such as visibility, position and spatial extension of the microstructure.<br>
The original image is located in an original image space (x',y'), the original<br>
microstructure is located in an original microstructure space (also called original<br>
dither matrix space) (x",y"), the transformed microstructure is located in a<br>
transformed microstructure space (also called transformed dither matrix space)<br>
(u',v'), and the target microstructure image is located in the target microstructure<br>
image space, also simply called target image space (x,y).<br>
Hereinafter, original image (x',y') may stand for original image space (x',y'), original<br>
microstructure (x",y") may stand for original microstructure space (x",y"),<br>
transformed microstructure may stand for transformed microstructure space (u',v')<br>
and target image (x,y) may stand for target image space (x,y).<br>
The microstructure may represent a text, a logo, a symbol, an ornament or any other<br>
kind of visual motif. Furthermore, the microstructure may combine several items, e.g.<br>
several symbols either identical or different, or a freely chosen combination of text,<br>
logos, symbols and ornaments. In the preferred cases of standard dithering and<br>
Multicolor Dithering, the microstructure is defined by a dither matrix whose<br>
succession of dither threshold levels represent the desired visual motifs (FIG. 1B).<br><br>
The parameter dependent geometrical transformation Tt may either be a parameter-<br>
dependent geometric transformation (e.g. translation, rotation, scaling, linear<br>
transformation, non-linear geometric transformation) or any other parametrized<br>
transformation creating from at least one microstructure a transformed microstructure<br>
whose shape varies as a function of one or several parameters. By modifying the<br>
parameters of the transformation Tt, one may create different instances of the same<br>
image and with the same microstructure information. This allows to creating<br>
variations of a security document according to relevant document information, such<br>
as its issued date, its validity or its document category. In a preferred embodiment,<br>
the transformation Tt provides the mapping between the transformed dither matrix<br>
space (u,v) and the original dither matrix space (see FIG. 12).<br>
The warping transformation Tw(x,y) which provides a warping between the target<br>
image space (x,y) and the transformed dither matrix space (u,v) may either be given<br>
by a formula allowing to obtain from a location (x,y) in the target image space the<br>
corresponding location (u,v) in the transformed dither matrix space or by a program<br>
function returning for a given (x,y) coordinate in the final target image space the<br>
corresponding location (u,v) in the transformed dither matrix space (see FIG. 12,<br>
transformation Tw(x,y)). Alternately, the warping transformation may be specified<br>
piece wise, by allowing the designer to specify a rectangular grid of control points<br>
and by allowing him to warp this grid as shown in FIG. 13A.<br>
The color information necessary for rendering the target transformed microstructure<br>
image may comprise either an indication of which original image color layers {Ci} are<br>
to used for rendering the target transformed microstructure image or the specification<br>
of a set of basic colors {Ci} comprising possibly colors different from red, green and<br>
blue, cyan, magenta, yellow, white and black, with which the target image is to be<br>
synthesized. Colors which are members of the set of colors {Cj} used for<br>
microstructure image rendering are called hereinafter "basic colors". A basic color is<br>
a color reproducible on the selected support (paper, plastic, metal, partly or fully<br>
transparent support, optical device). For example on paper, basic colors may be<br>
standard cyan, magenta, yellow and black, non-standard colors, (e.g. a Pantone<br>
color such as color Pantone 265C) and special inks such as metallic inks and<br><br>
iridescent inks (optically variable inks). Furthermore, basic colors also comprise<br>
opaque inks, which may offer a certain protection against counterfeiting attempts<br>
when printed for example on transparent support.<br>
In the case of a mask with more than two levels of intensity, the mask's values<br>
specify a blending between the image rendered with microstructures, for example a<br>
dithered image (standard or multi-color) and the color obtained by simple resampling<br>
of the original image according to the target's image size and resolution. Such a<br>
blending allows to produce less pronounced microstructures.<br>
The method for generating a microstructure target image is formulated below in<br>
general terms so as to encompass all methods capable of generating information at<br>
the microstructure level. However, in a preferred embodiment, either standard<br>
dithering or multicolor dithering is used.<br>
The method for generating a target image with an embedded microstructure<br>
comprises the following steps (see FIG. 8):<br>
(a)	definition of elements required for generating the target image, i.e. an original<br>
image, an original microstructure (in a preferred embodiment, an original dither<br>
matrix), possibly color information specifying a set of basic colors {Ci} used for<br>
rendering the target microstructure image, a parameter-dependent transformation,<br>
possibly a warping transformation and a mask;<br>
(b)	traversing the target image (x,y) pixel by pixel and row by row, determining<br>
corresponding positions in the original image (x',y'), in the transformed microstructure<br>
(preferred embodiment: transformed dither matrix) (u,v), in the original microstructure<br>
(preferred embodiment: original dither matrix) (x",y") and in the mask;<br>
(c)	obtaining from the original image position (x',y') the color Cr to be reproduced,<br>
from the original microstructure (preferred embodiment: original dither matrix) space<br>
position (x",y") the rendering information (preferred embodiment: the dither threshold<br>
value G) and from the current mask position the corresponding mask value p;<br>
(d)	carrying out the target image rendering algorithm (preferred embodiment:<br>
standard dithering or multicolor dithering) and determining output color C, possibly<br>
from the set of basic colors {Ci};<br><br>
(e) according to the mask value p, performing a blending between rendered<br>
(preferred embodiment: dithered) output color C and original image color Cr. In the<br>
case of simple printers capable of printing only a limited number of distinct color<br>
intensities, color Cr is rendered by its equivalent halftone colors Cpqrs obtained by a<br>
conventional halftoning technique (e.g. using blue noise masks, as described in K.E.<br>
Spaulding, R.L Miller, J. Schildkraut, Method for generating blue-noise dither<br>
matrices for digital halftoning, Journal of Electronic Imaging, Vol. 6, No. 2, April 1997,<br>
pp 208-230, section 4 "Blue Noise Matrices for Color Images").<br>
If the mask value p indicates that the present image location does not need to be<br>
rendered with transformed microstructures, then step (c) is modified to directly put<br>
color Cr , respectively its equivalent halftone colors Cpqrs, to be reproduced in the<br>
target image and steps (d) and (e) are skipped. If the mask is inexistent, then the<br>
whole image is reproduced with transformed microstructures.<br>
The original image may be a simple RGB color image stored in any known format.<br>
The microstructure (in a preferred embodiment: the dither matrix) is either<br>
precomputed and ready to use or has been created as described in the sections<br>
below, starting from section "Automatic synthesis of a dither matrix".<br>
Generation of microstructure images by standard dithering<br>
It is however possible to generate images with microstructures by applying the<br>
standard dithering method with a large dither matrix incorporating the microstructure<br>
shapes independently to one or several basic colors. A basic color may be selected<br>
from the set of cyan, magenta and yellow or any other set of colors by which the<br>
image is described. One may apply standard dithering to one, several or all basic<br>
colors. As an example, one may apply standard dithering separately to the cyan,<br>
magenta and yellow layers of an image (FIG. 14A and FIG. 14B) and display the<br>
resulting target image by superposing the dithered cyan, magenta and yellow layers.<br>
The resulting target image will thus be rendered with cyan, magenta, yellow, red<br>
(overlap of yellow and magenta), green (overlap of cyan and yellow), blue (overlap of<br>
cyan and magenta) and black (overlap of cyan, magenta and yellow), see FIG. 14C.<br><br>
Instead of applying standard dithering to cyan, magenta and yellow as in the previous<br>
example, one may also apply standard dithering to one of the color layers, for<br>
example the predominant color layer or the color layer dominant in the image part<br>
where one would like to insert the microstructure. For example, in order to insert a<br>
microstructure in the sky, one may choose to apply standard dithering to the cyan<br>
layer (FIG. 15B) and reproduce the other color layers by conventional methods such<br>
as cluster-dot screening or error-diffusion. In that case, target image pixels are<br>
composed of a cyan color layer obtained by standard dithering with a large dither<br>
matrix incorporating the microstructure shapes and magenta and yellow layers are<br>
reproduced with a conventional halftoning method.<br>
Generation of microstructure images by Multicolor Dithering<br>
In the preferred embodiment of generating microstructure images by Multicolor<br>
Dithering, the method comprises initialization steps, rendering steps and an image<br>
printing step.<br>
The initialization steps comprise (a) the initialization for the color separation of the<br>
original image (e.g. RGB) according to the selected set of basic colors, (b) the<br>
creation of a data structure facilitating the color separation, (c) carrying out the color<br>
separation and associating in a color separation map to each target color image pixel<br>
the basic colors with which it is to be color dithered and their associated basic colors<br>
weights, (d) associating in a warping transform map to each location (x,y) within the<br>
target image space a pointer to the corresponding location in the transformed dither<br>
matrix space according to the user defined warping transformation. Steps (b), (c) and<br>
(d) are useful for speeding up image rendition, especially when applying the same<br>
warping transformation on successively generated target images. As a variant, one<br>
may choose to carry out the color separation and possibly the warping transform<br>
during image rendering.<br>
Several methods for carrying out the color separation exist: one may solve the<br>
Neugebauer equations for the set of output colors (see for example H.R. Kang, Color<br>
Technology for Electronic Imaging Devices, SPIE Optical Engineering Press, 1997,<br><br>
Chapter 2, Section 1, pp. 34-40) or place the output colors in an output color space,<br>
e.g. CIE-XYZ and tetrahedrize that space (see S.M. Chosson, R.D. Hersch, Visually-<br>
based color space tetrahedrizations for printing with custom inks, Proc. SPIE, 2001,<br>
Vol. 4300, 81.-92). In that case, the preferred data structure facilitating the color<br>
separation is a 3D grid data structure pointing to the tetrahedra intersecting individual<br>
grid elements.<br>
In the case that the selected basic colors are located in a rectilinear grid, the<br>
tetrahedrization is straightforward : each cube or rectilinear volume element<br>
comprising 8 vertices can be decomposed into 6 tetrahedra (see H.R. Kang, Color<br>
Technology for Electronic Imaging Devices, SPIE Optical Engineering Press, 1997,<br>
Section 4.4 Tetrahedral interpolation, pp 70-72). If the designer is allowed to choose<br>
any set of basic colors or when non-standard or special inks are used, the<br>
tetrahedrization is slightly more complex, but can be carried out without difficulty with<br>
prior art methods (see for example the book Scientific Visualization : Overviews,<br>
Methodologies, and Techniques, by Gregory M. Nielson, Hans Hagen, Heinrich<br>
Muller, Mueller (eds), IEEE Press, Chapter 20, Tools for Triangulations and<br>
Tetrahedrizations and Constructing Functions Defined over Them, pp. 429-509).<br>
In the case that the color separation is carried out by tetrahedrization, each target<br>
image pixel color is rendered by 4 basic colors, members of the selected set of the<br>
basic colors. For computing the 4 basic colors associated with each target image<br>
pixel (x,y), the color Cr at the corresponding original image location (x',y') is<br>
determined by resampling, i.e. by interpolating between colors of neighbouring<br>
original image pixels (e.g. prior art nearest neighbour or bi-linear interpolation).<br>
Resampled color Cr is used to find the tetrahedron which encloses it. The 4 basic<br>
colors Ca , Cb , Cc , Cd located at the tetrahedron's vertices and their barycentric<br>
weights da , db , dc , dd allowing to render resampled original image color Cr<br>
according to<br>
Cr = da Ca+ db Cb+ dc Cc+ ddCd may be stored, possibly together with original image<br>
resampled color Cr , in a target image color separation map. The basic colors<br>
member of the set { Ca, Cb, Cc, Cd} with the largest relative amounts are called the<br>
dominant colors. Security document elements such as text, graphics or images may<br><br>
be conceived within a limited color gamut so as to ensure that only one or two colors<br>
are predominant across the largest part of that element's surface. This will yield a<br>
microstructure, where the dominant colors are thick in dark regions and thin in<br>
highlight regions of the security document<br>
The image rendering steps are as follows. For rendering successive target image<br>
instances of the target microstructure image, for each target image instance, we<br>
traverse the target image space pixel by pixel by traversing one pixel row after the<br>
other. For each target pixel (x,y), if the target image mask value M(x,y) indicates that<br>
multi-color dithering is to be applied, (e.g. M(x,y)0), we read from the target image<br>
color separation map the basic colors and their respective weights. We determine the<br>
dither threshold value G associated with a target pixel (x,y) by obtaining the pointer to<br>
the corresponding location (u,v) in the transformed dither matrix space, for example<br>
by accessing the warping transform map created in the initialization phase and from<br>
there, by applying the current transformation Tt(u,v), we obtain the current location<br>
(x",y") within the original dither matrix space. The threshold value G(x",y"), the basic<br>
colors Ca , Cb , Cc, Cd and their respective weights da , db , dc , dd are used for<br>
multicolor dithering. Multi-color dithering consists of determining the position of<br>
threshold value G with respect to intervals 0..da , da ..(da+ db), (da+ db)..( da+ db + dc),<br>
(da+ db + dc)..1. According to the interval within which G is located, the dithered target<br>
image color C(x,y) will take value Ca , Cb , Cc , or Cd (see FIG. 7C and section<br>
"Multicolor dithering" above). In the case that standard dithering is used instead of<br>
multi-color dithering, we determine as above the dither threshold value G and use it<br>
to compare it with the intensity of the basic color (or colors) to be dithered and<br>
according to the comparison (see section "Standard dithering" above), use that basic<br>
color (or colors) to render the current target image pixel (x,y). FIG. 15B shows how<br>
dithering can be applied to one of the image's color's, namely cyan.<br>
For rendering different target image instances with the same original image and the<br>
same original microstructure shapes, the parametrized transformation Tt(x,y)<br>
describing the mapping between the transformed dither matrix space and the original<br>
dither matrix space may be modified.<br><br>
In the case of a mask M(x,y) specifying discrete values representing a proportion p<br>
between 0 and 1, the final color Cf (x,y) is a combination of the dithered color C(x,y)<br>
and of the original color Cr (possibly reproduced by a conventional halftoning<br>
method), for example Cf (x,y) = p C(x,y) + (1-p) Cr. Instead of a pixel-wise blending<br>
between the dithered image color C(x,y) and the color Cr (which would be only<br>
feasible on a multi-intensity reproduction device such as a dye sublimation printer), it<br>
is possible to apply a spatial blending, i.e. to ensure that only proportion p of<br>
neighbouring pixels take the dithered color C(x,y) and proportion (1-p) takes the<br>
original conventionally halftoned color values Cr. For this purpose, one can use for<br>
example a spatial dispersed dither matrix D(x,y), e.g. Bayer's 4x4 dither matrix (FIG.<br>
16A) and use thresholds t=0,1,2..15 to decide if a pixel should take the original<br>
conventionally halftoned color value Cr, when p =
when p &gt; t/16. As an illustration of spatial blending, FIG. 16B shows in one-<br>
dimensional space the comparison between the proportion p(x) and the dither values<br>
D(x): where p(x) &gt; D(x), the corresponding segment (black in FIG. 16B) takes the<br>
dithered image color values C(x) and where p(x) 
(white in FIG. 16B) takes the original conventionally halftoned color values Cr(x).<br>
The printing step comprises the printing of the generated microstructure image. It<br>
should be noted that the terms "print" and "printing" in the present disclosure refer to<br>
any process for transferring an image onto a support, including by means of a<br>
lithographic, photographic, electrophotographic, ink-jet, dye-sublimation, engraving,<br>
etching, perforing, embossing or any other process.<br>
As an example let us assume FIG. 9A represents the original color image. FIG. 9B<br>
represents the dither matrix paving the original dither matrix space. The parametrized<br>
transformation Tt maps the transformed dither matrix within an transformed dither<br>
matrix space into the original dither matrix space. FIG. 10A represents a warping grid<br>
laid out over the transformed dither matrix space. In FIG, 10B, the warped grid is<br>
shown in the target image space. The warping transformation Tw allows to map<br>
locations from the target image space into corresponding locations in the transformed<br>
dither matrix space. FIG. 11A shows a mask specifying which part of the original<br>
image needs to be rendered by microstructures. FIG. 11B shows schematically the<br><br>
rendered target color image space, where the part covered by the mask is rendered<br>
with microstructures. The "LSP" microstructure is obtained thanks to the warping<br>
transformation (FIG. 13A) which transforms for example the repetitive microstructure<br>
shown in FIG. 13B into the warped microstructure shown in FIG. 13C.<br>
As real example, FIG. 1. shows a dither matrix comprising the "GET READY"<br>
microstructure shapes. FIG. 2. shows the microstructure obtained by dithering with<br>
constant foreground color intensity levels of 20%, 40%, 60% and 80% (the<br>
foreground color is shown in black, the background is represented by the paper<br>
white). FIG. 3. shows the original image, with a superimposed warping grid (the grid<br>
is made of rectangular elements, with one additional diagonal per rectangle defining<br>
two triangles; the triangles are used for the warping transformation). In the present<br>
case, the warping grid has the effect of shrinking the microstructure at the bottom<br>
and top of the image. FIG. 4 shows the bi-level mask specifying the regions to be<br>
rendered with a microstructure and FIG. 5 shows one instance of the resulting image<br>
comprising a microstructure in the regions specified by the mask. One can easily<br>
perceive the microstructure made of the warped "GET READY" shapes. FIG. 6<br>
shows several instances of the rendered microstructure image, i.e. the rendered<br>
microstructure image at different time points. The display of a microstructure image<br>
where in successive frames, transformations parameters evolve smoothly over time<br>
yields an image with a smoothly evolving microstructure hereinafter called "animated<br>
microstructure image" or "image with embedded microstructure evolving over time" or<br>
simply "image with animated microstructure". The transformation, also called<br>
"animation transformation" moves the microstructure up and down and at the same<br>
time displaces it slowly to the left. The animation transformation Tt of this example<br>
has the form<br>
x" = sx(u+kui)<br>
y"= sy( v+A-cos( (shu)360A ) )<br>
where / is the number of the current target image instance, s is the wave oscillating<br>
speed, ku is the horizontal translation speed, / is the horizontal period of the<br><br>
microstructure wave, A is its amplitude and sx sy represent respectively horizontal<br>
and vertical scaling factors. The cosinusoidal vertical displacement of the<br>
microstructure depends on its current location u, i.e. there is a phase difference in the<br>
vertical displacement of the microstructure at different horizontal locations. Variables<br>
u and v represent respectively the current horizontal and vertical coordinates within<br>
the transformed dither matrix space (u,v). An animated microstructure image may be<br>
incorporated into a support formed by an optical device. Such optical devices may<br>
comprise holograms, kinegrams or diffractive elements.<br>
Use of color and microstructures for strengthening the document protection<br>
Color images can strengthen the security of documents against anti-counterfeiting<br>
attempts by making it more difficult for potential counterfeiters to replace individual<br>
document elements or individual microstructure elements by other faked elements.<br>
One may for example create images with strongly varying colors for the subsequent<br>
synthesis of a target color microstructure image by taking as input image a grayscale<br>
image, overlaying on top of it a grid and assigning to each grid point a chromatic<br>
value in a suitable color space, for example a value for hue (H) and saturation (S) in<br>
the HLS color model (see Foley, Van Dam, Feiner, Hughes, Computer Graphics:<br>
Principles and Practice, Addison-Wesley, 1999, section 13.3.5: The HLS Color<br>
Model, pp 592-595). That grid may be warped as shown in FIG. 13 A. The original or<br>
possibly the warped grid define by interpolation (triangular interpolation within<br>
triangles obtained by subdivision of the grid quadrilaterals into pairs of triangles) one<br>
hue and saturation value for each pixel of the grayscale image. The intensity of each<br>
pixel of the grayscale image may be proportionally mapped onto the lightness (L) of<br>
the HLS space. By transforming back the HLS values of each pixel into RGB and<br>
then possibly into CMY (C=1-R, M=1-G, Y=1-B) one obtains an original color image<br>
with strong color variations, which after subsequent dithering with a dither matrix<br>
incorporating a microstructure will create a target microstructure image with a<br>
strongly varying local microstructure color. Such variations, together with the<br>
necessity of recreating manually microstructure elements made of different relative<br>
amounts of basic colors (as is the case with Multicolor Dithering) make the task of<br><br>
replacing individual document image elements by faked elements a very hard task for<br>
potential counterfeiters.<br>
Use of special inks such as metallic and iridescent inks for strengthening the<br>
document protection<br>
Special inks such as metallic or iridescent inks offer an even stronger protection<br>
against document counterfeiting attempts, since printing devices with at least one<br>
print cartridge with a special ink are not easily accessible to the general public. When<br>
observed from a given viewing angle, a special ink may have one given color,<br>
whereas, when seen from another angle, it may have a dirferent color. This allows to<br>
embed a special ink in the parts of the target image specified by a mask, which when<br>
seen by an observer from a certain angle yields no difference with the surrounding<br>
parts and when seen from another angle conveys a distinct visual message, the<br>
message represented by the mask's shape. One way to embed a special ink into its<br>
surrounding parts is to measure its spectrum with a spectrophotometer according to<br>
a given measuring geometry, e.g. a collimated light source at 45 degrees and the<br>
light sensor at zero degree (which is for example the geometry of the Gretag SPM<br>
500 spectrophotometer). From the measured spectrum, one may obtain the<br>
corresponding CIE-XYZ values (the formula for converting a spectrum to a tri-<br>
stimulus CIE-XYZ value is given in the book: G. Wyszecki and W.S. Stiles, Color<br>
Science, 2nd edition, J. Wiley, 1982, pp. 155-158) characterizing the basic color of<br>
the special ink under these viewing conditions. The basic color of the special ink is<br>
then used for the color separation of the original image (see above the section<br>
"Generation of microstructure images by Multicolor Dithering", paragraph on color<br>
separation by tetrahedrization). Parts of an original input color image to be rendered<br>
with a special ink may be rendered by a combination of that special ink and of other<br>
basic colors, e.g. three other basic colors. This technique allows to render an original<br>
image color either with or without the special ink. When it is rendered with a special<br>
ink, the special ink is, at certain observation conditions (e.g. a certain viewing angle),<br>
hidden within the target image. At a different observation condition (e.g. at a different<br>
viewing angle), the parts covered by the special ink are revealed. As an example,<br>
FIG. 35B shows a document seen from an angle where the parts covered by the<br><br>
special ink (e.g a metallic ink) reveal the message "TILT THE DOCUMENT, THIS<br>
PART SHOULD DISAPPEAR". The enlarged part of FIG. 35B clearly shows that this<br>
message incorporates the underlying microstructure, i.e. the underlying<br>
microstructure is printed at least partly with the special ink.<br>
In a similar manner, one may embed in a document an ultra-violet ink§ which is<br>
hidden in the dithered image under normal viewing conditions (its tri-stimulus CIE-<br>
XYZ values, measured and computed as shown above, allow to embed the ultra-<br>
violet ink in dithered images). But, under ultra-violet light, due to the fluorescence of<br>
ink under ultra-violet light, the parts covered by the ultra-violet ink will be revealed, for<br>
example: "THIS IS A VALID DOCUMENT".<br>
A similar behavior may also be expected from phosphorescent inks: under normal<br>
viewing conditions, the phosphorescent ink is hidden in the dithered image (its tri-<br>
stimulus CIE-XYZ values, measured and computed as shown above, allow to embed<br>
the phosphorescent ink in dithered images). But, when put in the dark after exposure<br>
under light, the parts covered by the the phosphorescent ink will be revealed, for<br>
example, "THIS IS A VALID DOCUMENT"<br>
Use of fluorescent inks for strengthening the document protection<br>
Fluorescent inks can be used to offer a further level of protection since they are not<br>
available on standard desktop printers. Since these inks tend to fade away, these<br>
inks may be used in security documents having a relatively short life time, for<br>
example travel documents, visas, airplane tickets or entrance tickets. The spectrum<br>
of a fluorescent ink can be measured by a photospectrometer, converted into a CIE-<br>
XYZ value which is then used for color separation as explained in the previous<br>
section "Use of special inks". If the fluorescent ink is the dominant ink, its fading<br>
effect may completely distroy the microstructure and therefore considerably modify<br>
the global image. This allow to produce security documents with a limited life time.<br>
Automatic synthesis of a dither matrix<br><br>
In many applications it is important to be able to generate the dither matrix on the fly,<br>
preferably starting from a simple bitmap image (e.g. a black-white image, 1 bit/pixel)<br>
incorporating the microstructure's original shapes. Such applications include the<br>
generation of images with security features for use in security documents, which may<br>
need to be customized and possibly personalized according to their content, i.e. their<br>
microstructure must vary depending on the content of the document which is to be<br>
generated.<br>
In addition several methods are proposed for equilibrating a dithered image, avoiding<br>
large spots with predominantly single color surfaces such as white or biack surfaces.<br>
Symbols, logos, text and other pictorial elements can be represented as bilevel<br>
bitmaps. Bi-level bitmaps can also be obtained by scanning black-white pictorial<br>
elements printed on paper.<br>
Automatic generation of dither matrices from bitmap images relies on the application<br>
of morphological operators (see An introduction to morphological image processing,<br>
by E. Dougherty, chap. 1, 3 , pp. 3-18, 66-75, SPIE Press, 1992). It also relies on re-<br>
ordering operations which are applied to sets of successive pixels obtained during<br>
skeletonization by morphological operators. The input bitmap can be of arbitrary size.<br>
Since the resulting dither array tiles the output image plane, the operators are applied<br>
in a wrap-around manner. Coordinates of pixels are computed modulo the width and<br>
height of the bitmap. Various operators and combinations of operators as well as<br>
various re-ordering operations are applied to the bitmap in order to generate the<br>
target dither array.<br>
Shape thinning for obtaining the foreground dither threshold values.<br>
The first part of the dither array generation method consists in determining the cells<br>
which will contain the foreground dither threshold values (cells with low values are<br>
set first when dithering the picture, they are usually part of the foreground of the<br>
shape). The preferred way to achieve this is to apply a thinning algorithm (FIG. 17)<br>
on the original bitmap and generate a list of pixel coordinates. In the present<br><br>
embodiment, one cell in the dither array corresponds to one pixel in the input bitmap.<br>
We use the thinning algorithm presented in Fundamentals of Digital Image<br>
Processing, by Anil K. Jain, chap. 9, pp. 381-389, Prentice Hall, 1989, which yields<br>
connected arcs while being insensitive to contour noise.<br>
While applying the thinning algorithm to the bitmap, each thinning step i provides a<br>
set Si of pixel coordinates. These pixels form the contour of the current shape,<br>
obtained by the previous thinning step; their set of coordinates is hereinafter called<br>
"contour pixel coordinates". The algorithm stops when the bitmap skeleton is<br>
obtained. The skeleton is the shape obtained when one further thinning step would<br>
have no effect (Figures 18A, 18B). The set of coordinates provided by one thinning<br>
step Si is appended to an ordered list of sets L1 (FIG. 17).<br>
The second part of the array generation consists in determining the cells which will<br>
contain the higher dither threshold values of the dither array (cells with high values<br>
compose the background of a dithered picture). The corresponding pixels are usually<br>
part of the background of the initial bitmap image (e.g. the background of letter A in<br>
FIG. 17). Many morphological operators, as well as combinations of them can be<br>
used to do so. We present two methods, both based on the dilation and thinning<br>
operators, the second method being applied to the inverse bitmap (video inverse),<br>
where black pixels become white and vice-versa. Hereinafter, we call the inverse<br>
bitmap "dual bitmap" (FIGS. 19A, 19B).<br>
To determine the higher dither values of the array, we could repetitively apply a<br>
dilation operator to the original bitmap. Morphological dilation allows to create new,<br>
bolder contours by growing a shape until it fills the entire bitmap space. However,<br>
little holes within the original bitmap are quickly filled while larger areas remain<br>
empty, blurring the contours of the microstructure shape after a few dilation steps.<br>
With methods such as method I and II presented in the next paragraphs, we<br>
constrain the dilation so that small gaps are preserved, while larger empty spaces<br>
are used to grow the shape.<br>
I. Alternated dilation for background dither array values (Fig. 33A).<br><br>
To compute the remaining array cells, we use the dual skeleton. The dual skeleton is<br>
obtained as the result of the thinning (iterative erosion) process applied to the dual<br>
bitmap (FIGS. 20A and 20B). We start the growing process with two patterns which<br>
are the initial bitmap (pattern 1, FIG. 18A) and the dual skeleton (pattern 2, FIG.<br>
20B).<br>
At each step of this alternated dilation method, a dilation operator is applied<br>
consecutively to pattern 1 (FIG. 21), then to pattern 2 (FIG. 22). The dilation operator<br>
takes into account the result of the previous step carried out on the opposite pattern:<br>
in each dilation step, new pixels are marked. If a particular dilation step tries to dilate<br>
a pixel marked by a previous step (superimposed pixels), the dilation is ignored. For<br>
example, when the pixel set by the dilation operator operating on pattern 1 is located<br>
on pattern 2, the pixel is not set. We maintain a set Sm of coordinates of the altered<br>
pixels in the patterns at each step m of the algorithm. Each of these sets is appended<br>
to an ordered list of sets L2 (FIG. 22). For the two first steps, pixels part of the<br>
skeleton and dual skeleton are considered as the sets SO and SI, located in the first<br>
and second place in the list L2. By construction, the content of each set Si is not<br>
ordered.<br>
II. Dual bitmap thinning Cthinning of background)<br>
Another way to determine the position of the background dither array values is to use<br>
only the succession of steps occurring during dual bitmap thinning as a criterion (dual<br>
erosion). This corresponds to the same process as was used to determine the<br>
foreground dither array values (lower values in array), except that the dual bitmap is<br>
given as input to the algorithm, instead of the original bitmap itself (FIG. 23). The<br>
result of this operation is the same as with alternated dilation: we obtain an ordered<br>
list of sets L2, but the dither array shape grows differently. FIG. 33B shows an<br>
example where the background becomes darker according to the succession of<br>
contour pixel coordinates obtained by dual thinning. The few first contour pixel<br>
coordinates obtained by dual bitmap thinning are put at the end of list L2 in order to<br>
ensure that the white outline around the initial bitmap microstructure shape (here an<br><br>
"A") is darkened only at the highest darkness levels. This allows to preserve the<br>
microstructure shape also in very dark parts of the dithered image (90% darkness).<br>
Merging lists of sets of pixel coordinates L1 (foreground) and L2 (background) into<br>
one list L<br>
The two first parts of the array generation (the first part is shape thinning and the<br>
second part is either alternated dilation or dual bitmap thinning) provide two lists of<br>
sets L1 and L2, each set containing pixel coordinates. These lists can now be<br>
merged together by simply appending the second list to the first one, resulting in a<br>
single list L This ordered list of bitmap pixel coordinates is used for creating the<br>
dither array, see section "Renumbering of dither cells". More sophisticated merging<br>
operations can be realised. For example one may equilibrate the distribution of black<br>
pixels in a tile by alternating the sets in the list L, one from L1, one from L2. In FIG.<br>
34 shows another example of creating list L", where the discrete contour pixel<br>
coordinates lists Si' associated to the background are obtained by alternated dilation.<br>
However they are inserted in a different order into list L2 so as to obtain a shape<br>
growing from the background until it reaches the initial foreground bitmap shape<br>
(shape described by pixel contours in list L1). Lists L2 and L1 are merged to form list<br>
L. The particular shape growing behavior shown in FIG. 34 ensures that the<br>
microstructure shape remains apparent even at very dark levels (close to 90%<br>
darkness).<br>
Renumbering of dither cells<br>
The last part of the dither array generation is the creation of a dither array of the size<br>
of the original bitmap and the numbering of the dither array cells according to the<br>
position of corresponding bitmap pixels in list L. To avoid scan lines artefacts and<br>
ensure regular filling of the contours, pixels from the same set Si are picked up in a<br>
random order.<br>
Synthesizing an eguilibrated dither array by combining a low and a high frequency<br>
dither array<br><br>
Since motifs (micro-structure shapes) incorporated in large dither arrays may not be<br>
well balanced, visually disturbing artefacts like alternating light and dark stripes may<br>
appear within the dithered image generated with a dither array obtained by the<br>
methods described above (FIG. 24). This phenomenon is accentuated by dot gain<br>
since middle and dark tones tend to become darker. In order to avoid such artefacts<br>
in the target image, it is important to equilibrate either the dither array or the final<br>
dithered image. Let us first describe one possible method for equilibrating the dither<br>
array based on the combination of the low frequency (LF) dither array synthesized<br>
from the initial bitmap and a high frequency (HF) dither array. The idea is to insert the<br>
high-frequency dither array in the background of the equilibrated dither array (FIG.<br>
28). The term "high-frequency dither array" is used as generic term meaning that its<br>
embedded pattern is of significantly higher frequency than the microstructure<br>
embedded within the low frequency dither array.<br>
In order to generate the equilibrated dither array, we first take the dither values of the<br>
L1 list corresponding to the foreground of the dither array. We then take the L2 list<br>
with the dither values of the background of the dither array. We remove from the L2<br>
list one or several successive contours (e.g. pixel set Sp' and Sp+1') in order to<br>
create a clear separation between the foreground and the background of the<br>
microstructure shape. We associate to the sets of cells which have been removed<br>
from the L2 list (e.g. pixel set Sp' and Sp+1') the highest possible threshold values<br>
yielding the background color even at a high foreground color intensity. In the case<br>
where the foreground is black or respectively has a saturated basic color, this<br>
ensures that these cells remain white even at a high darkness or respectively at high<br>
saturation. We then replace the remaining background cells (e.g. L2 minus the<br>
removed pixel sets Sp' and Sp+1') with the content of a high frequency dither array.<br>
This high frequency dither array, for example the dither array disclosed in US Patent<br>
5,438,431, and in the article (V. Gstromoukhov and R.D. Hersch, "Multi-Color and<br>
Artistic Dithering", Siggraph'99, Computer Graphics Proceedings, Annual Conference<br>
Series, 1999, pp. 425-432) comprises dither levels covering the full range of dither<br>
values. For improved protection the high frequency dither array may also incorporate<br><br>
tiny shapes incorporating a 3rd level of information such as symbols, characters or<br>
numbers (for example the greek frize in FIG. 27, zoomed out on the bottom left).<br>
The dither values of cells belonging to the foreground of the dither array (set L1) are<br>
numbered and scaled in order to also cover the full intensity range or at least a<br>
significant part of it. In order to avoid scan lines artefacts and ensure regular filling of<br>
the contours, cells belonging to a same set Si are picked up randomly and given<br>
successive dither threshold values. FIG. 28 shows the resulting equilibrated dither<br>
array combining a low frequency dither array incorporating the microstructure and a<br>
high-frequency dither array. FIG. 29A shows a wedge and FIG. 29B a uniform<br>
intensity patch rendered with the equilibrated dither array.<br>
When compared with the iterative equilibration technique described in V.<br>
Ostromoukhov, R.D. Hersch, "Multi-Color and Artistic Dithering", Siggraph'99,<br>
Computer Graphics Proceedings, Annual Conference Series, 1999, pp. 425-432, the<br>
presented method is much faster and more accurate, since it equilibrates the dither<br>
matrix specifically for the original image. There is no need to apply the equilibration to<br>
a large set of input intensity levels, neither to carry out several iterations.<br>
Mixing a low-frequency dither array with a high-frequency dither array in this manner<br>
improves local equilibration, but also induces a global tonal modification. In order to<br>
establish the reproduction curve used for tonal correction, one may print patches at<br>
different intensities, measure their density and deduce their surface coverage values,<br>
as is known in the art.<br>
An alternative means of improving the tone reproduction behavior consists in<br>
reassigning dither threshold values to the cells in the list L1 in such a way that for<br>
each intensity level to be reproduced, the number of added foreground pixels<br>
corresponds to the number of pixels that would have been added if the high-<br>
frequency dither array had been used in the area covered by the microstructure<br>
shape. This number can be easily computed by applying a mask corresponding to<br>
the foreground of the bitmap onto the high-frequency dither array and count the<br>
number of pixels reproducing the desired foreground intensity level. By applying this<br><br>
procedure for consecutive discrete intensity levels, we select successive cells within<br>
successive sets of cells from list L1 (again by picking each cell randomly within a<br>
single set Si ) and assign to each of them a dither threshold level corresponding to<br>
 the current discrete foreground intensity level.<br>
Target image equilibration by postprocessing<br>
A second possible method for equilibration compensates the uneven local surface<br>
coverage of the ink in the dithered picture by taking a portion of the foreground pixels<br>
(black) and redistributing it to the background regions (white). It uses a high-<br>
frequency dither matrix to locate the pixels to be redistributed. High-frequency pixel<br>
redistribution takes into account the dot gain and an approximation of the human<br>
visual system transfer function.<br>
For this purpose we need to detect the regions in the dithered picture that do not<br>
match accurately enough the intensity of the original image. As proposed by V.<br>
Ostromoukhov and R.D. Hersch, (in "Multi-Color and Artistic Dithering", Siggraph'99,<br>
Computer Graphics Proceedings, Annual Conference Series, 1999, pp. 425-432), we<br>
simulate the dot gain by adding to each pixel the darkness or color intensity value<br>
representing the dot grain of neighbouring pixels, e.g. horizontal and vertical<br>
neighbours contribute with a weight of 20% and diagonal neighbours contribute with<br>
a weight of 5%. We then apply a Gaussian low-pass filter approximating to some<br>
extent the low pass behaviour of the human visual system transfer function (HVS<br>
filter). The resulting filtered dithered image, hereinafter called "perceived dithered<br>
image" is compared with the original image and the difference image, called<br>
"deltamap" is then used for equilibrating the target image. The radius of the low-pass<br>
filter depends on the viewing distance and the resolution of the picture.<br>
Based on the estimation of about 30 cycles per degree for the cutoff frequency of the<br>
human visual system (Handbook of perception and human performance, L. Olzak, J.<br>
P. Thomas, chap. 7, pages 7-1 to 7-55, J. Wiley, 1986), we approximate the human<br>
visual system transfer function (hereinafter called "HVS filter") by the Gaussian<br>
function F(q) = Exp(-pq2), where the unit on the frequency axis (q-axis) corresponds<br><br>
to the cutoff frequency of 30 cycles per degree. The corresponding impulse<br>
response, i.e. the inverse Fourier Transform of F(q), is also a Gaussian function,<br>
f(r)=Exp(-pr2), whose unit (r-axis) corresponds to 1/30 degree of visual angle. To<br>
produce the discrete convolution kernel, the Gaussian impulse response function is<br>
sampled on a 5s x 5s grid, where the standard deviation s = 1/Sqrt(2p). For different<br>
printing resolutions as well as for different observation distances (e.g. for posters to<br>
be observed from far away) the discrete convolution kernel needs to be recomputed<br>
accordingly.<br>
For example, at 1200 pixels per inch and at an observation distance of 25 inches the<br>
visual angle formed by one inch is in degrees a=(1/25 * 360/2p). A visual angle of<br>
1/30 of degrees, where screen element details should disappear, corresponds to<br>
(1200/a)*(1/30)= 17.45 pixels and s = 1/Sqrt(2p) corresponds on our pixel grid to<br>
17.45/Sqrt(2p) = 7 pixels. A convolution kernel of size 5s x 5s corresponds in this<br>
example to a kernel of size 35x35 pixels.<br>
After applying dot gain simulation, human visual system filtering and comparison<br>
between the original and the perceived dithered image, we obtain a delta map<br>
Dm(x,y), composed of the pixel by pixel intensity differences between the initial input<br>
image P(x,y) and the perceived dithered image H'(x,y) (what is "seen"). Negative<br>
deltas indicate that the dithered picture is "seen" too bright locally, while positive<br>
deltas indicate that it is "seen" too dark. For convenience, the deltamap is computed<br>
as 2's complement 8 bit numbers. FIG. 25 shows a schematic view of the steps<br>
necessary to obtain the delta map. In the resulting printed deltamap, positive values<br>
are expressed by dark intensity levels (black=0 means no change, 1 means add 1,<br>
etc..) and negative values are expressed by high intensity levels (white=255 means<br>
subtract 1, 254 means subtract 2, etc.. on a 256 intensity level range).<br>
We need to add a number of black pixels in the dithered image to compensate for a<br>
too high brightness, and remove a number of black pixels where the picture is seen<br>
too dark. In our delta map, positive values can be seen as the proportion of white to<br>
be added to black areas to reach the desired local gray level. Negative values<br>
represent the proportion of white to be removed from white areas.<br><br>
The delta map Dm(x,y) is dithered with a high frequency dither array resulting in a<br>
dithered deltamap Dmd(x,y). This dithered deltamap Dmd(x,y) is composed with the .<br>
dithered image H(x,y) as follows. In areas where the delta map is positive, i.e. in<br>
black areas where black pixels need to be removed, the dithered deltamap Dmd(x.y)<br>
is ORed with the dithered image H(x,y). New white pixels will appear in the black<br>
parts of the dithered image. In areas where the delta map Dm(x,y) is negative, i.e. in<br>
white areas where black pixels need to be added, the dithered deltamap Dmd(x.y) is<br>
ANDed with the dithered image H(x,y) yielding the final equilibrated dithered image<br>
Q(x,y). New black pixels will appear in the white parts of the dithered image.<br>
In order words, as shown in FIG. 26, in a preferred embodiment the following logical<br>
operations are performed:<br>
Dm(x,y) = P(x,y) - H'(x,y), where the minus is the 2's complement minus on 8bit<br>
values<br>
If H(x,y) = 0 (black), Q(x,y) = H(x,y) OR Dmd(x,y);<br>
If H(x,y) = 1 (white), Q(x,y) = H(x,y) AND Dmd(x,y).<br>
To provide adequate equilibration, the high frequency pattern present in the high-<br>
frequency dither array needs to be several times smaller than the low frequency<br>
pattern. Any dither array comprising very small clusters may be used. In the example<br>
shown in FIG. 32 (original in FIG. 30, dithered with only the low-frequency dither<br>
matrix in FIG. 31), we use as high frequency dither matrix the rotated dispersed<br>
dither matrix proposed by V. Ostromoukhov, R. D. Hersch and I. Amidror ("Rotated<br>
Dispersed Dither: a New Technique for Digital Halftoning", Siggraph'94, Computer<br>
Graphics Proceedings, Annual Conference Series, pp. 123-130, 1994) since it<br>
exhibits a semi-clustering behaviour at mid-tones. It is therefore less sensible to dot<br>
gain than dispersed-dot halftones. The high-frequency dither array may also<br>
incorporate a second level microstructure made of artistic patterns or tiny shapes<br>
such as symbols, characters or numbers (greek frize in FIG. 27).<br>
It is important that the dot gain of the high-frequency dither array be correctly<br>
compensated. We can establish its tone reproduction behavior by printing a series of<br><br>
halftoned patches for different gray levels and measure their density. Using the<br>
Murray-Davis formula (H.R. Kang, Color Technology for Electronic Imaging Devices,<br>
SPIE Optical Engineering Press, 1997,section 2.2: Murray-Davis equation, pp 42-43),<br>
we determine the actual proportion of black on paper for each patch and compute the<br>
tone reproduction curve. During the equilibration process, the tone reproduction<br>
curve is used in order to compute for the deltamap values Dm(x,y) tone-corrected<br>
deltamap values Dm'(x,y) which are dithered to yield the dithered deltamap Dmd(x.y).<br>
Equilibration by postprocessing is carried out in a single pass and is specific to the<br>
desired target image. It is therefore faster and more accurate than the iterative<br>
equilibration technique described in V. Ostromoukhov, R.D. Hersch, "Multi-Color and<br>
Artistic Dithering", Siggraph'99, Computer Graphics Proceedings, Annual Conference<br>
Series, 1999, pp. 425-432.<br>
Automatic production of security documents<br>
It is possible to run a computer program operable for creating an original document<br>
image according to information related to said document, such as for example the<br>
type of the document, the name of the document holder, the issuing institution, the<br>
validity of the document, the background to be inserted into the document, etc..<br>
Furthermore, a slightly different computer program may also automatically generate<br>
the bitmap incorporating the microstructure shapes by inserting text or graphics into a<br>
bi-level bitmap according to document related information. These computer programs<br>
may carry out operating system calls in order to embed text, graphics and images<br>
into a document image, respectively a bitmap and save that document image or<br>
respectively bitmap as a file on the computer running the program.<br>
Such computer programs can be embedded into a preparation software module<br>
capable of generating both the original document image and the bitmap incorporating<br>
the microstructure shapes according to the information related to the target document<br>
to be created.<br>
With such a preparation software module, a complete automatic security document<br>
production chain may be established: upon a specification of a security document by<br><br>
document related information the following steps allow to generate a security<br>
document:<br>
(a)	producing an original document image comprising said document related<br>
information;<br>
(b)	producing a bitmap incorporating microstructure shapes expressing said<br>
document related information;<br>
(c)	synthesizing a dither array with said bitmap;<br>
(d)	dithering the original document image with the synthesized dither array, thereby<br>
generating the security document, where both the global document level and the<br>
microstructure level incorporate document related information.<br>
(e)	equilibrating the dithered original image thereby producing the target security<br>
document<br>
Step (e) is optional and applied for improving the quality of the resulting target<br>
security document. The generated security documents are fully personalized, since<br>
both the original document image and the microstructure incorporate the document<br>
related information (e.g. the document shown in FIG. 36).<br>
Generation of security documents via a global communications network<br>
Referring to Fig. 42, a web-based server system 2 for generating security documents<br>
such as commercial instrument printable files, is accessible via a global<br>
communications network such as the internet 4 by a user or a customer at a client<br>
site 6, having a printer 8 and a personal computer 10 or other computing means<br>
connected to the communications network 4. The server system may be a<br>
distributed system comprising servers or other data processing systems or<br>
databases at a single site, or at different sites interconnected with a communications<br>
network such as the internet, an intranet, or a local area network. The web-based<br>
server system 2 comprises a web server 12 including, or connected to, a customer<br>
database 14 in which information on customers is stored, a payment server or<br>
system 16, for example for effecting credit card payments, bank transfers and the<br>
like, and a production server 18 for performing calculations and other operations to<br>
create ticket images and package data files for transmission and printing. The<br><br>
production server may be interconnected to a context database 20 for storing<br>
background images and other information concerning the commercial instrument.<br>
It will be understood by skilled persons in the art that the configuration of the above<br>
described server system may be modified without departing from the scope of this<br>
invention, the various servers and databases being depicted merely as examples in<br>
order to understand the function of a possible server system for generating printed<br>
commercial instruments according to this invention.<br>
The server system for creating the commercial instrument may also be a proprietary<br>
system or an enterprise server system as illustrated in Fig. 44, whereby the user<br>
accesses the enterprise server system 2' through a local area network or direct<br>
connection from a terminal 10'. In this configuration, a user would typically be the<br>
issuer of the commercial instrument and the payment transaction would occur<br>
between the purchaser of the commercial instrument and the user.<br>
Referring to Fig. 45, a local or stand-alone server system 2" is shown incorporating in<br>
a single data processing system the functions of the enterprise server system 2' of<br>
Fig. 44.<br>
Referring to Fig. 43, a flow-chart generally illustrating the generation of a commercial<br>
instrument, such as a printed ticket, with a data processing system such as the<br>
server system described above, is shown. Initial operations include connection of the<br>
customer or user to the server system 2, 2', 2", and subsequently selection and<br>
specification of the product. For example, if the commercial instrument is a<br>
transportation ticket, the customer may specify the journey departure place and<br>
destination, the travel date and/or time, the class, the seat, etc. The initial steps may<br>
also comprise an identification procedure, particularly if customer information from a<br>
customer database is to be retrieved for inclusion in the printed commercial<br>
instrument, in which case the identification procedure may be after or before product<br>
selection and specification. An identification procedure may also be required where<br>
commercial instruments are issued only to known or identified persons. The term<br><br>
"product" shall be understood herein to generally mean the event, service, or item<br>
being purchased or transacted to which the commercial instrument relates.<br>
Once the product has been selected and specified, a payment order is created, for<br>
example using credit card, bank transfer or cash card information supplied by the<br>
customer to the server system which then logs the payment order and/or sends a<br>
provisional payment order to a payment system 16. The transaction amount will not<br>
be debited according to the payment order until confirmation that the ticket has been<br>
sent to the customer site.<br>
After product selection and specification in step 24, a ticket image printing file is<br>
generated in the production server 18 using information received from the web server<br>
portion 12 and, as the case may be, the customer database 14 and the context<br>
database 20, such that product information, personal information and contextual<br>
information may be included in the ticket image generation process.<br>
It may be noted that ticket image generation may be performed in parallel, before or<br>
after generation of the provisional payment order (step 28). The ticket image file is<br>
then packaged and preferably compressed such that it can be efficiently transmitted<br>
over a communications network such as the internet, and printed on a standard PC<br>
printer. The ticket image may for example be received on the user's or customer's<br>
computer screen as a page displayed in a web browser, or by e-mail, for example in<br>
commonly used text and image formats such as PDF, GIF, PNG, and the like that<br>
enable printing on personal PC printers with the appropriate PC software. The<br>
sending of the commercial instrument image file to the user's or customer's computer<br>
or terminal also generates a confirmation to execute the payment order in waiting.<br>
It will be apparent from the above that the security of the commercial instrument does<br>
not reside in the inability to print or copy numerous tickets, since the customer<br>
receives the printing file, or could simply copy a printed instrument. Security against<br>
the use of multiple copies is provided by personal or unique information. For<br>
example, for a transportation ticket, the date, destination and a photographic portrait<br>
of the bearer of the instrument will make the commercial instrument unusable by<br><br>
other persons and usable only during the period of validity by the bearer. For<br>
entertainment events, such as theatre, sports, cinema, or similar events, it would not<br>
always be necessary to include personal information if for example unique<br>
information such as a seat number, in conjunction with a date and time or venue,<br>
would be included in the ticket image.<br>
In Fig. 46, a flow-chart illustrating various steps or operations in the generation of a<br>
ticket image according to this invention is shown.<br>
In the specific example illustrated in Fig. 46, a train ticket for the journey from Milano<br>
Central Station to Berlin Zoological Garden, in second class, and valid on a specific<br>
day, is described. The product information 38 will have been specified by the user,<br>
who will also have provided customer information 40 that enables his/her<br>
identification and retrieval of further customer information from the customer<br>
database 14. The customer database may for example include a library of<br>
photographic portraits of customers. On the basis of the customer identity, the<br>
corresponding portrait of the customer is retrieved from the customer database for<br>
inclusion in the ticket image, as will be described further on.<br>
The product information 38 is sent to the production server or production server<br>
portion of the server system and used to select a background image 44 from the<br>
context database 20 and a microstructure pattern or shape 46 that will be applied to<br>
microstructure elements 48 in a mapping procedure 50, for example a planar<br>
mapping procedure. The microstructure elements 48 are organized so as to provide<br>
information, in particular information comprising text and numbers relating to the<br>
product information, for example in the case of a train ticket that indicates the journey<br>
starting and destination places, the date, and possibly additional information such as<br>
the class, the price and any other product specific information. It is also possible to<br>
include in the microstructure elements customer information such as the customer's<br>
name, address, date of birth or other information specific to the customer. The<br>
microstructure elements may also comprise elements having various graphical<br>
shapes or logos.<br><br>
The product information is also used by the production server or server portion to<br>
generate a product information layer that may include a simple presentation of the<br>
product specific information, in the present example of a transportation ticket, relating<br>
to the starting place and destination, the class, the price, the validity, date or period,<br>
possibly further including electronically verifiable security features such as an<br>
encrypted number code or a bar code. The coded or electronically verifiable security<br>
feature provides additional verification means for a person controlling the authenticity<br>
of the ticket in case there is any doubt after a visual verification, or for any other<br>
reason, such as arbitrary spot checks.<br>
The background image may be a photographic image, a drawing, or any other image<br>
that is preferably non-uniform and representing places, objects, events, or other<br>
things that may be easily recognized and interpreted visually, in other words, images<br>
that have some meaning or have characteristic features that facilitate the memorizing<br>
and recognition thereof by a person verifying the authenticity of the instrument. The<br>
background image is preferably an image that is proprietary and not easily available<br>
to the general public. The background image may be changed on a regular basis in<br>
order to increase the difficulty of reproducing the ticket image. Where the commercial<br>
instrument comprises a portrait 42 of the customer, the background and portrait<br>
images may be merged by any standard merging technique or by superposition 45 of<br>
the photograph on the background image to form a personalized contextual image<br>
layer 54.<br>
The microstructure pattern or shape 46 is for example a mathematical image<br>
deformation algorithm (warping transformation) as as described hereinabove or as<br>
used in planar mapping or other known image deformation techniques. The<br>
microstructure shape or pattern may vary between different types of commercial<br>
instruments on criteria established by the issuer, for example, different shapes for<br>
different ticket values, events, days of the week, months, etc. The shape or pattern<br>
may also be regularly changed, for example but not necessarily, when the<br>
background image is changed, in order to make reproduction of forgeries more<br>
difficult by reducing the time during which a background image and a pattern on the<br>
image remain valid.<br><br>
The microstructure elements 48 include in a preferred embodiment alphanumerical<br>
characters that enable product specific information such as the date or period of<br>
validity, the event, seating number, information on the journey starting place and<br>
destination, and the like to be read. The text that identifies the specific purpose of the<br>
commercial instrument may in itself be unique (such as a combination of the title,<br>
date and seating number of a theatre event) or may be unique in conjunction with<br>
customer specific information (for example a train ticket indicating a combination of a .<br>
date, a journey, and a portrait of the traveller). The microstructure elements are used<br>
to create a dither matrix representative of a microstructure image layer 56 that is<br>
rendered with the contextual image layer 54.<br>
The microstructure elements used in the present application, which include<br>
alphanumerical characters, are generated at a size that enable their reading at a<br>
personal document reading distance which may typically be in the order of 20 to 50<br>
cm from the eye. The microstructure elements are thus significantly larger than the<br>
screen dot sizes provided in even the lowest resolution printed images typically<br>
available.<br>
The microstructure elements are advantageously generated by automatic synthesis<br>
from bi-level bitmap elements as already described hereinabove, however the<br>
production of commercial instruments or other documents with security features<br>
according to this invention may use microstructure elements generated in other<br>
manners, as described for example in relation to figures 50a to 50g which show<br>
various graphical representations of a microstructure element.<br>
An alternate way of synthesizing microstructure elements<br>
The microstructure element 48 may be represented as a three-dimensional element<br>
61 against a background 63 as shown in Fig. 50a, whereby the depth of the element,<br>
in the direction coming out of the paper of Fig. 50a, may be separated into a plurality<br>
of planes parallel to the paper, each plane defining a grey level. The microstructure<br>
element may for example be defined in 256 planes that correspond to 256 grey<br><br>
levels, which equates with the number of grey levels commonly defined in standard<br>
printing techniques. The background 63 comprises "noise" that can be graphically<br>
represented as randomly distributed "peaks" that, when intersected by the high grey<br>
level planes, give the background a grainy aspect as shown in Figures 50b to 50d.<br>
When the grey level is very high, the character will be at its thickest with a dark<br>
background, as illustrated in Fig. 50b, the background getting lighter as the grey level<br>
decreases as represented successively by Figures 50c to 50e. For an intermediate<br>
grey level, the character is of medium thickness as shown in Fig. 50f, or if there is a<br>
very low grey level, the character is very thin as shown in Fig. 50g. In this example,<br>
grey levels are thus varied by adjusting the thickness of the characters, in addition to<br>
varying the density of the grainy background for the high grey levels, whereby it<br>
should be noted that the characters are preferably hormomorphic such that, as they<br>
reduce in thickness, their general shape remains. The latter property ensures the<br>
readability of the characters, whether depicting a low grey level or a high grey level.<br>
Instead of adjusting the thickness, other techniques are available for defining the<br>
microstructure element grey level, for example the character may be defined by a<br>
dark border of a constant outer shape and dimensions while varying border thickness<br>
towards the center of the character depending on the grey level.<br>
The representation of lettering as microstructure elements is for example depicted in<br>
Fig. 47, whereby the lettering on the left side of the figure are simple characters and<br>
on the right side of the figure shown as three-dimensional microstructure elements<br>
that graphically represent the microstructure dither matrix. In Fig. 47, the elements<br>
have already been subjected to a planar mapping procedure 50 with a microstructure<br>
shape (which in the specific example emulates the positioning of text lines' around a<br>
cylinder). It should be noted that the 3D representations of Fig. 50a and on the right<br>
side of Fig. 47 are merely means of assisting the reader in obtaining a visual<br>
interpretation of microstructure elements which are in fact defined in a dither matrix<br>
and could be represented in other ways.<br>
In generating the dither matrix, account is taken of both the text of microstructure<br>
elements and the microstructure shape. Moreover, the microstructure image is<br><br>
scaled to the same size as the contextual image. The contextual image and<br>
microstructure images 54, 56 are then rendered by applying the microstructure dither<br>
matrix to the contextual image with any of the dithering methods described herein.<br>
By way of example, one simple method of fusing is standard halftoning, as described<br>
above.<br>
The results of standard halftoning is illustrated for example in Fig. 48, whereby the<br>
contextual image and microstructure image are subjected to the above described<br>
standard halftoning procedure resulting in a halftoned image 58. As may be noticed<br>
in this halftoned image, in the light areas of the contextual image, the microstructure<br>
characters are very thin (because of the low grey level value) and in the dark areas<br>
very thick (because of the high grey level value).<br>
The grey level values of the dither matrix located between microstructure elements<br>
are preferably set at a low grey level value varying randomly such that the shape of<br>
the microstructure element remains visible (even in dark areas) after the halftoning<br>
process.<br>
It may be further noticed that the thickness of the microstructure characters vary<br>
along portions thereof, depending on the grey level of the contextual image in the<br>
vicinity of the portion of character in question.<br>
Referring to Fig. 53, the effect of applying a microstructure dither matrix of a<br>
microstructure element 48' to an image 44' by a halftoning technique is illustrated.<br>
This halftoned image 58 shows the varying thickness of the character "T" 61 and the<br>
density of the background grain 63 as a function of the grey level of the image 44.<br>
The visual quality of the computed halftoned image 58 is often not optimal due to the<br>
size of the microstructure elements composing the dither matrix. In order to improve<br>
the quality, the rendering procedure may further include an equilibration procedure as<br>
already described herein. Other equilibration or balancing techniques, for example<br>
which compare the halftoned image with the contextual image as illustrated in Fig.<br><br>
49, may be used. A balancing or equilibration technique that may be employed<br>
includes examining the neighbourhood of each point of the halftoned image,<br>
subsequently counting the number of black points and white points which are then<br>
used to compute an average grey level value, for example the number of white points<br>
divided by the total number of points in the considered neighbourhood. These<br>
average grey level values are compared with the grey level value of the<br>
corresponding point of the contextual image and if the difference is small, (for<br>
example below a defined or approximated value), then it is considered that the<br>
halftoned image is a good approximation of the contextual image at that point. If the<br>
difference between the compared grey level values is large, then it is considered that<br>
the halftoned image is locally a bad approximation of the contextual image and that<br>
the considered point of the halftoned image should be inverted, in other words, set to<br>
white if originally black, or set to black if originally white. A probalistic function may be<br>
used to determine whether the difference between the compared grey level values is<br>
to be considered small or large.<br>
While the halftoning and balancing or equilibration procedures have been described<br>
as separate procedures hereinabove, it would be possible to combine these two<br>
procedures in a single procedure, even if the terms "halftoning" and "balancing" are<br>
used separately.<br>
A simple graphical product information layer 52 may be superposed 61 or otherwise<br>
merged with the rendered image 60 to result in the completed commercial instrument<br>
image 62, such as the sporting event ticket image illustrated in Fig. 52. As can be<br>
seen in Fig. 52, the simple product information layer 64 indicates the validity date, the<br>
event name, and the price in an easy to read format, at least a part of this product<br>
information also being present in the microstructure of the rendered image and easily<br>
readable at a normal document reading distance of say 20 to 50 cm from the eye. In<br>
this particular example, the microstructure layer also comprises the name of the<br>
sporting event attendee. At the same time, the contextual image which in this<br>
example includes a photograph of a trophy and a person's portrait, is well-defined at<br>
normal document reading distance, and even improves beyond the document<br>
reading distance, say at arms length from the eye where the microstructure<br><br>
characters become less apparent. Visual verification of a commercial instrument<br>
generated according to this invention may include the steps shown in Fig. 51,<br>
whereby a ticket controller would check the relevance of the ticket information by<br>
reading the product information layer 64, and the microstructure information, which<br>
should correspond to the product information. The controller may also verify the<br>
contextual image and the microstructure shape or pattern and in this regard should<br>
be informed of the background image and microstructure pattern that applies to the<br>
type of commercial instrument at its date of validity. A bar code 66 which preferably<br>
includes an encrypted code, may be used as an additional verification means in case<br>
of doubt of the authenticity of the ticket, or for other reasons, such as random checks.<br>
Referring to Fig. 52a, a detailed view of a portion of the printed ticket of Fig. 52 is<br>
shown. The smallest screen dots used for printing the image are conventional screen<br>
dots using traditional shapes, such as an ellipse or circle. The screen dots may<br>
however be provided with a special shape that could be changed on a regular basis<br>
to increase the security against forgery. This security technique may be taken further<br>
by introducing additional layers of microstructure elements having sizes intermediate<br>
the smallest printed screen dot and the microstructure elements verifiable at normal<br>
reading distance, using a rendering procedure as set forth above. Verification of the<br>
intermediate microstructure elements may be performed by close visual inspection of<br>
the printed instrument, for example at a distance of 10 to 20 cm from the eye. As best<br>
seen in Figures 52a and 52b, in this example a second layer of smaller<br>
microstructure elements comprising the characters "05-05-04" is provided, indicating<br>
the date of the event. In other words, a plurality of microstructure image layers<br>
formed by microstructure elements of a different size for each layer could be<br>
rendered with the contextual image with the rendering procedures described above.<br>
It may be noted that commercial instruments or other security documents generated<br>
through a communications network as described above may also be displayed on an<br>
electronic screen, for example the screen of a portable electronic device, rather than<br>
being printed.<br>
Distinctive features and document protection features<br><br>
The present invention thus protects security documents comprising elements such as<br>
text, a photograph, graphics, images, and possibly a background motive by<br>
incorporating microstructures having shapes varying with the intensity of the<br>
document elements. Since, thanks to the dithering process, the target document<br>
image is built on top of microstructures, both document elements and microstructures<br>
cannot be erased or modified without significantly modifying the target document<br>
image. For example in FIG. 27, one can see that in this example, all the elements<br>
making up the image are microstructures. The global image is the girl's face. The first<br>
level microstructure is a dragon. The high-frequency dither array incorporates a<br>
second level microstructure in the shape of a greek graphic symbol (a frieze). Such a<br>
second level microstructure can incorporate simple second level microstructure<br>
shapes such as one or a few letters, numbers or symbols for additional protection.<br>
This second level microstructure embedded into the high-frequency dither array<br>
makes it even harder to create faked document images or document elements.<br>
A key distinctive feature which characterizes the present invention is its ability to<br>
synthesize the microstructure in the form of a dither matrix starting from a bilevel<br>
bitmap incorporating the microstructure shape, the generated dither matrix being<br>
sufficiently sophisticated for making the chosen microstructure visible both at high<br>
and low image intensities. For example in FIGS. 33A and 33B, the microstructure is<br>
visible at a darkness of below 10% and higher than 90%. The hebrew letters in FIG.<br>
34 are clearly visible between 10% and 90% darkness. Furthermore, the synthesis of<br>
the dither matrix can be carried out automatically by a computer program.<br>
A second distinctive feature of the present invention is its ability to create<br>
geometrically transformed microstructures allowing to create variations of the security<br>
document, while keeping the global image intact and without modifying the<br>
information (e.g. text) carried at the global level and at the microstructure level.<br>
These geometrically transformed microstructures also allow to generate on a display<br>
an image, whose microstructure is animated. For example, FIG. 6 shows several<br>
instances of the same image and the same microstructure generated with different<br>
transformation parameters.<br><br>
A third distinctive feature of the invention is its ability to carry out equilibration by<br>
making use of a high frequency dither matrix, possibly incorporating a second level<br>
microstructure (FIG. 27).<br>
A fourth distinctive feature is the possibility of generating color documents with<br>
standard, non-standard and special inks, where one, several or all contributing inks<br>
are part of the microstructure. Considered inks are for example metallic, iridescent,<br>
fluorescent, phosphorescent and ultra-violet inks.<br>
A fifth distinctive feature of the present invention is its ability of automatically<br>
synthesizing personalized security documents from information related to the<br>
document content.<br>
Let us enumerate the main protective features. A first protection is ensured by the<br>
continuity of the microstructure when crossing adjacent element boundaries (pieces<br>
of text, graphic elements, images). This continuity makes it extremely hard for<br>
potential counterfeiters to replace given document elements by faked elements (for<br>
example replace a photograph by a faked photograph). As a second protective<br>
feature, text, represented in the original image as dark typographic characters can be<br>
protected by the microstructure. A third protection is offered by the dithering process<br>
used for microstructure image synthesis which ensures that the microstructure shape<br>
thickness varies according to the current image intensity or when colors are used,<br>
according to the dominant color intensities (or ink coverage). Counterfeiters cannot<br>
therefore simply incrust into a document by alpha blending a pseudo microstructure<br>
generated with standard desktop graphic packages. A fourth protection is offered by<br>
allowing text to be part of the microstructure, providing additional means of verifying<br>
the authenticity of the document. This allows to establish a correlation between<br>
information at the global document level and at the microstructure level. For example,<br>
the name of a document holder may be repeated all over the document by<br>
embedding it into a microstructure made of text (at the first or possibly at the second<br>
microstructure level). Modifying that name would require to modify the microstructure<br>
warped over all the document, an almost impossible task. A fifth protection is offered<br><br>
by the possibility of generating different instances of the microstructure on different<br>
documents using the parametrized transformation Tt(u,v) and possibly the warping<br>
transform Tw(x,y). A given instance of the microstructure image defined by a<br>
particular parametrized transformation Tt(u,v) may be correlated with the document<br>
content, for example the value of the security document, the type of the document<br>
and the year when the document is issued.<br>
FIG. 36 shows as an example of a security document a diploma incorporating a<br>
microstructure containing the name of the document holder and the name of the<br>
institution issuing the diploma. Since the microstructure covers all document parts,<br>
parts of it cannot be replaced. Furthermore, thanks to the geometric transformation<br>
which warps the microstructure across the picture at different orientations and sizes,<br>
and thanks to the fact that the thickness of the microstructure adapts itself to the local<br>
image intensity, microstructure elements cannot be simply copied from one location<br>
to many other locations. In addition, in dark (or color saturated) parts of the<br>
document, the very thin separations between microstructure shapes make the the<br>
unauthorized document reproduction very difficult.<br>
Creating security documents with microstructures incorporating special inks<br>
The document protection by microstructures is not limited to documents printed with<br>
black-white or standard color inks (cyan, magenta, yellow and possibly black).<br>
According to pending US patent application 09/477,544 (Method an apparatus for<br>
generating digital halftone images by multi-color dithering, inventors V.<br>
Ostromoukhov, R.D. Hersch, filed Jan. 4, 2000, due assignee: EPFL), it is possible,<br>
with multicolor dithering, to use special inks such as non-standard color inks, metallic<br>
inks, fluorescent or iridescent inks (variable color inks) for generating security<br>
documents. In the case of metallic inks for example, when seen at a certain viewing<br>
angle, the microstructure appears as if it would have been printed with normal inks<br>
and at another viewing angle, due to specular reflection, the microstructure appears<br>
much more strongly. A similar variation of the appearance of the microstructure can<br>
be attained with iridescent inks. Such variations in the appearance of the<br><br>
microstructure completely disappear when the original document is either scanned<br>
and reproduced or photocopied.<br>
Furthermore, one may incorporate non-standard inks only in certain parts of the<br>
security document and print the other parts with standard inks. Then, the effect of a<br>
metallic ink may only be visible within document parts selected by a mask, the mask<br>
itself being capable of representing a visual message such as a text, graphic<br>
symbols, a graphic design or a dithered image. For example, one may use as a mask<br>
the dragon of FIG. 27 and render within the target image with metallic ink only those<br>
parts of the microstructure which are covered by the dragon shape (the dragon<br>
shape is obtained by simple dithering of the original image, without equilibration). In<br>
such a target image the dragon shape is highlighted by the metallic ink, when seen at<br>
an angle allowing specular reflection of the incident light.<br>
Creating security documents on screens or supports other than paper<br>
Document images incorporating microstructures may be used to generate security<br>
documents non only on paper but also on electronic displays (e.g. computer or<br>
mobile phone screens) or on other supports such as transparent or opaque plastic<br>
material, polymer material, packages of valuable products, optical disks such as CD-<br>
ROMs or DVDs, or in optical devices such as diffractive elements, holograms and<br>
kinegrams.<br>
Creation of artistic images by automatic synthesis of the microstructure<br>
The automatic synthesis of microstructure images opens very efficient ways for<br>
designing artistic images such as illustrations, posters and publicity images. The<br>
designer only needs to create an original image and original microstructure shapes.<br>
With the help of a standard desktop graphic package, he can scan the microstructure<br>
shapes or draw them, retouch them so as to meet his aesthetic wishes and convert<br>
them into an original microstructure bitmap needed for the automatic synthesis of the<br>
corresponding dither matrix. This dither matrix incorporating the microstructure<br>
shapes is then used to dither the original image and produce the target artistic<br><br>
dithered image. Therefore, once integrated into a desktop software package,<br>
automatic dithering is a very effective tool for creating graphic designs, posters and<br>
publicity. In addition, large scale posters may be created easily where from far away<br>
the global image is visible and from nearby the microstructure becomes visible. This<br>
microstructure incorporates a second layer of information such as text, logos, a<br>
graphic design or publicity. Such large scale posters are specially effective when<br>
situated for example on highways, where car drivers see at first the global image and<br>
then, when coming closer they see microstructure information.<br>
Creation of images with animated microstructures<br>
Images comprising animated microstructures can be used to create beautiful<br>
information and publicity sites attracting the attention of clients. Especially for clients<br>
visiting Web sites, images with animated microstructures are capable of forwarding a<br>
message incorporated into the animated microstructure. Parent patent application US<br>
09/902,227, filed July 11, 2001, by R.D. Hersch and B. Wittwer discloses a method<br>
for generating animated microstructure images, i.e. image sequences and<br>
animations, where from where from far away mainly the image is visible and from<br>
nearby mainly the evolving microstructure is visible. That method makes use of a<br>
large dither matrix incorporating the microstructure. Microstructure evolution is<br>
obtained by successively regenerating new instances of the image with modified<br>
transformation parameters. Thanks to the method for the automatic synthesis of<br>
dither matrices disclosed in the present invention, aesthetic dither matrices can be<br>
easily and rapidly produced and hence greatly facilitate the creation of images with<br>
animated microstructures.<br>
The disclosed methods have been described with respect to particular illustrative<br>
embodiments. It is to be understood that the invention is not limited to the above<br>
described embodiment and that various changes and modifications may be made by<br>
people skilled in the art without departing from the spirit and scope of the appended<br>
claims.<br>
Computing system for synthesizing security documents and microstructure images<br><br>
A computing system (FIG. 37) for synthesizing security documents comprises an<br>
interface for receiving a request for generating a security document, for example the<br>
diploma shown in FIG. 36. Relevant information (370, FIG. 37) is received with that<br>
request for example the name of the document holder, the issue date and the type of<br>
document to be issued. The computing system also comprises a preparation<br>
software module operable for preparing the data used for the production of the<br>
security document and a production software module operable for producing said<br>
security document. The preparation software module running on the computing<br>
system may generate the original document image, the microstructure shapes and<br>
possibly transformation parameters according to information received together with<br>
the request. The production software module first synthesizes the microstructure to<br>
be used for generating the security document and then synthesizes the security<br>
document with that microstructure which is then transmitted to an output device.<br>
In a preferred embodiment (FIG. 37, terms in parenthesis), the microstructure shapes<br>
are generated by producing a bitmap incorporating the microstructure shapes. The<br>
microstructure to be used for generating the security document is embodied in a<br>
dither array which is synthesized from said bitmap by applying to the bitmap<br>
mathematical morphology operations. Synthesizing the security document is carried<br>
out by dithering the original document image with the previously synthesized dither<br>
array.<br>
A similar computing system (FIG. 38) can be operated for synthesizing<br>
microstructure images such as microstructure images for graphic designs,<br>
information, publicity and posters. The computing system comprises an interface<br>
operable for receiving an original image, microstructure shapes, possibly a<br>
transformation selected from the set of available transformations and transformation<br>
parameters, as well as, in the case of color, a selection of the basic colors to be used<br>
for rendering the target dithered image (380, FIG. 38). The computing system also<br>
comprises a production software module operable for producing said artistic<br>
microstructure image. The production software module running on the computing<br><br>
system takes as input the microstructure shapes, synthesizes the microstructure, and<br>
produces the target microstructure image incorporating the microstructure.<br>
In a preferred embodiment, the microstructure shapes are incorporated into a bitmap<br>
received by the computer system's interface. The microstructure to be used for<br>
generating the security document is embodied in a dither array which is synthesized<br>
by the production software module from said bitmap by applying to the bitmap<br>
mathematical morphology operations. Synthesizing the target microstructure image is<br>
carried out by dithering the original document image with the previously synthesized<br>
dither array and if in color, possibly according to specified basic colors, and possibly<br>
according to the transformation and transformation parameters received by the<br>
computing system's interface.<br>
Computing system for displaying images with animated microstructure<br>
Images with animated microstructures can be synthesized offline by a computer<br>
running an animated microstructure image rendering software. The resulting image<br>
animation can be then incorporated into Web pages as animated images (e.g..<br>
animated GIF or MNG formats). An alternative consists in creating an image<br>
computing and display system, for example an applet, running the animated<br>
microstructure image rendering software. In that case, the image computing and<br>
display system will run on the client's computer and display the animated<br>
microstructure image or image animation. As a preferred embodiment, the image<br>
computing and display system will receive from the server computing system (FIG.<br>
39) as input data the input color image, the dither matrix, the animation<br>
transformation, the warping transformation, the set of basic colors {Ci} and a possible<br>
mask layer. With the present technology, the preferred embodiment of an image<br>
computing and display system is a Java applet. The image computing and display<br>
system's program (e.g. the program running as an applet) will then generate and<br>
display the target image by carrying out the initialization, image rendering and image<br>
display steps described above.<br><br>
In addition, specific embodiments of the animated microstructure image rendering<br>
system may allow to tune some of the image rendering parameters according to user<br>
preferences or user profiles. For example one image selected from a set of images,<br>
one set of basic colors selected from various sets of basic colors, one dither matrix<br>
selected from different dither matrices, one animation transformation and possibly a<br>
warping transformation may be tuned according to user preferences or profiles.<br>
These specific embodiments allow to customize the animated microstructure images<br>
according to users or user categories.<br>
Optionally, a specific server (e.g. a Web site) can be conceived which allows<br>
designers to create images with microstructures evolving over time (i.e. animated<br>
microstructure images) on their own computers (FIG. 40). The program interface<br>
running on their computers (e.g. dynamic Web page incorporating an applet) will<br>
exchange information with the server. With such a Web based design interface,<br>
graphic designers may specify or create the source image, the dither matrix, the<br>
basic colors, the animation transform, the warping transform and the image mask<br>
layer. By being able to modify interactively each of these parameters and elements,<br>
and immediately visualizing the results, designers may be able to interactively create<br>
appealing images with animated' microstructures. Upon signing a licensing<br>
agreement, they may then receive the authorization to transfer the animated<br>
microstructure rendering software (e.g. the applet's code) as well as the created data<br>
elements into their own Web pages. FIG. 41 shows an animated microstructure<br>
image incorporated into a Web page.<br><br><br>
WE CLAIM :<br>
1.	Method of generating an image incorporating a microstructure, comprising:<br>
-	obtaining an original image;<br>
-	generating a microstructure; and<br>
-	rendering a region or the whole said original image with said microstructure;<br>
wherein the operation of generating the microstructure includes an automatic synthesis<br>
of microstructure elements as a microstructure dither matrix, from original<br>
microstructure shapes, and wherein the synthesis of said dither matrix includes<br>
applying mathematical morphology operators to the microstructure shapes.<br><br>
2.	Method as claimed in claim 1, wherein the microstructure comprises a low<br>
frequency microstructure with low frequency microstructure elements generated from<br>
the original microstructure shapes, and a high frequency microstructure with high<br>
frequency microstructure elements, whereby the low frequency microstructure<br>
elements are larger than the high frequency microstructure elements.<br>
3.	Method as claimed in claim 1, comprising an image equilibration post-processing<br>
step after rendering said region or said original image, said equilibration post-<br>
processing step comprising a dithering operation with a high-frequency dither array.<br>
4.	Method as claimed in claim 1 wherein the applied mathematical morphology<br>
operators comprise a shape thinning operator for a bitmap shape foreground and an<br>
operator selected from a set of alternated dilation and dual bitmap thinning for a<br>
bitmap shape background.<br>
5.	Method as claimed in any preceding claim, wherein the synthesized<br>
microstructure elements are visible at both high and low intensities after rendering with<br>
the original image.<br>
6.	Method as claimed in any one of the preceding claims, wherein the original<br>
microstructure shapes are bitmap elements.<br><br>
7.	Method as claimed in any one of the preceding claims, wherein the visibility of<br>
the microstructure elements is tuned by a mask whose values represent relative<br>
weights of the original image halftoned with conventional methods and the original<br>
image synthesized with the microstructure.<br>
8.	Method as claimed in any one of the preceding claims, involving applying a<br>
parametrized transformation to warp the microstructure incorporated in the image.<br>
9.	Method as claimed in the preceding claim, wherein several image instances are<br>
successively generated by modifying parameters of the parametrized transformation,<br>
said set of image instances forming a displayable image animation.<br>
10.	Method as claimed in the preceding claim, wherein said parameters are modified<br>
smoothly as a function of time to yield a smoothly evolving animated microstructure.<br>
11.	Method as claimed in any one of the preceding claims, wherein the rendering of<br>
the microstructure and original image involves a standard or multicolor dithering<br>
operation.<br>
12.	Method as claimed in any one of the preceding claims, involving applying a mask<br>
specifying a region of the original image to be rendered with the microstructure.<br>
13.	Method as claimed in any one of the preceding claims, involving applying a multi-<br>
valued mask expressing weights of original image colors and weights of selected basic<br>
colors for generating the image.<br>
14.	Method as claimed in the preceding claim, wherein said original image colors are<br>
converted to basic colors making use of tetrahedrization of the color space.<br>
15.	Method as claimed in claim 1 wherein the microstructure elements are adapted<br>
to the original image color by having at least one dominant color being thicker in dark<br>
regions and thinner in light regions.<br><br>
16.	Method as claimed in any one of the preceding claims, wherein the<br>
microstructure comprises information personal to a user of the image.<br>
17.	Method as claimed in any one of the preceding claims, wherein the<br>
microstructure comprises information identifying and specific to a particular event or<br>
transaction, such as date, venue, seating, destination, time.<br>
18.	Method as claimed in any one of the preceding claims, wherein the<br>
microstructure elements comprise alphanumerical characters provided at a size in<br>
relation to the image that allow their reading at a personal document reading distance.<br>
19.	Method as claimed in claim 2 wherein the high-frequency microstructure<br>
elements are placed at locations corresponding to the background of the low frequency<br>
microstructure elements.<br>
20.	Method as claimed in claim 3, wherein said equilibration involves:<br><br>
-	applying dot gain simulation;<br>
-	applying a human visual system filtering; and<br>
-	comparing the original image with the resulting dot-gain simulated and filtered<br>
dithered image.<br><br>
21.	Method as claimed in the preceding claim, wherein the comparison yields a<br>
deltamap to which said dithering operation by the high frequency dither array is<br>
applied, the resulting dithered deltamap being composed with the dithered image.<br>
22.	Method as claimed in any one of the preceding claims, wherein a mask whose<br>
shape expresses a visual message specifies the part of the microstructure that is to be<br>
printed with special inks that enable, under certain observation conditions, the mask<br>
shape to remain hidden within the image and under other observation conditions, the<br>
mask shape to be clearly revealed.<br>
23.	Method as claimed in the preceding claim wherein parts of the image specified<br>
by the mask are printed with a special ink selected from a group of metallic and<br><br>
iridescent inks, whereby the mask shape is hidden at a certain observation angle and<br>
is visible at a different observation angle.<br>
24.	Method as claimed in the preceding claim,-wherein parts of the image specified<br>
by the mask are printed with a special ink invisible in daylight and visible in light at<br>
selected frequencies, such as Ultraviolet light.<br>
25.	Method as claimed in any one of the preceding claims involving:<br><br>
-	defining color information used for rendering the target image;<br>
-	defining parameters of a parametrized transformation;<br><br>
-	traversing a target image positions (x,y) pixel by pixel and row by row,<br>
determining corresponding positions in the original image (x',y') and, according<br>
to the parametrized transformation, corresponding positions in the<br>
microstructure (x",y");<br>
-	obtaining from the original image positions (x',y') the color Cr to be reproduced<br>
and from the microstructure positions (x",y") rendering information;<br>
-	rendering the target image by making use of the rendering information.<br>
26.	Method of generating a security document for printing or display, involving the<br>
steps of:<br>
-	selecting or retrieving an original image;<br>
-	selecting or retrieving information specific to a person, an event or transaction<br>
to which said security document relates;<br>
-	generating a microstructure comprising readable microstructure elements<br>
providing information on said person, event or transaction;<br>
-	rendering said original image with said microstructure image using the method<br>
as claimed in any one of claims 1 to 25.<br>
27.	Method as claimed in the preceding claim, wherein the image is printed or<br>
displayed on a support comprising any of paper, plastics, polymers, product packages,<br>
optical disks, and optical devices comprising holograms, kinegrams and diffractive<br>
elements.<br><br>
28.	Method as claimed in claim 26 or 27, wherein the security document is a<br>
commercial instrument bearing value or relating to a commercial transaction.<br>
29.	Method as claimed in claim 26 or 27, wherein the security document is a<br>
certificate, title or deed.<br>
30.	Method as claimed in claim 26 or 27, wherein the security document comprises<br>
information identifying a person or entity.<br>
31.	Method as claimed in claim 26, wherein the image incorporating a microstructure<br>
is generated in a server system, said server system preparing a file for printing said<br>
security document on a standard printer or for display on an electronic screen, such as<br>
a screen of a portable electronic device.<br>
32.	Method as claimed in the preceding claim, wherein said security document is<br>
printed on said standard printer at a customer site remote from said server system and<br>
accessible to said server system via a communications network such as the Internet.<br>
33.	Method as claimed in any one of claims 26 to 32, wherein some or all information<br>
included in the original image is retrieved from one or more databases via a global<br>
communications network such as the internet.<br>
34.	Method as claimed in any one of claims 26 to 33, wherein the original image<br>
comprises a portrait of a bearer selected from a customer database on the basis of<br>
information identifying said bearer.<br>
35.	An image incorporating a microstructure generated by a method as claimed in<br>
any one of the claims 1 to 25 wherein the microstructure elements comprise<br>
information specific to a particular event, transaction, or person.<br>
36.	A security document comprising an image as claimed in the preceding claim.<br>
37.	A computing system for synthesizing a security document comprising an image<br>
generated by the method as claimed in any one of claims 1 to 34, comprising:<br><br>
-	an interface operable for receiving a request for synthesizing a security<br>
document,<br>
-	a preparation software module operable for preparing data files according to<br>
document related information received with the request, where the preparation<br>
of data files comprises the generation of an original document image, the<br>
generation of original microstructure shapes and the generation of<br>
transformation parameters, and<br>
-	a production software module operable for producing the security document,<br>
where producing the security document comprises the automatic synthesis of<br>
microstructure elements as a microstructure dither matrix, wherein the<br>
synthesis of the dither matrix includes applying mathematical morphology<br>
operators to the microstructure shapes, and rendering thesecurity document<br>
with that microstructure.<br>
38. Computing system as claimed in the preceding claim, wherein microstructure<br>
shapes are generated by producing a bitmap incorporating the microstructure shapes,<br>
where the microstructure is embodied in a dither array synthesized from said bitmap by<br>
applying to it mathematical morphology operations and where the security document is<br>
synthesized by dithering the original document image with the synthesized dither array.<br><br><br>
The invention relates to the field of images incorporating information both at the <br>
global level and at the microstructure level and to methods of generating such<br>
images. There is provided a method of generating an image incorporating a<br>
microstructure, including the steps of obtaining an original image; generating a<br>
microstructure; and rendering a region or the whole said original image with said<br>
microstructure. According to the invention the operation of generating the<br>
microstructure includes an automatic synthesis of microstructure elements as a<br>
microstructure dither matrix, from original microstructure shapes, and the synthesis of<br>
said dither matrix includes applying mathematical morphology operators to the<br>
microstructure shapes. The invention enables truly automatic synthesis of<br>
microstructure elements, and permits very efficient generation of images<br>
incorporating a microstructure that are difficult to counterfeit. The generated images<br>
incorporating a microstructure may advantageously be used as a security feature in<br>
documents.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0wtMjAwOS0oMDYtMDktMjAxMSktQ09SUkVTUE9OREVOQ0UucGRm" target="_blank" style="word-wrap:break-word;">1682-KOL-2009-(06-09-2011)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLSgwOC0wNS0yMDEyKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-(08-05-2012)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUFTU0lHTk1FTlQgMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-ASSIGNMENT 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUNPUlJFU1BPTkRFTkNFIDEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-CORRESPONDENCE 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWNvcnJlc3BvbmRlbmNlLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWV4YW1pbmF0aW9uIHJlcG9ydC5wZGY=" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUZPUk0gMTggMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-FORM 18 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWZvcm0gMi5wZGY=" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUZPUk0gMyAxLjEucGRm" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-FORM 3 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdQQSAxLjEucGRm" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GPA 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtTEVUVEVSIFBBVEVOVC5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-LETTER PATENT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLUdSQU5URUQtU1BFQ0lGSUNBVElPTi5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-GRANTED-SPECIFICATION.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLU9USEVSIFBBVEVOVCBET0NVTUVOVC5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-OTHER PATENT DOCUMENT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1LT0xOUC0yMDAzLVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">1682-KOLNP-2003-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY4Mi1rb2xucC0yMDAzLXNwZWNpZmljYXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">1682-kolnp-2003-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="254016-power-contact-having-current-flow-guiding-feature-and-electrical-connector-containing-same.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="254018-modulation-of-replicative-fitness-by-deoptimization-of-synonymous-codons.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>254017</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1682/KOLNP/2003</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>37/2012</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>14-Sep-2012</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>12-Sep-2012</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>31-Dec-2003</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>CH-1015 LAUSANNE, SWITZERLAND</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HERSCH ROGER DAVID</td>
											<td>CHEMIN DES PLANCHES 39, CH-1066 EPALINGES, SWITZERLAND</td>
										</tr>
										<tr>
											<td>2</td>
											<td>WITTWER BERNARD</td>
											<td>LES CHAUX CH-1070 PUIDOUX, SWITZERLAND</td>
										</tr>
										<tr>
											<td>3</td>
											<td>BIEMANN DANIEL</td>
											<td>CHEIN DES FORNELS 1, CH-1803 CHARDONNE, SWITZERLAND</td>
										</tr>
										<tr>
											<td>4</td>
											<td>GOROSTIDI DANIEL</td>
											<td>CHEMIN DE LA COCARDE 3, CH-1024 ECUBLENS, SWITZERLAND</td>
										</tr>
										<tr>
											<td>5</td>
											<td>BONGARD DOMINIQUE</td>
											<td>LES FAUVETTES, CH-1681 BILLENS,SWITZERLAND</td>
										</tr>
										<tr>
											<td>6</td>
											<td>FORLER EDOUARD</td>
											<td>AVENUE DU TIR-FEDERAL 81, CH-1022 CHAVANNES-PRES-RENENS, SWITZERLAND</td>
										</tr>
										<tr>
											<td>7</td>
											<td>EMMEL PATRICK</td>
											<td>GEHRENACKERSTRASSE 11, CH-4133 PRATTELN, SWITZERLAND</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>B42D 15/10</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB02/02686</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2002-07-05</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>09/902,227</td>
									<td>2001-07-11</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>09/998,229</td>
									<td>2001-12-03</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>3</td>
									<td>02001158,1</td>
									<td>2002-01-25</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/254017-method-of-generating-an-image-incorporating-a-microstructure-and-method-of-generating-a-security-document by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:08:40 GMT -->
</html>
