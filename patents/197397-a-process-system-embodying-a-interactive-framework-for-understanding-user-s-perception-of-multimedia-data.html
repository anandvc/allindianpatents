<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/197397-a-process-system-embodying-a-interactive-framework-for-understanding-user-s-perception-of-multimedia-data by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:01:46 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 197397:&quot;A PROCESS &amp; SYSTEM EMBODYING A INTERACTIVE FRAMEWORK FOR UNDERSTANDING USER&#x27;S PERCEPTION OF MULTIMEDIA DATA&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;A PROCESS &amp; SYSTEM EMBODYING A INTERACTIVE FRAMEWORK FOR UNDERSTANDING USER&#x27;S PERCEPTION OF MULTIMEDIA DATA&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A methodology of highly interactive intra-object relevance feedback is used to retrieve multimedia data from a database. The query object could consist of one or more images, images derived from video, a video sequence, or an audio clip. The query is adjusted using the informa¬tion fed-back by the user about the relevance of previously extracted part(s) from the object itself, such that the adjusted query is a better approximation to the user&#x27;s perception. Since a single query object is utilized in the system according to the invention, high-performance learning techniques can be employed for this intra-object learning of user&#x27;s perception. The refined query is subsequently used for inter-object relevance feedback where data is retrieved from the database based on parameters learnt by intra-query object feedback mechanism, and the user provides feedback by ranking the retrieved objects in order of their relevance to him or her. In the system according to the invention, inter-object learning of user&#x27;s perception is expedited by utilizing the learnt parameters in the intra-object relevance feedback. Furthermore, the methodology of the invention allows for building refined queries based on part(s) or sub-sequence(s)of the query object rather than the entire object itself, thereby reducing the number of irrelevant objects, retrieved from the database. The methodology allows synthesis and modification of the input query object itself in the event a query object is not directly available, and also to learn the user&#x27;s perception.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>AN INTERACTIVE FRAMEWORK FOR<br>
UNDERSTANDING USER'S PERCEPTION OF MULTIMEDIA DATA<br>
DESCRIPTION BACKGROUND OF THE INVENTION<br>
Field of the Invention<br>
The present invention generally relates to retrieval of multimedia data (images, video and audio) from a database and, more particularly, to a system which understands the user's perception from the query object(s) itself via user interaction, thereby increasing the relevance of the data retrieved from the database, and subsequently increasing the speed of retrieval of the objects of interest.<br>
Background Description<br>
Effective utilization of rapidly growing collection of digital images, audio and video necessitates the development of efficient content-based query and retrieval methods. Traditional content-based image retrieval (CBIR) methods primarily focused on finding the "best" represen¬tations for the image-centric visual features (e.g., color, texture, shape). During the retrieval process, the user specifies weights to different visual features, and a retrieval system finds similar images to the user's query based on specified weights. See J. R. Smith and S. F. Chung, "Visual seek: A fully automated content basedimage query system", Proc. ACM Multimedia 96,1996, and W. Y. Ma and B. S. Manjunath, "Netra: A toolbox for navigating large image databases", Proc. IEEE Int. Conf. on Image Processing, 1997.<br>
Performance of such a computer-centric retrieval paradigm is not satisfactory (i.e., number of images irrelevant to the user is large), essentially due to the gap between high-level concepts (i.e., user's actual intention) and low-level visual features, and the inherent subjectivity of human perception. On the other hand, in emerging relevance feedback based approach to CBIR, the retrieval process is interactive between the computer and the user. Based on the initial query image, the computer returns a set of similar images from the database. The user assigns relevance to the retrieved images (from highly relevant to irrelevant). The computer tries to corre¬late the user's perception of the image in terms of the low-level features, typically by employing some machine learning techniques. It then performs the retrieval process again. This interactive process is repeated until the user finds the image of interest. See Y. Rui, Thomas S. Hung, M. Ortega and S. Mehrotra, "Relevence Feedback: A powertool in interactive content based image retrieval", IEEE Trans. Circuits and Systems for Video Technology, Special Issue on<br>
nteractive Multimedia Systems for The Internet, 1998, and C. Nastar, M. Mitschke, C. Meilhac, "Efficient Query Refinement for Image Retrieval", Proc. IEEE CVPR, 1998. This process of repeatedly searching the database can become a bottleneck with the increase in database size and the number of users.<br>
Due to subjectivity in human perception, irrelevant images are frequently retrieved from an image database, given a query by the user. Existing relevance feedback techniques repeatedly search the database which can be remotely located, and understand the user's perception by downloading relevant and irrelevant images to the user in each search. This repeated database search and download slows down the retrieval speed of the image ofinterest.<br>
SUMMARY OF THE INVENTION<br>
It is therefore an object of the present invention to provide an understanding of the user's perception from the query object(s) itself via user interaction, thereby increasing the relevance of the multimedia objects retrieved from the database, and subsequently increasing the speed of retrieval of the object ofinterest. The query can consist of any of the following: an image, an image set, image(s) derived from a video sequence, a video sequence or an audio clip. Although we describe the invention in detail for image retrieval, we provide sufficient examples for video and audio such that anyone skilled in the art can use the same techniques for general media queries.<br>
In this invention, we present a new methodology which incorporates interactive intra-query object relevance feedback and learning to understand the user's perception about the query object. The query is adjusted using the feedback given by the user about the relevance of previ¬ously extracted part(s) from the query object itself, such that the adjusted query is a better approximation to the user's perception. Since a single query object is utilized in the system according to the invention, high-performance learning techniques, which are often computation¬ally intensive, can be employed for this intra-query object learning of user's perception. The refined query can be subsequently used using prior-art techniques for inter-query object relevance feedback where data is retrieved from the database based on parameters learnt by intra-query object feedback mechanism, and the user provides feedback by ranking the retrieved data in order of their relevance to her/him. In the system according to the invention, intra-query object learning of user's perception is expedited by utilizing the learnt parameters in the intra-query object relevance feedback. Furthermore, the methodology of the invention allows for building refined queries based on part(s) of the query object rather than the entire object itself, thereby reducing irrelevant data being retrieved from the database. Also, unlike existing systems where the query object(s) is restricted to the set of database objects, there is no such restriction in the system according to the invention. In addition, the present invention allows the user to synthesize/modify the query object(s) starting from a textual query or from a set of dictionary objects; e.g., using a<br>
"drag-and-drop" approach. The user's action during the synthesis and modification process is further used to learn his or her perception of the image.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The foregoing and other objects, aspects and advantages will be better understood from the following detailed description of a preferred embodiment of the invention with reference to the drawings, in which:<br>
Figure 1 is a block diagram illustrating apparatus on which the process according to the invention may be implemented;<br>
Figure 2 is a block diagram illustrating another apparatus on which the process accord¬ing to the invention may be implemented;<br>
Figure 3 is a flow diagram illustrating the logic of the process for the complete multime¬dia retrieval system with user feedback and learning according to the invention;<br>
Figure 4 is a flow diagram illustrating in more detail the first learning loop, i.e., intra-query object learning, of the process shown in Figure 3;<br>
Figures 5 A and 5B are illustrations of an image showing segmentation of the image in the practice of the invention;<br>
Figure 6 is a flow diagram illustrating query object(s) synthesis from a textual query through user interaction using a pre-processed (i.e., pre-compiled) object set (i.e., dictionary of objects); and<br>
Figure 7 is a flow diagram illustrating an alternative embodiment of Figure 6, where a Graphic User Interface (GUI) is used for query object synthesis, instead of a textual query.<br>
DETAILED DESCRIPTION OF A PREFERRED<br>
EMBODIMENT OF THE INVENTION<br>
Referring now to the drawings, a representative system on which the present invention may be implemented is shown in Figure 1. A user 10 interacts via a monitor 11 and an input device 12, such as a keyboard and/or mouse, with a processing element 13. The processing element may be part of a computer system such as a personal computer or workstation, for example, which is programmed to perform the process according to the invention. The computer system typically includes memory and mass storage, such as a hard disk, as well as other support¬ing peripherals. The processing element 13 accesses an image database 14, typically stored on the mass storage of the computer system, in response to queries by the user 10.<br>
The computer system illustrated in Figure 1 is a stand alone computer system, but the invention may be implemented on a networked computer system, an example of which is illus¬trated in Figure 2. In mis example, a client computer system 20 accesses a server 21 via a network 22. The network 22 may be a Local Area Network (LAN) or Wide Area Network<br>
(WAN), for example. Alternatively, the network 22 may be the Internet. The server 21 accesses a multimedia database 23 in response to queries received from the client computer system 20. The database 23 is typically stored on a mass storage system using magnetic or optical media.<br>
In the preferred embodiment of this invention, as illustrated in Figure 3,the user starts the search process with the help of query object(s) in block 4000. The query object(s) may either be selected from a small database of query objects or may be supplied by the user. Alternatively, if the query object does not exist in the said database and if the user does not have a representa¬tive query object, the user may then synthesize such a query using a pre-compiled dictionary as described later. The user's query is processed by an intra-query object processing block 1000. This processing block includes an intra-query object learning function 301 which receives user feedback 302, and is illustrated in more detail in Figure 4. The output of the intra-object process¬ing block 1000 is used by the computer to perform database retrieval in function block 303. The retrieved objects are displayed to the user who is prompted to indicate whether he or she is satis¬fied with the retrieval or not. The user's response to the prompt is evaluated in decision block 304. If the user is satisfied, the present query stops and the user picks, i.e., downloads or saves, from the set of data returned by the computer in block 305. Otherwise, the process enters the second learning loop, the inter-query object processing block 2000. The inter-query object processing block 2000 includes an inter-query object learning function 306 which receives user feedback 307, just like the intra-query object processing block 1000. This second learning loop, i.e., inter-query object processing, is prior art and hence is not described in more detail.<br>
The intra-query object processing performed in processing block 1000 consists of (a) specification of part(s) of interest by the user (i.e., user's interest is only in part of the queryimage or the user's interest is only in the vocals of an audio clip), (b) tentative over-segmentation of the query object (or part of it) using low-level features like color, texture, shape, audio frequency, motion, etc. (It could also include for example separation of audio signal into high and low pitch components. Various prior-art segmentation techniques can beapplied in this context.), (c) merging or splitting of segments/regions specified by the user, (d) learning user's perception (e.g., color, texture, shape, topological and chronological arrangement of segments or relative impor¬tance of object motion in video or of varying frequency components in audio), and (e) extraction of semantic object(s) using such segments. Inter-query object processing comprises of (a) search¬ing the database for similar query object(s) using learnt parameters from intra-query object processing, (b) user's ranking of the retrieved media as relevant and irrelevant images, and (c) understanding user's perception to improve the retrieval efficiency for the next iteration of database retrieval.<br>
The intra-query object processing of processing block 1000 is shown in more detail in Figure 4. The first step in the process is media object segmentation performed in function block 401. Multimedia segmentation could imply image segmentation using low-level features like color, texture, etc. for images or audio segmentation into signals of various frequencies based on<br>
the pitch, or determination of video segmentation using motion vectors from the frames of a video clip. The segmentation results are displayed to the user in function block 402 with a prompt to indicate whether or not the user is satisfied with the segmentation results, at least in the region of interest. The user's input is evaluated in decision block 403, and if this input indicates that the user is not satisfied with the segmentation, then the user is prompted for further input, such as merge, de-merge, validate, re-order, audio mix, etc. This input is indicated by input block 404 and is used to learn the user's perception in function block 405. Based on the learnt user percep¬tion, a re-segmentation of the media object is performed in function block 406. Alternatively, the block 406 could also modify the media object or a part of the object to better leam the user's perception, e.g., re-coloring an image, modifying the pitch to assess the user's sensitivity to such changes. The results of re-segmentation ormodification are again displayed to the user at function block 402 and, again, the user is prompted to indicate his or her satisfaction. User's response is used to leam the perception; e.g., if color was changed and the user did not respond negatively, then the user cares more about texture and not color.<br>
The query object is defined by a set of segments, each segment for an image being a homogeneous region of the image, in terms of gray-level value, RGB value, texture and/or a combination of these. In the case of video, it could include motion vectors that describe the motion of object pixels over the frames in the video sequence. A segment is characterized by a feature vector x, a shape description d, and a similarity measure/for an image or video clip. The query object is characterized by a set of segments, their topological and chronological relation¬ship G. The segmentation results are shown to the user. If the user is interested only in the partial query image, he or she selects areas of interest by enclosing them in a bounded polygon, for example. A subset of segments surrounding the user's areas of interest are shown to the user. Alternatively, segmentation is performed only in the area(s) of interest. The user is now allowed to merge two or more segments, e.g., by clicking on the edge between them or by clicking points inside the segments. This enables the computer to capture the users notion of similarity, topologi¬cal and chronological relationship between different parts, and the user's area of interest in the query object. The user is also given an option of splitting a segment into two or more based on his perception, for example, by clicking on representative points in the segment. The computer now learns the model parameters and the similarity measures which would lead to merging or splitting of the selected segments. The re-grouped object is again shown to the user. This interactive process is repeated until the user is satisfied.<br>
The present invention allows the user to create a composite object consisting essentially of two (or more) dissimilar segments, e.g., a flower audits stem. The two segments which are dissimilar are retained as separate segments and are added to query object set. The topological arrangements and features of individual segments along with learnt similarity measures are used in subsequent database search. The similarity measures are adaptive quantities, which are adjusted with user's feedback. The measure could be different for different segments. Multimedia<br>
objects which contain the similar segments or a subset of segments and satisfy certain topological arrangement (if specified) are retrieved during inter-query object processing. In the case of video, the segmentation results might consist of an image frame along with motion vectors, e.g., a clip of a moving car might be shown as a single car with transnational vector and rotational vectors for the tires. The user may then select the car and the corresponding motion vector to say mat he or she is interested in a moving car. For the audio case, the computer might separate the vocals from the instrumentals based on pitch or percussion from a stringed instrument. The user may then select the desired sound effects.<br>
In the picture shown in Figure 5 A, the image is segmented into regions a, b, c, d, e and f. Segments a, b, c and d differ in color but are similar in texture. Segment a differs from segments e and f in texture. The user clicks on the edge joining segments a and b to merge these segments. The computer learns that user cares more about texture man color. The computer then groups the regions a, b, c and d together to make the query object. If now the user requests the search, the shape and the corresponding feature vector of only this segment abed shown in Figure 5B is used for searching the database.<br>
It is possible that the set of initial query images is null. In that ease, the system accord¬ing to the invention enables the user to create an approximate query object from a textual query using a pre-compiled dictionary of objects. The drag and drop approach is a good candidate for query object synthesis. Textual phrases can also be used for specifying topological relationship ofdictionary objects. Alternately, if the dictionary is large, the query can be formulated textually in terms of the dictionary objects and their topological relationships. The dictionary is augmented in run-time by letting the user add an object to the dictionary, every time he or she creates one in intra-object processing phase. Here the present invention is different from prior art techniques since the object in the present invention consists of the feature vector describing the region and a similarity measure/which will be used to measure the similarity of this segment to others. Thus, two segments with more or less the same feature vector could have different similarity measures, e.g. a homogeneous region made up of bricks in the shape of a cottage could either have a measure that says the shape matching is to be used to find cottages made up of either bricks or concrete or wood, or instead the measure could denote that the brick texture is to be used to find any brick region whether on the floor or wall, i.e., any shape. This is a different embodiment of this invention with the same objective of understanding the user's perception of the multimedia query object, achieved using query object synthesis and/or modification through user interaction.<br>
Query-object synthesis using a pre-processed (i.e., pre-compiled) object set (i.e., diction¬ary) of objects as described above is shown in Figure 6, which describes in detail the block 4000 of Figure 3. In this embodiment, the process could begin with a textual query, as shown in input block 601, that is first parsed in function block 602 and then categories are accessed from an "annotated" pre-processed object set, or dictionary, in function block 603. The object is then synthesized with user feedback for adding and/or deleting components or specifying the<br>
topological relationships between objects. This is performed in processing block 3000, the output of which is input to processing block 1000 in Figure 3. More particularly, in processing block 3000, the object is synthesized in function block 604, and the synthesized image is displayed inblock 605 with a prompt for the user to input his or her satisfaction. The user input is evaluated in decision block 606, and if the user is not satisfied, the user is prompted to provide additional user input. This input is indicated at input block 607 and, once the input is entered, the process loops back to function block 603.<br>
An alternative to this "object synthesis" approach could be just using a pre-processed object set (dictionary of objects); i.e., mere is no annotation in the object set and, hence, the user may not browse the categories. This is shown in Figure 7 where the query is input at input block 701, and in response to the query, the pre-processed image set is accessed in function block 702. At this point the process enters processing block 3000, as in Figure 6. This is a simpler version as compared to that illustrated in Figure 6. Consequently, the user may just drag-and-drop objects from the object set, but there is no textual query.<br>
The present invention is different and more user-friendly from the prior art reported by T. P. Minka and R. W. Picard, "Interactive learning using a society of models", Proc. IEEE CVPR, 1996, where the user indicates a region of interest in the image itself by marking a number of pixels. This system generalizes by selecting and, if necessary, combining a number of pre-compiled grouping of highly specialized and context-dependent features from a "society of models" using a restricted set of rules.<br>
Chad Carson, Serge Belongie, Hayit Greenspan, and Jitendra Malik in "Region-Based Image Querying", CVPR  ' 7 Workshop on Content-Based Access of Image and Video Librar¬ies, Puerto Rico, June 1997, also interpret the query image and show the segmented image to the user. The user can then select the segments of interest and in addition can manually assign weights to the different features. This is used to formulate the query and thus there is no notion of intra-image learning of the user's perception.<br>
While the invention has been described in terms of a preferred embodiment and alterna¬tive embodiments, those skilled in the art will recognize that the invention can be practiced with modification within the spirit and scope of the appended claims.<br><br><br>
CLAIMS<br>
Having thus described our invention, what we claim as new and desire to secure by Letters Patent is as follows:<br>
1.	^computer implemented metholT/bmbodyiiig an interactive framework for understanding a<br>
user's perception of multimedia Hat* for the retrieval of data Rom a database comprising the steps<br>
of:<br>
(a)	receiving a user's specification of area(s) or portion(s) of interest as part of the user's<br>
query object,<br>
(b)	tentatively over-segmenting at least a part of the query object,<br>
(c)	merging or splitting of segments specified by the user,<br>
(d)	learning the user's perception of area(s) or portion(s) of interest selected from the<br>
group consisting of color, texture, shape, time sequence, audio mixture, and topological arrange¬<br>
ment of segments, and<br>
(e)	extracting from the database semantic object(s) using the segments.<br><br>
2.	The method according to claim 1, wherein the query object is defined by a set of segments<br>
characterized by at least one of a feature vector, a shape description, or a similarity measure.<br>
3.	The method according to claim 1, wherein the user's specification includes at least one of<br>
color, texture, shape, audio frequency, motion or region of interest of the query object.<br>
4.	The method according to claim 1, wherein the query object is over-segmented by at least one<br>
of color, texture, shape, audio frequency, ormotion.<br>
5.	The computer implemented method of claim 1, wherein the step of inter-object processing<br>
comprises the steps of:<br><br>
(a)	searching the database for similar query object(s) using learned parameters from<br>
intra-query object processing;<br>
(b)	receiving the user's ranking of the retrieved objects as relevant or irrelevant data;<br>
and<br>
(c)	understanding the user's perception.<br>
6.	Aiiajmp^ex^plenieTS3"rn^u1ioTJ&gt;pf query-object synthesis/modification comprising the steps<br>
of:<br>
(a) receiving and parsing a textual query from a user;<br>
(b)	accessing a dictionary of pre-compiled annotated objects using a parsed textual<br>
query;<br>
(c)	organizing selected objects based on the user's interaction; and<br>
(d)	learning the user's perception of the selected objects from the user's interaction.<br>
7. A computer implemented method of query-object synthesis/modification comprising the steps of:<br>
(a)	accessing a dictionary of objects based on a user query;<br>
(b)	organizing selected objects based on the user's interaction; and<br>
(c)	learning the user's perception of the objects from the user's interaction.<br>
8.	A^on^uterjrnglernegteflinetbod of dictionary synthesis and updation comprising the steps of:<br>
(a)	adding an object and a similarity function for the object to the dictionary in a<br>
category chosen by a user or a computer, after the object has been retrieved; and<br>
(b)	annotating the object with a textual description given by the user.<br>
9.	A computer implemented method of dictionary synthesis and updation according to claim 8,<br>
wherein the similarity function comprises learned perception parameters.<br>
10.	N^ojnputer program produjjfocomprising a computer usable medium having computer<br>
readable program code embodied in the medium for embodying an interactive framework for<br>
understanding a user's perception of multimedia data for the retrieval of data from a database, the<br>
computer program product including:<br>
first computer program code for receiving a user's specification of area(s) or portion(s) of interest as part of the user's query object;<br>
second computer program code for tentatively over-segmenting at least a part of the query object;<br>
third computer program code for merging or splitting of segments specified by the user,<br>
fourth computer program code for learning the user's perception of area(s) or portion(s) of interest selected from the group consisting of color, texture, shape, time sequence, audio mixture, and topological arrangement of segments; and<br>
fifth computer program code for extracting from the database semantic objed(s) using the segments.<br>
11.	A computer program product comprising according to claim 10, wherein the fifth computer<br>
program code comprises:<br>
sixth computer program code for searching the database for similar query object(s) using learned parameters from intra-query object processing;<br>
seventh computer program code for receiving the user's ranking of the retrieved objects as relevant or irrelevant data; and<br>
eighth computer program code for understanding the user's perception.<br>
12.	A computer program product comprising a computer usable medium having computer<br>
readable program code embodied in the medium for query-object synthesis/modification, the<br>
computer program product including:<br>
first computer program code for receiving and parsing a textual query from a user;<br>
second computer program code for accessing a dictionary of pre-compiled annotated objects using a parsed textual query;<br>
third computer program code for organizing selected objects based on the user's interac¬tion; and<br>
fourth computer program code for learning the user's perception of the selected objects from the user's interaction.<br>
13.	A computer program product comprising a computer usable medium for query-object<br>
synthesis/modification, the computer program product including:<br>
first computer program code for accessing a dictionary of objects based on a user query;<br>
second computer program code for organizing selected objects based on the user's inter¬action; and<br>
third computer program code for learning the user's perception of theobjects from the user's interaction.<br>
14.	A computer program product comprising a computer usable medium for query-object<br>
synthesis/modification, the computer program product including:<br>
first computer program code for adding an object and a similarity function for the object to the dictionary in a category chosen by a user or a computer, after the object has been retrieved; and<br>
second computer program code for annotating the object with a textual description given by the user.<br>
15. A. system for embpdyingjin interactive framework for understanding a user's perception of multimedia data for the retrieval of data from a database comprising:<br>
means for receiving a user's specification of area(s) or portion(s) of interest as part of the s query object;<br>
means for tentatively over-segmenting at least a part of the query object;<br>
means for merging or splitting of segments specified by the user;<br>
means for learning the user's perception of area(s) or portion(s) of interest selected from the group consisting of color, texture, shape, time sequence, audio mixture, and topological "rrangement of segments; and<br>
means for extracting from the database semantic object(s) using the segments.<br>
16.	A system for embodying an interactive framework for understanding a user's perception of<br>
multimedia data for the retrieval of data from a database comprising according to claim 15,<br>
wherein the means for extracting comprises:<br>
(a)	means for searching the database for similar query object(s) usinglearned parameters<br>
from intra-query object processing;<br>
(b)	means for receiving the user's ranking of the retrieved objects as relevant or irrele¬<br>
vant data; and<br>
(c)	means for understanding the user's perception.<br>
17.	A system for query-object syn thesis/modification comprising:<br>
(a)	means for receiving and parsing a textual query from a user;<br>
(b)	means for accessing a dictionary of pre-compiled annotated objects using a parsed<br>
textual query;<br>
(c)	means for organizing selected objects based on the user's interaction; and<br>
(d)	means for learning the user's perception of the selected objects from the user's<br>
interaction.<br>
18.	A system for query-object synthesis/modification comprising:<br>
(a)	means for accessing a dictionary of objects based on a user query;<br>
(b)	means for organizing selected objects based on the user's interaction; and<br>
(c)	means for learning the user's perception of the objects from the user's interaction.<br>
19.	A system for dictionary synthesis and updation comprising:<br>
(a)	means for adding an object and a similarity function for the object to the dictionary<br>
in a category chosen by a user or a computer, after the object has been retrieved; and<br>
(b)	means for annotating the object with a textual description given by the user.<br>
20.	A   computer    implemented    method    embodying    an    interactive<br>
framework for understanding a user's perception of multimedia data<br>
for the retrieval of data from a database substantially as herein<br>
described with reference to and as illustrated by the accompanying<br>
drawings.<br>
21.	A       computer       implemented       method        of       query-object<br>
synthesis/modification    substantially    as    herein    described    with<br>
reference to and as illustrated by the accompanying drawings.<br>
22.	A   computer   implemented   method   of dictionary   synthesis   and<br>
updation substantially as herein described with reference to and as<br>
illustrated by the accompanying drawings.<br>
23.	A computer program product substantially as herein described with<br>
reference to and as illustrated by the accompanying drawings.<br>
24.	A system for embodying an interactive framework for understanding<br>
a user's perception of multimedia data for the retrieval of data from a<br>
database substantially as herein described with reference to and as<br>
illustrated by the accompanying drawings.<br>
25.	A system for query-object synthesis/modification  substantially as<br>
herein   described   with   reference   to   and   as   illustrated   by   the<br>
accompanying drawings.<br>
26.	A system for dictionary synthesis and updation substantially as herein<br>
described with reference to and as illustrated by the accompanying<br>
drawings.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">527-del-2000-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWNvcnJlc3BvbmRlbmNlLXBvLnBkZg==" target="_blank" style="word-wrap:break-word;">527-del-2000-correspondence-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">527-del-2000-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">527-del-2000-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWZvcm0tMTkucGRm" target="_blank" style="word-wrap:break-word;">527-del-2000-form-19.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LURFTC0yMDAwLUZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">527-DEL-2000-Form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLXBldGl0aW9uLTEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-petition-137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTI3LWRlbC0yMDAwLXBldGl0aW9uLTEzOC5wZGY=" target="_blank" style="word-wrap:break-word;">527-del-2000-petition-138.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="197390-an-apparatus-for-providing-dispatch-service-and-a-dispatch-communication-system-comprising-the-same.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="197399-a-process-for-substrate-preparation-for-powder-coating-of-galvanized-sheet.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>197397</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>527/DEL/2000</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>04/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>25-Jan-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td></td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>23-May-2000</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INTERNATIONAL BUSINESS MACHINE CORPORATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>ARMONK, NEW YORK 10504, U.S.A.</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>AGGARWAL GAURAV</td>
											<td>G-34, I.I.T. CAMPUS, HAUZ KHAS, NEW DELHI-110016, INDIA.</td>
										</tr>
										<tr>
											<td>2</td>
											<td>DUBEY PRADEEP KUMAR</td>
											<td>M-4, SAKET, NEW DELHI-110017, INDIA.</td>
										</tr>
										<tr>
											<td>3</td>
											<td>GHOSAL SUQATA</td>
											<td>J-230, SECOND FLOOR, SAKET, NEW DELHI - 110017, INDIA.</td>
										</tr>
										<tr>
											<td>4</td>
											<td>RAVI TUMKUR VENKATANARAVANA RAO</td>
											<td>DOOR NUMBER: 39/113, ID CROSS, REMCO LAYOUT, VIJAVNAGAR, BANGALORE - 56 040, INDIA.</td>
										</tr>
										<tr>
											<td>5</td>
											<td>KULSHRESHTHA ASHUTOSH</td>
											<td>C4/74/2, SDA, HAUZ KHAS, NEW DELHI - 110016, INDIA.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F 17/30</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>09/328,968</td>
									<td>1999-06-09</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/197397-a-process-system-embodying-a-interactive-framework-for-understanding-user-s-perception-of-multimedia-data by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:01:47 GMT -->
</html>
