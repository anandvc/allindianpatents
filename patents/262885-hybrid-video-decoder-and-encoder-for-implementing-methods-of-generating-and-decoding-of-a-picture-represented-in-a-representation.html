<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/262885-hybrid-video-decoder-and-encoder-for-implementing-methods-of-generating-and-decoding-of-a-picture-represented-in-a-representation by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:09:30 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 262885:HYBRID VIDEO DECODER AND ENCODER FOR IMPLEMENTING METHODS OF GENERATING AND DECODING OF A PICTURE REPRESENTED IN A REPRESENTATION</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">HYBRID VIDEO DECODER AND ENCODER FOR IMPLEMENTING METHODS OF GENERATING AND DECODING OF A PICTURE REPRESENTED IN A REPRESENTATION</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to a Hybrid video decoder (100) for reconstructing a picture represented in a representation having a first (104A) and a second picture block (104B) that are encoded in a predictive coding scheme, the picture blocks carrying picture information for picture areas smaller than the area of the picture, wherein the first picture block (104A) is carrying the picture information in a first color-space representation of a prediction residual and the second picture block (104B) is carrying the picture information in a second color-space representation of the prediction residual, the decoder comprising: a color-space transformer (102) for transforming either the color-space representation of the first picture block (104A) to the second color-space representation or the color-space representation of the second picture block (104B) to the first color-space representation, characterized by comprising: a requantizer for deriving the picture information describing the prediction residual of the first (104A) and the second picture block (104B) from a quantized representation of the picture information, wherein the decoder (100) comprises an entropy decoder for deriving the quantized representation of the picture information from an entropy encoded representation of the quantized representation of the picture information using a decoding rule.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
Picture Coding using Adaptive Colour Space Transformation<br>
Description<br>
The present invention relates to picture coding and in par-<br>
ticular to a concept allowing for a more efficient coding<br>
of picture content, i.e. producing encoded representations<br>
of pictures or picture streams having a better R/D-ratio.<br>
Applications where pictures or picture streams have to be<br>
encoded efficiently are numerous. For example, still image<br>
compression is normally done by digital photo cameras to<br>
increase the number of pictures that can be stored on a<br>
storage medium of a given size. When it comes to transmis-<br>
sion of image sequences or complete movies over a transmis-<br>
sion medium offering only limited bandwidth, the use of an<br>
efficient codec (coder-decoder) that allows for a high com-<br>
pression of the content of the pictures becomes even more<br>
urgent. This is on the one hand due to the desired trans-<br>
mission over transport channels offering low bandwidth,<br>
such as the streaming of video content to mobile phones. On<br>
the other hand, the transmission of high-resolution video<br>
content is becoming more and more popular since displays<br>
capable of displaying such high resolution pictures are<br>
spreading more and more amongst consumers. One major trend<br>
is the upcoming broadcast of high-definition television<br>
(HDTV).<br>
In general, two different coding approaches may be distin-<br>
guished, the first aiming for an encoding without any loss<br>
of information and the second accepting a (moderate) loss<br>
of information and quality to achieve a significant reduc-<br>
tion in file sizes. Although lossless encoding techniques<br>
exist for both still images and movie content, these tech-<br>
niques, often based on entropy coding, cannot achieve a<br>
file-size reduction being sufficient or acceptable for the<br><br>
desired application. Therefore, lossy compression is mostly<br>
preferred such as JPEG for still image compression and<br>
MPEG 2 for movie compression.<br>
Generally, lossy compression has the problem of a decreased<br>
quality of the compressed pictures compared to the underly-<br>
ing original picture. Naturally, the quality of the picture<br>
becomes worse when the compression rate is increased, i.e.<br>
when the file size of the compressed picture is decreased.<br>
Therefore, one has to find a compromise between the desired<br>
quality of a compressed image and the file size acceptable<br>
for transmission or storage. Mostly, the decrease in file<br>
size and also the loss in information is achieved by quan-<br>
tization of parameters describing the picture properties<br>
and hence, the coarser the quantization the worse the qual-<br>
ity and the smaller the compressed picture. The quality of<br>
the compressed picture is commonly estimated by a compari-<br>
son of the compressed picture with the underlying original<br>
picture. This allows estimating a signal-to-noise ratio,<br>
wherein the noise is understood to be the noise introduced<br>
during the compression.<br>
In current compression algorithms, a block-wise processing<br>
of images is widely used. The underlying basic idea is that<br>
for normal image content, a change of content, e.g. of<br>
color and brightness, of neighboring pixels is normally<br>
relatively small. Therefore, by using areas of neighboring<br>
pixels that are processed and compressed together, one<br>
should achieve rather high compression rates without sig-<br>
nificantly reducing the perceptual quality of the picture.<br>
Such a picture block is from here on also referred to as<br>
macro-block. Thus, in other words, the macro-blocks serve<br>
as a kind of sub-picture unit in coding. The block-<br>
subdivision is illustrated in Fig. 7, where a picture 10 is<br>
subdivided into 12 equally sized picture blocks 12A to 12L.<br>
The subdivision into 12 different picture blocks is to be<br>
understood as an example only.<br><br>
As an example, a single picture block 12 I is magnified in<br>
Fig. 7, wherein the subdivision of the picture block 12 I<br>
into an 8 x 8 matrix shows the single pixel elements build-<br>
ing the macro-block 121. Also here, the formation of a pic-<br>
ture block from 8x8 individual pixels is to be understood<br>
as an example only. To represent color within each individ-<br>
ual pixel, each pixel is assigned three parameters holding<br>
different color information in a certain color space.<br>
One simple approach of encoding a macro-block is to quan-<br>
tize the three parameters of each single pixel and to per-<br>
form an entropy coding on the quantized parameters after<br>
the quantization. Since quantization significantly reduces<br>
the available parameter space for the entropy coding, quan-<br>
tization of the parameters can already reduce the amount of<br>
storage space or bits needed to describe one macro-block<br>
significantly.<br>
However, in order to reduce the amount of syntax elements<br>
describing the picture content having high energy, the pic-<br>
ture information within one macro-block is often described<br>
by transformation coefficients, generated by transforming<br>
the picture content within the macro-blocks into another<br>
representation (spectral domain). One example is to perform<br>
a discrete cosine transformation, eventually on a sub-<br>
macro-block level, and to use the transformation coeffi-<br>
cients as the image information, which may then be quan-<br>
tized and which might also be entropy coded after quantiza-<br>
tion.<br>
The transformation may, for example, be applied to the com-<br>
plete pixel information, i.e. three parameter values per .<br>
pixel of the picture block 121. Preferably, the transforma-<br>
tion is performed separately for the three parame-<br>
ters/components .<br>
For further reduction of file sizes and higher compression,<br>
one may also make use of a property of the human eye, which<br><br>
seems to put more weight on brightness information than on<br>
color information when judging the perceptual quality of an<br>
encoded picture. Therefore, one possibility to enhance the<br>
coding performance (with respect to quality and bit rate)<br>
is to reduce the number of color parameters with respect to<br>
the number of brightness parameters within a macro-block.<br>
That is, the information basis, on which a representation<br>
based of transformation coefficients is based, contains<br>
more information on brightness within the picture block<br>
than on color. Since there are numerous ways to describe a<br>
color by one single brightness-value and two color-values,<br>
the brightness-value shall be referred to as luma-value and<br>
the color -values shall be referred to as chroma-values<br>
from here on.<br>
One possible way of building such a picture block 121,<br>
suited to be transformed, is indicated in Fig. 7. The mag-<br>
nified picture block 121 has 8x8 individual pixels, each<br>
pixel normally described by one luma and two chroma values.<br>
Fig. 121 exemplifies a way to reduce the amount of chroma-<br>
information in that only the chroma information of specific<br>
pixels is used as the data set underlying the transforma-<br>
tion. This is indicated by the letter C within each indi-<br>
vidual pixel that is part of the chroma-data set. On the<br>
contrary, the most important luma information of every in-<br>
dividual pixel is used.<br>
It is to be understood that the situation shown in the mag-<br>
nified macro-block 121 is an example only. It is also pos-<br>
sible to further reduce the amount of chroma information.<br>
This could, for example, be achieved by omitting every sec-<br>
ond chroma information, that is for every eight luma val-<br>
ues, one chroma value would be taken into account during<br>
the transformation. It would also be possible to not simply<br>
use the chroma-values of the pixels shown in Fig. 12A but<br>
to calculate an average chroma value from four neighboring<br>
pixels by averaging the chroma value of the pixels. Such a<br>
chroma value would then be assigned to a position within<br><br>
the macro-block that is lying in the center of the four un-<br>
derlying pixels, as indicated by chroma value 16 indicated<br>
in Fig. 7.<br>
The encoding techniques described above can generally be<br>
used for both still images and moving pictures. For moving<br>
pictures, more sophisticated methods of encoding are used,<br>
involving motion estimation.<br>
In case of macro-block-wise motion estimation, two (or<br>
more) pictures of a picture stream (the pictures do not<br>
necessarily have to directly follow each other) are located<br>
which show the same picture content in the two images. In<br>
the simplest case, the picture content within the macro-<br>
block of a current frame has not changed compared to the<br>
reference frame. However, the content of the macro-block<br>
may appear at a slightly different position in the refer-<br>
ence frame. In this case it is sufficient to know the mo-<br>
tion vector of the movement of the picture content during<br>
the transition from the reference picture to the macro-<br>
block of the current picture to reconstruct or predict the<br>
picture information of the picture block in the current<br>
picture, once the reference picture is completely known at<br>
the decoder side. Of course, normally there are slight<br>
changes within the picture block during the transition from<br>
the reference picture to the current picture. Due to this,<br>
the prediction error is also transmitted thereby allowing<br>
to reconstruct the change of picture content in the macro-<br>
block along with the motion vector, to allow for a complete<br>
reconstruction of the macro-block in the current picture.<br>
Codecs which use motion prediction with subsequent residual<br>
coding such as transformation and entropy coding are called<br>
hybrid video codecs.<br>
According to state of the art techniques, predictive coding<br>
allows for an efficient representation of picture se-<br>
quences. In predictive coding, first a value for a quantity<br>
to be coded is predicted and then only the difference of<br><br>
the really observed value to the predicted value is coded<br>
and transmitted. This will also yield a gain in bit rate,<br>
since having a reliable prediction, the difference parame-<br>
ters will on the average be smaller than the absolute pa-<br>
rameters describing the picture within the macro-block.<br>
Hence, the symbol space on which a subsequent entropy cod-<br>
ing (with or without preceding quantization) is based can<br>
be decreased, allowing for shorter code words and such for<br>
a reduction in bit-rate.<br>
Although there have been quite some efforts undertaken to<br>
decrease the file size of compressed pictures or movies<br>
which are compressed using block-wise coding strategies<br>
without unacceptably decreasing the perceptual quality of<br>
the compressed content, the properties of the single pic-<br>
ture blocks are still not exploited optimally with respect<br>
to different parametric representations of picture blocks.<br>
It is the object of the present invention to provide a cod-<br>
ing scheme allowing for a more efficient use of inherent<br>
properties of differing parametric representations of pic-<br>
ture blocks in block-wise picture processing.<br>
This object is achieved by an apparatus in accordance with<br>
claims 1 and 17, by a method in accordance with claims 22<br>
or 23, and by a parameter bit stream in accordance with<br>
claim 24.<br>
The present invention is based on the finding that pictures<br>
or a picture stream can be encoded highly efficient when a<br>
representation of pictures is chosen that has different<br>
picture blocks, with each picture block carrying picture<br>
information for picture areas smaller than the full area of<br>
the picture, and when the different picture blocks carry<br>
the picture information either in a first color-space rep-<br>
resentation or in a second color-space-representation.<br>
Since different color-space-representations have individual<br>
inherent properties with respect to their describing pa-<br><br>
rameters, choosing an appropriate color-space-<br>
representation individually for the picture blocks results<br>
in an encoded representation of pictures that has a better<br>
quality at a given size or bit rate.<br>
In one embodiment of the present invention, an inventive<br>
decoder is used, that receives a bit stream having differ-<br>
ent picture blocks, the picture blocks carrying picture in-<br>
formation either in a first color-space-representation or<br>
in a second color-space-representation. The decoder further<br>
receives a transformation flag, indicating whether the<br>
color-space-representation of the picture block presently<br>
operated on is to be transformed into a different color-<br>
space-representation or not. Such a decoder allows for the<br>
reconstruction of image blocks within an image decoding<br>
process that are encoded in different color-space-<br>
representations. The decoder is therefore operative to<br>
process an inventive bit stream which allows for a more<br>
compact representation of a picture or a picture stream<br>
without decreasing the picture quality.<br>
In a further embodiment of the present invention, an inven-<br>
tive decoder is used which is operative to process picture<br>
blocks in a RGB-representation and in a representation, in<br>
which the color and the brightness information is stored by<br>
separate parameters, i.e. a representation having one luma-<br>
parameter and two chroma-parameters. This is advantageous<br>
in that normally image material is present in the RGB-<br>
color-space and can therefore be processed by the inventive<br>
decoder. Additionally, inherent differences of the parame-<br>
ter values of different color-space representations can be<br>
advantageously made use of to provide an optimal reproduc-<br>
tion quality at a given bit rate.<br>
In a further embodiment of the present invention, an inven-<br>
tive decoder has a color-space transformer that is opera-<br>
tive to perform the color-space-transformation on a para-<br>
metric representation of the picture blocks, wherein the<br><br>
parametric representation describes the picture block in a<br>
transform domain, for example in a frequency domain. This<br>
has the great advantage that in prior art picture process-<br>
ing, picture data is normally transformed prior to trans-<br>
mission to allow for an efficient quantization. Therefore,<br>
an inventive decoder that is operative to also work in the<br>
transform domain can be easily implemented into prior art<br>
designs to further increase the coding efficiency of those<br>
designs.<br>
In a further embodiment of the present invention, an inven-<br>
tive decoder is integrated into a picture or video decoder<br>
that further has a requantizer and an entropy decoder.<br>
Such, the inventive decoder can be used within the picture<br>
or video decoder to further increase the coding efficiency<br>
in that a video decoder or a picture decoder having an in-<br>
ventive decoder is enabled to process inventive, highly<br>
compressed bit streams.<br>
In a further embodiment of the present invention, an inven-<br>
tive decoder is operative to switch the color-space-<br>
transformation on and off depending on a transformation<br>
flag present in a provided bit stream. Such an inventive<br>
decoder can therefore be implemented into prior art designs<br>
and allows both prior art decoding and decoding inventive<br>
bit streams within one single device.<br>
In a further embodiment of the present invention an inven-<br>
tive encoder is having a color-space-transformer for trans-<br>
forming the color-space-representation of picture blocks<br>
from a "natural" color-space-representation (i.e. the<br>
color-space representation in which the content is origi-<br>
nally created) to a secondary color-space-representation<br>
when a transformation decider is indicating the desired<br>
transformation. The transformation decider is operative to<br>
estimate, on a block basis, the expected quality of the en-<br>
coded picture representation when the respective blocks are<br>
encoded in the natural color-space-representation or in the<br><br>
secondary color-space-representation. The inventive trans-<br>
formation decider is therefore also operative to decide<br>
whether a transformation is needed or appropriate for the<br>
individual blocks on the basis of a desired maximum bit<br>
rate and hence always choosing the best possible coding<br>
quality at a given bit rate. This has the great advantage<br>
that implementing the inventive concept allows for lower<br>
bit rates than prior art techniques while preserving the<br>
same perceptual quality.<br>
Preferred embodiments of the present invention are subse-<br>
quently described by referring to the enclosed drawings,<br>
wherein:<br>
Fig. 1 shows an embodiment of an inventive encoder;<br>
Fig. 2 shows a bit rate versus quality graph of differ-<br>
ent color-space-representations;<br>
Fig. 3 shows an example for a color-space-transformation<br>
emphasizing the inventive concept;<br>
Fig. 4 shows an embodiment of an inventive encoder;<br>
Fig. 4b shows an example of a given context for context<br>
based coding;<br>
Fig. 5 shows an example of an encoding concept for an<br>
embodiment of an inventive encoder;<br>
Fig. 6 shows an example of an inventive bit stream; and<br>
Fig. 7 shows block-wise decomposition of a picture for<br>
subsequent picture processing.<br>
Fig. 1 shows an inventive decoder 100. The decoder 100 is<br>
having a color-space transformer 102 that is operative to<br>
transform a picture block from a first color-space-<br><br>
representation (A) to a second color-space-repre-<br>
sentation (B) and vice versa. The decoder is used within<br>
the reconstruction of a picture or a movie that is repre-<br>
sented in a representation having a first picture block and<br>
a second picture block within pictures, wherein the picture<br>
blocks carry their picture information in a first color-<br>
space-representation (A) or in a second color-space-repre-<br>
sentation (B) . The decoder 100 receives a bit stream 104<br>
comprising several picture blocks 104A to 104D as an input,<br>
wherein the picture blocks 104A to 104D are included within<br>
the bit stream 104 in different color-space-<br>
representations A or B.<br>
The color-space transformer 102 within the decoder 100 re-<br>
ceives selected picture blocks to convert them from their<br>
original color-space-representation to a desired color-<br>
space-representation. As can be seen by the output bit<br>
stream 106 of the decoder 100, in the example given in<br>
Fig. 1, the color-space transformer is operative to trans-<br>
form the color-space-representation (B) of the picture<br>
blocks 104C and 104B to color-space-representation A such<br>
that after the decoding all picture blocks within the out-<br>
put stream 106 are represented in the color-space-<br>
representation A.<br>
In a modification of Fig. 1, the decoder 100 can further-<br>
more comprise a flag receiver 108 for receiving a transfor-<br>
mation information transmitted within the bit stream that<br>
indicates whether a corresponding picture block has a<br>
color-space-representation that shall be transformed or<br>
not. Depending on the received transformation indication,<br>
the flag receiver 108 can either direct a picture block to<br>
the color-space transformer or directly to the output of<br>
the decoder (100).<br>
Although in a preferred embodiment an inventive decoder re-<br>
ceives a transformation indication signal with the bit<br>
stream, it is also possible to implement a decoder that<br><br>
recognizes by some recognization algorithm, whether a<br>
color-space transformation is required or not for a certain<br>
picture block. This could, for example, be derived from the<br>
picture block element representation itself.<br>
In a further embodiment of the present invention an inven-<br>
tive decoder is operative to receive an additional activa-<br>
tion flag that is activating or deactivating the color-<br>
space transformer for a number of consecutive frames<br>
(slices) or, more general, for larger groups of picture<br>
blocks.<br>
It is a further preferred embodiment of the present inven-<br>
tion to implement the inventive decoder in a video decoder<br>
which is operative to receive a bit stream signal that is<br>
comprising picture information of picture blocks that are<br>
encoded in a predictive coding scheme based on motion esti-<br>
mation of picture blocks.<br>
In such a predictive coding scheme, only the difference or<br>
residual (difference macro-blocks) between the motion-<br>
compensated prediction for the picture blocks and the ac-<br>
tual content of the picture blocks is transmitted to in-<br>
crease the encoding efficiency. In one embodiment of the<br>
present invention, these differential macro-blocks are<br>
transmitted and decoded either in a primary (e.g. RGB) or<br>
in a secondary (e.g. YCoCg) color-space-representation.<br>
Therefore, the already rather compact information describ-<br>
ing the differential picture blocks can be further de-<br>
creased by a simple color transformation, which is computa-<br>
tionally cheap. When it comes to coding of differential<br>
signals i.e. signals that are intended to have describing<br>
parameters of low values (i.e. small numbers), the effect<br>
of a color-space transformation may be extremely benefi-<br>
cial. This will shortly be motivated in the following de-<br>
scription of Figs. 2 and 3.<br><br>
In the context of residual signals, the present invention<br>
describes a technique for switching between a primary (e.g.<br>
RGB) and a secondary (e.g. YCoCg) color-space in order to<br>
adapt the color-space-representation of the prediction re-<br>
sidual signal to the characteristics of the given video<br>
source and the specific coding conditions at hand. By using<br>
the inventive concept and techniques, an encoder may choose<br>
between two alternative color representations of the resid-<br>
ual signal for each single macro-block (picture-block) in a<br>
rate-distortion optimal way. The encoder's choice may be<br>
signaled to a corresponding decoder by means of a macro-<br>
block-based flag. In a preferred embodiment of the present<br>
invention, the inventive concept may be applied to advanced<br>
video codecs such as H.264/MPEG4-AVC and is particularly<br>
useful to reduce the demanded bit rate in high-quality cod-<br>
ing scenarios of those advanced codecs. A rate-distortion<br>
optimal way may be understood such that, for example, a<br>
maximum bit rate for a bit stream is specified and an in-<br>
ventive encoder is operative to choose the color-space-<br>
representation of the residual signal that provides the<br>
best encoding quality at the specified bit rate. However,<br>
it is also possible to optimize the rate for a fixed qual-<br>
ity or optimize a R/D ratio by use of some cost function.<br>
The quality-bit rate dependency is, for a single sample<br>
frame, plotted in Fig. 2.<br>
As can be seen, a specified maximum bit rate is given on<br>
the x-axis (in units of Mbits/Sec) and the corresponding<br>
image quality (signal-to-noise ratio in units of dB) is<br>
plotted on the y-axis. Fig. 2 shows two so called "rate-<br>
distortion performance curves" for encoding a single pic-<br>
ture in two different fixed color-space-representations.<br>
The first curve 120 shows the rate dependency of the pic-<br>
ture when RGB is chosen as color-space-representation and<br>
the second curve 122 shows the rate-distortion performance<br>
when YCoCg is chosen as color-space-representation. Fig. 2<br>
shows the known effect that a single color-space-<br><br>
representation cannot be optimal (in a rate-distortion<br>
sense) for all different source picture characteristics. In<br>
general, the amount of correlation between the R, G and B<br>
channels is highly signal dependent and may even change<br>
within a given picture.<br>
Fig. 2 shows the rate-distortion (R-D) curves for a typical<br>
intra-only coding scenario, where the color-space-<br>
representations have been fixed before encoding. Curve 120<br>
represents the R-D performance obtained for the case of en-<br>
coding in the original RGB domain, while encoding of the<br>
same source in the YCoCg color-space results in an R-D per-<br>
formance shown by Fig. 122. It may be noted that the dis-<br>
tortion (D) in the plot has been measured as the average of<br>
the R, G, and B picture peak signal-to-noise ratio values,<br>
that is by comparing the original picture with the addi-<br>
tional noise introduced by the encoding.<br>
It may be noted that the curves in Fig. 2 represent aver-<br>
aged data for a complete picture. The effects discussed in<br>
the following paragraphs with respect to bit rate may be<br>
much more dominant when observed for single macro-blocks<br>
since averaging effects then do not occur and the differ-<br>
ence of the quality achieved by using different color-<br>
space-representations on the single macro-block level may<br>
even be bigger.<br>
As can be seen from the R-D curves 120 and 122 in Fig. 2,<br>
low bit rate encoding using the YCoCg representation per-<br>
forms significantly better than that using the correspond-<br>
ing RGB representation. On the other hand, RGB-based encod-<br>
ing leads to an increasingly better performance when moving<br>
towards higher bit rates with more and more noise compo-<br>
nents getting encoded. As a consequence, there is a cross-<br>
over region 123 indicating a sub-optimal R-D performance of<br>
both alternative representations since in either case, for<br>
encoding the sample in a single color-space-representation<br>
one can only move along one or the other R-D curve. Using<br><br>
an inventive decoder 100 and a corresponding inventive en-<br>
coder, the present inventive concept solves this problem<br>
and is achieving a coding performance corresponding to<br>
curve 124, which is the R-D envelope of both the RGB-based<br>
and YCoCg-based R-D curves.<br>
Moreover, in many coding applications neither the specific<br>
coding conditions nor the typical characteristics of the<br>
source are known beforehand. Using the inventive decoder<br>
and corresponding inventive encoders, the optimum color-<br>
space-representation can be adaptively chosen to be optimum<br>
in a rate-distortion sense.<br>
Fig. 3 gives an example for a conversion of a nearly gray _<br>
signal from the RGB-color-space to the YCoCg-color-space to<br>
further explain the inventive concept and the mechanisms<br>
leading to a potential decrease in bit rate. The color<br>
transform from the RGB to the YCoCg color-space-<br>
representation can be performed in a reversible way by ap-<br>
plying the following operations to each triple of (R, G, B)<br>
or (Y,Co,Cg) values, respectively:<br><br>
In the above notation, the operator (») means bitwise<br>
movement of the underlying, bit-string to the right and is<br>
thus equivalent to a division by 2.<br>
It may again be noted that the inventive idea does not de-<br>
pend on the exact choice of the color-space-representations<br>
to switch between. In the given examples, the restriction<br>
to the cited color-space-representations is mainly because<br>
of the fact that they are widely used.<br><br>
Fig. 3 shows a graphical representation of a color-space<br>
transformation from the RGB color-space to the YCoCg color-<br>
space. The original RGB-signal 140 exemplarily has nearly<br>
equally valued R, G and B parameters, i.e. the correspond-<br>
ing pixel is nearly gray with an intensity proportional or<br>
depending on the sum of the RGB values. Since the pixel in<br>
question is nearly colorless, a transformation to the YCoCg<br>
color-space does provide parameter values that are close to<br>
zero for the chroma parameters Co and Cg, resembling the<br>
fact that the signal is nearly colorless. On the other<br>
hand, the luma parameter Y is having a father big value<br>
compared to the chroma parameters.<br>
The example shown in Fig. 3 shows a content that is pre-<br>
dominantly less color saturated in which the usage of a<br>
decorrelating color transform from RGB to, for example,<br>
YCoCg may be very helpful in terms of overall coding effi-<br>
ciency since in that case the corresponding tristimulus<br>
values (values of the single information channels within<br>
one color-space-representation) are closer to being equal<br>
to one another. If within one picture, the color saturation<br>
is rather low, the individual RGB values might differ to<br>
some extend. The sum, i.e. the Y-parameter of the YCoCg-<br>
representation may then be varying smoothly over the image,<br>
and, due to the low color saturation, the Co and Cg parame-<br>
ters are rather small. Such smoothly or nearly constant pa-<br>
rameters can be encoded more efficiently.<br>
Such, the effectiveness of a color transform may be highly<br>
dependent on the specific coding conditions. This is espe-<br>
cially true for sources that contain a high amount of sig-<br>
nal-independent, uncorrelated noise in the primary chan-<br>
nels. The color transform from RGB to YCoCg, when written<br>
in a matrix form, has matrix elements off the diagonal that<br>
are rather significant in value. The "amplification" of the<br>
Y-channel above a quantization threshold 152, which is<br>
shown for illustrative purposes only, is directly connected<br>
to these off-diagonal elements. Therefore, for the sources<br><br>
containing a high amount of signal-independent, uncorre-<br>
lated noise, the significant off-diagonal elements of a<br>
decorrelating color transform may cause a severe amplifica-<br>
tion of the noise, which in turn results in a degradation<br>
of coding efficiency in the high bit-rate range where the<br>
noise components typically are supposed to survive the<br>
quantization process.<br>
As mentioned before, with respect to Figs. 2 and 3, it can<br>
be extremely beneficial to adapt the color representation<br>
to the characteristics of the given prediction residual<br>
signal on a macro-block by macro-block (picture-block by<br>
picture-block) basis. Therefore, within a bit stream com-<br>
prising the prediction residual signals, a new syntax ele-<br>
ment could be introduced in the bit stream. That syntax<br>
element could for example, when being equal to one, indi-<br>
cate encoding and decoding of the given macro-block involv-<br>
ing the application of the color-space transformation by<br>
invoking the corresponding forward and inverse transform<br>
operations shown before. That introduced flag could, when<br>
being equal to zero or not present, further mean that the<br>
encoding and decoding process proceeds in the same way as<br>
already specified before, i.e. based on the original color<br>
space that existed before encoding.<br>
Fig. 4 shows an inventive encoder 200 for generating a rep-<br>
resentation of a picture having multiple picture blocks<br>
that are carrying picture information for picture areas<br>
that are smaller than the area of the full picture 200. The<br>
encoder 200 has a color-space transformer 202 for trans-<br>
forming the picture information of picture blocks from a<br>
first color-space representation (A) to a second color-<br>
space representation (B).<br>
Encoding the picture on a picture-block basis, the individ-<br>
ual picture-blocks 210A to 210F are input into the inven-<br>
tive encoder 200. The encoder outputs encoded picture<br><br>
blocks either in a first color-space representation (A) or<br>
in a second color-space representation (B).<br>
The encoder 200 may further comprise a transformation de-<br>
cider 214 that decides on a picture-block by picture-block<br>
basis, whether the transformation for the processed pic-<br>
ture-block shall be performed. The transformation de-<br>
cider 214 can; for example, meet the transformation deci-<br>
sion based on a maximum allowable bit rate, choosing the<br>
color-space representation providing the best possible<br>
quality at the given bit rate.<br>
Another possibility would be to define a desired maximum<br>
quality (closely connected to the coarseness of quantiza-<br>
tion) , i.e. a desired distortion value, and the transforma-<br>
tion decider 214 is working on a try and error basis, where<br>
the individual picture-blocks are generally encoded in both<br>
color-space representations and the transformation de-<br>
cider 214 is choosing the color-space transformation re-<br>
sulting in the lower bit rate. Of course, every other deci-<br>
sion rule may be used by the transformation decider, for<br>
example, based on analytical expressions or estimations<br>
based on previously tabulated sample configurations. The<br>
inventive encoder 200 may furthermore be operative to in-<br>
corporate transformation information indicating a desired<br>
transformation for a given picture block to the bit stream<br>
also having the information on the picture blocks. This<br>
signals to a corresponding decoder, whether a color-space<br>
transformation is to be performed on the decoder side or<br>
not.<br>
When introducing such an additional flag as proposed before<br>
to signal whether the color-space transformation is to be<br>
performed for a macro-block in question or not, further bit<br>
rate can be saved by entropy encoding this introduced flag,<br>
for example called mb_rct_flag ("macroblock residual color<br>
transform flag"). To achieve an efficient coding, an arith-<br>
metic coding concept can, for example, be applied to code<br><br>
the binary data. Therefore, the chosen arithmetic coding<br>
could be a binary arithmetic coding concept, relying on the<br>
probability of occurrence of values 0 or 1 per bit (or per<br>
mb_rct__flag concerning a specific macro-block) . Further-<br>
more, it would, for example, be advantageous to implement<br>
the binary arithmetic coding in an adaptive manner, i.e. in<br>
a way that the underlying probability distribution of the<br>
arithmetic coding algorithm is "learning" or updated in de-<br>
pendence on the actual occurance of mb_rct_flag's already<br>
having been encoded. That is, that the probabilities of the<br>
occurrence of the single bit values are updated once a real<br>
value is observed and thus the underlying probability dis-<br>
tribution is adapted to the actual.<br>
Furthermore, the adaptive binary arithmetic coding can also<br>
be implemented in a context sensitive manner, i.e. differ-<br>
ent probability distributions are at hand for different de-<br>
fined contexts. In other words, more than one context could<br>
be spent for mb_rct_flag. One example of a context descrip-<br>
tion is shown in Fig. 4a where, within a picture 240, three<br>
macro-blocks 242a, 242b and 242c are shown. If, for exam-<br>
ple, macro-block 242a is to be encoded, the context, i.e.<br>
the environment condition of the macro-block to be coded,<br>
could be derived by the neighboring left (a) macro-block<br>
242b and by the neighboring upper (b) macro-block 242c.<br>
Based on the<br>
mb_rct_flag's of these macro-blocks, 3 different contexts<br>
ctxldxlnc can be berived by the following expression:<br>
ctxldxlnc( C ) = (mb_rct_flag ( A ) ==0) : 0 ? 1 +<br>
(mb_rct_flag ( B ) ==0) ? 0 : 1.<br>
According to an alternative notation, this could be written<br>
as:<br>
ctxldxlnc( C ) = mb_rct_flag (A) + mb_rct_flag ( B ).<br>
It should be noted that, as already mentioned above, the<br>
mb_rct_flags do not necessarily have to be present for each<br><br>
individual macro-block. It is to be supposed that the flag<br>
is equal to 0 when not present for the evaluation of the<br>
above formula.<br>
One may, for example, further foresee an additional func-<br>
tionality, which is also signaled by a flag<br>
"rct_mode_flag". This flag' can switch the color-space-<br>
transformation on and off for a greater sample of macro-<br>
blocks that are forming , for example, a slice of macro-<br>
blocks that shares together some other distinct properties.<br>
Only if rct_mode_flag is equal to 1, mb_rct_flag's shall be<br>
present in the macro-block layer.<br>
Fig. 5 illustrates, for a simplified example, the encoding<br>
process using motion estimation and predictive residual<br>
coding. The encoding shall be shortly explained on a basis<br>
of two consecutive pictures 250 and 252. Motion estimation<br>
is presented with the help of a sample macro-block 254A in<br>
picture 252.<br>
The picture content of the macro-block 254A is also found<br>
during a motion estimation step in the picture 252, called<br>
reference picture. In the reference picture the correspond-<br>
ing macro-block 254B is displaced by a motion vector 256<br>
from its position 254A in picture 252. In case the macro-<br>
block 254B has not changed its content at all, a straight-<br>
forward way for deriving the picture portion of picture 252<br>
that corresponds to the position of the macro-block 254B<br>
would be to simply transmit the motion vector 256 within a<br>
bit stream. This enables a decoder to reconstruct picture-<br>
block 254B at the appropriate position, when the decoder<br>
has knowledge of the preceding picture 250.<br>
In a more general scenario, the picture content of the<br>
macro-block 254B will have changed with respect to the pic-<br>
ture content of the corresponding area 254A in the refer-<br>
ence picture 250. In predictive coding, only the difference<br>
of the prediction 254A to the actual content 254B is trans-<br><br>
mitted, since the residual samples are expected to be small<br>
and therefore can be coded using low bit rate. Thus,, in ad-<br>
dition to the macro-block 250A and the motion vector 256<br>
the residual signal 258 has to be computed and used for a<br>
representation of the finally transmitted signal. According<br>
to the present invention, the finally transmitted signal<br>
can either be transmitted in a first color-space represen-<br>
tation 258A or in a second color-space representation 258B<br>
depending on the bit rate or bandwidth of a transmission<br>
channel available.<br>
It is noted here that having a single motion vector for all<br>
three signal components (e.g. R, G and B), i.e. the refer-<br>
ence information is derived from the same block of the same<br>
reference picture, is the simplest possible case. In a more<br>
general approach, different motion vectors for each signal<br>
component can be derived, i.e. the reference information is<br>
derived from different picture blocks, that can addition-<br>
ally originate from different reference pictures. The pre-<br>
sent invention is thus not necessarily restricted to the<br>
case of having one motion vector, i.e., the same prediction<br>
operator for all three components. It is for example a pre-<br>
ferred embodiment of the present invention to have one sin-<br>
gle motion vector.<br>
As already mentioned above, the application in a macro-<br>
block based coding scheme using predictive residual coding<br>
is a preferred application scenario, since then the re-<br>
quired bit rate can advantageously be further decreased by<br>
simple and computationally cheap color-space transforma-<br>
tions .<br>
Fig. 6 shows an inventive bit stream 300 having multiple<br>
bit stream representations of picture-blocks 302A to 302C<br>
that can be provided in a first color-space representation<br>
(A) or in a second color-space representation (B). The in-<br>
ventive bit stream can be used by an inventive decoder al-<br>
lowing for a highly compressed transmission of a compressed<br><br>
picture or a compressed picture sequence by a transmission<br>
channel, that may be wired, wireless, or the like. Of<br>
course the storage of an inventive bit stream on a com-<br>
puter-readable storage medium is also possible, having the<br>
advantage of requiring only little storage space. The bit<br>
stream may further comprise indication information 304 in-<br>
dicating the desired color-space-transformation of picture-<br>
block 302B.<br>
Although the previously described embodiments of the pre-<br>
sent invention have been described mainly using the RGB and<br>
YCoCg-spaces, the present invention is not at all limited<br>
to the use of those color-spaces. In a further embodiment,<br>
arbitrary other color-spaces or other means of decorrelat-<br>
ing inter-color techniques may be used and it is even pos-<br>
sible to provide an inventive encoder or decoder capable of<br>
transforming between three or more different color-space<br>
representations.<br>
Although the present invention has been mainly described<br>
with respect to video coding, it may also advantageously be<br>
used for coding of still images. Furthermore, the number of<br>
samples may be varied.<br>
Depending on certain implementation requirements of the in-<br>
ventive methods, the inventive methods can be implemented<br>
in hardware or in software. The implementation can be per-<br>
formed using a digital storage medium, in particular a<br>
disk, DVD or a CD having electronically readable control<br>
signals stored thereon, which cooperate with a programmable<br>
computer system such that the inventive methods are per-<br>
formed. Generally, the present invention is, therefore, a<br>
computer program product with a program code stored on a<br>
machine-readable carrier, the program code being operative<br>
for performing the inventive methods when the computer pro-<br>
gram product runs on a computer. In other words, the inven-<br>
tive methods are, therefore, a computer program having a<br><br>
program code for performing at least one of the inventive<br>
methods when the computer program runs on a computer.<br>
While the foregoing has been particularly shown and de-<br>
scribed with reference to particular embodiments thereof,<br>
it will be understood by those skilled in the art that<br>
various other changes in the form and details may be made<br>
without departing from the spirit and scope thereof. It is<br>
to be understood that various changes may be made in adapt-<br>
ing to different embodiments without departing from the<br>
broader concepts disclosed herein and comprehended by the<br>
claims that follow.<br><br>
WE CLAIM:<br>
1. Hybrid video decoder (100) for reconstructing a picture represented in a<br>
representation having a first (104A) and a second picture block (104B) that are<br>
encoded in a predictive coding scheme, the picture blocks carrying picture<br>
information for picture areas smaller than the area of the picture, wherein the<br>
first picture block (104A) is carrying the picture information in a first color-space<br>
representation of a prediction residual and the second picture block (104B) is<br>
carrying the picture information in a second color-space representation of the<br>
prediction residual, the decoder comprising:<br>
a color-space transformer (102) for transforming either the color-space<br>
representation of the first picture block (104A) to the second color-space<br>
representation or the color-space representation of the second picture block<br>
(104B) to the first color-space representation,<br>
characterized by comprising:<br>
a requantizer for deriving the picture information describing the prediction<br>
residual of the first (104A) and the second picture block (104B) from a quantized<br>
representation of the picture information,<br><br>
wherein the decoder (100) comprises an entropy decoder for deriving the<br>
quantized representation of the picture information from an entropy encoded<br>
representation of the quantized representation of the picture information using a<br>
decoding rule.<br>
2.	Decoder (100) as claimed in claim 1, wherein the color-space transformer (102)<br>
is operative to process transformation indication information indicating a desired<br>
transformation for a picture block; and wherein the decoder (100) is having a<br>
flag receiver (108) for receiving the transformation indication information.<br>
3.	Decoder (100) as claimed in claim 1, wherein the color-space transformer (102)<br>
is operative to process the RGB-color-space and a second color-space<br>
representation comprising one luma-parameter indicating a brightness and two<br>
chroma parameters indicating a chromatic composition of a signal.<br>
4.	Decoder (100) as claimed in claim 3, wherein the color-space transformer (102)<br>
is operative to perform the color-space transformation between the RGB-color-<br>
space described by parameters R, G, and B and the second color-space<br>
representation described by the luma parameter Y and the chroma parameters<br>
Cg and Co, wherein the luma parameter and the chroma parameters are derived<br>
according to the formulas:<br><br><br>
5.	Decoder (100) as claimed in claim 2, wherein the luma parameter and the<br>
chroma parameter is derived according to the formulas:<br><br>
6.	Decoder (100) as claimed in any of the preceding claims, wherein the color-<br>
space transformer (102) is operative to perform the transformation based on a<br>
parametric representation of the picture information within the picture blocks, the<br>
parametric representation describing the picture information in a transform<br>
domain.<br>
7.	Decoder (100) as claimed in claim 6, wherein the color-space transformer (102)<br>
is operative to perform the transformation based on a parameter representation<br>
describing the picture information in a frequency domain.<br><br>
8.	Decoder (100) as claimed in any of the preceding claims, wherein the entropy<br>
decoder is operative to use an entropy decoding rule comprising the use of a<br>
Variable-length-codebook.<br>
9.	Decoder (100) as claimed in any of the preceding claims, wherein the entropy<br>
decoder is operative to use a entropy decoding rule comprising the use of a<br>
binary arithmetic coding algorithm.<br>
10.	Decoder (100) as claimed in any of the preceding claims, wherein the entropy<br>
decoder is operative to use a decoding rule having one or more sub-rules chosen<br>
depending on a decoding context.<br>
11.	Decoder (100) as claimed in any of the preceding claims, wherein the decoder is<br>
operative to reconstruct the picture using information from reference pictures of<br>
a picture stream, which are temporarily preceding or following the picture within<br>
the picture stream and that are represented using related picture blocks<br>
corresponding to the picture blocks of the picture, the related picture blocks<br>
having picture information on the same picture content as the picture blocks<br>
(104A, 104B), wherein a positional change between the picture blocks and the<br>
corresponding picture blocks of the reference pictures with respect to a fixed<br>
location of the given picture blocks can be described by motion vectors.<br><br>
12.	Decoder (100) as claimed in claim 11, wherein the decoder is operative to<br>
reconstruct the picture blocks (104A, 104B) using the corresponding picture<br>
blocks and differential picture blocks predicting a change in picture information of<br>
the picture blocks with respect to the corresponding picture blocks.<br>
13.	Decoder (100) as claimed in claims 11 or 12, comprising an input interface for<br>
receiving a bit stream representation of the picture stream having the information<br>
of the single pictures of the picture stream.<br>
14.	Decoder (100) as claimed in any of the preceding claims, comprising a picture<br>
composer for reconstructing the picture using the first (104A) and the second<br>
picture block (104B).<br>
15.	Decoder (100) as claimed in any of the preceding claims, wherein the color-space<br>
transformer (102) is operative to process bypass information indicating a<br>
sequence of picture blocks and to switch off color-space transformation for the<br>
sequence of picture blocks indicated by the bypass information.<br><br>
16. Hybrid video encoder (200) for generating a representation of a picture (212)<br>
having picture blocks (212A, 212B) that are encoded in a predictive coding<br>
scheme, the picture blocks carrying picture information for picture areas smaller<br>
than the area of the picture (210) in a first color-space representation of a<br>
prediction residual, the encoder (200) comprising:<br>
a color-space-transformation decider (214) adapted to decide whether a color-<br>
space transformation for the picture blocks is to be performed or not;<br>
a color-space transformer (202) for, depending on the decision, transforming the<br>
picture information of the prediction residual of the picture blocks (212A, 212B)<br>
to a second color-space representation and incorporating the picture information<br>
of the picture blocks into the representation in the second color-space<br>
representation or the first color-space representation, wherein the color-space<br>
transformer (202) is configured to transform the picture information of the<br>
selected picture blocks (212A, 212B) to the second color-space representation<br>
and incorporate the picture information of the selected picture blocks into the<br>
representation in the second color-space representation and the picture<br>
information of the other picture blocks into the representation in the first color-<br>
space representation,<br>
characterized in that the color-space-transformation decider (214) is adapted to<br>
decide whether the transformation for the picture blocks is to be performed or<br>
not on a picture-block by picture-block basis using a decision rule that is selecting<br><br>
picture blocks in a rate-distortion optimal way, and to generate transformation<br>
information indicating the selected picture blocks to be transformed.<br>
17.	Encoder (200) as claimed in claim 16, wherein the color-space transformation<br>
decider (214) is operative to use a decision rule that is selecting the picture block<br>
requiring less information units when transformed to the second color-space<br>
representation.<br>
18.	Encoder (200) as claimed in claim 16 or 17, comprising an output interface for<br>
outputting a bit stream (300) having the picture information including the<br>
information of the first (214A) and the second picture block (212B).<br>
19.	Method of hybrid video decoding a picture represented in a representation having<br>
a first (104A) and a second (104B) picture block that are encoded in a predictive<br>
coding scheme, the picture blocks carrying picture information for picture areas<br>
smaller than the area of the picture,<br>
transforming either the color-space representation of the first picture block<br>
(104A) to the second color-space representation or the color-space<br>
representation of the second picture block (104B) to the first color-space<br>
representation,<br><br>
characterized in that the first picture block (104A) is carrying the picture<br>
information in a first color-space representation of a prediction residual and the<br>
second picture block (104B) is carrying the picture information in a second color-<br>
space representation of the prediction residual.<br>
20. Method of generating, using hybrid video coding, a representation of a picture<br>
having picture blocks (212A, 212B) that are encoded in a predictive coding<br>
scheme, the picture blocks carrying picture information for picture areas smaller<br>
than the area of the picture in a first color-space representation of a prediction<br>
residual, the method comprising:<br>
deciding whether a color-space transformation for the picture blocks is to be<br>
performed or not;<br>
transforming, depending on the decision, the picture information of the prediction<br>
residual of the picture blocks (212B) to a second color-space representation;<br>
incorporating, depending on the decision, the picture information of the picture<br>
blocks into the representation in the second color-space representation or the<br>
first color-space representation;<br>
deriving a quantized representation of the representation of the picture blocks;<br>
and<br><br>
deriving an entropy encoded representation of the quantized representation of<br>
the picture blocks using an encoding rule;<br>
characterized in that the decision whether the color-space transformation for the<br>
picture blocks is to be performed or not is performed on a picture-block by<br>
picture-block basis using a decision rule that is selecting picture blocks in a rate-<br>
distortion optimal way, with generating transformation information indicating the<br>
selected picture blocks to be transformed,<br>
wherein the transforming is performed such that the picture information of the<br>
selected picture blocks (212A, 212B) is transformed to the second color-space<br>
representation, and the incorporating is performed such that the picture<br>
information of the selected picture blocks is incorporated into the representation<br>
in the second color-space representation and the picture information of the other<br>
picture blocks is incorporated into the representation in the first color-space<br>
representation.<br><br><br><br>
ABSTRACT<br><br><br>
TITLE " Hybrid Video decoder and encoder for implementing<br>
methods of generating and decoding of a picture represented in a<br>
representation"<br>
The invention relates to a Hybrid video decoder (100) for reconstructing a<br>
picture represented in a representation having a first (104A) and a second<br>
picture block (104B) that are encoded in a predictive coding scheme, the<br>
picture blocks carrying picture information for picture areas smaller than<br>
the area of the picture, wherein the first picture block (104A) is carrying<br>
the picture information in a first color-space representation of a prediction<br>
residual and the second picture block (104B) is carrying the picture<br>
information in a second color-space representation of the prediction<br>
residual, the decoder comprising: a color-space transformer (102) for<br>
transforming either the color-space representation of the first picture<br>
block (104A) to the second color-space representation or the color-space<br>
representation of the second picture block (104B) to the first color-space<br>
representation, characterized by comprising: a requantizer for deriving the<br>
picture information describing the prediction residual of the first (104A)<br>
and the second picture block (104B) from a quantized representation of<br>
the picture information, wherein the decoder (100) comprises an entropy<br>
decoder for deriving the quantized representation of the picture<br>
information from an entropy encoded representation of the quantized<br>
representation of the picture information using a decoding rule.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1jb3JyZXNwb25kZW5jZSBvdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1mb3JtIDIucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1pbnRlcm5hdGlvbmFsIHNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-international search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1wY3QgcHJpb3JpdHkgZG9jdW1lbnQgbm90aWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-pct priority document notification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC1wY3QgcmVxdWVzdCBmb3JtLnBkZg==" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-pct request form.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDI4NjMta29sbnAtMjAwOC10cmFuc2xhdGVkIGNvcHkgb2YgcHJpb3JpdHkgZG9jdW1lbnQucGRm" target="_blank" style="word-wrap:break-word;">02863-kolnp-2008-translated copy of priority document.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgwMi0wNS0yMDE0KS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(02-05-2014)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1GT1JNLTMucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-FORM-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxNy0xMi0yMDEzKS1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(17-12-2013)-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgxOC0xMi0yMDEyKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(18-12-2012)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LSgyMi0wNy0yMDA4KS1GT1JNIDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-(22-07-2008)-FORM 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUNBTkNFTExFRCBQQUdFUy5wZGY=" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-CANCELLED PAGES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LUNPUlJFU1BPTkRFTkNFIDEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-CORRESPONDENCE 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LUNPUlJFU1BPTkRFTkNFIDEuMi5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-CORRESPONDENCE 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUZPUk0gMTMucGRm" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-FORM 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUZPUk0gMTgtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-FORM 18-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUZPUk0gMjYucGRm" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-FORM 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtRk9STSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUdSQU5URUQtU1BFQ0lGSUNBVElPTi1DT01QTEVURS5wZGY=" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-GRANTED-SPECIFICATION-COMPLETE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LUlOVEVSTkFUSU9OQUwgUFJFTElNSU5BUlkgRVhBTUlOQVRJT04gUkVQT1JULnBkZg==" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-INTERNATIONAL PRELIMINARY EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-INTERNATIONAL SEARCH REPORT &amp; OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAxLjEucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-INTERNATIONAL SEARCH REPORT 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LU9USEVSUyAxLjEucGRm" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-OTHERS 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LU9USEVSUy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-OTHERS-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1LT0xOUC0yMDA4LVBBLnBkZg==" target="_blank" style="word-wrap:break-word;">2863-KOLNP-2008-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LVBFVElUSU9OIFVOREVSIFJVTEUgMTM3LnBkZg==" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg2My1rb2xucC0yMDA4LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">2863-kolnp-2008-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMDI4NjMta29sbnAtMjAwOC5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-02863-kolnp-2008.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="262884-a-composition-for-treating-metal-surface-to-form-a-conversion-or-passivation-coating.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="262886-a-rocker-arm-assembly-in-a-valve-train-of-an-internal-combustion-engine.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>262885</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2863/KOLNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>39/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>26-Sep-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>22-Sep-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>14-Jul-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C 80686 MUNICH</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DETLEV MARPE</td>
											<td>SÜDWESTKORSO 70, 12161 BERLIN</td>
										</tr>
										<tr>
											<td>2</td>
											<td>PETER KAUFF</td>
											<td>JOACHIM-FRIEDRICH-STR. 13 10711 BERLIN</td>
										</tr>
										<tr>
											<td>3</td>
											<td>THOMAS WIEGAND</td>
											<td>FASANENSTRASSE 42 10719 BERLIN</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2006/001292</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-02-13</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>PCT/EP2006/000286</td>
									<td>2006-01-13</td>
								    <td>EPO</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/262885-hybrid-video-decoder-and-encoder-for-implementing-methods-of-generating-and-decoding-of-a-picture-represented-in-a-representation by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:09:31 GMT -->
</html>
