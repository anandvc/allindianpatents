<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/225836-a-system-and-a-method-for-speech-to-speech-generation by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:42:46 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 225836:A SYSTEM AND A METHOD FOR SPEECH-TO-SPEECH GENERATION</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A SYSTEM AND A METHOD FOR SPEECH-TO-SPEECH GENERATION</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>ABSTRACT SPEECH-TO-SPEECH GENERATION SYSTEM AND METHOD This invention discloses a expressive speech-to-speech generation system and method. The system and method can generate expressive speech output by using expressive parameters extracted from the original speech signal to drive the standard TTS system. The system comprises: speech recognition means, machine translation means, text-to-apeech generation means, expressive parameter detection means for extracting expressive parameters from the speech of language A, and expressive parameter mapping means for mapping the expressive parameters extracted by the expressive parameter detection means from language A to language B, and driving the text-co-speech generation means by the mapping results to synthesize expressive speech. The system and method can improve the quality of Che speech output of Che translating system or TTS system.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td><br><br><br><br><br>
SPEECH-TO-SPEECH GENERATION SYSTEM AND METHOD Field of the invention<br>
This invention relates generally to The field of machine translation, and in. particular to an expressive speech-to-speech generation system and method.<br>
Background of the Invention<br>
Machine translation is a technique to convert the text or speech of a language to that of another language by using a computer.  In other words, the machine translation is to automatically translate one language into another language without the involvement of human labor by using the huge memory capacity and digital processing ability of computer to generate dictionary and syntax with mathematics method, based on the theory of language formation and structure analysis.<br>
Generally speaking, current machine translation system is a text-based translation system, which translates the text of one language to that of another language. But with the development of society, the speech-based translation system is needed. By using current speech recognition technique, text-based translation technique and TTS (text-to-speech) technique, a first language speech may be recognized with the speech recognition technique and transformed into the text of the language,- then the text of the first language is translated into that of a second language, based on which, the speech of the second language is generated by using the TTS technique.<br>
However, the existing TTS systems usually produce inexpressive and monotonous speech.  For a typical TTS system available today, the standard pronunciations of all the words (in syllables) are first recorded and analyzed, and then relevant parameters for standard "expressions" at the word level are scored in a dictionary, A  synthesized word is generated from the component syllables, with standard control parameters defined in a dictionary, using the usual smoothing techniques to stitch the components together. Such a speech production cannot create speech chat is full of expressions based on the meanings of the sentence and the emotions of the speaker.<br>
Therefore, the embodiment of the present invention provides an expressive speech-to-speech system and method.<br><br>
According to the embodiment of the present invention, an expressive speech-to-speech system and method uses expressive parameters obtained from the original speech signal to drive a standard TTS system to generate expressive speech.<br>
According to one aspect oE the invention there is provided a speech-to-speech generation system as described in claim 1.<br>
According to a second aspect of the invention there is provided a speech-to-speech generation system as described in claim 6.<br>
According to a third aspect of the invention there is provided a method of speech-to-speech generation as described in claim 10.<br>
According to a fourth aspect of the invention there is provided a method of speech-to-speeCh generation as described in claim 16.<br>
The expressive speech-to-speech system and method of the present embodiment can improve the speech quality of translating system or TTS system.<br>
The aforementioned and further objects and features of the invention could be better illustrated in the following detailed description with accompanying drawings. The detailed description and embodiments are only intended to illustrate the invention.<br>
BRIEF DESCRIPTION OP THE DRAWINGS<br>
Fig. 1 is a block diagram of an expressive speech-to-speech system according to the present invention;<br>
Fig. 2 is a block diagram of an expressive parameter detection means in Fig. 1 according to an embodiment of the present invention.-<br>
Fig. 3 is a block diagram showing an expressive parameter mapping means in Fig. 1 according to an embodiment of the present invention;<br>
Fig. 4 is a block diagram showing an expressive speech-to-speech system according to another embodiment of the present invention;<br><br>
Fig. 5 is a flowcharc showing procedures of expressive speech-to-speech translation according to an embodiment of the presenc invention;<br>
Fig. 6 is a flowchart showing procedures of detecting expressive parameters according to an embodiment of the present invention;<br>
Fig. 7 is a flowchart showing procedures of mapping detecting expressive parameters and adjusting TTS parameters according to an embodiment of the present invention; and<br>
Fig. 8 is a flowcharc showing procedures of expressive speech-to-speech translation according to another embodiment of the present invention-<br>
DETAILED OBSCHIPTION OF THE PREFERRED EMBODIMENTS<br>
As shown in Fig. 1, an expressive speech-to-speech system according to an embodiment of the present invention comprises: speech recognition means 101. machine translation means 102, text-to-speech generation means 10 3. expressive paramecer detection means 104 and expressive paramecer mapping means 105.  The speech recognition means 101 is used to recognize the speech of language A and create the coctesponding text of language A; the machine translation means 102 is used Co Cranslate the Cext from language A to lang-Jage B; the text-to-speech generation means 103 is used to generate the speech of language B according to the text of language B; the expressive parameter detection means 104 is used to extract expressive parameters from the speech of language A; and the expressive parameters mapping means 105 is used Co mapping The expressive paramecers extracted by the expressive parameter detection means from language A to language B and drive The text-to-speech generation means by the mapping results to synthesize expressive speech.<br>
As known to those skilled in the art, there are many prior arts to accomplish the Speech Recognition Means. Machine Translation Means and TTS Means. So we only describe expressive parameter detection means and expressive parameter mapping means according to an embodiment of this invention with Fig. 2 and Fig. 3.<br>
Firstly, the key parameters Chat reflect the expression of speech were introduced.<br><br>
The key parameters of speech, which control expression, can be defined aC different levels.<br>
1.	AC word level, the key expression parameters are; speed (durations,<br>
volume (energy level) and pitch [including range and tone).  Since a<br>
word generally consists of several characters/syllables (most words<br>
have two or more characters/syllables in Chinese), such expression<br>
parameters must also be defined at the syllable level, in the form<br>
of vectors or timed sequences. For example, when a person speaks<br>
angrily, the word volume is very high, the words pitch is higher<br>
than normal condition and its envelope is not smooth, and many of<br>
pitch mark points even disappear. And at the same time The duration<br>
becomes shorter. Another example is Chat when we speak a sentence in<br>
a normal way. we would probably emphasize some words in the<br>
sentence, changing the pitch, energy and duration of these words.<br>
2.	At sentence level, we focus on the intonation. For example, the<br>
envelope of an exclamatory sentence is different from that of a<br>
declarative statement.<br>
The following is to describe how The expressive parameter detection means and the expressive parameter mapping means work according to this invention with Fig. 2 and Fig. 3- That is how to extract expressive parameters and use the extracted expressive parameters to drive the text-to-speech generation means to synthesize expressive speech.<br>
As shown in Fig. 2, the expressive parameter detection means of the invention includes the following components:<br>
Part A: Analyze the pitch, duration and volume of The speaker, in Part A, we exploiC the resulc of Speech Recognition to get the alignment result between speech and words (or characters). And record it in the following structure:<br><br><br><br>
Then we use Short Time Analysis method to get such parameters:<br>
1.	Short time energy of each Short Time Window.<br>
2.	Detect the pitch contour of the word.<br>
3.	The duration of the words.<br>
According these parameters, we take a step forward to get the following parameters:<br>
1.	Average Short time energy in the word.<br>
2.	Top M short time energy in the word.<br>
3.	Pitch range, maximum pitch, minimum pitch, and the value of<br>
the pitch in the word.<br>
4.	The duration of the word.<br>
Part B: according to the text of the result of speech recognition, we use a standard language A TTS System to generate the speech of language A without expression, and then analyze the parameters of the no expressive TTS. The parameters are the reference of analysis of expressive speech. Part C: we analyze the variation of the parameters for these words in a sentence forming expressive and standard speech. The reason is that different people speak with different volume and pitch at different speeds. Even for a person, when he speaks the same sentences at different time, these parameters are not the same. So in order to analyze the role of the words in a sentence according to the reference speech, we use the relative parameters.<br>
We use normalized parameter method to get the relative parameters from absolute parameters. The relative parameters are:<br>
1. The relative average Short time energy in the word.<br><br>
2.	The relative Top N shore time energy in the word.<br>
3.	The relative Pitch range, relative maximum pitch, relative<br>
minimum pitch in the word.<br>
4.	The relative duration of the word.<br>
Part V:   analyze the expressive speech parameters at word level and at sentence level according to the reference that comes from the standard speech parameters.<br>
1.	At The word level, we compare the relative parameters of the expressive speech with Chose of the reference speech to see which parameters of words vary violently.<br>
2.	At the sentence level, we sort the words according to their variation level and word property, and geC the key expressive words in The sentences.<br>
part E;  according to The result of paracnecers comparison and the knowledge that what cerCain expression will cause what parameters vary, we get The expressive information of the sentence, i.e. detect the expressive parameters, and record The parameter according Co the following structure:<br><br>
For example, when we speak "i-!" angrily in Chinese, many pitthes disappear, and The absolute volume is higher than reference and at the same time the relative volume is very sharp, and the duration is much shorter than the reference. Thus, it can be concluded that the expression at the sentence level is angry.  The key expressive word is  "iSf.<br><br>
The following is to describe how the expressive parameter mapping means according to an embodiment of this invention is structured, with reference to Fig. 3A and Fig. 3B. The expressive parameter mapping means comprises;<br>
Part A: Mapping the structure of expressive parameters from language A to language B according to the machine translation result. The key method is to find out what words in language B to which the words in language A, which are important for showing expression, correspond. The following is the mapping result:<br>
Sentence content for language B I<br>
Sentence Expressive type; word content of  language B {  Text;<br>
Soundslike;<br>
Position in sentence;<br>
Word expressive information in language A;<br>
Word expressive information in language B; } }<br>
Word expressive of language A f        Text; Expressive type; Expressive level; "Expressive parameters; }<br>
Word expressive of language B ( Expressive type; Expressive level;<br>
•Expressive parameters;<br>
Part B: Based on the mapping result of expressive information, the adjustment parameters that can drive the TTS for language are generated. By this means, we use an expressive parameter table of language B to give<br><br>
out which words use what a set of parameters according to the expressive parameters. The parameters in the table are the relative adjusting parameters.<br>
The process is shown in Fig. 3B. The expressive parameters are converted by converting tables of two levels (words level converting table and sentence level converting table), and become the parameters for adjusting the cext-to-speech generation means.<br>
The converting cables of the two levels are:<br>
1.    The word level converting table, for converting expressive parameters to the parameters that adjust TTS.<br>
The following is the structure of the table:<br>
Structure of Word TTS adjusting Parameters table {<br>
Expressive_Type ; Expressive_Para;<br>
TTS adjusting parameters; );<br>
Structure of TTS adjusting parameters {<br>
float Fseii_P__rat6; float Fsen_ain_rate; float Fph_t_rate;<br>
struct Equation Expressive_equat; ( for changing the curve characteristic of  pitch contour) I;<br>
2.    The sentence level converting table, for giving out the prosody<br>
parameters of the sentence level according to emotional type of the sentence to adjust the parameters at the word level adjustment TTS.<br>
Structure of sentence TTS adjusting Parameters table {<br>
Emotion_Type ;<br>
Words_PQsition; Words__property;<br><br>
TTS adjusting parameters;<br>
!;<br>
Structure of TTS adjusting parameters {<br>
float Fsen_P_rate;<br>
float Fsen_am_rate;<br>
float Fph_t_rate;<br>
struct Equation Expressive_equat; ( Cor changing the curve characteristic of  pitch contour) );<br>
The speech-to-speech system according to the present invention has been described as above in connection with embodiments. As known to those skilled in the art, the present invention can also be used to translate different dialects of the same language. As shown in Pig. 4, the system is similar to that in Fig. 1. The only difference is that the translation between different dialects of the same language does not need the machine translation means, in particular, the speech recognition means 101 is used to recognize the speech of language A and create the corresponding text of language A; the text-to-speech generation means 103 is used to generate the speech of language B according to the text of language B; the expressive parameter detection means LQ4 is used to extract expressive parameters from the speech of dialect A; and the expressive parameter mapping means<br>
105 is used to map the expressive parameters extracted by expressive parameter detection means 104 from dialect A to dialect B and drive the text-to-speech generation means with the mapping results to synthesize expressive speech.<br>
The expressive speech-to-speech system according to the present invention has been described in connection with Fig. 1-4. The system generates expressive speech output by using expressive parameters extracted from the original speech signals to drive the standard TTS system.<br><br>
The present invention also provides an expressive speech-to-speech method.  The following is to describe an embodiment of speech-co-speech translation process according to the invention, with Fig. 5-8.<br>
As shown in Fig. 5, an expressive speech-to-speech method according to an embodiment of the invention comprises The steps of: recognizing the speech of language A and creating the corresponding text of language A<br>
(501); translating The text from language A to language B (SD2J; generating the speech of language B according Co the text of language B<br>
(503); extracting expressive parameters from the speech of language A<br>
(504); and mapping the expressive parameters extracted by the detecting steps from language A to language B, and driving The cext-to-speech generation process by the mapping results to synthesize expressive speech<br>
(505) .<br>
The following is to describe the expressive detection process and the expressive mapping process according to an embodiment of the present invention, with Fig. 6 and Fig. 7. That is how to extract expressive parameters and use the extracted expressive parameters to drive the existing TTS process to synthesize expressive speech. As shown in Fig. 6. the expressive detection process comprises The steps of;<br>
Step 601: analyze the pitch, duration and volume of the speaker. In Step 601, we exploit the result of speech recognition to get the alignment result between speech and words tor characters) .  Then we use Short Tiitie Analyze method to get such parameters:<br>
1.  Short time energy of each Short Time Window. 2 .   Detect the pitch contour of the word. 3. The duration of The words.<br>
According these parameters, we take a step forward to get The following parameters:<br>
1.	Average Short time energy in the word.<br>
2.	Top N short time energy in The word.<br>
3.	Pitch range, maximum pitch, minimum pitch, and pitch number in<br>
The word. i.   The duration of the word.<br><br>
step 602: according to the text that is the result of speech recognition, we use a standard language A TTS System to generate the speech of language A  without expression. Then analyze the parameters of the inexpressive TTS. The parameters are the reference of analysis of expressive speech.<br>
Step 603: Analyze the variation of the parameters for these words in the sentence that is from expressive and standard speech. The reason is that different people maybe speak with different volume, different pitch, at different speed. Even for a person, when he speaks the same sentences at different time, these parameters are not the same. So in order to analyze the role of the words in the sentence according to the reference speech, we use the relative parameters.<br>
We use normalized parameter method to get the relative parameters from absolute parameters. The relative parameters are:<br>
l.The relative average short time energy in the word.<br>
2.The relative top N short time energy in the word.<br>
3.The relative pitch range, relative maximum pitch, relative<br>
minimum pitch in the word. 4.The relative duration of the word.<br>
Step 604: analyze the expressive speech parameters at word level and at sentence level according to the reference that comes from the standard speech parameters.<br>
1.	At the word level, we compare the relative parameters of the expressive speech with those of the reference speech to see which parameters of which words vary violently.<br>
2.	At the sentence level, we sort the words according to their variation level and word property, to get the key expressive words in the sentences.<br>
Step 605:  according to the result of parameters comparison and the knowledge that what certain expression will cause what parameters vary, we get the expressive information of the sentence or in another word, detect the expressive parameters.<br>
Next, we describe the expressive mapping process according to an embodiment of the present invention in connection with Fig. 7. The process comprises steps o£:<br><br>
step 701: mapping the structure of expressive parameters from language A to language B according to The machine translation result. The key method is to find out the words in language B corresponding to those in language A that are important for expression transfer.<br>
Step 702: according to the mapping result of expressive information, generate the adjusting parameters that could drive language B TTS. By this means, we use an expressive parameter table of language B. according to which the word or syllable synthesis parameters are provided.<br>
The speech-to-speech method according to the present invention has been described in connection with embodiments. As known to those skilled in the art, the present invention can also be used to translate different dialects of the same language. As shown in Fig. 8, the processes are similar to those in Fig. 5. The only difference is that the translation between different dialects of the same language does not need the text translation process. In particular, the process comprises the steps of; recognizing the speech of dialect A, and creating the corresponding text (801); generating the speech of language B according to the text of language B (3021; extracting expressive parameters from the speech of dialect A  (803); and mapping the expressive parameters extracted by the detecting steps from dialect A CO dialect B and then applying the mapping results to the text-to-speech generation process to synthesize expressive speech (804).<br>
The expressive speech-to-speech system and method according to the preferred embodiment have been described in connection with figures. Those having ordinary skill in the art may devise alternative embodiments without departing from the sprit and scope of the present invention. The present invention includes all those modified and alternative embodiments. The scope of the present invention shall be limited by the companying claims.<br><br><br><br>
CLAIMS<br>
1.	A speech-to-speech generation system, comprising:<br>
speech recognition means, for recognizing the speech of language A and creating the corresponding text of language A;<br>
machine translation means for translating the text from language A to language B;<br>
text-Co-speech generation means. Cor generating Che speech of language B according to the text of language B,<br>
said speech-to-speech translation system is characterized by further comprising:<br>
expressive parameter detection means, for extracting expressive parameters from the speech of language A; and<br>
expressive parameter mapping means for mapping the expressive parameters extracted by the expressive parameter detection means from language A to language B, and driving the text-to-speech generation means by the mapping results to synthesize expressive speech.<br>
2.	A system according to claim 1, characterized in that: said expressive parameter detection means extracts the expressive parameters at different levels.<br>
3.	A system according to claim 2. characterized in that said expressive parameter detection means extracts the expressive parameters at Che word level.<br>
4.	A system according to claim 2, characterized in Chat said expressive parameter deteccion means extracts the expressive parameters at the sentence level.<br>
5.	A system according to any one of claims 1 to 4. characterized in that said expressive parameter mapping means maps the expressive parameters from language A to language B. then converts the expressive parameters of language B into the parameters for adjusting the<br>
text-Co-speech generation means by the word level converting and the sentence level converting.<br><br>
6.	A speech-to-speech generation system, comprising:<br>
speech recognition means for recognizing the speech of dialect A and creating the corresponding text;<br>
text-to-speech generation means for generating the speech of another dialect B according to the text,<br>
said speech-to-speech generation system is characterized by further comprising:<br>
expressive parameter detection means, for extracting expressive parameters from the speech of dialect A; and<br>
expressive parameter mapping means, for mapping the expressive parameters extracted by the expressive parameter detection means from dialect A to dialect B, and driving the text-to-speech generation means by the mapping results to synthesize expressive speech-<br>
7.	A system according to claim 6, characterized in that said expressive<br>
parameter detection means extracts the expressive parameters at different<br>
levels.<br>
a.    A system according to claim 7, characterized in that said expressive parameter detection means extracts the expressive parameters at the word level.<br>
9.	A system according to claim 7. characterized in that said expressive parameter detection means extracts the expressive parameters at the sentence level,<br>
10.	A system according to any one of claims 6 to 9,   characterized in that said expressive mapping means maps the expressive parameters from dialect A to dialect B, then converting the expressive parameters of dialect B into the parameters for adjusting the text-to-speech generation means by the word level converting and the sentence level converting.<br>
11.	A speech-to-speech generation method, comprising the steps of: recognizing the speech of language A and creating the corresponding text of language A;<br>
translating the text from language A to language B;<br><br>
generating the speech of language B according to the text of language B,<br>
said expressive speech-to-speech method is characterized by further comprising the steps of:<br>
extracting expressive parameters from the speech of language A; and<br>
mapping the expressive parameters extracted by the detecting steps from language A to language B, and driving the text-to-speech generation process by the mapping results to synthesize expressive speech.<br>
12.	A method according to claim 11, characterized in that extracting the expressive parameters is performed at different levels.<br>
13.	A method according to claim 12, characterized in that said different levels include the word level.<br>
14.	A method according to claim 12. characterised in that said different levels include the sentence level.<br>
15.	A method according to any one of claims 11 to 14. characterized in that mapping the expressive parameters from language A to language B, further comprises the step of  converting the expressive parameters of language B into the parameters for adjusting the text-to-speech generation means by the word level converting and the sentence level converting.<br>
16.	A speech-to-speech generation method, comprising the steps of:<br>
recognizing the speech of dialect A and creating the corresponding text;<br>
generating the speech of another dialect B according to the text, said speech-to-speech generation method is characterized by further comprising steps:<br>
extracting expressive parameters from the speech of dialect A; and<br>
mapping the expressive parameters extracted by the detecting steps from dialect ft to dialect B, and driving the text-to-speech generating process by the mapping results to synthesis expressive speech.<br><br>
17.	A method according co claim 16. characterized in that extracting the expressive parameters is performed ac differenc levels.<br>
18.	A method according to claim 17. characterized in Chac said different levels include the word level.<br>
19.	A method according to claim 17, characterized in that said different levels include the sentence level.<br>
20.	A method according to any one of claims 16 to 19. characterized in that mapping the expressive parameters from dialecC A to dialecC B, further comprises the step of  converting Che expressive parameters of dialecC B inCo Che parameters for adjusting Che text-to-speech generation means by the word level converting and the sentence level converting.<br><br>
21. A speech-to-speech generation system substantially as herein described with reference to the accompanying drawings.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGFic3RyYWN0IGR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 abstract duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGNsYWltcyBkdXBsaWNhdGUucGRm" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 claims duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGNvcnJlc3BvbmRlbmNlIG90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGNvcnJlc3BvbmRlbmNlIHBvLnBkZg==" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 correspondence po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGRlc2NyaXB0aW9uIChjb21wbGV0ZSkgZHVwbGljYXRlLnBkZg==" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 description (complete) duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGRyYXdpbmdzIGR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 drawings duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIGZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIHBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 pct.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTU5Mi1jaGVucC0yMDAzIHBldGl0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">1592-chenp-2003 petition.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="225835-a-method-of-producing-a-ss-alanine-free-spray-dryable-pantothenate-composition.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="225837-a-stabiliser-combination-for-halogen-containing-polymers-and-the-application-thereof.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>225836</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1592/CHENP/2003</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>02/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>09-Jan-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>01-Dec-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>08-Oct-2003</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INTERNATIONAL BUSINESS MACHINES CORPORATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>NEW ORCHARD ROAD, ARMONK, NEW YORK 10504</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>TANG, DONALD</td>
											<td>49 FOX DEN ROAD, MT. KISCO, NY 10549</td>
										</tr>
										<tr>
											<td>2</td>
											<td>SHEN, LIQIN</td>
											<td>5-10-09 XINKANG YUAN, XIAOQU, XISANQI, BEIJING 100096,</td>
										</tr>
										<tr>
											<td>3</td>
											<td>SHI, QIN</td>
											<td>2-401, 13 NO, JU YUAN SHANGDI, HAIDIAN DISTRICT, BEIJING 100085,</td>
										</tr>
										<tr>
											<td>4</td>
											<td>ZHANG, WEI</td>
											<td>RM 442 BLD 25, FANGHUNI YUAN, YIHE SHANGZHUANG, HAIDIAN DISTRICT, BEIJING 100095,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G10 L 13/04</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/GB02/01277</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2002-03-15</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>01116524.3</td>
									<td>2001-04-11</td>
								    <td>China</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/225836-a-system-and-a-method-for-speech-to-speech-generation by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:42:47 GMT -->
</html>
