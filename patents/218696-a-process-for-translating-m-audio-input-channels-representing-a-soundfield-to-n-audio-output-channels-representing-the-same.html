<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/218696-a-process-for-translating-m-audio-input-channels-representing-a-soundfield-to-n-audio-output-channels-representing-the-same by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:40:01 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 218696:A PROCESS FOR TRANSLATING M AUDIO INPUT CHANNELS REPRESENTING A SOUNDFIELD TO N AUDIO OUTPUT CHANNELS REPRESENTING THE SAME.</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A PROCESS FOR TRANSLATING M AUDIO INPUT CHANNELS REPRESENTING A SOUNDFIELD TO N AUDIO OUTPUT CHANNELS REPRESENTING THE SAME.</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A PROCESS FOR TYRANSLATING M AUDIO INPUT CHANNELS REPRESENTING A SOUNDFIELD TO N AUDIO OUTPUT CHANNELS (1-23) REPRESENTING THE SAME SOUNDFIELD, WHEREIN EACH CHANNEL IS A SINGLE AUDIO STREAM REPRESENTING AUDIO ARRIVING FROM A DIRECTION, M AND N ARE POSITIVE WHOLE INTEGERS, AND M IS AT LEAST 2, GENERATES ONE OR MORE SETS OF OUTPUT CHANNELS, EACH SET HAVING ONE OR MORE OUTPUT CHANNELS. EACH SET IS ASSOCIATED WITH TWO OR MORE SPECIALLY ADJACENT INPUT CHANNELS AND EACH OUTPUT CHANNEL IN A SET IS GENERATED BY A PROCESS THAT INCLUDES DETERMINING A MEASURE OF THE CORRELATION OF THE TWO OR MORE INPUT CHANNELS AND THE LEVEL INTERRELATIONSHIPS OF THE TWO OR MORE INPUT CHANNELS.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>A PROCESS FOR TRANSLATING M AUDIO INPUT CHANNELS<br>
REPRESENTING A SOUNDFIELD TO N AUDIO OUTPUT<br>
CHANNELS REPRESENTING THE SAME SOUNDFIELD<br>
TECHNICAL FIELD<br>
The present invention relats to a process for translating m audio input channels<br>
representing a soundfield to n audio output channels representing the same<br>
soundfield. More particularly, the invention relates to translating M audio input<br>
channels representing a soundfield to N audio output channels representing the<br>
same soundfield, wherein each channel is a single audio stream representing audio<br>
arriving from a direction, M and N are positive whole integers, and M is at least 2,<br>
BACKGROUND ART<br>
Although humans have only two ears, we hear sound as a three dimensional<br>
entity, relying upon a number of localization cues, such as head related transfer<br>
functions (HRTFs) and head motion. Full fidelity sound reproduction therefore<br>
requires the retention and reproduction of the full 3D soundfield, or at least the<br>
perceptual cues thereof. Unfortunately, sound recording technology is not oriented<br>
toward capture of the 3D soundfield, nor toward capture of a 2D plane of sound, nor<br>
even toward capture of a 1D line of sound. Current sound recording technology is<br>
oriented strictly toward capture, preservation, and presentation of zero dimensional,<br>
discrete channels of audio.<br>
Most of the effort on improving fidelity since Edison"s original invention of<br>
sound recording has focused on ameliorating the imperfections of his original analog<br>
modulated-groove cylinder/disc media. These imperfections included limited,<br>
uneven frequency response, noise, distortion, wow, flutter, speed accuracy, wear,<br>
dirt, and copying generation loss. Although there were any number of piecemeal<br>
attempts at isolated improvements, including electronic amplification, tape recording,<br>
noise reduction, and record players that cost more than some cars, the traditional<br>
problems of individual channel quality were arguably not finally resolved until the<br>
singular development of digital recording in general, and specifically the introduction<br>
of the audio Compact Disc. Since then, aside from some effort at further extending<br>
the quality of digital recording to 24bits/96 kHz sampling, the primary efforts in<br>
audio reproduction research have been focused on reducing the amount of data<br>
needed to maintain individual channel quality, mostly using perceptual coders, and<br>
on increasing the spatial fidelity. The latter problem is the subject of this document.<br>
Efforts on improving spatial fidelity have proceeded along two fronts: trying<br>
to convey the perceptual cues of a full sound field, and trying to convey an<br>
approximation to the actual original sound field. Examples of systems employing the<br>
former approach include binaural recording and two-speaker-based virtual surround<br>
systems. Such systems exhibit a number of unfortunate imperfections, especially in<br>
reliably localizing sounds in some directions, and in requiring the use of headphones<br>
or a fixed single listener position.<br>
For presentation of spatial sound to multiple listeners, whether in a living room<br>
or a commercial venue like a movie theatre, the only viable alternative has been to<br>
try to approximate the actual original sound field. Given the discrete channel nature<br>
of sound recording, it is not surprising that most efforts to date have involved what<br>
might be termed conservative increases in the number of presentation channels.<br>
Representative systems include the panned-mono three-speaker film soundtracks of<br>
the early 50"s, conventional stereo sound, quadraphonic systems of the 60"s, five<br>
channel discrete magnetic soundtracks on 70mm films, Dolby surround using a<br>
matrix in the 70"s, AC-3 5.1 channel sound of the 90"s, and recently, Surround-EX<br>
6.1 channel sound. "Dolby", "Pro Logic" and "Surround EX" are trademarks of<br>
Dolby Laboratories Licensing Corporation. To one degree or another, these systems<br>
provide enhanced spatial reproduction compared to monophonic presentation.<br>
However, mixing a larger number of channels incurs larger time and cost penalties<br>
on content producers, and the resulting perception is typically one of a few scattered,<br>
discrete channels, rather that a continuum soundfield. Aspects of Dolby Pro Logic<br>
decoding are described in U.S. Patent 4,799,260, which patent is incorporated by<br>
reference herein in its entirety. Details of AC-3 are set forth in "Digital Audio<br>
Compression Standard (AC-3)," Advanced Television Systems Committee (ATSC),<br>
Document A/52, December 20, 1995 (available on the World Wide Web of the<br>
Internet at www.atsc.org/Standards/A52/a_52.doc). See also the Errata Sheet of July<br>
22, 1999 (available on the World Wide Web of the Internet at<br>
www.doIby.com/tech/ATSCerr.pdf.<br>
Insights Underlying Aspects of the Present Invention<br>
The basis for recreating an arbitrary distribution in a source-free wave medium<br>
is provided by a theorem by Gauss that stipulates that a wave field within some<br>
region is completely specified by the pressure distribution along the boundary of the<br>
region. This implies that re-creation of the sound field in a concert hall within the<br>
confines of a living room is possible by conceptually placing the living room, walls<br>
impermeable to sound, within the concert hall, then electronically rendering the walls<br>
sonically transparent by festooning the outside of the walls with an infinite number of<br>
infinitesimal microphones, each connected with suitable amplification to a<br>
corresponding loudspeaker just inside the wall. By interposing a suitable recording<br>
medium between microphones and speakers, a complete, if impractical, system of<br>
accurate 3D sound reproduction is realized. The only remaining design task is to<br>
render the system practical.<br>
A first step toward practicality can be taken by noting the signal of interest is<br>
bandlimited, at about 20 kHz, permitting the application of the Spatial Sampling<br>
theorem, a variant of the more common Temporal Sampling theorem. The latter<br>
holds that there is no loss of information if a continuous bandlimited temporal<br>
waveform is discretely sampled at a rate at least twice the highest frequency of the<br>
source. The former theory follows from the same considerations to stipulate that the<br>
spatial sampling interval must by at least twice as dense as the shortest wavelength in<br>
order to avoid information loss. Since the wavelength of 20 kHz in air is about 3/8",<br>
the implication is that an accurate 3D sound system can be implemented with an<br>
array of microphones and loudspeakers spaced no more than 3/16" apart. Extended<br>
over all surfaces of a typical 9"xl2" room, this works out to about 2.5 million<br>
channels, a considerable improvement over an infinite number, but still impractical at<br>
this time. Still, it establishes the basic approach of using an array of discrete<br>
channels as spatial samples, from which the sound field can be recovered by<br>
application of appropriate interpolation.<br>
Once the sound field is characterized, it is possible in principle for a decoder to<br>
derive the optimal signal feed for any output loudspeaker. The channels supplied to<br>
such a decoder will be referred to herein variously as "cardinal," "transmitted," and<br>
"input" channels, and any output channel with a location that does not correspond to<br>
the position of one of the cardinal channels will be referred to as an "intermediate"<br>
channel. An output channel may also have a location coincident with the position of<br>
a cardinal input channel.<br>
It is therefore desirable to reduce the number of discrete channel spatial<br>
samples, or cardinal channels. One possible basis for doing so is the fact that, above<br>
1500 Hz, the ear no longer follows individual cycles, only the critical band envelope.<br>
This might allow channel spacing commensurate with 1500 Hz, or about 3". This<br>
would reduce the total for the 9"xl2" room to about 6000 channels, a useful saving of<br>
about 2.49 million channels compared to the previous arrangement.<br>
In any case, further reduction in the number of spatial sampling channels is<br>
theoretically possible by appeal to psychoacoustic localization limits. The horizontal<br>
limit of resolution, for centered sounds, is about 1 degree of arc. The corresponding<br>
limit of vertical resolution is about 5 degrees. If this density is extended<br>
appropriately around a sphere, the result will still be a few hundred to a few thousand<br>
channels.<br>
EP 1 054 575 A discloses a process for translating two audio input channels<br>
representing a soundfield to eight audio output channels representing the same<br>
soundfield, wherein each channel is a single audio stream representing audio<br>
arriving from a direction. A matrix generates, from the two input channels the eight<br>
output channels by a process that includes determining a measure of the correlation<br>
of the two input channels and the level interrelationships of the two input channels.<br>
It is an object of the invention to solve the problem of how to approximate, in<br>
a practical way, an actual original sound field for presentation to multiple listeners in<br>
a living room or a commercial venue like a movie theatre.<br>
-5A- <br>
DISCLOSURE OF THE INVENTION<br>
In accordance with the present invention, a process translates M audio input<br>
channels representing a soundfield to N audio output channels representing the same<br>
soundfield, wherein each channel is a single audio stream representing audio arriving<br>
from a direction, M and N are positive whole integers, and M is at least two. One or<br>
more sets of output channels are generated, each set having one or more output<br>
channels. Each set is associated with two or more spatially adjacent input channels<br>
and each output channel in a set is generated by a process that includes determining a<br>
measure of the correlation of the two or more input channels and the level<br>
interrelationships of the two or more input channels.<br>
In one aspect of the present invention, multiple sets of output channels are<br>
associated with more than two input channels and the process determines the<br>
correlation of input channels with which each set of output channels is associated<br>
according to a hierarchical order such that each set or sets is ranked according to the<br>
number of input channels with which its output channel or channels are associated,<br>
the greatest number of input channels having the highest ranking, and the processing<br>
processes sets in order according to their hierarchical order. Further according to an<br>
aspect of the present invention, the processing takes into account the results of<br>
processing higher order sets.<br>
The playback or decoding aspects of the present invention assume that each of<br>
the M audio input channels representing audio arriving from a direction was<br>
generated by a passive-matrix nearest-neighbor amplitude-panned encoding of each<br>
source direction (i.e., a source direction is assumed to map primarily to the nearest<br>
cardinal channel or channels), without the requirement of additional side chain<br>
information (the use of side chain or auxiliary information is optional), making it<br>
compatible with existing mixing techniques, consoles, and formats. Although such<br>
source signals may be generated by explicitly employing a passive encoding matrix,<br>
most conventional recording techniques inherently generate such source signals<br>
(thus, constituting an "effective encoding matrix")- The playback or decoding<br>
aspects of the present invention are also largely compatible with natural recording<br>
source signals, such as might be made with five real directional microphones, since,<br>
allowing for some possible time delay, sounds arriving from intermediate directions<br>
tend to map principally to the nearest microphones (in a horizontal array, specifically<br>
to the nearest pair of microphones).<br>
A decoder or decoding process according to aspects of the present invention<br>
may be implemented as a lattice of coupled processing modules or modular functions<br>
(hereinafter, "decoding modules"), each of which is used to generate one or more<br>
output channels (or, alternatively, control signals usable to generate one or more<br>
output channels) from the two or more of the closest spatially adjacent cardinal<br>
channels associated with the decoding module. The output channels represent<br>
relative proportions of the audio signals in the closest spatially adjacent cardinal<br>
channels associated with the particular decoding module. As explained in more<br>
detail below, the decoding modules are loosely coupled to each other in the sense that<br>
modules share nodes and there is a hierarchy of decoding modules. Modules are<br>
ordered in the hierarchy according to the number of cardinal channels they are<br>
associated with (the module or modules with the highest number of associated<br>
cardinal channels is ranked highest). A supervisory routine function presides over<br>
the modules so that common node signals are equitably shared and higher-order<br>
decoder modules may affect the output of lower-order modules.<br>
Each decoder module may, in effect, include a matrix such that it directly<br>
generates output signals or each decoder module may generate control signals that<br>
are used, along with the control signals generated by other decoder modules, to vary<br>
the coefficients of a variable matrix or the scale factors of inputs to or outputs from a<br>
fixed matrix in order to generate all of the output signals.<br>
Decoder modules emulate the operation of the human ear to attempt to provide<br>
perceptually transparent reproduction. Each decoder module may be implemented as<br>
either a wideband or multiband structure or function, in the latter case with either a<br>
continuous filterbank, or a block-structure, for example, a transform-based processor,<br>
using, for example, the same essential processing in each band.<br>
Although the basic invention relates generally to the spatial translation of M<br>
input channels to N output channels, wherein M and N are positive whole integers<br>
and M is at least two, another aspect of this invention is that the quantity of speakers<br>
receiving the N output channels can be reduced to a practical number by judicious<br>
reliance upon virtual imaging, that is the creation of perceived sonic images at<br>
positions in space other than where a loudspeaker is located. The most common use<br>
of virtual imaging is in the stereo reproduction of an image part way between two<br>
speakers, by panning a mono signal between the channels. Virtual imaging is not<br>
considered a viable technique for group presentation with a sparse number of<br>
channels, because it requires the listener to be equidistant from the two speakers, or<br>
nearly so. In movie theatres, for example, the left and right front speakers are too far<br>
apart to obtain useful phantom imaging of a center image to much of the audience,<br>
so, given the importance of the center channel as the source of much of the dialog, a<br>
physical center speaker is used instead.<br>
However, as the density of the speakers is increased, a point will be reached<br>
where virtual imaging is viable between any pair of speakers for much of the<br>
audience, at least to the extent that pans are smooth; with sufficient speakers, the<br>
gaps between the speakers are no longer perceived as such. Such an array has the<br>
potential to be nearly indistinguishable from the 2 million array derived earlier.<br>
In order to test aspects of the present invention, we deployed a horizontal array<br>
of 5 speakers on each wall, 16 total allowing for common corner speakers, plus a ring<br>
of 6 speakers above the listener at a vertical angle of about 45 degrees, plus a single<br>
speaker directly above, total 23, plus a subwoofer/LFE channel, total 24, all fed from<br>
a PC set up for 24-channel playback. Although by current parlance this system might<br>
be referred to as a 23.1 channel system, for simplicity it will be referred to as a 24-channel<br>
system herein.<br>
FIG. 1 is a top plan view showing schematically an idealized decoding arrangement in<br>
the manner of the just-described test arrangement. Five wide range horizontal cardinal channels<br>
are shown as squares 1", 3", 5", 9" and 13" on the outer circle. A vertical channel, perhaps derived<br>
from the five wide range cardinals via correlation or generated reverberation, or separately<br>
supplied, is shown as the broken square 23" in the center. The twenty-three wide range output<br>
channels are shown as numbered filled circles 1-23. The outer circle of sixteen output channels<br>
is on a horizontal plane, the inner circle of six output channels is forty-five degrees above the<br>
horizontal plane. Output channel 23 is directly above one or more listeners. Five two-input<br>
decoding modules are illustrated as arrows 24-28 around the outer circle, connected between<br>
each pair of horizontal cardinal channels. Five additional two-input vertical decoding modules<br>
are illustrated as arrows 29-33 connecting the vertical channel to each of the horizontal cardinals.<br>
Output channel 21, the elevated center rear channel, is derived from a three-input decoding<br>
module illustrated as arrows between output channel 21 and cardinal channels 9,13 and 23.<br>
Thus, each module is associated with a respective pair or trio of closest spatially adjacent<br>
cardinal channels. Although the decoding modules represented in FIG. 1 have three, four or five<br>
output channels, a decoding module may have any reasonable number of output channels. An<br>
output channels may be located intermediate to one or more cardinal channels or at the same<br>
position as a cardinal channel. Thus, in the FIG. 1 example, each of the cardinal channel<br>
locations is also an output channel. Each input channel is shared by multiple decoding modules.<br>
As will be discussed, a design goal of this invention is that the playback processor should<br>
be capable in concept of working with an arbitrary number and arrangement of speakers, so the<br>
24-channel array will be used as an illustrative but<br>
non-unique example of the density and arrangement required to achieve a convincing<br>
continuum perceived soundfield according to one aspect of the invention.<br>
The desire to be able to use a large, and possibly user-selectable, number of<br>
presentation channels raises the question of the number of discrete channels, and/or<br>
other information, that must be conveyed to the playback processor in order for it to<br>
derive, at least as one option, the twenty four channels described above. Obviously,<br>
one possible approach is simply to transmit twenty four discrete channels, but aside<br>
from the fact that it would likely be onerous for content producers to have to mix that<br>
many separate channels, and for a transmission medium to convey as many channels,<br>
it is preferred not to do so, as the 24-channel arrangement is merely one of many<br>
possible, and it is desired to allow for more or fewer presentation channels from a<br>
common transmitted signal array.<br>
One way to recover output channels is to use formal spatial interpolation, a<br>
fixed weighted sum of the transmitted channels for each output, assuming the density<br>
of such channels is sufficiently great to allow for that. However, this would require<br>
from thousands to millions of transmitted channels, analogous to the use of a multi-<br>
hundred-tap FIR filter to perform temporal interpolation of a single signal.<br>
Reduction to a practical number of transmitted channels requires the application of<br>
psychoacoustic principles and more aggressive, dynamic interpolation from far fewer<br>
channels, still leaving unanswered the question of just how many channels are<br>
needed to impart the percept of a complete soundfield.<br>
This question was addressed by an experiment performed by the present<br>
invenitor some years ago, and recently replicated by another. The basis for the earlier<br>
experiment, at least, was the observation that conventional 2-channel binaural<br>
recording is capable of reproducing a realistic left/right image spread, but results in<br>
erratic front/back localization, owing in part to the imperfection of any HRTF<br>
employed, and the lack of head motion cues. To circumvent this drawback, a dual-<br>
binaural (4-channel) recording was made, using two pairs of directional microphones<br>
spaced commensurate to the size of the human head. One pair faced forward, the<br>
other to the rear. The resulting recording was played over four speakers spaced close<br>
to the head, to mitigate acoustic cross coupling effects. This arrangement provided<br>
realistic left/right timing and amplitude localization cues from each pair of speakers,<br>
plus unambiguous front/back information from the corresponding discrete positions<br>
of the microphones and speakers. The result was a singularly compelling surround<br>
sound presentation that lacked only a viable representation of height information. A<br>
recent experiment of another added a center front channel and two height channels,<br>
and was reported to be similarly realistic, perhaps even enhanced by the addition of<br>
height information.<br>
Therefore, from both psychoacoustic considerations and empirical evidence, it<br>
appears that the relevant perceptual information can be conveyed in perhaps 4 to 5<br>
"binaural-like" horizontal channels, plus perhaps one or more vertical channels.<br>
However, the signal crossfeed characteristic of binaural channel pairs makes them<br>
unsuitable for direct playback to a group via loudspeakers, since there is very little<br>
separation at midrange and low frequencies. So rather than introducing the crossfeed<br>
at the encoder (as is done for a binaural pair) only to have to undo it in the decoder, it<br>
is simpler and more direct to keep channels isolated, and to mix output channel<br>
signals from the nearest transmitted channels. Not only does this allow for direct<br>
playback through a like number of speakers without a decoder, if desired, plus<br>
optional downmix to fewer channels with a passive matrix decoder, but it essentially<br>
corresponds to the existing standard arrangement of 5.1 channels, at least in the<br>
horizontal plane. It is also largely compatible with natural recordings, such as might<br>
be made with five real directional microphones, since, allowing for some possible<br>
time delay, sounds arriving from intermediate directions will tend to map principally<br>
to the nearest microphones (in a horizontal array, specifically to the nearest pair of<br>
microphones).<br>
Thus, from a perceptual standpoint, it should be possible for a channel<br>
translation decoder to accept a standard 5.1 channel program and convincingly<br>
present it through an arbitrary number of horizontally arrayed speakers, including the<br>
sixteen horizontal speakers of the twenty-four-channel array described earlier. With<br>
the addition of a vertical channel, such as is sometimes proposed for a digital cinema<br>
system, it should be possible to feed the entire twenty-four-channel array with<br>
individually derived, perceptually valid signals that together impart a continuum<br>
soundfield percept at most listening positions. Of course, if there is access to the fine<br>
grain source channels at the encoding site, additional information about them might<br>
be used to actively alter the encode matrix scale factors to pre-compensate for<br>
decoder limitations, or might simply be included as additional side-chain (auxiliary)<br>
information, perhaps similar to the coupling coordinates used in AC-3 (Dolby<br>
Digital) multichannel coding, but perceptually, such extra information should not be<br>
necessary; and practically, requiring the inclusion of such information is undesirable.<br>
The intended operation of the channel translation decoder is not limited to operation<br>
with 5.1 channel sources, and may use fewer or more, but there is at least some<br>
justification to the belief that credible performance can be obtained from 5.1 channel<br>
sources.<br>
This still leaves unanswered the question of just how to extract the<br>
intermediate output channels from a sparse array of transmitted channels. The<br>
solution proposed by one aspect of the present invention is to exploit again the notion<br>
of virtual imaging, but in a somewhat different way. It was previously noted that<br>
virtual imaging is not viable for group presentation with sparse speaker arrays<br>
because it required the listener to be nearly equidistant from each speaker. But it will<br>
work, after a fashion, for a listener who is fortuitously so placed, allowing the percept<br>
of intermediate phantom channels for signals that have been amplitude panned<br>
between the nearest real output channels. It is therefore proposed in one aspect of the<br>
present invention that the channel translation decoder consist of a series of modular<br>
interpolating signal processors, each in effect emulating an optimally placed listener,<br>
and each functioning in a manner analogous to the human auditory system to extract<br>
what would otherwise be virtual images from amplitude-panned signals, and feed<br>
them to real loudspeakers; the speakers preferably arrayed densely enough that<br>
natural virtual imaging can fill in the remaining gaps between them.<br>
In general, each decoding module derives its inputs from the nearest<br>
transmitted cardinal channels, which, for example, for a canopy (overhead) array of<br>
speakers may be three or more cardinal channels. One way of generating output<br>
channels involving more than two cardinal channels might be to employ a series of<br>
pair-wise operations, with, e.g., outputs of some pair-wise decoding modules feeding<br>
the inputs of other modules. However, this has two drawbacks. One is that<br>
cascading decoding modules introduces multiple cascaded time constants, resulting<br>
in some output channels responding more quickly than others, causing audible<br>
position artifacts. The second drawback is that pair-wise correlation alone can only<br>
place intermediate or derived output channels along the line between the pair; use of<br>
three or more cardinals removes this restriction. Consequently, an extension to<br>
common pair-wise correlation has been developed to correlate three or more output<br>
signals; this technique is described below.<br>
Horizontal localization in the human ear is predicated primarily upon two<br>
localization cues: interaural amplitude differences and interaural time differences.<br>
The latter cue is only valid for signal pairs in near time alignment, ± 600<br>
microseconds or so. The practical effect is that phantom intermediate images will<br>
only occur at positions corresponding to a particular left/right amplitude difference,<br>
assuming the common signal content in the two real channels is correlated, or nearly<br>
so. (Note: two signals can have cross correlation values that span from +1 to —1.<br>
Full)/ correlated signals (correlation =1) have the same waveform and time<br>
alignment, but may have different amplitudes, corresponding to off-center image<br>
positions.) As the correlation of a signal pair diminishes below 1, the perceived<br>
image will tend to spread, until, for two uncorrelated signals, there will be no<br>
intermediate image, only separate and distinct left and right images. Negative<br>
correlations are usually treated by the ear as similar to uncorrelated signal pairs,<br>
although the two images may appear to be spread wider. The correlations are carried<br>
out on a critical band basis, and above about 1500 Hz, the critical band signal<br>
envelopes are used instead of the signals themselves, to save human computational<br>
requirements (MIPS).<br>
Vertical localization is a little more complex, relying on HRTF pinna cues and<br>
dynamic modulation of the horizontal cues with head motion, but the final effect is<br>
similar to horizontal localization with respect to panned amplitudes, cross<br>
correlation, and corresponding perceived image position and fusion. Vertical spatial<br>
resolution is, however, less precise than horizontal resolution, and does not require as<br>
dense an array of cardinal channels for adequate interpolation performance.<br>
An advantage of using directional processors that emulate the operation of the<br>
human ear is that any imperfections or limitations of the signal processing should be<br>
perceptually masked by like imperfections and limitations of the human ear, allowing<br>
for the possibility that the system will be perceived as nearly indistinguishable from<br>
the original full continuum presentation.<br>
Although the present invention is designed to make effective use of however<br>
many or few output channels are available (including playback via as many<br>
loudspeakers as there are input channels with no decoding, and passive mixdown to<br>
fewer channels, including mono, stereo and surround compatible Lt/Rt), it is<br>
preferably intended to employ a large and somewhat arbitrary, but nonetheless<br>
practical number of presentation channels/loudspeakers, and use as source material a<br>
similar or smaller number of encoded channels, including existing 5.1 channel<br>
surround tracks, and possible next-generation 11- or 12-channel digital cinema<br>
soundtracks.<br>
Implementations of the present invention desirably should exhibit four<br>
principles: error containment, dominant containment, constant power, and<br>
synchronized smoothing.<br>
Error containment refers to the notion that, given the likelihood of decoding<br>
errors, the decoded position of each source should be in some reasonable sense near<br>
its true, intended direction. This mandates a certain degree of conservatism in<br>
decoding strategy. Faced with the prospect of more aggressive decoding<br>
accompanied by possibly greater spatial disparity in the event of errors, it is usually<br>
preferable to accept less precise decoding in exchange for assured spatial<br>
containment. Even in situations in which more precise decoding can confidently be<br>
applied, it may be unwise to do so if there is a likelihood that dynamic signal<br>
conditions will require the decoder to ratchet between aggressive and conservative<br>
modes, resulting in audible artifacts.<br>
Dominant containment, a more constrained variant of error containment, is the<br>
requirement that a single well-defined dominant signal should be panned by the<br>
decoder to only nearest neighbor output channels. This condition is necessary to<br>
maintain image fusion for dominant signals, and contributes to the perceived<br>
discreteness of a matrix decoder. While a signal is dominant, it is suppressed from<br>
other output channels, either by subtracting it from the associated cardinal signals, or<br>
by directly applying to other output channels matrix coefficients complementary to<br>
those used to derive the dominant signal ("anti-dominant coefficients/signal").<br>
Constant power decoding requires not only that the total decoded output power<br>
be equal to the input power, but also equates the input/output power of each channel<br>
and directional signal encoded in the conveyed cardinal array. This minimizes gain-<br>
pumping artifacts.<br>
Synchronized smoothing applies to systems with signal dependent smoothing<br>
time constants, and requires that if any smoothing network within a decoding module<br>
is switched to a fast time constant mode, all other smoothing networks within the<br>
module be similarly switched. This is to avoid having a newly dominant directional<br>
signal appear to slowly fade/pan from the previous dominant direction.<br>
BRIEF DISCRETION OF THE ACCOMPANYING DRAWING<br>
FIG. 1 is a schematic drawing showing a top plan view of an idealized decoder<br>
arrangement.<br>
BEST MODE FOR CARRYING OUT THE INVENTION<br>
Decoding Module<br>
Because encoding any source direction is assumed to map primarily to the<br>
nearest cardinal channels, channel translation decoding is based on a series of semi-<br>
autonomous decoding modules which in a general sense recover output channels,<br>
particularly intermediate output channels, each usually from a subset of all the<br>
transmitted channels, in a fashion similar to the human ear.<br>
In a fashion analogous to the human ear, the operation of the decoding module<br>
is based on a combination of amplitude ratios, to determine the nominal ongoing<br>
primary direction, and cross correlation, to determine the relative width of the image.<br>
Using control information derived from the amplitude ratios and cross<br>
correlation, the processor then extracts output channel audio signals. Since this is<br>
best done on a linear basis, to avoid generation of distortion products, the decoder<br>
forms weighted sums of cardinal channels containing the signal of interest. (As<br>
explained below, it may also be desirable to include information about non-neighbor<br>
cardinals in the calculation of the weighted sum.) This limited but dynamic form of<br>
interpolation is more commonly referred to as matrixing. If, in the source, the<br>
desired signal is mapped (amplitude panned) to the nearest M cardinal channels, then<br>
the problem is one of M:N matrix decoding. In other words, the output channels<br>
represent relative proportions of the input channels.<br>
- 10 -<br>
Especially in the case of two-input decoding modules, this is much like the<br>
issue addressed by active 2:N matrix decoders, such as the now classic Dolby Pro<br>
Logic matrix decoder, with pairwise decoding module inputs corresponding to the<br>
Lt/Rt encoded signals<br>
Note: The outputs of a 2:N matrix decoder are sometimes referred to as<br>
cardinal channels. This document, however, uses "cardinal" to refer to the input<br>
channels of the channel translation decoder.<br>
There is, however, at least one significant difference between prior art active<br>
2:N decoders and the operation of a decoding module according to the present<br>
invention. While the former use left/right amplitudes to indicate left/right position,<br>
as postulated as well for the channel translation decoder, they also use interchannel<br>
phase to indicate front/back position, relying specifically on the ratio of<br>
sum/difference of the Lt/Rt encoded channels.<br>
There are two problems with such active 2:N decoder arrangements. One is<br>
that fully correlated (frontal), but off-center signals, for example, will result in a<br>
sum/difference ratio of less than infinity, incorrectly indicating a less-fhan-full-<br>
frontal position (similarly for full anti-correlated off-center rear signals). The result<br>
is a somewhat warped decoding space. The second drawback is that the positional<br>
mapping is many-to-one, introducing inherent decoding errors. For example, in a<br>
4:2:4 matrix system, an uncorrelated Left-In and Right-In signal pair with no Front-<br>
In or Rear-In will map to the same net, uncorrelated Lt/Rt pair as will an uncorrelated<br>
Front-In/Back-In pair, with no Left-In/Right-In, or for that matter from all four inputs<br>
uncorrelated. The decoder, faced with an uncorrelated Lt/Rt signal pair, has no<br>
choice but to "relax the matrix", that is use a passive matrix that distributes sound to<br>
all output channels. It is incapable of decoding to a simultaneous Left-Out/Right-Out<br>
only, or Front-Out/Rear-Out only signal array.<br>
The underlying problem is that the use of interchannel phase to code<br>
front/back position in N:2:N matrixing systems runs counter to the operation of the<br>
human ear, which does not use phase to judge front/back position. The present<br>
invention works best with at least three non-collinear cardinal channels, so that<br>
front/back position is indicated by the assumed directions of the cardinal channels,<br>
without assigning different directions depending on their relative phases or polarities.<br>
I As such, a pair of uncorrelated or anti-correlated channel translation cardinal signals<br>
unambiguously decodes to isolated cardinal-output channel signals, with no<br>
intermediate signal and no "rearward" direction indicated. This, by the way, avoids<br>
the unfortunate "center pileup" effect in active 2:N decoders, in which uncorrelated<br>
Left-In and Right-In signals are presented with reduced separation because the<br>
decoder feeds sum and difference of these signals to center and surround channels.)<br>
Of course, it is possible in principle to spatially expand a Lt/Rt signal pair by<br>
cascading a 2:N decoder, N = 4, or 5, with an N:M channel translation system, but in<br>
that case any limitations of the 2:N decoder, such as center pileup, will be carried<br>
over to the channel multiplied outputs. It is also possible to combine these functions<br>
into a channel translation decoder configured to accept 2-channel Lt/Rt signals and,<br>
in such cases, modify its behavior to interpret negative correlation signals as having<br>
rearward orientation, leaving the rest of the processing largely intact. However, even<br>
in that case, decoding ambiguities resulting from having only two transmitted<br>
channels would remain.<br>
Thus, each decoding module, especially those with two input channels,<br>
resembles a prior art active 2:N decoder, with the front/back detection disabled or<br>
modified, and an arbitrary number of output channels. Of course, it is a<br>
mathematical impossibility to use matrixing to uniquely extract a larger number of<br>
channels from a smaller number, as this basically involves N linear equations with M<br>
unknowns, M greater than N. Therefore, it is to be expected that the decoding<br>
module may at times exhibit less than perfect channel recovery in the presence of<br>
multiple active source direction signals. However, the human auditory system,<br>
limited to using just two ears, will tend to be subject to the same limitations, allowing<br>
the system to be perceived as discrete, even with all channels operating. Isolated<br>
channel quality, with other channels muted, is still a consideration to accommodate<br>
listeners that may be situated near one speaker.<br>
To be sure, the ear is operating on a frequency-dependent basis, but given that<br>
most sonic images will be similarly correlated at all frequencies, together with the<br>
successful empirical experience with Pro Logic decoders as a wideband system, it is<br>
to be expected that a wideband channel translation system may also be capable of<br>
satisfactory performance in some applications. Multiband channel translation<br>
decoding should also be possible, using similar processing on a band-by-band basis,<br>
and using the same encoded signal in each case, so the number and bandwidth of<br>
individual bands can be left as a free parameter to the decoder implementer.<br>
Although multiband processing is likely to require higher MIPS than wideband<br>
processing, the computational demands may not be that much higher if the input<br>
signals are divided into data blocks and the process is carried out on a block basis.<br>
Before describing an algorithm usable by the decoding modules of the present<br>
invention, consideration is first given to the problem of shared nodes.<br>
Shared Nodes<br>
If the cardinal channel groups used by the decoding modules were all<br>
independent, then the decoding modules themselves could be independent,<br>
autonomous entities. Such is, however, not usually the case. A given transmitted<br>
channel will in general share separate output signals with two or more neighboring<br>
cardinal channels. If independent decoding modules are used to decode the array,<br>
each will be influenced by output signals of neighboring channels, resulting in<br>
possibly serious decoding errors. In effect, two output signals of neighboring<br>
decoding modules will "pull", or gravitate, toward each other, because of the<br>
increased level of the common cardinal node containing both signals. If, as is likely<br>
to be the case, the signals are dynamic, so too will be the amount of interaction,<br>
leading to signal dependent dynamic positioning errors of a possibly highly<br>
objectionable nature. This problem does not arise with Pro Logic and other active<br>
2:N decoding, since they use only a single, isolated channel pair as the decoder input.<br>
Thus, it is necessary to compensate for the "shared node" effect. One possible<br>
way to do so would be to subtract one recovered signal from the common node<br>
before trying to recover the output signal of an adjacent decoding module sharing the<br>
common node. This is often not possible, so as a fall back, each decoding module<br>
estimates the amount of common output signal energy present at its input channels,<br>
and a supervisor routine then informs each module of its neighbors" output signal<br>
energy estimates.<br>
Pair-wise calculation of common energy<br>
For example, suppose cardinal channel pair A/B contains a common signal X<br>
along with individual, uncorrelated signals Y and Z:<br>
So, in the case of an output signal shared equally by two neighboring cardinal<br>
channels which may also contain independent, uncorrelated signals, the averaged<br>
cross-product of the signals is equal to the energy of the common signal component<br>
in each channel. If the common signal is not shared equally, i.e., it is panned toward<br>
one of the cardinals, the averaged cross-product will be the geometric mean between<br>
the energy of the common components in A and B, from which individual channel<br>
common energy estimates can be derived by normalizing by the square root of the<br>
ratio of the channel amplitudes. Actual time averages are computed with a leaky<br>
integrator having a suitable decay time constant, to reflect ongoing activity. The time<br>
constant smoothing can be elaborated with nonlinear attack and decay time options,<br>
and in a multiband system, may be scaled with frequency.<br>
Higher order calculation of common energy<br>
In order to derive the common energy of decoding modules with three or more<br>
inputs, it is necessary to form averaged cross-products of all the input signals.<br>
Simply performing pairwise processing of the inputs will fail to differentiate between<br>
separate output signals between each pair of inputs and a signal common to all.<br>
Consider, for example, three cardinal channels, A, B, and C, made up of<br>
uncorrelated signals W, Y, Z, and common signal X:<br>
If the average cross-product is calculated, all terms involving combinations of<br>
W, Y, and Z will cancel, as in the second order calculation, leaving the average of<br>
X3:<br>
Unfortunately, if X is a zero mean time signal, as expected, then the average of<br>
its cube is zero. Unlike averaging X2, which is positive for any nonzero value of X,<br>
X3 has the same sign as X, so the positive and negative contributions will tend to<br>
cancel. Obviously, the same holds for any odd power of X, corresponding to an odd<br>
number of module inputs, but even exponents greater than 2 can also lead to<br>
erroneous results; for example four inputs with components (X, X, -X, -X) will have<br>
the same product/average as (X, X, X, X).<br>
This problem has been resolved by employing a variant of the averaged<br>
product technique. Before being averaged, the sign of the each product is discarded<br>
by taking the absolute value of the product. The signs of each term of the product are<br>
examined. If they are all the same, the absolute value of the product is applied to the<br>
averager. If any of the signs are different from the others, the negative of the<br>
absolute value of the product is averaged. Since the number of possible same-sign<br>
combinations may not be the same as the number of possible different-sign<br>
combinations, a weighting factor comprised of the ratio of the number of same to<br>
different sign combinations is applied to the negated absolute value products to<br>
compensate. For example, a three-input module has two ways for the signs to be the<br>
same, out of eight possibilities, leaving six possible ways for the signs to be different,<br>
resulting in a scale factor of 2/6 = 1/3. This compensation causes the integrated or<br>
summed product to grow in a positive direction if and only if there is a signal<br>
component common to all inputs of a decoding module.<br>
However, in order for the averages of different order modules to be<br>
comparable, they must all have the same dimensions. A conventional second-order<br>
correlation involves averages of two-input multiplications and hence of quantities<br>
with the dimensions of energy or power. Thus the terms to be averaged in higher<br>
order correlations must be modified also to have the dimensions of power. For a kth<br>
order correlation, the individual product absolute values must therefore be raised to<br>
the power 2/k before being averaged.<br>
Of course, regardless of the order, the individual input node energies of a<br>
module, if needed, can be calculated as the average of the square of the<br>
corresponding node signal, and need not be first raised to the kth power and then<br>
reduced to a second order quantity.<br>
Shared nodes: Neighbor levels<br>
By using averaged squares and modified cross-products of cardinal channel<br>
signals, the amount of common output channel signal energy can be estimated. The<br>
above example involved a single interpolation processor, but if one or more of the<br>
A/B(/C) nodes were common to another module with its own common signal<br>
component, uncorrelated with any other signals, then the averaged cross-product<br>
computed above would not be affected, making the calculation inherently free of any<br>
image pulling effects. (Note: if the two output signals are not uncorrelated, they will<br>
tend to pull the decoders some, but should have a similar effect on the human ear, so<br>
again system operation should remain faithful to human audition.)<br>
Once each decoding module has computed the estimated common output<br>
channel signal energy at each of its cardinal nodes, the supervisor routine function<br>
can inform neighboring modules of each others" common energy, at which point the<br>
extraction of the output channel signals can proceed as described below. The<br>
calculation of the common energy used by a module at a node must take into account<br>
the hierarchy of possibly overlapping modules of different order, and subtract the<br>
common energy of a higher order module from the estimated common energy of any<br>
lower order module sharing the same nodes.<br>
For example, suppose there are two adjacent cardinal channels A and B,<br>
representing two horizontal directions, plus a cardinal channel C, representing a<br>
vertical direction, and further suppose the existence of an intermediate or derived<br>
output channel representing an interior direction (i.e. one within the limits of A, B<br>
and C), with signal energy X2. The common energy of a three-input module, with<br>
inputs (A, B, C), will be X2, but so will the common energy of two-input modules (A,<br>
B), (B, C), and (A, C). If the common energy of A-connected modules (A, B, C), (A,<br>
B), and (A, C) is simply added, the result is 3X2, instead of X2. In order for the<br>
calculation of common node energy to be correct, the common energy of each higher<br>
order module is first subtracted from the estimate of the common energy of each<br>
overlapping lower-level module, so the common energy X2 of higher order module<br>
(A, B, C) is subtracted from the common energy estimates of the two two-input<br>
modules, resulting in 0 in each case, and making the net common energy estimate at<br>
node A equal to X2 + 0 + 0 - X2.<br>
Output Channel Signal Extraction<br>
As has been noted, the process of recovering the ensemble of output channels<br>
from the transmitted channels in a linear fashion is basically one of matrixing, that is<br>
forming weighted sums of the cardinal channels to derive output channel signals.<br>
The optimal choice of matrix scale factors is generally signal dependent. Indeed, if<br>
the number of currently active output channels is equal to the number of transmitted<br>
channels (but representing different directions), making the system exactly<br>
constrained, it is mathematically possible to compute an exact inverse of the effective<br>
encoding matrix, and recover isolated versions of the source signals. Even if the<br>
number of active output channels is greater than the number of cardinals, it may still<br>
be possible to compute a matrix pseudo-inverse.<br>
Unfortunately, there are problems with this approach, not the least of which is<br>
that it is computationally demanding, especially on a multiband basis, and oriented<br>
toward high accuracy floating point implementation. Even though intermediate<br>
signals are assumed to be panned to nearest neighbor cardinal channels, a<br>
mathematical inverse or pseudo-inverse of the effective encoding matrix will in<br>
general involve contributions from all cardinal channels to each output channel,<br>
because of the node sharing effect. If there are any imperfections in the decoding, as<br>
indeed there inevitably will be, a cardinal channel signal could be reproduced from<br>
an output channel far removed from it spatially, which is highly undesirable. In<br>
addition, pseudo-inverse calculations tend to produce minimum-RMS-energy<br>
solutions, which maximally spread the sound around, providing minimum separation;<br>
this is quite the opposite of the intention.<br>
So, in order to implement a practical, fault-tolerant decoder in which spatial<br>
decoding errors are inherently contained, the same modular structure as was used for<br>
signal detection is employed for signal extraction.<br>
Following are details of the extraction process by which output signals are<br>
recovered by a decoding module. Note that the effective position of each output<br>
channel connected to the module is assumed to be indicated by the amplitude ratio<br>
that would otherwise be needed to pan a signal to that physical location, i.e., the ratio<br>
of the effective matrix encoding coefficients corresponding to that direction. To<br>
avoid divide-by-zero problems, ratios are typically calculated as the quotient of one<br>
channel"s matrix coefficient over the RMS sum of all of that input channels" matrix<br>
coefficients (usually 1). For example, in a two-input module with inputs L and R, the<br>
energy ratio used would be the L energy over the sum of the L and R energies ("L-<br>
ratio"), which has a well-behaved range of 0 to 1. If the two-input decoding module<br>
has five output channels with effective encoding matrix coefficient pairs of (1.0, 0),<br>
(0.89, 0.45), (0.71, 0.71), (0.45, 0.89) and (0, 1.0), the corresponding L-ratios are 1.0,<br>
0.89, 0.71, 0.45, and 0, since each scale factor pair has an RMS sum of 1.0.<br>
From the signal energy of each input node (cardinal channel) of the decoding<br>
module is subtracted any node-sharing signal energy claimed by neighboring<br>
decoding modules, resulting in normalized input signal power levels used for the<br>
remainder of the calculation.<br>
The dominant direction indicator is calculated as the vector sum of the cardinal<br>
directions, weighted by the relative energy. For a two input module, this simplifies<br>
to being the L-ratio of the normalized input signal power levels.<br>
The output channels bracketing the dominant direction are determined by<br>
comparing the dominant direction L-ratio of step two, to the L-ratios of the output<br>
channels. For example, if the L-ratio of the above five-output-decoding-module<br>
inputs is 0.75, the second and third output channels bracket dominant signal<br>
direction, since 0.89 &gt; 0.75 &gt; 0.71.<br>
Panning scale factors to map the dominant signal onto the nearest bracketing<br>
channels are calculated from the ratio of the anti-dominant signal levels of the<br>
channels. The anti-dominant signal associated with a particular output channel is the<br>
signal that results when the corresponding decoding module"s input signals are<br>
matrixed with the output channel"s anti-dominant matrix scale factors. An output<br>
channel"s anti-dominant matrix scale factors are those scale factors with RMS sum =<br>
1.0 which result in zero output when a single dominant signal is panned to the output<br>
channel in question. If an output channel"s encode matrix scale factors are (A, B),<br>
then the anti-dominant scale factors of the channel are just (B, -A).<br>
Proof<br>
If a single dominant signal is panned to an output channel with encode scale<br>
factors (A, B), then the signal must have amplitudes (kA, kB), k the overall<br>
amplitude of the signal. Then the anti-dominant signal for that channel is (kA * B —<br>
kB * A) = 0.<br>
So, if a dominant signal consists of two-input module input signals (x(t), y(t))<br>
with input amplitudes normalized to RMS=1 (X, Y), the extracted dominant signal<br>
will be dom(t) = Xx(t) + Yy(t). If the position of this signal is bracketed by output<br>
channels having matrix scale factors (A, B) and (C, D) respectively, the dominant<br>
signal scale factor scaling dom(t) for the former channel will be:<br>
SF(A,B) - sqrt ((DX - CY) / ((DX - CY) + (BX - AY))),<br>
while the equivalent dominant signal scale factor for the latter channel will be:<br>
SF(C,D) = sqrt ((BX - AY) / ((DX - CY) + (BX - AY))).<br>
As the dominant direction is panned from one output channel to the other,<br>
these two scale factors move in opposite directions between zero and one with<br>
constant power sum.<br>
The anti-dominant signal is calculated and panned with suitable gain scaling to<br>
all non-dominant channels. The anti-dominant signal is a matrixed signal lacking<br>
any of the dominant signal. If the inputs to a decoding module are (x(t), y(t)) with<br>
normalized amplitudes (X, Y), the dominant signal is Xx(t)+Yy(t) and the anti-<br>
dominant signal is Yx(t)-Xy(t), irrespective of the positions of the non-dominant<br>
output channels.<br>
In addition to the dominant/anti-dominant signal distribution, a second signal<br>
distribution is calculated, using the "passive" matrix, which is basically the output<br>
channel matrix scale factors already discussed, scaled to preserve power.<br>
The cross correlation of the decoding module input signals is calculated as the<br>
averaged cross-product of the input signals divided by the square root of the product<br>
of the normalized input levels.<br>
Returning to details of the extraction process, the final output signals are then<br>
calculated as a weighted crossfade sum of the dominant and passive signal<br>
distributions, using the decoding module"s input signal cross-correlation to derive the<br>
crossfade factor. For correlational, the dominant/anti-dominant distribution is used<br>
exclusively. As the correlation diminishes, the output signal array is broadened by<br>
cross-fading to the passive distribution, reaching completion at a low positive value<br>
of correlation, typically 0.2 to 0.4, depending on the number of output channels<br>
connected to the decoding module. As the correlation falls further, toward zero, the<br>
passive amplitude output distribution is progressively bowed outward, reducing the<br>
output channel levels, emulating the response of the human ear to such signals.<br>
Vertical Processing<br>
Most of the processing described so far applies to the extraction of output<br>
channel signals from neighboring cardinal channels, regardless of the direction of the<br>
output and cardinal channels. However, because of the horizontal orientation of the<br>
ears, human auditory localization tends to be less sensitive to interchanne! correlation<br>
in the vertical direction than horizontally. To remain faithful to the operation of the<br>
human ear, it may be desirable to relax the correlation constraint in interpolation<br>
processors using vertically-oriented input channels, such as processing the<br>
correlation signal with a warping function before otherwise applying it. However, it<br>
may be that use of the same processing as for horizontal channels will not involve<br>
any audible penalty, which will simplify the structure of the overall decoder.<br>
Strictly speaking, vertical information includes both sound from above and<br>
below, and the decoder structure described will work equally well with either, but in<br>
practice there is little natural sound normally perceived as coming from below, so<br>
such processing and channels can probably be omitted without seriously<br>
compromising the perceived spatial fidelity of the system.<br>
That notion may have practical significance in the application of channel<br>
translation to existing 5.1 channel surround material, which, of course, lacks any<br>
vertical channel. However, it may contain vertical information, such as fly-overs,<br>
which are panned across many or all of the horizontal channels. Thus, it should be<br>
possible to extract a virtual vertical channel from such source material, by looking<br>
for correlations among non-neighboring channels or groups of channels. Where such<br>
correlations exist, they will usually indicate the presence of vertical information from<br>
above, rather than below the listener. In some instances, it may also be possible to<br>
derive virtual vertical information from a reverberation generator, perhaps keyed to a<br>
model of the intended listening environment. Once the virtual vertical channel is<br>
extracted or derived from the 5.1-channel source, the expansion to larger numbers of<br>
channels, such as the 24-channel arrangement described earlier, can proceed as if a<br>
real vertical channel had been supplied.<br>
Directional Memory<br>
One respect in which the operation of the decoding module control generation<br>
described above is similar to a 2:N active decoder such as a Pro Logic decoder is that<br>
the only "memory" in the process is in the smoothing networks, which derive the<br>
basic control signals. At any one point in time, there is only one dominant direction<br>
and one value of input correlation; and signal extraction proceeds directly from these<br>
signals.<br>
However, particularly in complex acoustical environments (like the archetypal<br>
cocktail party), the human ear exhibits a certain degree of positional memory, or<br>
inertia, in that a briefly dominant sound from a given direction that is clearly<br>
localized will result in other, less distinctly localizable sounds from that general<br>
direction to be perceived as coming from the same source.<br>
It is possible to emulate this effect in the decoding modules (and, indeed, in<br>
Pro Logic decoding as well) by adding an explicit mechanism to keep track of<br>
recently dominant directions and, during intervals of directionally ambiguous signal<br>
conditions, weight the output signal distribution toward recently dominant directions.<br>
This can enhance the perceived reproduced discreteness and stability of complex<br>
signal arrays.<br>
Modified Correlation and Selective Channel Mixing<br>
As described, the spreading determination of each decoding module is based<br>
on the coincident cross correlation of its input signals. This may underestimate the<br>
amount of output signal content under some conditions. This will occur, for<br>
example, with a naturally recorded signal in which non-centered directions have<br>
slightly different arrival times, along with unequal amplitudes, resulting in a reduced<br>
correlation value. The effect may be exaggerated if wide-spaced microphones are<br>
used, with commensurately elongated interchannel delays. To compensate, the<br>
correlation calculation can be extended to cover a range of interchannel time delays,<br>
at the expense of slightly higher processing MIPS requirements. Also, since the<br>
neurons on the auditory nerve have an effective time constant of about 1 msec, more<br>
realistic correlation values may be obtained by first smoothing the rectified audio<br>
with a smoother having a 1 msec, time constant.<br>
In addition, if a content producer has an existing 5.1 channel program with<br>
strongly uncorrelated channels, the evenness of the spread when processed with a<br>
channel translation decoder can be increased by slightly mixing adjacent channels,<br>
thereby increasing the correlation, which will cause the channel translation decoding<br>
module to provide a more even spread among its intermediate output channels. Such<br>
mixing can be done selectively, for example leaving the center front channel signal<br>
unmixed, to preserve the compactness of the dialog track.<br>
Loudness Compression/Expansion<br>
When the encoding process involves mixing a larger number of channels to a<br>
smaller number, there is a potential for clipping of the encoded signal if some form<br>
of gain compensation is not provided. This problem exists as well for conventional<br>
matrix encoding, but is potentially of greater significance for channel translation,<br>
because the number of channels being mixed to a given output channel is greater. To<br>
avoid clipping in such cases, an overall gain scale factor is derived by the encoder<br>
and conveyed in the encoded bitstream to the decoder. Normally, this value is 0 dB,<br>
but can be set to a nonzero attenuating value by the encoder to avoid clipping, with<br>
the decoder providing an equivalent amount of compensating gain.<br>
If the decoder is used to process an existing multichannel that lacks such a<br>
scale factor program (e.g., an existing 5.1 channel soundtrack), it could optionally<br>
use a fixed scale factor with an assumed value (presumably 0 dB), or apply an<br>
expansion function based on signal level and/or dynamics, or possibly make use of<br>
available metadata, such as a dialog normalization value, to adjust the decoder gain.<br>
The present invention and its various aspects may be implemented in analog<br>
circuitry, or more probably as software functions performed in digital signal<br>
processors, programmed general-purpose digital computers, and/or special purpose<br>
-31 -<br>
digital computers. Interfaces between analog and digital signal streams may be<br>
performed in appropriate hardware and/or as functions in software and/or firmware.<br>
WE CLAIM :<br>
1. A process for translating M audio input channels (1", 3", 5", 9", 13") representing<br>
a soundfield to N audio output channels (1-23) representing the same soundfield,<br>
wherein each channel is a single audio stream representing audio arriving from a<br>
direction, M and N are positive whole integers, and M is a positive integer equal to two<br>
or more, comprising<br>
a plurality of decoding modules (24-33) each associated with two or more<br>
spatially adjacent input channels (1", 3", 5", 9", 13"), wherein each input channel is<br>
shared among multiple modules (24-33), and each module (24-33) either<br>
-includes a matrix that generates, from the associated two or more input<br>
channels (1", 3", 5", 9", 13"), one or more output channels (1-23) each constituting a<br>
subset of said N channels, by a process that includes determining a measure of the<br>
correlation of the two or more input channels (1", 3", 5", 9", 13") and the level<br>
interrelationships of the two or more input channels (1", 3", 5", 9",13"), or<br>
-generates, from the associated two or more input channels (1", 3", 5", 9", 13")<br>
by a process that includes determining a measure of the correlation of the two or more<br>
input channels (1", 3", 5", 9", 13") and the level interrelationships of the two or more<br>
input channels (1", 3, 5, 9", 13"), control signals that are used, along with control<br>
signals generated by other decoder modules (24-33), to vary the coefficients of a<br>
variable matrix to generate all of the output channels (1-23), or<br>
-generates, from the associated two or more input channels (1", 3", 5", 9", 13")<br>
by a process that includes determining a measure of the correlation of the two or more<br>
input channels (1", 3",5", 9", 13") and the level interrelationships of the two or more<br>
input channels (1", 3", 5", 9", 13"), control signals that are used, along with control<br>
signals generated by other decoder modules (24-33) to vary the scale factors of inputs<br>
to or outputs from a fixed matrix to generate all of the output channels (1-23).<br>
2. The process as claimed in claim 1 wherein the modules (24-33) are<br>
hierarchically ordered according to their number of input channels (1", 3", 5", 9", 13")<br>
and a supervisor communicates with the modules (24-33) to control the sharing of<br>
input signals in accordance with their hierarchical ordering.<br>
A process for translating M audio input channels representing a<br>
soundfield to N audio output channels (1-23) representing the same<br>
soundfield, wherein each channel is a single audio stream representing audio<br>
arriving from a direction, M and N are positive whole integers, and M is at<br>
least 2, generates one or more sets of output channels, each set having one<br>
or more output channels. Each set is associated with two or more spatially<br>
adjacent input channels and each output channel in a set is generated by a<br>
process that includes determining a measure of the correlation of the two or<br>
more input channels and the level interrelationships of the two or more input<br>
channels.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1LT0xOUC0yMDAzLUZPUk0tMjcucGRm" target="_blank" style="word-wrap:break-word;">1017-KOLNP-2003-FORM-27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtYXNzaWdubWVudC5wZGY=" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtY29ycmVzcG9uZGVuY2UucGRm" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZm9ybSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZm9ybSAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-form 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZm9ybSAxOC5wZGY=" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZm9ybSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZm9ybSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtZ3BhLnBkZg==" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtcmVwbHkgdG8gZXhhbWluYXRpb24gcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNy1rb2xucC0yMDAzLWdyYW50ZWQtc3BlY2lmaWNhdGlvbi5wZGY=" target="_blank" style="word-wrap:break-word;">1017-kolnp-2003-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="218695-modulation-and-demodulation-apparatus-and-method.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="218697-a-novel-hormone-releasing-intrauterine-device-and-a-process-for-the-preparation-thereof.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>218696</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1017/KOLNP/2003</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>15/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>11-Apr-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>09-Apr-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>08-Aug-2003</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>DOLBY LABORATORIES LICENSING CORPORATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>100 POTRERO AVENUE, SAN FRANCISCO, CA 94103,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DAVID MARK FRANKLIN</td>
											<td>100 POTRERO AVENUE, SAN FRANCISCO, CA 94103,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04S 3/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US02/03619</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2002-02-07</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/267,284</td>
									<td>2001-02-07</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/218696-a-process-for-translating-m-audio-input-channels-representing-a-soundfield-to-n-audio-output-channels-representing-the-same by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:40:02 GMT -->
</html>
