<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/257748-decoder-encoder-and-methods-of-encoding-decoding-precision-scalable-bit-stream-with-encoded-predetrmined-picture by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:34:16 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 257748:DECODER, ENCODER AND METHODS OF ENCODING/DECODING PRECISION-SCALABLE BIT STREAM WITH ENCODED PREDETRMINED PICTURE</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">DECODER, ENCODER AND METHODS OF ENCODING/DECODING PRECISION-SCALABLE BIT STREAM WITH ENCODED PREDETRMINED PICTURE</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates with an improved coding efficiency is achieved by giving the encoder the opportunity to change the field/frame-wise treatment of individual picture portions between the first precision-encoded data and the second precision-encoded data, with the second precision being higher than the first precision.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
Coding scheme enabling precision-scalability<br>
Description<br>
The present invention relates to picture or video coding<br>
supporting quality-, precision- or SNR-scalability.<br>
A current project of the Joint Video Team (JVT) of the<br>
ISO/IEC Moving Pictures Experts Group (MPEG) and the ITU-T<br>
Video Coding Experts Group (VCEG) is the development of a<br>
scalable extension of the state-of-the-art video coding<br>
standard H.264/MPEG4-AVC defined in ITU-T Rec. &amp; ISO/LEG<br>
14496-10 AVC, "Advanced Video Coding lor Generic<br>
Audiovisual Services," version 3, 2005. The current, working<br>
draft as described in J. Reichel, H. Schwarz and M. Wien,<br>
eds. "Scalable Video Coding - Joint Draft 4, "Joint Video<br>
Tem Doc. JVT-Q201, Nice, France, October 2005 and J.<br>
Reichel, H. Schwarz and M. Wien, eds. , "Joint Scalable<br>
Video Model JSVM-4," Joint Video Team, Doc. JVT-Q202, Nice,<br>
France, October 2005, supports temporal, spatial and SNR<br>
scalable coding of video sequences or any combination<br>
thereof.<br>
H.264/MPEG4-AVC as described in ITU-T Rec. &amp; ISO/IEC 14496-<br>
10 AVC, "Advanced Video Coding for Generic Audiovisual<br>
Services, " version 3, 2005, specifies a hybrid video codec<br>
in which macroblock prediction signals are either generated<br>
by motion-compensated prediction or intra-prediction and<br>
both predictions are followed by residual coding.<br>
H.264/MPEG4-AVC coding without the scalability extension is<br>
referred to as single-layer H.264/MPEG4-AVC coding. Rate-<br>
distortion performance comparable to single-layer<br>
H. 264/MPEG4-AVC means that the same visual reproduction<br>
qualjity is typically achieved at 10% bit-rate. Given the<br>
abovje, scalability is considered as a functionality for<br>
removal of parts of the bit-stream while achieving an R-D<br>
performance at any supported spatial, temporal or SNR<br><br>
resolution that is comparable to single-layer H. 264/MPKG4<br>
AVC fcoding at that particular resolution.<br><br>
The basic design of the scalable video coding (SVC) can be<br>
classified as layered video codec. In each layer, the basic<br>
concepts of motion-compensated prediction and intra<br>
prediction are employed as in H.264/MPEG4-AVC. However,<br>
additional inter-layer prediction mechanisms have been<br>
integrated in order to exploit the redundancy between<br>
several spatial or SNR layers. SNR scalability is basically<br>
achieved by residual quantization, while for spatial<br>
scalability, a combination of motion-compensated prediction<br>
and oversampled pyramid decomposition is employed. The<br>
temporal scalability approach of H.264/MPEG4-AVC is<br>
maintained.<br>
In general, the coder structure depends on the scalability<br>
space that is required by an application. For illustration,<br>
Fig.5 shows a typical coder structure 900 with two spatial<br>
layers 902a, 902b. In each layer, an independent<br>
hierarchical motion-compensated prediction structure 904a,b<br>
with layer-specific motion parameters 906a,b is employed.<br>
The redundancy between consecutive layers 902a,b is<br>
exploited by inter-layer prediction concepts 908 that<br>
include prediction mechanisms for motion parameters 906a,b<br>
as well as texture data 910a,b. A base representation<br>
912a,b of the input pictures 914a,b of each layer 902a,b is<br>
obtained by transform coding 916a,b similar to that of<br>
H.264/MPEG4-AVC, the corresponding NAL units (NAL - Network<br>
Abstraction Layer) contain motion information and texture<br>
data; the NAL units of the base representation of the<br>
lowest layer, i.e. 912a, are compatible with single-layer<br>
H.264/MPEG4-AVC. The reconstruction quality of the base<br>
representations can be improved by an additional coding<br>
918a,b of so-called progressive refinement slices; the<br>
corresponding NAL units can be arbitrarily truncated in<br>
ordei: to support fine granular quality scalability (FGS) or<br>
flexible bit-rate adaptation.<br><br>
The [resulting bit-streams output by the base layer coding<br>
916a,b and the progressive SNR refinement texture coding<br>
918a,b of the respective layers 902a,b, respectively, arc<br>
multiplexed by a multiplexer 920 in order to result in the<br>
scalable bit-stream 922. This bit-stream 922 is scalable in<br>
time, space and SNR quality.<br>
Summarizing, in accordance with the above scalable<br>
extension of the Video Coding Standard H.264/MPEG4-AVC, the<br>
temporal scalability is provided by using a hierarchical<br>
prediction structure. For this hierarchical prediction<br>
structure, the one of single-layer H.2 64/MPEG4-AVC<br>
standards may be used without any changes. For spatial and<br>
SNR scalability, additional tools have to be added to the<br>
single-layer H . 264/MPEG4.AVC. All three scalability typos<br>
can be combined in order to generate a bit-stream that<br>
supports a large degree on combined scalability.<br>
For SNR scalability, coarse-grain scalability (CGS) . and<br>
fine-granular scalability (FGS) are distinguished. With<br>
CGS, only selected SNR scalability layers are supported and<br>
the coding efficiency is optimized for coarse rate<br>
graduations as factor 1.5-2 from one layer to the next. FGS<br>
enables the truncation of NAL units at any arbitrary and<br>
eventually byte-aligned point. NAL units represent bit<br>
packets, which are serially aligned in order to represent<br>
the scalable bit-stream 922 output by multiplexer 920.<br>
In Order to support fine-granular SNR scalability, so-<br>
called progressive refinement (PR) slices have been<br>
introduced. Progressive refinement slices contain<br>
refinement information for refining the reconstruction<br>
quality available for that slice from the base layer bit-<br>
stream 912a,b, respectively. Even more precise, each NAL<br>
unit for a PR slice represents a refinement signal that<br>
corresponds to a bisection of a quantization step size (QP<br>
increase of 6). These signals are represented in a way that<br><br>
only a single inverse transform has to be performed for<br>
each transform block at the decoder side. In other words,<br>
the refinement signal represented by a PR NAL unit refines<br>
the transformation coefficients of transform blocks into<br>
which a current picture of the video has been separated. At<br>
the decoder side, this refinement signal may be used to<br>
refine the transformation' coefficients within the base<br>
layer bit-stream before performing the inverse transform in<br>
order to reconstruct the texture of prediction residual<br>
used for reconstructing the actual picture by use of a<br>
spatial and/or temporal prediction, such as by means of<br>
motion compensation.<br>
The progressive refinement NAL units can be truncated at<br>
any arbitrary point, so that the quality of the SNR base<br>
layer can be improved in a fine granular way. Therefore,<br>
the coding order of transform coefficient levels has been<br>
modified. Instead of scanning the transform coefficients<br>
macroblock-by-macroblock, as it is done in (normal) slices,<br>
the transform coefficient blocks are scanned in separate<br>
pathjs and in each path, only a few coding symbols for a<br>
transform coefficient block are coded. With the except ion<br>
of the modified coding order, the CABAC entropy coding as<br>
specified in H.2 64/MPEG4-AVC is re-used.<br>
An improvement of the coder structure shown in Fig. 5 has<br>
been described in M. Winken, H. Schwarz, D. Marpe, and T.<br>
Wiegand, "Adaptive motion refinement for FGS slices," Joint<br>
Video Team, Doc. JVT-Q031, Nice, France, October 2005. In<br>
particular, as described there, a concept for fine-granular<br>
SNR scalable coding of video sequences with an adaptive<br>
refinement of motion/prediction information is added to the<br>
codijng structure of Fig. 5. The approach of adaptive motion<br>
information refinement for SNR scalable video coding<br>
enables the video encoder of Fig. 5 the choice to select a,<br>
in rate-distortion (RD) sense, better tradeoff between bit<br>
rate for coding of residual and motion data. In particular,<br>
as indicated by the dashed lines 92 4a and 92 4b in Fig. 5,<br><br>
the refinement coding blocks 918a and 918b additionally<br>
decide, for each macroblock in a progressive refinement<br>
slice which corresponds to a base layer slice that supports<br>
motion-compensated prediction (so-called P- and B-slices),<br>
which of the two following possible coding modes is to be<br>
used. In particular, according to a first mode, coding<br>
block 918a, b uses the same motion information as the SNR<br>
base layer and thus transmits only a refinement of the<br>
residual data. This mode is equal to the foregoing<br>
description of the functionality of the coding structure of<br>
Fig. 5. However, in the alternative coding mode, coding<br>
block 918a,b transmits new motion information together with<br>
a new residual within the refinement slice information.<br>
Both the new motion and residual data can be predicted from<br>
the SNR subordinate layer to achieve a better RD-<br>
performance. The possible motion modes are the same as<br>
supported by the video coding standard H.264/MPEG 4-AVC,<br>
whicn means that by subdivision of the macroblocks into<br>
smaller blocks for motion-compensated prediction up to 16<br>
motion vectors for P-slices and up to 32 motion vectors for<br>
B-slices can be signalled.<br>
The jdecision between the two coding modes with respect to<br>
the motion information performed by blocks 918a,b is made<br>
using a Lagrangian approach where a Lagrangian cost.<br>
functional J = D + λR is minimized for a given λ. Hero, D<br>
stands for the distortion between original. and<br>
reconstructed (decoded) signal and R gives the bit rato<br>
needjed for coding of the macroblock. If the cost, for<br>
refining only the residual data is higher than the cost for<br>
one of the possible motion refinement modes, it is in rate-<br>
distortion sense obviously better to transmit a new set of<br>
motion information for this macroblock. Consequently, using<br>
adaptive motion information refinement it is possible to<br>
achieve a higher picture quality at the same bit rate.<br>
The above-explained scalable extensions of the video coding<br>
standard H.264/MPEG 4-AVC work well with progressive source<br><br>
material, i.e. videos in which the pictures may bo<br>
effectively handled picture- or frame-wise, i.e.<br>
irrespective of their composition from a top and a bottom<br>
field. However, it would be desirable to have a coding<br>
structure that enables precision-scalability with a better<br>
RD-performance for interlaced source material, i.e. videos<br>
in which each frame is composed of two interleaved fields<br>
with the fields being individually handled like frames<br>
(field-coded) or with macroblock pair-wise deciding as to<br>
whether the respective macroblock portion is divided up<br>
into two macroblocks in accordance with the membership of<br>
to the top or bottom field or the membership to the top or<br>
bottom half of the macroblock pair area within the frame.<br>
Thus, it is an object of the present application to provide<br>
a coding scheme providing precision scalability allowing<br>
for an improved coding efficiency especially in interlaced<br>
video material.<br>
This object is achieved by a decoder according to claim 1,<br>
and encoder according to claim 13, a method according to<br>
claim 22 or 23, and a precision-scalable bit-stream 21.<br>
The basic idea underlying the present invention is that an<br>
improved coding efficiency may be achieved by giving the<br>
encoder the opportunity to change the field/frame-wise<br>
treatment of individual picture portions between the. first<br>
precision-encoded data and the second precision-encoded<br>
data, with the second precision being higher than the first<br>
precision.<br>
In Accordance with a preferred embodiment of the present<br>
invention, a concept for fine-granular SNR scalable coding<br>
of interlaced frames is achieved by making and coding the<br>
frame/field decision in a progressive refinement slice<br>
independently of the frame/field decision of the<br>
corresponding base quality slice. Compared thereto, the<br>
above-described scalable extensions of the H.264/MPEG 4-AVC<br><br>
standard not supporting motion information refinement,<br>
merely code a refinement of the transform coefficients. The<br>
motion and prediction information is copied from the<br>
corresponding base layer slice. Furthermore, the tools for<br>
supporting SNR and spatial scalability have only been<br>
designed for progressive source material. Special tools for<br>
increasing the coding efficiency for interlaced source<br>
material have not been incorporated. According to the<br>
aforementioned scalable extension including motion<br>
information refinement, the FGS coding scheme allows the<br>
adaptive refinement of motion and prediction information<br>
for improving the coding efficiency of the fine-granular<br>
SNR scalable coding especially for large bit-rate<br>
intervals. However, also the latter FGS coding scheme has<br>
only been designed for progressive source material.<br>
The ibelow-explained FGS coding scheme embodiment extends<br>
the above-described motion information refinement, scalable<br>
extension in a way that it also supports a revision of the<br>
frame/field decision of the co-located macroblock pair and<br>
the base quality slice, thereby enabling achieving a<br>
precision-scalable data stream with an improved R/D ratio.<br>
In the following, preferred embodiments of the present<br>
application are described with reference to the Figs, in<br>
particular, it is shown in<br>
Fig. 1 a block diagram of a video encoder according to<br>
an embodiment of the present invention;<br>
Fig. 2 a schematic illustrating the subdivision of a<br>
picture into macroblock pairs as well as a<br>
macroblock scan of a progressive refinement slice<br>
in case of a slice of a coded frame with<br>
macroblock-adaptive frame/field decision being<br>
activated;<br><br>
Fig.3a a schematic block diagram illustrating the	mode<br>
 of operation of the encoder of Fig. 1	with<br>
respect to the creation of the base layer	data<br>
 stream;<br>
Fig.3b	a schematic block diagram illustrating the mode<br>
	of operation of the encoder of Fig. 1 with<br>
	respect to the creation of the first enhancement<br>
	layer;<br>
Fig. 4 a flow chart showing the steps performed at<br>
 decoder side in accordance with an embodiment of<br>
the present invention; and<br>
Fig. 5 a conventional coder structure for scalable video<br>
coding.<br>
The present invention is described in the following by<br>
means of an embodiment with a similar structure to the<br>
conventional coder structure of Fig. 5. However, in order<br>
to more clearly indicate the improvements in accordance<br>
with the present invention, the video encoder of Fig. 1<br>
representing an embodiment of the present invention is<br>
firstly described as operating in accordance with the<br>
scalable extensions of the H. 264/MPEG4-AVC standard having<br>
been presented in the introductory portion of this<br>
specification with respect to Fig. 5. Thereafter, the<br>
actual operation of the encoder Fig. 1 is illustrated by<br>
emphasizing the differences to the mode of operation in<br>
accordance with the video structure of Fig. 5. As will turn<br>
out from this discussion, the differences reside in the<br>
refinement coding means.<br>
The I video coder of Fig. 1 operating as defined in the<br>
above-mentioned Joint Drafts supports two spatial layers.<br>
To this end, the encoder of Fig. 1, which is generally<br>
indicated by 100, comprises two layer portions or layers<br>
102a and 102b, among which layer 102b is dedicated for<br><br>
generating that part of the desired scalable bit-stream<br>
concerning a coarser spatial resolution, while the other<br>
layer 102a is dedicated for supplementing the bit-stream<br>
output by layer 102b with information concerning a higher<br>
resolution representation of an input video signal 104 .<br>
Therefore, the video signal 104 to be encoded by encoder<br>
100 is directly input into layer 102a, whereas encoder 100<br>
comprises a spatial decimeter 106 for spatially decimating<br>
the video signal 104 before inputting the resulting<br>
spatially decimated video signal 108 into layer 102b.<br>
The decimation performed in spatial decimeter 10 6<br>
comprises, for example, decimating the number of pixels for<br>
each picture 104a of the original video signal 104 by a<br>
factbr of 4 by means of discarding every second pixel in<br>
column and row directions.<br>
The low-resolution layer 102b comprises a motion-<br>
compensated prediction block 110b, a base layer 'coding<br>
block 112b and a refinement coding block 114b. The<br>
prediction block 110b performs a motion-compensated<br>
prediction on pictures 108a of the decimated video s.i.gna!<br>
108 | in order to predict pictures 108a of the decimated<br>
videb signal 108 from other reference pictures 108a of the<br>
decifnated video signal 108. For example, for a specific<br>
picture 108a, the prediction block 110b generates motion<br>
information that indicates as to how this picture may be<br>
predicted from other pictures of the video signal 108, i.e.<br>
from reference pictures. In particular, to this end, the<br>
motion information may comprise pairs of motion vectors and<br><br>
associated reference picture indices, each pair indicating,<br>
for example, how a specific part or macroblock of the<br>
current picture is predicted from an index reference<br>
picture by displacing the respective reference picture by<br>
the respective motion vector. Each macroblock may be<br>
assigned one or more pairs of motion vectors and reference<br>
picture indices. Moreover, some of the macroblocks of a<br>
picture may be intra-predicted, i.e. predicted by use of<br><br>
the information of the current picture. In particular, the<br>
prediction block 110b may perform a hierarchical motion-<br>
compensator prediction on the decimated video signal 108.<br>
The prediction block 110b outputs the motion information<br>
116b as well as the prediction residuals of the video<br>
texture information 118b representing the differences<br>
between the predictors and the actual decimated pictures<br>
108a. In particular, the determination of the motion<br>
information and the texture information 116b and 118b and<br>
prediction block 110b is performed such that the resulting<br>
encoding of this information by means of the subsequent<br>
base layer coding 110b results in a base-representation<br>
bit-stream with, preferably, optimum rate-distortion<br>
performance.<br>
As already described above, the base layer coding block<br>
112b receives the first motion information 116b and the<br>
texture information 118b from block 110b and encodes the<br>
information to a base-representation bit-stream 120b. The<br>
encoding performed by block 112b comprises a transformation<br>
and a quantization of the texture information 118b. in<br>
particular, the quantization used by block 112b is<br>
relatively coarse. Thus, in order to enable quaJi.ty-or<br>
precision-up scaling of the bit-stream 12 0b, the refinement<br>
codihg block 114b supports the bit-stream 120b with<br>
additional bit-streams for various refinement layers<br>
containing information for refining the coarsely quantized<br>
transform coefficients representing the texture information<br>
in bit-stream 120b. As discussed later in more detail,<br>
refinement coding block 114b - for example, in co-operation<br>
with the prediction block 110b - is also able to decide<br>
that a specific refinement layer bit-stream 122b should be<br>
accompanied by refined motion information 116b, a<br>
funcitionality that has also been described in the above-<br>
mentioned scalable extension. However, this functionality<br>
is, according to the embodiment of the present invention,<br>
related to the functionality of newly coding the<br><br>
frame field decision, and therefore these functionalities<br>
shall collectively be described hereinafter. The refinement;<br>
of the residual texture information relative to the base<br>
representation 120b of the formerly-output lower refinement;<br>
layer bit-stream 122b comprises, for example, the encoding<br>
of the current quantization error of the transform<br>
coefficients thereby representing the texture information<br>
118b with a finer quantization prediction.<br>
Both bit-streams 120b and 122b are multiplexed by a<br>
multiplexer 124 comprised by encoder 100 in order to insert.<br>
both bit-streams into the final scalable bit-stream 126<br>
representing the output of encoder 100.<br>
Layer 102a substantially operates the same as layer 102b.<br>
Accordingly, layer 102a comprises a motion-compensation<br>
prediction block 110a, a base layer coding block 112a and a<br>
refinement coding block 114a. In. conformity with layer<br>
102b the prediction block 110a receives the video signal<br>
104 and performs a motion-compensated predict, i on thereon in<br>
order to obtain motion information 116a and texture<br>
information 118a. The output motion and texture information<br>
116a and 118a are received by coding block 112a, which<br>
encodes this information to obtain the base representation<br>
bit-Stream 120a. The refinement coding block 114a codes<br>
refinements of the quantization error manifesting itself on<br>
the base representation 120a by comparing a transformation<br>
coefficient of bit-stream 120a and the actual.<br>
transformation coefficient resulting from the original<br>
texture information 118a and, accordingly, output, s<br>
refinement-layer bit-streams 122a for various refinement.<br>
layers.<br>
The jonly difference between layers 102a and 102b is that<br>
layer 102a is inter-layer predicted. That is, the<br>
prediction block 110a uses information derivable from layer<br>
102b, such as residual texture information, motion<br>
information or a reconstructed video signal, as derived<br><br>
from one or more of the bit-streams 120b and 122b in order<br>
to pre-predict the high-resolution pictures 104a of the<br>
video signal 104, thereafter performing the motion-<br>
compensated prediction on the pre-prediction residuals, as<br>
mentioned above with respect to prediction block 110b<br>
relative to the decimated video signal 108. Alternatively,<br>
the prediction block 110a uses the information derivable<br>
from layer 102b for predicting the motion compensated<br>
residual 118a. In this case, for intra blocks, picture<br>
content 104a may be predicted by means of the reconstructed<br>
base layer picture. For inter blocks 104a, the motion<br>
vector (s) 116a output from 110a may be predicted from the<br>
corresponding reconstructed base layer motion vector.<br>
Moreover, after the motion compensated residual 118a of<br>
layer 102a has been determined, same may be predicted from<br>
the reconstructed base layer residual for the corresponding<br>
picture which residual is then further prosecuted in blocks<br>
112ai 114a.<br>
So far, the description of the mode of operation of the<br>
encoder of Fig. 1 concentrated on the treatment of the<br>
residual information by refinement coding means 114a, b. In<br>
particular, the residual information or texture information<br>
output by blocks 110a,b and encoded with a base layer<br>
precision in coding means 112a,b is refined in the<br>
refinement coding means 114a,b. However, refinement coding<br>
means 114a, b also enables a refinement or change of the<br>
motion information from layer to the next as well as a<br>
change in the frame/field decision made by blocks 118a,b.<br>
The functionality of the encoder of Fig. 1 as described up<br>
to here fits well to cases of progressive video source<br>
material or in cases where the base layer coding means<br>
112a, b uses f rame_MBS_only_ f lag being equal to one, which<br>
means that the picture sequence representing the video<br>
consists of coded frames only, so that a decomposition of<br>
the frames into fields is neglected. However, the SNR and<br>
spatial scalability provided by the encoder of Fig. 1 in<br><br>
accoxdance with the functionality described so far is not<br>
ideal for interlaced source materia]. Due to this reason,<br>
the encoder of Fig. 1 operating in accordance with an<br>
embodiment of the present invention not only enables<br>
refinement of the texture information but also the motion<br>
information and, primarily, the frame/field decision,<br>
thereby forming a kind of extension to interlaced sources.<br>
However, before describing the different behavior of the<br>
encoder of Fig. 1, reference is made to the H.264/MPEG4-AVC<br>
standard in which several interlaced tools have been<br>
incorporated. In the first tool, a frame can either be<br>
coded as a coded frame or as two coded fields. This is<br>
referred to as picture-adaptive frame field coding. In<br>
other words, a frame or video may be considered to contain<br>
two interleaved fields, a top and a bottom field. The top<br>
field contains even-numbered rows 0, 2, . . . H/2-1, with ii<br>
being the number of rows of the frame, wherein the bottom<br>
field contains the odd-numbered rows starting with the<br>
second line of the frame. If two fields of a frame arc<br>
captlared at different time instances, the frame, may bo<br>
referred to as an interlaced frame or it may otherwise bo<br>
referred to as a progressive frame. The coding<br>
representation in H.264/MPEG4-AVC is primarily agnostic<br>
with respect to this video characteristic, i.e. the<br>
underlying interlaced or progressive timing of the original<br>
captured pictures. Instead, its coding specifics a<br>
representation primary based on geometric concepts, rather<br>
than, being based on timing. The above-mentioned concept of<br>
picture-adaptive frame field coding is also extended to<br>
macroblock adaptive frame field coding. When a frame is<br>
coded as a single frame and the flag<br><br>
mb_aplaptive_f rame _f ield_f lag, which is transmitted in the<br>
sequence parameter set is equal to 1, the scanning of<br>
macroblocks inside a slice is modified, as depicted in Fig.<br>
2. Fig. 2 shows an exemplary portion of a picture 200. The<br>
picture is subdivided into macroblocks 202. Moreover, with<br>
a macroblock-adaptive frame/field coding being activated,<br><br>
each pair of vertically adjacent macroblocks 202 is grouped<br>
into a macroblock pair 204. As will become clearer from the<br>
following discussion, the subdivision of the picture 200<br>
into macroblocks 202 rather serves as a provision of a<br>
quantum unity in which the encoder may decide about coding<br>
parameters that have to be adapted to the video content in<br>
the respective picture area in order to result in high<br>
coding efficiency. The macroblock pairs 204, in turn,<br>
subdivide the picture 200 spatially into a rectangular<br>
array of macroblock pairs 204. The two macroblocks 202a and<br>
202b of one macroblock pair 204 spatially occupy either<br>
substantially the whole macroblock pair portion of the<br>
picture 200 with a vertical resolution being half the<br>
vertical resolution of picture 200, or divide the area of<br>
the macroblock pair 204 spatially into an upper half and a<br>
lowet half. In any case, the macroblock containing the<br>
first, third, ... lines or occupying the upper half is called<br>
the top macroblock 202a, whereas the other is called the<br>
bottom macroblock. In other words, two such vortical<br>
adjacent macroblocks are referred to as a macroblock pair<br>
which may also be arranged in a rectangular array as is<br>
shown in Fig. 2. For each macroblock pair, a syntax element<br>
mb_fleld_decoding_flag is transmitted or inferred. When<br>
mb_field_decoding_flag is equal to 0, the macroblock pair<br>
is coded as a frame macroblock pair with the top macroblock<br>
representing the top half of the macroblock pair and the<br>
bottom macroblock representing the bottom half of the<br>
macroblock pair in the geometrical sense. The motion-<br>
compensation prediction and transform coding for both the<br>
top and the bottom macroblock, is applied as for<br>
macroblocks of frames with mb adaptive frame field coding<br>
equal to 0 indicating that macroblock adaptive frame field<br>
coding is deactivated and merely frame macroblocks exist.<br>
When mb_field_decoding_flag is equal to 1, the macroblock<br>
pair represents a field macroblock pair with a top<br>
macroblock representing the top field lines of the<br>
macroblock pair and the bottom macroblock representing the<br>
bottom field lines of the macroblock pair. Thus, in this<br><br>
case, the top and the bottom macroblock substantially cover<br>
the Isame area of the picture, namely the macroblock pa.i r<br>
area. However, in these macroblocks, the vertical<br>
resolution is twice the horizontal resolution. In the case<br>
of the latter field macroblock pairs,' the motion<br>
compensation prediction and the transform coding is<br>
performed on a field basis. The coding of the picture<br>
content within the base and refinement layers is performed<br>
in slices, i.e. groups of macroblocks or macroblock pairs.<br>
One picture or frame may be composed of one or more slices.<br>
In Eig. 2, the macroblock pairs are assumed to belong to<br>
the isame slice, and the arrows in Fig. 2 indicate an order<br>
in which the macroblocks are coded in the respective<br>
layers. As can be seen, the macroblocks are scanned pair-<br>
wise, with the top macroblock first followed by the<br>
respective bottom macroblock whereinafter the next<br>
macrbblock pair is visited.<br>
Macroblocks of coded fields or macroblocks with<br>
mb_field_decoding_f lag equal to 1 of coded frames are<br>
refelrred to as field macroblocks. Since each transform<br>
block of a field macroblock represents an image area with a<br>
vertlical resolution that is equal, to twice the horizontal<br>
resolution, it is likely that the distribution of non-zero<br>
transform coefficient levels is shifted towards horizonta;<br>
low frequencies and for a rate-distortion optimized coding,<br>
the scanning of transform coefficients inside a transform<br>
block is modified for field macroblocks relative to frame<br>
macrloblocks.<br>
The following description of the encoder of Fig. 1 focuses<br>
on the refinement of the motion information as we 11 as the<br>
renewal of the frame/field decision performed for the<br>
respective macroblock pairs. However, before describing the<br>
refinement renewal of this data, reference is made to Fig.<br>
3a ishowing schematically the steps performed by blocks<br>
110a, b and 112a,b to obtain the base layer bit-stream<br>
912a,b. Again, as a starting point, Fig. 3a shows a current<br><br>
picture 200 to be coded, the picture 200 being subdivided<br>
into macroblocks 202, the macrobiocks 202 being grouped<br>
into macroblock pairs 204, so that the macroblock pairs 204<br>
spatially subdivide the picture 200 into a rectangular<br>
array. In encoding the picture 200, block 110a,b decides,<br>
for each macroblock pair 204, as to whether the macroblocks<br>
of this macroblock pair shall be macroblocks of coded<br>
fields or macroblocks of coded frames. In other words,<br>
block 904a, b decides for each macroblock pair as to whether<br>
same shall be coded in the field or frame mode, this<br>
decision being indicated in Fig. 3a at 206. The macroblock<br>
pair-wise performance of the decision 206 is indicated by<br>
exemplarily highlighting one of the macroblock pairs 204 by<br>
encircling same with a circle 208. The consequence of the<br>
decision 206 is indicated at 210a and b. As can be scon, in<br>
case of frame-coded macrobiocks 202a and 202b constituting<br>
a macroblock pair 204, same spatially subdivide the picture<br>
area occupied by the macroblock pair 204 into an upper half<br>
and a lower half. Therefore, both macroblock pairs 202a and<br>
202b comprise the picture information contained in both<br>
odd-humbered and even-numbered lines of the picture, the<br>
odd-humbered lines being indicated by white rectangles,<br>
whereas the even-numbered lines are hatched. By contrast,<br>
in dase of field mode, the top macroblock 2 02 a merely<br>
comprises the picture information within the macroblock<br>
pair area as contained in the odd-numbered lines, i.e. the<br>
top field, whereas the bottom macroblock contains the<br>
picture information within the macroblock pair area<br>
contained in the even-numbered lines. This becomes clear by<br>
compiaring 210a and 210b. The picture resolution in the<br>
vertical direction is reduced by a factor of 2 in the case<br>
of field mode. The frame/field mode decision 206 made by<br>
blocjk 104a,b is somehow reflected in the base layer bit-<br>
stream 120a, b such that, at the decoder side, the decisions<br>
206 imay be extracted from the scalable bit-stream 126 and,<br>
especially, from the base layer data-stream in the scalable<br>
bit-stream 126, as it is indicated in Fig. 3a by arrow 212<br>
poiniting from decision 206 to a block 214 contained in the<br><br>
base layer data stream 216. As a precautionary measure<br>
only, it is noted that the frame/field mode decisions do<br>
not necessarily need to be arranged or encoded into a<br>
continuous block within the base layer data stream 216. The<br>
decision with respect to the respective macroblock pairs<br>
■<br>
204 may be distributed over the base layer data stream 216<br>
in a parsable way. For more details, reference is made to<br>
the H.264/MPEG-AVC standard.<br><br>
However, the frame/field mode decisions 206 are not the<br>
only decisions to be made, by blocks 110a, b. Rather, as<br>
indicted by 218, blocks 110a,b also determine the motion<br>
parameters for each macroblock. These motion parameters<br>
define, for example, at which spatial resolution motion<br>
vectors are determined for a respective macroblock. As it<br>
is shown in Fig. 3a at 220a for example, the top macroblock<br>
202a has been further subdivided into four partitions 222,<br>
wherein for each partition 222 a . motion vector 224 is<br>
defined. Compared thereto, the bottom macroblock 202b is<br>
left as one partition, so that merely one motion vector 224<br>
has been determined for this macroblock. Of course, the<br>
decision 218 with respect to the motion parameters is, in<br>
the rate/distortion optimization sense, not independent of<br>
the frame/field decision 206. This is indicated by 220b<br>
indicating an exemplary partitioning for the macroblocks<br>
202a and 202b in case of field-coded macroblocks, whereas<br>
the iearlier described case of 220a shall reflect the case<br>
of frame-coded macroblocks. Although the partitioning is<br>
exemplarily shown to be the same, it is clear that the<br>
partitioning may be different depending on the frame/field<br>
decision 206. A further motion parameter may define the<br>
number of reference pictures used for motion-compensatedly<br>
predicting the respective macroblock. This decision may be<br>
made on a partition basis, macroblock basis or picture<br>
basis as well as a slice basis. However, for simpli tying<br>
Fig. 3a, just one motion vector is shown for each partition<br>
222. Beside this, the motion parameters 218 of course<br>
define the motion vectors themselves, such as the direction<br><br>
and length thereof. The motion vectors define the<br>
displacement of the reconstructed reference picture having<br>
to be performed before taking the picture content of the<br>
reconstructed reference picture as a prediction for the<br>
picture information contained in macroblock 2 02a,b. In<br>
determining 22 6 the residual or prediction error, . the<br>
picture content taken from the reconstructed reference<br>
picture displaced as defined by the motion vectors 224 is<br>
of course different when considering field-coded<br>
macroblocks and frame-coded macroblocks. In case of frame-<br>
coded macroblocks, the picture information used out; of the<br>
displaced and reconstructed reference picture represent a<br>
continuous spatial sub-area. However, in case of a field-<br>
coded macroblock, the picture information used out of the<br>
displaced and reconstructed reference picture relates to an<br>
area twice as high. The residual thus obtained for a<br>
specific partition 222 is indicated at 228 for a frame-<br>
coded macroblock and at 222b for a field-coded macroblock.<br>
The residual samples contained in this partition 228a,b are<br>
not directly coded into the base layer bit-stream. Rather,<br>
a transformation, such as a DCT or some other spectral<br>
decomposition, is performed on the residual samples in<br>
order to obtain a transformation coefficient matrix for<br>
representing the residual information contained in 22 8a,b.<br>
The transformation 230 may be performed on the whole<br>
partition or macroblock 202a,b. However, the transformation<br><br>
230 may also be performed on sub-portions of the macroblock<br>
202a,b or the partition 228a,b, as exemplarily indicated by<br>
dashed lines 232 in partition 22.8a. Accordingly, one or<br>
more transformation coefficient matrices 234 may be<br>
obtained from one macroblock or partition.<br>
The motion parameters 218 as well as the transformation<br>
coefficients in matrices 234 - the latter in relatively<br><br>
coarsely quantized form as already mentioned above - are-<br>
incorporated by base layer coding means 112a,b into the<br>
base layer data stream 216 or 120a, b, as shown by arrows<br><br>
236 and 238, thereby obtaining motion information 240 and<br>
residual information 242 in base layer data stream 120a,b.<br>
A Lagrangian approach may be used for determining the<br>
frame/field mode decisions and the motion parameters 2i8<br>
such that the rate/distortion ratio is somehow optimized.<br>
Although the decisions 206 and 218 may Ln the<br>
rate/distortion sense be optimal for the quality associated<br>
with the base layer data stream, different decisions 206<br>
and 218 may be optimal when considering a higher quality.<br>
This consideration results in the mode of operation of<br>
encoder of Fig. 1 in accordance with an embodiment of the<br>
present application, according to which the frame/field<br>
mode decision 206 does not necessarily have to be<br>
maintained by the encoder. Rather, encoder and decoder are<br>
enabled to change the frame/field mode decision with<br>
respect to individual macroblock pairs in the refinement<br>
layers. In accordance with the embodiment of Figg. 1, a<br>
change of the frame/field mode decision is always<br>
accompanied by a renewal of the motion parameters and the<br>
residual transform coefficients, too. However, as will be<br>
described afterwards, this does not necessarily have to be<br>
the case.<br>
Fig. 3b schematically shows the mode of operation of the<br>
refinement coding means 114a,b in accordance with an<br>
embodiment of the present invention. Fig. 3b focuses on the<br>
refinement of one exemplary macroblock pair 204, which is<br>
exemplarily composed of two frame-coded macroblocks 2 02a<br>
and 202b, with a top macroblock 202a being partitioned into<br>
four partitions 222, whereas the bottom macroblock 202b is<br>
composed of merely one partition. The field/frame mode<br>
decision and the motion parameters thus defined for the<br>
representative macroblock pair 204 correspond to the ones<br>
shown at 220a in Fig. 3a. As has also already been<br>
described with respect to Fig. 3a, the residual information<br>
with respect to the macroblock pair 204 is transmitted by<br>
use of transform coefficients arranged in a transform<br><br>
coefficient matrix .234. The transform coefficients in the<br>
transform coefficient . matrix 234 correspond to different.<br>
frequencies in horizontal direction 244 and vertical<br>
direction 24 6. In Fig. 3b, the upper left transform<br>
coefficient, for example, corresponds to the DC component.,<br>
this transform coefficient being indicated by 248a.<br>
Now, considering the refinement or quality or precision<br>
enhancement for the macroblock pair 204, refinement; coding<br>
means 114a,b makes 250 a decision as to whether to keep or<br>
to change the frame/field mode decision relative to the<br>
decision made by block 110a, b with respect to the base<br>
layer.<br>
Firstly, the case of keeping the frame/field mode decision<br>
is considered. In this case, the macroblock pair 204 is<br>
still treated as frame-coded in the refinement layer.<br>
However, refinement coding means 114a,b considers whether<br>
it is in rate-distortion sense better to keep the motion<br>
information, i.e. to adopt the motion information from the<br>
subordinate layer, i.e. the base layer, and just refine the<br>
residual information, or whether it is better to change the<br>
motion information and residual information compared to the<br>
base layer. This decision is indicated by 252 in Fig. 3b.<br>
If refinement coding means 114a,b decides, for a specific<br>
macroblock pair 204, to keep both the frame/field mode<br>
decision and the motion information, refinement coding<br>
means 114a,b incorporates the results of the decisions 250<br>
and 252 into the first enhancement layer data stream<br>
122a, b. The result of decision 250 is incorporated into<br>
data stream 122a,b in form of mode change indicators 256,<br>
as indicated by the dashed line 258. Accordingly, the<br>
result of decision 252 is incorporated into data stream<br>
122a,b as a motion precision-enhancement on/off indicator<br>
260, as indicted by a dashed line 262. Moreover, refinement<br>
coding means 114a,b incorporates into the data stream<br>
122a,b residual precision enhancement information 266, this<br>
incorporation being indicated with dashed arrow 263. In the<br><br>
current preferred embodiment, the residual precision<br>
enhancement information 266 incorporated at 263 shall<br>
represent residual transform coefficient levels<br>
representing a residual of the respective transform<br>
coefficient levels as defined so far by the subordinate<br>
layer, i.e. subordinate refinement layer or base layer,<br>
relative to the real transform coefficients at a reduced<br>
quantization step size, such as divided by two relative to<br>
the subordinate layer. However, as indicated below, a<br>
further flag/indicator within stream 122a,b may be used to<br>
indicate that, for a specific macroblock, the residual<br>
precision enhancement information 266 is to be interpreted<br>
at decoder side as anew transform coefficient levels<br>
representing the transform coefficient levels independent,<br>
of the current transform coefficient levels as derivable up<br>
to the subordinate layer.<br>
The refinement coding means 114a,b may decide not to keep<br>
the motion information for a specific macroblock but to<br>
refine same relative to the base layer, in this case, the<br>
refinement coding means 114a,b indicates the result of this<br>
alternative decision 252 by a respective indicator 260 in<br>
the first enhancement layer data stream 122a,b. Moreover,<br>
refinement coding means 114a,b incorporates into the data<br>
stream 122a,b motion precision enhancement information 2 64<br>
as well as residual precision enhancement information 2 66,<br>
as it is indicated by dashed arrows 268 and 270. The motion<br>
precision enhancement information 264 and/or the residual<br>
precision enhancement information 266 may either represent<br>
completely new motion information/residual information or<br>
refinement information for refining the motion information<br>
and residual information of the subordinate layer,<br>
respectively, i.e. the base layer in the case illustrated<br>
in Fig. 3b. Completely new enhancement information -264 or<br>
266 shall indicate - as already indicated above with<br>
respect to the residual data - enhancement information that<br>
completely replaces the respective enhancement information<br>
of the subordinate enhancement layer, i.e. the base layer.<br><br>
Contrary thereto, enhancement information 264 and 266 is<br>
for refining the motion/residual information of the<br>
subordinate layer, the motion/residual information of the<br>
current refinement layer, i.e. the first enhancement layer<br>
in case of Fig. 3b, being derivable merely by combining<br>
both the current enhancement information 264, 266 as well.<br>
as the motion/residual information of the subordinate<br>
layer, such as by adding corresponding transform<br>
coefficient levels or motion vector component levels of the<br>
 two consecutive refinement levels.<br>
To illustrate the effect of changing the motion information<br>
in the first enhancement layer, the effect of keeping the<br>
frame/field mode decision but changing the motion<br>
information is indicated in Fig. 3b at 272. As shown there,<br>
the motion information associated with macroblock pair 204<br>
in the first enhancement layer differs from the motion<br>
information associated with that macroblock pair 204 in the<br>
base layer in that two reference pictures are used for<br>
predicting the picture content within the macroblock pair.<br>
Accordingly, each partition 222 is associated with two<br>
motion vectors 224a and 224b. Moreover, the motion<br>
information of the first refinement layer changes the<br>
partitioning of the bottom macroblock 202b in that same is<br>
partitioned into four partitions instead of forming merely<br>
one partition, as it is the case in the base layer. The<br>
motion information of the first refinement layer, i.e. the<br>
reference picture numbers, the motion vectors 224a and 224b<br>
as well as the partitionings of macroblocks 202a and 2 02b<br>
may be either coded completely new in the first enhancement<br>
layer data stream 122a,b or with taking the motion<br>
information of the base layer as a predictor. For example,<br>
if the motion vectors 224a correspond to the same reference<br>
picture, merely the offset of the motion vectors 224a<br>
relative to the motion vectors 22.4 of the base layer may be<br>
coded into motion-precision enhancement information 264. By<br>
assuming a temporarily linear motion, the motion vectors<br>
224 may also serve as the basis for a prediction of the new<br><br>
motion vectors 224b relating to a different reference<br>
picture. Beside this, the single motion vector 224 of the<br>
single partition of the bottom macroblock 202b may serve as<br>
a predictor for the motion vectors of each partition of the<br>
bottom macroblock 202b in the first enhancement layer.<br>
Similarly, the transform coefficient levels for the<br>
transform coefficients of the transform coefficient matrix<br>
234 transmitted in the first enhancement layer data stream<br>
122a,b may either represent merely residuals or offsets<br>
relative to the transform coefficient levels of the base<br>
layer quantized with a finer quantization step size, or<br>
represent a transform coefficient of the transform<br>
coefficient matrix 234 completely anew without use of the<br>
transform coefficients of the base layer as a prediction.<br>
Up to now, the case has been described in which the<br>
refinement coding means 114a,b decides to maintain the<br>
frame/field mode decision with respect to macroblock pa i r<br>
204. However, if the result of decision 250 is to change<br>
the frame/field mode in the first enhancement layer, this<br>
is indicated by a respective mode change indicator 256, and<br>
new motion information along with new residual information<br>
is inserted in form of motion precision enhancement<br>
information 264 and residual precision enhancement.<br>
information 266 into the first enhancement layer data<br>
stream 122a,b, as it is indicated by dashed arrows 274 and<br>
27 6. In particular, according to the example of Fig. 3b,<br>
the motion information of macroblock pair 204 is changed<br>
from the base layer to the first enhancement layer such<br>
that new motion vectors 224 for the partitions 222- of the<br>
top macroblock 202a are defined, and the bottom macroblock<br>
202b is partitioned into four partitions 222 with one<br>
motion vector 224 for each partition 222. As is indicated<br>
at 278, the macroblocks 202a and 202b are now field-coded<br>
with the top macroblock 202a, for example, merely including<br>
odd-numbered lines. The residual information is coded by<br>
means of transform coefficient levels of transform<br><br>
coefficients in respective transform coefficient matrixes<br>
234 with the levels being coded without using the transform<br>
coefficient levels of the matrices 234 of the base layer as<br>
a prediction.<br>
However, although in accordance with the present embodiment<br>
the motion and residual information is coded completely new<br>
in the case of not keeping the frame/field mode decision,<br>
alternatively, the motion information and residual<br>
information of the base layer defined for different<br>
frame/field modes may be used as a predictor. Consider, for<br>
example, the transform coefficients. The vertical<br>
resolution of the residual samples in the base layer is<br>
twice the vertical resolution of the residual samples of<br>
the first enhancement layer. Due to this, the highest-<br>
frequency component in the vertical direction 24 6 for which<br>
matrix 234 of the base layer comprises transform<br>
coefficients is twice the highest-frequency component in<br>
the vertical direction 24 6 for which matrix 2 34 of the<br>
first enhancement layer comprises transform coefficients.<br>
Thus, at least a part of the matrices 234 of the base layer<br>
may be used as a predictor for the transform coefficients<br>
of the matrices 234 of the first enhancement layer. To be<br>
more precise, the transform coefficient level of the<br>
transform coefficient 248a representing the DC component<br>
and transmitted 276 within the residual precision<br>
enhancement information 2 66 in the first enhancement layer<br>
data stream 122a,b may represent an offset relative to the<br>
transform coefficient level for the corresponding transform<br>
coefficient 248a transmitted in the base layer data stream<br>
120a,b. The same applies for the higher-frequency<br>
horizontal components. Moreover, the transform coefficient<br>
levels of the first enhancement layer transmitted for the<br>
next but one higher vertical frequency component 280 may be<br>
coded as prediction errors relative to the next vertical<br>
frequency components in the base layer indicated by 282.<br>
Similarly, the motion vectors of the frame-coded<br><br>
macroblocks of the base layer may be used as predictors for<br>
the motion vectors of the first enhancement layer.<br>
Of course, the above example of changing the frame-coded<br>
macroblock pair from the base layer to a field-coded<br>
macroblock pair in the first enhancement layer was just a<br>
possible example. Of course, a field-coded macroblock pair<br>
in the base layer may be changed into a frame-coded<br>
macroblock pair in the first enhancement Layer. Moreover,<br>
it is possible that no change in the frame/field mode<br>
decision with respect to a specific macroblock pair occurs<br>
in the first enhancement layer but in the second or<br>
following enhancement layer. The quality or precision of<br>
the pictures of the video may be increased and the<br>
distortion of the picture decreased from one layer to the<br>
next by, for example, decreasing the quantization step size<br>
for transmitting the transform coefficient .levels,<br>
increasing the resolution by which the motion vectors are<br>
defined and/or using a finer partitioning and a greater<br>
number of reference pictures for the motion compensation.<br>
Moreover, apart from the indicators 256 and 260, other<br>
indicators may also be transmitted within the first.<br>
enhancement layer data stream 122a,b. For example,<br>
indicators may be transmitted within first enhancement<br>
layer data stream 122a,b in order to indicate as to whether<br>
merely the motion information or the residual information<br>
or both are replaced or refined by the first enhancement.<br>
layer data stream 122a,b with respect to a specific<br>
macroblock. Similarly, index indicators may be used in<br>
order to define as to whether motion precision enhancement<br>
information or residual precision enhancement information<br>
with respect to a specific macroblock is to replace or<br>
refine the respective motion/residual information of the<br>
subordinate layer.<br>
It may be noted that, in accordance with a preferred<br>
embodiment of the present invention, the order in which the<br>
transform coefficient levels of the first enhancement layer<br><br>
are inserted in the current enhancement layer data stream<br>
122a, b is dependent on the result of decision 250. For<br>
example, if, in accordance with a current enhancement<br>
layer, a specific macroblock is a frame-coded macroblock, a<br>
scan path 284 used for defining the order in which the<br>
transform coefficient levels of the first enhancement layer<br>
are inserted into the residual precision enhancement<br>
information 266 is different from a scan path 286 used tor<br>
the transform coefficient levels of the respective field-<br>
coded macroblock in the subordinate enhancement layer. The<br>
difference in the scan paths for field- and frame-coded<br>
macroblocks reflects the existence of higher-frequency<br>
vertical components in the transform coefficient matrixes<br>
234 of frame-coded macroblocks relative to field-coded<br>
macroblocks. In particular, preferably the transform<br>
coefficients are transmitted within the residual precision<br>
enhancement information 2 66 with first transmitting the<br>
transform coefficient levels of the non-significant.<br>
transform coefficients, i.e. those transform coefficients<br>
for which the transform coefficient level is 0 according t.o<br>
the subordinate layer. The transform coefficient levels of<br>
the non-significant transform coefficients are coded in a<br>
so-called significant path. The coding of the transform<br>
coefficient levels of significant transform coefficients<br>
following thereto is called a refinement path. The<br>
significance path is performed in several cycles. In the<br>
first cycle, for example, the first non-significant<br>
transform coefficient along the scan path 28 4 or 28 6 in the<br>
first transform block (see 232 in Fig. 3a) in the first<br>
macroblock is coded. Eventually, further transform<br>
coefficient levels of following non-significant transform<br>
coefficients in scan path direction 284 and 28 6 within the<br>
current transform block are coded immediately thereafter,<br>
depending on the transformation block size. Then, the next.<br>
transform block in a transform block scan order within the<br>
current macroblock is visited until all transform blocks<br>
within the current macroblock have been visited.<br>
Thereafter, the next macroblock in macroblock scan order<br><br>
within the current slice is visited, wherein the procedure<br>
is performed again within this macroblock, the macro-block<br>
scan order being indicated in Fig. 2 by 288. Further cycles<br>
are performed after having visited the last transform block<br>
in the last macroblock of the current slice. After having<br>
coded the transform coefficient levels of the non-<br>
significant transform coefficients, the transform<br>
coefficient levels of the significant transform<br>
coefficients are coded in the refinement path. The<br>
refinement path may, depending on the encoding scheme used<br>
for coding the syntax elements into the bit-stream 126, for<br>
example, variable length coding or arithmetic coding<br>
performed by scanning the macroblocks within a slice merely<br>
once or by scanning them in a fixed number of cycles each<br>
cycle being dedicated for a specific transform coefficient<br>
position in scan order 284 or 286, with a respective<br>
transform coefficient level for a specific transform<br>
coefficient position merely being coded if. the transform<br>
coefficient is significant.<br>
In the significance path as well as the refinement path,<br>
the scan path used for determining the visiting order among<br>
the transform coefficients within the respective transform<br>
block depends on the frame/field mode of the corresponding<br>
macroblock pair according to the current refinement layer.<br>
That is, the ordering of the transform coefficients in the<br>
first enhancement layer data stream 122a,b may have an<br>
impact on the rate/distortion ratio of the resulting first<br>
enhancement layer data stream 122a,b since, if a context-<br>
adaptive coding scheme is used, an ordering of the<br>
transform coefficient levels in the first enhancement layer<br>
such that transform coefficient levels having a similar<br>
probability distribution are arranged in a juxtaposed<br>
position within the first enhancement layer data stream<br>
122a,b may enable a better adaptation of the probability<br>
estimation used for encoding. Therefore, the decisions 250<br>
and 252 may also depend on the influence of these decisions<br>
to the coding efficiency or quality of the probability<br><br>
estimation used for encoding the syntax elements and, in<br>
particular, the transform coefficient levels in the first,<br>
enhancement layer.<br>
The way, refinement coding means 114a,b makes decisions 250<br>
and 252 may be similar to the way by which blocks 110a, b<br>
along with base layer coding blocks 112a,b create the base<br>
layer bit-stream 120a,b. To be more precise, a Lagranqian<br>
approach may be used in order to optimize the decisions in<br>
rate/distortion sense.<br>
After having described the functionality of the refinement.<br>
coding means 114a,b with respect to Fig. 3b, the mode of<br>
operation of the encoder of Fig. 1 is described again with<br>
respect to Fig. 1 to Fig. 3b with more specific reference<br>
to the H.264/MPEG4-AVC standard. In other words, the<br>
functionality of the encoder of Fig. 1 is described more<br>
precisely in the context of creating a scalable bit-stream<br>
126 as a scalable extension of the H.264 /MPEG4-AVC<br>
standard. In the above-described SVC working drafts of<br>
October 2005, the scalability tools were especially<br>
dedicated for frame_MBS_only_flag equal to 1. In other<br>
words, in accordance with these drafts the macroblocks were<br>
frame macroblocks only. The concepts of supporting SNR and<br>
spatial scalability have only been designed for progressive<br>
source material. However, the encoder of Fig. 1 forms an<br>
extension to interlaced sources by considering the<br>
properties of interlaced source material. In particular,<br>
the encoder of Fig. 1 optimizes the coding of progressive<br>
refinement slices with adaptive motion refinement as<br>
described in the above working draft JVT-Q031 for<br>
interlaced source material. In addition to the motion and<br>
residual refinement, a revision of the macroblock-bascd<br>
frame/field decision of the base quality layer can be<br>
transmitted in an FGS enhancement layer.<br>
In particular, the encoder of Fig. 1 extends the coding of<br>
progressive refinement slices with adaptive motion<br><br>
refinement for interlaced frames with macrobl ock-adaptivo<br>
frame/field decisions in that, when macroblock-adaptivo<br>
frame/field coding is enabled, then, for all macroblock<br>
pairs or a subset of the macroblock pairs of a progressive<br>
refinement slice of a coded frame, a syntax element is<br>
transmitted that signals whether the macroblock pairs are<br>
coded as a pair or field or frame macroblocks. Depending on<br>
the frame/field mode of the macroblock pair and the<br>
progressive refinement slice and the frame/field mode of<br>
the co-located macroblock pair in the subordinate SNR<br>
layer, the following applies: (1) If the current macroblock<br>
202a (Fig. 3b) is coded in the field-frame mode and the co-<br>
located macroblock pair in the subordinate SNR layer (in<br>
Fig. 3b, the base layer) is coded in the same field-frame<br>
mode (see yes path starting from decision 250 in Fig. 3b),<br>
the field-frame decision of the SNR subordinate layer<br>
macroblock pair is used. The motion and prediction<br>
information can be refined independently of the field/frame<br>
decision as transmitted by additional indicators or syntax<br>
elements 2 62, 2 68 and 270, wherein reference is made to RCT<br>
EP 2005/010972 for further details in this regard, the<br>
content of which is incorporated herein by reference with<br>
respect to the refinement of the motion information and<br>
refinement information in case of keeping the frame/field<br>
mode decision unchanged. (2) Otherwise, if the field/frame<br>
decision in the current slice is different from the<br>
field/frame decision in the subordinate SNR layer (see yes<br>
branch from 250), for both macroblocks in the macroblock<br>
pair, a new macroblock mode (260) together with<br>
corresponding motion and prediction information (264) is<br>
transmitted in addition to the refinement (266) of the<br>
residual signal. The possible macroblock modes are the same<br>
as supported by the coding standard H.264 /MPEG4-AVC, which<br>
means that by subdivision of the macroblock into smaller<br>
blocks or partitions for motion-compensated prediction up<br>
to 16 motion vectors for P-slices and up to 32 motion<br>
vectors for B-slices can be signalled.<br><br>
One way to make this frame/field decision in a progressive<br>
refinement slice is to use a Lagrangian approach where a<br>
Lagrangian cost functional J = D + λR is minimized for a<br>
given A. Here, D stands for the distortion between original<br>
and reconstructed (decoded) signal and R represents the bit.<br>
rate needed for coding the macroblock pair. If the cost for<br>
reversing the frame/field decision of the subordinate SNR<br>
layer is lower than the cost for keeping the frame/decision<br>
of the subordinate SNR layer, it is in rate-distortion<br>
sense obviously better to reverse the frame/field decision<br>
of the macroblock pair and transmit a new set of motion<br>
and/or prediction information (see no-path of decision<br>
250). Consequently, using the adaptive frame/field<br>
refinement it is possible to achieve a higher picture<br>
quality at the same bit rate.<br>
An advantage of the FGS coding scheme presented here with<br>
respect to Figs. 1 and 3b is that the inverse transform at<br>
the decoder side has to be performed only once for each<br>
transform block. The scaled transform coefficients of the<br>
base quality layer and of all associated progressive<br>
refinement slices are, as far as macroblock pairs with<br>
maintained frame/field coding mode are concerned, added up,<br>
and merely the obtained transform coefficients, which<br>
represent the highest available quality, have to be<br>
transformed. This concept is, in accordance with the FGS<br>
coding scheme of Figs. 1 and 3b, also followed with respect<br>
to the adaptive motion refinement. In order to not increase<br>
the decoder complexity for the FGS coding scheme with<br>
adaptive frame/field decisions, preferably a special<br>
restriction is introduced for the case that the frame/field<br>
decision of the subordinate SNR layer is changed. When a<br>
new macroblock mode is transmitted in the FGS coding scheme<br>
with adaptive motion refinement at a certain refinement<br>
layer, a further syntax element residual _prediction__flag<br>
signals whether the residual signal of the SNR base layer<br>
(or the subordinate refinement layer) is used for<br>
reconstruction. If this flag is equal to 1, the transform<br><br>
coefficients that have been transmitted in the SNR base<br>
layer are used for reconstructing the residual of the<br>
enhancement layer representation. Otherwise, if this flag<br>
is equal to 0, the residual signal of the enhancement layer<br>
representation is reconstructed by using only the transform<br>
coefficient levels 2 66 that are transmitted in the FGS<br>
enhancement layer 122a,b. Since the transforms that are<br>
performed for field macroblock pairs use different sets of<br>
samples than the transforms that are performed for frame<br>
macroblock pairs, it is advantageous to avoid multiple<br>
transforms by forbidding the residual prediction when a<br>
frame/field decision is changed. Thus, in a preferred<br>
embodiment of the present invention, the syntax element<br>
that specifies the above-described usage of a residual from<br>
the SNR base layer, i.e. the syntax element<br>
residual_prediction_flag, is only transmitted when the<br>
frame/field decision of the SNR base layer is not modified<br>
in the SNR enhancement layer. Otherwise, the syntax element<br>
residual_prediction_flag is inferred to be equal to 0 at<br>
the decoder side.<br>
According to an embodiment of the present invention,	the<br>
syntax of specifying the frame/field decision and	the<br>
macroblock mode for the FGS enhancement layer can	be<br>
expressed by the following pseudo-code. In so far,	the<br>
following code defines the steps performed by blocks 114a, b<br>
to code the syntax elements mentioned above into	the<br>
refinement layer data stream 122a,b.<br><br><br><br><br>
The first if-clause (line 12) checks as to whether the<br>
video source material has been coded by the base layer<br>
coding blocks 112a, b such that a macrob].ock-adapt.i vc<br>
frame/field decision is activated. If this is the case a<br>
syntax element mb_field_decoding_flag_EL is transmitted in<br>
the enhancement layer for a current macroblock pair or<br>
several macroblock pairs (line 16) in order to define its<br>
frame/field decision in that enhancement .layer. The second<br>
t<br>
ilf-clause (line 20) checks as to whether the frame/field<br>
decision has changed in the enhancement layer relative to<br>
the base layer where the frame/field decision is coded into<br>
mb_field_decoding_flag.<br>
The next lines (lines 22-62) define the information<br>
transmitted when the frame/field decision has not been<br>
modified. In this case, firstly, a syntax element.<br>
change_top_pred_info_flag is transmitted and coded (line<br>
26) indicating as to whether the motion/prediction<br>
information for the current top macroblock is modified<br>
relative to the subordinate layer. This syntax element.<br>
therefore represents an indicator 260 as shown in Fig. 3b.<br>
If this is the case (third if-clause in line 30) , a new<br>
macroblock mode, new motion vectors and reference picture<br>
numbers are transmitted (lines 32 and 34). Then, a<br>
transmission (line 36) of syntax element<br>
residual_prediction_flag is performed for signalling as to<br>
whether the transform coefficient levels for the current<br>
top macroblock to follow are transmitted as self-contained<br>
new transform coefficients or refinement information for<br>
refining the current coarser quantized transform<br>
coefficients. Then, i.e. if the motion information is<br>
indicated to be adopted from the subordinate layer (no path<br>
of if clause at line 30) or the new motion information<br>
along with the residual_prediction_flag has been<br>
transmitted (lines 32-36), the transmission of the<br>
transform coefficient levels is performed (lines 40, 4 2)<br>
with the transform coefficient levels representing, in the<br>
case of change_top_pred_info_flag being set, new transform<br><br>
coefficient level information or differentially coded or<br>
residual transform coefficient levels, depending on<br>
residual_prediction_flag transferred in line 36. In the<br>
other case, i.e. change_top_pred_info_flag not being set,<br>
the transform coefficient levels represent residual<br>
transform coefficient levels, i.e. residual prediction flag<br>
is inferred to indicate differential coding. This is<br>
repeated for the bottom macroblock (lines 44-60).<br>
In other words, in accordance with the present embodiment,<br>
in case of the frame/field decision being not modified, in<br>
any case, a "refinement" of the residual information takes<br>
place. Of course, this refinment may be zero, or<br>
"refinement" may mean that the bit-stream transmitted so<br>
far is not used but that a complete anew signal is<br>
transmitted that is not differentially coded. The first<br>
flag, i.e. change_top/bot_pred_info flag, indicates as to<br>
whether the refinement of the residual is conducted in the<br>
"normal mode", i.e. the same motion parameters are used as<br>
in the subordinate layer, und the refinement of the<br>
residual is coded as a difference to the transform<br>
coefficients transmitted so far in the base iayer and<br>
subordinate refinement layers if any. In case<br>
change_top/bot_pred__info_flag is not set, new motion<br>
parameters are transmitted - in the present case without<br>
differential coding but the latter is also possible as<br>
indicated above -, and a further flag is transmitted, i.e.<br>
residual_prediction_flag, this flag indicating as to<br>
whether the residual being valid so far is used. If the<br>
latter flag is set, then the refinement is coded as a<br>
difference/residual/refinement, otherwise the residual<br>
signal is coded completely anew.<br>
However, otherwise, if the frame/field decision has been<br>
modified relative to the base layer, new macroblock<br>
partitioning mode, motion vectors and reference picture<br>
numbers are transmitted (lines 70, 72) for the current top<br>
macroblock without signalling syntax element.<br><br>
residual_prediction_flag which is, instead, at the decoder<br>
side, to be inferred to be equal to 0 (lines 74, 76). This<br>
is repeated for the bottom macroblock (lines 78-86). The<br>
transmission of the transform coefficient levels for the<br>
current macroblock pair then starts (lines 90 and 92) after<br>
having transmitted the motion information for the top and<br>
bottom macroblocks for the whole macroblock pair. Of<br>
course, the steps 10-92 are performed for further<br>
macroblock pairs as well.<br>
With respect to the above pseudo-code embodiment, it is<br>
emphasized that the modified syntax only applies when a<br>
coded frame is transmitted, i.e. field_pic_flag is equal to<br>
0, and macroblock-adaptive frame/field coding is enabled,<br>
i.e. mb_adaptive_frame_field_flag is equal to 1 (line 12).<br>
Further, the frame/field decision is only transmitted<br>
(lines 16, 18) when the macroblock pair is visited the<br>
first time during the coding of progressive refinement<br>
slice. When the syntax element is different from the<br>
corresponding syntax element of the base SNR layer, a new<br>
set of macroblock modes, motion and/or prediction<br>
information are transmitted (lines 70, 72, 80, 82) tor both<br>
macroblocks of the macroblock pair, • and the<br>
residual_prediction_flag is inferred to be equal to 0 for<br>
both macroblocks of the macroblock pair (.Lines 74, 76, 84,<br>
86). Additionally, a syntax element specifying the<br>
transform size could be transmitted. The coding proceeds<br>
with a first transform coefficient level of the top<br>
macroblock in the significance path described above (lines<br>
90 ■, 92) . When the value of the syntax element specifying<br>
the frame/field decision is identical to its value in the<br>
base quality slice, the FGS coding follows the concept in<br>
the above-reference PCT application or the concept of JVT-<br>
Q031. The coding proceeds with the top macroblock, and here<br>
first a syntax element, which specifies a change of the<br>
macroblock mode and associated motion and prediction data,<br>
change_top_pred info_flag is transmitted (line 26). If this<br>
syntax element is equal to 1, a new macroblock mode and<br><br>
associated motion and prediction data as well as a flag<br>
specifying the usage of residual prediction from the base<br>
layer are transmitted (lines 32-36). The coding then<br>
proceeds with the first transform coefficient level of the<br>
top macroblock in the significance path (lines 40, 42).<br>
In all following visits of a macroblock pair or macroblock,<br>
i.e. when mb_field_decoding flag EL and<br>
change_top_pred_info_flag or change_bot_pred_info flag<br>
(when applicable) and the corresponding syntax elements<br>
specifying a modified macroblock prediction modes have<br>
already been transmitted, only further transform<br>
coefficient levels are coded in the order mentioned above.<br>
That means, the syntax element mb fie] d_ decoding flag El,<br>
(and a possible modification of the macroblock prediction<br>
information for the corresponding macroblock pair) is onJy<br>
transmitted when a macroblock pair is visited the first<br>
time and no transform coefficient level for this macroblock<br>
pair has been transmitted in the current progressive<br>
refinement slice. Similarly, the syntax element<br>
change_top_pred_info_flag or change_bot_pred_info_flag as<br>
well as a possible modification of the macroblock<br>
prediction information is only transmitted when<br>
mb_field_decoding_flag_EL is equal to<br>
mb_field_decoding_flag of the co-located macroblock pair Ln<br>
the SNR base layer, and when the macroblock is visited the<br>
first time and no transform coefficient level has been<br>
transmitted for this macroblock.<br>
With respect to Fig. 4, the steps to be performed by a<br>
decoder for decoding the scalable bit-stream 126 are<br>
described . The decoder starts with parsing the base layer<br>
bit-stream 122a and 122b contained in the scalable bit-<br>
stream 126 in step 800. As a result of step 800, the<br>
decoder knows the field/frame mode for each macroblock pai r<br>
as well as the motion parameters for each macroblock as<br>
well as the existence of the residual information. In other<br>
words, in step 800, the decoder extracts the information<br><br>
214, 240 and 242 from the base layer data stream 122a,b. In<br>
the next step, step 802, the decoder checks as to whether<br>
further refinement or quality enhancement is<br>
desited/required. If not, the decoder immediately decodes<br>
the base layer data stream 122a,b in a decoding step 804.<br>
'■■ Depending on the spatial resolution desired/requi red, the<br>
decoding 804 is performed by merely decoding the base layer<br>
bit-Stream 120b in accordance with the H.2 64/MPEG4-AVC<br>
standard or both base layer bit-streams 120a,b are decoded<br>
in accordance with that standard and then the coarsly<br>
reconstructed pictures are refined by the finer!y<br>
reconstructed ones.<br>
If a further refinement is desired/required, the decoder<br>
steps to step 806 in which the frame/field mode change<br>
indication (mb_field_decoding_flag) and, if no change is<br>
indicated, the motion enhancement on/off. indication<br>
(change_*_pred_into_flag) is extracted from the next<br>
higher-order refinement layer bit-stream 122a,b. Upon step<br>
806, the decoder is able to reconstruct from the<br>
frame/field mode of the macrob.lock pairs in the current<br>
refinement layer and the significance of: the transform<br>
coefficient levels in the base layer or subordinate layer,<br>
the significance path and the refinement path used at the<br>
encoder side for the current refinement layer. In the next<br>
step, step 8 08, decoder parses the refinement layer<br>
accordingly in order to extract the motion information for<br>
all macroblocks with motion enhancement on/off indication<br>
indicating a replacement of the current motion information<br>
and for all macroblocks with changed frame/field mode<br>
decision, as well as the residual information representing<br>
differentially coded residual information or self-contained<br>
residual information depending on residual prediction flag<br>
being parsed from the refinement data stream in case of<br>
change_*_pred_into_flag being set, and inferred to indicate<br>
differential coding in case of change_*_pred_into_f1ag<br>
being not set. Next, in step 810, the decoder checks for<br>
each macroblock pair as to whether the frame/field mode has<br><br>
changed relative to the subordinate layer. If yes, the<br>
decoder steps to step 812 and replaces, since the<br>
residual_prediction_flag is inferred to be equal to 0, the<br>
current encoding data, i.e. the current motion/residual<br>
da*ta, with the motion/refinement information 264 and 266<br>
extracted from the enhancement layer data stream of the<br>
current enhancement layer. However, for all macroblock<br>
pairs where the frame/field mode has not been modified, the<br>
decoder checks the motion enhancement on/off indicator,<br>
i.e. the syntax element change_bot_pred_info [Mag, as to<br>
whether motion enhancement information 264 or 266 exists<br>
for the respective macroblocks of the macroblock pair. If<br>
this is the case, the decoder replaces - in an alternative<br>
embodiment refines - the current motion data for thi s<br>
macroblock, i.e. the motion information, and replaces or<br>
refines the residual data for this macroblock depending on<br>
the respective flag transmitted in the incoming data<br>
stream, i.e. residual_jprediction flag. To be more precise,<br>
in the case of decoding the enhancement layer data stream<br>
in accordance with the above-pseudo code, the motion<br>
information is always replaced, whereas, in case of the<br>
frame/field decision being not modified, the residual<br>
information is replaced or refined depending on some<br>
indicator, namely residual_prediction_flag in the case of'<br>
the above pseudo-code enhancement layer data stream. in<br>
case of replacement, the motion information for a specific<br>
macroblock contained in the enhancement layer completely<br>
replaces the motion information of the subordinate layer.<br>
In case of refinement, the information of the subordinate<br>
layer is combined with the respective information .in the<br>
enhancement layer. Especially, the transform coefficient<br>
levels of the enhancement layer are dequantized and added<br>
to the already having been dequantized or scaled (and<br>
eventually summed up) transform coefficient levels of: the<br>
corresponding transform coefficients of the subordinate<br>
layer.<br><br>
Otherwise, i.e. if the motion enhancement on/off indicator<br>
shows that the enhancement layer has no motion enhancemenl<br>
information for the respective macroblock, nothing is<br>
changed with respect to the motion data for this macroblock<br>
but the decoder refines, in step 818, the residual data by<br>
means of combining the current transform coefficients<br>
gained from*the incoming data stream so Ear and - via do-<br>
quantization - the refinement information of the current<br>
refinement layer for refining the residual data, i.e. the<br>
transform coefficient levels defined for a reduced<br>
quantization step size.<br>
Thereafter, i.e. after having performed any of steps 812,<br>
816, and 818 for all macroblocks of the current picture,<br>
the procedure returns to step 802 in order to check as to<br>
whether further refinement is desired/required. If yes,<br>
steps 806 to 818 are performed again for the next<br>
refinement layer. Otherwise, the procedure steps forward to<br>
step 804, where the current encoding data is decoded, I.e.<br>
the re-transformation, such as an inverse spectra!<br>
decomposition, is performed, the picture content of the<br>
macroblocks is predicted by use of the current motion<br>
information and based on already reconstructed reference<br>
pictures and the residual information obtained by the re-<br>
transformations combined with the prediction thus obtained<br>
in order to yield the current picture in its reconstructed<br>
form.<br>
Summarizing the above embodiments., they represent an FGS<br>
coding scheme with the following properties. Firstly, the<br>
coding of refinement signals for frames with macroblock-<br>
adaptive frame/field decision in which a pair of vertical<br>
adjacent macroblocks is either coded as a pair of frame or<br>
a pair of field macroblocks, is supported. Further, the<br>
frame/field decision for macroblock pairs of the base SNR<br>
layer is allowed to be adaptively modified in the FGS<br>
enhancement layer. It is possible that the frame/field<br>
decision for an FGS enhancement layer is signaled by a<br><br>
syntax element for each macroblock pair or for a subset; of<br>
macroblock pairs in the FGS enhancement layer. For the<br>
macroblock pairs, for which the frame/field decision is not<br>
signaled, the frame/field decision is inferred by using<br>
already transmitted syntax elements. In one embodiment, a<br>
complete set - of macroblock motion and prediction<br>
information is transmitted when the frame/field decision in<br>
the enhancement layer is different from the frame/field<br>
decision of the SNR base layer. A syntax element specifying<br>
the usage of a residual prediction from SNR base layer may<br>
be inferred to be equal to X, when the frame/field decision<br>
in the enhancement layer is different from the frame/field<br>
decision of the SNR base layer. At this, a value of X<br>
specifies that no residual prediction is applied and that<br>
the reconstructed residual signals is obtained by using<br>
only the transform coefficient levels of the current; FGS<br>
enhancement layer. Alternatively, for both macroblocks of a<br>
macroblock pair, a syntax element; may be transmitted when<br>
their frame/field decision in the enhancement layer is<br>
identical to the frame/field decision of the SNR base<br>
layer. This syntax element could specify whether a now<br>
macroblock motion and/or prediction information is<br>
transmitted in the FGS enhancement layer or whether t he-<br>
motion and/or prediction information of the co-located<br>
macroblock in the SNR base layer are used. The motion<br>
compensation for field macroblocks is performed on a field<br>
basis, whereas the motion compensation for frame<br>
macroblocks is performed on a frame basis. Similarly, the<br>
inverse transform for field macroblocks may be performed on<br>
a field basis, whereas the inverse transform for frame<br>
macroblocks may be performed on a frame basis. Further,<br>
similarly, the scan order of transform coefficients inside<br>
a transform block may be dependent on whether the<br>
macroblock is a field or a frame macroblock.<br>
Lastly, it is noted that the syntax element for specifying<br>
the frame/field mode of a macroblock pair may be<br>
transmitted using conditioned entropy codes, where the<br><br>
condition is dependent on the frame/field mode of the co-<br>
located macroblock pair in the SNR base layer. E'or example,<br>
the syntax element 258 could be transmitted by means of an<br>
entropy code using a probability estimation that is<br>
dependent on the field/frame mode decision 212 in the base<br>
layer.<br>
Finally, it is noted that the above embodiments were<br>
especially related to the H.264/MPEG4-AVC standard.<br>
However, the present invention is also applicable for to<br>
other coding schemes.<br>
Depending on an actual implementation, the Inventive coding<br>
scheme can be implemented in hardware or in software.<br>
Therefore, the present invention also relates to a computer<br>
program, which can be stored on a computer-readable medi urn<br>
such as a CD, a disc or any other data carrier. The present<br>
invention is, therefore, also a computer program having a<br>
program code which, when executed on a computer, performs<br>
the inventive method described in connection with the above<br>
figures.<br>
Furthermore, it is noted that all steps indicated in the<br>
flow diagrams could be implemented by respective means and<br>
the implementations may comprise sub-routines running on a<br>
CPU, circuit parts of an ASIC or the like.<br>
While the foregoing has been particularly shown and<br>
described with reference to particular embodiments thereof,<br>
it will be understood by those skilled in the art that<br>
various other changes in the form and details may be made<br>
without departing from the spirit and scope thereof. It is<br>
to be understood that various changes may be made in<br>
adapting to different embodiments without departing from<br>
the broader concepts disclosed herein and comprehended by<br>
the claims that follow.<br><br>
WE CLAIM :<br>
1. Decoder for decoding an encoded precision-scalable data stream (126)<br>
encoding a predetermined picture (200), the encoded precision-scalable<br>
data stream comprising :<br>
-	first precision-encoded data (120a,b) into which the predetermined<br>
picture is encoded with a first precision with using one of a frame coding<br>
mode and a field coding mode for a predetermined portion (202a,b) of the<br>
predetermined picture;<br>
-	higher precision information (122a,b) representing second precision<br>
encoded data into which the predetermined portion (202a,b) is encoded<br>
with a second precision higher than the first precision with using the other<br>
of the frame coding mode and the field coding mode for the<br>
predetermined portion (202a,b), or representing refinement information<br>
refining the first precision-encoded data to obtain the second precision-<br>
encoded data; and<br>
-	indication information (256) indicating an existence of a change in the<br>
frame and field coding modes used for the predetermined portion,<br>
between the first precision-encoded data and the second precision-<br>
encoded data;<br>
the decoder comprising:<br><br>
checking means (810) for checking the indication information as to<br>
whether same indicates the existence or an absence of a change in the<br>
frame or field coding modes used for the predetermined portion, between<br>
the first precision-encoded data and the second precision-encoded data;<br>
arranging means (810-816) for, if the indication information indicate the<br>
existence of the change in the frame and field coding modes,<br>
disregarding, at least partially, the first precision-encoded data with<br>
respect to the predetermined portion and arranging, instead, the second<br>
precision-encoded data as data for decoding, or, based on the higher<br>
precision information, refining the first precision-encoded data with<br>
respect to the predetermined portion to obtain the second precision-<br>
encoded data and arranging the obtained second precision-encoded data<br>
as data for decoding; and<br>
decoding means (804) for decoding the arranged data with using the<br>
other of the frame and field coding modes for the predetermined portion<br>
of the predetermined picture to reconstruct the predetermined picture<br>
with the second precision.<br>
2.	Decoder as claimed in claim 1, further comprising parsing means (800-<br>
808) for parsing the encoded precision-scalable data stream to realize the<br>
first precision-encoded data and the higher precision information (122a,b).<br>
3.	Decoder as claimed in claim 2, wherein the parsing means (800-808) is<br>
configured to perform the parsing of the higher precision information<br>
(122a,b) depending on the indication information.<br><br>
4.	Decoder as claimed in any of the preceding claims, wherein the<br>
predetermined picture is part of a video picture sequence (104) and the<br>
decoding means is configured to extract motion information and<br>
respective residual information for the predetermined portion from the<br>
data for decoding, apply the motion information to reconstructed<br>
reference pictures to obtain a motion-compensated prediction for the<br>
predetermined portion, and reconstruct the predetermined portion based<br>
on the motion-compensated prediction and the residual information.<br>
5.	Decoder as claimed in claim 4, wherein the decoding means (804) is<br>
configured to perform an inverse spectral decomposition to extract the<br>
residual information.<br>
6.	Decoder as claimed in any of claims 4 and 5, wherein the decoding means<br>
(804) is configured to perform the application of the motion information<br>
and the reconstruction of the predetermined portion dependent on the<br>
indication information.<br>
7.	Decoder as claimed in any of the preceding claims, wherein the arranging<br>
means (810-816) is configured to disregard the second precision-encoded<br>
data and arrange the first precision-encoded data as data for decoding if<br>
an instruction to the decoder signals that the predetermined picture is to<br>
be reconstructed merely in the first precision.<br>
8.	Decoder as claimed in any of the preceding claims, wherein the arranging<br>
means (810-816) is configured to, if the indication information indicate the<br>
absence of the change in the frame and field coding decisions for the<br>
predetermined portion between the first precision-encoded data and the<br><br>
second precision-encoded data, check (814) refinement change<br>
information (260) in the encoded precision-scalable data stream as to<br>
whether the first precision-encoded data is to be refined with respect to<br>
the predetermined portion or not, and, depending on the check result,<br>
keep the first precision-encoded data as the data to be decoded with<br>
respect to the predetermined portion or refine (816), based on the high<br>
precision information, the first precision encoded data to obtain the<br>
second precision-encoded data and arrange the obtained second<br>
precision-encoded data as the data to be decoded.<br>
9.	Decoder as claimed in any of the preceding claims, wherein the indication<br>
information is signaled by a first syntax element associated with said<br>
predetermined portion and the predetermined picture comprises another<br>
predetermined portion, wherein the higher precision information (122a,b)<br>
lacks any second syntax element associated with said other portion for<br>
signaling an absence or an existence of a change in the frame and field<br>
coding modes with respect to the other predetermined portion between<br>
the first precision-encoded data and the second precision-encoded data,<br>
wherein the checking means (810) is configured to infer a value of the<br>
second syntax element by use of already transmitted syntax elements.<br>
10.	Decoder as claimed in any of the. preceding claims, further comprising<br>
second checking means (814) for, if the indication information indicates<br>
the absence of the change in the frame and field coding modes with<br>
respect to the predetermined portion between the first precision-encoded<br>
data and the second precision-encoded data, checking a subordinate<br>
information (260) comprised by the higher precision information (122a,b)<br>
as to whether the second precision-encoded data includes motion<br><br>
information and/or residual information, and as to whether the second<br>
precision-encoded data is to replace the first precision-encoded data with<br>
respect to the predetermined portion or the second precision-encoded<br>
data is dedicated for refining the first precision-encoded data to obtain the<br>
second precision-encoded data, to obtain a check result, wherein the<br>
arranging means (810-816) is configured to perform the disregarding and<br>
arranging or the refining and arranging with respect to the motion or<br>
residual information dependent on the check result.<br>
11.	Decoder as claimed in any of the preceding claims, wherein the second<br>
precision-encoded data comprises transform coefficient levels of transform<br>
coefficients of a transform coefficient matrix (234) representing a motion-<br>
compensated residual of at least a portion of the predetermined portion,<br>
and wherein the parsing means is arranged to use a scan order among<br>
the transform coefficients, which is equal to one of a first and a second<br>
scan order (286) different to the first scan order (284), dependent on the<br>
indication information.<br>
12.	Decoder as claimed in claim 11, wherein the arranging means (810-816)<br>
and decoding means (804) are configured to, if the indication information<br>
(256) indicates the presence of the change in the frame and field coding<br>
modes for the predetermined portion between the first precision-encoded<br>
data and the second precision-encoded data, apply an inverse transform<br>
to the transform matrix (234) to obtain the motion-compensated residual,<br>
combine the motion-compensated residual with a portion of a<br>
reconstructed reference picture encoded using a field or frame coding<br>
mode, displaced from the predetermined portion by motion information<br>
indicated in the higher precision information (122a,b) or the first<br><br>
precision-encoded data to obtain a candidate reconstructed picture that is<br>
equal to the reconstructed picture in case of the other one of the frame<br>
and field coding mode being the frame coding mode, and, if the other one<br>
of the frame and field coding mode is the field coding mode, convert the<br>
candidate reconstructed picture from a frame representation into a field<br>
representation to obtain the reconstructed picture.<br>
13. Encoder for encoding a predetermined picture, comprising:<br>
base encoding means (110a,b, 112a,b) for encoding the predetermined<br>
picture with a first precision with using one of a frame coding mode and a<br>
field coding mode for a predetermined portion (202a,b) of the<br>
predetermined picture to obtain first precision-encoded data (120a,b);<br>
determination means (114a,b) for determining higher precision<br>
information (120a,b) representing second precision-encoded data into<br>
which the predetermined portion is encoded with a second precision being<br>
higher than the first precision using the other of the frame coding mode<br>
and field coding mode, or representing refinement information refining the<br>
first precision-encoded data to obtain the second precision-encoded data;<br>
and<br>
construction means (124) for constructing an encoded precision-scalable<br>
data stream (126) encoding the predetermined picture to include the first<br>
precision-encoded data (120a,b), the higher precision information<br>
(122a,b) and indication information (256) indicating a change in the frame<br>
and field coding modes used for the predetermined portion, between the<br>
first precision-encoded data and the second precision-encoded data.<br><br>
14.	Encoder as claimed in claim 13, wherein the predetermined picture further<br>
comprises another predetermined portion, and the higher precision<br>
information (122a,b) also represents other second precision-encoded data<br>
into which the other predetermined portion is encoded with the second<br>
precision and using the one of the frame and field coding modes or also<br>
representing respective other refinement information refining the other<br>
first-precision encoded data into which the other predetermined portion is<br>
encoded with the first precision, wherein the determination means<br>
(114a,b) is configured to determine the second-precision encoded data<br>
such that same comprise first transform coefficient levels of transform<br>
coefficients of a first transform coefficient matrix (234) representing a<br>
motion-compensated residual of the predetermined portion, and the other<br>
second precision-encoded data so that same comprise second transform<br>
coefficient levels of transform coefficients of a second transform<br>
coefficient matrix (234) representing a motion-compensated residual of<br>
the other predetermined portion, and the construction means (114a,b)<br>
being configured to code the first transform coefficient levels into the<br>
encoded precision-scalable data stream in accordance with a first scan<br>
order (284) among the transform coefficients of the first transform<br>
coefficient matrix, and the second transform coefficient levels into the<br>
encoded precision-scalable data stream in accordance with a second scan<br>
order (286) among the transform coefficients of the second transform<br>
coefficient matrix (234) being different from the first scan order (284).<br>
15.	Encoder as claimed in claim 13 or 14, wherein the construction means<br>
(124) is configured to perform the construction such that a correct parsing<br>
of the higher precision information (122a,b) depends on the indication<br>
information.<br><br>
16.	Encoder as claimed in any claims 13 to 15, wherein the predetermined<br>
picture is part of a video picture sequence (104) and the base encoding<br>
means and the determination means (114a,b) are designed such that the<br>
second-precision encoded data enables obtaining motion information<br>
and/or respective residual information for the predetermined portion from<br>
the encoded precision-scalable data stream, applying the motion<br>
information to already encoded and reconstructed reference pictures to<br>
obtain a motion-compensated prediction for the predetermined portion,<br>
and reconstructing the predetermined portion based on the motion-<br>
compensated prediction and the residual information.<br>
17.	Encoder as claimed in claim 16, wherein the base encoding means<br>
(110a,b, 112a,b) and the determination means (114a,b) are configured<br>
such that an inverse spectral decomposition has to be performed to<br>
extract the residual information.<br>
18.	Encoder as claimed in any of claims 16 and 17, wherein the base encoding<br>
means and the determination means are configured such that the<br>
application of the motion information and the reconstruction of the<br>
predetermined portion have to be performed dependent on the indication<br>
information.<br>
19.	Encoder as claimed in any of claims 13 to 18, wherein the construction<br>
means (114a,b) is configured such that the indication information (256)<br>
indicates the absence of the change in the frame and field coding modes<br>
of another predetermined portion of the predetermined picture between<br>
the first precision-encoded data and the second precision-encoded data,<br>
and the construction means (114a,b) and the determination means<br><br>
(114a,b) are configured such that the encoded precision-scalable data<br>
stream comprises refinement change information (260) indicating as to<br>
whether the first-precision encoded data is to be refined with respect to<br>
the other predetermined portion or not, and the higher precision<br>
information additionally represents further refinement information refining<br>
the first precision-encoded data with respect to the other predetermined<br>
portion to obtain other second-precision encoded data encoding the<br>
predetermined portion with the second precision.<br>
20. Encoder as claimed in any of claims 13 to 19, wherein the construction<br>
means (114a,b) is configured such that the indication information<br>
indicates the absence of the change in the frame and field coding modes<br>
of another predetermined portion of the predetermined picture between<br>
the first precision-encoded data and the second precision-encoded data,<br>
the construction means (114a,b) and the determination means (114a,b)<br>
are configured such that the encoded precision-scalable data stream<br>
comprises subordinate information (260) in the higher precision<br>
information (122a,b), indicating as to whether the higher precision<br>
information (122a,b) includes other second precision-encoded data<br>
including motion information and/or residual information for the other<br>
predetermined portion, and indicating as to whether the other second<br>
precision-encoded data is to replace the first precision-encoded data with<br>
respect to the predetermined portion or the other second-precision<br>
encoded data is dedicated for refining the first precision-encoded data<br>
with respect to the other predetermined portion to obtain the second-<br>
precision encoded data.<br><br>
21.	Precision-scalable bit-stream having encoded therein a predetermined<br>
picture, the precision-scalable bit-stream comprising:<br>
precision-encoded data (120a,b) into which the predetermined picture is<br>
encoded with a first precision using one of a frame and field coding mode<br>
for a predetermined portion (202a,b) of the predetermined picture a first<br>
one of frame-wise and field-wise;<br>
higher precision information (122a,b) representing second precision<br>
encoded data into which the predetermined portion (202a,b) is encoded<br>
with a second precision higher than the first precision using the other of<br>
the frame and field coding modes for the predetermined portion (202a,b),<br>
or representing refinement information refining the first precision-encoded<br>
data to obtain the second precision-encoded data; and<br>
indication information (256) indicating an existence of a change in the<br>
frame and field coding modes between the first precision-encoded data<br>
and the second precision-encoded data.<br>
22.	Method for decoding an encoded precision-scalable data stream (126)<br>
encoding a predetermined picture (200), the encoded precision-scalable<br>
data stream comprising first precision-encoded data (120a,b) into which<br>
the predetermined picture is encoded with a first precision with using one<br>
of a frame coding mode and a field coding mode for a predetermined<br>
portion (202a,b) of the predetermined picture a first one of frame-wise<br>
and field-wise, higher precision information (122a,b) representing second<br>
precision encoded data into which the predetermined portion (202a,b) is<br>
encoded with a second precision higher than the first precision with using<br><br>
the other of the frame coding mode and field coding mode for the<br>
predetermined portion (202a,b) or representing refinement information<br>
refining the first precision-encoded data to obtain the second precision-<br>
encoded data, and indication information (256) indicating an existence of<br>
a change in the frame-/field coding modes used for the predetermined<br>
portion, between the first precision-encoded data to obtain the second<br>
precision-encoded data, the method comprising the following steps,<br>
performed on a hardware:<br>
checking (810) the indication information as to whether same indicates<br>
the existence or an absence of a change in the frame or field coding<br>
modes used for the predetermined portion between the first precision-<br>
encoded data and the second precision-encoded data;<br>
if the indication information indicate the existence of the change in the<br>
frame and field coding, disregarding, at least partially, the first precision-<br>
encoded data with respect to the predetermined portion and arranging,<br>
instead, the second precision-encoded data as data for decoding, or,<br>
based on the higher precision information, refining the first precision-<br>
encoded data with respect to the predetermined portion to obtain the<br>
second precision-encoded data and arranging the obtained second<br>
precision-encoded data as data for decoding; and<br>
decoding (804) the arranged data with using the other of the frame or<br>
field coding modes for the predetermined portion of the predetermined<br>
picture to reconstruct the predetermined picture with the second<br>
precision.<br><br>
23. Method for encoding a predetermined picture, comprising the following<br>
steps, performed on a hardware:<br>
encoding a predetermined portion (202a,b) of a predetermined picture<br>
(200) with a first precision usiing one of frame-wise coding mode or field-<br>
wise coding mode to obtain first precision-encoded data (120a,b);<br>
determining higher precision information representing second precision-<br>
encoded data into which encoded with a second precision higher than the<br>
first precision using the other of the frame coding mode or field coding<br>
mode for the predetermined portion, or representing refinement<br>
information refining the first precision-encoded data to obtain the second<br>
precision-encoded data; and<br>
constructing an encoded precision-scalable data stream (126) encoding<br>
the predetermined picture to include the first precision-encoded data<br>
(120a,b), the higher precision information (122a,b) and indication<br>
information (256) indicating an existence of a change in the frame-field<br>
coding modes used for the predetermined portion between the first<br>
precision-encoded data and the second precision-encoded data.<br><br><br><br>
ABSTRACT<br><br><br>
TITLE "CODING METHODS AND APPARATUSES FOR PRECISION<br>
SCALABILITY"<br>
The invention relates with an improved coding efficiency is achieved by giving<br>
the encoder the opportunity to change the field/frame-wise treatment of<br>
individual picture portions between the first precision-encoded data and the<br>
second precision-encoded data, with the second precision being higher than the<br>
first precision.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-correspondence others 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4yLnBkZg==" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-correspondence others 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1mb3JtIDIucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1pbnRlcm5hdGlvbmFsIHNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-international search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1wY3QgcHJpb3JpdHkgZG9jdW1lbnQgbm90aWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-pct priority document notification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDM0MTcta29sbnAtMjAwNy1wY3QgcmVxdWVzdCBmb3JtLnBkZg==" target="_blank" style="word-wrap:break-word;">03417-kolnp-2007-pct request form.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1GT1JNLTUucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-FORM-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LSgxMS0wNC0yMDEzKS1QRVRJVElPTiBVTkRFUiBTRUNUSU9OIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-(11-04-2013)-PETITION UNDER SECTION 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUNBTkNFTExFRCBQQUdFUy5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-CANCELLED PAGES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFIE9USEVSUyAxLjIucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-CORRESPONDENCE OTHERS 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUZPUk0gMTgucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-FORM 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUZPUk0gMjYucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-FORM 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUdSQU5URUQtU1BFQ0lGSUNBVElPTi1DT01QTEVURS5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-GRANTED-SPECIFICATION-COMPLETE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgUFVCTElDQVRJT04ucGRm" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-INTERNATIONAL PUBLICATION.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-INTERNATIONAL SEARCH REPORT &amp; OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LVBBLnBkZg==" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzQxNy1LT0xOUC0yMDA3LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">3417-KOLNP-2007-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMDM0MTcta29sbnAtMjAwNy5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-03417-kolnp-2007.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="257747-method-for-tracking-an-object-in-an-avatar-based-video-conferencing-system.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="257749-method-and-apparatus-for-handling-data-blocks-in-a-mobile-communications-system.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>257748</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3417/KOLNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>44/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>01-Nov-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>31-Oct-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>13-Sep-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C 80686 MUNCHEN</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HEIKO SCHWARZ</td>
											<td>KLAUSTHALER STRASSE 3 13187 BERLIN</td>
										</tr>
										<tr>
											<td>2</td>
											<td>TOBIAS HINZ</td>
											<td>AUERSTRASSE 41 10249 BERLIN</td>
										</tr>
										<tr>
											<td>3</td>
											<td>THOMAS WIEGAND</td>
											<td>FASANENSTRASSE 42 10719 BERLIN</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/50</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2006/002634</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-03-22</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td></td>
									<td></td>
								    <td>NA</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/257748-decoder-encoder-and-methods-of-encoding-decoding-precision-scalable-bit-stream-with-encoded-predetrmined-picture by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:34:17 GMT -->
</html>
