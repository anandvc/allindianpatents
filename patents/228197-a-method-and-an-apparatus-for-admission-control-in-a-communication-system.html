<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/228197-a-method-and-an-apparatus-for-admission-control-in-a-communication-system by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:46:39 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 228197:A METHOD AND AN APPARATUS FOR ADMISSION CONTROL IN A COMMUNICATION SYSTEM</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A METHOD AND AN APPARATUS FOR ADMISSION CONTROL IN A COMMUNICATION SYSTEM</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method and apparatus for admission control in a communication system. An Access Network (AN) element determines available resources. When available resources are sufficient to support the requirements of a requested application flow, the AN admits the application flow. The AN periodically, and on trigger events, updates a measure of available resources. The admission control may operate in coordination with a scheduler applying a compensation factor to each flow type, and a compensation factor for aggregate flows of a given user.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
ADMISSION CONTROL AND RESOURCE ALLOCATION IN A COMMUNICATION SYSTEM SUPPORTING APPLICATION FLOWS HAVING QUALITY OF SERVICE REQUIREMENTS<br>
Claim of Priority under 35 U.S.C. ยง119<br>
[1001]     The present Application for Patent claims priority to Provisional<br>
Patent Application No. 60/455,906, entitled. "System for Allocating Resources<br>
in a Communication System," filed March 17, 2003, assigned to the assignee<br>
hereof and hereby expressly incorporated by reference herein.<br>
BACKGROUND<br>
1.       Field of the Invention: [1002]     The   present   application   relates   to   communication   systems. Particularly, these embodiments are directed to allocating communication resources among the plurality of subscribers to a communication system.<br>
2. Related Ari:: [1003] Several solutions have been presented to address the problem of allocating limited communication resources provided by a single node in a communication system among a plurality of subscribers. It is an objective of such systems to provide sufficient resources at the nodes to satisfy the requirements of all subscribers while minimizing costs. Accordingly, such systems are typically designed with the objective of efficient allocation of resources among the various subscribers.<br>
[1004] Various systems have implemented a Frequency Division Multiple Access (FDMA) scheme, which allocates resources to each of the subscribers concurrently. A communication node in such systems typically has a limited bandwidth for either transmitting information to or receiving information from each subscriber in the network at any point in time. This scheme typically involves allocating distinct portions of the total bandwidth to the individual subscribers. While such a scheme may be effective for systems in which subscribers require uninterrupted communication with the communication node,<br><br>
better utilization of the total bandwidth may be achieved when such constant, uninterrupted communication is not required.<br>
[1005] Other schemes for allocating communication resources of a single communication node among a plurality of subscribers include Time Division Multiple Access (TDMA) schemes. These TDMA schemes are particularly effective in allocating the limited bandwidth resources of a single communication node among a plurality of subscribers, wherein users do not require constant, uninterrupted communication with the single communication node. TDMA schemes typically dedicate the entire bandwidth of the single communication node to each of the subscribers at designated time intervals. In a wireless communication system which employs a Code Division-Multiple Access (CDMA) scheme, this may be accomplished by assigning to each of the subscriber units all code channels at the designated time intervals on a time multiplexed basis. The communication node implements the unique carrier frequency or channel code associated with the subscriber to enable exclusive communication with the subscriber. TDMA schemes may also be Implemented in land line systems using physical contact relay switching or packet switching. [1006] TDMA systems typically allocate equal time intervals to each subscriber in a round robin fashion. This may result in under utilization of ceri:ain time intervals by certain subscribers. Similariy, other subscribers may have communication resource requirements, which exceed the allocated time interval, leaving these subscribers under served. The system operator may choose to either Incur the cost of increasing the bandwidth of the node to ensure that no subscribers are under-served, or allow under-served subscribers to continue to be under-served.<br>
[1007] Accordingly, there is a need to provide a system and method of allocating communication resources among subscribers to a communication network efficiently and fairiy according to a network policy of allocating the communication resources among the subscribers. Consistent therewith, there is a need to maximize the number of users served by the system, including, but not limited to, providing mechanisms for performing resource allocation on a per flow basis and/or on an aggregate basis in response to the specific requirements, constraints, and/or goals of the system.  Still further there is a<br><br>
need for admission control and preemption methods which optimize resource allocation.<br>
BRIEF DESCRIPTION OF THE FIGURES<br>
[1008]     FIG. 1 shows a communication network according to an embodiment<br>
of the present invention.<br>
[1009]     FIG. 2A shows a block diagram of a base station controller and base<br>
station apparatus configured in accordance with an embodiment of the present<br>
invention.<br>
[1010]     FIG. 2B shows a block diagram of a remote station apparatus<br>
configured in accordance with an embodiment of the present Invention.<br>
[1011]     FIG. 3 shows a flow diagram illustrating the execution of a scheduling<br>
algorithm in an embodiment of the channel scheduler shown in FIG. 2A.<br>
[1012]     FIG.   4   is   a   communication   system   supporting   multimedia<br>
applications, wherein each application communication is represented by an<br>
application flow.<br>
[1013]     FIG. 5 is an application flow queue.<br>
[1014]     FIG. 6 is a timing diagram illustrating signal timing of part of an<br>
application flow.<br>
[1015]     FIG. 7A is a timing diagram illustrating jitter measurements for an<br>
application flow.<br>
[1016]     FIG. 7B is a timing diagram illustrating transmission of successive IP<br>
packets during time slots for processing an application flow.<br>
[1017]     FIG. 8 is a flow diagram illustrating scheduling of application flows in<br>
a communication system.<br>
[1018]     FIG. 9 is a flow diagram illustrating scheduling of application flows<br>
having different Quality of Service (QoS) requirements.<br>
[1019]     FIG. 10 is an architectural diagram illustrating the definition of each<br>
application flow consistent with a scheduling algorithm according to one<br>
embodiment.<br>
[1020]     FIG.   11   is  a table  identifying  class types  according  to  one<br>
embodiment.<br><br>
[1021]     FIG. 12A illustrates a portion of a scheduling algorithm according to<br>
one embodiment, including Initialization of an application flow.<br>
[1022]     FIG. 12B illustrates a portion of a scheduling algorithm according to<br>
one embodiment, including processing of an application flow as a function of<br>
class type.<br>
[1023]     FIG. 12C illustrates a portion of a scheduling algorithm according to<br>
one embodiment, including processing of a Mode II application flow and<br>
processing of a Mode III application flow.<br>
[1024]     FIG. 12D illustrates a portion of a scheduling algorithm according to<br>
one embodiment, including processing of a Mode I application flow.<br>
[1025]     FIG. 12E illustrates a portion of a scheduling algorithm according to<br>
one embodiment, including adaptive weighting and scheduling based thereon.<br>
[1026]     FIG. 13 illustrates a Base Station Transceiver System (BTS) for<br>
implementing an algorithm for scheduling application flows using an adaptive<br>
weighted algorithm in a wireless communication system.<br>
[1027]     FIG.   14  is a timing diagram  plotting  maximum  resources for<br>
allocation, such as data rate (LMAX),  reserved resources (Res(t)),  and<br>
available resources (Avail(t)) as a function of time.<br>
[1028]     FIG. 15 is a timing diagram plotting the data request received from<br>
users in a High Rate Packet Data type system, and estimate capacity, L(t), as a<br>
function of time, to reserve at time t.<br>
[1029]     FIG. 16 is an information flow diagram illustrating a scheduler for a<br>
High Rate Packet Data type system supporting multiple application flows<br>
having Quality of Service (QoS) requirements, wherein the flows are scheduled<br>
by application of a per flow compensation.<br>
[1030]     FIG. 17 is an infomiation flow diagram illustrating a scheduler for a<br>
High Rate Packet Data type system supporting multiple application flows<br>
having Quality of Service (QoS) requirements, wherein the flows are scheduled<br>
by application of an aggregate compensation.<br>
[1031]     FIGs. 18Athrough 1 BE illustrate an algorithm for admission control in<br>
a High Rate Packet Data type system supporting multiple application flows<br>
having Quality of Service (QoS) requirements<br><br>
[10321 FIG- 19 illustrates an algorithm for preemption in a High Rate Packet Data type system supporting multiple application flows having Quality of Service (QoS) requirements.<br>
[1033] FIG. 20 is a block diagram of an Access Network (AN) element in a High Rate Packet Data type system supporting multiple application flows having Quality of Service (QoS) requirements.<br>
DETAILED DESCRIPTION<br>
[1034] Embodiments of the present invention are directed to a system and apparatus for allocating resources among a plurality of subscribers to a communication network, which are serviced by a single communication node. At individual discrete transmission intervals, or "service intervals," individual subscribers seize a finite resource of the communication node to the exclusion of all other subscribers. The individual subscribers are selected to seize the finite resource based upon a weight or score associated with the individual subscribers. Changes in a weight associated with an individual subscriber are preferably based upon an instantaneous rate at which the individual subscriber is capable of consuming the finite resource.<br>
[1035] Referring to the figures, FIG. 1 represents an exemplary variable rate communication system. One such system is described in the U.S. Patent Application Serial No. 08/963,386, entitled Method and Apparatus for High Rate Packet Data Transmission, filed on November 3, 1997, assigned to Qualcomm, inc. and incorporated herein by reference. The variable rate communication system comprises multiple cells 2A-2G. Each cell 2 is serviced by a corresponding base station 4. Various remote stations 6 are dispersed throughout the communication system. In the exemplary embodiment, each of remote stations 6 communicates with at most one base station 4 on a forward link at any data transmission interval. For example, base station 4A transmits data exclusively to remote station 6A, base station 4B transmits data exclusively to remote station 6B, and base station 4C transmits data exclusively to remote station 6C on the forward link at time slot n. As shown by FIG. 1, each base station 4 preferably transmits data to one remote station 6 at any<br><br>
given moment. In other embodiments, the base station 4 may communicate with more than one remote station 6 at a particular data transmission interval to the exclusion of all other remote stations 6 associated with the base station 4. In addition, the data rate is variable and In one embodiment is dependent on the carrier-to-interference ratio (C/l) as measured by the receiving remote station 6 and the required energy-per-bit-to-noise ratio (Eb/No). The reverse link from remote stations 6 to base stations 4 is not shown in FIG. 1 for simplicity. According to an embodiment, the remote stations 6 are mobile units with wireless transceivers operated by wireless data service subscribers. [1036] A block diagram illustrating the basic subsystems of an exemplary variable rate communication system Is shown in FIGs. 2A-2B. Base station controller 10 interfaces with packet network interface 24, Public Switched Telephone Network (PSTN) 30, and all base stations 4 in the communication system (only one base station 4 is shown in FIG. 2 for simplicity). Base station controller 10 coordinates the communication between remote stations 6 in the communication system and other users connected to packet network interface 24 and PSTN 30. PSTN 30 interfaces with users through a standard telephone network (not shown in FIG. 2).<br>
[1037] Base station controller 10 contains many selector elements 14, although only one is shown in FIG. 2A for simplicity. Each selector element 14 is assigned to control communication between one or more base stations 4 and one remote station 6. If selector element 14 has not been assigned to remote station 6, call control processor 16 is informed of the need to page remote station 6. Call control processor 16 then directs base station 4 to page remote station 6.<br>
[1038] Data source 20 contains a quantity of data, which is to be transmitted to the remote station 6. Data source 20 provides the data to packet network interface 24. Packet network interface 24 receives the data and routes the data to the selector element 14. Selector element 14 transmits the data to each base station 4 in communication with remote station 6. In the exemplary embodiment, each base station 4 maintains a data queue 40 which stores the data to be transmitted to the remote station 6.<br><br>
[1039] The data is transmitted in data packets from data queue 40 to channel element 42. in the exemplary embodiment, on the forward link, a "data packet" refers to a quantity of data, which is the maximum of 1024 bfts and a quantity of data to be transmitted to a destination remote station 6 within a "time slot" (such as = 1.667 msec). For each data packet, channel element 42 inserts the necessary control fields. In the exemplary embodiment, channel element 42 CRC encodes the data packet and control fields and inserts a set of code tail bits. The data packet, control fields, CRC parity bits, and code tail bits comprise a formatted packet. In the exemplary embodiment, channel element 42 then encodes the formatted packet and interieaves (or reorders) the symbols within the encoded packet. In the exemplary embodiment, the interieaved packet is covered with a Walsh code, and spread with the short PNl and PNQ codes. The spread data is provided to RF unit 44 which quadrature modulates, filters, and amplifies the signal. The forward link signal is transmitted over the air through antenna 46 on forward link 50. [1040] At remote station 6, the forward link signal is received by antenna 60 and routed to a receiver within front end 62. The receiver filters, amplifies, quadrature demodulates, and quantizes the signal. The digitized signal is provided to demodulator (DEMOD) 64 where it is despread with the short PNl and PNQ codes and decovered with the Walsh cover. The demodulated data is provided to decoder 66 which perfomns the inverse of the signal processing functions done at base station 4, specifically the de-interieaving, decoding, and CRC check functions. The decoded data is provided to data sink 68. [1041] The hardware, as pointed out above, supports variable rate transmissions of data, messaging, voice, video, and other communications over the forward link. The rate of data transmitted from the data queue 40 varies to accommodate changes in signal strength and the noise environment at the remote station 6. Each of the remote stations 6 preferably transmits a Data Rate Control (DRC) signal to an associated base station 4 at each time slot. DRC refers to a control mechanism whereby a remote station determines a desired data rate for the forward link, i.e., data rate to receive data at the remote station. The remote station sends the desired data rate as a data rate request or instruction to the base station via a DRC message. The DRC signal<br><br>
provides information to the base station 4, which includes the identity ot the remote station 6 and the rate at which the remote station 6 is to receive data from its associated data queue. Accordingly, circuitry at the remote station 6 measures the signal strength and estimates the noise environment at the remote station 6 to determine the rate information is to be transmitted in the DRC signal.<br>
[1042] The DRC signal transmitted by each remote station 6 travels through reverse link channel 52 and is received at base station 4 through antenna 46 and RF unit 44. In the exemplary embodiment, the DRC information is demodulated in channel element 42 and provided to a channel scheduler 12A located in the base station controller 10 or to a channel scheduler 12B located in the base station 4. In a first exemplary embodiment, the channel scheduler 12B is located in the base station 4. In an alternate embodiment, the channel scheduler 12A is located in the base station controller 10, and connects to all selector elements 14 within the base station controller 10. [1043] In one embodiment, channel scheduler 12B receives information from data queue 40 indicating the amount of data queued up for each remote station, also called queue size. Channel scheduler 128 then performs scheduling based on DRC information and queue size for each remote station sen/iced by base station 4. If queue size is required for a scheduling algorithm used in the alternate embodiment, channel scheduler 12A may receive queue size information from selector element 14.<br>
[1044] Embodiments of the present invention are applicable to other hardware architectures, which may support variable rate transmissions. The present invention may be readily extended to cover variable rate transmissions on the reverse link. For example, instead of determining the rate of receiving data at the base station 4 based upon a DRC signal from remote stations 6, the base station 4 measures the strength of the signal received from the remote stations 6 and estimates the noise environment to determine a rate of receiving data from the remote station 6. The base station 4 then transmits to each associated remote station 6 the rate at which data is to be transmitted in the reverse link from the remote station 6. The base station 4 may then schedule<br><br>
transmissions on the reverse link based upon the different data rates on the reverse link in a manner similar to that described herein for the forward link. [1045] Also, a base station 4 of the embodiment discussed above transmits to a selected one, or selected ones, of the remote stations 6 to the exclusion of the remaining remote stations associated with the base station 4 using CDMA scheme. At any particular time, the base station 4 transmits to the selected one, or selected ones, of the remote station 6 by using a code, which is assigned to the receiving base station(s) 4. However, the present invention is also applicable to other systems employing different TDMA methods for providing data to select base station(s) 4, to the exclusion of the other base stations 4, for allocating transmission resources optimally. [1046] The channel scheduler 12 schedules the variable rate transmissions on the forward link. The channel scheduler 12 receives the queue size, which is indicative of the amount of data to transmit to remote station 6, and messages from remote stations 6. The channel scheduler 12 preferably schedules data transmissions to achieve the system goal of maximum data throughput while confonning to a fairness constraint.<br>
[1047] As shown in FIG. 1, remote stations 6 are dispersed throughout the communication system and may be in communication with zero or one base station 4 on the forward link. In the exemplary embodiment, channel scheduler 12 coordinates the forward link data transmissions over the entire communication system. A scheduling method and apparatus for high speed data transmission are described in detail in U.S. Patent No. 6,335,922, issued January 1, 2002, assigned to the assignee of the present invention and incorporated by reference herein.<br>
[1048] According to an embodiment, the channel scheduler 12 is implemented in a computer system, which includes a processor, Random Access Memory (RAM) and a program memory for storing instructions to be executed by the processor (not shown). The processor, RAM and program memory may be dedicated to the functions of the channel scheduler 12. In other embodiments, the processor, RAM and program memory may be part of a shared computing resource for performing additional functions at the base station controller 10.<br><br>
[1049] FIG. 3 shows an embodiment of a scheduling algorithm, which controls the channel scheduler 12 to schedule transmissions from the base station 4 to the remote stations 6. As discussed above, a data queue 40 is associated with each remote station 6. The channel scheduler 12 associates each of the data queues 40 with a "weight" which is evaluated at a step 110 for selecting the particular remote station 6 associated with the base station 4 to receive data in a subsequent service interval. The channel scheduler 12 selects individual remote stations 6 to receive a data transmission in discrete service intervals. At step 102, the channel scheduler initializes the weight for each queue associated with the base station 4.<br>
[1050] A channel scheduler 12 cycles through steps 104 through 112 at transmission intervals or service intervals. At step 104, the channel scheduler 12 determines whether there are any additional queues to be added due to the association of an additional remote station 6 with the base station 4 detected in the previous service interval. The channel scheduler 12 also initializes the weights associated with the new queues at step 104. As discussed above, the base station 4 receives the DRC signal from each remote station 6 associated therewith at regular intervals, such as time slots.<br>
[1051] This DRC signal also provides the information which the channel scheduler uses at step 106 to determine the instantaneous rate for consuming information (or receiving transmitted data) for each of the remote stations associated with each queue. According to an embodiment, a DRC signal transmitted from any remote station 6 indicates that the remote station 6 is capable of receiving data at any one of multiple effective data rates. [1052] The channel scheduler 12 at step 108 determines the length of a service interval during which data is to be transmitted to any pari:icular remote station 6 based upon the remote station's 6 associated instantaneous rate for receiving data (as indicated in the most recently received DRC signal). According to an embodiment, the instantaneous rate of receiving data Ri detennlnes the service interval length L1 associated with a particular data queue at step 106.<br>
[1053] The channel scheduler 12 at step 110 selects the particular data queue for transmission.  The associated quantity of data to be transmitted is<br><br>
then retrieved from a data queue 40 and then provided to the channel element 42 for transmission to the remote station 6 associated with the data queue 40. As discussed below, the channel scheduler 12 at step 110 selects the queue for providing the data, which is transmitted in a following service interval using information including each weight associated with each queue. The weight associated with the transmitted queue is then updated at step 112. [1054] One skilled in the art will appreciate that channel scheduler 12 may be implemented using a variety of approaches without departing from the present invention. For example, channel scheduler 12 may be implemented using a computer system including a processor, random access memory (RAM) and a program memory for storing instructions to be executed by the processor (not shown). In other embodiments, the functions of channel scheduler 12 may be incorporated into a shared computing resource also used to perform additional functions at the base station 4 or the base station controller 10, In addition, the processor used to perform channel scheduler functions may be a general-purpose microprocessor, digital signal processor (DSP), programmable logic device, application specific integrated circuit (ASIC), or other device capable of performng the algorithms described herein, without departing from the present invention.<br>
[1055] As shown in the embodiment of FIG. 1, the remote stations 6 are mobile and capable of changing associations among the different base stations 4. For example, a remote station 6F is initially receiving data transmissions from the base station 4F. The remote station 6f may then move out of the cell of the base station 4F and into the cell of the base station 4G. The remote station 6F may then start transmitting a DRC signal to alert the base station 4G instead of the base station 4F. By not receiving a DRC signal from the remote station 6F, logic at the base station 4F deduces that the remote station 6f has disengaged and is no longer to receive data transmissions. The data queue associated with the remote station 6F may then be transmitted to the base station 4G via a land line or RF communication link.<br><br>
Adaptive weighted schedulinh Algorithm<br>
[1056] Still further, a problem exists when multimedia services, or other services having a variety of transmission requirements, are transmitted in a wireless communication system, wherein the multimedia service transmissions, referred to as "flows" (which are described further hereinbelow), create bursty traffic. Bursty traffic is characterized by several variables, including a measure of burstiness, and an average data rate. Additionally, there is a need to satisfy Quality of Service (QoS) requirements for each of the various flows in the system. The current scheduling methods, such as the Proportional Fair (PF) algorithm, generally select a flow to serve based upon a metric given as a ratio of a requested data rate, referred to as Data Rate Control data request or "DRC," to throughput, identified as "T." Such calculations may not guarantee the required QoS of all users. Therefore, pure PF algorithms may not provide sufficient complexity to satisfy the QoS requirements of users accessing multimedia or other applications. There is a need for a scheduler able to satisfy these various requirements.<br>
[1057] Note that the following discussion considers a cdma2000 system supporting High Rate Packet Data (HRPD) services as described in IS-856. This system is used as an example. The present invention is applicable to other systems wherein users are selected for service according to a scheduling algorithm<br>
[1058] In an HRPD system, the air interface may support up to four parallel application streams. The first stream carries signaling information, and the other three may be used to cany applications with different Quality of Service (QoS) requirements or other applications.<br>
[1059] The following glossary is provided for clarity in understanding one embodiment presented hereinbelow. The following glossary is not intended to be exhaustive. The following glossary is not intended to limit the present invention thereto, but rather is provided for clarity and understanding with respect to one embodiment of a communication system supporting an adaptive weighted scheduling algorithm.<br><br>
GLOSSARY<br>
[1060]Access Network (AN) - the network equipment providing data connectivity between a cellular network and a packet switched data network (typically the Internet) and the ATs. An AN in an HRPD system is equivalent to a base station in a cellular communication system.<br>
[1061]Access Terminal (AT) - a device providing data connectivity to a user. An AT In an HRPD system corresponds to a mobile station in a cellular communication system. An AT may be connected to a computing device such as a laptop personal computer or It may be a self-contained data device such as a Personal Digital Assistant (PDA).<br>
[1062]Application flow - the designated transmission path from source to AT for a given application stream. Each application flow is identified by a source, destination, traffic profile and quality of service<br>
[1063]Application stream - a data communication corresponding to an application. Most applications streams have designated quality of service requirements.<br>
[1064] Automatic repeat request (ARQ) - a mechanism whereby the transmitter initiates a retransmission of data based on occurrence or nonoccurrence of an event.<br>
[1065]Avail(t): the unreserved bandwidth at time t on the Forward Link.<br>
[1066] Average data rate (r) - average input data rate over time for a given application flow.<br>
[1067]Average delay (AvgD)- average of the delay incurred over multiple packets or bits from an AN to an AT.<br>
[1068]Burstiness (a) - measure of the burstiness or density and relation in time of packets in an application flow.<br>
[1069] Data Rate Control (DRC) - a mechanism whereby an AT transmits a requested data rate to the AN.<br><br>
[1070] Deficit Packets (defpkts) - defined for flow k at the beginning of slot n. The deficit packet is a packet not yet transmitted In the flow, and defpkts is specifically defined as the number of equal-size packets, for example mid-processing packets such as Medium Access Control (MAC) packets, that have stayed in the BTS longer than the delay threshold for flow k.<br>
[1071] Deficit Bits (defbits) - number of bits corresponding to the deficit packets.<br>
[1072] Delay bound - specified time allowed for transmission of a packet of data from AN to AT.<br>
[1073]Delay threshold - function of delay bound or jitter bound and used to compute defpkts.<br>
[1074] Delay  compensation  factor  (๏ผ)  -  compensation   factor  used  to<br>
compensate for delay violations. [1075JDRC compensation factor (ฮฒ) - compensation factor accounting for data<br>
request requirements associated with a user of an application<br>
flow. Used to do graceful recovery of applications. [1076] Enhanced Jitter Threshold (dv) - used for computation of enhanced jitter<br>
compensation function on detection of jitter violation between two<br>
consecutive IP packets of a flow. [1077] Flow weight (w) - initial weight value applied to each application flow<br>
using an adaptive weighted scheduling algorithm. Adaptive weight<br>
(aw) is the adaptive value of the weight [1078]Forward Link (FL) - transmission air link from AN to AT. [1079] Head Of Line (HOL) packet - first packet in a queue. [1080] High Rate Packet Data (HRPD) - a data service transmitting packet data<br>
communications at a high data rate.   Also referred to as High<br>
Data Rate (HDR), and specified in the IS-856 standard entitled<br>
"cdma2000 High Rate Packet Data Air Interface Specification." [1081]Jitter " time variation between received successive packets. [1082] Jitter bound (j) - bound on the jitter for a given application flow. [1083] Jitter compensation factor, Enhanced (5) - compensation factor to<br>
compensate for jitter violations for a flow.<br><br>
[1084]Lmax- Maximum rate at which a BTS may transmit data on the Forward<br>
Link (e.g., 2.4Mbps in a cdma2000 1xEV-DO type network). [1085]L(t) - an estimate of the Fonvard Link capacity to reserve at time t based<br>
upon previous QoS violation statistics and network load related<br>
statistics [1086] Normalized Deficit Packets (ndefpkts) - normalized deficit packets<br>
computed using deficit packets and required rate of that flow. [1087] Normalized Deficit Bits (ndefbits) - normalized deficit bits corresponding<br>
to normalized deficit packets. [1088] Motion Pictures Experts Group (MPEG) - protocol for transmission of<br>
multimedia materials.<br>
[1089]Pending packets -pendk,j[n]- number of pending bytes of IP packet j<br>
of flow k in the BTS and BSC in the slot n. [1090] Proportional Fair (PF) algorithm - a scheduling algorithm wherein data<br>
communications are scheduled according to a selection factor<br>
calculated for each AT as a ratio of a requested data rate to<br>
throughput. [1091]Quallty of Service (QoS) - requirements relating to transmission of a<br>
packet data communication, including but not limited to, delay,<br>
required rate, and jitter.<br>
[1092]QoS and network compensation functions {0,y,a,^,b) - compensation<br>
functions as used in the adaptive weighted scheduling algorithm. [1093] Quality of Service Group (QSG) - group of application types that have<br>
similar QoS requirements. [1094] Rate compensation factor (a) - compensation factor calculated to<br>
compensate for rate violations. [1095] Rate of Service (R) or required rate (required_rate) - rate requested by a<br>
flow. [1096]Res(t): Reserved bandwidth at time t on the Forward Link. [1097] Retransmission queue (RK) - Retransmission queue storing application<br>
flows scheduled for retransmission. [1098] Reverse Link (RL) - transmission air link from AT to AN.<br><br>
[1099] Selection metric (Y) - metric used for comparison of application flows for<br>
scheduling determinations. [1100]Traffic Profile (ฯ, r) - measures relating to burstiness and data rate. [1101]Transmission queue (Tx) - Transmission queue storing application flows<br>
for a given BTS. [1102]Waiting time parameter (ฮณ) - measure of waiting time for the HOL of an<br>
IP packet within the AN.<br>
Applying Adaptive Weights to the Proportion Fair Scheduling Algorithm [1103] A Proportional Fair (PF) scheduling algorithm, which selects a flow to serve based upon the metric DRC/T, is described for the Forward Link of a cdma2000 IxEV-DO network. The PF algorithm is designed to provide each user with approximately the same number of transmission slots. To enhance, such a scheduling algorithm, described herein is an adaptive weighted DRC/T algorithm, which extends and optimizes the DRC/T algorithm to satisfy the various QoS requirements for different types of applications. Each multimedia application has a respective, specified QoS requirement. The goals of a scheduling algorithm include satisfying the various QoS requirements. The adaptive algorithm, also referred to as adaptive w*DRC/T algorithm, presented herein provides a variety of performance benefits over the DRC/T algorithm for forward link of a cdma2000 IxEV-DO network wherein application flows include multimedia application services. Delay and jitter bound requirements of delay and jitter sensitive applications on forward link of a cdma2000 IxEV-DO network are satisfied using an adaptive algorithm. Further, an adaptive scheduling algorithm ensures that rate requirements are met and the average delay is reduced for multimedia applications. While multimedia applications are provided as an example to illustrate implementation of an adaptive scheduling algorithm, the methods and apparatus described herein may be applied to other applications having QoS requirements or other quantifiable requirements associated therewith.<br>
[1104] For applications having rate and latency requirements, such as web browsing and gaming, an adaptive scheduling algorithm provides rate guarantees and reduces average delay. For other applications having only rate<br><br>
requirements, an adaptive weighted scheduling algorithm may be used to satisfy the rate guarantees. While providing these QoS guarantees, an adaptive weighted scheduling algorithm also works to maintain the total throughput at a reasonably high level, and achieving a total throughput close to that achieved when a pure PF scheduling algorithm is used. A pure PF scheduling algorithm refers to an algorithm employing the DRC/T calculation. While giving extra resources to flows with QoS violations, an adaptive weighted scheduling algorithm distributes available resources in a fair manner. Various compensation mechanisms consistent therewith are provided herein. [1105] FIG. 4 illustrates a system 800, which supports multimedia applications. Note again that the present invention is applicable to other systems wherein flows have QoS requirements. System 800 includes multimedia source 802 coupled to a Packet Data Service Node (PDSN) 806. The PDSN 806 is also coupled to the Base Station Controller (BSC) 804, which may include multiple BSCs. The BSC 804 communicates with the various ATs 812, 814, 816, 818, etc., via Base Station Transceiver Systems (BTSs) 808, 810. The system 800 may include more BTSs and ATs than those illustrated. Three flows are illustrated: a first flow from multimedia source 802 via PDSN 806, BSC 804, and BTS 808, to AT 812; a second flow from multimedia source 802 via PDSN 806, BSC 804, and BTS 810, to AT 816; and a third flow from multimedia source 802 via PDSN 806, BSC 804, and BTS 810 to AT 818. Note that one AT may be the destination of multiple flows. In one example, transmission of a Moving Picture Experi:s Group (MPEG) type application separates the audio and video into separate flows.<br>
[1106] Each application flow to be transmitted in system 800 has: an associated source address; destination address; and QoS requirements. The application flow is then scheduled for transmission from the source to the destination. The application flow traverses a path, similar to those illustrated in FIG. 4.<br>
[1107] Each BTS 808, 810 is adapted to maintain a queue of flows as illustrated in FIG. 5. Note, each BTS maintains one set of queues corresponding to each application flow on its Forward Link (FL). One application flow is directed to one AT.   Note, however, multiple flows may be<br><br>
directed to an AT. Each flow has a Quality of Service Group (QSG) type associated therewith. Each QSG is defined by a set of QoS parameters. Each flow of a given QSG has specific values for each of the parameters in the set. For example, one QSG may be defined by the set including delay and jitter. Those flows of such a QSG will specify requirements for delay and jitter. For each of the flows In a queue, the BTS maintains a set including three separate queues: (1) original transmission queue (Tx); (2) retransmission queue (Rx); and (3) automatic repeat request queue (ARQ). In one embodiment, the ARQ queue may correspond to a queue storing flows for any type repeat mechanism performed between the BTS and the MS, such as an early decision ARQ. The multimedia applications may Include a delay sensitive application, such as video conferencing, having delay bound requirements. The delay bound is a specified time allowed from transmission from an AN to receipt by an AT. An adaptive weighting algorithm works to meet the delay bound requirements and to reduce the average delay experienced by IP packets of such applications. For applications having both rate and average delay requirements, an adaptive weighted scheduling algorithm worlds to meet the rate requirements and to reduce the average delay.<br>
[1108] Another consideration for some types of applications, such as multimedia video applications, is the "jitter" experienced between successive packets in a multimedia transmission. Jitter refers to the variation in time between received packets. Jitter occurs when successive waveforms arrive at the receiver slightly early or late. In wireless communications, such waveforms typically convey a logical one or zero, which is then decoded at the receiver. The timing variations defined as jitter distort the visual impact of the received transmission. An adaptive weighted scheduling algorithm reduces the worst-case delay variation as well as the delay variation between consecutive packets for delay sensitive applications.<br>
[1109] While satisfying the QoS requirements of the various users, an adaptive algorithm is also designed to meet the rate requirements of application flows when those flows are "conforming." An application flow is said to be conforming if it sends data per the pre-specified traffic profile, if flows with rate requirements are non-conforming, i.e., they send more data than pre-specified<br><br>
in their traffic profiles, the algorithm gives higher preference to flows with lower data rates. While the adaptive weighted algorithm is described in the context of a cdma2000 1xEV-D0 network herein, the concepts and methods may be applied to other types of wireless networks as well.<br>
[1110] With respect to the multimedia application flows, each flow is defined by: (1) traffic profile; (2) QoS profile; (3) Internet Protocol (IP) source address; and (4) IP destination address. A flow may also include: (5) L4 protocol type; (6) L4 Port Number; and (7) L4 Destination Port Number, wherein L4 refers to the Transfer Control Protocol (TCP)/Unreliable Datagram Protocol (UDP) layer in a protocol stack. For example, MPEG-audio and MPEG-video flows corresponding to an MPEG application may be treated as separate flows.<br>
[1111] Each flow is specified by a traffic profile and Is monitored or shaped to ensure that it conforms to that traffic profile. The traffic profile is defined by a variable representing a measure of burstiness, identified as a, and the average data rate of the flow, identified as r. Each flow is, therefore, described by a traffic profile (a, r.) The QoS profile is defined by at least one of the following parameters: (1) delay bound, identified as "D," which defines the time allowed from transmission to receipt for an IP packet. For multimedia application flows, a system may specify the delay bound. For some other application flows, such as web browsing, the system may specify average delay (AvgD) in place of or in addition to delay bound; (2) jitter bound, identified as "j," which defines the maximum allowable variation in time between received packets at the AT; (3) and a rate of service (or required rate), identified as "R" or "recLrate". [1112] To define the delay bound D, refer to FIG, 6, which is a timing diagram including various AN elements and an AT. A multimedia flow is transmitted from the multimedia source (not shown) via the PDSN, BSC, and BTS to the AT. An IP packet is transmitted from the PDSN at time to, and is received at the AT at time t3. The parameter D defines the maximum allowable time from time to to time t3, i.e., D specifies the limlt(s) of t3-t0. [1113] To define the jitter bound, j, refer to FIG. 7A, which is a timing diagram including the AN elements and an AT. A first packet is transmitted at time t1 from the PDSN and is received at time t1' at the AT. A second packet Is<br><br>
transmitted at time t2 from the PDSN and is received at time t2' at the AT. The jitter bound, j, defines the maximum allowable variation between successive packets, wherein the variation is given as (t2'-ti') -(t2-ti). FIG. 7B further details successive IP packets transmitted over several slots.<br>
[1114] In one embodiment, QoS profiles are categorized into groups, referred to as QoS Scheduling Groups (QSGs). Table 1 lists the categories.<br><br>
[1115] FIG. 8 illustrates the processing of flows according to an adaptive weighted scheduling algorithm. Flows 900, 902, 904, and 906 are processed by a scheduling unit 908 labeled "S." The scheduling unit 908 applies an adaptive weighted scheduling algorithm wherein a QSG profile is used for each of the flows. The QSG profile identifies the variables that are used to calculate the adapted weight as detailed hereinbelow. The scheduling unit 908 then outputs a scheduled transmission to a selected AT.<br><br><br><br>
Adaptive w*DRC/T Algorithm<br>
[1117] In one embodiment, the adaptive weighted scheduling algorithm, referred to as the "adaptive w*DRC/T" algorithm, assigns an initial weight to each flow. Suppose the initial weight assigned to flow k is denoted by Wk and the DRC requested by the AT con-esponding to the flow k for slot n is DRC[k,n]. The adaptive w*DRC/T algorithm computes the following metric for each flow k in every slot n<br><br>
Here, throughput for flow k and slot n, Tk[n] ,is as defined for DRC/T in the PF<br>
algorithm.  As used in the adaptive weighted scheduling algorithm, awk[n] is<br>
the adaptive weight for flow k in slot n. The adaptive w*DRC/T scheduling algorithm works in several modes, wherein the mode is defined by the QSG. The adaptive weight for flow k in slot n, awk.[n], is computed based upon the<br>
scheduler mode and a set of selected policies or mechanisms, described further hereinbelow. Note that Equation (4) is calculated for each flow, wherein the adaptive weights will be calculated according to a formulation specific to each flow. In other words, the scheduling algorithm considers the QoS profile of a given flow, and uses the QoS profile to form the calculations of the adaptive weight for the flow, in this way, different flows having different QoS requirements may have adaptive weights that are calculated differently.  The<br>
scheduling algorithm next selects a flow with the maximum value of Yk[n] to<br>
serve in slot n.<br>
[1118]     The adaptive w*DRC/T scheduler works in the following modes:<br><br>
Mode I   [aw*DRC/T](r, d, j): designed for delay and jitter sensitive<br>
applications having tight requirements on delay and jitter bounds, and<br>
requiring some minimal rate.<br>
Mode II    [aw*DRC/T|(r, d): used for applications with average delay<br>
and rate requirements.<br>
Mode III    [aw*DRC/T](r):    used for applications having only rate<br>
requirements specified.<br>
Mode IV   [DRC/T]:   used for flows not specifying any QoS plan but<br>
served by the DRC/T algorithm. Based upon the QoS requirements, a particular mode of the adaptive w*DRC/T algorithm may be used for a given flow. Mode II may also be used on a flow to increase the throughput given to that flow by the scheduler. For example, Mode II may be used for FTP applications so as to potentially increase throughput for the corresponding application flows. [1119]     One example of grouping applications, i.e., QSG, is given below:<br>
Group I : Voice over IP (VolP)-like applications with tight requirements<br>
on delay bounds and delay variation.  Note that often such applications<br>
also have rate requirement(s). Use scheduler Mode L<br>
Group II: Multimedia conferencing applications with tight requirements<br>
on delay bound, and delay variation.    Even though some of these<br>
applications are adaptive, it is desirable to ensure a rate of service for<br>
consistent good quality.   Use scheduler Mode I.<br>
Group III: Video streaming applications with requirements on delay<br>
bound, rate and delay variation. Use scheduler Mode I.<br>
Group IV: Web browsing applications with rate and (average) delay<br>
requirements - Use scheduler Mode II.<br>
Group V: FTP applications with rate - Use scheduler Mode III.<br>
Alternatively, use scheduler Mode II with relaxed delay constraints.<br>
Group VI: Best effort applications - Use PF algorithm, i.e., DRC/T<br>
algorithm, without adaptive weighting. Note that database transactions, gaming and other applications may also be classified into suitable groups as per respective QoS requirements.<br><br>
[1120] FIG. 9 illustrates an adaptive weighted scheduler having multiple levels, Including but not limited to, level I and level 11. The level I scheduler has multiple schedulers, S1, S2, S3,... Sm, wherein m refers to the total number of Groups. Each level I scheduler in FIG. 9 runs a particular operation mode of the adaptive w*DRC/T scheduling algorithm and selects a flow from that group. First, the Level 1 scheduler calculates part of Y. specifically, the throughput, T, and the rate compensation factor, a. Next, the level 11 scheduler considers flows and provides input to level I scheduler sufficient for complete calculation of the selection metric Y by the level 1 scheduler. Once Y is completely computed for all pending flows, the level I scheduler evaluates the Y values and selects a flow with the highest value of Y. Each level I scheduler evaluates a group of flows having similar QoS requirements. The selected flow of each level 1 scheduler is then provided to the level II scheduler for comparison with flows from other groups. The level II scheduler considers one selected flow per group and selects the one having the highest value of the metric (aw'DRC/T) or Y. The process is repeated for every slot when the scheduler needs to select a flow to serve. Alternate embodiments may use a single level scheduler, or may use more levels than illustrated in FIG. 9. Alternate embodiments may include a different number of level 1 schedulers, wherein the level I schedulers correspond to flow organizations.<br><br><br><br>
wherein the operator is multiplication. The following discussion provides details of the various compensation terms that may be included in the adaptive weight calculation.<br>
[1122] For Mode I applications, the QoS profile specifies all of the parameters indicated in Equation (6). The adaptive weight calculations consider delay compensation due to delay threshold violations, delay compensation due to waiting time threshold violations, rate compensation due to rate violation, and enhanced jitter compensation due to enhanced jitter threshold violation. The concept boosts weights of a flow that is violating the specified QoS requirements. Triggered on violation of QoS requirement(s), such flow is given credit. The credit is implemented by multiplying the weight of the flow by a suitable value for a delay compensation function. This is further mullplied by rate compensation and enhanced jitter compensation. [1123] In contrast, when a flow appears to receive excess service, such flow may be penalized. A flow may be penalized in any of a variety of ways. According to one method, the flow may be directly penalized by reducing the flow weight. According to another method, the flow may be indirectly penalized by maintaining that flow weight while increasing the weights of other users who are lagging (i.e., those flows that have not achieved a required QoS).<br><br>
[1125]     For each flow, a max and a min threshold on ๏ผ is also specified so<br>
as to assure a flow doesn't consume several slots consecutively and starve other flows. This is also designed to ensure that a flow's delay compensation term due to delay threshold violation is at least as good as the min threshold<br><br><br><br><br>
[1130]     FIG. 10 provides an architectural diagram corresponding to one embodiment.   Each application flow is described by a traffic profile, a QoS<br><br>
profile, and a DRC request, i.e., requested data rate. Each traffic profile includes a measure of burstiness and an average data rate. Each QoS profile includes a class type and the parameter bounds. The class type may be one of Mode I, Mode II, Mode III, or Mode IV. The bounds specify bounds for delay, jitter, and the required data rate. Some applications such as web browsing, may specify average delay instead of delay bound. Delay thresholds for mode I are chosen to be less than jitter bound; and for mode II, delay threshold is chosen to be less than the average delay. An enhanced jitter threshold is chosen to be less than the jitter bound. Alternate embodiments may apply more or less information to each application flow, wherein the QoS requirements may be specific to the network and configuration. [1131] FIG. 11 is a table specifying the QoS requirements and QoS parameters for each class type. As indicated, Mode I corresponds to the strictest requirements, while Mode IV corresponds to a Best Effort, wherein no QoS requirements are specified. Alternate embodiments may include other QoS requirements, QoS parameters and/or modes.<br>
[1132] FIGs. 12A through 12E illustrate processing of an application flow and scheduling of that application flow as part of the active application flows. FIG. 12A is a flow diagram illustrating the initialization and set up for an individual application flow. The process starts at step 1100 to select the mechanisms used for each compensation parameter. The compensation parameters include, but are not limited to: delay (๏ผ); pending time (ฮณ); DRC (ฮฒ); jitter (5); and rate (a). At step 1102 the threshold values are selected for applicable compensation parameters. Note that compensation parameters may include any parameter of the application flow of significance to the AN. The algorithm for calculating intermediate weights at step 1102, wherein the intermediate weights are used in calculating the adaptive weights used for scheduling. At step 1106 the scaling parameter (C) and the priority factor (Z), both used in calculating adaptive weights, are set. At step 1108 the initial weight for this application flow is set. At step 1110 the QoS requirements of the application flow are evaluated. If there are no specified QoS requirements, other than the rate identified by the DRC request, the default condition is used. The default condition is referred to as "Best Effort" as described hereinabove.<br><br>
In this case, the default processing sets all of the compensation factors used for this application flow equal to one. For the present embodiment, in this case the calculation of Equation (6) uses a multiplication operator and, therefore, setting factors to one effectively ignores those factors. I.e., those factors do not impact the weighting. Note alternate embodiments may implement other mechanisms and functions, and, therefore, use other mechanisms to ignore specific or all compensation factors.<br>
[1133] The Best Effort processing continues at steps 1112 and 1116. The resultant scheduling factor calculation is consistent with the proportional fair calculation. If the application flow has QoS requirements, processing continues to step 1114. Steps 1114 and 1116 indicate processing continued in subsequent figures.<br>
[1134] FIG. 12B continues the processing of FIG. 12A from step 1114. At step 1120 processing of the current slot starts. At step 1122 a decision is made as the class type of the application flow. I^ode I is processed at step 1128, Mode II is processed at step 1126, and Mode III is processed at step 1124. Mode I QoS parameters are monitored at step 1128; Mode II QoS parameters are monitored at step 1126; and Mode ill QoS parameters are monitored at step 1124. QoS violation checlcs are then made at steps 1130, 1140, and 1150, further detailed in FIGs. 12C and 12D. [1135] Processing of the application flow continues at step 1130 of FIG. 12C for a Mode I, II or 111 application. At step 1132, the algorithm periodically monitors for rate violations. Note that the rate compensation calculation is performed periodically and used for multiple slots thereafter. If a rate violation is detected at step 1134, processing continues to step 1138 to calculate the rate compensation factor (a). Else, the rate compensation factor (a) is set equal to one at step 1136. Processing then continues to step 1160 further detailed in FIG. 12E.<br>
[1136] Processing of the application flow continues at step 1140 of FIG. 12C for a Mode I or II application. At step 1142 the method monitors for delay and jitter violations at every slot. If a delay and/or jitter violation is detected at step 1144, processing continues to step 1148 to calculate the delay compensation factor (๏ผ), according to the mechanism selected at initialization. For a Mode I<br><br>
flow which has requested enhanced jitter compensation, then the enhanced<br>
jitter compensation factor (5) is also computed. For Mode I flows which have not requested enhanced jitter compensation and for mode II flows, 5 is set equal to 1. Else, the delay compensation factor (๏ผ) is set equal to one at step 1146 and 5 is set equal to 1. Processing then continues to step 1160 further detailed in FIG. 12E. Note that for a Mode I or II application flow, violation checks may be done in tandem or in parallel. In other words, rate violation and delay/jitter violation checks may be performed successively in time, or concurrently.<br><br>
The scheduling algorithm then schedules application flows according to the scheduling factors calculated for each of the active application flows. [1139] FIG. 13 illustrates a BTS 1200 adapted for applying a scheduling algorithm according to one embodiment. The BTS 1200 includes a scheduling unit 1202, application flow processing unit 1206, QoS parameter evaluation 1204, adaptive weight calculation unit 1212, and CPU 1208, each coupled to a communication bus 1210.  The scheduling unit 1202 performs the scheduling<br><br>
by preparing scheduling factors for each application flow, and then selecting among the various active application flows according to the scheduling factors. The policy and goals of a given system are incorporated into the scheduling algorithm. QoS parameter evaluation 1204 monitors for QoS violations, and provides information to scheduling unit 1202 and weight calculation unit 1212. Application flow processing performs processing, which includes, but is not limited to, directing packets to the destination AT, receiving from the destination AT QoS information used for scheduling, and providing such information to the QoS parameter evaluation 1204. The BTS 1200 also includes a memory 1214 for storing intermediate information, and maintaining data used for calculating averages, flow queues, etc. Violation checks are done at the BTS. One embodiment keeps counting the number of bytes sent out for each flow and uses that for a rate violation check. Each packet is time stamped when it arrives at the BSC. The time keeps incrementing as long as the packet remains in the AN, BSC or BTS. The BTS uses this time for detection of threshold violations and then computes delay, waiting time or enhanced jitter compensation functions according to the flow.<br>
Admission Control<br>
[1140] Admission control refers to the decision process in allowing entry to a user requesting a data service. When a new user requests a data service, such as an application having QoS requirements, the AN determines if there are available resources to support such usage. The admission process considers the requested application, the current usage, as well as QoS and network statistics. If the AN determines the new user may be supported, then the corresponding application flow is admitted. Else, if there are not currently resources available, the application flow Is denied or placed in a queue to await a change in status. Note that a new user may actually be a user with a currently active application flow that is requesting an additional service, i.e., additional application flow.<br>
[1141] In addition to and as a part of admission control, a process of preemption may be implemented for terminating active application flows,<br><br>
wherein current operating conditions are evaluated to make preemption decisions, in this case, each of the current flows is evaluated for QoS violations, as well as data rate.<br>
[1142] This section presents an adaptive per-sector admission control algorithm. Such admission control algorithm decides whether or not to admit (or preempt) a flow in a given wireless multimedia network. It is therefore possible to determine the number of flows (of each class) which may be allowed in a given network. Embodiments of an admission control algorithm presented herein include mechanisms to perform both inter-user and intra-user QoS monitoring, and then applying this information to admission and/or preemption decisions. Such embodiments are designed to ensure per-flow and per-user QoS requirements are satisfied for the admitted flows and users. Such mechanisms facilitate coordination of an admission control algorithm and a hierarchical scheduling algorithm.<br>
[1143] Scheduling and admission control are part of the Forward Link (FL) QoS management in a wireless networks, wherein such management is a complex problem. QoS management is a significant consideration in design and operation of a communication network. Application flows are classified according to criteria as defined by the system. In one embodiment, the classification is according to QoS requirements. First, admission control determines a number of flows that may be admitted under current operating conditions. The number of flows is then divided into a number of flows per each class. The system then operates to satisfy the QoS requirements for each admitted flow. Note the number of flows may change dynamically over time and with the type of application. For example, at a first time, the Access Network (AN) may support a first scenario wherein each type of application is allowed a specific number of flows. At a second time, the AN may support a second scenario wherein at least one of the types of application is be allowed a different number of flows.<br>
[1144] A scheduler (i.e., scheduling algorithm) implements a fairness strategy among the admitted flows. The scheduler further attempts to perform a graceful recovery of flows having QoS violations. An operator's revenues and profits are dependent on the effectiveness of the scheduling algorithm used.<br><br>
More efficient and feature-rich algorithms provide opportunities to increase these profits.<br>
[1145] With respect to admission control, one embodiment implements a subscription factor based method. Note subscription based methods are often used in admission control algorithms for wireline networks. In a wireless network, the channel conditions of each user keep varying and hence the forward link capacity as seen by the BTS scheduler also keeps varying. The wireline subscription factor based algorithm assumes fixed link capacity and thus is not directly applicable in wireless networks.<br>
[1146] For wireless networks, one embodiment provides an Adaptive Subscription Factor (ASF) based admission control algorithm for FL management, wherein the network supports multiple application flows having QoS requirements. The ASF admission control in a wireless network dynamically updates the subscription factor by monitoring the QoS statistics and network statistics. Various mechanisms may be used to perform the updating functions. It is therefore possible to take corrective action using the adaptive subscription factor. Additionally, the ASF is used to implement a preemption method.<br><br>
[1148] FIG. 14 is a timing diagram plotting the maximum data rate, the reserved bandwidth, and the available bandwidth as a function of time. The maximum rate at which the BTS may transmit data on forward link (Lmax)<br>
provides an upper bound for the allocation of resources. Active application flows are evaluated to determine the reserved bandwidth, Res(t). Using QoS violation and network load related statistics, the calculation of an adaptive subscription factor and an estimate of forward link capacity, L(t), desired to be reserved at time t is performed.   Note it is possible that L(t)
example, suppose admitted flows were experiencing very good channel conditions at the time of their admission.  Now, channel conditions of several<br><br><br><br><br>
Adaptation Method for A(t): Per-Sector QoS and Network Statistics [1152] FIGs. 18A through 18E provide a flow diagram of a method 300 for admission control for a system supporting multiple application flows having QoS requirements. In FIG. 18A, when a request for a new flow is received by the AN at decision diamond 302, admission control procedures are applied at step 304. Else, the process waits for a new flow request. Note that during this time, the AN continues to monitor current operating conditions to develop QoS statistics for currently active flows and network statistics for flows. Admission control procedures determine if resources are available to support the new flow.  Resource measures, such as illustrated in FIG. 14, are updated at step<br><br>
305. If a new flow is admitted at decision diamond 306, processing continues to step 307 for application of an adaptive scheduling process. [1153]     The admission control procedures of step 304 are further detailed in FIG. 18B.   At decision diamond 308 if the required rate for the flow fk is<br>
greater than an average DRC data request for the flow  fk, processing<br>
continues to step 312 to deny entry of the flow /^. Else, processing returns to<br>
decision diamond 310 to determine if the required rate for flow /^ is greater<br>
than the available resources, Avail, at time t. If the required rate is less than Avail then the flow is admitted at step 314, else the flow is denied at step 312. [1154] The updating of resource measures of step 305 are further detailed in FIG. 18C. At step 320 the resource measures, Avail and Res, are updated. QoS statistics are updated and monitored at step 322. The ASF is updated at step 324 based on the results of steps 320 and 322. The estimated resource level, L, is recalculated at step 326. If a new flow is requested at step 328 processing returns for processing at step 304 of FIG. 18A. If a new flow is not requested at step 328, then user presence in the sector is determined at step 330 for each user. At step 332 a sample duration period is determined. [1155] Continuing with FIG. 18D, QSG parameters are selected for each flow. Two parallel processing paths are considered, wherein a first path processes rate violations at step 342 over a rate sample interval. Note the rate sample interval is greater than the sample duration calculated at step 332. A second path details processing of each active flow. For a given flow, the process determines a ratio of IP packets having delay violations during the sample duration at step 344. At step 346, a ratio of IP packets with jitter violations during the sample duration is calculated for the flow under consideration. The fraction of slots used by the flow during the sample duration is then calculated at step 348. At step 350 the process determines a fraction of slots given to flows having QoS requirements during the sample duration. At step 352 the process checks for QoS violations and detennines the QoS group ID at step 354.<br>
[1156]     Processing continues to FIG. 18E wherein step 360 calculates the number of flows for each QoS group. At step 362 the process then calculates<br><br>
the fraction of QoS flows corresponding to each QoS statistic. The results of step 360 and 362 are then compared to predetermined threshold values at step 364. Note the threshold values may be updated dynamically during operation. At step 366 the ASF are adjusted accordingly.<br>
[1157] FIGs. 18A through 18E provide one embodiment of an admission control method. Further details of an admission control method are discussed hereinbelow. The AN element, such as BTS, collects per-sector statistics for each flow and uses this information for per-sector admission control and preemption algorithms. Per-sector statistics are collected only for the duration when the user corresponding to that flow is in that sector. The BTS collects the QoS and network related statistics periodically.  Let T be the time period after<br><br><br><br><br>
This is counted for a sector when two consecutive IP Packets for a flow were transmitted on that sector.<br><br><br><br><br>
[1165]     The process calculates a fraction of slots, during the sample duration, used for flows having QoS requirements, and also calculates a<br><br><br><br>
Let M denote the QoS stat group id (QS_GID) resulting in:<br><br><br>
Adaptation of S(t) is done periodicaily after every time period T, which is pre-specified. For the purpose of adaptation, the above groups may be considered as follows:<br><br><br><br><br>
Preemption Scheme<br>
[1170] FIG. 19 illustrates a preemption method 400 according to one embodiment The method 400 begins by detemiining if the ASF was increased at decision diamond 402. When an ASF increase is detected, processing continues to step 404 to determine the flow having the highest number of rate violations. In other words, when the ASF increases, the preemption method 400 begins to identify those flows to preempt In the present embodiment, flows with rate violations are identified as the best candidates for preemption. Alternate embodiments may prioritize other flows, and may dynamically change the priority scheme.<br>
[1171] If a preemption maximum value, PMAX, (detailed hereinbelow) is reached at decision diamond 406, processing continues to step 408 to preempt the flow having the highest number of delay violations. Else processing returns to decision diamond 402. After preempting a flow at step 408, processing continues to decision diamond 410 to determine if there are multiple flows having the highest number of delay violations. For multiple flows, processing continues to step 412 to preempt the flow using the most slots. Typically, this<br><br><br><br><br>
Number of slots taken by a flow and its corresponding DRC are also taken into account while doing adaptation of ASF as described earlier. The process computes AS(t) and computes Avail(t) as:<br><br><br>
The process continues monitoring QoS statistics for all the admittecl flows and users, and monitoring network related statistics. Use these to continue adapting the subscription factor. The ASF, AS(t), is then computed and applied.<br><br><br><br>
[1177]     The process defines an aggregate delay compensation for user Uj, โข<br>
at an arbitrary slot n. Consider all the flows of this user that have delay requirements and look at the Head Of Line (HOL) i\/lAC packet for each of these delay sensitive flows, if none has been in the system for a period longer than its delay threshold, then:<br><br><br><br>
scheduler, the process selects a flow to serve for that user as per the following scheme.<br><br><br>
[1183] The following steps may be followed in performing the scheduling algorithm described herein.<br>
Step 1: Consider all the backlogged flows of the selected user in that slot. Step 2: Consider flows corresponding to groups 1 and 2 for that user. Select a flow wherein HOL packet has violated its delay threshold and is closest to the delay bound for that flow. If a flow has been found, serve this flow. Otherwise, go to step 3,<br>
Step 3: Consider flows corresponding to group 3 wherein an HOL packet has crossed the delay threshold and select the flow wherein an HOL packet is closest to the delay bound. If a flow is found, serve this flow. Otherwise, go to the next step.<br>
Step 4: Consider flows corresponding to group 4 wherein an HOL pacl^et has crossed the delay threshold and select the flow wherein an HOL packet is closest to the delay bound. If a flow is found, serve this flow. Otherwise, go to the next step.<br>
Step 5: Pick up a backlogged flow to serve from groups 1 to 4. Give preference to the flow having the lowest number group. If a flow has been selected, serve it. Otherwise, go to the next step.<br>
Step 6: Consider the backlogged flow corresponding to group 5 for that user. Select the one with the maximum value of required_rate/served_rate. Serve this flow. If none is selected, go to the next step.<br>
Step 7: Serve a best effort flow for that user. If there are more than one, pick up one with the minimum value of the served rate.<br>
[1184] FIG. 16 illustrates a two level scheduler applying a per-flow and peruser compensation.   The scheduler illustrated in FIG. 16 and FIG. 17 is a<br><br>
hierarchical scheduler used for inter and intra QoS compensation as described herein. As illustrated in FIG. 16, the first level, identified as Level I, includes multiple scheduling elements or nodes, S1, S2, ... SM, wherein each node processes a different QSG. In this example, M. is the number of QSG groups that will be processed. For example, the scheduling node S1 processes Voice over IP (VoIP) type application flows. While VoIP is given as an example, any application flows classified as QSG1 will be processed at S1. Such flows have delay and jitter bounds specified for evaluating QoS requirements. Multiple application VoIP type flows are processed at the scheduling element S1. Similarly, each scheduling element processes flows for a specified QSG. Note that alternate embodiments may provide application flows for multiple QSGs to one scheduling element. Note, multiple scheduling elements may be used for processing a same QSG group.<br>
[1185] The Level I of the scheduler illustrated in FIG. 16 computes a portion of the per-flow compensation. Multiple application flows for each user are illustrated in FIG. 16. The Level II scheduling element completes computation of the per-flow compensation.<br>
[1186] FIG. 17 illustrates a scheduler having scheduling nodes S1, S2, ... Sz. In this step, z is the number of users. Note, the number of users is dynamic and therefore the number of current scheduling nodes may change dynamically. Each scheduling node S1, S2, ... Sz is adapted to receive multiple flows from a given user. Scheduling node S1 receives flows F1 through Fk for user 1 (U1). Here k is the total number of application flows currently processed for user 1. Using the per-flow compensation computed for each flow by level I and level II schedulers in FIG. 16, the level II scheduler in FIG. 17 computes aggregate user compensation for each user. The Level II scheduler then selects a user to serve in a slot as per the adaptive weighted DRC/T algorithm described above for user selection method. The Level 11 scheduler then selects among the weighted values received from the Level I schedulers. As indicated, W(Uk) is the initial weight assigned to user Uk, and ATR(Uk) is the aggregate target rate for user Uk. Once a user is selected, the Level I scheduler corresponding to that user selects a flow to serve for that user in that slot as per the flow selection method described above.<br><br>
[1187] A forward link scheduler may allow each user to specify a willing price for a flow for service at a given DRC value in a slot. Once the price is specified, an adaptive frame structure scheduler works to meet QoS requirements of different types of applications. The corresponding scheduling mechanism allows a service provider to find a good balance between the goals of increasing profits and meeting QoS requirements of applications. Such scheduling mechanisms also provide end-users dynamic cost control, and may be used for applications having rate and/or average delay requirements or for streaming applications, etc. One embodiment provides a pricing option wherein each flow specifies the price for each slot when it is served. This price is dependent upon the DRC value requested by the user for the flow in that slot. The price fiow j (i.e., the user accessing flow j) is willing to pay in slot m is designated as c[j,m,DRC[j,m]. Here DRC[j,m] denotes the rate at which this user may be served in slot m. A user may specify the price statically, such as a prespecified price for each value of DRC. Alternatively, a user may specify the price dynamically, such as to change the price during the lifetime of an application. This allows the user to have some control over the price to respond to a changing channel condition and to achieve a desired QoS. An operator may use such a scheduler along with the scheduler presented for the inter and intra user QoS. This allows an operator to specify at least two types of pricing schemes. For inter and intra user QoS scheduler, the operator may specify a static pricing scheme (based on static service level agreement) and at the same time, allow a dynamic pricing scheme for the adaptive frame structure based scheduler. A user may choose to use different schemes for different flows.<br>
[1188] One embodiment divides time into several frames and makes scheduling decisions for each slot depending upon DRC values, QoS requirements, QoS violation statistics and price specified by each user. A frame structure basically gives the order in which user queues should be served in a round. The network decides in each scheduling round which flow/user to serve in a given slot for that round in order to achieve the desired goals. The frame structure, i.e., the order in which flows are served in each round, keeps varying and referred to as the AFS based algorithm.<br><br>
[1189] The following definitions explain some notations used in the computation process. Given N queues (and one queue for each flow), assume that the QoS requirements for flow; are met if it is served at rate rj]]. An initial weight w[j] and time scale ts[j] are also pre-specified for each flow ;. The process aims to provide rate guarantees to flow j, which may be monitored at every slot that is an integer multiple of the time scale (i.e., at every slot m'*ts[j] where m is an integer).<br>
[1190] Let startU] be the slot when flow j initially started being considered to be served in a round. By the end of slot z, the system desires to serve S[j,z]=r[j]*(Z'Start[j]) bits where z=m*tslj] for some integer m. Using one scheduling mechanism, the system is able to balance the number of (time) slots desired for allocation to a given flow and the number of bits desired to serve that flow.<br><br>
When the deficit in bits is positive, the corresponding flow is lagging in service and is to be compensated. On the other hand excess service received by a flow is not explicitly penalized, but is indirectly penalized, as this flow would not<br><br>
be compensated, while other flows which are lagging in service would be compensated.<br><br>
[1193] Let lslot[n] be the last slot of round n and fslot[n] be the first slot of round n. Suppose aw[j,n] denotes the (adaptive) weight assigned to flow; for round n. This weight decides the number of slots that are allocated to flowy in round n.<br>
[1194] An ordering is given to DRC values requested by users. Specifically, if DRC1[B,S] is better than DRC2[B,S] then {B/S)1 (B/S)2   Here B is the<br>
number of bits per packet and S is the number of slots. [1195] For each scheduling round of the AFS scheduler, the process computes the state variables given above for each round, and then computes weights for each flow at the beginning of each round to allocate a certain number of slots to this flow for that round. For this purpose, the process uses an adaptive weight computation mechanism and computes the frame structure for each round using a per-round service discipline.<br><br><br>
[1200]     Use of these thresholds, along with the adaptive weight computation mechanisms described here, prevents any flow from consuming an unfairly<br><br>
large number of slots in a round, and at the same time does not penalized that<br><br>
The process then computes an adaptive weight for flow/, wherein the adaptive weight for a non-empty queue in round n is as follows:<br><br><br>
and flow j has at least one packet pending at the beginning of slot m in the round n. Next, compute:<br><br><br>
[1205] An AN element according to one embodiment is illustrated in FIG. 20. The AN element 500 receives application flow data and processes the data for transmission to a user. The AN element 500 schedules multiple application flows, wherein each flow has QoS requirements. Note the application flows may include a Best Effort flow, as described hereinabove. The AN element 500 includes a flow classification unit 502 adapted to identify the traffic profile and QoS profile associated with the flow and map the flow to a class, or QSG. The flow classification unit 502 Is coupled to a scheduler 504, an admission control unit 510, and a QoS monitor 506. The scheduler 504 may implement any of a variety of scheduling algorithms, including, but not limited to, a Proportional Fair (PF) algorithm and an adaptive weighted PF algorithm. The admission control unit 510 applies an admission control scheme to the application flows received by the AN 500. The admission control unit 510 evaluates each new flow requested based on QoS and network statistics and determines if sufficient resources are available to support the new flow. An adaptation unit is coupled to the admission control unit, wherein the ASF are updated. The adaptation unit 512 is adapted to perform preemption determination of currently active application flows. Preemption considers the performance of a given flow with respect to data rate, slots used, and other QoS and network statistics. The QoS monitor is adapted to monitor the QoS requirements of a received application flow. Note that the AN element 500 typically receives multiple flows and selects among them for transmission to a user. The scheduler 504 receives information from admission control unit 510<br><br>
regarding whether a new flow is admitted. Scheduler 504 receives QoS statistics and other information from the QoS monitor 506, wherein the scheduler 504 applies the QoS information to select a flow for transmission. [1206] Presented herein are methods and apparatus for admission control, preemption and scheduling of application flows in a wireless communication system. Admission control considers requested data rate of a new flow, and compares this to the available resources. Once admitted, the flow is provided to a scheduler, which is adapted to perform per flow and per user analysis to select a user for transmission in each slot or designated time period. [1207] Those of skill in the art would understand that information and signals may be represented using any of a variety of different technologies and techniques. For example, data, instructions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description may be represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof.<br>
[1208] Those of skill would further appreciate that the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware, computer software, or combinations of both. To cleariy Illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention.<br>
[1209] The various illustrative logical blocks, modules, and circuits described in connection with the embodiments disclosed herein may be implemented or perfomied with a general purpose processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic device, discrete gate or transistor<br><br>
logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor, but in the alternative, the processor may be any conventional processor, controller, microcontroller, or state machine. A processor may also be implemented as a combination of computing devices, e.g., a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration.<br>
[1210] The steps of a method or algorithm described in connection with the embodiments disclosed herein may be embodied directly in hardware, in a software module executed by a processor, or in a combination of the two. A software module may reside in RAM memory, flash memory, ROM memory, EPROM memory, EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such the processor may read information from, and write information to, the storage medium. In the altemative, the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a user terminal. In the alternative, the processor and the storage medium may reside as discrete components in a user terminal. [1211] The previous description of the disclosed embodiments is provided to enable any person skilled in the art to make or use the present invention. Various modifications to these embodiments will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other embodiments without departing from the spirit or scope of the invention. Thus, the present invention is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein. [1212]     What is claimed is:<br><br><br><br><br><br>
CLAIMS<br>
1.	A method for admission control in a communication system supporting<br>
Internet Protocol (IP) applications, the communication system including an<br>
Access Network (AN) and a plurality of Access Terminals (ATs), each of the<br>
ATs sending a requested data rate to the AN, the communication system<br>
supporting application flows having QoS requirements to the ATs, the method<br>
comprising:<br>
determining available resources in the communication system; receiving a request for a first application flow having a first traffic profile<br>
and a first QoS profile; determining if the available resources support the request for the first<br>
application flow; denying the first application flow if the first application flow has a<br>
corresponding data rate greater than an average requested data<br>
rate; and admitting the first application flow if the corresponding data rate is not<br>
greater than the average requested data rate, and if the available<br>
resources support the request for the first application flow.<br>
2.	The method as in claim 1, wherein determining if the available resources<br>
support the first application flow; comprises:<br>
determining reserved resources in the communication system; comparing the reserved resources to the capacity of the communication<br>
system; and determining the available resources as the difference between the<br>
capacity and the reserved resources.<br>
3.	The method as in claim 2, further comprising:<br>
determining an adaptive subscription factor for the first application flow.<br>
4.	The method as in claim 3, further comprising:<br><br>
updating the adaptive subscription factor based on Quality of Service (QoS) statistics for the first application flow.<br>
5.	The method as in claim 4, further comprises:<br>
determining QoS statistics for the first application flow;<br>
comparing the QoS statistics for the first application flow to other current<br>
flows in the sector; and updating the available resources and reserved resources in response to<br>
comparing the QoS statistics for the first application flow to other<br>
current flows in the sector.<br>
6.	The method as in claim 5, further comprising:<br>
determining user presence of the first application flow in a sector of the<br>
wireless communication system; and determining a sample duration for the first application flow, wherein determining QoS statistics for the first application flow comprises:<br>
determining QoS statistics for the first application flow during the sample<br>
duration.<br>
7.	The method as in claim 6, where a first sample duration is associated with rate violations and a second sample duration is associated with delay violations.<br>
8.	The method as in claim 6, wherein comparing the QoS statistics for the first application flow to other current flows in the sector comprises:<br>
calculating  a  first fraction  of slots  used   by flows   having  QoS<br>
requirements during the sample period; calculating a second fraction of slots used by the first application flow<br>
during the sample period; calculating a third fraction of QoS fiows corresponding to a first QoS<br>
statistic; comparing the third fraction to a corresponding threshold value; and<br><br>
evaluating an adaptive subscription in response to comparing the third fraction to a corresponding threshold value.<br>
9.	A method for allocating resources in a communication system supporting<br>
Internet Protocol (IP) applications, the communication system including an<br>
Access Network (AN) and a plurality of Access Terminals (ATs), each of the<br>
ATs sending a requested data rate to the AN, the communication system<br>
supporting application flows having QoS requirements to the ATs. the method<br>
comprising:<br>
for increases in adaptive subscription, preempting a first flow having a<br>
first type of QoS violation; determining a preemption maximum value is reached for the first type of<br>
QoS violation; and preempting a second flow having a second type of QoS violation.<br>
10.	The method as in claim 9, wherein preempting a second flow further<br>
comprises:<br>
selecting the second flow based on a number of slots used for transmission of the second flow.<br>
11 A method for scheduling resources in a wireless communication system support:ing packet data application flows, the method comprising:<br>
selecting at least one compensation factor for a quality of service<br>
parameter associated with a first type of application flow, calculating the at least one compensation factor based on a quality of<br>
service parameter; calculating a weight for the first type of application flow as a function of<br>
the at least one compensation factor; calculating a per-flow scheduling factor using the weight; and scheduling the application flow based on the scheduling factor.<br>
12. The method as in claim 11, wherein a first user has a plurality of active application flows, the method further comprising:<br><br>
computing  an  aggregate compensation  factor for the  plurality of application flows.<br>
13.	The method as in claim 12, wherein the plurality of active application<br>
flows includes application flows of the first type and of a second type.<br>
14.	The method as in claim 13, further comprising: calculating a weight for a second type of application flow.<br>
15.	The method as in claim 14, further comprising:<br>
selecting one of the plurality of active application flows for transmission.<br>
16.	An apparatus for admission control in a communication system<br>
supporting Internet Protocol (IP) applications, the communication system<br>
including an Access Network (AN) and a plurality of Access Terminals (ATs),<br>
each of the ATs sending a requested data rate to the AN, the communication<br>
system supporting application flows having QoS requirements to the ATs, the<br>
apparatus comprising:<br>
means for determining  available  resources  in  the  communication<br>
system; means for receiving a request for a first application flow having a first<br>
traffic profile and a first QoS profile; means for detemiining if the available resources support the request for<br>
the first application flow; means for denying the first application flow If the first application flow<br>
has a corresponding data rate greater than an average requested<br>
data rate; and means for admitting the first application flow if the corresponding data<br>
rate is not greater than the average requested data rate, and if<br>
the   available   resources   support  the   request  for  the  first<br>
application flow.<br><br>
17.	An apparatus for allocating resources in a communication system<br>
supporting Intemet Protocol (IP) applications, the communication system<br>
including an Access Network (AN) and a plurality of Access Terminals (ATs),<br>
each of the ATs sending a requested data rate to the AN, the communication<br>
system supporting application flows having QoS requirements to the ATs, the<br>
apparatus comprising:<br>
means for preempting a first flow having a first type of QoS violation for<br>
increases in adaptive subscription; means for determining a preemption maximum value is reached for the<br>
first type of QoS violation; and means for preempting a second flow having a second type of QoS<br>
violation.<br>
18.	An apparatus for scheduling resources in a wireless communication<br>
system supporting packet data application flows, the apparatus comprising:<br>
means for selecting at least one compensation factor for a quality of<br>
service parameter associated with a first type of application flow, means for calculating the at least one compensation factor based on a<br>
quality of service parameter; means for calculating a weight for the first type of application flow as a<br>
function of the at least one compensation factor; means for calculating a per-flow scheduling factor using the weight; and means for scheduling the application flow based on the scheduling<br>
factor.<br>
19.	An apparatus for allocating resources in a communication system<br>
supporting Internet Protocol (IP) applications, the communication system<br>
including an Access Network (AN) and a plurality of Access Temninals (ATs),<br>
each of the ATs sending a requested data rate to the AN, the communication<br>
system supporting application flows having QoS requirements to the ATs, the<br>
apparatus comprising:<br><br>
a flow classification unit adapted to receive an application flow and determine the Quality of Service (QoS) requirements of the application flow;<br>
a scheduler coupled to the flow classification unit adapted to schedule packet data transmissions;<br>
an admission control unit coupled to the flow classification unit and scheduler, the admission control unit adapted to admit application flows when available resources support a requested data rate;<br>
a QoS monitor coupled to the flow classification unit, the scheduler and the admission control unit, the QoS monitor adapted to detennine QoS violations for the application flow and maintain QoS statistics; and<br>
an adaptation unit coupled to the admission control unit, the adaptation unit adapted to update a measure of available resources.<br>
20.	The apparatus as in claim 19, wherein the scheduler is adapted to<br>
schedule application flows in response to requested data rates.<br>
21.	The apparatus as in claim 19, wherein the scheduler is adapted to<br>
schedule application flows in response to QoS statistics.<br>
22.	The apparatus as in claim 19, wherein the scheduler is adapted to schedule application flows in response to QoS requirements.<br>
23.	The apparatus as in claim 19, wherein the scheduler is adapted to schedule application flows based on subscription information.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1hc3NpZ25tZW50LnBkZg==" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1jb3JyZXNwb25kZW5jZSBvdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1jb3JyZXNwb25kZW5jZSBwby5wZGY=" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-correspondence po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDAwNS1wY3QucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-20005-pct.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDA1IGFic3RyYWN0IGdyYW50ZWQucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-2005 abstract granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDA1IGNsYWltcyBncmFudGVkLnBkZg==" target="_blank" style="word-wrap:break-word;">2276-chenp-2005 claims granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDA1IGRlc2NyaXB0aW9uIChjb21wbGV0ZSkgZ3JhbnRlZC5wZGY=" target="_blank" style="word-wrap:break-word;">2276-chenp-2005 description (complete) granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjI3Ni1jaGVucC0yMDA1IGRyYXdpbmdzIGdyYW50ZWQucGRm" target="_blank" style="word-wrap:break-word;">2276-chenp-2005 drawings granted.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="228196-recovery-of-metal-values-from-cermet-material.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="228198-a-method-for-improving-the-radiostability-of-a-18f-fluor-deoxy-glucose-18f-fdg-solution.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>228197</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2276/CHENP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>10/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>06-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>28-Jan-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>15-Sep-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>QUALCOMM INCORPORATED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>5775 MOREHOUSE DRIVE, SAN DIEGO, CALIFORNIA 92121,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>TANEJA , MUKESH</td>
											<td>10762 CAMINITO ALVAREZ, SAN DIEGO, CALIFORNIA 92126,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>PANKAJ, RAJESH, K</td>
											<td>7356 PARK VILLAGE ROAD, SAN DIEGO, CALIFORNIA 92129,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04L 12/56</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US04/08283</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-03-17</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10/425,854</td>
									<td>2003-04-28</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/455,906</td>
									<td>2003-03-17</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/228197-a-method-and-an-apparatus-for-admission-control-in-a-communication-system by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:46:40 GMT -->
</html>
