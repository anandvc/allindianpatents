<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/202611-device-having-a-voice-or-manual-user-interface-and-process-for-aiding-with-learning-the-voice-instructions-of-such-a-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:03:34 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 202611:&quot;DEVICE HAVING A VOICE OR MANUAL USER INTERFACE AND PROCESS FOR AIDING WITH LEARNING THE VOICE INSTRUCTIONS OF SUCH A DEVICE&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;DEVICE HAVING A VOICE OR MANUAL USER INTERFACE AND PROCESS FOR AIDING WITH LEARNING THE VOICE INSTRUCTIONS OF SUCH A DEVICE&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The device has a voice and/or manual user interface for accessing its functions. The functions are accessible through a hierarchy of menus in which the branches can be short-circuited by voice instructions referred to as voice short-cuts. According to the invention, means are provided for storing the sequences of interactions performed by the user and for detecting the cases in which a voice short-cut could have been used instead of the sequence of interactions. In this case, a message is sent to the user in order to inform him or her of the existence of the detected voice short-cut. The invention also relates to a process for aiding with learning the voice instructions of the device using the means above.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>- 1A-<br>
The present invention relates to a device having a voice and/or manual user interface and to a process for aiding with learning the voice instructions of such a device. It relates in particular to the field of devices designed to be controlled using a remote control that can be operated by voice or alternatively using buttons.<br>
In general, the various functions of a device are accessed through a hierarchy of menus through which the user navigates using buttons on his or her remote control, using voice instructions or optionally buttons fitted to the device itself.<br>
One problem which arises for the users is to know the voice instructions, that is to say. the keywords which need to be spoken in order to use them. This is because, even if these keywords are chosen so as to be memorized with ease, if the user does not use them often, he runs the risk of forgetting them and therefore not using the voice instructions.<br>
One first way of aiding users to know the voice instructions consists in implementing the principle of "WYSIWYCS", standing for "What You See Is What You Can Say" . That is to say, when a menu contains headings (a heading being a submenu or a function) is displayed on the screen, the user can reach or activate one of the headings by saying the keyword displayed on the screen which corresponds to this heading.<br>
However, the main benefit of voice instruction of the devices over manual instruction involves the use of short-cuts for:<br>
-	either directly accessing certain menus or<br>
certain functions of the devices by saying a keyword<br>
corresponding to the said menu or the said function,<br>
without  having  to  perform  multiple  operations  of<br>
navigating through the menu,  in which case the term<br>
navigation voice short-cuts is used;<br>
-	or  directly  activating  certain  functions,<br>
also by saying a keyword corresponding to the said<br>
function, without having to enter into any menu,  in<br><br>
- 2 -<br>
which case the term activation voice  short-cuts  is<br>
used;<br>
it being possible for these two possibilities to be<br>
combined with voice short-cuts which make it possible<br>
both to access a function and activate it.<br>
In this case, the "WYSIWYCS" approach cannot be applied since the user will not necessarily see on screen the keywords which he can say to reach a menu or activate a given function.<br>
One object of the invention is to solve the problem explained above by making it easier for users to learn and know the voice instructions.<br>
For this purpose, the invention provides a device having a voice and/or manual user interface for accessing its functions, the functions being accessible through a hierarchy of menus in which the branches can be short-circuited by certain voice instructions referred to as voice short-cuts. According to the invention, the device has:<br>
-	means for storing a sequence of interactions<br>
by the user;<br>
-	means for detecting the existence of a voice<br>
short-cut  corresponding  to  the  stored  sequence  of<br>
interactions; and<br>
-	means for delivering,  in the event that the<br>
existence of a voice short-cut is detected, a message<br>
to the user in order to inform him or her of the<br>
existence of the voice short-cut.<br>
The invention also relates to a process for aiding the learning of voice instructions of a device as mentioned above. This process comprises the steps consisting in:<br>
a)	storing a sequence of interactions by the<br>
user;<br>
b)	testing   whether    a   voice    short-cut<br>
corresponding to said sequence of interactions exists;<br>
and<br><br>
- 3 -<br>
c) in the event that the existence of a voice short-cut is detected, providing means for informing the user of the existence of the voice short-cut.<br>
Thus, as soon as the user uses a complex sequence of interactions to reach a menu or a function of the device even though he could have reached this menu or this function using a voice short-cut, he will be reminded of the use of this voice short-cut. By virtue of the invention, the user will find it very easy to remember the voice short-cuts corresponding to the menus or functions which he accesses most often.<br>
According to a particular embodiment of the invention, step a) comprises:<br>
i) storage of the initial state of the user interface;<br>
ii) detection of an action performed by the user;<br>
iii) storage of the current state of the user interface following this action;<br>
steps ii) and iii) being repeated until one of the following conditions for the end of a sequence of interactions is fulfilled:<br>
-	the  action  detected  corresponds  to  the<br>
activation of a function; or<br>
-	no action is detected for a period longer<br>
than a predetermined limit duration.<br>
It is thus possible to detect both sequences of interactions leading to the activation of a function and those consisting in accessing a menu or a particular function without activating it.<br>
According to a particular embodiment, the user interface has a remote control equipped with buttons and a microphone, and the action detected in step ii) belongs to the set consisting of:<br>
-	a button on the remote control being pressed;<br>
and<br>
-	the   microphone   picking   up   a   keyword<br>
corresponding to a voice instruction.<br><br>
- 4 -<br>
Advantageously, the process of the invention furthermore comprises the steps consisting in:<br>
iv) providing a use counter associated with each voice instruction of the device;<br>
v) testing whether the action detected in step ii) is a voice instruction which corresponds to a voice short-cut; and<br>
vi) incrementing the use counter associated with said voice instruction when the answer to the test above is positive.<br>
According to a preferred aspect of the invention, the storage means of the device include an interaction register comprising:<br>
-	an "initial state" field in which the initial<br>
state of the user interface is stored during step i);<br>
-	a "current state" field in which the current<br>
state of the user interface is stored during step iii).<br>
According to a particular embodiment, step a) furthermore includes:<br>
vii) storage of the use of each voice short-cut detected in step v); and step c) furthermore includes<br>
viii) checking that the voice short-cut corresponding to the stored sequence of interactions has not already been used during said sequence of interactions.<br>
According to a preferred aspect of the invention, if in step viii) it is detected that the voice short-cut corresponding to the stored sequence of interactions has not yet been used during said sequence of interactions, then the steps consisting in:<br>
ix) comparing the use counter of the voice instruction corresponding to said voice short-cut with a predetermined threshold, and<br>
-	if the use counter is greater than or<br>
equal to the threshold, then<br>
x) decrementing the use counter;<br>
-	else,<br><br>
- 5 -<br>
xi) sending a message to the user informing him or her of the existence of the voice short-cut detected in step b)<br>
are carried out.<br>
Thus, if the user is in the habit of using a voice short-cut but sometimes forgets to employ it, the system reacts "intelligently" by not reminding him or her of the existence of the voice short-cut.<br>
According to another aspect of the invention, means are provided for disabling the process described above for the case when the user does not in general wish to be disturbed by the messages reminding him or her of the voice instructions.<br>
Other characteristics and advantages of the invention will become apparent from the description below of a particular nonlimiting embodiment of the invention, given with reference to the appended drawings in which:<br>
-	Figures la and lb represent an example of a<br>
device having a voice and/or manual user interface<br>
according to a first aspect of the invention;<br>
-	Figure 2 represents,  in block-diagram form,<br>
the circuits with which a device represented in Figure<br>
la is equipped;<br>
-	Figure  3  represents  an  example  of  menu<br>
hierarchy for navigating through the menus of the user<br>
interface of a device represented in Figure la;<br>
-	Figures 4a to 4e represent examples of menus<br>
such as those belonging to the hierarchy represented in<br>
Figure 3,  which are displayed on the screen of the<br>
device in Figure la;<br>
-	Figures  5a  and  5b  represent  a  flow  chart<br>
illustrating the various steps in the process according<br>
to a second aspect of the invention.<br>
Figure la represents a television receiver device, or television set 1, having a screen 3 which makes it possible to display the video picture corresponding to a signal received by the tuner of the television  set  or  coming  from  an  external  source<br><br>
- 6 -<br>
connected to the television set, such as a video cassette recorder. The screen 3 is also used to display the navigation menus of the user interface of the television set.<br>
The rest of the description will be given with reference to the television receiver device 1 whose user interface comprises a remote control, of the type represented in Figure lb, which is multimode, that is to say can be operated by voice or by pressing buttons, is fitted with buttons 5-11 for manual operation of the functions of the television set and includes a microphone (not shown) for voice instruction of the said functions. Naturally, however, the invention applies more generally to any type of device whose functions can be activated by voice and/or manual instruction, such as a video cassette recorder or a decoder for the signal received from a satellite or via cable.<br>
In order to activate the functions of the television set manually, the user can either use traditional buttons on his or her remote control (buttons 7 for adjusting the volume "Vol.+" and "Vol.-", buttons 8 for running through the channels "PR+" and "PR-" or buttons 6 for selecting a particular channel) , or call up a main menu using button 5, move through this menu using the navigation buttons 9c; 9d and select a menu or activate a particular function using the activation button 10, or alternatively make an adjustment using the buttons "+" 9b and "-" 9a. A button 11 is furthermore provided for exiting the menu. An example of such a menu will be described below with reference to Figure 3.<br>
The remote control 4 also includes a microphone (not shown) for allowing the user to reach or activate functions of the television set by voice. A transmitter (not shown) of high-frequency signals (HF) is furthermore provided which, on the one hand, receives the signals corresponding to operation of the buttons, conditioned by a coding circuit, and on the other hand<br><br>
- 7 -<br>
the audio signals picked up by the microphone, and transmits these instruction signals to the television set.<br>
Figure 2 represents the elements of the television set 1 for processing the signals delivered by the remote control 4.<br>
A high-frequency <hf receiver receives the signals sent by transmitter of remote control. it delivers coming from buttons control to a button-decoder circuit on one hand and microphone voice-recognition other hand. circuits are connected microprocessor which only functional unit system for managing user interface has been represented in figure this comprises navigation management module manages progress through hierarchy menus as function instruction received></hf>
The navigation management module 22 is connected to a first TV management module 26 which manages various functions of the television set, such as volume, changing channel, brightness, contrast, etc. and which is connected to the circuits 19 of the television set. The module 22 is also connected to a second, voice-assistant module 24 which, according to the invention, continuously scrutinizes and stores the interactions performed by the user in order to detect the cases in which he or she could have used a voice short-cut instead of a longer series of interactions to reach a function of the television set.<br>
The module 22 is lastly connected to a third, graphical management module 28 which controls a circuit 20 for displaying data on screen, often referred to as an OSD circuit standing for "On Screen Display" . The OSD circuit 20 is a text and graphics generator which makes it possible to display menus and pictograms on the screen and which makes it possible, according to a preferred aspect of the invention, to display messages<br><br>
- 8 -<br>
intended for the user in order to inform him or her of the existence of voice short-cuts when he does not use them.<br>
Furthermore, a memory 15 of the volatile type and a memory 17 of the nonvolatile type are connected to the microprocessor and are used, as will be seen below, by the voice-assistant module 24 to store respectively nonpersistent and persistent data.<br>
The voice-assistant 24, TV management 26 and graphical management 28 modules form part of the management system 18 of the user interface. The links between the navigation management module 22 and the TV management 2 6' and voice-assistant 24 modules are of the two-way type, as is the link between the module 2 6 and the circuits of the television set 19 and the link between the module 24 and the memories 15 and 17. Similarly, the voice-recognition circuit 16 is connected to the module 22 by a two-way link.<br>
Figure 3 represents the hierarchy of menus for accessing the various functions of the television set. This tree comprises an initial node 30 labelled "TV SCREEN" which corresponds to the state in which a televised programme is being displayed on the screen of the television set. All the nodes 35-45 internal to the tree, which are represented in Figure 3 by black spots, are navigation nodes while the nodes corresponding to the "leaves" of the tree, which are represented by underlined words, are function nodes. The navigation nodes correspond either to menus covering several functions, for example the "PICTURE" menu located at node 37, or to function fields covering several options, for example the "FORMAT" field located at node 39 in the "PICTURE" menu.<br>
The menu hierarchy represented in Figure 3 is given by way of example, and it is entirely conceivable to apply the invention with menus containing other functions.<br>
The "MAIN MENU" menu located at node 35 is selected when the user presses a button 5 of the remote<br><br>
- 9 -<br>
control (Figure 1b) or when he says the "main menu" keyword to the microphone of his or her remote control. The "MAIN MENU" menu provides access to four menus which are displayed in a window in overlay on the current video picture: a programme guide 40, the list of available channels 38 and the setting of certain parameters of the picture 37 and the sound 36. Each of these menus 36, 37, 38, 40 makes it possible to access either function fields covering several options which appear in the form of navigation nodes 39, 41-45 in Figure 3, or functions of the television set directly (underlined words).<br>
In order to access the various headings of the hierarchy, the user can either adopt the conventional procedure of using the navigation 9c; 9d and activation 10 buttons of the remote control, or use the voice instruction by saying one of the keywords corresponding to the title of the headings proposed.<br>
Figures 4a to 4e illustrate the appearance of various windows which are shown on the screen of the television set when the user is navigating through the hierarchy represented in Figure 3.<br>
Let us assume that the user is currently watching a televised programme, that is to say he or she is at node 30 of the hierarchy (Figure 3), and he or she wishes to adjust the contrast of his or her television set.<br>
If he or she is only using the manual interface, that is to say the buttons on the remote control 4, he or she adopts the following procedure: he or she firstly presses button 5 which causes the "MAIN MENU" window 50 to be displayed on the screen (Figure 4a) . This window has four headings 51 to 54 corresponding to the four menus 36-40 accessible from the "MAIN MENU". When the window 50 is displayed, the first heading "PROGRAMME GUIDE" is selected by default, which is why heading 51 is highlighted in Figure 4a. To reach the "PICTURE" menu in which the "CONTRAST" function is located, the user needs to press twice on<br><br>
- 10 -<br>
the navigation button 9d, the first time to select heading 52 (Figure 4b) and the second time to select heading 53 (Figure 4c) . He or she then needs to press on the activation button 10 to bring about display of window 60 (Figure 4d) containing the various functions of the "PICTURE" menu.<br>
This window 60 contains headings 62-65 corresponding to the functions accessible from node 37 (Figure 3) . It also contains a "RETURN" heading 61 which, when activated, makes it possible to return to the "MAIN MENU". This "RETURN" heading, although not represented in the hierarchy in Figure 3, is in fact present in all the menus and submenus of the hierarchy apart from the "MAIN MENU".<br>
In order to reach the "CONTRAST" function, the user also needs to press once on button 9d, which modifies the appearance of window 60 as represented in Figure 4e. At this stage, the user can adjust the contrast by using buttons 9a; 9b, which moves the cursor 70 displayed in the box corresponding to the heading 62 of window 60.<br>
To carry out the same operation, namely adjust the contrast of the television set from the initial node 30 of the menu hierarchy, the user can also use the voice interface. This solution is much more advantageous since it allows him or her to take shortcuts through the hierarchy.<br>
"Thus, all the user needs to do is say the "contrast" keyword for the window 60 to be displayed immediately on the screen with the appearance represented in Figure 4e, that is to say with the "CONTRAST" function selected. The "contrast" voice instruction therefore constitutes a voice short-cut in this context since it makes it possible for the corresponding function to be reached directly without the need to perform five operations, as is the case with manual instruction.<br>
It can be noted that it is also possible to perform the operations described above with reference<br><br>
- 11 -<br>
to Figures 4a to 4e by using voice instructions according to the "WYSIWYCS" principle. This slightly shortens the sequence of interactions compared with manual instruction, because the user can move directly from the window represented in Figure 4 a to the one represented in Figure 4d by saying the "picture" keyword. Even in this case, however, the sequence of interactions is longer than when the user uses the "contrast" voice short-cut from the start.<br>
According to the invention, all the cases when the user uses a long sequence of interactions (using manual and/or voice instructions) to reach a menu or function, or to activate a functions, when he or she could have performed the same operation faster using a voice short-cut, will be detected. Following this detection, the user is informed of the existence of this voice short-cut so that he or she can get used to using the voice short-cuts.<br>
In order to detect the existence of voice short-cuts, the principle is to store the sequences of interactions by the user and see whether the starting node and the finishing node of the sequence of interactions are separated by at least one navigation node.<br>
A sequence of interactions by the user is made up of interactions which comprise: an action by the user as well as the state of the user interface following the action, that is to say the node currently occupied in the hierarchy following the action.<br>
An action by the user corresponds:<br>
-	either to pressing a button on the remote<br>
control;<br>
-	or to saying a keyword corresponding to a<br>
voice instruction.<br>
An action leads either to movement through the navigation tree or to activation of a function. A sequence of interactions ends:<br>
-	either with the activation of a function;<br><br>
- 12 -<br>
- or with the user taking no action for a duration longer than a limit duration, fixed for example at 5 to 10 seconds.<br>
In practice, according to a preferred embodiment, the state of the user interface is stored before the start of the sequence of interactions, and the current state of the user interface is stored as the user performs interactions. When a sequence of interactions is ended, the initial state and the final current state of the user interface are then compared and, as will be seen below, it is deduced from this whether a voice short-cut could have been used to perform the same sequence of interactions.<br>
In order to do this, an interaction register IR will preferably be used. It comprises two fields: an "Initial state" field and a "Current state" field. This interaction register IR is, for example, produced by saving two memory locations in the volatile-type memory 15 to which the microprocessor comprising the functional unit 18 is connected (Figure 2).<br>
Table 1 below illustrates the change in the contents of the interaction register in the case corresponding to the example described above with reference to Figures 4a to 4e:<br><br>
Table 1<br>
In the example above, when the sequence of interactions is ended, the interaction register IR therefore  contains  the  "TV  SCREEN"  state  in  its<br><br>
- 13 -<br>
"Initial state" field and, in its "Current state" field, the state corresponding to selection of the "CONTRAST" function from the "PICTURE" menu. In practice, each state of the interface has a corresponding code, and it is these codes which are stored in the memory locations forming the interaction register IR.<br>
In order to detect the existence of a voice short-cut corresponding to a stored sequence of interactions, a table referred to as the "Voice Function Table" is used which, for each "Starting state" of the user interface, contains a list of all the "Final states" which can be accessed from this "Starting state" by voice instruction, as well as the corresponding keyword which needs to be said.<br>
This voice function table VFT depends on the menu hierarchy which is defined at the start for the user interface. It is stored by the management system of the user interface in the nonvolatile memory 17 (Figure 2). This table VFT comprises four columns: a "Starting state" column, a "Final state" column, a "Voice instruction" column containing the corresponding keywords and, according to a preferred embodiment of the invention, a "Voice short-cut indicator" column which indicates whether or not, when moving from the "Starting state" to the "Final state" by using the "Voice instruction", this constitutes a voice shortcut . When the "Voice short-cut indicator" is equal to " 1" this means that the "Voice instruction" constitutes a voice short-cut. In the converse case, when the "Voice short-cut indicator" is equal to " 0", this means that it is not a voice short-cut.<br>
For example, part of the voice function table VFT corresponding to the menu hierarchy in Figure 3 has been represented below (Table 2):<br><br>
- 14 -<br><br>
Table 2<br>
In order then to detect whether a sequence of interactions which has been stored in the interaction register IR can be replaced by a voice short-cut, all that needs to be done is to look in the VFT table to see whether:<br>
-	for a "Starting state" equal to the " Initial<br>
state" of the interaction register IR, it is possible to<br>
find:<br>
-	a "Final state" equal to the "Current state" of<br>
the interaction register IR such that:<br>
-	the "Voice short-cut indicator"  is equal to<br>
If all these conditions are combined, then it can be deduced from this that the corresponding "Voice instruction" constitutes a voice short-cut of the sequence of interactions which is stored in the interaction register IR.<br><br>
- 15 -<br>
Thus, in the case of the sequence which was illustrated by Table 1, a search will be made in the VFT table as to whether, for a "Starting state" equal to "TV SCREEN", a "Final state" equal to "PICTURE (CONTRAST)" can be found (that is to say the state in which the "CONTRAST" function is selected from the "PICTURE" menu) such that the corresponding "Voice short-cut indicator" is equal to "1". These conditions are found in combination in Table 2 (row 6) , which means that there is a voice short-cut for reaching the same end state as that of the stored sequence of interactions. It can furthermore be seen in Table 2 that the "Voice instruction" corresponding to this voice short-cut is "contrast".<br>
According to the invention, it will therefore be indicated to the user by a suitable message that he or she could have used the voice short-cut consisting in saying the word "contrast". This message may advantageously be delivered in the form of text which appears in a window on the screen of the television set. It may also be delivered in audible form using a voice synthesizer or, alternatively, in both visual and audible form.<br>
The flow chart represented in Figures 5a and 5b represents the various steps in the process for aiding with learning the voice instructions of the television set according to the invention, which process is implemented by the voice-assistant module 24 described with reference to Figure 2.<br>
After a starting step 100 during which various initializations of the system are carried out, the process starts with a first step 101 of resetting the interaction register IR. This step consists in initializing the "Initial state" field and the "Current state" field of the interaction register IR with the current state of the user interface.<br>
During this step 101, a list referred to as the "used short-cut list" USL is also reset. This list USL is preferably stored in the volatile-type memory 15<br><br>
- 16 -<br>
(Figure 2) in which the interaction register IR is also stored. It is used, as will be seen below in the description of the process, to store the voice shortcuts which are used during a sequence of interactions.<br>
The process continues with a first test 102 to check whether or not the user has performed an action. If the answer is yes, then a second test 103 is carried out to check whether or not the action performed by the user is a voice short-cut. This test is carried out as follows, each time a new action by the user is detected.<br>
Firstly, a check is made as to whether the action detected in test 102 is a voice instruction. If the answer is no, then the answer to the test 103 will also be negative. If, however, the detected action is a voice instruction, then a search will be made as to whether or not this voice instruction constitutes a voice short-cut. In order to do this, the voice function table VFT is used and a search is made as to whether:<br>
-	for a "Starting state" equal to the "Current<br>
state" of the interaction register IR, it is possible<br>
to find:<br>
-	a "Voice  instruction"  equal  to  the  voice<br>
instruction identified in the action detected in step<br>
102, such that:<br>
-	the "Voice short-cut indicator" is equal to<br>
"1"<br>
If the answer to this test is positive, then we move on to step 104 which consists in storing the use of the voice short-cut in the list USL and incrementing a "Use counter" for the short-cut.<br>
In fact, a use counter is associated with each voice instruction apart from those which cannot ever constitute voice short-cuts. For example, in the "PROGRAMME GUIDE" menu, the "SUMMARY" function can only ever be activated from the "PROGRAMME GUIDE" menu. The "summary" voice instruction cannot therefore ever constitute a voice short-cut.  In practice,  a "Voice<br><br>
- 17 -<br>
short-cut table" VST comprising a "Voice instruction" column as well as a "Use counter" column will be stored. This table is constructed by copying into the "Voice instruction" column of the voice function table VFT all the voice instructions which have at least once a "Voice short-cut indicator" equal to "1".<br>
Each time the use of a voice short-cut is detected in step 103, the use counter of the associated voice instruction is incremented (step 104). Conversely, each time a voice short-cut could have been used to access a function but the user uses a longer sequence of interactions, the use counter of the associated voice instruction is decremented (step 113 described below).<br>
This makes it possible, as will be seen below, not to inform the user of the existence of a voice short-cut when he or she is in the habit of using it {in this case, its use counter will be high) but occasionally forgets to employ it.<br>
When the use counter of a voice short-cut is incremented in step 104, the voice instruction corresponding to this short-cut is also stored in the list USL of short-cuts used. This list USL will be subsequently used in step 111.<br>
If the answer to the test in step 103 is negative, then we move on to another test {step 108) to check whether or not the last action performed, detected in step 102, corresponds to the activation of a function. In fact, if the answer to this test is negative, it is assumed that the sequence of interactions is not ended and, in this case, we move on to a step 106 of updating the interaction register then we return to step 102. Step 104 described above is also always followed by this step 108.<br>
Step 106 consists in storing the current state of the user interface, that is to say the state of the interface following the action detected in step 102, in the "Current state" field of the interaction register IR.<br><br>
- 18 -<br>
If the answer to test 108 is positive, then we move on to step 110.<br>
When the first test 102 of detecting an action by the user is negative, another test is carried out in step 105 to check whether the limit duration, fixed for example at 5 or 10 seconds, has elapsed. If it has not, we return to step 102 to test whether the user performs an action. If, however, the limit duration has elapsed, it is assumed that the sequence of interactions is ended and we move on to step 110.<br>
When we reach step 110, this means that the sequence of interactions is ended and that the "Initial state" and the final "Current state" of this sequence of interactions are stored in the interaction register IR. In step 110, a test is then carried out, using the method explained above (following the description of the table VFT), as to whether the sequence of interactions that was stored in the interaction register IR can be replaced in full by a voice shortcut .<br>
If the result of test 110 is negative, that is to say if no possible overall voice short-cut is detected for the stored sequence of interactions, then we return to step 101 to start storing a new sequence of interactions. However, in the event that the result of test 110 is positive, that is to say an overall voice short-cut corresponding to the stored sequence of interactions is detected, then in step 111 a check is made that this voice short-cut has not already been used in the sequence of interactions. This is because it is possible for the user to perform a number of interactions by navigating through the hierarchy of menus, for example through the programme guide, then use a voice short-cut to reach, for example, the function of adjusting the brightness by saying the "brightness" keyword. In this case, there is no point in reminding the user of the existence of the voice short-cut. In order to detect whether the voice shortcut, for example "brightness", has been used during the<br><br>
- 19 -<br>
sequence of interactions, a check is made as to whether or not the "brightness" voice instruction is present in the list USL of the short-cuts used.<br>
If the test in step 111 is positive, the voice short-cut detected in step 110 having already been used during the sequence of interactions, then we return to step 101. In the converse case, the process continues with step 112 which consists in testing whether the use counter for the voice instruction (stored in the table VST) is greater than or equal to a predetermined threshold, for example set at 5. This is equivalent to testing whether or not, in the past, the user has already used the voice short-cut more than five times. If the answer to this test is positive, the use counter for the voice short-cut will be decremented in step 113 but it would be considered superfluous to remind the user of the existence of the voice short-cut because he or she has already used it several times, and we return to step 101.<br>
Conversely, if the answer to test 112 is negative, it is necessary to remind the user of the existence of the voice short-cut. Before this, an additional test is carried out in step 114 with a view to detecting whether or not the user is deliberately refusing to use the voice instructions, for example so as not to disturb the people around him or her. In order to do this, a first counter A counts down the time elapsed since the last use of a voice instruction by the user. This counter is time-based by the clock of the system and is reset each time a new voice instruction is detected, or alternatively when the television set is turned to standby. A second counter B is provided for counting the number of times that a reminder of the existence of a voice short-cut has been given during the period counted down by the counter A. This counter is incremented each time a voice short-cut is suggested to the user, and is reset each time a new voice instruction is used.<br><br>
- 20 -<br>
In order to carry out the test 114, we look whether the value of the counter A is greater than or equal to a predetermined duration, for example 15 minutes, and whether the value of the counter B is greater than or equal to a predetermined number of suggestions of voice short-cuts, for example 5. If the result of the test is positive, then there is no point in informing the user of the existence of the voice short-cut detected in step 110, and we return to step 101 to start storing a new sequence of interactions.<br>
In the event that the result of test 114 is negative, then it is assumed that the user is not systematically refusing the voice instructions and, in step 115, he or she is sent a message to inform him or her of the existence of the voice short-cut detected in step 110. This message may be delivered in the form of text displayed on the screen of the television set, or alternatively in audible form using a voice synthesizer.<br>
It is furthermore advantageous to provide a means of deactivating the voice-assistant module 24 when the user intentionally does not wish to be disturbed by the messages which the voice assistant sends to remind him or her of the existence of the voice instructions. In order to do this, it is in particular possible to provide a special additional button (not shown) on the remote control or alternatively a specific heading (not shown) in the menu hierarchy.<br><br>
- 21 -<br>
WE CLAIM :<br>
1 . Device having a voice and/or manual user interface for accessing its functions, said functions being accessible through a hierarchy of menus (30-4 5) in which the branches can be short-circuited by certcin voice instructions referred to as voice short-cuts, characterized in that it has:<br>
-	means (IR) for storing a sequence of interactions by<br>
the user;<br>
-	means (24,  17)  for detecting the existence of a voice<br>
short-cut corresponding to the stored sequence of interactions;<br>
and<br>
-	displaying or audible means (20-28) for delivering, in<br>
the event that the existence of a voice short-cut is detected, a<br>
message to  the user in order to inform him or  her  of the<br>
existence of said voice short-cut.<br>
2.	Process for aiding with learning of voice instructions of<br>
a device according to Claim 1, characterized in that it comprises<br>
the steps consisting in:<br>
a)	storing (101-108) a sequence of interactions by the<br>
user;<br>
b)	testing (110) whether a voice short-cut corresponding<br>
to said sequence of interactions exists; and<br>
c)	in the event that the existence of a voice short-cut<br>
is detected, providing (115) means for informing the user of the<br>
existence of said voice short-cut.<br>
3.	Process according to Claim 2, characterized in that step<br>
a) comprises:<br>
i) storage (101) of the initial state of the user interface;<br>
ii) detection (102) of an action performed by the user;<br>
iii) storage (106) of the current state of the user interface following this action;<br>
steps ii) and iii) bei nc repeated until one of the following conditions (105, 108) for the end of a sequence of interactions is fulfilled:<br><br>
- 22 -<br>
-	the action detected corresponds to the activation of a<br>
function; or<br>
-	no  action  is  detected  for  a  period  longer  than  a<br>
predetermined limit duration.<br>
4 .      Process according to Claim 3, characterized in that the, action detected in step ii) belongs to the set consisting of:<br>
-	a button on a remote contrsl of the user interface<br>
being pressed; and<br>
-	the microphone  of  the  user  interface  picking  up a<br>
keyword corresponding to a voice instruction.<br>
5.	Process  according  to  either  of  Claims   3  and  4,<br>
characterized  in  that  it  furthermore  comprises  the  steps<br>
consisting in:<br>
iv) testing {103) whether the action detected in step ii) is a voice instrue tion which corresponds to a voice short-cut; and<br>
v) incrementing (104) a use counter associated with said voice instruction of the device when the answer to the test above is positive.<br>
6.	Process according to one of claims 3 to 5, characcerized<br>
in that the storage means of the device include an interaction<br>
register (15) comprising:<br>
- an "Initial state" field in which the initial state of the user interface is stored during step i);<br>
 - a "Current state" field in which the current srate of the user interface is stored during step iii).<br>
7.	Process according to Claim 6, characterized in that the<br>
means for detecting the existence of a voice short-cut include a<br>
voice function table (17) comprising,  for each "Starting stare"<br>
of the user interface,  a list of all the "Final states" as a<br>
function of the "Voice instructions" used, as well as a "Voice<br>
short-cut indicator" indicating whether or not the change from<br><br>
- 23 -<br>
one "Starting state" to one "Final state" by using a "Voice instruction" constitutes a voice short-cut;<br>
and in that step iv) is carried out (103) by testing whether:<br>
I. ) the action detected in step ii) is a voice instruction and, it the answer to this test I.) is positive,<br>
II.) by testing whether<br>
-	fer a "Starting state" equal to the "Current<br>
state" of the interaction register (15), it is possible to find:<br>
-	a  "Voice  instruction"  equal  to  the  voice<br>
instruction identified during test 1.), such that:<br>
-	the "Voice  short-cut  indicator"  indicates the<br>
existence of a voice short-cut.<br>
8.	Process according to Claim 7, characterized in that step<br>
b) is carried out by testing, in the voice function table (17),<br>
whether:<br>
-	for a "Starting state" equal to the "Initial state" of<br>
the interaction register (15), it is possible to find:<br>
' - a "Final state" equal to the "Current state" of the interaction register (15) such that:<br>
-	the "Voice short-cut indicator" indicates tne existence<br>
of a voice short-cut.<br>
9.	Process according to one of Claims 5 to 8, characterized<br>
in that step a) furthermore includes:<br>
vi) storage (104) of the use of each vcice short-cut detected in step iv ) .<br>
10.	Process according to Claim 9, characterized in that step<br>
c) furthermore includes<br>
v-ii) checking (111) that the voice short-cut corresponding to the stored sequence of interactions has not already been used curing said sequence of interactions-<br>
11.	Process according to Claim 10, characterized in that if<br>
in  step  vii)   it  is  detected  that  the  voice  short-cut<br><br>
- 24 -<br>
corresponding to tne stored sequence of interactions has not yet been used during  said sequence of -interactions, then the steps consisting in:<br>
viii) comparing (112) the use counter of the voice instruction corresponding to said voice shorft-cut with a predetermined threshold, and<br>
-	if the use counter is greater that or equal to<br>
said threshold, then<br>
ix) decrementing (113) said use counter;<br>
-	or else,<br>
x) sending a message (115) to the user informing him or her of the existence of the voice short-cut detected in step b)' are carried out.<br>
12.     Process according to Claim 11, characterized in that it furthermore comprises the steps consisting in:<br>
and in that a test (114) is carried out before step xi) to detect whether the value of the counter A counting down the time elapsed since the last use of a voice instruction by the user is greater than or equal to a predetermined duration and, if the value of the counter B counting the number of messages sent to the user in accordance with step x) during the period counted down by the counter A is greater than or equal to a predetermined number of messages, step x) being carried out only in the event of a negative reply to said test (114).<br>
13. Device according to Claim 1, characterized in that it comprises means for disabling the process according to one of Claims 2 to 3.2.<br>
The device has a voice and/or manual user interface for accessing its functions. The functions are accessible through a hierarchy of menus in which the branches can be short-circuited by voice instructions referred to as voice short-cuts.<br>
According to the invention, means are provided for storing the sequences of interactions performed by the user and for detecting the cases in which a voice short-cut could have been used instead of the sequence of interactions. In this case, a message is sent to the user in order to inform him or her of the existence of the detected voice short-cut.<br>
The invention also relates to a process for aiding with learning the voice instructions of the device using the means above.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">01014-cal-1999-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">01014-cal-1999-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktY29ycmVzcG9uZGVuY2UucGRm" target="_blank" style="word-wrap:break-word;">01014-cal-1999-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZGVzY3JpcHRpb24oY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">01014-cal-1999-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">01014-cal-1999-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">01014-cal-1999-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZm9ybS0xOC5wZGY=" target="_blank" style="word-wrap:break-word;">01014-cal-1999-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZm9ybS0yLnBkZg==" target="_blank" style="word-wrap:break-word;">01014-cal-1999-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZm9ybS0yNi5wZGY=" target="_blank" style="word-wrap:break-word;">01014-cal-1999-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">01014-cal-1999-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktbGV0dGVycyBwYXRlbnQucGRm" target="_blank" style="word-wrap:break-word;">01014-cal-1999-letters patent.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktcHJpb3JpdHkgZG9jdW1lbnQgb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">01014-cal-1999-priority document others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktcHJpb3JpdHkgZG9jdW1lbnQucGRm" target="_blank" style="word-wrap:break-word;">01014-cal-1999-priority document.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDEwMTQtY2FsLTE5OTktcmVwbHkgZi5lLnIucGRm" target="_blank" style="word-wrap:break-word;">01014-cal-1999-reply f.e.r.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTAxNC1DQUwtMTk5OS1GT1JNLTI3LnBkZg==" target="_blank" style="word-wrap:break-word;">1014-CAL-1999-FORM-27.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="202610-pick-and-place-apparatus-of-a-handler-system-for-testing-semiconductor-devices.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="202612-a-method-for-providing-a-push-rod-and-ball-end-combination-for-positioning-components-of-a-brake-system-and-a-push-rod-and-ball-end-combination-therefor.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>202611</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1014/CAL/1999</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>11/2007</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>16-Mar-2007</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>16-Mar-2007</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>30-Dec-1999</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON multimedia</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46 Qual A , Le Gallo F-92100 Boulogne-Billancourt,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DIEHL Eric,</td>
											<td>La Buzardiere, F-35340 Liffre,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>SHAO Jiang,</td>
											<td>10 rue Constant Veron, F-35000 Rennes</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G08B 3/10</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>9900460</td>
									<td>1999-01-18</td>
								    <td>France</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/202611-device-having-a-voice-or-manual-user-interface-and-process-for-aiding-with-learning-the-voice-instructions-of-such-a-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:03:35 GMT -->
</html>
