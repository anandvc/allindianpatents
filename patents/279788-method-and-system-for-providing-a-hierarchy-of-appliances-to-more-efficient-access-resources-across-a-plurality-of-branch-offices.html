<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/279788-method-and-system-for-providing-a-hierarchy-of-appliances-to-more-efficient-access-resources-across-a-plurality-of-branch-offices by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:13:24 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 279788:METHOD AND SYSTEM FOR PROVIDING A HIERARCHY OF APPLIANCES TO MORE EFFICIENT ACCESS RESOURCES ACROSS A PLURALITY OF BRANCH OFFICES</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND SYSTEM FOR PROVIDING A HIERARCHY OF APPLIANCES TO MORE EFFICIENT ACCESS RESOURCES ACROSS A PLURALITY OF BRANCH OFFICES</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Systems and methods are disclosed for providing a hierarchy of appliances to more efficiently access resources across a plurality of branch offices. A method comprises the steps of: establishing, by a first aggregator appliance, connections with a first plurality of branch office appliances; establishing, by a second aggregator appliance, connections with a second plurality of branch office appliances, the first plurality of branch office appliances not having information identifying the second plurality of branch office appliances; receiving, by the first aggregator appliance, from a first branch office appliance a request from a client for access to a resource; identifying, by the first aggregator appliance via the second aggregator appliance, a second branch office appliance from the second plurality of branch office appliances to service the request; transmitting, by the first aggregator appliance, to the first branch office appliance information identifying the second branch office appliance; and establishing, by the first branch office appliance, a connection with the second branch office appliance. Corresponding systems are also described.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>SYSTEMS AND METHODS FOR<br>
HIERARCHICAL GLOBAL LOAD BALANCING<br>
Field of the Invention<br>
The present invention generally relates to data communication networks. In<br>
particular, the present invention relates to systems and methods for providing aggregator<br>
appliances for global and hierarchical load balancing of branch offices.<br>
Background of the Invention<br>
A corporate or enterprise network may service many branch offices. Each branch<br>
office may have its own network, servers and resources. An appliance may be deployed at a<br>
branch office to provide gateway services locally to the client or servers located at the branch<br>
office. In the corporate-wide network, branch office appliances may be deployed at each of<br>
the branch offices. Many resources, such as servers, applications, data files may be deployed<br>
across these branch offices. Additionally, a branch office may have under utilized resources<br>
and available computing time.<br>
At any of the branch offices there may be resources that could be available or useful<br>
to access by users or computing devices at other branch offices. For example, a client of a<br>
first branch office may want to access a resource, such as an application, on a server at a<br>
second branch office. In some cases, the client of the first branch office is not aware of the<br>
existence or availability of resources at the second branch office. In other cases, resources at<br>
branch offices lay idle as they are not easily available to users across the corporate network.<br>
This results in inefficient use of the corporate network and deployed resource. In order to<br>
avail a client of a branch office access to resources from another branch office, an<br>
administrator may need to manually and specifically configure the gateway or branch office<br>
appliance to know of the other appliances in the network. With resources deployed across<br>
 <br>
many branch offices, each of the branch office appliances may need to be manually<br>
configured to know of the other branch office appliances. This leads to significant amount of<br>
time and costs in configuring and maintaining multiple branch office appliances or gateway.<br>
It would, therefore, be desirable to provide systems and methods to reduce branch<br>
office configuration while load-balancing resources globally across the enterprise and branch<br>
offices.<br>
Brief Summary of the Invention<br>
The present invention is directed towards an aggregator appliance that provides<br>
aggregation and load-balancing of branch office appliances in a hierarchical fashion and a<br>
manner that reduces configuration of the branch office appliance. Any of the branch office<br>
appliances may be configured to know of or identify a single aggregator appliance 400. For<br>
example, a first branch office appliance may be configured to identify and connect to the first<br>
aggregator appliance. The first branch office appliance may not be configured to have any<br>
information and therefore may not know of the second aggregator appliance or any branch<br>
office appliances connected to the second aggregator appliance. In this manner, the<br>
configuration of branch office appliance is reduced. Even though the configuration is<br>
reduced, a branch office appliance servicing a request may access any of the other appliances<br>
known to an aggregator appliance. Since the aggregator appliances share information on<br>
branch office appliance, a first aggregator appliance can identify to a first branch office<br>
appliance information identifying any of the branch office appliances connected via any of<br>
the aggregator appliances. In this way, resource requests can be load balanced globally<br>
across all branch offices and branch office appliances.<br>
In one aspect, the present invention is related to a method for providing a hierarchy of<br>
appliances to more efficiently access resources across a plurality of branch offices. The<br>
method includes the steps of: establishing, by a first aggregator appliance, connections with a<br>
 <br>
first plurality of branch office appliances, and establishing, by a second aggregator appliance,<br>
connections with a second plurality of branch office appliances. The first plurality of branch<br>
office appliances may not have information identifying the second plurality of branch office<br>
appliances. The second plurality of branch office appliances may also not have information<br>
identifying the first plurality of branch office appliances. The method includes receiving, by<br>
the first aggregator appliance, from a first branch office appliance of the first plurality of<br>
branch office a request from a client for access to a resource. The first aggregator appliance<br>
identifies via the second aggregator appliance a second branch office appliance from the<br>
second plurality of branch office appliances to service the request. The first aggregator<br>
appliance transmits to one of the client or a first branch office appliance information<br>
identifying the second branch office appliance. The method includes the client establishing a<br>
connection with the second branch office appliance.<br>
In one embodiment, the method includes transmitting, by the first branch office<br>
appliance, information identifying the second branch office appliance to the client.<br>
In another embodiment, the method includes establishes, by the client via the first branch<br>
office appliance, a second connection via the second branch office appliance with a server.<br>
In some embodiments, the method includes establishing, by the first aggregator appliance,<br>
communications with the second aggregator appliance, in one embodiment, the first<br>
aggregator appliance communicates information about the first plurality of branch office<br>
appliances to the second aggregator appliance. In another embodiments, the second<br>
aggregator appliance communicates information about the second plurality of branch office<br>
appliances to the first aggregator appliance.<br>
In another embodiment, the method includes determining, by the first aggregator<br>
appliance, information on performance or operational characteristics for each of the first<br>
plurality of branch office appliances. In some embodiments, the method includes<br>
determining, by the second aggregator appliance, performance or operational characteristics<br>
 <br>
of each of the second plurality of branch office appliances. In one embodiment, the method<br>
includes selecting, by the first or second aggregator appliance, the second branch office<br>
appliance based on one of the performance or operational characteristics.<br>
In yet another embodiment, the method includes by the first office branch office<br>
appliance or the second branch office appliance, communications between the client and the<br>
server. The method may include accelerating using one or more of the following techniques:<br>
1) compression, 2) TCP connection pooling, 3)TCP connection multiplexing, 4) TCP<br>
buffering, and 5) caching. In some embodiments, the first aggregator appliance or the second<br>
aggregator appliance is deployed at a data center. In another embodiment, the client is<br>
deployed at the first branch office.<br>
In another aspect, the present invention is related to a system for providing a<br>
hierarchy of appliances to more efficiently access resources across a plurality of branch<br>
offices, the system comprises a first aggregator appliance and a second aggregator appliance.<br>
The first aggregator appliance establishes connections with a first plurality of branch office<br>
appliances. The second aggregator appliance establishes connections with a second plurality<br>
of branch office appliances. The first plurality of branch office appliances may not have<br>
information identifying the second plurality of branch office appliances. The second plurality<br>
of branch office appliances may also not have information identifying the first plurality of<br>
branch office appliances. The system also includes a first branch office appliance of the first<br>
plurality of branch offices transmitting to the first aggregator appliance a request from a<br>
client for access to a resource. The first aggregator appliance identifies via the second<br>
aggregator appliance a second branch office appliance from the second plurality of branch<br>
office appliances to service the request and transmits to the first branch office appliance<br>
information identifying the second branch office appliance. The system also includes the<br>
client establishing a connection with the second branch office appliance.<br>
 <br>
In one embodiment, the first branch office appliance transmits information identifying<br>
the second branch office appliance to the client. In another embodiment, the client<br>
establishes via the first branch office appliance a second connection via the second branch<br>
office appliance with a server. In some embodiments, the first aggregator appliamce<br>
establishes communications with the second aggregator appliance. In one embodiment, the<br>
first aggregator appliance communicates information about the first plurality of branch office<br>
appliances to the second aggregator appliance. In yet another embodiment, the second<br>
aggregator appliance communicates information about the second plurality of branch office<br>
appliances to the first aggregator appliance. In some embodiments, the first or second<br>
aggregator appliance determines information on performance or operational charactersitics<br>
for each of the first plurality of branch office appliances. In another embodiment of the<br>
system, the first aggregator appliance selects the second branch office appliance based on one<br>
of the performance or operational characteristics.<br>
In some embodiments, the first office branch office appliance or the second branch<br>
office appliance accelerates communications between the client and a server. The<br>
acceleration techniques may include one or more of the following: 1) compression, 2) TCP<br>
connection pooling, 3)TCP connection multiplexing, 4) TCP buffering, and 5) caching.<br>
In other embodiments, the first aggregator appliance or the second aggregator appliance is<br>
deployed at a data center. In one embodiment, the client is deployed at the first branch office.<br>
The details of various embodiments of the invention are set forth in the accompanying<br>
drawings and the description below.<br>
Brief Description of the Figures<br>
The foregoing and other objects, aspects, features, and advantages of the invention<br>
will become more apparent and better understood by referring to the following description<br>
taken in conjunction with the accompanying drawings, in which:<br>
 <br>
FIG. 1A is a block diagram of an embodiment of a network environment for a client<br>
to access a server via an appliance;<br>
FIG. IB is a block diagram of an embodiment of an environment for delivering a<br>
computing environment from a server to a client via an appliance;<br>
FIGs. 1C and ID are block diagrams of embodiments of a computing device;<br>
FIG. 2A is a block diagram of an embodiment of an appliance for processing<br>
communications between a client and a server;<br>
FIG. 2B is a block diagram of another embodiment of an appliance for optimizing,<br>
accelerating, load-balancing and routing communications between a client and a server;<br>
FIG. 3 is a block diagram of an embodiment of a client for communicating with a<br>
server via the appliance;<br>
FIG. 4A is a block diagram of an embodiment of aggregator appliances to access<br>
resources across branch offices;<br>
FIG. 4B is a block diagram of another embodiment of a deployment of aggregator<br>
appliances to load balance a plurality of branch offices; and<br>
FIG. 5 is a flow diagram of steps of an embodiment of a method for practicing<br>
hierarchical load balancing with aggregator appliances to access resources across branch<br>
offices.<br>
The features and advantages of the present invention will become more apparent from<br>
the detailed description set forth below when taken in conjunction with the drawings, in<br>
which like reference characters identify corresponding elements throughout. In the drawings,<br>
like reference numbers generally indicate identical, functionally similar, and/or structurally<br>
similar elements.<br>
 <br>
Detailed Description of the Invention<br>
A. Network and Computing Environment<br>
Prior to discussing the specifics of embodiments of the systems and methods of an<br>
appliance and/or client, it may be helpful to discuss the network and computing environments<br>
in which such embodiments may be deployed. Referring now to Figure 1 A, an embodiment<br>
of a network environment is depicted. In brief overview, the network environment comprises<br>
one or more clients 102a-102n (also generally referred to as local machine(s) 102, or client(s)<br>
102) in communication with one or more servers 106a-106n (also generally referred to as<br>
server(s) 106, or remote machine(s) 106) via one or more networks 104, 104' (generally<br>
referred to as network 104). In some embodiments, a client 102 communicates with a server<br>
106 via an appliance 200.<br>
Although FIG. 1A shows a network 104 and a network 104' between the clients 102<br>
and the servers 106, the clients 102 and the servers 106 may be on the same network 104.<br>
The networks 104 and 104' can be the same type of network or different types of networks.<br>
The network 104 and/or the network 104' can be a local-area network (LAN), such as a<br>
company Intranet, a metropolitan area network (MAN), or a wide area network (WAN), such<br>
as the Internet or the World Wide Web. In one embodiment, network 104' may be a private<br>
network and network 104 may be a public network. In some embodiments, network 104 may<br>
be a private network and network 104' a public network. In another embodiment, networks<br>
104 and 104' may both be private networks. In some embodiments, clients 102 may be<br>
located at a branch office of a corporate enterprise communicating via a WAN connection<br>
over the network 104 to the servers 106 located at a corporate data center.<br>
The network 104 and/or 104' be any type and/or form of network and may include<br>
any of the following: a point to point network, a broadcast network, a wide area network, a<br>
local area network, a telecommunications network, a data communication network, a<br>
computer network, an ATM (Asynchronous Transfer Mode) network, a SONET<br>
 <br>
(Synchronous Optical Network) network, a SDH (Synchronous Digital Hierarchy) network, a<br>
wireless network and a wireline network. In some embodiments, the network 104 may<br>
comprise a wireless link, such as an infrared channel or satellite band. The topology of the<br>
network 104 and/or 104' may be a bus, star, or ring network topology. The network 104<br>
and/or 104' and network topology may be of any such network or network topology as<br>
known to those ordinarily skilled in the art capable of supporting the operations described<br>
herein.<br>
As shown in FIG. 1 A, the appliance 200, which also may be referred to as an interface<br>
unit 200 or gateway 200, is shown between the networks 104 and 104'. In some<br>
embodiments, the appliance 200 may be located on network 104. For example, a branch<br>
office of a corporate enterprise may deploy an appliance 200 at the branch office. In other<br>
embodiments, the appliance 200 may be located on network 104'. For example, an appliance<br>
200 may be located at a corporate data center. In yet another embodiment, a plurality of<br>
appliances 200 may be deployed on network 104. In some embodiments, a plurality of<br>
appliances 200 may be deployed on network 104'. In one embodiment, a first appliance 200<br>
communicates with a second appliance 200'. In other embodiments, the appliance 200 could<br>
be a part of any client 102 or server 106 on the same or different network 104,104' as the<br>
client 102. One or more appliances 200 may be located at any point in the network or<br>
network communications path between a client 102 and a server 106.<br>
In one embodiment, the system may include multiple, logically-grouped servers 106.<br>
In these embodiments, the logical group of servers may be referred to as a server farm 38. In<br>
some of these embodiments, the serves 106 may be geographically dispersed. In some cases,<br>
a farm 38 may be administered as a single entity. In other embodiments, the server farm 38<br>
comprises a plurality of server farms 38. In one embodiment, the server farm executes one or<br>
more applications on behalf of one or more clients 102.<br>
 <br>
The servers 106 within each farm 38 can be heterogeneous. One or moire of the<br>
servers 106 can operate according to one type of operating system platform (e.g., WINDOWS<br>
NT, manufactured by Microsoft Corp. of Redmond, Washington), while one or more of the<br>
other servers 106 can operate on according to another type of operating system platform (e.g.,<br>
Unix or Linux). The servers 106 of each farm 38 do not need to be physically proximate to<br>
another server 106 in the same farm 38. Thus, the group of servers 106 logically grouped as<br>
a farm 38 may be interconnected using a wide-area network (WAN) connection or medium-<br>
area network (MAN) connection. For example, a farm 38 may include servers 106 physically<br>
located in different continents or different regions of a continent, countiy, state, city, campus,<br>
or room. Data transmission speeds between servers 106 in the farm 38 can be increased if the<br>
servers 106 are connected using a local-area network (LAN) connection or some form of<br>
direct connection.<br>
Servers 106 may be referred to as a file server, application server, web server, proxy<br>
server, or gateway server. In some embodiments, a server 106 may have the capacity to<br>
function as either an application server or as a master application server. In one embodiment,<br>
a server 106 may include an Active Directory. The clients 102 may also be referred to as<br>
client nodes or endpoints. In some embodiments, a client 102 has the capacity to function as<br>
both a client node seeking access to applications on a server and as an application server<br>
providing access to hosted applications for other clients 102a-102n.<br>
In some embodiments, a client 102 communicates with a server 106. In one<br>
embodiment, the client 102 communicates directly with one of the servers 106 in a farm 38.<br>
In another embodiment, the client 102 executes a program neighborhood application to<br>
communicate with a server 106 in a farm 38. In still another embodiment, the server 106<br>
provides the functionality of a master node. In some embodiments, the client 102<br>
communicates with the server 106 in the farm 38 through a network 104. Over the network<br>
104, the client 102 can, for example, request execution of various applications hosted by the<br>
 <br>
servers 106a-106n in the farm 38 and receive output of the results of the application<br>
execution for display. In some embodiments, only the master node provides the functionality<br>
required to identify and provide address information associated with a server 106' hosting a<br>
requested application.<br>
In one embodiment, the server 106 provides functionality of a web server. In another<br>
embodiment, the server 106a receives requests from the client 102, forwards the requests to a<br>
second server 106b and responds to the request by the client 102 with a response to the<br>
request from the server 106b. Tn still another embodiment, the server 106 acquires an<br>
enumeration of applications available to the client 102 and address information associated<br>
with a server 106 hosting an application identified by the enumeration of applications. In yet<br>
another embodiment, the server 106 presents the response to the request to the client 102<br>
using a web interface. In one embodiment, the client 102 communicates directly with the<br>
server 106 to access the identified application. In another embodiment, the client 102<br>
receives application output data, such as display data, generated by an execution of the<br>
identified application on the server 106.<br>
Referring now to FIG. IB, a network environment for delivering and/or operating a<br>
computing environment on a client 102 is depicted. In some embodiments, a server 106<br>
includes an application delivery system 190 for delivering a computing environment or an<br>
application and/or data file to one or more clients 102. In brief overview, a client 10 is in<br>
communication with a server 106 via network 104, 104' and appliance 200. For example, the<br>
client 102 may reside in a remote office of a company, e.g., a branch office, and the server<br>
106 may reside at a corporate data center. The client 102 comprises a client agent 120, and a<br>
computing environment 15. The computing environment 15 may execute or operate an<br>
application that accesses, processes or uses a data file. The computing environment 15,<br>
application and/or data file may be delivered via the appliance 200 and/or the server 106.<br>
 <br>
In some embodiments, the appliance 200 accelerates delivery of a computing<br>
environment 15, or any portion thereof, to a client 102. In one embodiment, the appliance<br>
200 accelerates the delivery of the computing environment 15 by the application delivery<br>
system 190. For example, the embodiments described herein may be used to accelerate<br>
delivery of a streaming application and data file processable by the application from a central<br>
corporate data center to a remote user location, such as a branch office of the company. In<br>
another embodiment, the appliance 200 accelerates transport layer traffic between a client<br>
102 and a server 106. The appliance 200 may provide acceleration techniques for<br>
accelerating any transport layer payload from a server 106 to a client 102, such as: 1)<br>
transport layer connection pooling, 2) transport layer connection multiplexing, 3) transport<br>
control protocol buffering, 4) compression and 5) caching. In some embodiments, the<br>
appliance 200 provides load balancing of servers 106 in responding to requests from clients<br>
102. In other embodiments, the appliance 200 acts as a proxy or access server to provide<br>
access to the one or more servers 106. In another embodiment, the appliance 200 provides a<br>
secure virtual private network connection from a first network 104 of the client 102 to the<br>
second network 104' of the server 106, such as an SSL VPN connection. It yet other<br>
embodiments, the appliance 200 provides application firewall security, control and<br>
management of the connection and communications between a client 102 and a server 106.<br>
In some embodiments, the application delivery management system 190 provides<br>
application delivery techniques to deliver a computing environment to a desktop of a user,<br>
remote or otherwise, based on a plurality of execution methods and based on any<br>
authentication and authorization policies applied via a policy engine 195. With these<br>
techniques, a remote user may obtain a computing environment and access to server stored<br>
applications and data files from any network connected device 100. In one embodiment, the<br>
application delivery system 190 may reside or execute on a server 106. In another<br>
embodiment, the application delivery system 190 may reside or execute on a plurality of<br>
 <br>
servers 106a-106n. In some embodiments, the application delivery system 190 may execute<br>
in a server farm 38. In one embodiment, the server 106 executing the application delivery<br>
system 190 may also store or provide the application and data file. In another embodiment, a<br>
first set of one or more servers 106 may execute the application delivery system 190, and a<br>
different server 106n may store or provide the application and data file. In some<br>
embodiments, each of the application delivery system 190, the application, and data file may<br>
reside or be located on different servers. In yet another embodiment, any portion of the<br>
application delivery system 190 may reside, execute or be stored on or distributed to the<br>
appliance 200, or a plurality of appliances.<br>
The client 102 may include a computing environment 15 for executing an application<br>
that uses or processes a data file. The client 102 via networks 104, 104' and appliance 200<br>
may request an application and data file from the server 106. In one embodiment, the<br>
appliance 200 may forward a request from the client 102 to the server 106. For example, the<br>
client 102 may not have the application and data file stored or accessible locally. In response<br>
to the request, the application delivery system 190 and/or server 106 may deliver the<br>
application and data file to the client 102. For example, in one embodiment, the server 106<br>
may transmit the application as an application stream to operate in computing environment<br>
15 on client 102.<br>
In some embodiments, the application delivery system 190 comprises any portion of<br>
the Citrix Access Suite™ by Citrix Systems, Inc., such as the MetaFrame or Citrix<br>
Presentation Server™ and/or any of the Microsoft® Windows Terminal Services<br>
manufactured by the Microsoft Corporation. In one embodiment, the application delivery<br>
system 190 may deliver one or more applications to clients 102 or users via a remote-display<br>
protocol or otherwise via remote-based or server-based computing. In another embodiment,<br>
the application delivery system 190 may deliver one or more applications to clients or users<br>
via steaming of the application.<br>
 <br>
In one embodiment, the application delivery system 190 includes a policy engine 195<br>
for controlling and managing the access to, selection of application execution methods and<br>
the delivery of applications. In some embodiments, the policy engine 195 determines the one<br>
or more applications a user or client 102 may access. In another embodiment, the policy<br>
engine 195 determines how the application should be delivered to the user or client 102, e.g.,<br>
the method of execution. In some embodiments, the application delivery system 190<br>
provides a plurality of delivery techniques from which to select a method of application<br>
execution, such as a server-based computing, streaming or delivering the application locally<br>
to the client 120 for local execution.<br>
In one embodiment, a client 102 requests execution of an application program and the<br>
application delivery system 190 comprising a server 106 selects a method of executing the<br>
application program. In some embodiments, the server 106 receives credentials from the<br>
client 102. In another embodiment, the server 106 receives a request for an enumeration of<br>
available applications from the client 102. In one embodiment, in response to the request or<br>
receipt of credentials, the application delivery system 190 enumerates a plurality of<br>
application programs available to the client 102. The application delivery system 190<br>
receives a request to execute an enumerated application. The application delivery system 190<br>
selects one of a predetermined number of methods for executing the enumerated application,<br>
for example, responsive to a policy of a policy engine. The application delivery system 190<br>
may select a method of execution of the application enabling the client 102 to receive<br>
application-output data generated by execution of the application program on a server 106.<br>
The application delivery system 190 may select a method of execution of the application<br>
enabling the local machine 10 to execute the application program locally after retrieving a<br>
plurality of application files comprising the application. In yet another embodiment, the<br>
application delivery system 190 may select a method of execution of the application to stream<br>
the application via the network 104 to the client 102.<br>
 <br>
A client 102 may execute, operate or otherwise provide an application, which can be<br>
any type and/or form of software, program, or executable instructions such as any type and/or<br>
form of web browser, web-based client, client-server application, a thin-client computing<br>
client, an ActiveX control, or a Java applet, or any other type and/or form of executable<br>
instructions capable of executing on client 102. In some embodiments, the application may<br>
be a server-based or a remote-based application executed on behalf of the client 102 on a<br>
server 106. In one embodiments the server 106 may display output to the client 102 using<br>
any thin-client or remote-display protocol, such as the Independent Computing Architecture<br>
(ICA) protocol manufactured by Citrix Systems, Inc. of Ft. Lauderdale, Florida or the<br>
Remote Desktop Protocol (RDP) manufactured by the Microsoft Corporation of Redmond,<br>
Washington. The application can use any type of protocol and it can be, for exa.mple, an<br>
HTTP client, an FTP client, an Oscar client, or a Telnet client. In other embodiments, the<br>
application comprises any type of software related to VoIP communications, such as a soft IP<br>
telephone. In further embodiments, the application comprises any application related to real-<br>
time data communications, such as applications for streaming video and/or audio.<br>
In some embodiments, the server 106 or a server farm 38 may be running one or more<br>
applications, such as an application providing a thin-client computing or remote display<br>
presentation application. In one embodiment, the server 106 or server farm 38 executes as an<br>
application, any portion of the Citrix Access Suite™ by Citrix Systems, Inc., such as the<br>
MetaFrame or Citrix Presentation Server™, and/or any of the Microsoft® Windows Terminal<br>
Services manufactured by the Microsoft Corporation. In one embodiment, the application is<br>
an ICA client, developed by Citrix Systems, Inc. of Fort Lauderdale, Florida. In other<br>
embodiments, the application includes a Remote Desktop (RDP) client, developed by<br>
Microsoft Corporation of Redmond, Washington. Also, the server 106 may run an<br>
application, which for example, may be an application server providing email services such<br>
as Microsoft Exchange manufactured by the Microsoft Corporation of Redmond,<br>
 <br>
Washington, a web or Internet server, or a desktop sharing server, or a collaboration server.<br>
In some embodiments, any of the applications may comprise any type of hosted service or<br>
products, such as GoToMeeting™ provided by Citrix Online Division, Inc. of Santa Barbara,<br>
California, WebEx™ provided by WebEx, Inc. of Santa Clara, California, or Microsoft<br>
Office Live Meeting provided by Microsoft Corporation of Redmond, Washington.<br>
The client 102, server 106, and appliance 200 may be deployed as and/or executed on<br>
any type and form of computing device, such as a computer, network device or appliance<br>
capable of communicating on any type and form of network and performing the operations<br>
described herein. FIGs. IC and ID depict block diagrams of a computing device 100 useful<br>
for practicing an embodiment of the client 102, server 106 or appliance 200. As shown in<br>
FIGs. IC and ID, each computing device 100 includes a central processing unit 101, and a<br>
main memory unit 122. As shown in FIG. IC, a computing device 100 may include a visual<br>
display device 124, a keyboard 126 and/or a pointing device 127, such as a mouse. Each<br>
computing device 100 may also include additional optional elements, such as one or more<br>
input/output devices 130a-130b (generally referred to using reference numeral 130), and a<br>
cache memory 140 in communication with the central processing unit 101.<br>
The central processing unit 101 is any logic circuitry that responds to and processes<br>
instructions fetched from the main memory unit 122. In many embodiments, the central<br>
processing unit is provided by a microprocessor unit, such as: those manufactured by Intel<br>
Corporation of Mountain View, California; those manufactured by Motorola Corporation of<br>
Schaumburg, Illinois; those manufactured by Transmeta Corporation of Santa Clara,<br>
California; the RS/6000 processor, those manufactured by International Business Machines<br>
of White Plains, New York; or those manufactured by Advanced Micro Devices of<br>
Sunnyvale, California. The computing device 100 may be based on any of these processors,<br>
or any other processor capable of operating as described herein.<br>
 <br>
Mam memory unit 122 may be one or more memory chips capable of storing data and<br>
allowing any storage location to be directly accessed by the microprocessor 101, such as<br>
Static random access memory (SRAM), Burst SRAM or SynchBurst SRAM (BSRAM),<br>
Dynamic random access memory (DRAM), Fast Page Mode DRAM (FPM DRAM),<br>
Enhanced DRAM (EDRAM), Extended Data Output RAM (EDO RAM), Extended Data<br>
Output DRAM (EDO DRAM), Burst Extended Data Output DRAM (BEDO DRAM),<br>
Enhanced DRAM (EDRAM), synchronous DRAM (SDRAM), JEDEC SRAM, PC100<br>
SDRAM, Double Data Rate SDRAM (DDR SDRAM), Enhanced SDRAM (ESDRAM),<br>
SyncLink DRAM (SLDRAM), Direct Rambus DRAM (DRDRAM), or Ferroelectric RAM<br>
(FRAM). The main memory 122 may be based on any of the above described memory chips,<br>
or any other available memory chips capable of operating as described herein. In the<br>
embodiment shown in FIG. 1C, the processor 101 communicates with main memory 122 via<br>
a system bus 150 (described in more detail below). FIG. 1C depicts an embodiment of a<br>
computing device 100 in which the processor communicates directly with main memory 122<br>
via a memory port 103. For example, in FIG. ID the main memory 122 may be DRDRAM.<br>
FIG. ID depicts an embodiment in which the main processor 101 communicates<br>
directly with cache memory 140 via a secondary bus, sometimes referred to as a backside<br>
bus. In other embodiments, the main processor 101 communicates with cache memory 140<br>
using the system bus 150. Cache memory 140 typically has a faster response time than main<br>
memory 122 and is typically provided by SRAM, BSRAM, or EDRAM. In the embodiment<br>
shown in FIG. 1C, the processor 101 communicates with various I/O devices 130 via a local<br>
system bus 150. Various busses may be used to connect the central processing unit 101 to<br>
any of the I/O devices 130, including a VESA VL bus, an ISA bus, an EISA bus, a<br>
MicroChannel Architecture (MCA) bus, a PCI bus, a PCI-X bus, a PCI-Express bus, or a<br>
NuBus. For embodiments in which the I/O device is a video display 124, the processor 101<br>
may use an Advanced Graphics Port (AGP) to communicate with the display 124. FIG. ID<br>
 <br>
depicts an embodiment of a computer 100 in which the main processor 101 communicates<br>
directly with I/O device 130 via HyperTransport, Rapid I/O, or InfiniBand. FIG. 1D also<br>
depicts an embodiment in which local busses and direct communication are mixed: the<br>
processor 101 communicates with I/O device 130 using a local interconnect bus while<br>
communicating with I/O device 130 directly.<br>
The computing device 100 may support any suitable installation device 116, such as a<br>
floppy disk drive for receiving floppy disks such as 3.5-inch, 5.25-inch disks or ZIP disks, a<br>
CD-ROM drive, a CD-R/RW drive, a DVD-ROM drive, tape drives of various formats, USB<br>
device, hard-drive or any other device suitable for installing software and programs such as<br>
any client agent 120, or portion thereof. The computing device 100 may further comprise a<br>
storage device 128, such as one or more hard disk drives or redundant arrays of independent<br>
disks, for storing an operating system and other related software, and for storing application<br>
software programs such as any program related to the client agent 120. Optionally, any of the<br>
installation devices 116 could also be used as the storage device 128. Additionally, the<br>
operating system and the software can be run from a bootable medium, for example, a<br>
bootable CD, such as KNOPPIX®, a bootable CD for GNU/Linux that is available as a<br>
GNU/Linux distribution from knoppix.net.<br>
Furthermore, the computing device 100 may include a network interface 118 to<br>
interface to a Local Area Network (LAN), Wide Area Network (WAN) or the Internet<br>
through a variety of connections including, but not limited to, standard telephone lines, LAN<br>
or WAN links (e.g., 802.11, Tl, T3, 56kb, X.25), broadband connections (e.g., ISDN, Frame<br>
Relay, ATM), wireless connections, or some combination of any or all of the above. The<br>
network interface 118 may comprise a built-in network adapter, network interface card,<br>
PCMCIA network card, card bus network adapter, wireless network adapter, USB network<br>
adapter, modem or any other device suitable for interfacing the computing device 100 to any<br>
type of network capable of communication and performing the operations described herein.<br>
 <br>
A wide variety of I/O devices 130a-130n may be present in the computing device 100. Input<br>
devices include keyboards, mice, trackpads, trackballs, microphones, and drawing tablets.<br>
Output devices include video displays, speakers, inkjet printers, laser printers, and dye-<br>
sublimation printers. The I/O devices 130 may be controlled by an I/O controller 123 as<br>
shown in FIG. 1C. The I/O controller may control one or more I/O devices such as a<br>
keyboard 126 and a pointing device 127, e.g., a mouse or optical pen. Furthermore, an I/O<br>
device may also provide storage 128 and/or an installation medium 116 for the computing<br>
device 100. In still other embodiments, the computing device 100 may provide USB<br>
connections to receive handheld USB storage devices such as the USB Flash Drive line of<br>
devices manufactured by Twintech Industry, Inc. of Los Alamitos, California.<br>
In some embodiments, the computing device 100 may comprise or be connected to<br>
multiple display devices 124a-124n, which each may be of the same or different type and/or<br>
form. As such, any of the I/O devices 130a-130n and/or the I/O controller 123 may comprise<br>
any type and/or form of suitable hardware, software, or combination of hardware and<br>
software to support, enable or provide for the connection and use of multiple display devices<br>
124a-124n by the computing device 100. For example, the computing device 100 may<br>
include any type and/or form of video adapter, video card, driver, and/or library to interface,<br>
communicate, connect or otherwise use the display devices 124a-124n. In one embodiment, a<br>
video adapter may comprise multiple connectors to interface to multiple display devices<br>
124a-124n. In other embodiments, the computing device 100 may include multiple video<br>
adapters, with each video adapter connected to one or more of the display devices 124a-124n.<br>
In some embodiments, any portion of the operating system of the computing device 100 may<br>
be configured for using multiple displays 124a-124n. In other embodiments, one or more of<br>
the display devices 124a-124n may be provided by one or more other computing devices,<br>
such as computing devices 100a and 100b connected to the computing device 100, for<br>
example, via a network. These embodiments may include any type of software designed and<br>
 <br>
constructed to use another computer's display device as a second display device 124a for the<br>
computing device 100. One ordinarily skilled in the art will recognize and appreciate the<br>
various ways and embodiments that a computing device 100 may be configured to have<br>
multiple display devices 124a-124n.<br>
In further embodiments, an I/O device 130 may be a bridge 170 between the system<br>
bus 150 and an external communication bus, such as a USB bus, an Apple Desktop Bus, an<br>
RS-232 serial connection, a SCSI bus, a Fire Wire bus, a FireWire 800 bus, an Ethernet bus,<br>
an AppleTalk bus, a Gigabit Ethernet bus, an Asynchronous Transfer Mode bus, a HIPPI bus,<br>
a Super HIPPI bus, a SerialPius bus, a SCI/LAMP bus, a FibreChannei bus, or a Serial<br>
Attached small computer system interface bus.<br>
A computing device 100 of the sort depicted in FIGs. 1C and ID typically operate<br>
under the control of operating systems, which control scheduling of tasks and access to<br>
system resources. The computing device 100 can be running any operating system such as<br>
any of the versions of the Microsoft® Windows operating systems, the different releases of<br>
the Unix and Linux operating systems, any version of the Mac OS® for Macintosh<br>
computers, any embedded operating system, any real-time operating system, any open source<br>
operating system, any proprietary operating system, any operating systems for mobile<br>
computing devices, or any other operating system capable of running on the computing<br>
device and performing the operations described herein. Typical operating systems include:<br>
WINDOWS 3.x, WINDOWS 95, WINDOWS 98, WINDOWS 2000, WINDOWS NT 3.51,<br>
WINDOWS NT 4.0, WINDOWS CE, and WINDOWS XP, all of which are manufactured by<br>
Microsoft Corporation of Redmond, Washington; MacOS, manufactured by Apple Computer<br>
of Cupertino, California; OS/2, manufactured by International Business Machines of<br>
Armonk, New York; and Linux, a freely-available operating system distributed by Caldera<br>
Corp. of Salt Lake City, Utah, or any type and/or form of a Unix operating system, among<br>
others.<br>
 <br>
In other embodiments, the computing device 100 may have different processors,<br>
operating systems, and input devices consistent with the device. For example, in one<br>
embodiment the computer 100 is a Treo 180, 270, 1060, 600 or 650 smart phone<br>
manufactured by Palm, Inc. In this embodiment, the Treo smart phone is operated under the<br>
control of the PalmOS operating system and includes a stylus input device as well as a five-<br>
way navigator device. Moreover, the computing device 100 can be any workstation, desktop<br>
computer, laptop or notebook computer, server, handheld computer, mobile telephone, any<br>
other computer, or other form of computing or telecommunications device that is capable of<br>
communication and that has sufficient processor power and memory capacity to perform the<br>
operations described herein.<br>
B. Appliance Architecture<br>
FIG. 2A illustrates an example embodiment of the appliance 200. The architecture of<br>
the appliance 200 in FIG. 2A is provided by way of illustration only and is not intended to be<br>
limiting. As shown in FIG. 2, appliance 200 comprises a hardware layer 206 and a software<br>
layer divided into a user space 202 and a kernel space 204.<br>
Hardware layer 206 provides the hardware elements upon which programs and<br>
services within kernel space 204 and user space 202 are executed. Hardware layer 206 also<br>
provides the structures and elements which allow programs and services within kernel space<br>
204 and user space 202 to communicate data both internally and externally with respect to<br>
appliance 200. As shown in FIG. 2, the hardware layer 206 includes a processing unit 262<br>
for executing software programs and services, a memory 264 for storing software and data,<br>
network ports 266 for transmitting and receiving data over a network, and an encryption<br>
processor 260 for performing functions related to Secure Sockets Layer processing of data<br>
transmitted and received over the network. In some embodiments, the central processing unit<br>
262 may perform the functions of the encryption processor 260 in a single processor.<br>
 <br>
Additionally, the hardware layer 206 may comprise multiple processors for each of the<br>
processing unit 262 and the encryption processor 260. The processor 262 may include any of<br>
the processors 101 described above in connection with FIGs. 1C and ID. In some<br>
embodiments, the central processing unit 262 may perform the functions of the encryption<br>
processor 260 in a single processor. Additionally, the hardware layer 206 may comprise<br>
multiple processors for each of the processing unit 262 and the encryption processor 260. For<br>
example, in one embodiment, the appliance 200 comprises a first processor 262 and a second<br>
processor 262'. In other embodiments, the processor 262 or 262' comprises a multi-core<br>
processor.<br>
Although the hardware layer 206 of appliance 200 is generally illustrated with an<br>
encryption processor 260, processor 260 may be a processor for performing functions related<br>
to any encryption protocol, such as the Secure Socket Layer (SSL) or Transport Layer<br>
Security (TLS) protocol. In some embodiments, the processor 260 may be a general purpose<br>
processor (GPP), and in further embodiments, may be have executable instructions for<br>
performing processing of any security related protocol.<br>
Although the hardware layer 206 of appliance 200 is illustrated with certain elements<br>
in FIG. 2, the hardware portions or components of appliance 200 may comprise any type and<br>
form of elements, hardware or software, of a computing device, such as the computing device<br>
100 illustrated and discussed herein in conjunction with FIGs. 1C and ID. In some<br>
embodiments, the appliance 200 may comprise a server, gateway, router, switch, bridge or<br>
other type of computing or network device, and have any hardware and/or software elements<br>
associated therewith.<br>
The operating system of appliance 200 allocates, manages, or otherwise segregates<br>
the available system memory into kernel space 204 and user space 204. In example software<br>
architecture 200, the operating system may be any type and/or form of Unix operating system<br>
although the invention is not so limited. As such, the appliance 200 can be running any<br>
 <br>
operating system such as any of the versions of the Microsoft® Windows operating systems,<br>
the different releases of the Unix and Linux operating systems, any version of the Mac OS®<br>
for Macintosh computers, any embedded operating system, any network operating system,<br>
any real-time operating system, any open source operating system, any proprietary operating<br>
system, any operating systems for mobile computing devices or network devices, or any other<br>
operating system capable of running on the appliance 200 and performing the operations<br>
described herein.<br>
The kernel space 204 is reserved for running the kernel 230, including any device<br>
drivers, kernel extensions or other kernel related software. As known to those skilled in the<br>
art, the kernel 230 is the core of the operating system, and provides access, control, and<br>
management of resources and hardware-related elements of the application 104. In<br>
accordance with an embodiment of the appliance 200, the kernel space 204 also includes a<br>
number of network services or processes working in conjunction with a cache manager 232.<br>
sometimes also referred to as the integrated cache, the benefits of which are described in<br>
detail further herein. Additionally, the embodiment of the kernel 230 will depend on the<br>
embodiment of the operating system installed, configured, or otherwise used by the device<br>
200.<br>
In one embodiment, the device 200 comprises one network stack 267, such as a<br>
TCP/IP based stack, for communicating with the client 102 and/or the server 106. In one<br>
embodiment, the network stack 267 is used to communicate with a first network, such as<br>
network 108, and a second network 110. In some embodiments, the device 200 terminates a<br>
first transport layer connection, such as a TCP connection of a client 102, and establishes a<br>
second transport layer connection to a server 106 for use by the client 102, e.g., the second<br>
transport layer connection is terminated at the appliance 200 and the server 106. The first<br>
and second transport layer connections may be established via a single network stack 267. In<br>
other embodiments, the device 200 may comprise multiple network stacks, for example 267<br>
 <br>
and 267', and the first transport layer connection may be established or terminated at one<br>
network stack 267, and the second transport layer connection on the second network stack<br>
267'. For example, one network stack may be for receiving and transmitting network packet<br>
on a first network, and another network stack for receiving and transmitting network packets<br>
on a second network. Tn one embodiment, the network stack 267 comprises a buffer 243 for<br>
queuing one or more network packets for transmission by the appliance 200.<br>
As shown in FIG. 2, the kernel space 204 includes the cache manager 232, a high-<br>
speed layer 2-7 integrated packet engine 240, an encryption engine 234, a policy engine 236<br>
and multi-protocol compression logic 238. Running these components or processes 232,<br>
240, 234, 236 and 238 in kernel space 204 or kernel mode instead of the user space 202<br>
improves the performance of each of these components, alone and in combination. Kernel<br>
operation means that these components or processes 232, 240, 234, 236 and 238 run in the<br>
core address space of the operating system of the device 200. For example, running the<br>
encryption engine 234 in kernel mode improves encryption performance by moving<br>
encryption and decryption operations to the kernel, thereby reducing the number of<br>
transitions between the memory space or a kernel thread in kernel mode and the memory<br>
space or a thread in user mode. For example, data obtained in kernel mode may not need to<br>
be passed or copied to a process or thread running in user mode, such as from a kernel level<br>
data structure to a user level data structure. In another aspect, the number of context switches<br>
between kernel mode and user mode are also reduced. Additionally, synchronization of and<br>
communications between any of the components or processes 232, 240, 235, 236 and 238 can<br>
be performed more efficiently in the kernel space 204.<br>
In some embodiments, any portion of the components 232, 240, 234, 236 and 238<br>
may run or operate in the kernel space 204, while other portions of these components 232,<br>
240, 234, 236 and 238 may run or operate in user space 202. In one embodiment, the<br>
appliance 200 uses a kernel-level data structure providing access to any portion of one or<br>
 <br>
more network packets, for example, a network packet comprising a request from a client 102<br>
or a response from a server 106. In some embodiments, the kernel-level data structure may<br>
be obtained by the packet engine 240 via a transport layer driver interface or filter to the<br>
network stack 267. The kernel-level data structure may comprise any interface and/or data<br>
accessible via the kernel space 204 related to the network stack 267, network traffic or<br>
packets received or transmitted by the network stack 267. In other embodiments, the kernel-<br>
level data structure maybe used by any of the components or processes 232, 240, 234, 236<br>
and 238 to perform the desired operation of the component or process. In one embodiment, a<br>
component 232, 240, 234, 236 and 238 is running in kernel mode 204 when using the kernel-<br>
level data structure, while in another embodiment, the component 232, 240, 234, 236 and 238<br>
is running in user mode when using the kernel-level data structure. In some embodiments,<br>
the kernel-level data structure may be copied or passed to a second kernel-level data<br>
structure, or any desired user-level data structure.<br>
The cache manager 232 may comprise software, hardware or any combination of<br>
software and hardware to provide cache access, control and management of any type and<br>
form of content, such as objects or dynamically generated objects served by the originating<br>
servers 106. The data, objects or content processed and stored by the cache manager 232<br>
may comprise data in any format, such as a markup language, or communicated via any<br>
protocol. In some embodiments, the cache manager 232 duplicates original data stored<br>
elsewhere or data previously computed, generated or transmitted, in which the original data<br>
may require longer access time to fetch, compute or otherwise obtain relative to reading a<br>
cache memory element. Once the data is stored in the cache memory element, future use can<br>
be made by accessing the cached copy rather than refetching or recomputing the original<br>
data, thereby reducing the access time. In some embodiments, the cache memory element nat<br>
comprise a data object in memory 264 of device 200. In other embodiments, the cache<br>
memory element may comprise memory having a faster access time than memory 264. In<br>
 <br>
another embodiment, the cache memory element may comrpise any type and form of storage<br>
element of the device 200, such as a portion of a hard disk. Tn some embodiments, the<br>
processing unit 262 may provide cache memory for use by the cache manager 232. In yet<br>
further embodiments, the cache manager 232 may use any portion and combination of<br>
memory, storage, or the processing unit for caching data, objects, and other content.<br>
Furthermore, the cache manager 232 includes any logic, functions, rules, or<br>
operations to perform any embodiments of the techniques of the appliance 200 described<br>
herein. For example, the cache manager 232 includes logic or functionality to invalidate<br>
objects based on the expiration of an invalidation time period or upon receipt of an<br>
invalidation command from a client 102 or server 106. In some embodiments, the cache<br>
manager 232 may operate as a program, service, process or task executing in the kernel space<br>
204, and in other embodiments, in the user space 202. In one embodiment, a first portion of<br>
the cache manager 232 executes in the user space 202 while a second portion executes in the<br>
kernel space 204. In some embodiments, the cache manager 232 can comprise any type of<br>
general purpose processor (GPP), or any other type of integrated circuit, such as a Field<br>
Programmable Gate Array (FPGA), Programmable Logic Device (PLD), or Application<br>
Specific Integrated Circuit (ASIC).<br>
The policy engine 236 may include, for example, an intelligent statistical engine or<br>
other programmable application(s). In one embodiment, the policy engine 236 provides a<br>
configuration mechanism to allow a user to identifying, specify, define or configure a caching<br>
policy. Policy engine 236, in some embodiments, also has access to memory to support data<br>
structures such as lookup tables or hash tables to enable user-selected caching policy<br>
decisions. In other embodiments, the policy engine 236 may comprise any logic, rules,<br>
functions or operations to determine and provide access, control and management of objects,<br>
data or content being cached by the appliance 200 in addition to access, control and<br>
management of security, network traffic, network access, compression or any other function<br>
 <br>
or operation performed by the appliance 200. Further examples of specific caching policies<br>
are further described herein.<br>
The encryption engine 234 comprises any logic, business rules, functions or<br>
operations for handling the processing of any security related protocol, such as SSL or TLS,<br>
or any function related thereto. For example, the encryption engine 234 encrypts and<br>
decrypts network packets, or any portion thereof, communicated via the appliance 200. The<br>
encryption engine 234 may also setup or establish SSL or TLS connections on behalf of the<br>
client 102a-102n, server 106a-106n, or appliance 200. As such, the encryption engine 234<br>
provides offloading and acceleration of SSL processing. In one embodiment, the encryption<br>
engine 234 uses a tunneling protocol to provide a virtual private network between a client<br>
102a-102n and a server 106a-106n. In some embodiments, the encryption engine 234 is in<br>
communication with the Encryption processor 260. In other embodiments, the encryption<br>
engine 234 comprises executable instructions running on the Encryption processor 260.<br>
The multi-protocol compression engine 238 comprises any logic, business rules,<br>
function or operations for compressing one or more protocols of a network packet, such as<br>
any of the protocols used by the network stack 267 of the device 200. In one embodiment,<br>
multi-protocol compression engine 238 compresses bi-directionally between clients 102a-<br>
102n and servers 106a-106n any TCP/IP based protocol, including Messaging Application<br>
Programming Interface (MAPI) (email), File Transfer Protocol (FTP), HyperText Transfer<br>
Protocol (HTTP), Common Internet File System (CIFS) protocol (file transfer), Independent<br>
Computing Architecture (ICA) protocol, Remote Desktop Protocol (RDP), Wireless<br>
Application Protocol (WAP), Mobile IP protocol, and Voice Over IP (VoIP) protocol. In<br>
other embodiments, multi-protocol compression engine 238 provides compression of<br>
Hypertext Markup Language (HTML) based protocols and in some embodiments, provides<br>
compression of any markup languages, such as the Extensible Markup Language (XML). In<br>
one embodiment, the multi-protocol compression engine 238 provides compression of any<br>
 <br>
high-performance protocol, such as any protocol designed for appliance 200 to appliance 200<br>
communications. In another embodiment, the multi-protocol compression engine 238<br>
compresses any pay load of or any communication using a modified transport control<br>
protocol, such as Transaction TCP (T/TCP), TCP with selection acknowledgements (TCP-<br>
SACK), TCP with large windows (TCP-LW), a congestion prediction protocol such as the<br>
TCP-Vegas protocol, and a TCP spoofing protocol.<br>
As such, the multi-protocol compression engine 238 accelerates performance for users<br>
accessing applications via desktop clients, e.g., Microsoft Outlook and non-Web thin clients,<br>
such as any client launched by popular enterprise applications like Oracle, SAP and Siebel,<br>
and even mobile clients, such as the Pocket PC. In some embodiments, the multi-protocol<br>
compression engine 238 by executing in the kernel mode 204 and integrating with packet<br>
processing engine 240 accessing the network stack 267 is able to compress any of the<br>
protocols canned by the TCP/IP protocol, such as any application layer protocol.<br>
High speed layer 2-7 integrated packet engine 240, also generally referred to as a<br>
packet processing engine or packet engine, is responsible for managing the kernel-level<br>
processing of packets received and transmitted by appliance 200 via network ports 266. The<br>
high speed layer 2-7 integrated packet engine 240 may comprise a buffer for queuing one or<br>
more network packets during processing, such as for receipt of a network packet or<br>
transmission of a network packer. Additionally, the high speed layer 2-7 integrated packet<br>
engine 240 is in communication with one or more network stacks 267 to send and receive<br>
network packets via network ports 266. The high speed layer 2-7 integrated packet engine<br>
240 works in conjunction with encryption engine 234, cache manager 232, policy engine 236<br>
and multi-protocol compression logic 238. In particular, encryption engine 234 is configured<br>
to perform SSL processing of packets, policy engine 236 is configured to perform functions<br>
related to traffic management such as request-level content switching and request-level cache<br>
 <br>
redirection, and multi-protocol compression logic 238 is configured to perform functions<br>
related to compression and decompression of data.<br>
The high speed layer 2-7 integrated packet engine 240 includes a packet processing<br>
timer 242. In one embodiment, the packet processing timer 242 provides one or more time<br>
intervals to trigger the processing of incoming, i.e., received, or outgoing, i.e., transmitted,<br>
network packets. In some embodiments, the high speed layer 2-7 integrated packet engine<br>
240 processes network packets responsive to the timer 242. The packet processing timer 242<br>
provides any type and form of signal to the packet engine 240 to notify, trigger, or<br>
communicate a time related event, interval or occurrence. In many embodiments, the packet<br>
processing timer 242 operates in the order of milliseconds, such as for example 100ms, 50ms<br>
or 25ms. For example, in some embodiments, the packet processing timer 242 provides time<br>
intervals or otherwise causes a network packet to be processed by the high speed layer 2-7<br>
integrated packet engine 240 at a 10 ms time interval, while in other embodiments, at a 5 ms<br>
time interval, and still yet in further embodiments, as short as a 3, 2, or 1 ms time interval.<br>
The high speed layer 2-7 integrated packet engine 240 may be interfaced, integrated or in<br>
communication with the encryption engine 234, cache manager 232, policy engine 236 and<br>
multi-protocol compression engine 238 during operation. As such, any of the logic,<br>
functions, or operations of the encryption engine 234, cache manager 232, policy engine 236<br>
and multi-protocol compression logic 238 may be performed responsive to the packet<br>
processing timer 242 and/or the packet engine 240. Therefore, any of the logic, functions, or<br>
operations of the encryption engine 234, cache manager 232, policy engine 236 and multi-<br>
protocol compression logic 238 may be performed at the granularity of time intervals<br>
provided via the packet processing timer 242, for example, at a time interval of less than or<br>
equal to 10ms. For example, in one embodiment, the cache manager 232 may perform<br>
invalidation of any cached objects responsive to the high speed layer 2-7 integrated packet<br>
engine 240 and/or the packet processing timer 242. In another embodiment, the expiry or<br>
 <br>
invalidation time of a cached object can be set to the same order of granularity as the time<br>
interval of the packet processing timer 242, such as at every 10 ms.<br>
In contrast to kernel space 204, user space 202 is the memory area or portion of the<br>
operating system used by user mode applications or programs otherwise running in user<br>
mode. A user mode application may not access kernel space 204 directly and uses service<br>
calls in order to access kernel services. As shown in FIG. 2, user space 202 of appliance 200<br>
includes a graphical user interface (GUI) 210, a command line interface (CLI) 212, shell<br>
services 214, health monitoring program 216, and daemon services 218. GUI 210 and CLI<br>
212 provide a means by which a system administrator or other user can interact with and<br>
control the operation of appliance 200, such as via the operating system of the appliance 200<br>
and either is user space 202 or kernel space 204. The GUI 210 may be any type and form of<br>
graphical user interface and may be presented via text, graphical or otherwise, by any type of<br>
program or application, such as a browser. The CLI 212 may be any type and form of<br>
command line or text-based interface, such as a command line provided by the operating<br>
system. For example, the CLI 212 may comprise a shell, which is a tool to enable users to<br>
interact with the operating system. In some embodiments, the CLI 212 may be provided via a<br>
bash, csh, tcsh, or ksh type shell. The shell services 214 comprises the programs, services,<br>
tasks, processes or executable instructions to support interaction with the appliance 200 or<br>
operating system by a user via the GUI 210 and/or CLI 212.<br>
Health monitoring program 216 is used to monitor, check, report and ensure that<br>
network systems are functioning properly and that users are receiving requested content over<br>
a network. Health monitoring program 216 comprises one or more programs, services, tasks,<br>
processes or executable instructions to provide logic, rules, functions or operations for<br>
monitoring any activity of the appliance 200. In some embodiments, the health, monitoring<br>
program 216 intercepts and inspects any network traffic passed via the appliance 200. In<br>
other embodiments, the health monitoring program 216 interfaces by any suitable means<br>
 <br>
and/or mechanisms with one or more of the following: the encryption engine 234, cache<br>
manager 232, policy engine 236, multi-protocol compression logic 238, packet engine 240,<br>
daemon services 218, and shell services 214. As such, the health monitoring program 216<br>
may call any application programming interface (API) to determine a state, status, or health<br>
of any portion of the appliance 200. For example, the health monitoring program 216 may<br>
ping or send a status inquiry on a periodic basis to check if a program, process, service or task<br>
is active and currently running. In another example, the health monitoring program 216 may<br>
check any status, error or history logs provided by any program, process, service or task to<br>
determine any condition, status or error with any portion of the appliance 200.<br>
Daemon services 218 are programs that run continuously or in the background and<br>
handle periodic service requests received by appliance 200. In some embodiments, a daemon<br>
service may forward the requests to other programs or processes, such as another daemon<br>
service 218 as appropriate. As known to those skilled in the art, a daemon service 218 may<br>
run unattended to perform continuous or periodic system wide functions, such as network<br>
control, or to perform any desired task. In some embodiments, one or more daemon services<br>
218 run in the user space 202, while in other embodiments, one or more daemon services 218<br>
run in the kernel space.<br>
Referring now to FIG. 2B, another embodiment of the appliance 200 is depicted. In<br>
brief overview, the appliance 200 provides one or more of the following services,<br>
functionality or operations: SSL VPN connectivity 280, switching/load balancing 284,<br>
Domain Name Service resolution 286, acceleration 288 and an application firewall 290 for<br>
communications between one or more clients 102 and one or more servers 106. In one<br>
embodiment, the appliance 200 comprises any of the network devices manufactured by Citrix<br>
Systems, Inc. of Ft. Lauderdale Florida, referred to as Citrix NetScaler devices. Each of the<br>
servers 106 may provide one or more network related services 270a-270n (referred to as<br>
services 270). For example, a server 106 may provide an http service 270. The appliance<br>
 <br>
200 comprises one or more virtual servers or virtual internet protocol servers, referred to as a<br>
vServer, VIP server, or just VIP 275a-275n (also referred herein as vServer 275). The<br>
vServer 275 receives, intercepts or otherwise processes communications between a client 102<br>
and a server 106 in accordance with the configuration and operations of the appliance 200.<br>
The vServer 275 may comprise software, hardware or any combination of software<br>
and hardware. The vServer 275 may comprise any type and form of program, service, task,<br>
process or executable instructions operating in user mode 202, kernel mode 204 or any<br>
combination thereof in the appliance 200. The vServer 275 includes any logic, functions,<br>
rules, or operations to perform any embodiments of the techniques described herein, such as<br>
SSL VPN 280, switching/load balancing 284, Domain Name Service resolution 286,<br>
acceleration 288 and an application firewall 290. In some embodiments, the vServer 275<br>
establishes a connection to a service 270 of a server 106. The service 275 may comprise any<br>
program, application, process, task or set of executable instructions capable of connecting to<br>
and communicating to the appliance 200, client 102 or vServer 275. For example, the service<br>
275 may comprise a web server, http server, ftp, email or database server. In some<br>
embodiments, the service 270 is a daemon process or network driver for listening, receiving<br>
and/or sending communications for an application, such as email, database or an enterprise<br>
application. In some embodiments, the service 270 may communicate on a specific IP<br>
address, or IP address and port.<br>
In some embodiments, the vServer 275 applies one or more policies of the policy<br>
engine 236 to network communications between the client 102 and server 106. In one<br>
embodiment, the policies are associated with a VServer 275. In another embodiment, the<br>
policies are based on a user, or a group of users. In yet another embodiment, a policy is<br>
global and applies to one or more vServers 275a-275n, and any user or group of users<br>
communicating via the appliance 200. In some embodiments, the policies of the policy<br>
engine have conditions upon which the policy is applied based on any content of the<br>
 <br>
communication, such as internet protocol address, port, protocol type, header or fields in a<br>
packet, or the context of the communication, such as user, group of the user, vServer 275,<br>
transport layer connection, and/or identification or attributes of the client 102 or server 106.<br>
In other embodiments, the appliance 200 communicates or interfaces with the policy<br>
engine 236 to determine authentication and/or authorization of a remote user or a remote<br>
client 102 to access the computing environment 15, application, and/or data file from a server<br>
106. In another embodiment, the appliance 200 communicates or interfaces with the policy<br>
engine 236 to determine authentication and/or authorization of a remote user or a remote<br>
client 102 to have the application delivery system 190 deliver one or more of the computing<br>
environment 15, application, and/or data file. In yet another embodiment, the appliance 200<br>
establishes a VPN or SSL VPN connection based on the policy engine's 236 authentication<br>
and/or authorization of a remote user or a remote client 103 In one embodiment, the<br>
appliance 102 controls the flow of network traffic and communication sessions based on<br>
policies of the policy engine 236. For example, the appliance 200 may control the access to<br>
a computing environment 15, application or data file based on the policy engine 236.<br>
In some embodiments, the vServer 275 establishes a transport layer connection, such<br>
as a TCP or UDP connection with a client 102 via the client agent 120. In one embodiment,<br>
the vServer 275 listens for and receives communications from the client 102. In other<br>
embodiments, the vServer 275 establishes a transport layer connection, such as a TCP or<br>
UDP connection with a client server 106. In one embodiment, the vServer 275 establishes<br>
the transport layer connection to an internet protocol address and port of a server 270 running<br>
on the server 106. In another embodiment, the vServer 275 associates a first transport layer<br>
connection to a client 102 with a second transport layer connection to the server 106. In<br>
some embodiments, a vServer 275 establishes a pool of tranport layer connections to a server<br>
106 and multiplexes client requests via the pooled transport layer connections.<br>
 <br>
In some embodiments, the appliance 200 provides a SSL VPN connection 280<br>
between a client 102 and a server 106. For example, a client 102 on a first network 102<br>
requests to establish a connection to a server 106 on a second network 104'. In some<br>
embodiments, the second network 104' is not routable from the first network 104. In other<br>
embodiments, the client 102 is on a public network 104 and the server 106 is on a private<br>
network 104', such as a corporate network. In one embodiment, the client agent 120<br>
intercepts communications of the client 102 on the first network 104, encrypts the<br>
communications, and transmits the communications via a first transport layer connection to<br>
the appliance 200. The appliance 200 associates the first transport layer connection on the<br>
first network 104 to a second transport layer connection to the server 106 on the second<br>
network 104. The appliance 200 receives the intercepted communication from the client<br>
agent 102, decrypts the communications, and transmits the communication to the server 106<br>
on the second network 104 via the second transport layer connection. The second transport<br>
layer connection may be a pooled transport layer connection. As such, the appliance 200<br>
provides an end-to-end secure transport layer connection for the client 102 between the two<br>
networks 104, 104'.<br>
In one embodiment, the appliance 200 hosts an intranet internet protocol or intranetIP<br>
282 address of the client 102 on the virtual private network 104. The client 102 has a local<br>
network identifier, such as an internet protocol (IP) address and/or host name on the first<br>
network 104. When connected to the second network 104' via the appliance 200, the<br>
appliance 200 establishes, assigns or otherwise provides an IntranetIP, which is network<br>
identifier, such as IP address and/or host name, for the client 102 on the second network 104'.<br>
The appliance 200 listens for and receives on the second or private network 104' for any<br>
communications directed towards the client 102 using the client's established IntranetIP 282.<br>
In one embodiment, the appliance 200 acts as or on behalf of the client 102 on the second<br>
private network 104. For example, in another embodiment, a vServer 275 listens for and<br>
 <br>
responds to communications to the IntranetIP 282 of the client 102. In some embodiments, if<br>
a computing device 100 on the second network 104' transmits a request, the appliance 200<br>
processes the request as if it were the client 102. For example, the appliance 200 may<br>
respond to a ping to the client's IntranetIP 282. In another example, the appliance may<br>
establish a connection, such as a TCP or UDP connection, with computing device 100 on the<br>
second network 104 requesting a connection with the client's IntranetIP 282.<br>
In some embodiments, the appliance 200 provides one or more of the following<br>
acceleration techniques 288 to communications between the client 102 and server 106: 1)<br>
compression; 2) decompression; 3) Transmission Control Protocol pooling; 4) Transmission<br>
Control Protocol multiplexing; 5) Transmission Control Protocol buffering; and 6) caching.<br>
In one embodiment, the appliance 200 relieves servers 106 of much of the processing load<br>
caused by repeatedly opening and closing transport layers connections to clients 102 by<br>
opening one or more transport layer connections with each server 106 and maintaining these<br>
connections to allow repeated data accesses by clients via the Internet. This technique is<br>
referred to herein as "connection pooling".<br>
In some embodiments, in order to seamlessly splice communications from a client<br>
102 to a server 106 via a pooled transport layer connection, the appliance 200 translates or<br>
multiplexes communications by modifying sequence number and acknowledgment numbers<br>
at the transport layer protocol level. This is referred to as "connection multiplexing". In some<br>
embodiments, no application layer protocol interaction is required. For example, in the case<br>
of an in-bound packet (that is, a packet received from a client 102), the source network<br>
address of the packet is changed to that of an output port of appliance 200, and the destination<br>
network address is changed to that of the intended server. In the case of an outbound packet<br>
(that is, one received from a server 106), the source network address is changed from that of<br>
the server 106 to that of an output port of appliance 200 and the destination address is<br>
changed from that of appliance 200 to that of the requesting client 102. The sequence<br>
 <br>
numbers and acknowledgment numbers of the packet are also translated to sequence numbers<br>
and acknowledgement expected by the client 102 on the appliance's 200 transport layer<br>
connection to the client 102. In some embodiments, the packet checksum of the transport<br>
layer protocol is recalculated to account for these translations.<br>
In another embodiment, the appliance 200 provides switching or load-balancing<br>
functionality 284 for communications between the client 102 and server 106. In some<br>
embodiments, the appliance 200 distributes traffic and directs client requests to a server 106<br>
based on layer 4 or application-layer request data. In one embodiment, although the network<br>
layer or layer 2 of the network packet identifies a destination server 106, the appliance 200<br>
determines the server 106 to distribute the network packet by application information and<br>
data carried as payload of the transport layer packet. In one embodiment, the health<br>
monitoring programs 216 of the appliance 200 monitor the health of servers to determine the<br>
server 106 for which to distribute a client's request. In some embodiments, if the appliance<br>
200 detects a server 106 is not available or has a load over a predetermined threshold, the<br>
appliance 200 can direct or distribute client requests to another server 106.<br>
In some embodiments, the appliance 200 acts as a Domain Name Service (DNS)<br>
resolver or otherwise provides resolution of a DNS request from clients 102. In some<br>
embodiments, the appliance intercepts' a DNS request transmitted by the client 102. In one<br>
embodiment, the appliance 200 responds to a client's DNS request with an IP address of or<br>
hosted by the appliance 200. In this embodiment, the client 102 transmits network<br>
communication for the domain name to the appliance 200. In another embodiment, the<br>
appliance 200 responds to a client's DNS request with an IP address of or hosted by a second<br>
appliance 200'. In some embodiments, the appliance 200 responds to a client's DNS request<br>
with an IP address of a server 106 determined by the appliance 200.<br>
In yet another embodiment, the appliance 200 provides application firewall<br>
functionality 290 for communications between the client 102 and server 106. In one<br>
 <br>
embodiment, the policy engine 236 provides rules for detecting and blocking illegitimate<br>
requests. In some embodiments, the application firewall 290 protects against denial of<br>
service (DoS) attacks. In other embodiments, the appliance inspects the content of intercepted<br>
requests to identify and block application-based attacks. In some embodiments, the<br>
rules/policy engine 236 comprises one or more application firewall or security control<br>
policies for providing protections against various classes and types of web or Internet based<br>
vulnerabilities, such as one or more of the following: 1) buffer overflow, 2) CGI-BIN<br>
parameter manipulation, 3) form/hidden field manipulation, 4) forceful browsing, 5) cookie<br>
or session poisoning, 6) broken access control list (ACLs) or weak passwords, 7) cross-site<br>
scripting (XSS), 8) command injection, 9) SQL injection, 10) error triggering sensitive<br>
information leak, 11) insecure use of cryptography, 12) server misconfiguration, 13) back<br>
doors and debug options, 14) website defacement, 15) platform or operating systems<br>
vulnerabilities, and 16) zero-day exploits. In an embodiment, the application firewall 290<br>
provides HTML form field protection in the form of inspecting or analyzing the network<br>
communication for one or more of the following: 1) required fields are returned, 2) no added<br>
field allowed, 3) read-only and hidden field enforcement, 4) drop-down list and radio button<br>
field conformance, and 5) form-field max-length enforcement. In some embodiments, the<br>
application firewall 290 ensures cookies are not modified. In other embodiments, the<br>
application firewall 290 protects against forceful browsing by enforcing legal URLs.<br>
In still yet other embodiments, the application firewall 290 protects any confidential<br>
information contained in the network communication. The application firewall 290 may<br>
inspect or analyze any network communication in accordance with the rules or polices of the<br>
engine 236 to identify any confidential information in any field of the network packet. In<br>
some embodiments, the application firewall 290 identifies in the network communication one<br>
or more occurrences of a credit card number, password, social security number, name, patient<br>
code, contact information, and age. The encoded portion of the network communication may<br>
 <br>
comprise these occurrences or the confidential information. Based on these occurrences, in<br>
one embodiment, the application firewall 290 may take a policy action on the network<br>
communication, such as prevent transmission of the network communication. In another<br>
embodiment, the application firewall 290 may rewrite, remove or otherwise mask such<br>
identified occurrence or confidential information.<br>
C. Client Agent<br>
Referring now to FIG. 3, an embodiment of the client agent 120 is depicted. The<br>
client 102 includes a client agent 120 for establishing and exchanging communications with<br>
the appliance 200 and/or server 106 via a network 104. In brief overview, the client 102<br>
operates on computing device 100 having an operating system with a kernel mode 302 and a<br>
user mode 303, and a network stack 310 with one or more layers 310a-310b. The client 102<br>
may have installed and/or execute one or more applications. In some embodiments, one or<br>
more applications may communicate via the network stack 310 to a network 104. One of the<br>
applications, such as a web browser, may also include a first program 322. For example, the<br>
first program 322 may be used in some embodiments to install and/or execute the client agent<br>
120, or any portion thereof. The client agent 120 includes an interception mechanism, or<br>
interceptor 350, for intercepting network communications from the network stack 310 from<br>
the one or more applications.<br>
The network stack 310 of the client 102 may comprise any type and form of software,<br>
or hardware, or any combinations thereof, for providing connectivity to and communications<br>
with a network. In one embodiment, the network stack 310 comprises a software<br>
implementation for a network protocol suite. The network stack 310 may comprise one or<br>
more network layers, such as any networks layers of the Open Systems Interconnection (OSI)<br>
communications model as those skilled in the art recognize and appreciate. As such, the<br>
 <br>
network stack 310 may comprise any type and form of protocols for any of the following<br>
layers of the OS1 model: 1) physical link layer, 2) data link layer, 3) network layer, 4)<br>
transport layer, 5) session layer, 6) presentation layer, and 7) application layer. In one<br>
embodiment, the network stack 310 may comprise a transport control protocol (TCP) over the<br>
network layer protocol of the internet protocol (TP), generally referred to as TCP/IP. In some<br>
embodiments, the TCP/IP protocol may be carried over the Ethernet protocol, which may<br>
comprise any of the family of IEEE wide-area-network (WAN) or local-area-network (LAN)<br>
protocols, such as those protocols covered by the IEEE 802.3. In some embodiments, the<br>
network stack 310 comprises any type and form of a wireless protocol, such as IEEE 802.11<br>
and/or mobile internet protocol.<br>
In view of a TCP/IP based network, any TCP/IP based protocol may be used,<br>
including Messaging Application Programming Interface (MAPI) (email), File Transfer<br>
Protocol (FTP), HyperText Transfer Protocol (HTTP), Common Internet File System (CIFS)<br>
protocol (file transfer), Independent Computing Architecture (ICA) protocol, Remote<br>
Desktop Protocol (RDP), Wireless Application Protocol (WAP), Mobile IP protocol, and<br>
Voice Over IP (VoIP) protocol. In another embodiment, the network stack 310 comprises<br>
any type and form of transport control protocol, such as a modified transport control protocol,<br>
for example a Transaction TCP (T/TCP), TCP with selection acknowledgements (TCP-<br>
SACK), TCP with large windows (TCP-LW), a congestion prediction protocol such as the<br>
TCP-Vegas protocol, and a TCP spoofing protocol. In other embodiments, any type and<br>
form of user datagram protocol (UDP), such as UDP over IP, may be used by the network<br>
stack 310, such as for voice communications or real-time data communications.<br>
Furthermore, the network stack 310 may include one or more network drivers<br>
supporting the one or more layers, such as a TCP driver or a network layer driver. The<br>
network drivers may be included as part of the operating system of the computing device 100<br>
or as part of any network interface cards or other network access components of the<br>
 <br>
computing device 100. In some embodiments, any of the network drivers of the network<br>
stack 310 may be customized, modified or adapted to provide a custom or modified portion<br>
of the network stack 310 in support of any of the techniques described herein. In other<br>
embodiments, the acceleration program 120 is designed and constructed to operate with or<br>
work in conjunction with the network stack 310 installed or otherwise provided by the<br>
operating system of the client 102.<br>
The network stack 310 comprises any type and form of interfaces for receiving,<br>
obtaining, providing or otherwise accessing any information and data related to network<br>
communications of the client 102. In one embodiment, an interface to the network stack 310<br>
comprises an application programming interface (API). The interface may also comprise any<br>
function call, hooking or filtering mechanism, event or call back mechanism, or any type of<br>
interfacing technique. The network stack 310 via the interface may receive or provide any<br>
type and form of data structure, such as an object, related to functionality or operation of the<br>
network stack 310. For example, the data structure may comprise information and data<br>
related to a network packet or one or more network packets. In some embodiments, the data<br>
structure comprises a portion of the network packet processed at a protocol layer of the<br>
network stack 310, such as a network packet of the transport layer. In some embodiments,<br>
the data structure 325 comprises a kernel-level data structure, while in other embodiments,<br>
the data structure 325 comprises a user-mode data structure. A kernel-level data structure<br>
may comprise a data structure obtained or related to a portion of the network stack 310<br>
operating in kernel-mode 302, or a network driver or other software running in kernel-mode<br>
302, or any data structure obtained or received by a service, process, task, thread or other<br>
executable instructions running or operating in kernel-mode of the operating system.<br>
Additionally, some portions of the network stack 310 may execute or operate in<br>
kernel-mode 302, for example, the data link or network layer, while other portions execute or<br>
operate in user-mode 303, such as an application layer of the network stack 310. For<br>
 <br>
example, a first portion 310a of the network stack may provide user-mode access to the<br>
network stack 310 to an application while a second portion 310a of the network stack 310<br>
provides access to a network. In some embodiments, a first portion 310a of the network stack<br>
may comprise one or more upper layers of the network stack 310, such as any of layers 5-7.<br>
In other embodiments, a second portion 31 Ob of the network stack 310 comprises one or<br>
more lower layers, such as any of layers 1-4. Each of the first portion 310a and second<br>
portion 310b of the network stack 310 may comprise any portion of the network stack 310, at<br>
any one or more network layers, in user-mode 203, kernel-mode, 202, or combinations<br>
thereof, or at any portion of a network layer or interface point to a network layer or any<br>
portion of or interface point to the user-mode 203 and kernel-mode 203. .<br>
The interceptor 350 may comprise software, hardware, or any combination of<br>
software and hardware. In one embodiment, the interceptor 350 intercept a network<br>
communication at any point in the network stack 310, and redirects or transmits the network<br>
communication to a destination desired, managed or controlled by the mterceptor 350 or<br>
client agent 120. For example, the interceptor 350 may intercept a network communication<br>
of a network stack 310 of a first network and transmit the network communication to the<br>
appliance 200 for transmission on a second network 104. In some embodiments, the<br>
interceptor 350 comprises any type interceptor 350 comprises a driver, such as a network<br>
driver constructed and designed to interface and work with the network stack 310. In some<br>
embodiments, the client agent 120 and/or interceptor 350 operates at one or more layers of<br>
the network stack 310, such as at the transport layer. In one embodiment, the interceptor 350<br>
comprises a filter driver, hooking mechanism, or any form and type of suitable network<br>
driver interface that interfaces to the transport layer of the network stack, such as via the<br>
transport driver interface (TDI). In some embodiments, the interceptor 350 interfaces to a<br>
first protocol layer, such as the transport layer and another protocol layer, such as any layer<br>
above the transport protocol layer, for example, an application protocol layer. In one<br>
 <br>
embodiment, the interceptor 350 may comprise a driver complying with the Network Driver<br>
Interface Specification (NDIS), or a NDIS driver. In another embodiment, the interceptor<br>
350 may comprise a min-filter or a mini-port driver. In one embodiment, the interceptor 350,<br>
or portion thereof, operates in kernel-mode 202. In another embodiment, the interceptor 350,<br>
or portion thereof, operates in user-mode 203. In some embodiments, a portion of the<br>
interceptor 350 operates in kernel-mode 202 while another portion of the interceptor 350<br>
operates in user-mode 203. In other embodiments, the client agent 120 operates in user-mode<br>
203 but interfaces via the interceptor 350 to a kernel-mode driver, process, service, task or<br>
portion of the operating system, such as to obtain a kernel-level data structure 225. In further<br>
embodiments, the interceptor 350 is a user-mode application or program, such as application.<br>
In one embodiment, the interceptor 350 intercepts any transport layer connection<br>
requests. In these embodiments, the interceptor 350 execute transport layer application<br>
programming interface (API) calls to set the destination information, such as destination IP<br>
address and/or port to a desired location for the location. In this manner, the interceptor 350<br>
intercepts and redirects the transport layer connection to a IP address and port controlled or<br>
managed by the interceptor 350 or client agent 120. In one embodiment, the interceptor 350<br>
sets the destination information for the connection to a local IP address and port of the client<br>
102 on which the client agent 120 is listening. For example, the client agent 120 may<br>
comprise a proxy service listening on a local IP address and port for redirected transport layer<br>
communications. In some embodiments, the client agent 120 then communicates the<br>
redirected transport layer communication to the appliance 200.<br>
In some embodiments, the interceptor 350 intercepts a Domain Name Service (DNS)<br>
request. In one embodiment, the client agent 120 and/or interceptor 350 resolves the DNS<br>
request. In another embodiment, the interceptor transmits the intercepted DNS request to the<br>
appliance 200 for DNS resolution. In one embodiment, the appliance 200 resolves the DNS<br>
 <br>
request and communicates the DNS response to the client agent 120. In some embodiments,<br>
the appliance 200 resolves the DNS request via another appliance 200' or a DNS server 106.<br>
In yet another embodiment, the client agent 120 may comprise two agents 120 and<br>
120'. In one embodiment, a first agent 120 may comprise an interceptor 350 operating at the<br>
network layer of the network stack 310. In some embodiments, the first agent 120 intercepts<br>
network layer requests such as Internet Control Message Protocol (ICMP) requests (e.g., ping<br>
and traceroute). In other embodiments, the second agent 120' may operate at the transport<br>
layer and intercept transport layer communications. In some embodiments, the first agent<br>
120 intercepts communications at one layer of the network stack 210 and interfaces with or<br>
communicates the intercepted communication to the second agent 120'.<br>
The client agent 120 and/or interceptor 350 may operate at or interface with a protocol<br>
layer in a manner transparent to any other protocol layer of the network stack 310. For<br>
example, in one embodiment, the interceptor 350 operates or interfaces with the transport<br>
layer of the network stack 310 transparently to any protocol layer below the transport layer,<br>
such as the network layer, and any protocol layer above the transport layer, such as the<br>
session, presentation or application layer protocols. This allows the other protocol layers of<br>
the network stack 310 to operate as desired and without modification for using the interceptor<br>
350. As such, the client agent 120 and/or interceptor 350 can interface with the transport<br>
layer to secure, optimize, accelerate, route or load-balance any communications provided via<br>
any protocol carried by the transport layer, such as any application layer protocol over<br>
TCP/IP.<br>
Furthermore, the client agent 120 and/or interceptor may operate at or interface with<br>
the network stack 310 in a manner transparent to any application, a user of the client 102, and<br>
any other computing device, such as a server, in communications with the client 102. The<br>
client agent 120 and/or interceptor 350 may be installed and/or executed on the client 102 in a<br>
manner without modification of an application. In some embodiments, the user of the client<br>
 <br>
102 or a computing device in communications with the client 102 are not aware of the<br>
existence, execution or operation of the client agent 120 and/or interceptor 350. As such, in<br>
some embodiments, the client agent 120 and/or interceptor 350 is installed, executed, and/or<br>
operated transparently to an application, user of the client 102, another computing device,<br>
such as a server, or any of the protocol layers above and/or below the protocol layer<br>
interfaced to by the interceptor 350.<br>
The client agent 120 includes an acceleration program 302, a streaming client 306,<br>
and/or a collection agent 304. In one embodiment, the client agent 120 comprises an<br>
Independent Computing Architecture (ICA) client, or any portion thereof, developed by<br>
Citrix Systems, Inc. of Fort Lauderdale, Florida, and is also referred to as an ICA client. In<br>
some embodiments, the client 120 comprises an application streaming client 306 for<br>
streaming an application from a server 106 to a client 102. In some embodiments, the client<br>
agent 120 comprises an acceleration program 302 for accelerating communications between<br>
client 102 and server 106. In another embodiment, the client agent 120 includes a collection<br>
agent 304 for performing end-point detection/scanning and collecting end-point information<br>
for the appliance 200 and/or server 106.<br>
In some embodiments, the acceleration program 302 comprises a client-side<br>
acceleration program for performing one or more acceleration techniques to accelerate,<br>
enhance or otherwise improve a client's communications with and/or access to a server 106,<br>
such as accessing an application provided by a server 106. The logic, functions, and/or<br>
operations of the executable instructions of the acceleration program 302 may perform one or<br>
more of the following acceleration techniques: 1) multi-protocol compression, 2) transport<br>
control protocol pooling, 3) transport control protocol multiplexing, 4) transport control<br>
protocol buffering, and 5) caching via a cache manager. Additionally, the acceleration<br>
program 302 may perform encryption and/or decryption of any communications received<br>
and/or transmitted by the client 102. In some embodiments, the acceleration program 302<br>
 <br>
performs one or more of the acceleration techniques in an integrated manner or fashion.<br>
Additionally, the acceleration program 302 can perform compression on any of the protocols,<br>
or multiple-protocols, carried as a payload of a network packet of the transport layer protocol.<br>
The streaming client 306 comprises an application, program, process, service, task or<br>
executable instructions for receiving and executing a streamed application from a server 106.<br>
A server 106 may stream one or more application data files to the streaming client 306 for<br>
playing, executing or otherwise causing to be executed the application on the client 102. In<br>
some embodiments, the server 106 transmits a set of compressed or packaged application<br>
data files to the streaming client 306. In some embodiments, the plurality of application files<br>
are compressed and stored on a file server within an archive file such as a CAB, ZIP, SIT,<br>
TAR, JAR or other archive. In one embodiment, the server 106 decompresses, unpackages or<br>
unarchives the application files and transmits the files to the client 102. In another<br>
embodiment, the client 102 decompresses, unpackages or unarchives the application files.<br>
The streaming client 306 dynamically installs the application, or portion thereof, and executes<br>
the application. In one embodiment, the streaming client 306 may be an executable program.<br>
In some embodiments, the streaming client 306 may be able to launch another executable<br>
program.<br>
The collection agent 304 comprises an application, program, process, service, task or<br>
executable instructions for identifying, obtaining and/or collecting information about the<br>
client 102. In some embodiments, the appliance 200 transmits the collection agent 304 to the<br>
client 102 or client agent 120. The collection agent 304 may be configured according to one<br>
or more policies of the policy engine 236 of the appliance. In other embodiments, the<br>
collection agent 304 transmits collected information on the client 102 to the appliance 200.<br>
In one embodiment, the policy engine 236 of the appliance 200 uses the collected information<br>
to determine and provide access, authentication and authorization control of the client's<br>
connection to a network 104.<br>
 <br>
In one embodiment, the collection agent 304 comprises an end-point detection and<br>
scanning mechanism, which identifies and determines one or more attributes or<br>
characteristics of the client. For example, the collection agent 304 may identify and<br>
determine any one or more of the following client-side attributes: 1) the operating system<br>
an/or a version of an operating system, 2) a service pack of the operating system, 3) a running<br>
service, 4) a running process, and 5) a file. The collection agent 304 may also identify and<br>
determine the presence or versions of any one or more of the following on the client: 1)<br>
antivirus software, 2) personal firewall software, 3) anti-spam software, and 4) internet<br>
security software. The policy engine 236 may have one or more policies based on any one or<br>
more of the attributes or characteristics of the client or client-side attributes.<br>
In some embodiments and still referring to FIG. 3, a first program 322 may be used to<br>
install and/or execute the client agent 120, or portion thereof, such as the interceptor 350,<br>
automatically, silently, transparently, or otherwise. In one embodiment, the first program 322<br>
comprises a plugin component, such an ActiveX control or Java control or script that is<br>
loaded into and executed by an application. For example, the first program comprises an<br>
ActiveX control loaded and run by a web browser application, such as in the memory space<br>
or context of the application. In another embodiment, the first program 322 comprises a set<br>
of executable instructions loaded into and run by the application, such as a browser. In one<br>
embodiment, the first program 322 comprises a designed and constructed program to install<br>
the client agent 120. In some embodiments, the first program 322 obtains, downloads, or<br>
receives the client agent 120 via the network from another computing device. In another<br>
embodiment, the first program 322 is an installer program or a plug and play manager for<br>
installing programs, such as network drivers, on the operating system of the client 102.<br>
D. Hierarchical Global Load Balancing<br>
 <br>
Referring now to FIG. 4A, an embodiment of a hierarchy of aggregator appliances<br>
400A-400B (also referred herein as aggregator appliance 400) for load balancing resources<br>
across branch offices is depicted. In brief overview, a first aggregator appliance 400A is<br>
connected to a first set of branch office appliances 200A-200N (also referred herein as branch<br>
office appliance 200) providing services to branch offices 405A-405N. A second aggregator<br>
appliance 400B is connected to a second set of branch office appliances 200A'-200N'<br>
providing services to branch offices 405A'-405N'. The first aggregator appliance 405A and<br>
the second aggregator appliance 400B establish connections with each other to communicate<br>
information 410A, 410A' and 410B, 410B' on performance and operational characteristics of<br>
respective branch office appliances. With this information 410, 420, either of the aggregator<br>
appliances 400A-400N can perform load balancing/switching 284 to select a branch office<br>
appliance 200 from the first set of branch office appliances 200A-200N or the second set of<br>
branch office appliances 200A'-200N' to service requests to access resources from a client<br>
102.<br>
Any of the branch office appliances 200A-200N or 200A'-200N' may be configured<br>
to know of or identify a single aggregator appliance 400. For example, a first branch office<br>
appliance 200A may be configured to identify and connect to the first aggregator appliance<br>
400A. The first branch office appliance 200A may not be configured to have any information<br>
and therefore may not know of the second aggregator appliance 400B or any branch office<br>
appliances 200A'-200N' connected to the second aggregator appliance 400EJ. In this manner,<br>
the configuration of branch office appliance 200 is reduced. Even though the configuration is<br>
reduced, a branch office appliance servicing a request may access any of the other appliances<br>
200A-200N' known to an aggregator appliance 400. Since the aggregator appliances 400A-<br>
400B share information on branch office appliance 200A-200N', a first aggregator appliance<br>
200 can identify to a first branch office appliance 200 information identifying any of the<br>
 <br>
branch office appliances 200A-200N' connected via any of the aggregator appliances 400A-<br>
400B.<br>
In some embodiments, the branch office appliances 200 provide any of the<br>
functionality, operations and services of an appliance 200 described in conjunction with<br>
FIGs. 2A and 2B. The branch office appliances 200A'-200N' provide acceleration 288, load<br>
balancing/switching 284, SSL VPN 280 and/or application firewall services 290 to any of the<br>
computing devices and users of its respective branch office 405AM05N'. The branch office<br>
appliances 200A-200N provide acceleration 288, load balancing 284, switching, SSL VPN<br>
280 and/or application firewall services 290 to any of the computing devices and users of its<br>
respective branch office 405A-405N. In one embodiment, each of the branch office<br>
appliances 200A'-200N' provide the same functionality, operations and service. In other<br>
embodiments, each of the branch office appliance 200 may provide different functionality,<br>
operations or services than another branch office appliance. For example, a first branch<br>
office appliance 200A may provide for SSL VPN 280 and acceleration 288, and a second<br>
branch office appliance 200A' may provide load balancing/switching 284 with SSL VPN<br>
280. A third branch office appliance 200N may provide only SSL VPN 280 and a fourth<br>
branch office appliance 200N, acceleration 288. Further to the example, a fifth branch office<br>
appliance 200B may provide acceleration 288 while a sixth branch office appliance 200C<br>
provides application firewall 290 functionality.<br>
Although branch office appliances 200 are generally described as an appliance 200 in<br>
a branch office 405, the branch office appliance 200 may be an appliance 200 deployed at<br>
any location in a network 104, 105'. For example, a branch office appliance 200 may be<br>
deployed at a data center. In another example, a branch office appliance 200 may be<br>
deployed on a subnet or network segment of a corporate LAN 104. In another embodiment, a<br>
branch office appliance 200A may be deployed on a first corporate LAN and a second branch<br>
office appliance 200B' on a second corporate LAN. In some embodiments, a branch office<br>
 <br>
appliance 200 may be deployed on the same network 104, 104' as an aggregator appliance<br>
400. So, although the appliance 200 is described in FTG. 4A as a branch office appliance<br>
200, it is not limited to operations only at a branch office 405.<br>
The aggregator appliance 400 comprises software, hardware or any combination of<br>
software and hardware. Tn one embodiment, the aggregator appliance 400 comprises logic,<br>
functions or operations, such as via the aggregator 450, to determine, collect and aggregates<br>
information 410 about one or more branch office appliances 200. For example, the<br>
information 410 may comprise information on the status, load or performance of a branch<br>
office appliance 200. In one embodiment, the aggregator 450 comprises an application,<br>
process, service, task or set of executable instructions. The aggregator 450 comprises any<br>
type, form and combination of data structures, objects, files and/or databases for receiving<br>
and storing information 410 about any of the branch office appliances 200. In some<br>
embodiments, the aggregator 450 stores the information 410 in an organized or arranged<br>
manner associated with or identified by a name or identifier of the branch office appliance<br>
200. For example, the information 410 may be indexed via an identifier of the appliance<br>
200. In some embodiments, the aggregator 450 stores or associates temporal data with the<br>
information 410, such as time of recording or time related to an event.<br>
In one embodiment, the aggregator appliance 400 and/or aggregator 450 receive<br>
information 410 from the branch office appliance via a connection. In some embodiments,<br>
the aggregator appliance 400 and a branch office appliance 200 establish or communicate via<br>
a transport layer connection, such as a TCP or UDP connection. Tn other embodiments, the<br>
aggregator appliance 400 and branch office appliance 200 maintain a connection. In other<br>
embodiments, the aggregator appliance 400 and branch office appliance 200 establish a<br>
connection on an as needed basis, e.g., connect and reconnect when they need to<br>
communicate.<br>
 <br>
In some embodiments, the aggregator appliance 400 establishes a connection or<br>
communicates with a predetermined number of branch office appliances 200. In other<br>
embodiments, the aggregator appliance 400 collects and aggregates information on a<br>
predetermined number of branch office appliances 200. In one embodiment, the<br>
predetermined number of branch offices is 31. In another embodiments, the predetermined<br>
number of branch offices is 32. In yet other embodiments, the predetermined number of<br>
branch offices is 16,48, 60, 96, 128 or 256. In a further embodiment, the predetermined<br>
number of branch offices is 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200 or 250. The<br>
number of branch offices an aggregator appliance 400 may connect to or collect information<br>
from may depend on the operational or performance characteristics of the networks 104,<br>
104', the appliance 200, the branch offices 405, and branch office networks 104 along with<br>
the applications, data, and resource usage of the users across branch offices. In some<br>
embodiments, the predetermined number of branch office appliance 200 may not be set or<br>
configured, or otherwise limited only by the memory, capacity and performance of the<br>
aggregator appliance 400.<br>
In another embodiment, the aggregator appliance 400 requests information 410 from<br>
each of the branch office appliance 200 it is connected to. In some embodiments, the<br>
aggregator appliance 400 requests information upon establishment of the connection to the<br>
branch office appliance 200. In another embodiment, the aggregator appliance 400 requests<br>
information 410 from the branch office appliance 200 on a predetermined frequency, such as<br>
every 1 sec, or 1 msec. For example, the aggregator appliance 400 may poll each of its<br>
branch office appliances 200A-200N every 1 sec for information 410. In some embodiments,<br>
the aggregator appliance 400 requests information 410 from the branch office appliance 200<br>
over a predetermined time period, such as every 1 sec for an hour. In yet another<br>
embodiment, the aggregator appliance 400 requests information 410 from a branch office<br>
 <br>
appliance 200 upon an event, such as receiving a request from a client 102, or receiving a<br>
DNS request.<br>
The information 410 may comprise any type and form of data, statistics, status or<br>
information related to or associated with the operational and/or performance characteristics of<br>
the branch office appliance 200, the network 104 of the branch office appliance 200, and/or<br>
any connection to the branch office appliance 200, such as via a client 102, server 106 or the<br>
aggregator appliance 400. In some embodiments, the information 410 comprises operational<br>
and/or performance data on any client 102 and/or server 106 connected to the branch office<br>
appliance 200. In one embodiment, the branch office appliance 200 determines operational<br>
and/or performance information about any client 102 or server 106 it is connected to or<br>
servicing, and creates information 410 on these clients 102 and/or server 106. In this<br>
embodiment, the branch office appliance 200 may provide this information 410 to the<br>
aggregator appliance 400.<br>
In some embodiments, the operational and/or performance characteristic information<br>
410 includes information on any of the following for a branch office appliance 200, client<br>
102 or server: 1) load; 2) numbers and types of connections, 3) resource usage, 4) resource<br>
availability, 5) number of requests outstanding, 6) number of requests transmitted, 7) number<br>
of clients servicing, 8) response time information, including average and historical response<br>
times, 9) errors, status, performance or bandwidth of a connection, and 10) number of<br>
sessions, and states or status thereof. In another embodiment, the information 410 includes<br>
information on any IP or network layer information of the appliance 200, or the connections<br>
of the appliance 200, or of the clients and/or servers serviced by the appliance 200. For<br>
example, the information 410 may include a routing table of the appliance 2 OOfor performing<br>
network address translation, such as for an SSL VPN connection.<br>
Each of the aggregator appliances 400A-400B may share or otherwise communicate<br>
the aggregated information 410 with the other aggregator appliance. The first aggregator<br>
 <br>
appliance 400A establishes a connection, such as a TCP or UDP transport layer connection<br>
with the second aggregator appliance 400B. In one embodiment, the second aggregator<br>
appliance 400B uses this connection. In another embodiment, the second aggregator<br>
appliance 400B establishes a connection, such as a TCP or UDP transport layer connection,<br>
to the first aggregator appliance 400A. In one embodiment, the aggregator appliances 400A-<br>
400B may establish a connection or communication channel with each other upon bootup or<br>
startup. In other embodiments, the aggregator appliances 400A-400B may establish<br>
connections upon a configuration change or event. In another embodiment, the aggregator<br>
appliances 400A-400B may send out a broadcast on the network 104 to determine the<br>
existence or availability of another aggregator appliance 400.<br>
In one embodiment, the first aggregator appliance 400A transmits its information<br>
410A to the second aggregator appliance 400B. The second aggregator appliance 400B<br>
stores the received information 410A as information 410A' as illustrated in FIG. 4A. In<br>
some embodiments, information 410A' is aggregated or combined with information 410A.<br>
In other embodiments, mformation 410A' is associated with information 410A. In another<br>
embodiment, the second aggregator appliance 400B transmits its information 410B to the<br>
first aggregator appliance 400A. The first aggregator appliance 400A stores the received<br>
information 410B as information 4i0B&gt; as illustrated m FiG. 4A. In some embodiments,<br>
information 410B' is aggregated or combined with information 410B. In other embodiments,<br>
information 410B' is associated with information 410B. The first and second aggregator<br>
appliances 400A-400B may exchange or provide information 410A and 410B once, or on a<br>
predetermined frequency, such as every 1 msec or 1 sec. In some embodiments, the first and<br>
second aggregator appliances 400A-400B use a request/reply messaging mechanism or<br>
protocol to transmit information 410A-410B to each other. In other embodiments, the first<br>
and second aggregator appliances 400A-400B have a custom or proprietary exchange<br>
 <br>
protocol for exchanging information 410A-410B about branch office appliances 200A-<br>
200N'.<br>
By exchanging information 410A-410B, each of the first aggregator appliance 400A<br>
and second aggregator appliance 400B have information 410A and 41 OB on both the first set<br>
of one or more branch office appliances 200A-200N and the second set of one or more<br>
branch office appliances 200A'-200N'. Although the first aggregator appliance 400A is<br>
collecting, aggregating and monitoring information 410A about the branch office appliances<br>
200A-200N, the first aggregator appliance 400A obtains information 410B about the branch<br>
office appliances 200A'-200N' collected, aggregated and monitored by the second aggregator<br>
appliance 400B. Likewise, although the second aggregator appliance 400B is collecting,<br>
aggregating and monitoring information 410B about the branch office appliances 200A'-<br>
200N', the second aggregator appliance 400B obtains information 410A about the branch<br>
office appliances 200A-200N collected, aggregated and monitored by the first aggregator<br>
appliance 400A.<br>
With the aggregator appliances 400A-400B, a first branch office appliance 200A, in<br>
one embodiment, need only know the identity or internet protocol information of the first<br>
aggregator appliance 400A, but obtains the identify other branch office appliances 200A'-<br>
200N' via the aggregator appliance 400A. For example, upon receiving a request from a<br>
client for a resource, the first branch office appliance 200A may forward the request to the<br>
aggregator appliance 400a. In response, the aggregator appliance 400A may transmit the<br>
identity of a branch office appliance 200A'-200N' monitored by aggregator appliance 400B<br>
in order to service the request. In some embodiments, this simplifies the configuration of<br>
each or any of the branch office appliances 200, yet, at the same time, allows any branch<br>
office appliance 200A-200N to access the services of or connect to a resource via another<br>
branch office appliance 200A'-200N'. In this way, clients can access resources across any of<br>
the branch offices 405A-405N via any of the branch office appliances 200A-200N' using the<br>
 <br>
information 410A-410B collected via the aggregator appliances 400A-400B. In other<br>
embodiments, a client 102 can connect directly to any of the aggregators 400A-400N and get<br>
load balanced to any of the branch office appliances 200.<br>
The aggregator appliances 400A-400B comprises load-balancing/switching 284<br>
functionality, operations and/or logic for determining and providing load-balancing services<br>
to any of the branch office appliances 200, clients 102 of the branch offices 405, or servers<br>
106 accessed via the branch offices 405 or branch office appliances 200. Using the<br>
information 410A and 410B', in one embodiment, the first aggregator appliance 400A can<br>
determine a branch office appliance 200 from any of the branch office appliances 200A-<br>
200N' to service a request from a client 102. Using the information 410A' and 410B, in<br>
another embodiment, the first second appliance 400B can determine a branch office appliance<br>
200 from any of the branch office appliances 200A-200N' to service a request from a client<br>
102. Additionally, the aggregator appliances 400A-400N can use information 410A, 4ION<br>
to determine a resource, such as server 106, access via a branch office appliance 200 to<br>
service a request. In this manner and in some embodiments, the aggregator appliances 400A-<br>
440N provide load-balancing and switching information for the aggregation of all resources<br>
and branch office appliances 200A-200N across all the branch office 405A-405N'.<br>
The aggregator appliance 400, in some embodiments, comprises any of the<br>
functionality, operations or services of a branch office appliance 200. For example, in<br>
addition to the load balancing 284 and aggregation operations of the aggregator appliance<br>
400 described herein, the aggregator appliance may perform acceleration, SSL VPN or<br>
application firewall functionality. The first aggregator appliance 400A and the second<br>
aggregator appliance 400B may be deployed on the same network 104 and/or different<br>
networks 104, 104'. In some embodiments, additional aggregator appliances 400 may be<br>
deployed to scale up to service a plurality of branch offices 405 and branch office appliances<br>
200.<br>
 <br>
Referring now to FIG. 4B, another embodiment of a deployment of multiple<br>
aggregator appliances is depicted. In brief overview, a plurality of aggregator appliances<br>
400A, 400B and 400N are deployed to provide aggregation and/or load-balancing services to<br>
a plurality of branch offices: branch offices 1-31 405A-405N, branch offices 32-63 405A'-<br>
405N, and branch offices 64-N 405A"-405N". The first aggregator appliance 400A is<br>
connected to and obtains information 410 on a first set of one or more branch office<br>
appliances 405A-405N. The second aggregator appliance 400B is connected to and obtains<br>
information 410 on a second set of one or more branch office appliances 405A'-405N'. The<br>
third aggregator appliance 400N is connected to and obtains information 410 on a third set of<br>
one or more branch office appliances 405A"-405N".<br>
Each of the aggregator appliances 400A-400N can exchange information 410 with<br>
each other to identify, learn about and obtain information 410 on other branch office<br>
appliances 200A-220N, 200A'-200N' and 200A"-200N"". In one embodiment, the first<br>
aggregator appliance 400A establishes a connection with the second aggregator appliance<br>
400B and third aggregator appliance 400N. In another embodiment, the second aggregator<br>
appliance 400B establishes a connection with the first aggregator appliance 400A and third<br>
aggregator appliance 400N. In yet another embodiment, the third aggregator appliance 400N<br>
establishes a connection with the second aggregator appliance 400B and first aggregator<br>
appliance 400A. Through any of these connections, the aggregator appliances 400 can ask,<br>
receive, transmit, or otherwise obtain information 410 on a set of one or more branch office<br>
appliances 200 to which it may not be currently connected.<br>
In some embodiments, each of the aggregator appliances 400 may be connected to,<br>
obtain and monitor information 410 on a number of branch office appliances 200 different<br>
than another aggregator appliance 400. For example, the first aggregator appliance 400A<br>
may monitor and obtain information 410 on 2,3, 4, 5 or 10 appliances 200 while the second<br>
aggregator appliance 200 monitors and obtains information 410 on 20, 30 or 31 appliances<br>
 <br>
200. Further to the example, the third aggregator appliance 400C may monitor and obtain<br>
information 410 on a single branch office appliance 200 or any number of branch office<br>
appliances 200. Although the deployment illustrated in FIG. 4B depicts three aggregator<br>
appliances 400A-400N servicing three sets of multiple branch offices, any number of<br>
aggregator appliances 400 may be deployed to service any number of branch offices 405.<br>
In one embodiment, an aggregator appliance, such as aggregator appliance 400N',<br>
depicted with dotted connected lines in FIG. 4B may be used as a master aggregator node or<br>
appliance 400. For example, in some embodiments, the master aggregator appliance 400N'<br>
may not collect information 410 from branch office appliances 200 directly, but instead<br>
aggregates the information 410 from the other aggregator appliances 400A-400N that<br>
collected such information. In some embodiments, the master aggregator appliance 400N<br>
acts as a backup service to any of the other aggregator appliances 400. For example, in one<br>
case, if an aggregator appliance 400A went down or was rebooted, upon startup the<br>
aggregator appliance 400A can obtain the latest saved information 410 from the master<br>
aggregator appliance 400N'. In other embodiments, each of the aggregator appliance 400A-<br>
400N establish a connection with the master aggregator appliance 400N' to provide or update<br>
the information 410 on the master aggregator appliance 400N' and/or to also obtain<br>
information 410 from the other appliances 400 it may not yet have.<br>
With the deployment architecture illustrated in FIG. 4B, in some embodiments, any<br>
number of aggregator appliances 400 can be deployed to scale load-balancing and<br>
aggregation services to any number of branch offices 405. As the number of branch offices<br>
405 and/or branch office appliances 200 increases, the configuration of a branch office<br>
appliance 200 remains relatively simple in that it needs only to be configured to know of an<br>
existing aggregator appliance 400A or a newly deployed aggregator appliance 400N.<br>
Through the aggregation and exchanging of information 410 among the aggregation<br>
 <br>
appliances 200, any client or branch office appliance 200 can access resources across any of<br>
the branch offices 405.<br>
Referring now to FIG. 5, steps of an embodiment of a method 500 for practicing<br>
aggregations and load-balancing via the aggregation appliances 400 is depicted. In brief<br>
overview, at step 505, a first aggregator appliance 405A establishes connections with and<br>
obtains information 410A on a first plurality of branch office appliances 200A-200N. At<br>
step 510, a second aggregator appliance 410A establishes connections with and obtains<br>
information 410B a second plurality of branch offices 200A'-200N'. One or more of the first<br>
set of branch office appliances 200A-200N may not have any information or be configured<br>
to identify any of the second set of branch office appliances 200A'-200N'. At step 515, the<br>
first and second aggregator appliances 400A-400B establish a connection or communication<br>
between each other. At step 520, the first and second aggregator appliances 400A-400N<br>
exchange identification, operational and performance information 410 about the first and<br>
. second set of branch office appliances 200. At step 525, a first aggregator appliance 400A<br>
receives a request from a client 102 to access a resource. For example, a first branch office<br>
appliance 200A may transmit the request to the first aggregator appliance 400A, such a for<br>
client 102a depicted in FIG. 4A. In another example, a client 102 may transmit the request to<br>
an aggregator appliance 400A, such as clients 102b and 102n as illustrated in FIG. 4A. At<br>
step 530, the first aggregator appliance selects via information 410 received from the second<br>
aggregator appliance 400B a second branch office appliance 200A' from the second set of<br>
branch office appliances 200A'-200N' to service the request. At step 540, the first<br>
aggregator appliance 200 transmits the information on the selected second branch office<br>
appliance 200A' to the client 102, directly or via a first branch office appliance 200A<br>
servicing the client 102. At step 545, the client 102 establishes a connection with the second<br>
branch office appliance 200A', directly or via the first branch office appliance 200A.<br>
 <br>
In further detail, at step 505, a first aggregator appliance 200A establishes any type<br>
and form of connection to one or more branch office appliances 200A-200N. Tn one<br>
embodiment, the first aggregator appliance 200A established a transport layer connection,<br>
such as TCP or UDP, to the branch office appliances 200A-200N. In one embodiment, any<br>
of the branch office appliances 200A-200N requests the connection to the aggregator<br>
appliance 400A. In another embodiment, the aggregator appliance 400A requests the<br>
connection to any of the branch office appliance 200A-200N. In some embodiments, any of<br>
the branch office appliances 200A-200N may have a transport layer connection to one or<br>
more clients 102, such as with a client agent 120. In another embodiment, any of the branch<br>
office appliances 200A-200N may have a transport layer connection to one or more servers<br>
106, such as with a service 270.<br>
The first aggregator appliance 400 A may obtain information 410 about any of the first<br>
set of branch office appliances 200A-200N via any of its connections to these appliances. In<br>
one embodiment, the first aggregator appliance 400A obtains information 410 from a branch<br>
office appliance 200 upon establishment of the connection. In another embodiment, the first<br>
aggregator appliance 400A obtains information 410 from a branch office appliance 200 upon<br>
a predetermined frequency, such as polling every 1 msec or 1 sec. In some embodiments,,<br>
the first aggregator appliance 400A obtains information 410 from a branch office appliance<br>
200 via a request/reply mechanism. In yet another embodiment, a branch office appliance<br>
200 transmits the information 410 to the aggregator appliance 400A upon startup or on a<br>
predetermined frequency, such as pushing the information to the aggregator 400 every 1 msec<br>
or 1 sec.<br>
Likewise to step 505, at step 510, the second aggregator appliance 400B establishes a<br>
connection, such as a transport layer connection, to a second set of one or more branch<br>
offices appliances 200A'-200N'. The second set of branch office appliances 200A'-200N'<br>
may have transport layer connections to one or more clients 102 and/or servers 106. The<br>
 <br>
second aggregator appliance 400B may obtain information 410 about any of the second set of<br>
branch office appliances 200A'-200N' via any of its connections to these appliances. The<br>
second aggregator appliance 400B may receive, request or obtain information 410 at any time<br>
or frequency.<br>
Although the first aggregator appliance 400A has information 410A on the first set of<br>
branch office appliances 200A-200N and the second aggregator appliance 400B has<br>
information 410B on the second set of branch office appliances 200A'-200N', the first<br>
aggregator appliance 400A may not know the identification of or have information on any of<br>
the second set of branch office appliances 200A'-200N\ Likewise, the second aggregator<br>
appliance 400B may not know the identification or have information on any of the firs set of<br>
branch office appliances 200A-200N. In some embodiments, a first branch office appliance<br>
200 A of the first set of branch office appliances 200A-200N does not know the identification<br>
of or have information on any of the second set of branch office appliances 200A'-200N'. In<br>
other embodiments, a second branch office appliance 200A' of the second set of branch<br>
office appliances 200A'-200N' does not know the identification of or have information on<br>
any of the second set of branch office appliances 200A-200N.<br>
At step 515, the first aggregator appliance 400A and the second aggregator appliance<br>
400B establish communications, such as via a transport layer connection, for example, TCP<br>
or UDP. In some embodiments, the first aggregator appliance 400A and second aggregator<br>
appliance 400B establish one connection between each other for communications. In other<br>
embodiments, the first aggregator appliance 400A establishes a connection with the second<br>
aggregator appliance 400B, and the second aggregator appliance 400B establishes a<br>
connection with the first aggregator appliance 400A.<br>
At step 520, the aggregator appliances 400A and 400B may exchange information<br>
410 on a periodic basis, such as a frequency of every 1 sec or 1 msec. In some embodiments,<br>
an aggregator appliance 400A transmits information 410 to another aggregator appliance<br>
 <br>
400B upon receipt of such information 410 from a branch office appliance 200. In one<br>
embodiment, the aggregator appliances 400A and 400B exchange or receive information 410<br>
from a master aggregator appliance 400N'. By the exchange or receipt of information 410,<br>
each aggregator appliance 400A-400B has information 410A, 410B on each of the sets of<br>
branch office appliances. Although the first aggregator appliance 400A is connected to the<br>
first set of branch office appliances 200A-200N, the first aggregator appliance 400A has also<br>
obtained information 410B' on the second set of branch office appliances 200A'-200N'.<br>
Likewise, although the second aggregator appliance 400B is connected to the second set of<br>
branch office appliances 200A'-200N', the second aggregator appliance 400B has also<br>
obtained information 410A' on the first set of branch office appliances 200'-200N. With<br>
both sets of information 410A, 410B, an aggregator appliance 400 can make switching and<br>
load-balancing decisions to access resources across all of the branch office appliances 200<br>
and branch office 405.<br>
At step 525, one of the aggregator appliances 400 received a request from a client to<br>
access a resource. In one embodiment, the client 102 transmits the request to the aggregator<br>
appliance 400. In another embodiment, a branch office appliance 200 transmits the request<br>
on behalf of the client 102 to the aggregator appliance 400. In yet another embodiment,<br>
another aggregator appliance 400B may transmit the request to the aggregator appliance<br>
400A. In some embodiments, the request comprises a connect request, such as a TCP or<br>
UDP connection request or a VPN request. In other embodiments, the request comprises a<br>
session request, such as an SSL or TLS session or an application session such as to a hosted<br>
service. In another embodiment, the request comprises a Domain Name Service (DNS)<br>
request, such as to resolve a domain name. In one embodiment, the request comprises a<br>
request to execute an application, such as via the application delivery system 500. In other<br>
embodiments, the request comprises an authentication or authorization request. In yet<br>
 <br>
another embodiment, the request comprises a request to receive a portion of a computing<br>
environment 15, such as an application, or portion thereof, or a data file.<br>
At step 535, in response to receipt of the request, the aggregator appliance 400<br>
determines, identifies and selects a branch office appliance 200 to service the request. The<br>
aggregator appliance 400 uses any of the information 410A, 410B to determine a branch<br>
office appliance 200 suitable to service the request. In one embodiment, the aggregator<br>
appliance 400 uses the information 410 to determine, identify and select a server 106 access<br>
or serviced by a branch office appliance 200. In some embodiments, the aggregator<br>
appliance 400 analyzes or processes any of the operational and/or performance characteristics<br>
of the information 410 to determine an appliance 200 suitable for the request. In other<br>
embodiments, the aggregator appliance 400 may maintain persistence between a client 102<br>
and a branch office appliance 200. For example, the aggregator appliance 400 may assign a<br>
client 102 to a branch office appliance 200 that is currently servicing the client 102, recently<br>
serviced the client 102 or has previously serviced the client 102.<br>
In some embodiments, the first aggregator appliance 400A identifies and selects a<br>
second branch office appliance 200A' from the second set of branch office appliances 200A'-<br>
200N'. In one embodiment, the first aggregator appliance 400A identifies and selects a first<br>
branch office appliance 200A from the first set of branch office appliances 200A-200N. In<br>
other embodiments, the second aggregator appliance 400B identifies and selects a first branch<br>
office appliance 200A from the first set of branch office appliances 200A-200N. In yet<br>
another embodiment, the second aggregator appliance 400B identifies and selects a second<br>
branch office appliance 200A' from the second set of branch office appliances 200A'-200N'.<br>
At step 540, the aggregator appliance 400 in response to the client request, transmits<br>
information about the selected branch office appliance 200 to the client 102 or the appliance<br>
200 servicing the client 102. In one embodiment, the aggregator appliance 400 transmits the<br>
identification or selection of the appliance 200 directly to the client 102, such as to client<br>
 <br>
agent 120. In another embodiment, the aggregator appliance 400 transmits the identification<br>
or selection of the appliance 200 to the branch office appliance 2~. In some embodiments,<br>
the aggregator appliance 400 identifies to the client 102 or branch office appliance the IP<br>
address or domain name, or other IP layer information, of the selected branch office<br>
appliance 200. In other embodiments, the aggregator appliance 400 identifies to the client<br>
102 or branch office appliance 200 information to connect to the selected branch office<br>
appliance 200.<br>
At step 545, the client 102 establishes a connection with the branch office appliance<br>
200 selected or identified by the aggregator appliance 400. In some embodiments, the client<br>
102, such a via client agent 120, establishes a transport layer connection, for example, a TCP<br>
or UDP with the selected branch office appliance 200. In other embodiments, the branch<br>
office appliance 200 connected to the client 102 establishes a transport layer connection to<br>
the selected branch office appliance, for example, on behalf of the client 102. In some<br>
embodiments, the client 102 establishes an SSL VPN connection with the selected branch<br>
office appliance 200. In some embodiments, the selected branch office appliance 200<br>
provides or establishes connections to one or more servers 106. For example, the branch<br>
office appliance 200 may have pooled transport layer connections to the servers 106 over<br>
which client requests are multiplexed. In yet other embodiments, the selected branch office<br>
appliance 200 may provide additional load-balancing/switching functionality 284 for the<br>
client 102. In another embodiments, the selected branch office appliance 200 provides<br>
acceleration or application firewall services to the client 102.<br>
Although an embodiment of the method 500 is generally described above in<br>
connection with a client 102 accessing the resource from a branch office 405 and/or branch<br>
office appliance 200, the method 500 may be practiced with any client 102 accessing the<br>
aggregator appliances 400 from any location. For example, as illustrated in FIG. 4A, clients<br>
102b and 102n may access an aggregator appliance 400 without first accessing a branch<br>
 <br>
office appliance 200. In one embodiment, a client 102b or 102n may be on the Internet and<br>
connect to an aggregator appliance 200. In other embodiments, the client 102 or 102n may<br>
be on the same network 104, such as a LAN, as the aggregator appliance 400A-400N. The<br>
aggregator appliance 400 can load-balance the client's request and direct the client 102b-<br>
102n to a selected branch office appliance 200.<br>
In view of the structure, functions and operations of the aggregator appliances<br>
described herein, the aggregator appliances provide for reduced configuration of branch<br>
office appliances while also providing a scalable, hierarchical deployment of branch office<br>
appliances. By exchanging branch office appliance information among aggregator appliances<br>
deployed in a hierarchical fashion, any of the aggregator appliances can make load-balancing<br>
and switching decisions to access any of the branch office appliances, or any resources<br>
provided via branch office appliances. Although a branch office appliance may be configured<br>
to communicate with or know of an aggregator appliance, the branch office appliance may<br>
learn of or obtain information of other branch office resources via the aggregation and load-<br>
balancing techniques discussed herein. The aggregator appliances globally load-balance<br>
resource requests of any client from any location across all branch offices and branch office<br>
appliances.<br>
 <br>
<br>
We Claim:<br>
1.	A method for providing a hierarchy of appliances to more efficiently access resources<br>
across a plurality of branch offices, the method comprising the steps of:<br>
(a)	establishing, by a first aggregator appliance, connections with a first plurality of<br>
branch office appliances;<br>
(b)	establishing, by a second aggregator appliance, connections with a second<br>
plurality of branch office appliances, the first plurality of branch office appliances not having<br>
information identifying the second plurality of branch office appliances;<br>
(c)	receiving, by the first aggregator appliance, from a first branch office appliance of<br>
the first plurality of branch offices a request from a client for access to a resource;<br>
(d)	identifying, by the first aggregator appliance via the second aggregator appliance,<br>
a second branch office appliance from the second plurality of branch office appliances to<br>
service the request;<br>
(e)	transmitting, by the first aggregator appliance, to the first branch office appliance<br>
information identifying the second branch office appliance; and<br>
(f)	establishing, by the client, a connection with the second branch office appliance.<br>
<br>
2.	The method of claim 1, wherein step (e) further comprises transmitting, by the first<br>
branch office appliance, information identifying the second branch office appliance to the<br>
client.<br>
3.	The method of claim 1, comprising establishing, by the client via the first branch<br>
office appliance, a second connection via the second branch office appliance with a server.<br>
4.	The method of claim 1, comprising establishing, by the first aggregator appliance,<br>
communications with the second aggregator appliance.<br>
5.	The method of claim 3, comprising communicating, by the first aggregator appliance,<br>
information about the first plurality of branch office appliances to the second aggregator<br>
appliance.<br>
6.	The method of claim 3, comprising communicating, by the second aggregator<br>
appliance, information about the second plurality of branch office appliances to the first<br>
aggregator appliance.<br>
7.	The method of claim 1, determining, by the first aggregator appliance, information on<br>
one of performance or operational characteristics for each of the first plurality of branch<br>
office appliances.<br>
 <br>
8.	The method of claim 1, determining, by the second aggregator appliance, one of<br>
performance or operational characteristics of each of the second plurality of branch office<br>
appliances.<br>
9.	The method of claim 7, wherein step (d) comprising selecting, by the first aggregator<br>
appliance, the second branch office appliance based on one of the performance or operational<br>
characteristics.<br>
10.	The method of claim 8, comprising accelerating, by one of the first office branch<br>
office appliance or the second branch office appliance, communications between the client<br>
and the server.<br>
11.	The method of claim 10, wherein accelerating comprises using one or more of the<br>
following techniques:<br>
compression;<br>
TCP connection pooling;<br>
TCP connection multiplexing;<br>
TCP buffering; and<br>
caching.<br>
12.	The method of claim 1, wherein one of the first aggregator appliance or the second<br>
aggregator appliance is deployed at a data center.<br>
13.	The method of claim 1, wherein the client is deployed at the first branch office..<br>
14.	A system for providing a hierarchy of appliances to more efficiently access resources<br>
across a plurality of branch offices, the system comprising:<br>
a first aggregator appliance establishing connections with a first plurality of branch<br>
office appliances;<br>
a second aggregator appliance establishing connections with a second plurality of<br>
branch office appliances, the first plurality of branch office appliances not having information<br>
identifying the second plurality of branch office appliances;<br>
a first branch office appliance of the first plurality of branch offices transmitting to the<br>
first aggregator appliance a request from a client for access to a resource;<br>
wherein the first aggregator appliance identifies via the second aggregator appliance,<br>
a second branch office appliance from the second plurality of branch office appliances to<br>
service the request, and transmitting to the first branch office appliance information<br>
identifying the second branch office appliance; and<br>
 <br>
the client establishes a connection with the second branch office appliance.<br>
15.	The system of claim 14, wherein the first branch office appliance transmitting<br>
information identifying the second branch office appliance to the client.<br>
16.	The system of claim 14, wherein the client establishes via the first branch office<br>
appliance a second connection via the second branch office appliance with a server.<br>
17.	The system of claim 14, wherein the first aggregator appliance establishes<br>
communications with the second aggregator appliance.<br>
18.	The system of claim 17, wherein the first aggregator appliance communicates<br>
information about the first plurality of branch office appliances to the second aggregator<br>
appliance.<br>
19.	The system of claim 14, wherein the second aggregator appliance communicates<br>
information about the second plurality of branch office appliances to the first aggregator<br>
appliance.<br>
20.	The system of claim 14, wherein the first aggregator appliance determines<br>
information on one of performance or operational characteristics for each of the first plurality<br>
of branch office appliances.<br>
21.	The system of claim 14, wherein the second aggregator appliance determines one of<br>
performance or operational characteristics of each of the second plurality of branch office<br>
appliances.<br>
22.	The system of claim 21, wherein the first aggregator appliance selects the second<br>
branch office appliance based on one of the performance or operational characteristics.<br>
23.	The system of claim 14, wherein one of the first office branch office appliance or the<br>
second branch office appliance accelerates communications between the client and a server.<br>
24.	The system of claim 23, wherein accelerating comprises using one or more of the<br>
following techniques:<br>
compression;<br>
TCP connection pooling;<br>
TCP connection multiplexing;<br>
TCP buffering; and<br>
caching.<br>
 <br>
25.	The system of claim 14, wherein one of the first aggregator appliance or the second<br>
aggregator appliance is deployed at a data center.<br>
26.	The system of claim 14, wherein the client is deployed at the first branch office.<br>
<br>
Systems and methods are disclosed for providing a hierarchy of appliances to more efficiently access resources<br>
across a plurality of branch offices. A method comprises the steps of: establishing, by a first aggregator appliance, connections with<br>
a first plurality of branch office appliances; establishing, by a second aggregator appliance, connections with a second plurality of<br>
branch office appliances, the first plurality of branch office appliances not having information identifying the second plurality of<br>
branch office appliances; receiving, by the first aggregator appliance, from a first branch office appliance a request from a client<br>
for access to a resource; identifying, by the first aggregator appliance via the second aggregator appliance, a second branch office<br>
appliance from the second plurality of branch office appliances to service the request; transmitting, by the first aggregator appliance,<br>
to the first branch office appliance information identifying the second branch office appliance; and establishing, by the first branch<br>
office appliance, a connection with the second branch office appliance. Corresponding systems are also described.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=Z95Ecs/4E0mtDQq+jdQLBQ==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=Z95Ecs/4E0mtDQq+jdQLBQ==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="279787-a-method-of-synthesizing-a-crystalline-material-having-a-cha-framework-type.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="279789-transition-metal-complex-compounds-olefin-oligomerization-catalysts-including-the-compounds-and-processes-for-producing-olefin-oligomers-using-the-catalysts.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>279788</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>728/KOLNP/2009</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>05/2017</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>03-Feb-2017</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>31-Jan-2017</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>24-Feb-2009</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>CITRIX SYSTEMS, INC.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>851 WEST CYPRESS CREEK ROAD, FORT LAUDERDALE, FL</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>SHETTY, ANIL</td>
											<td>C/O CITRIX SILICON VALLEY, 4988 GREAT AMERICA PARKWAY, SANTA CLARA, CA 95054</td>
										</tr>
										<tr>
											<td>2</td>
											<td>KAMATH, SANDEEP</td>
											<td>C/O CITRIX SILICON VALLEY, 4988 GREAT AMERICA PARKWAY, SANTA CLARA, CA 95054</td>
										</tr>
										<tr>
											<td>3</td>
											<td>SUGANTHI, JOSEPHINE</td>
											<td>C/O CITRIX SILICON VALLEY, 4988 GREAT AMERICA PARKWAY, SANTA CLARA, CA 95054</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04L 29/08</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2007/075037</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2007-08-02</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>11/462,345</td>
									<td>2006-08-03</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/279788-method-and-system-for-providing-a-hierarchy-of-appliances-to-more-efficient-access-resources-across-a-plurality-of-branch-offices by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:13:25 GMT -->
</html>
