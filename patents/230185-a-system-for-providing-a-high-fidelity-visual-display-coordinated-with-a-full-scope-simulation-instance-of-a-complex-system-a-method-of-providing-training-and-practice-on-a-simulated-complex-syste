<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/230185-a-system-for-providing-a-high-fidelity-visual-display-coordinated-with-a-full-scope-simulation-instance-of-a-complex-system-a-method-of-providing-training-and-practice-on-a-simulated-complex-system-and-a-complex-system-training-and-practice-apparatus by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:56:22 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 230185:A SYSTEM FOR PROVIDING A HIGH-FIDELITY VISUAL DISPLAY COORDINATED WITH A FULL-SCOPE SIMULATION INSTANCE OF A COMPLEX SYSTEM A METHOD OF PROVIDING TRAINING AND PRACTICE ON A SIMULATED COMPLEX SYSTEM AND A COMPLEX SYSTEM TRAINING AND PRACTICE APPARATUS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A SYSTEM FOR PROVIDING A HIGH-FIDELITY VISUAL DISPLAY COORDINATED WITH A FULL-SCOPE SIMULATION INSTANCE OF A COMPLEX SYSTEM A METHOD OF PROVIDING TRAINING AND PRACTICE ON A SIMULATED COMPLEX SYSTEM AND A COMPLEX SYSTEM TRAINING AND PRACTICE APPARATUS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Control panels of a simulated complex system are displayed as a texture mask (94) over a three-dimensional visual representation of an environment in which the complex system is operating. The three-dimensional visual representation is displayed in an inactive window (90) to a user practicing or training on the simulated system. An active window (92) underlying a display window (100) is used to track user inputs to the control panels. Smart graphics processing (42) translates the user inputs into data elements that are sent to a full-scope simulation (48), and simulation conditions are returned and used to update the display of the control panels and the visual representation of the environment.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>A SYSTEM FOR PROVIDING A HIGH-FIDELITY VISUAL DISPLAY<br>
COORDINATED WITH A FULL-SCOPE SIMULATION INSTANCE OF A<br>
COMPLEX SYSTEM:A METHOD OF PROVIDING TRAINING AND<br>
PRACTICE ON A SIMULATED COMPLEX SYSTEM AND A COMPLEX<br>
SYSTEM TRAINING AND PRACTICE APPARATUS<br>
TECHNICAL FIELD<br>
The preserit invention relates to a system for providing a high-fidelity visual<br>
display coordinated with a full-scope simulation instance of a complex system, a<br>
method of providing training and practice on a simulated complex system and a<br>
complex system training and practice apparatus and, in general, to the simulation of<br>
complex systems for the purpose of system and integrated procedure training and<br>
practice and, in particular, to a method and apparatus for providing complex system<br>
simulation in which interactive graphics representing control panels of a simulated<br>
complex system are merged with real-time simulated three-dimensional imagery of<br>
!	• ' ■<br>
an environment in which the simulated complex system is being operated.<br>
BACKGROUND OF THE INVENTION<br>
The complexity of systems used in many human<br>
endeavors has increased to a point that extensive<br>
training is required for safe operation and maintenance.<br>
Training on real systems is particularly problematic in<br>
industries that use expensive and/or potentially<br>
dangerous equipment. Examples of this equipment include<br>
aircraft, ships, submarines, military equipment, nuclear<br>
power plants, and a host of other complex systems. It has<br>
therefore become standard practice to use simulations of<br>
the complex systems for training. In order to faithfully<br>
reproduce the behavior of real complex systems, "full-<br>
scope" simulation is required. A full-scope simulation is<br>
a simulation in which all necessary subsystems are<br>
simulated to an extent that the full-scope simulation<br><br>
responds in all relevant conditions, both normal and<br>
abnormal, substantially identically to the real system.<br>
In many applications involving a full-scope<br>
simulator, a high fidelity visual system is required.<br>
These visual systems typically provide a three-<br>
dimensional immersive environment for the operator(s).<br>
Three-dimensional immersive environments are known to<br>
significantly improve the effectiveness of the simulator.<br>
The degree of realism provided by a high fidelity visual<br>
system is now quite advanced. The level of detail<br>
provided by such visual systems requires large visual<br>
databases that must be synchronized with the full scope<br>
simulator, in order to render the three-dimensional<br>
visual scenes in real time. Because of their size and<br>
complexity, full-scope simulators that include high<br>
fidelity visual systems are typically housed in a special<br>
facility, and users are compelled to travel to the<br>
facility for training and practice. One such three-<br>
dimensional training station is taught in UK Patent<br>
Application No. 2 255 563 which teaches a simulator<br>
system for vehicles comprising a vehicle cockpit 12<br>
including user operable vehicle controls and at least one<br>
window aperture 16, 17, 18, a viewscreen 165, 175, 185<br>
viewable through the or each aperture, a digital video<br>
effects apparatus for manipulating at least one set of<br>
backdrop video data for forming at least one control<br>
sequence of motion video images for displaying on a<br>
respective viewscreen. Motion video background images<br>
are generated by applying different manipulations at<br>
successive image timings to the background video data.<br><br>
The application further describes an image generation<br>
system that include a computer graphics modeler for<br>
producing a computer graphics image of a foreground<br>
sceen, e.g. the interior of a motor vehicle including a<br>
transparent portion or portions, e.g- the vehicle<br>
windows. A digital video effects apparatus manipulates<br>
background video data to form a controlled sequence of<br>
motion video background images and a compositor for<br>
keying a computer graphics foreground image into the<br>
controlled sequence of the motion video background images<br>
to form an output image sequence with the background<br>
visible through transparent portions of the foreground.<br>
A two-dimensional, vector-based graphical user<br>
interface manufactured by the Applicant permits a user to<br>
interact with a full-scope simulation accessed through a<br>
network, such as the Internet. The user interface<br>
consists of "smart" graphical objects with which the user<br>
interacts, In order to provide a context for a specific<br>
application, the smart graphical objects are overlaid on<br>
a bitmapped image appropriate for the application -<br>
It has been recognised for some time that in many<br>
simulation applications it is advantageous to integrate<br>
three-dimensional real-time visual effects into an<br>
interactive user interface. This type of environment is<br>
essential in applications where an operator needs to<br><br>
familiarize themselves with an out-of-the-window scene,<br>
and interpret visual (out-of-the-window) information in<br>
order to determine how to respond appropriately to a<br>
situation. Simulators that provide varying degrees of<br>
visual and simulation fidelity are commercially<br>
available. Such simulators permit users to interact with<br>
a three-dimensional visual environment using an interface<br>
such as a joystick or a keyboard. Examples are Microsoft<br>
Flight Simulator 2000® and AirBook™ by Simigon. A<br>
disadvantage of such systems is that the user interfaces<br>
are not very intuitive, and not directly associated with<br>
all simulated systems.<br>
Applicant's two-dimensional, vector-based graphical<br>
user interface referenced above permits a user to learn<br>
or practice integrated procedures, and acquire systems<br>
knowledge by interacting with the smart graphics in the<br>
two-dimensional user interface. The user inputs to the<br>
interface are supplied to a full-scope simulation server<br>
that reacts in a realistic way to the inputs, and returns<br>
simulation condition data that is used, in turn, to<br>
update the appearance of the two-dimensional user<br>
interface. While this permits the user to learn or<br>
practice integrated procedures and acquire systems<br>
knowledge, it does not provide the three-dimensional<br>
visual environment required for certain training and<br>
practice applications. For example, in the airline<br>
industry, airport familiarization, familiarizing with<br>
low-visibility atmospheric conditions for flying, airport<br>
approaches, runway maneuvers and the like require a<br>
three-dimensional visual environment.<br><br>
There is therefore a need for a system that<br>
incorporates three-dimensional environment visualization<br>
into a fully functional graphical user interface to<br>
enable low-cost learning and practice of integrated<br>
procedures and operation of a complex system.<br>
OBJECTS OF THE INVENTION<br>
It is therefore an object of the invention to<br>
provide a system that incorporates three-dimensional<br>
visualization into a fully functional graphical user<br>
interface to enable low-cost learning and practice of<br>
integrated procedures and operation of a complex system.<br>
It is a further object of the invention to provide a<br>
method and apparatus for generating an interactive<br>
graphical user interface in which real-time, three-<br>
dimensional visual information is seamlessly merged with<br>
interactive graphical representations of control panels<br>
of a simulated complex system.<br>
It is yet a further object of the invention to<br>
provide a three-dimensional representation of out-of-the-<br>
window views for an operator of a complex system that is<br>
dynamically updated by feedback from a full-scope<br>
simulation of the complex system.<br>
It is another object of the invention to provide a<br>
visualization system in which a two-dimensional texture<br>
mask that is translated into visual texture data that is<br>
applied to a full screen polygon at zero depth to the<br>
user on a three-dimensional image generated using visual<br>
environment data.<br><br>
It is yet another object of the invention to provide<br>
a visualization system in which an inactive display<br>
window overlays an interface window that accepts user<br>
inputs associated with control panels visually<br>
represented by graphics in the inactive window.<br>
SUMMARY OF THE INVENTION<br>
The invention therefore provides a system for<br>
generating a high-fidelity visual display that provides a<br>
three-dimensional immersive visual environment for a user<br>
of the system coordinated with a full-scope simulation of <br>
a complex system that responds in all relevant<br>
conditions, both normal and abnormal, substantially<br>
identically to the real system, the system comprising<br>
smart graphics processing adapted to generate a two-<br>
dimensional image of displayed control panels of the<br>
simulated complex system, the image including embedded<br>
smart graphics to permit the user to manipulate virtual<br>
controls associated with the displayed control panels,<br>
and three-dimensional visuals processing for generating<br>
the high fidelity visual display using visual environment<br>
data CHARACTERIZED by: three-dimensional<br>
visuals processing adapted to generate the high-fidelity<br>
visual display by overlaying a two-dimensional texture<br>
mask that is translated into visual texture data that is<br>
applied to a full screen polygon at zero depth to the<br>
user on a three-dimensional image generated using the<br>
visual environment data.<br>
The invention further provides a method of<br>
generating training and practice on a simulated complex<br><br>
system for personnel who are to operate or maintain the<br>
complex system, comprising steps of: generating a two-<br>
dimensional image of displayed control panels of the<br>
simulated complex system, the two-dimensional image<br>
including embedded smart graphics to permit the personnel<br>
to manipulate virtual controls associated with the<br>
displayed control panels; generating a high fidelity<br>
visual display that provides a three-dimensional<br>
immersive visual environment for a user of the system<br>
using visual environment data and a texture mask derived<br>
from the two-dimensional image, CHARACTERIZED<br>
by: generating the high-fidelity visual display by<br>
overlaying a two-dimensional texture mask that is<br>
translated into visual texture data, which is applied to<br>
a full screen polygon at zero depth to the user on a<br>
three-dimensional image generated using the visual<br>
environment data.<br>
The invention therefore provides an economical<br>
training system that generates realistic visual<br>
simulations for procedure and operator training on a<br>
simulated complex system. Smart graphics processing<br>
translates user inputs into data values that are passed<br><br>
to a full scope simulation. The full scope simulation<br>
provides feedback to visual simulation processes that<br>
update the display of control panels of the complex<br>
system, as well as out-of-the-window views of a simulated<br>
environment.<br>
RRIEF DESCRIPTION OF THE ACCOMPANYING DRAWINGS<br>
Further features and advantages of the present<br>
invention will become apparent from the following<br>
detailed description, taken in combination with the<br>
appended drawings, in which:<br>
FIG. 1 is a schematic diagram of an overview of one<br>
embodiment of a system in accordance with the invention;<br>
FIG. 2 is schematic diagram of an embodiment of a<br>
client/server architecture for implementing the system<br>
shown in FIG. 1;<br>
FIG. 3 is a schematic diagram of overview of an<br>
implementation of a user interface in accordance with one<br>
embodiment of the invention;<br>
FIG. 4 is a schematic diagram providing a more<br>
detailed view of the user interface shown in FIG. 3;<br>
FIG. 5 is a flowchart showing principal logic used<br>
to drive the two-dimensional graphics system shown in<br>
FIG. 3;<br>
FIG. 6 is a flowchart showing principal logic used<br>
to drive the three-dimensional visual system shown in<br>
FIG. 3;<br><br>
FIG. 7 is a flowchart showing the principal logic<br>
used to create or update a texture mask used to display<br>
the user interface shown in FIGs. 3 and 4/ and<br>
FIG. 8 is a schematic diagram of another embodiment<br>
of a client/server architecture that can be used to<br>
implement the system in accordance with the invention.<br>
It will be noted that throughout the appended<br>
drawings, like features are identified by like reference<br>
numerals.<br>
DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT<br>
The present invention enables a three-dimensional<br>
visual environment to be incorporated into an interactive<br>
graphical user interface, to support a host of new<br>
complex system simulation applications. Those<br>
applications apply full-scope simulation with high<br>
fidelity visual systems to enable self-paced learning and<br>
practice on complex simulated systems. The integration of<br>
self-paced courseware for classroom or distance learning<br>
is also enabled.<br>
Incorporating a three-dimensional visual environment<br>
into an interactive user interface poses significant<br>
difficulties. First, because of the size of high fidelity<br>
visual system databases, it is currently necessary to<br>
keep the visual database local to a client computer that<br>
displays the graphical user interface. High fidelity<br>
visual system information cannot be reasonably<br>
transferred across a network in real time using currently<br>
available commercial technology. In addition, extensive,<br>
high-speed processing is required to render such<br>
databases in real time. This places a significant<br><br>
processing load on the client computer, and requires a<br>
graphics acceleration card. Consequently, the full-scope<br>
simulation, which also requires extensive, high-speed<br>
processing, should ideally be run on another processor,<br>
locally or remotely such as a simulation server. This<br>
gives rise to a third problem: how to synchronize the<br>
three-dimensional rendering with the simulation, while<br>
the simulation runs remotely.<br>
As will be explained below in detail, these problems<br>
can be overcome by having a local copy of the simulation,<br>
the visual database and a local three-dimensional visuals<br>
system. Optionally, the processing load on the client can<br>
be reduced by having the simulator execute on a remote<br>
server. In order to further control the client computer<br>
processing load, the refresh rate of the three-<br>
dimensional environment is adjusted. Certain of the<br>
demanding visual effects can also be disabled, if<br>
required, and some of the non-critical details in the<br>
visual database can be removed. It should be understood,<br>
however, that these optimization techniques are only<br>
required in cases in which the client computer does not<br>
have adequate processing speed to be able to render the<br>
full three-dimension visuals.<br>
FIG. 1 is a schematic diagram of an overview of a<br>
system 2 0 in accordance with the invention. The system 2 0<br>
includes one or more client computer(s) 22 connected to a<br>
network 24, such as a local area network (LAN) ,<br>
metropolitan area network (MAN), wide area network (WAN),<br>
or an open network such as an Intranet, or the Internet.<br>
Each of the client computers 22 supports a local<br>
database 2 6 of data used to render high fidelity three-<br><br>
dimensional visual effects, in a manner well known in the<br>
art. The database of high-fidelity three-dimensional<br>
visual effects data may be supplied to the client<br>
computer in a number of ways. For example, the content of<br>
the database can be downloaded from a remote database 30<br>
from a service provider using electronic commerce, or<br>
some other contractual agreement; purchased on a compact<br>
disc or a flash memory; or, supplied through some other<br>
channel on a computer readable medium. In order to<br>
practice the invention, the client computer is connected<br>
through the network 24 to a simulation server 28, which<br>
may simulate any one of a number of complex systems, like<br>
an aircraft, for example.<br>
The system 20 is particularly suited for distance<br>
learning or skills practice. Distance learning is<br>
facilitated by the use of self-paced courseware.<br>
Consequently, the client computer 20 is likewise<br>
optionally provisioned with courseware 32, as will be<br>
explained below in more detail with reference to FIG. 8.<br>
The courseware 32 may be downloaded, along with<br>
corresponding smart graphics objects 23 and three-<br>
dimensional databases relevant to the courseware, from<br>
service provider databases 30, 33, 34, or obtained<br>
through any other channel, as explained above with<br>
reference to the database 26. Distance learning can be<br>
further enhanced by the use of a Learning Management<br>
System (LMS) 38. The learning management system 38<br>
records, tracks, validates and evaluates students using<br>
student validation and course records 40.<br>
FIG. 2 is a schematic diagram of one embodiment of a<br>
client/server architecture for implementing the system<br>
shown in FIG. 1. As explained above, the client<br><br>
computer 22 is connected through the network 24 to the<br>
simulator server 28 using any suitable communications<br>
protocol. The client computer handles graphics processing<br>
using smart graphics processing (SGP) 42 programs that<br>
retrieve two-dimensional graphics information from a<br>
database 52, and three-dimensional visuals (3DV)<br>
processing programs 44, which retrieve visual information<br>
from the database 26. The SPG 42 generates a two-<br>
dimensional image containing smart graphics representing<br>
virtual controls that can be manipulated by a user of the<br>
system 20, in a manner known in the art. The 3DV<br>
processing programs generate three-dimensional visuals of<br>
an environment surrounding the simulated complex system,<br>
also in a manner well Known in the art. The SGP 42 and<br>
the 3DV 44 are interconnected b0y a visual merge<br>
management (VMM) function 4 6, as will be explained below<br>
in some detall.<br>
The simulation server 28 supports an instance 48 of<br>
a full-scope Complex system simulaton, which exchanges<br>
data elements with the client computer 22 through a data<br>
control and provision function 50. Although the<br>
processing load is divided between the client computer 22<br>
and the server computer 28, there is stili a significant<br>
barrier to overcome. In order to integrate The high<br>
fidelity visual display, a single view that incorporates<br>
both the interactive smart graphics and the three-<br>
dimensional visuals must be presented to the user.<br>
As shown in FIG. 2, both the SGP 4 2 and the 3DV 4 4<br>
interact with the simulation instance 48, to ensure that<br>
user inputs to the smart graphics are passed to the<br>
simulator and that simulator conditions update visual<br><br>
displays generated by both the SGP 42 and the 3DV 44<br>
programs. The user views both, but interacts only with<br>
the smart graphics that represent switches, dials, levers<br>
and other control interfaces on the displayed<br>
representations of the control panels and displays. In<br>
the two-dimensional graphical user interface, a bitmap is<br>
used to provide context for vector-based smart graphics.<br>
In order to create one view, both graphical environments<br>
are overlaid in a way that permits an appropriate portion<br>
of each environment to be presented to the user (i.e. -<br>
the simulated environment appears through windows of the<br>
simulated complex system, and smart graphics appear on<br>
the bitmap of the simulated control panels and displays).<br>
This is complicated by the variety of user controls that<br>
must be displayed by the SGP 42. Furthermore, the user<br>
can resize a window, pan, scroll, zoom, or make some<br>
change to the viewport. As the user does this, only an<br>
appropriate part of the smart graphics is displayed by<br>
the graphical user interface. This requires real-time<br>
changes in the location and amount of three-dimensional<br>
visuals that are displayed. In order to accomplish this,<br>
the VMM function 46 was created. The role of the VMM<br>
function 4 6 is to locally synchronize and coordinate the<br>
presentation of both the two-dimensional and three-<br>
dimensional information, so that a single, coordinated<br>
view is presented to the user.<br>
In order to faithfully render a condition of the<br>
full-scope simulation instance 48, the client computer 22<br>
must continuously send data generated by user interaction<br>
with the SGP 42, and information retrieved from the<br>
database 2 6 by the 3DV 44. The client computer 22 must<br>
likewise receive data from the simulation instance 48,<br><br>
and use that information to update the displays generated<br>
by each of the SGP 42 and 3DV 44. On the client<br>
computer 22 side, the information exchange with the<br>
simulation server 28 is handled by a data control and<br>
provision 60, which coordinates data communications with<br>
a counterpart data control and provision function 50 on<br>
the server 28. The data control selects a data provision<br>
function to track data element subscriptions, as will be<br>
explained below with reference to FIG. 5, used by the<br>
SGP 42, to write data to, and read data from, a shared<br>
memory 56 used by the 3DV 44.<br>
FIG. 3 provides an overview of the high fidelity<br>
visual display in accordance with the invention. A two-<br>
dimensional graphics system 70 includes an application<br>
program interface (API) 72 through which the data control<br>
and provision function 60 (FIG. 2) moves simulation<br>
input/output data, as explained above. The VMM 4 6 also<br>
uses the API 72 for retrieving bitmap data and window<br>
size information used to control a merged visual<br>
image 90, as will be explained below in more detail.<br>
Likewise, a three-dimensional visual system 80, which has<br>
an API 82 used by the data control and provision 60 and<br>
the VMM 46. As will be explained below in more detail,<br>
the two-dimensional graphics system 70 generates a two-<br>
dimensional user interface window 92, which is<br>
conveniently blanked since it is always positioned behind<br>
the display window. The two-dimensional graphics<br>
system 70 also generates a bitmap image, conveniently<br>
stored in an off-screen buffer 110 (see FIG. 4). The<br>
function of the bitmap image and its associated changes<br>
are important. The bitmap is used as a mask to show only<br>
the appropriate portions of the three-dimensional visuals<br><br>
generated by the three-dimensional visual systems 80. The<br>
user views only those three-dimensional visuals that are<br>
not masked by the bitmap stored in the off-screen<br>
buffer 110. As will be explained below in more detail<br>
with reference to FIG. 7, a bitmap can be thought of as<br>
an opaque mask consisting of color attributes (Red, Green<br>
and Blue). By defining a single chroma-key (a unique<br>
color), in a manner known in the art, the bitmap mask can<br>
be modified so that areas which are to be transparent are<br>
assigned the chroma-key color attribute. This modified<br>
bitmap is then converted to a texture, which is used by<br>
the texture mask assembler 116 in the three-dimensional<br>
visual system 80 to create a texture mask, as will be<br>
explained below with reference to FIG. 4.<br>
The texture mask is translated into visual texture<br>
data that is applied to a full screen polygon at zero<br>
depth to the user. Consequently, the user views the<br>
three-dimensional visuals through the transparent<br>
portion(s) of the mask. Since the balance of the image 90<br>
is the two-dimensional graphics derived from the bitmap,<br>
the effect is an integration of the previously separate<br>
two-dimensional and three-dimensional images, both of<br>
which are appropriately synchronized with the simulation <br>
instance 48.<br>
FIG. 4 is a more detailed representation of the<br>
client computer 22 image processing functions shown in<br>
FIG. 3. The SGP 42 generates the bitmap image that is<br>
stored in the off-screen buffer 10. As will be explained<br>
below with reference to FIG. 5, the off-screen buffer 110<br>
must be updated each time any one of three events occurs.<br>
Namely, the user interacts with the smart graphics to<br><br>
change a condition of a virtual control displayed by the<br>
display window 100; the user performs a zoom, pan, scroll<br>
or resize operation on the display window 100; or input<br>
is received from the simulator instance 48 that requires<br>
that a displayed control panel be changed. When any one<br>
of those events occurs, the bitmap used to generate the<br>
texture mask must be changed.<br>
Consequently, each time the SGP 42 changes the off-<br>
screen buffer 110 that stores the bitmap, the SGP 42<br>
notifies the VMM 46 of viewport changes and off-screen<br>
buffer updates, consequently, the VMM function 4 6 sends<br>
the command to the SGP to copy the off-screen buffer to<br>
the shared memory device context. The VMM function 4 6<br>
then performs the necessary coordination with the three-<br>
dimensional visual system 8P to effect corresponding<br>
changes in the high fidelity visual display window 90. In<br>
this embodiment, the VMM function 4 6 passes the new<br>
bitmap to the texture mask assembler 116, which converts<br>
the bitmap to visual texture data. The texture mask<br>
assembler then passes the visual texture data to a three-<br>
dimensional rendering process 114, which uses it to<br>
generate the high fidelity visual display window 90. As<br>
well, the window dimension and the field-of-view are<br>
forwarded by the VMM 4 6 to the visual system through the<br>
3D visual system API (FIG. 3) .<br>
The three-dimensional rendering process is<br>
continuously receiving input from the simulation<br>
instance 48, and reading visual system information from<br>
the database 26 (FIG. 2) using a database interface 118.<br>
The three-dimensional rendering process 119 converts the visual<br><br>
information into a three dimensional visual image that is<br>
overlaid with the texture mask created by the texture<br>
mask assembler 116 to generate the display window 90.<br>
Interpolation and extrapolation algorithms (dead-<br>
reckoning) predict and smooth some of the data (such as<br>
position and attitude information) received from the<br>
simulation, in a manner well known in the art. The<br>
display window 90 displays the texture mask 94 (in this<br>
example, an aircraft cockpit). Transparent areas 96 of<br>
the texture mask 94 display the three-dimensional<br>
visuals. The display window 90 is generated with user<br>
input functions disabled, in a manner known in the art.<br>
The display window 90 is then displayed over a window 92<br>
that has user input functions enabled. The window 92 is<br>
optionally blanked, as explained above. The functional<br>
window 92 is controlled by the SGP 42, which accepts the<br>
user input events directed to the display window 100. The<br>
SGP coordinates user input events recorded by window 92<br>
with smart graphics objects embedded in the bitmap image<br>
stored in the off-screen buffer 110.<br>
Consequently, when the user manipulates a pointing<br>
device that controls a cursor 102, to change a control<br>
setting on a displayed control panel, the SGP 42 detects<br>
the event and determines a position of the cursor 102 on<br>
the enabled window 92. The SGP 42 determines what changes<br>
are required to the bitmap stored in the off-screen<br>
buffer 110, as well as what data, if any, must be sent to<br>
the simulation instance 48. It should be noted that a<br>
touch-sensitive display surface can be used in place of a<br>
pointing device, in which case a touch event is detected<br>
instead of the pointing device event described above.<br><br>
FIG. 5 is a flowchart that shows the principal steps<br>
performed by the SGP 42 while performing methods in<br>
accordance with the invention. In an initialization<br>
phase, the SGP 42 performs data element subscription<br>
(step 150). In order to ensure efficient use of<br>
network 24 resources, only data relevant to a displayed<br>
part the of control panels of the simulated complex<br>
system is sent to, or received from, the simulation<br>
instance 48. Consequently, a data element subscription<br>
process is performed. During the data element<br>
subscription process, the SGP 42 registers with the data<br>
control and provision function 60 all data elements<br>
associated with smart graphics displayed by a default<br>
start-up view of the control panel (s) . After the data<br>
element subscription process is completed, the SGP 42<br>
initializes a two-dimensional graphics window 92 and<br>
generates a bitmap that is stored in the off-screen<br>
buffet 110 (step 152). Upon VMM 46 requests, the SGP 42<br>
copies the bitmap to the shared memory device context<br>
controlled by the VMM 46 (step 154). Then, the VMM<br>
coordinates the bitmap processing with the 3DV 80, as<br>
described above. In step 156, the SGP 42 determines<br>
whether the current session has ended. If so, the SGP 42<br>
terminates and garbage collection ensues, in a manner<br>
well known in the art. Otherwise, the SGP 42 checks a<br>
user input register (step 158) to determine whether there<br>
has been input from the user. If user input is detected,<br>
the SGP 42 determines (step 160) whether the input has<br>
resulted in a change of view (resize, pan or zoom<br>
operation). If not, the user input has changed a state of<br>
one of the displayed smart graphics, so the SGP 42<br>
determines which data element(s) must be updated<br><br>
(step 162) to advise the simulator instance 48 of the<br>
change of state. If it was determined in step 158 that<br>
there was no user input, the SGP 42 checks (step 164) to<br>
determine if any of the subscribed data elements have<br>
been changed by feed back from the simulation<br>
instance 48. If none of the data elements have been<br>
updated by the simulation instance 48, the process loops<br>
back to step 156.<br>
The bitmap stored in the off-screen buffer 110 must<br>
be updated, regardless of whether the data elements have<br>
been updated by user input (step 162) or by feed back<br>
from the simulator instance 48 (step 164). Consequently,<br>
the bitmap is updated in step 166, and the new bitmap<br>
image is passed to the VMM 46 (step 168).<br>
If it was determined in step 160 that the user input<br>
resulted in a change of view (resize, pan or zoom<br>
operation), the smart graphics processing 42 computes a<br>
new window size, location and zoom factor (step 170) and<br>
updates the window 92 (step 172). The new window data is<br>
then sent to the VMM 46 when requested by the latter<br>
(step 174). It is then determined (step 176), whether the<br>
change of view requires a change in the subscription to<br>
any of the data elements. If so, all data elements that<br>
have been excluded by the change of view are un-<br>
subscribed to, and any newly required data elements are<br>
subscribed to (step 180). In either case, the bitmap is<br>
updated (step 166) and sent to the VMM 46 (step 168), as<br>
described above.<br>
FIG. 6 is a flowchart that illustrates an overview<br>
of the logic used in the 3DV 44 to perform the methods in<br>
accordance with the invention. The process begins with an<br><br>
initialization of the window 90. The 3DV 44 relies on<br>
simulator input for location, attitude, and many other<br>
simulated system dependent variables to generate the<br>
three-dimensional visuals displayed in the window 90.<br>
Likewise, as will be explained below in more detail, the<br>
database 26 may contain data elements that must be<br>
communicated to the simulation instance 48. Consequently,<br>
system initialization begins with a data element<br>
subscription process (step 200), as explained above with<br>
reference to FIG. 5. The 3DV 44 then initializes the<br>
window 90 to display a default view (step 204) and checks<br>
to determine whether new window data has, been received<br>
from the VMM 46 (step 204) . If new window data has not<br>
been received, the 3DV 44 determines whether the VMM 4 6<br>
is requesting a bitmap update (step 206). If a bitmap<br>
update is required, the bitmap is accepted from the VMM<br>
(step 210) and passed to the texture mask assembler 116,<br>
which converts the bitmap to a texture mask, as will be<br>
explained below with reference to FIG. 7. Likewise, if it<br>
is determined in step 204 that new window data (window<br>
size, position, scroll or zoom factor) is available from<br>
the VMM 46, the window data is accepted from the VMM 4 6<br>
in step 208 and the updated bitmap is accepted (step 210)<br>
and passed to the texture mask assembler 116. In either<br>
case, the new texture mask is generated by the texture<br>
mask assembler 116 (step 212), so that the display<br>
window 90 displays the correct texture mask over the<br>
three-dimensional visuals.<br>
In step 214, the subscribed data elements are read<br>
from the shared three-dimensional memory 56 (FIG. 2),<br>
because those data elements may be required to set up a<br>
retrieval of information form the<br><br>
database 26 required for a next iteration of the three-<br>
dimensional visuals component of window 90. Information<br>
is then read from the database 26 (step 216), in a manner<br>
well known in the art. After the data retrieval, it is<br>
determined in step 218 whether the data retrieval<br>
returned any data elements that must be passed back to<br>
simulator instance 48. For example, the three-dimensional<br>
database may contain information about approaching<br>
objects, changes in elevation, obstructions, or other<br>
information required by the simulation instance 48 to<br>
update instruments, raise alarms, etc. If data element<br>
values were retrieved from the three-dimensional database<br>
26, those data element values are written to the three-<br>
dimensional shared memory 56 in step 220. Otherwise, the<br>
3DV 44 renders the visual for window 90 by overlaying the<br>
three-dimensional visuals with the texture mask, as will<br>
be explained below in more detail with reference to<br>
FIG. 7. In step 224, it is determined whether the session<br>
has ended. If it has not, the process reiterates from<br>
step 204. The quality of the 3DV is optimized by running<br>
at approximately 60 Hz; however, in order to reduce<br>
processing load on the client computer the 3DV can run' at<br>
lower refresh rates. Additionally, in order to reduce<br>
processing load on the client computer 22, the SGP 42<br>
described above with reference to FIG. 4 preferably<br>
iterates at about 5 Hz, which provides a high fidelity<br>
simulation.<br>
FIG. 7 is a flowchart showing principal steps in the<br>
processing of bitmap data to generate the visuals for the<br>
window 90 displayed by the 3DV 44. In step 300, the<br>
3DV 44 receives a new bitmap, which may be accompanied by<br>
new window data, from the VMM 46, as explained in detail<br><br>
above. The new bitmap is passed to the texture mask<br>
assembler 116, which filters out the chroma-key values<br>
(step 302), as described above, and translates the<br>
remainder of the bitmap image to visual texture data<br>
(step 304). The visual texture data may include<br>
transparent regions, be completely transparent, in a<br>
manner known in the art, or be completely opaque,<br>
dependent an the point of view. The texture mask<br>
assembler 116 then passes the texture mask data to the<br>
three-dimensional rendering process 114 (FIG, 4), which<br>
overlays the texture as a full-screen polygon at zero<br>
depth to the viewer atop a high-fidelity image of the<br>
environment created using the data retrieved from the<br>
database 2 6/ as described above.<br>
PIG. 8 is a schematic diagram of another embodiment<br>
of a system 20 in accordance with the invention, in which<br>
a client computer 22 is used as a training device that<br>
employs self-paced courseware as a training aid. The<br>
system 20 includes the simulation server 28 connected to<br>
the client computer 22 through network 24. As explained<br>
above, the client computer 22 connects to a simulation<br>
instance 48 of the simulation server 28 through data<br>
control and provision functions 50.<br>
The client computer 22 includes the data control and<br>
provision functions 58, 60 described above. It also<br>
includes a run time engine (RTE) 130, used to drive the<br>
courseware 32. The courseware 32 is integrated with and<br>
functions in concert with both the two-dimensional<br>
graphics system 70 and the three-dimensional visual<br>
system 80. For example, the courseware 32 may generate<br>
text boxes that are integrated into the bitmap image<br><br>
passed by the VMM 46 from the two-dimensional graphics<br>
system 70 to the three-dimensional visual system 80. The<br>
courseware may also be used to introduce visual effects<br>
or visual highlights into the display output of the<br>
three-dimensional visual system 80. For example, if the<br>
complex system is an aircraft, the courseware may<br>
illustrate a recommended approach path to a runway using<br>
a visual indicator displayed in the window 90. Likewise,<br>
obstacles or hazards may be highlighted or indicated with<br>
a visual marker, or the like. Consequently, the<br>
integrated courseware can be used for a number of<br>
important training and practice applications.<br>
The invention therefore provides an important tool,<br>
when combined with courseware, that permits a rapid<br>
advance in the training of integrated procedures, and the<br>
acquisition of systems knowledge and operator skills<br>
related to the operation or maintenance of any simulated<br>
complex system. The system in accordance with the<br>
invention permits distance learning and skills practice<br>
from a remote location with all of the attendant benefits<br>
of a full-scope simulation with high fidelity visuals,<br>
including a fully functional control interface that<br>
faithfully duplicates the appearance and functionality of<br>
a control panel of the real system. The system in<br>
accordance with the invention is useful in an unlimited<br>
number of applications, since it provides all of the<br>
benefits of a full-scope simulator, except for the motion<br>
and immersive physical environment.<br>
The embodiment(s) of the invention described above<br>
are intended to be exemplary only. The scope of the<br><br>
invention is therefore intended to be limited solely by<br>
the scope of the appended claims.<br><br>
WE CLAIM :<br>
1.	A system for providing a high-fidelity visual display coordinated with a<br>
full-scope simulation instance of a complex system, the system comprising<br>
smart graphics processing that generates a two-dimensional image of<br>
displayed control panels of the simulated complex system, the two-<br>
dimensional image having embedded smart graphics that translate user input<br>
events representing user manipulations of virtual controls associated with the<br>
displayed control panels into data elements that are sent to the full-scope<br>
simulation instance, three-dimensional visuals processing for generating the<br>
high fidelity visual display using visual environment data, and a visual merge<br>
management function that synchronizes and coordinates the two-dimensional<br>
image and the three-dimensional visuals to present a single, coordinated view<br>
to the user, and the full-scope simulation instance is fully coordinated with the<br>
high fidelity visual display by exchanging data between the smart graphics<br>
processing, the three-dimensional visuals processing and the full-scope<br>
simulation instance to determine when a change to the single coordinated<br>
view presented to the user is required.<br>
2.	The system as claimed in claim 1 comprising a high-fidelity three-<br>
dimensional database for dynamic modeling of an environment in which the<br>
complex system operates, the database providing the visuals environment<br>
data to the three-dimensional visuals processing.<br>
3.	The system as claimed in claim 1 wherein the three-dimensional<br>
visuals processing exchanges data with the full-scope simulation instance, so<br>
that the full-scope simulation instance is responsive to the visual environment<br>
data, and the three-dimensional visuals processing is coordinated with the<br>
full-scope simulation instance in real time.<br>
4.	The system as claimed in claim 1 comprising courseware adapted to<br>
facilitate the learning of system knowledge and procedures by the user of the<br>
system.<br><br>
5.	The system as claimed in claim 1 wherein the smart graphics<br>
processing stores the two-dimensional image in an off-screen buffer and<br>
maintains a shared memory device context for tracking the smart graphics<br>
associated with the two-dimensional image to enable translation of the user<br>
input events into changes to data element values that are supplied to the full-<br>
scope simulation instance.<br>
6.	The system as claimed in claim 5 wherein the smart graphics<br>
processing updates the two-dimensional image in response to a user input<br>
event that changes a viewport that displays the high-fidelity visual display.<br>
7.	The system as claimed in claim 6 wherein the visual merge<br>
management function communicates and coordinates changes in the two-<br>
dimensional image to the three-dimensional visuals processing.<br>
8.	The system as claimed in claim 7 wherein the visual 12merge<br>
management function receives window data and bitmap updates, and<br>
forwards the window data and the bitmap updates to the three-dimensional<br>
visuals processing.<br>
9.	The system as claimed in claim 8 comprising a texture mask<br>
assembler adapted to receive the bitmap updates, and to convert the bitmap<br>
to a texture mask.<br>
10.	The system as claimed in claim 9 wherein three-dimensional<br>
processing generates the high-fidelity visual display by overlaying the texture<br>
mask on a three-dimensional image generated using the visual environment<br>
data.<br>
11.	The system as claimed in claim 10 wherein the smart graphics<br>
processing and the three-dimensional visuals processing each dynamically<br>
subscribe to data elements used to exchange data with the instance of the<br>
full-scope simulation.<br><br>
12.	The system as claimed in claim 11 wherein the smart graphics<br>
processing changes its data element subscriptions each time a change to the<br>
two-dimensional image results in a change to smart graphics embedded in<br>
the two-dimensional image.<br>
13.	The system as claimed in claim 1 wherein the client computer<br>
comprises courseware for providing training in any one of systems<br>
knowledge, integrated procedures, and skills required to operate or maintain<br>
the complex system.<br>
14.	A method of providing training and practice on a simulated complex<br>
system for personnel who are to operate or maintain the complex system,<br>
comprising:<br>
generating a two-dimensional image of displayed control panels of the<br>
simulated complex system, the two-dimensional image having embedded<br>
smart graphics processing that translates user input events representing user<br>
manipulations of virtual controls associated with the displayed control panels<br>
into data elements that are sent to a full-scope simulation instance of the<br>
complex system;<br>
generating a high fidelity visual display using three-dimensional visuals<br>
processing which processes visual environment data and a visual merge<br>
management function that synchronizes and coordinates the two-dimensional<br>
image and the three-dimensional visuals to present a single, coordinated view<br>
to the user; and<br>
coordinating the high fidelity visual display with the full-scope<br>
simulation instance of the complex system by exchanging data between the<br>
smart graphics processing, the three-dimensional visuals processing and the<br>
full-scope simulation instance to determine when a change to the single<br>
coordinated view presented to the user is required.<br>
15.	The method as claimed in claim 14 comprising retrieving the visual<br>
environment data from a database local to a client computer that performs the<br>
steps of generating and coordinating.<br><br>
Control panels of a simulated complex system are displayed as a texture mask (94)<br>
over a three-dimensional visual representation of an environment in which the<br>
complex system is operating. The three-dimensional visual representation is<br>
displayed in an inactive window (90) to a user practicing or training on the simulated<br>
system. An active window (92) underlying a display window (100) is used to track<br>
user inputs to the control panels. Smart graphics processing (42) translates the user<br>
inputs into data elements that are sent to a full-scope simulation (48), and simulation<br>
conditions are returned and used to update the display of the control panels and the<br>
visual representation of the environment.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1LT0xOUC0yMDA0LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">1742-KOLNP-2004-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1LT0xOUC0yMDA0LUZPUk0gMjcucGRm" target="_blank" style="word-wrap:break-word;">1742-KOLNP-2004-FORM 27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1LT0xOUC0yMDA0LUZPUk0tMjcucGRm" target="_blank" style="word-wrap:break-word;">1742-KOLNP-2004-FORM-27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtYXNzaWdubWVudC5wZGY=" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtY29ycmVzcG9uZGVuY2UucGRm" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZXhhbWluYXRpb24gcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZm9ybSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZm9ybSAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-form 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZm9ybSAxOC5wZGY=" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZm9ybSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZm9ybSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtZ3BhLnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtcmVwbHkgdG8gZXhhbWluYXRpb24gcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTc0Mi1rb2xucC0yMDA0LWdyYW50ZWQtc3BlY2lmaWNhdGlvbi5wZGY=" target="_blank" style="word-wrap:break-word;">1742-kolnp-2004-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="230184-power-off-state-display-apparatus-of-refrigerator-and-method-thereof.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="230186-ship-for-transporting-electrical-energy.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>230185</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1742/KOLNP/2004</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>09/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>27-Feb-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>25-Feb-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>17-Nov-2004</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>CAE INC</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>8585 COTE DE LIESSE, C.P. 1800, SAINT LAURENT, QUEBEC, CANADA H4L 4X4</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>RIEL YVES</td>
											<td>326 CHEMIN DE LA LORRAINE, LAVAL QUEBEC H7G 1Y5</td>
										</tr>
										<tr>
											<td>2</td>
											<td>GAGNON PIERRE</td>
											<td>2927 RENE-LAENNEC #301, LAVAL, QUEBEC H7K 3V6</td>
										</tr>
										<tr>
											<td>3</td>
											<td>BOISVERT PHILIPPE</td>
											<td>33 REAL-MOUSSEAU, NOTRE-DAME DES PRARIES, QUEBEC J6E 8N2</td>
										</tr>
										<tr>
											<td>4</td>
											<td>DAIGLE JEAN</td>
											<td>1150 MONTIGNY, DORVAL QUEBEC, H9S 5N7</td>
										</tr>
										<tr>
											<td>5</td>
											<td>CULL CHRISTOPHER A</td>
											<td>2500 CAVENDISH BOULEVARD, APT. 319, MONTREAL QUEBEC H4B 2Z6</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G09B 9/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/CA2003/00705</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2003-05-14</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10/143,868</td>
									<td>2002-05-14</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/230185-a-system-for-providing-a-high-fidelity-visual-display-coordinated-with-a-full-scope-simulation-instance-of-a-complex-system-a-method-of-providing-training-and-practice-on-a-simulated-complex-system-and-a-complex-system-training-and-practice-apparatus by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:56:23 GMT -->
</html>
