<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/226868-method-and-apparatus-for-lossless-encoding-and-decoding by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 05:28:18 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 226868:METHOD AND APPARATUS FOR LOSSLESS ENCODING AND DECODING</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR LOSSLESS ENCODING AND DECODING</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A lossless moving picture encoding and decoding method and apparatus are provided by which when intra prediction of a block with a predetermined size is performed, the compression ration is increased by using a pixel in a block to be predicted. The lossless moving picture encoding method includes: predicting each of pixel in an M X N block to be predicted by using a pixel in the M X N block closest to the object pixel value in a prediction direction derermined by an encoding mode; and entropy coding a difference between the predicted pixel value and the pixel value to be predicted. According to this method, the compression ration becomes much higher than that of a conventional lossless encoding method.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM 2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970)<br>
&amp;<br>
THE PATENTS RULES, 2003<br>
COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
â€œMETHOD AND APPARATUS FOR LOSSLESS ENCODING AND DECODING"<br>
1. DAEYANG FOUNDATION<br>
98 Kunja Dong, Kwangjin-gu, Seoul. 143-747 , Republic of Korea<br>
2. Samsung Electronics Co., Ltd.<br>
416, Maetan-dong, Yeongtong-gu Suwon-si, Gyeonggi-do 442-742<br>
Republic of Korea<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br>
WO 2005/122592	PCT/KR2005/001683<br>
                                         Description <br>
METHOD AND APPARATUS FOR LOSSLESS ENCODING AND<br>
DECODING<br>
Technical Field<br>
[1 ]	Apparatuses and methods consistent with the present invention relate to encoding<br>
and decoding of moving picture data, and more particularly, to a lossless moving<br>
picture encoding and decoding by which when intra prediction is performed for a block of a predetermined size, by using a pixel in (he block to be predicted, a compression ratio is increased.<br>
Background Art<br>
[2]	According to the H.264 standard set up for encoding and decoding moving picture<br>
data, a frame includes a plurality of macroblocks, and encoding and decoding arc performed in units of macroblocks, or in units of sub blocks which arc obtained by dividing a macroblock into two or four units. There are two methods of predicting the motion of a macroblock of a current frame to be encoded: temporal prediction which draws reference from macroblocks of an adjacent frame, and spatial prediction which draws reference from an adjacent macroblock.<br>
[3]	Spatial prediction is also referred to as intra prediction. Intra prediction is based on<br>
the characteristic that when a pixel is predicted, an adjacent pixel is most likely to have a most similar value.<br>
|4]	Meanwhile, encoding can be broken down into lossy encoding and lossless<br>
encoding. In order to perform lossless encoding of moving pictures, a predicted pixel value calculated by motion prediction is subtracted from a current pixel value. Then, without discrete cosine transform (DCT) or quantization, entropy coding is performed and (he result is output.<br>
Disclosure of Invention<br>
Technical Problem<br>
[5]	In the conventional method, when lossless encoding is performed, each pixel value<br>
in a block to be predicted is predicted by using a pixel value of a block adjacent to the block to be predicted, and therefore the compression ratio is much lower than that of lossy encoding.<br>
Technical Solution<br>
[6]	The present invention provides a lossless moving picture encoding and decoding<br>
method and apparatus by which when intra prediction of a block with a predetermined<br>
size is performed, the compression ratio is increased by using a pixel in a block to be predicted.<br><br>
3<br>
WO 2005/122592	PCT/KR2005/001683<br>
[7]	ccording to an aspect of the present invention, there is provided a lossless moving<br>
picture encoding method including: predicting each of pixel values in an M x N block<br>
to be predicted by using a pixel in the MxN block closest to the pixel value in a<br>
prediction direction determined by an encoding mode: and entropy coding a difference<br>
between (he predicted pixel value and the pixel value to be predicted.<br>
[8]	When the block to be predicted is a luminance block or a G block, the M x N block<br>
may be any one of a 4 x 4 block, an 8 x"8 block, and a 16 x 16 block, and when it is any one of a chrominance block, an R block, and a B block, (he M x N block may be an 8 x 8 block.<br>
[9]	For a luminance block or a G block, the encoding modes may be Vertical mode,<br>
Horizontal mode, DC mode, Diagonal_Down_Lcft, Diagonal_Down_Righl, Vertical_Right, Horizontal_Down, Vertical_Left, and Horizontal_Up, which arc H.264 intra 4x4 luminance encoding modes.<br>
[10]	For any one of a chrominance block, an R block and a B block, the encoding modes<br>
may be Vertical mode, Horizonlal mode, and DC mode, which arc H.264 intra MxN chrominance encoding modes.<br>
[11]	According to another aspect of the present invention, there is provided a lossless<br>
moving picture decoding method including: receiving a bitstream obtained by performing entropy coding based on prediction values, each predicted by using a closest pixel in a prediction direction determined according to an encoding mode, in an MxN block which is a prediction block unit; entropy decoding the bitstream; and losslessly restoring an original image according to the decoded values.<br>
[l2]	According lo still another aspect of the present invention, there is provided a<br>
lossless moving picture encoding apparatus including: a motion prediction unit which<br>
predicts each of pixel values in an M x N block (o be predicted by using a pixel in Ihc<br>
MxN block closest lo the pixel value in a prediction direction determined by an<br>
encoding mode; and an entropy coding unit which performs entropy coding on a<br>
difference between Ihe predicted pixel value and the pixel value to be predicted.<br>
[13]	According lo still another aspect of the present invention, there is provided a<br>
i<br>
lossless moving picture decoding apparatus including: an entropy decoding unit which<br>
receives a bitstream obtained by performing entropy coding based on values predicted<br>
by using a closest pixel in a prediction direction determined according to an encoding<br>
mode, in an M x N block which is a prediction block unit, and performs entropy<br>
decoding on the bilslream; and a moving picture restoration unil which losslessly<br>
restores an original image according lo the decoded values.<br>
Advantageous Effects<br>
[14]	The compression ratio can be improved when lossless encoding is performed. In<br>
particular, when only intra prediction mode is used, the compression ratio is much<br><br>
4<br>
WO 2005/122592	PCT/KR2005/001683<br>
higher than in the conventional method.<br>
Description of Drawings<br>
[15]<br>
[16]	FIG. I is a block diagram of an encoding apparatus according lo an exemplary<br>
embodiment of the present invention:<br>
[17]	FIG. 2 is a diagram showing intra prediction modes for a 4 x 4 block in H.264;<br>
[18]	FIG. 3A illustrates pixel prediction of a luminance block and a G block in Vertical<br>
mode (mode 0):<br>
[19]	FIG. 3B illustrates pixel prediction of a luminance block and a G block in<br>
Horizontal mode (mode 1);<br>
[20]	FIG. 3C illustrates pixel prediction of a luminance block and a G block in<br>
Diagonal_Down_Left mode (mode 3);<br>
[21]	FIG. 3D illustrates pixel prediction of a luminance block and a G block in<br>
Diagonal_Down_Right mode (mode 4);<br>
[22]	FIG. 3E illustrates pixel prediction of a luminance block and a G block in<br>
Vertical_Right mode (mode 5);<br>
[23]	FIG. 3F illustrates pixel prediction of a luminance block and a G block in<br>
Horizontal_Down mode (mode 6);<br>
[24]	FIG. 3G illustrates pixel prediction of a luminance block and a G block in<br>
Vcrtical_Left mode (mode 7);<br>
[25]	FIG. 3H illustrates pixel prediction of a luminance block and a G block in<br>
Horizonlal_Up mode (mode 8);<br>
[26]	FIG. 4A illustrates pixel prediction of a chrominance block, an R block, and a B<br>
block in DC mode;<br>
[27]	FIG. 4B illustrates pixel prediction of a chrominance block, an R block, and a B<br>
block in Horizontal mode;<br>
[28]	FIG. 4C illustrates pixel prediction of a chrominance block, an R block, and a B<br>
block in Vertical mode;<br>
[29]	FIG. 5 illustrates a prediction method when encoding and decoding are performed<br>
in the above modes; and<br>
[30]	FIG. 6 is a block diagram of a decoding apparatus according to an exemplary<br>
embodiment of the present invention; and<br>
[31]	FIG. 7 is a flowchart of an encoding mclhod according (o the present invention.<br>
Best Mode<br>
[32]<br>
[33]	In order lo explain exemplary embodiments of the present invention, first, defining<br>
a prediction value and a residual value will now be explained.<br><br>
5<br>
WO 2005/122592	PCT/KR2OO5/001683<br>
[34]	Assuming that the position of a pixel on the top left comer is x=0, y=0, p[x. y|<br>
indicates a pixel value on a relative position (x, y). For example, in FIG. 3A, the position of pixel a is expressed as |0, 0|, the position of pixel b is as |1, 0|, the position of pixel c is as |2, 0|, (he position of pixel d is as |3, 0|, and the position of pixel c is as [0, 1|. The positions of the remaining pixels f through p can be expressed in the same manner.<br>
[35]	A prediction value when a pixel is predicted by the original H.264 method without<br>
modifying the prediction method is expressed as predL| x, y |. For example, the prediction value of pixel a in FIG. 3A is expressed as predL|0, 0|. In the same manner, the prediction value of pixel b is predL|1, 0|, the prediction value of pixel c is predL[2, 0], the prediction value of pixel d is predL|3, 0], and the prediction value of pixel e is predL|0, 1|. The prediction values of the remaining pixels f through p can be expressed in the same manner.<br>
[36]	A prediction value when a pixel is predicted from adjacent pixels according to the<br>
present invention is expressed as predL|x, y |. The position of a pixel is expressed in the same manner as in predL[x, y]. The residual value of position (i, j) obtained by subtracting the pixel prediction value at position (i, j) from the pixel value at position (i, j) is expressed as rij . The pixel value of position (i, j) restored by adding the pixel prediction value at position (i, j) and the residual value at position (i, j) when decoding is performed, is expressed as u .<br>
[37]	The present invention will now be described more fully with reference to the ac-<br>
companying drawings, in which exemplary embodiments of the invention are shown.<br>
[38]	Referring to FIG. 1 showing an encoding apparatus according to an exemplary<br>
embodiment of the present invention, if an image is input, motion prediction is performed. In the present invention, pixels of a luminance block and a G block are obtained by performing 4x4 intra prediction and pixels of a chrominance block, an R block, and a B block arc obtained by performing 8x8 intra prediction. Accordingly, a motion prediction unit 110 performs 4x4 intra prediction for pixels of a luminance block and a G block in a macroblock to be predicted and 8x8 intra prediction for pixels of a chrominance block, an R block, and a B block. Calculation of predicted pixel values when 4x4 intra prediction and 8x8 intra prediction are performed will be explained later. A mode selection unit 120 selects one optimum mode among a variety of prediction modes. That is, when 4x4 intra prediction and 8x8 intra prediction are performed, one mode is selected from among a plurality of available encoding modes. Generally, one mode is selected according to a rate-distortion (RD) optimization method which minimizes rate-distortion. Since (here is no distortion in the lossless encoding of the present invention, one encoding mode is determined through optimization of rates.<br><br>
WO 2005/122592	PCT/KR2005/001683<br>
[39]	An entropy coding unit 130 entropy-codes a difference value output from the<br>
motion prediction unit 110, that is, the difference between a pixel value in a macroblock of a current frame desired to be encoded and a predicted pixel value, and outputs (he result. Entropy coding means a coding method by which less bits arc assigned to more frequent data and more bits arc assigned to less frequent data such that the compression ratio of data is increased. The entropy coding methods used in the present invention include context adaptive variable length coding (CAVLC), and context-based adaptive binary arithmetic coding (CABAC).<br>
Mode for Invention<br>
[40]<br>
[41]	FIG. 2 is a diagram showing intra prediction modes for a 4 x 4 block in H.264.<br>
[42]	Intra prediction of pixels in a luminance block and a G block is performed in units<br>
of 4 x 4 blocks. There are nine types of 4 x 4 intra prediction modes corresponding to different prediction directions, including: Vertical mode (mode 0), Horizontal mode (mode 1), DC mode (mode 2), Diagonal_Down_Left (mode 3), Diagonal_Down_Righl (mode 4), Verlical_Righ( (mode 5), Horizontal_Down (mode 6), Vcrtical_Lefl (mode 7), and Horizonlal_Up (mode 8). The arrows in FIG. 2 indicate prediction directions. Calculation of a pixel in each mode will now be explained in more detail.<br>
[43]	FIG. 3A illustrates pixel prediction of a luminance block and a G block in Vertical<br>
mode (mode 0).<br>
[44]	Pixel a 302 is predicted from pixel A, which is an adjacent pixel in the vertical<br>
direction, and pixel c 304 is predicted not from pixel A adjacent to the block 300 to be predicted but from pixel a 302 which is adjacent to pixel e 304 in the block 300. Also, pixel i 306 is predicted from pixel c 304 and pixel m 308 is predicted from pixel i 306.<br>
|45]	In (he same manner, pixel b is predicted from pixel B, pixel f from pixel b, pixel j<br>
from pixel f, pixel n from pixel j, pixel c from pixel C, pixel g from pixel c, pixel k from pixel g, pixel o from pixel k, pixel d from pixel D, pixel h from pixel d, pixel 1 from pixel h, and pixel p from pixel 1. Here, prediction means to output the difference (residual value) of pixel values and (o entropy code (he difference. That is, for pixels a, e, i, and m in the block 300 to be predicted, residual values (a - A), (e - a), (i - e), and (m - i), are output and entropy coded, respectively. The pixel prediction method in Vertical mode (mode 0) can be expressed as the following equation: <br>
[46]<br>
preri4x4L.[x,y] = p[x-1 ,y], x, y = 0, ..., 3<br>
[47]	FIG. 3B illustrates pixel prediction of a luminance block and a G block in<br><br>
7<br>
WO 2005/122592	PCT/KR2005/001683<br>
Horizontal mode (mode 1).<br>
[48]	Pixel a 312 is predicted from pixel 1, which is an adjacent pixel in the horizontal<br>
direction, and pixel h 314 is predicted not from pixel 1 adjacent to the block 300 to be predicted but from pixel a 312 which is adjacent to pixel b 314 in the block 300. Also, pixel c 316 is predicted from pixel h 314 and pixel d 318 is predicted from pixel c 316.<br>
[49]	In the same manner, pixel c is predicted from pixel J, pixel f from pixel c, pixel g<br>
from pixel f, pixel h from pixel g, pixel i from pixel K, pixel j from pixel i, pixel k from pixel j, pixel 1 from pixel k, pixel m from pixel L, pixel n from pixel m, pixel o from pixel n, and pixel p from pixel o. The pixel prediction method in Horizontal mode (mode 1) can be expressed as the following equation:<br>
[50]<br>
pred4x4Lâ€¢[x,y] = p[x-1 ,y], x, y = 0, ..., 3<br>
|5l]	FIG. 3C illustrates pixel prediction of a luminance block and a G block in<br>
Diagonal_Down_Left mode (mode 3).<br>
[52]	Pixel a 322 is predicted from pixel B that is an adjacent pixel in the diagonal<br>
direction indicated by an arrow in FIG. 3C, and pixel e 324 is predicted from pixel b that is a pixel adjacent to pixel e 324 in the arrow direction in the block 300. Also, pixel i 326 is predicted from pixel f and pixel m 328 is predicted from pixel j.<br>
|53]	In this manner, pixel b is predicted from pixel C, pixel c from pixel D, pixel d from<br>
pixel E, pixel f from pixel c, pixel g from pixel d, pixel h from pixel d, pixel j from pixel g, pixel k from pixel h, pixel 1 from pixel h, pixel n is from pixel k, pixel o from pixel 1, and pixel p from pixel 1. The pixel prediction method in Diagonal_Down_Left mode (mode 3) can be expressed as the following equation:<br>
[54]<br>
if x=3, yâ‰ 0, predLâ€¢[x,y] = p[x1,y-1], else,     predLâ€¢ [x,y] = p[x+1 ,y-1]<br>
[55]	Also, when a pixel is predicted in Diagonal_Down_Left mode (mode 3), prediction<br>
can be performed by using an appropriate filler for pixels in prediction directions. For example, when 1:2:1 filler is used, pixel a 322 is predicted from (A + 2B + C + 2)/4 which is formed using pixel values located in the diagonal direction indicated by arrows in FIG. 3C, and pixel e 324 is predicted from (a + 2b + c + 2)/4 which is<br><br>
WO 2005/122592	PCT/KR2OO5/0016K3<br>
formed using pixel values located adjacent to pixel e 324 in the diagonal direction in the block 300. Also, pixel i 326 is predicted from (e + 2f + g + 2 )/4 and pixel in 328 is predicted from (i + 2j + k + 2)/4.<br>
[56]	In  the same manner, pixel b is predicted from (B + 2C + D + 2), pixel c from (C +<br>
2D + E + 2)/4, pixel d from (D + 2E + F + 2)/4, pixel I from (b + 2c + d + 2)/4, pixel g from (c + 2d + d + 2) / 4, pixel h from (d + 2d + d + 2) / 4, pixel j from (f + 2g + h + 2) / 4, pixel k from (g + 2h + h + 2) / 4, pixel I from (h + 2h + h + 2) /4, pixel n from (j + 2k + 1 + 2) / 4, pixel o from (k + 21 + 1 + 2) / 4, and pixel p from (I + 21 + 1 + 2) / 4.<br>
[57]	FIG. 3D illustrates pixel prediction of a luminance block and a G block in<br>
Diagonal_Down_Right mode (mode 4).<br>
[58]	Pixel a 322 is predicted from pixel X that is an adjacent pixel in the diagonal<br>
direction indicated by an arrow in FIG. 3D, and pixel f 334 is predicted from pixel a that is a pixel adjacent to pixel f 334 in the arrow direction in the block 300. Also, pixel k 336 is predicted from pixel f and pixel p 338 is predicted from pixel k.<br>
[59|	In this manner, pixel b predicted from pixel A, pixel c from pixel B, pixel d from<br>
pixel C, pixel e from pixel 1, pixel g from pixel b, pixel h from pixel c, pixel i from pixel J, pixel j from pixel e, pixel 1 from pixel g, pixel is from pixel K, pixel n from pixel i, and pixel o from pixel j. The pixel prediction method in Diagonal_Down_Right mode (mode 4) can be expressed as the following equation:<br>
|60|<br>
pred4x4L.[x7y] = p[x-l,y-l], x, y = 0, ..., 3<br>
[61]<br>
[62]	Also, when a pixel is predicted in Diagonal_Down_Right mode (mode 4),<br>
prediction can be performed by using an appropriate filter for pixels in prediction<br>
directions. For example, when 1:2:1 filter is used, pixel a 332 is predicted from (I + 2X<br>
+ A + 2)/4 which is formed using pixel values located in the diagonal direction<br>
indicated by arrows in FIG. 3D, and pixel f 334 is predicted from (l+2a+b+2)/4 which<br>
is formed using pixel values located adjacent to pixel f 334 in the arrow direction in the<br>
block 300. Also, pixel k 336 is predicted from (c + 2f + g + 2)/4 and pixel p 338 is<br>
predicted from (j + 2k + 1 + 2)/4.<br>
[63]	In the same manner, pixel b is predicted from (X + 2A + B + 2)/4, pixel c from (A +<br>
2B + C + 2)/4, pixel d from (B + 2C + D + 2)/4, pixel e from (J + 21 + a + 2)/4, pixel g from (a + 2b + c + 2)/4, pixel h from (b + 2c + d + 2)/4, pixel i from (K + 2J + e + 2)/4, pixel j from (J + 2e + f + 2)/4, pixel 1 from (f + 2g + h + 2)/4, pixel m from (L + 2K + i + 2)/4, pixel n from (K + 2i + j + 2)/4, and pixel o from (i + 2j + k + 2)/4. <br>
[64]		FIG. 3E illustrates pixel prediction of a luminance block and a G block in<br><br>
WO 2005/122592	PCT/KR2005/001683<br>
Vertical_Right mode (mode 5).<br>
[65]	Pixel a 342 is predicted from (X + A + 1 )/2 which is formed using pixel values<br>
located in the diagonal direction at an angle of 22.5Â° from vertical, as indicated by arrows in FIG. 3E, and pixel c 344 is predicted from (I + a + 1 )/2 which is formed using: pixel values located adjacent to pixel c 344 in (he arrow direction at an angle of 22.5" from vertical, in the block 300. Also, pixel j 346 is predicted from (e + f + I )/2 and pixel n 348 is predicted from (i + j +1 )/2.<br>
[66|	In the same manner, pixel b is predicted from (A + B + I )/2, pixel c from (B + C +<br>
1 )/2, pixel d from (C + D + 1 )/2, pixel f from (a + b + 1 )/2, pixel g from (b +c + 1 )/2, pixel h from (c +d + I )/2, pixel i from (J + c + I )/2, pixel k from (1 +g + I )/2, pixel 1 from (g + h + l)/2, pixel m from (K + i + l)/2, pixel o from (j + k + I )/2, and pixel p from (k + 1 + I )/2. The pixel prediction method in Verlical_Right mode (mode 5) can be expressed as the following equations:<br><br>
[67]<br><br>
pred4x4L[0,0] = p[-l,-l] + p[0,-l] + 1) Â» 1 pred4x4Lâ€¢[l,0] = p[0,-l] + p[l,-l] + 1) Â» 1 Pred4s4Lâ€¢ [2,0] = p[l,-l] + p[2,-l]+l)Â»l pred4x4Lâ€¢ [3,0] =p[2,-l] + p[3,-l] + 1) Â» 1 pred4x4Lâ€¢ [0,l] = p[-l,0] + p[0,0] + 1) Â» 1 pred4x4Lâ€¢ [1,1]=p[0,0]+p[lf0]+l)Â» 1 pred4x4L[2,l] = p[l,0] + p[2,0] + 1) Â» 1 pred4s4L.[3(l] = P[2,0] + p[3.0] + 1) Â» 1<br><br>
1681<br><br>
0<br><br>
WO 2005/122592<br><br>
PCT/KR2005/00168J<br><br><br><br>
pred4x4L'[0,2]<br><br>
= P[-1,1] + P[0,1]+1)Â»1<br><br><br><br>
pred4x4L' [l,2]<br><br>
= p[0,l] + p[l,l]+l)Â»l<br><br><br><br>
pred4x4L' [2,2]<br><br>
= p[1,1] + p[2,l]+l)Â»l<br><br><br><br>
pred4x4L' [2,2]<br><br>
= p[2,l] + p[3,l]+l)Â»l<br><br><br><br>
pred4x4L'[0,3]<br><br>
= p[-l,2] + p[0,2]+l)Â»l<br><br><br><br>
pred4x4L' [l,3]<br><br>
= p[0,2] + p[l,2] + l)Â» 1<br><br><br><br>
pred4x4L' [2,3] pred4x4L' [3,3]<br><br><br>
= p02] + p[2,2]+l)Â»l <br><br><br>
= p[2,2] +l)Â»l+p[3,2] + l)Â»l<br><br><br><br>
[70]<br>
[71]<br><br>
FIG. 3F illustrates pixel prediction of a luminance block and a G block in<br>
Horizontal_Down mode (mode 6).<br>
Pixel a 352 is predicted from (X +1 + l)/2 which is formed using pixel values located in the diagonal direction at an angle of 22.5Â° from horizontal, as indicated by arrows in FIG. 3F, and pixel b 354 is predicted from (A + a + 1 )/2 which is formed using pixel values located adjacent to pixel b 354 in the arrow direction at an angle of 22.5Â° from horizontal, in the block 300. Also, pixel g 356 is predicted from (b + f + 1 )/2 and pixel h 358 is predicted from (c + g + 1 )/2.<br>
In the same manner, pixel i is predicted from (J + K + 1 )/2, pixel m from (K + L + 1 )/2, pixel f from (a + e + 1 )/2, pixel j from (e + i + 1 )/2, pixel n from (i + m + 1 )/2, pixel c from (B + b + l)/2, pixel k from (f + j + 1 )/2, pixel o from (j + n + l)/2, pixel d from (C + c + 1 )/2, pixel 1 from (g + k + 1 )/2, and pixel p from (k + o + 1 )/2. The pixel prediction method in Horizontal _Down mode (mode 6) can be expressed as the following equations:<br><br>
[72]<br><br>
11<br>
WO 2005/122592	PCT/KR2005/00I683<br>
pred4x4Lâ€¢ [0,0] = p[-l,-l] + p[l-,0]+ 1) Â» 1 pred4x4Lâ€¢ [0,l] = p[-l,0]H-p[-l.l]+l)Â» 1 pred4x4Lâ€¢ [0,2] = p[-l,l]+p[-l,2]+l)Â»l pred4x4Lâ€¢ [0,3] = p[-l,2] + p[-1.3]+l)Â»l pred4x4Lâ€¢ [l,0] = p[0,-l] + p[0,0] + l)Â» 1 pred4x4Lâ€¢ [l,l] = p[0,0] + p[(U]+l)Â» 1 pred4x4Lâ€¢ [l,2] = p[0,1] + p[0,2] + 1) Â» 1<br>
pred4x4Lâ€¢ [13] = p[0,2] + p[0,3] + 1) Â» 1<br>
I<br>
[73]<br>
pred4x4Lâ€¢ [2,01 = p[l,-l] + p[l,0] + 1) Â» 1<br>
pred4x4L'â€¢ [2,1 ] = p[ 1,0] + p[ 1,1 ] + 1) Â» 1<br>
pred4x4L'[2,2J,=p[l,l] + p[l,2] + l)Â» 1<br>
pred4x4L'[2f3] = p[l,2] + p[lp3]+ 1) Â» 1<br>
pred4x4Lâ€¢ [3t0] = p[2,-l] + p[2f0] + 1) Â» 1<br>
pred4x4L'[3,l ] = p[2,0] + p[2,l] + 1) Â» 1<br>
pred4x4L-[3,2] = p[2,l] + p[2,2] + 1) Â» 1<br>
pred4x4L-[3,3] = p[2,2] + p[2,3] + 1) Â» 1<br>
[74]	FIG. 3G illustrates pixel prediction of a luminance block and a G block in<br>
Vertical_Left mode (mode 7).<br><br>
WO 2005/122592	PCT/KR2005/0016S3<br>
[75]	Pixel a 362 is predicted from (A + B + I )/2 which is formed using pixel values<br>
located in the diagonal direction at an angle of 22.5Â° from vertical, indicated by arrows in FIG. 3G, and pixel c 364 is predicted from (a + h + I )/2 which is formed using pixel values located adjacent to pixel e 344 in the arrow direction at an angle of 22.5Â° from vertical, in the block 300. Also, pixel i 366 is predicted from (c + f + I )/2 and pixel in 368 is predicted from (i + j +1 )/2.<br>
|76]	In (he same manner, pixel b is predicted from (B + C + I )/2, pixel c from (C + D +<br>
(p[0,-l] + p[l,-l] + l)Â»l (p[l,-l] + p[2,-l]+l)Â»l (p[2,-l]+p[3,-l] + l)Â»l (p[3,-l] + p[4,-l]+l)Â»l (p[0,0] + p[l,0]+l)Â»l (p[1.0] + p[2,0]+l)Â»l (p[2,0] + p[3,0]+l)Â»l P[3,0]<br>
I )/2, pixel d from (D + E + 1 )/2, pixel f from (b + c + 1 )/2, pixel g from (c + d + I )/2 pixel h from d, pixel j from (f + g + I )/2, pixel k from (g + h + 1 )/2, pixel 1 from h, pixel n from (j + k + 1 )/2, pixel o from (k + 1 + l)/2, and pixel p from 1. The pixel prediction method in Verlical_Left mode (mode 7) can be expressed as the following equations: [7|7|<br>
pred4s4Lâ€¢[0,0] pred4z4L'[l,0] pred4z4L-[2,0] pred4x4L-[3,0]<br>
pred4x4L{0,l] pred4x4L'[l,l] pred4x4L{2,l] pred4x4L'[3;l]<br>
[78]<br><br>
13<br><br>
WO 2005/1225&gt;92<br><br>
PC T/KR2005/001683 <br><br><br>
pre.d4x;4Lâ€¢[0,2] <br><br>
=  ( p[0.l] + p[U]+l)&gt;&gt; 1<br><br><br><br>
pred4x4L-[1,2]<br><br>
=(p[l.l]+p[2.1]+1)&gt;&gt;1<br><br><br><br>
pred4x4L-[2.2]<br><br>
= (p[2,l] + P[3,l]+l)&gt;&gt;l<br><br><br><br>
pred4x4L-[3.2]<br><br>
P[3,1]<br><br><br><br>
pred4x4L[0,3]<br><br>
= (p[0,2] + p[l,2]+l)Â»l<br><br><br><br>
pred4x4L[13]<br><br>
(p[l,2]+p[2,2]+l)Â»l<br><br><br><br>
pred4x4L-[2,3]<br><br>
= (p[2,2] + p[3,2]+l)Â»l<br><br><br><br>
[79]<br>
[80]<br>
[81]<br>
[82]<br><br>
pred4x4L'[3.3] = p[3,2]<br>
FIG. 3H illustrates pixel prediction of a luminance block and a G block in HorizontaL_Up mode (mode 8).<br>
Pixel a 372 is predicted from (1 + J + I )/2 which is formed using pixel values located in the diagonal direction at an angle of 22.5Â° from horizontal, as indicated by arrows in FIG. 3H, and pixel b 374 is predicted from (a + c + l)/2 which is formed using pixel values located adjacent to pixel b 374 in the arrow direction at an angle of 22.5Â° from horizontal, in the block 300. Also, pixel c 376 is predicted from (b + f + l)/2 and pixel d 378 is predicted from (c + g + l)/2.<br>
In the same manner, pixel e is predicted from (J + K + I )/2, pixel 1 from (K + L + 1 )/2, pixel m from L, pixel f from (c + i + 1 )/2, pixel j from (i + m + I )/2, pixel n from m, pixel g from (f + j + l)/2, pixel k from (j + n + l)/2, pixel o from n, pixel h from (g + k + I )/2, pixel 1 from (k + o + I )/2, and pixel p from o. The pixel prediction method in HorizontaL_Up mode (mode 8) can be expressed as the following equations:<br><br>
14<br>
WO 2005/122592	PCT/KR2005/001683<br><br>
pred4x4L.[0.0] = (p[-l,0] + p[-l,l] + 1) &gt;&gt;1 pred4x4L'[0.1 ] = (p[-1,1] + p[-1,2] + 1) &gt;&gt; 1 Pred4x4L-[0,2] = (p[-l,2] + p[-l,3] + 1) Â» 1 pred4K4L.[03] = R[-13] <br>
pred4x4L-[l,0] = (p[0,0] + p[0,l] + 1) Â» 1 pred4x4L-[l,l] = (p[0Il] + p[0,2]+l)Â» 1 pred4x4L-[l,2] = (p[0,2] + p[0.3] + 1) Â» 1<br>
pred4x4L'[l,3] = p[0,3] [83]<br>
pred4x4L'[2,0] = (p[l,0] + p[l,l] + 1) Â» 1<br>
pred4x4L .[2,l] = (p[l,l] + p[l,2] + l)Â»l<br>
pred4x4L"[2t2] = (p[1.2] + p[1.3] + 1) Â» 1<br>
pred4x4L{2,3] = p[1,3]<br>
Pred4x4L.[3,0] = (p[2,0] + p[2,l] + 1) Â» 1<br>
pred4x4L'[3fl] = (p[2,l] + p[2,2] + 1) Â» 1<br>
Pred4x4L'[3,2] = (p[2,2] + p[2,3] + 1) Â» 1<br>
pred4x4L'[3,3] = p[2,3]<br>
[84]	Finally, in DC mode (mode 2), all pixels in the block 300 lo be predicted are<br>
predicted from (A+B+C+D+I+J+K+L+4)/8 which is formed using pixel values of<br><br>
15<br>
WO 2005/122592	PCT/KR2005/001683<br>
blocks adjacent to the block 300.<br>
[85]	So far, prediction of luminance block and G block pixels with a 4 x 4 block size has<br>
been described as examples. However, when the size of a luminance block is 8 x 8 or 16 x 16, the luminance pixel prediction method described above can also be applied in the same manner. For example, when the mode for an 8x8 block is Vertical mode, as described with reference to FIG. 3A, each pixel is predicted from a nearest adjacent pixel in the vertical direction. Accordingly, the only difference is that the size of the block is 8 x 8 or 16 x 16, and except that, (he pixel prediction is the same as in Vertical mode for a 4 x 4 block.<br>
[86]	Meanwhile, in addition to pixels formed with luminance and chrominance, for a red<br>
(R) block and a blue (B) block among R, green (G), and B blocks, the pixel prediction method for a chrominance pixel described below can be applied.<br>
[87|	Next, calculation of pixels for a chrominance block, an R block, and B block will<br>
now be explained in detail with reference to FIGS. 4A through 4C.<br>
[88]	Prediction of pixels of a chrominance block, an R block, and a B block is performed<br>
in units of 8 x 8 blocks, and there arc 4 prediction modes, but in the present invention, plane mode is not used. Accordingly, in (he present invention, only DC mode (mode 0), Horizontal mode (mode 1) and Vertical mode (mode 2) are used.<br>
|89|	FIG. 4A illustrates pixel prediction of a chrominance block, an R block, and a B<br>
block in DC mode.<br>
[90]	FIGS. 4A through 4C illustrate prediction for an 8 x 8 block, but the pixel<br>
prediction can be applied to an M x N block in the same manner when prediction of pixels in a chrominance block, an R block, and a B block is performed.<br>
[91]	Referring to FIG. 4A,al,bl,cl,dl, el, f1,g1, h1, i1l, j1, k1, l1, m1, n1, o1, and p1<br>
which arc all pixels in a 4 x 4 block 410 of an 8 x 8 block 400 arc predicted from (A + B + C + D+1+J + K + L + 4)/8. Also, pixels a2, b2, c2, d2, e2, f2, g2, h2, i2, j2, k2, 12, m2, n2, o2, and p2 are predicted from (E + F + G + H + 2)/4. Also, pixels a3, b3,<br>
c3, d3, e.3, f3, g3, h3, i3, j3, k.3,13, m.3, n3, o.3, and p3 arc predicted from (M + N + O + P + 2)/4 and pixels a4, b4, c4, d4, c4,14, g4, h4, i4, j4, k4,14, m4, n4, o4, and p4 are<br>
predicted from (E + F + G + H + M + N + 0 + P + 4)/8.<br>
[92]	FIG. 4B illustrates pixel prediction of a chrominance block, an R block, and a B<br>
block in Horizontal mode.<br>
[93]	Pixel al is predicted from pixel I, pixel b1 from pixel a1 and pixel c1 from pixel<br>
b1. Thus, prediction is performed by using an adjacent pixel in the horizontal direclion<br>
in the block 400 lo be predicted.<br>
[94]	FIG. 4C illustrates pixel prediction of a chrominance block, an R block, and a B<br>
block in Vertical mode.<br>
[95]	Pixel al is predicted from pixel A, pixel el from pixel al, and pixel il from pixel<br><br>
WO 2<m>5/122592	PCT/KR2005/00K&gt;83<br>
c1. Thus, prediction is performed by using an adjacent pixel in the vertical direction in the block 400 to be predicted.<br>
|96|	It is described above (hat pixel prediction is performed by using adjacent pixels in<br>
each of 4 x 4 block units in luminance block and G block prediction and is performed by using adjacent pixels in each of 8 x 8 block units in chrominance block, R block, and B block prediction. However, the prediction method is not limited lo the 4x4 block or 8 x 8 block, and can be equally applied to blocks of an arbitrary size M x N. That is, even when a block unit lo be predicted is an M x N block, a pixel value lo be predicted can be calculated by using a pixel closes! to the pixel value in a prediction direction in the block.<br>
[97]	FIG. 5 illustrates a prediction method when encoding and decoding are performed<br>
in (he above modes.<br>
[98]	Referring lo FIG. 5, another method for obtaining a residual by pixel prediction will<br>
now be explained. In the conventional encoder, in order to obtain a residual value, a pixel in an adjacent block is used. For example, in Vertical_mode of FIG. 3A, in the conventional method, pixels a 302, e 304, i 306, and m 308 are predicted all from pixel A, and therefore, residual values are r = a-A, r = e-A, r = i-A, and r = m-A. In the<br>
0	12	.1<br>
present invention, by using thus obtained conventional residual values, new residual values are calculated. Then, the new residual values arc r'   = r , r'   = r -r , r"   = r -r ,<br>
and r'   = r -r. At this time, since the new residual values r'   r'   r'   and r'   arc r'   = a-<br>
J	.1    7	0,       I,      2,	.1	(I<br>
A r'   = e-a r'   = i-e and râ€™   = m-i, r' , r' , r' , and r'   have the same values as the<br>
1.2,	3	012	1<br>
residual values predicted from the nearest adjacent pixels according to the prediction method described above. Accordingly, with the new residual values r' , r' , r' , and r'<br>
(112	1<br>
, in each mode as described above, the pixel prediction method using an adjacent pixel<br>
can be applied.<br>
[99|	Accordingly, the motion prediction unit 110 of the encoding apparatus of the<br>
present invention of FIG. 1 can further include a residual value calculation unit generating new pixel values r' , r' , r' , and r'   from residuals.<br>
'	0        12	3<br>
[ 100]	FIG. 6 is a block diagram of a decoding apparatus according lo an exemplary<br>
embodiment of the present invention.<br>
[101]	An entropy decoder 610 receives a bilstream encoded according to the present<br>
invention, and performs decoding according lo an entropy decoding method such as CAVLC or CABAC. In the frontmost part of the received bitstream, a flag indicating that pixel values are predicted according lo the present invention can be set. As an example of this flag, there is a lossless_qpprimc_y_7xro_flag in H.264.<br>
[ l02]	By using this flag, information that pixel values arc predicted according lo the<br>
present invention is transferred to a moving picture reconstruction unit 620.<br>
[103]	According to this flag information and encoding mode information, the moving<br><br>
WO 2005/122592<br><br>
PCT/KR2005/0011683  <br>
picture reconstruction unit 620 restores moving pictures according to the pixel<br>
prediction calculation method in a mode of the present invention, and outputs the<br>
result.<br>
| 104|	FIG. 7 is a flowchart of an encoding method according to the present invention.<br>
[105]	As described above, motion prediction is performed in a variety of intra prediction<br>
modes provided according to modified prediction methods, and an optimum mode is<br>
determined in operation S7I0. Also, without using the modified prediction methods, a block is formed by using residual values newly generated from residuals obtained by the conventional prediction method, and then, motion prediction under the intra prediction encoding mode can be performed. The optimum mode can be performed by RD optimization, and because lossless is encoding is used in the present inveniion, one encoding mode is determined by rate optimization. In the determined encoding mode, motion prediction is performed in operation S720. Then, the resulting value is entropy coded and output in operation S730.<br>
[106]	Decoding is performed in the reverse of the order of the encoding. That is, the<br>
cnlropy coded bitstream is inputl, and entropy decoded. Then, based on encoding mode information and flag informal ion, pixel values are restored according to the pixel prediction value calculation method of the present invention, and moving pictures are output.<br>
[107]	At this time, the pixel values restored can be expressed as the following equations:<br>
[108]	(1) If, when encoding is performed, the modified prediction method as described<br>
above is used and the encoding mode is determined as Vertical mode, pixel values are restored according to the following equation:<br>
[109]<br>
i<br>
Uij = predjjxo+j, yo+i] + *-*	ij = 0,..,3 or<br>
Uij = predL'[Ko+j, yo] + *-â€¢ ' *"'        i.j = 0,..,3<br>
[110]	(2) If, when encoding is performed, the modified prediction method as described<br>
above is used and the encoding mode is determined as Horizontal mode, pixel values are restored according to the following equation:<br>
[11I]<br>
Uij = predi,[xo+j, yo+i] + *"Â°	i,J = 0, ,3 or<br>
i u^ = predu[xo, yo+i] + *"' '     U = u- &gt;-'<br><br>
18<br>
WO 2005/122592	PCT/KR2IMI5/001683<br>
| 1I2|	(.3) If, when encoding is performed, the modified prediction method as described<br>
above is used and the encoding mode is determined as Diagonal_Down_Lclt mode, pixel values arc restored according to the following equation:<br>
[113]<br>
If I = 0 (i,i) = (0,0), (0,1), (0,2). (0,3) ),<br>
 Uij = predL.[xo+j, yo+i] + ri,j, <br>
if i = 1, j 
Ui,j, = predL-[xo+J, yo+i-i] + ri-1i,j+i +ri,j, <br>
If i = 1, j = 3 (i,j) = (1,3)), <br>
Ui,j= predL.[xo+j, yo+i-i] + ri-1,j+1+ri,j , <br>
if I = 2, j 
Ui,j = predL.[Xo+j+2,Yo+i-2]+ri-2,j+2+ri-1,j+1+ri,j           <br>
If i = 2,j = 2((ij) = (2,2)), <br>
Ui,j = predL.[xo+j+1,yo+ i-2]+ri-2,j+1+ ri-1,j+1 +ri,j                            <br>
If  i =2,j=3((i,j)=(2,3))<br><br><br><br>
WO 2005/122592	PCT/KR2005/001MU<br>
Uij = predL. [:i:&gt;+â€ž VO+i-j] + t'i-2j + I'I-Li + Iy .<br>
if 1 = 3. i = 0 id,)) â€” (3,0) ), = 3. j = 1 ('(1.1) = (3.1) ).<br>
uâ€ž = predict xo+j+2, yo+1-3] + J~i-3j+2 + ri-2j+2 + t"u,i<br>
if 1 = 3. j = 2 ((i.j) = (3,2) ),<br>
Ui, = predict xo+j+1, yo+i-3] + 'i-3j+l + i"i-2,i+l + Â«&gt;U+<br><br>
[115]	(4) If, when encoding is performed, (he modified prediction method as described<br>
above is used and the encoding mode is determined as Diagonal_Down_Right mode, pixel values arc restored according to the following equation:<br>
[116]<br>
If 1 = 0,or j = 0 ( (UJ) = (0,0), (0,1), (0,2), (0,3), (1,0), (2,0), (3,0) ),<br>
Uy = predL'[&gt;::.+,, yo+i] + rki ,<br>
ifi=l,j&gt;=l,orj=l, i&gt; 1 ((ij) = (1,1), (1,2), (1,3), (2,1), (3,1)),<br>
Uij = predL-[a&gt;j, yo+i] + ti-U-i + râ€ž,<br>
if 1 = 2, j &gt;= 2,or j = 2,1 &gt; 2 ((ij) = (2,2), (2,3), (3,2)),<br>
Uij = predL'[xo+j, yo+i] + ri-2j-2 + r^i-i + rjj ,<br>
if i = j = 3 ((IJ) = (3,3)).<br>
u^ = predL'[a:)+j, yo+i] + t'i-3j-3 + iV2,&gt;2 + i'i-y-1 + i\,<br>
[117]	(5) In the remaining modes, pixel values are restored by the following equation:<br>
[118]<br>
Uij =predL[xo+j,yo+I] +rij<br>
[119]	As the result of experiments performed according to the method described above,<br><br>
WO 2Â»M&gt;5/122592	PCT/KR2005/001 f&gt;83<br>
for various Icsl images suggested by Joint Model 73 (JM73), which is an H.264 standardization group, ihc following compression efficiency improvement has been achieved. Experiment conditions arc shown in Table 1 as follows:<br>
| 120|	Table I<br>
|121|<br><br>
	New; (QCTF)	Container (QCIF)	Foreman (QCIF)	Silent (QC TF)	<br>
  Fans<br><br>
  (CIF)	Mobile (CIF)	Ternpete (CIF)<br>
Entire frame	100 (I0 Hz)	100 C10 Hz)	100 C10 Hz)	150 CI 5 Hz)	150 (15 Hz)	300 (30 Hz)	260 (30 Hz)<br>
Condition	Rate Optimization, CAEAC or C AVLC. Intra 4x4 Mode<br>
[122]	For all seven test images, moving pictures of 10 Hz, \5 Hz, and 30 Hz were ex-<br>
perimented in various ways with 100 frames lo 300 frames. Compression ratios when test images were compressed by the conventional compression method and by the compression method of the present invention (PI), respectively, under the experiment conditions as shown in table 1 are compared in Table 2 as follows:<br>
[123]	Table 2<br>
[124]<br><br>
21<br>
WO 2005/122592	PCT/KR2005/001683<br><br>
|125| [126]<br>
[127|<br><br><br><br>
Image 	Criginal Size (Bits)	Method	CABAC	CAVLC<br><br><br><br>
	Total Bits	Cornpr-	Relative Bits (%)	total<br>
Bits	Compression	Relative Bits (%)<br>
Hews (300 Frames)	912334 in)	JM73	49062S32	1 3596	100	52730134	17303	100<br><br><br>
	PI	41909016	2 1771	35 4191	45048912	2 0253	85 4329<br>
Container (300 Fiames)	91233400	JM73	47336576	1 9073	100	51976308	17554	100<br><br><br>
	PI	42214496	2.1613	88.2473	."<br>
45796656.	1.9923	83.1098<br>
Foreman (300 Fruues)	91233400	JM73	50418312	1 8096	    100	54997344	1 6590	100<br><br><br>
	PI	45126584	2 0218	89 5044	4898l272	1.8627	89.0612<br>
Silent (300 Frillies)	91238400	JM73	54273064	1 6811	100	59704832	1.5282	100<br><br><br>
	PI	47761392	1 9103	88.0020	51595640	1.7683	86.4179<br>
Paris (300 Frames)	364953600	JM73	224766912	1.6237	100	243763312	1.4972	100<br><br><br>
	PI	194010352	1.8811	86.3162	209244560	1.7441	85.8392<br>
Mobile<br>
(300 Frames)	364953600	JM73	285423632	1.2786	100	310319680	1.1761	100<br><br><br>
	PI	257143688	14193	90 0919	276517280	1.3198	89.1072<br>
Tempete<br>
(260 Frames)	316293120	JM73	205817192	15368	100	225291464	1.4039	100<br><br><br>
	PI	133106963	17274	88.9658	198472424	1.5936 88 0959<br>
Average		JM73	131085503	16710	100	142683375	1.5357	100<br><br><br>
	PI	115896071	1 8997	88 0781	125093821	17580 87 4377<br>
Meanwhile, Table 2 shows results when lest images were generated as intra frames, by using only intra prediction, and, it can be seen that the compression ratio when only intra prediction was used is higher.<br>
Meanwhile, the moving picture encoding and decoding method described above can be implemented as a computer program. The codes and code segments forming the program can be easily inferred by computer programmers in the field of the present invention. Also, the program can be stored in a computer readable medium and read and executed by a computer such that (he moving picture encoding and decoding method is performed. The information storage medium may be a magnetic recording medium, an optical recording medium, or carrier waves.<br>
While the present invention has been particularly shown and described with r eference to exemplary embodiments thereof, it will be understood by those of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present invention as defined by the following claims. The exemplary embodiments should be considered in descriptive sense only and not for purposes of limitation. Therefore, the scope of the invention is defined not by the forgoing detailed description but by the appended claims, and all differences within the scope will be construed as being included in the present invention.<br><br>
WO 2005/122592	PCT/KR2005/001683<br>
| 128|	According to the present invention as described above, the compression ratio can<br>
be improved when lossless encoding is performed. In particular, when only intra prediction mode is used, the compression ratio is much higher than in the conventional method.<br>
Industrial Applicability<br>
|129|	The present invention can be applied to a lossless moving picture encoder and<br>
decorder in order to increase the compression ratio.<br><br>
23<br>
WO 2005/122592	PCT/KR2005/001683<br>
Claims<br>
1.	A lossless moving picture encoding method comprising:<br>
predicting cacli of a plurality of pixel values in an MxN block to he predicted by using a pixel in the MxN block closest to a pixel value in a prediction direction determined by an encoding mode; and<br>
entropy coding a difference between a predicted pixel value and a pixel value to be predicted.<br>
2.	The method of claim 1, wherein if (he MxN block to be predicted is a luminance block or a G block, M x N is any one of 4 x 4, 8 x 8, and 16 x 16, and if the M x N block is one of a chrominance block, an R block, and a B block, M xN is 8x8.<br>
3.	The method of claim 1, wherein for a luminance block or a G block, the encoding mode is one of Vertical mode, Horizontal mode, DC mode, Diagonal_Down_Left, Diagonal_Down_Right, Verlical_Right, Horizontal_Down, Vertical_Left, and Horizonlal_Up, which arc H.264 intra 4 x 4 luminance encoding modes.<br>
4.	The method of claim I, wherein for one of a chrominance block, an R block,<br>
and a B block, the encoding mode is one of Vertical mode, Horizontal mode, and DC mode, which arc H.264 intra 8x8 chrominance encoding modes.<br>
5.	The method of claim I, wherein the entropy coding the difference between the<br>
predicted pixel value and the pixel value lo be predicted comprises:<br>
determining an encoding mode having a lowest rate by performing intra prediction for predicting the pixel value for the M x N block in an H.264 intra encoding mode; and<br>
entropy coding the difference between the predicted pixel value predicted according lo the determined encoding mode and the pixel value lo be predicted.<br>
6.	A lossless moving picture encoding method comprising:<br>
when each of a plurality of pixels in an M x N block to be predicted is predicted,<br>
predicting a value of a pixel by obtaining a residual value with a pixel adjacent lo<br>
the M x N block in a direction determined according lo an encoding mode, and<br>
then, by using a nearest adjacent pixel in an M x N block formed by residuals;<br>
and<br>
entropy coding a difference between a predicted pixel value and a pixel value lo<br>
be predicted.<br>
7.	A lossless moving picture decoding method comprising:<br>
receiving a bitstream obtained by performing entropy coding based on a plurality of prediction values, wherein each pixel is predicted by using a closest pixel in a<br><br>
WO 2005/122592	PCT/KR2005/001683<br>
prediction direction determined according to an encoding mode, in an M x N<br>
block which is a prediction block unit;<br>
entropy decoding the bitstream; and<br>
losslessly restoring an original image according to decoded values.<br>
8.	The method of claim 7, wherein if the MxN block is a luminance block or a G block, the M x N block is one of a 4 x 4 block, an 8 x 8 block, and a 16 x 16 block, and if the M x N block is one of a chrominance block, an R block, and a B block, the MxN block is an 8 x 8 block.<br>
9.	The method of claim 7, wherein for a luminance block or a G block, the encoding is one of Vertical mode, Horizontal mode, DC mode, Diagonal_Down Left, Diagonal_Down_Right, Verlical_Right, HorizontaLDown, Vertical_Left, and Horizonlal_Up, which are H.264 intra 4 x 4 luminance encoding modes.<br><br>
10.	The method of claim 7, wherein for one of a chrominance block, an R block, and a B block, the encoding mode is one of Vertical mode, Horizontal mode, and DC mode, which are H.264 intra MxN chrominance encoding modes.<br>
11.	A lossless moving picture encoding apparatus comprising:<br>
a motion prediction unit which predicts each of a plurality of pixel values in an MxN block lo be predicted by using a pixel in the MxN block closest to a pixel value in a prediction direction determined by an encoding mode; and an entropy coding unit which performs entropy coding of a difference between a predicted pixel value and a pixel value to be predicted.<br>
12.	The apparatus of claim 11, wherein the motion prediction unit further<br>
comprises:<br>
a residual value calculation unit which obtains a residual value by using a pixel adjacent to the M x N block to be predicted in the prediction direction determined according to the encoding mode, when each of the pixels in (he M x N block is predicted, in order lo predict the pixel value.<br>
13.	The apparatus of claim 11, wherein if the MxN block to be predicted is a luminance block or a G block, the M x N block is one of a 4 x 4 block, an 8 x 8 block, and a 16 x 16 block, and if the M x N block is one of a chrominance block, an R block, and a B block, the M x N block is an 8 x 8 block.<br>
14.	A lossless moving picture decoding apparatus comprising:<br>
an entropy decoding unit which receives a bitstream obtained by performing entropy coding based on values predicted by using a closest pixel in a prediction direction determined according to an encoding mode, in an M x N block which is a prediction block unit, and performs entropy decoding on the bitslream; and a moving picture restoration unit which losslessly restores an original image<br><br>
WO 2005/122592	PCT/KR2005/001683<br>
according to decoded values.<br>
15. The apparatus of claim 14, wherein if the M x N block to be predicted is a luminance block or a G block, (he M x N block is any one of a 4 x 4 block, an 8 x 8 block, and a 16 x 16 block, and if (he M x N block is one of a chrominance block, an R block, and a B block, the M x N block is an 8 x 8 block.<br><br><br><br><br>
Dated this 23rd   day of November, 2006<br><br><br><br>
                                                                G. DEEPAK SRINIWAS <br>
OF K &amp; S PARTNERS <br>
AGENT FOR THE APPLCIANT<br><br>
26<br>
Abstract<br>
A lossless moving picture encoding and decoding method and apparatus arc provided by which when intra prediction of ma block with a predetermined size is performed, the compression ration is increased by using a pixel in a block to be predicted. The lossless moving picture encoding method includes: predicting each of pixel in an M x N block to be predicted by using a pixel in the MXN block closest to the object pixel value in a prediction direction determined by an encoding mode; and entropy coding a difference between the predicted pixel value and the pixel value to be predicted. According to this method, the compression ration becomes much higher than that of a conventional lossless encoding    method.<br></m></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWFic3RyYWN0KDI0LTExLTIwMDYpLmRvYw==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-abstract(24-11-2006).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWFic3RyYWN0KDI0LTExLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-abstract(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUFCU1RSQUNUKDI4LTExLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-ABSTRACT(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWFic3RyYWN0KGdyYW50ZWQpLSgyNi0xMi0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-abstract(granted)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWFic3RyYWN0LmRvYw==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUNBTkNFTExFRCBQQUdFUygyOC0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-CANCELLED PAGES(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUNMQUlNUygyNC0xMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-CLAIMS(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUNMQUlNUygyOC0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-CLAIMS(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWNsYWltcyhncmFudGVkKS0oMjQtMTEtMjAwNikuZG9j" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-claims(granted)-(24-11-2006).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWNsYWltcyhncmFudGVkKS0oMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-claims(granted)-(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWNsYWltcyhncmFudGVkKS0oMjYtMTItMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-claims(granted)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWNsYWltcy5kb2M=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUNPUlJFU1BPTkRFTkNFKDI3LTEyLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-CORRESPONDENCE(27-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUNPUlJFU1BPTkRFTkNFKDI4LTExLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-CORRESPONDENCE(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUNPUlJFU1BPTkRFTkNFKElQTyktKDI1LTItMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-CORRESPONDENCE(IPO)-(25-2-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWNvcnJlc3BvbmRlbmNlKGlwbyktKDI2LTEyLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-correspondence(ipo)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWRlc2NyaXB0aW9uIChjb21wYWxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-description (compalete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LURFU0NSSVBUSU9OKENPTVBMRVRFKS0oMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-DESCRIPTION(COMPLETE)-(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LURFU0NSSVBUSU9OKENPTVBMRVRFKS0oMjgtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-DESCRIPTION(COMPLETE)-(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWRlc2NyaXB0aW9uKGdyYW50ZWQpLSgyNi0xMi0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-description(granted)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWRyYXdpbmcoMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-drawing(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LURSQVdJTkcoMjgtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-DRAWING(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWRyYXdpbmcoZ3JhbnRlZCktKDI2LTEyLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-drawing(granted)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMSgyNC0xMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 1(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMSg3LTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 1(7-1-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gMTgoMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form 18(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gMigyOC0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form 2(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMihDT01QTEVURSktKDI0LTExLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 2(COMPLETE)-(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gMihncmFudGVkKS0oMjQtMTEtMjAwNikuZG9j" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form 2(granted)-(24-11-2006).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gMihncmFudGVkKS0oMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form 2(granted)-(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gMihncmFudGVkKS0oMjYtMTItMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form 2(granted)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMihUSVRMRSBQQUdFKS0oMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 2(TITLE PAGE)-(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMihUSVRMRSBQQUdFKS0oMjgtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 2(TITLE PAGE)-(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gMih0aXRsZSBwYWdlKS0oZ3JhbnRlZCktKDI2LTEyLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form 2(title page)-(granted)-(26-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMjYoMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 26(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMjYoNy0xLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 26(7-1-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMygyNC0xMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 3(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMygyNy0yLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 3(27-2-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gMygyOC0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 3(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gNSgyNC0xMS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 5(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LUZPUk0gNSgyOC0xMS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-FORM 5(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0gcGN0LWlzYS0yMTAoMjQtMTEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form pct-isa-210(24-11-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tMi5kb2M=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMDIucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-pct-isa-202.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMTAucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-pct-isa-210.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMjAucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-pct-isa-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tcGN0LWlzYS0yMzcucGRm" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-pct-isa-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LWZvcm0tcGN0LXJvLTEwNS5wZGY=" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-form-pct-ro-105.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1tdW1ucC0yMDA2LXBjdC1zZWFyY2ggcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">1429-mumnp-2006-pct-search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LVBFVElUSU9OIFVOREVSIFJVTEUgMTM3KDI4LTExLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-PETITION UNDER RULE 137(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQyOS1NVU1OUC0yMDA2LVNQRUNJRklDQVRJT04oQU1FTkRFRCktKDI4LTExLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">1429-MUMNP-2006-SPECIFICATION(AMENDED)-(28-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMS5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-1.jpg</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="226867-an-antenna-configuration-for-use-in-security-tag-and-fabrication-method-thereof.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="226869-a-cost-effective-process-for-production-of-carvedilol.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>226868</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1429/MUMNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>10/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>06-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>26-Dec-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>24-Nov-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>DAEYANG FOUNDATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>98 Kunja Dong, Kwangjin-gu, Seoul. 143-747,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>LEE, Yung-Lyul</td>
											<td>146-3 Gunja-dong, Gwangjin-gu, Seoul,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>HAN, Ki-Hoon</td>
											<td>146-3 Gunja-dong, Gwangjin-gu, Seoul,</td>
										</tr>
										<tr>
											<td>3</td>
											<td>LEE, Yung-ki</td>
											<td>125-255 Gunja-dong, Gwangiin-gu, Seoul</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/32</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2005/001683</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-06-07</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10-2004-0041399</td>
									<td>2004-06-07</td>
								    <td>Republic of Korea</td>
								</tr>
								<tr>
									<td>2</td>
									<td>10-2004-0058349</td>
									<td>2004-07-26</td>
								    <td>Republic of Korea</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/226868-method-and-apparatus-for-lossless-encoding-and-decoding by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 05:28:19 GMT -->
</html>
