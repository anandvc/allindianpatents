<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/228143-biased-motion-vector-interpolation-for-reduced-video-artifacts by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:43:03 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 228143:BIASED MOTION VECTOR INTERPOLATION FOR REDUCED VIDEO ARTIFACTS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">BIASED MOTION VECTOR INTERPOLATION FOR REDUCED VIDEO ARTIFACTS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>In a video processing system where motion vectors are estimated for a subset of the blocks of data forming a video frame, and motion vectors are interpolated for the remainder of the blocks of the frame, a method includes determining, for at least at least one block of the current frame for which a motion vector is not estimated (204), whether a block to the left or right has an estimated zero motion vector (206), determining whether the at least one block had an estimated zero motion vector in a previous frame (206), and if both determinations are affirmative (208), providing a predetermined motion vector for the at least one block. The predetermined motion vector may be a zero motion vector (208).</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
BIASED MOTION VECTOR INTERPOLATION FOR REDUCED VIDEO ARTIFACTS<br>
The present invention relates generally to image processing, and more particularly relates to methods of biased motion vector interpolation to reduce video artifacts.<br>
Advances in semiconductor manufacturing, digital systems architecture, and communication infrastructure have provided the means to produce and deliver large volumes of video content. These advances, in addition to making possible the production and delivery of such video content, have also made it economically feasible for consumer electronic products to incorporate video processing circuitry and software.<br>
Even though the delivery and playback of video content, and in some cases the production of video content, is possible to implement in consumer electronic products, it is desirable to produce such consumer electronic products in a low cost manner. Similarly, even though there have been large increases in the traffic capacity of generally available communication infrastructures, it is nevertheless desirable to reduce the amount of data actually presented for communication. The goal of producing low cost products that operate with video data is generally addressed by attempting to reduce the computational complexity of the tasks required to be performed by such equipment. The goal of reducing communication traffic is generally addressed by compressing the source material such that there is less data to be transmitted.<br>
A variety of well-known schemes, techniques, and standards have been developed for the compression and decompression of video data, as well as other types of image data. A common approach to video compression exploits the fact there is typically a significant amount of commonality between one frame of video and the next temporally sequential video frame. Such approaches may encode a first frame and then process one or more subsequent frames to generate "motion vectors" which are then transmitted in place of those subsequent frames. The motion vectors contain substantially less data than the frames from which they were derived so that less data traffic is generated for transmission. The motion vectors can be used to "reconstruct" the video data for playback.<br>
It will be understood that various video compression schemes may be used even where transmission over a communications network is not intended, such as, for example, when the compressed video is stored on CD, DVD, magnetic disk, video tape, or other such<br>
media.<br>
In a process sometimes performed on video data, and referred to as "scan rate conversion", some motion vectors may be interpolated from other motion vectors, rather<br><br>
than being derived from their corresponding actual video data. Such a process provides an estimation of the motion that takes place. This estimation is typically performed by deriving a motion vector for every other block of pixels (where the blocks are typically 8 pixels x 8 pixels). Consequently, half of the motion vectors of a total picture are actually interpolated from other motion vectors, rather than being derived from the actual video data. This is done to save on computation, memory, bus bandwidth, and so on. Typically, an averaging, or median filtering, technique is used to generate the missing motion vectors.<br>
Unfortunately, undesirable video artifacts are sometimes generated during playback in systems that use the approach of calculating motion vectors from other motion vectors, rather than deriving all the motion vectors.<br>
What is needed are methods for interpolating motion vectors such that video artifact generation is reduced.<br>
Briefly, in a video processing system where motion vectors are estimated for a subset of the blocks of data forming a video frame, and motion vectors are interpolated for the remainder of the blocks of the frame, a method includes determining, for at least one. block of the current frame for which a motion vector is not estimated, whether a block to the left or a block to the right of the at least one block has an estimated zero motion vector, determining whether the at least one block had an estimated zero motion vector in a previous frame, and if both determinations are affirmative, providing a predetermined motion vector for the at least one block. Such a predetermined motion vector may be a zero motion vector.<br>
Fig. 1 illustrates a frame of video data partitioned into blocks.<br>
Fig. 2 is a flow diagram illustrating a process of providing motion vectors in accordance with the present invention.<br>
Generally, the present invention relates to methods for estimating motion vectors in video material. The present invention is an improvement with respect to current interpolation algorithms for interpolating motion vectors of non-estimated regions or blocks. Various embodiments of the present invention provide a method of motion vector interpolation that can be used to improve the results achieved with any arbitrarily chosen interpolation algorithm. In the case where only non-zero motion vectors are obtained in the region of a skipped block, then the skipped block receives, i.e., is assigned, a motion vector which has been interpolated from the motion vectors of the surrounding blocks having the non-zero motion vectors. However, if the motion vector associated with either the block to<br><br>
the left or the block to the right, i.e., the blocks surrounding the skipped block, is zero, and the previous (estimated) motion vector (for the skipped block) is also zero, then a predetermined motion vector, such as a zero motion vector, is used as the current motion vector of the skipped block.<br>
Reference herein to "one embodiment", "an embodiment", or similar formulations, means that a particular feature, structure, operation, or characteristic described in connection with the embodiment, is included in at least one embodiment of the present invention. Thus, the appearances of such phrases or formulations herein are not necessarily all referring to the same embodiment Furthermore, various particular features, structures, operations, or characteristics may be combined in any suitable manner in one or more embodiments.<br>
Pixel refers to a picture element. A pixel is essentially the smallest addressable unit of a display. One common way of representing pixels is as one or more bits of digital data.<br>
Block refers to a collection of pixels which is a subset of the pixels that make up a frame, or picture.<br>
A neighborhood refers to one or more blocks within a predetermined range of any particular block. In some embodiments the neighborhood includes, but is not limited to, the immediately adjacent blocks for a given block. However, the present invention is not limited to any particular range, or rule set, for defining which blocks are within the neighborhood of a given block.<br>
Skipped block refers to a block for which a motion vector is not estimated. In accordance with the present invention, either a predetermined motion vector (e.g., a zero motion vector), or an interpolated motion vector is assigned to, or produced for, skipped blocks.<br>
An estimated motion vector refers to a motion vector derived, or obtained from, the processing of pixel information.<br>
An interpolated motion vector refers to a motion vector derived, or obtained from, the processing of estimated motion vectors.<br>
Referring to Fig. 1, an illustrative layout for a partition, or sub-division, of a frame of video data is shown. More particularly, a frame of video data may be represented as a two-dimensional array of pixels. In some embodiments, each pixel is represented by one or more digital bits of data. For many video processing algorithms it is useful to operate on blocks of video data. These blocks of video data are two-dimensional collections of pixels<br><br>
that represent subsets, or sub-arrays, of the frame of video data. These blocks may be of any particular size, although a typical block size is eight pixels by eight pixels. The blocks of video data may be referenced in terms of an X,Y coordinate system. In such a system, each of the blocks may be viewed as being in a row and a column. In this context, a row represents a series of horizontally oriented blocks, each of which would be displayed sequentially across a display screen in a raster type of display. Similarly, a column represents a vertically oriented set of blocks. As illustrated in Fig. 1, an N x M array of blocks is shown which illustrates the partitioning of a two-dimensional frame of video data into a collection of sub-arrays (i.e. blocks). In the illustrative addressing scheme of Fig 1, arrows indicate the direction of ascending values for the X and Y coordinates. The illustrated frame of video data partitioned into blocks is a convenient device for working with this type of data because it corresponds to the spatial layout of a display generated from the frame of video data. It is noted however, that in any particular implementation of a video processing system in accordance with the present invention, video data may be stored in any convenient or suitable pattern, within a memory or similar storage system, and does not need to be distributed in a such memory system in the same order that the data would be displayed on a visual display.<br>
In motion estimators that are currently being used, in particular for scan-rate conversion, motion vectors are produced (i.e., estimated), for every other block of pixels, where a block is typically 8 pixels by 8 pixels. Consequently, motion vectors based on. actual video data are being produced for only half of the picture data. The primary reason for skipping the production of motion vectors based on actual video data for half of the blocks is to reduce the requirements for computational resources. As noted above, determining the motion vector for a block of pixels has a computational cost, and reducing the amount of computation substantially in this way, also reduces the requirement for computational resources in an electronic product, and thereby reduces the cost of that product. However, since motion vectors are required for every block of pixels in any motion-compensation process, the motion vectors for those blocks for which a motion vector computation was not performed need to be produced in a manner which is less computationally intensive than deriving the motion vectors directly from the pixel data.<br>
A common approach to generating the "missing" motion vectors in a manner that has the desired lower computational cost is to use either averaging or median filtering<br><br>
techniques (or a combination of both) to generate the motion vectors for the skipped blocks. Consistency is, therefore, inherently achieved.<br>
As noted above, under certain circumstances, a motion estimator might estimate motion for only part of a picture, that is, only for a subset of the blocks which make up a frame of video data. The motion vectors belonging to the non-estimated regions or blocks are then interpolated from the estimated motion vectors of the blocks in the direct neighborhood. One type of problem may occur, for example, at the left side of sub-titles as the first letter might fall in a block for which a motion vector is not derived based on actual video data and therefore the motion vector for that block needs to be interpolated from its neighborhood. If the vide around the sub-title is moving, it is very likely that with state-of-the-art techniques the block containing the first letter might get a non-zero motion vector, and therefore potentially cause artifacts due to motion compensation techniques.<br>
Various embodiments of the present invention provide desirable results, in terms of improved visual display in video playback, particularly in terms of reduced video artifacts. This is useful for reducing such artifacts which appear in conventional systems, particularly in picture regions containing sub-titles. These various embodiments of the present invention may be used with any number of generic interpolation processes. In this respect, embodiments of the present invention may be readily applied to a wide variety of existing video processing systems and processes.<br>
In an illustrative embodiment, a generic interpolation process is used to produce and assign motion vectors to blocks for which a motion vector was not estimated (i.e., a skipped block) in picture regions that contain only non-zero motion vectors. However, a zero motion vector is assigned to the skipped block if the estimated block on the left or right has a zero motion vector, and the estimated motion vector for the current block in the previous frame was a zero motion vector.<br>
Referring to Fig. 2, an illustrative method in accordance with the present invention is shown. The illustrative method is performed in the context of processing a series of frames of video data, wherein the frames of video data are sub-divided, or partitioned, into blocks, typically of 8 pixels by 8 pixels. In Fig. 2, "MV" indicates motion vector; "X" indicates a block coordinate in the x dimension (typically horizontal); " Y" indicates a block coordinate in the y dimension (typically vertical); and "nfI indicates the current frame of video data. With respect to a current frame of video data, motion vectors are estimated 202 for every other block, i.e., for half of the blocks of the current frame of video data. By<br><br>
estimating a motion vector, it is meant that the motion vector is derived from operations performed upon the video data. In the illustrative example of Fig. 2, a quincunx sub-sampling pattern is used. After motion vectors are estimated, a first block of the video data, for which a motion vector was not estimated, is selected 204. Let the coordinates of the first selected block be referred to as (X,Y,n). More generically, the first selected block may be referred to as the current block (X,Y,n). A determination is then made 206 as to whether a motion vector for the block to the left (i.e., MV(X-l,Y,n)), or a motion vector for a block to the right (i.e., MV(X+l,Y,n), of the first selected block (i.e., (X,Y,n)) has a zero motion vector; and whether the motion vector for the first selected block in the previous frame (i.e., MV(X,Y,n-l)) was a zero motion vector. If the determination is affirmative, then a zero motion vector is assigned 208 to the current block (i.e., MV(X,Y,n) is a zero motion vector). If the determination of 206 is negative, then a motion vector is interpolated from the neighborhood of the first selected block and assigned to that block 210. After a motion vector has been assigned to the first selected block (208 or 210), a determination is made 212 as to whether all the blocks which require a motion vector to be assigned have been processed. If the determination of 212 is affirmative then the current frame has been fully processed and the system is ready for the next task 216. If the determination of 212 is negative then another block for which a motion vector was not estimated in the current frame of video data is selected 214, and the process continues at 206.<br>
It is noted that with respect to the relationship between the blocks and the motion vectors, various video compression/decompression systems use the motion vectors to reconstruct a video playback from an initial frame and from the changes indicated by the motion vectors. In other words, rather than transmitting the actual video information in the various blocks of data, motion vectors are transmitted instead. In this regard, it is said that motion vectors are "assigned" to a block, "provided" to a block, or "associated" with a block. It will be understood that these terms are used somewhat interchangeably and are meant to convey the relationship between a motion vector and block which is to be reconstructed by application of the motion vector to an "initial" frame of video data.<br>
In typical embodiments of the present invention, a plurality of frames of video data are received and processed in accordance with method illustrated in Fig. 2.<br>
Various embodiments of the present invention include methods and apparatus for reducing artifacts in processed video data. Such embodiments may be suitable for use in motion estimators and compensators. More particularly, various embodiments of the<br><br>
present invention provide improvement with respect to conventional interpolation processes used for interpolating motion vectors for non-estimated regions, or blocks.<br>
An advantage of some embodiments of the present invention includes a reduction in the video artifacts associated with subtitles in video processing systems that provide estimated motion vectors for only a portion of the blocks of a frame of video data, without processing any additional block, or pixel, data.<br>
It is noted that many alternative embodiments in accordance with the present invention are possible. In one such alternative, the motion vectors associated with blocks that are further separated, spatially and/or temporally, from the current selected block are evaluated in determining whether to assign a zero motion vector to the current selected block. It is noted that such embodiments may require additional computational resources, and in particular that embodiments which utilize blocks further temporally separated from the current block generally require additional memory resources to maintain such a history. Other alternative embodiments may include assigning a motion vector other than the zero motion vector, i.e., a predetermined but non-zero motion vector.<br>
Still other alternative embodiments may include a sampling structure other than a quincunx sub-sampling pattern. In principle, any field alternating sampling pattern may be included in embodiments of the present invention. The quincunx sub-sampling pattern has been presented to illustrate the present invention.<br>
The present invention may be implemented as circuit-based solutions, including possible implementation on a single integrated circuit As would be apparent to one skilled in the art, various functions of circuit elements may also be implemented as processing operations in a software program. Such software may be employed in, for example, a digital signal processor, micro-controller, or general-purpose computer.<br>
The present invention can be embodied in the form of methods and apparatus for practicing those methods. The present invention can also be embodied in the form of program code embodied in tangible media, such as punched cards, magnetic tape, floppy disks, hard disk drives, CD-ROMs, flash memory cards, or any other machine-readable storage medium, wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. The present invention can also be embodied in the form of program code, for example, whether stored in a storage medium, loaded into and/or executed by a machine, or transmitted over some transmission medium or carrier, such as over electrical wiring or<br><br>
cabling, through fiber optics, or via electromagnetic radiation, wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. When implemented on a general-purpose processor, the program code segments combine with the processor to provide a unique device that operates analogously to specific logic circuits.<br>
It is to be understood that the present invention is not limited to the embodiments described above, but encompasses any and all embodiments within the scope of the subjoined Claims.<br><br><br>
CLAIMS What is claimed is:<br>
1.	A method of processing video data, comprising: providing a frame of video data, the frame of video data comprising a plurality of blocks of pixels, the blocks being addressable in a two-dimensional array of rows and columns; selecting alternating blocks of the frame of video data and estimating a motion vector for the selected blocks; selecting at least one block of the frame of video data for which a motion vector has not been estimated (204), and determining whether a block to the left or a block to the right of the selected at least one block has an estimated zero motion vector (206), and determining whether the selected at least one block had an estimated zero motion vector in a previous frame (206); and providing, if the determinations are affirmative (208), a predetermined motion vector to the selected at least one block.<br>
2.	The method of Claim 1, wherein the block to the left is the block sequentially preceding the selected at least one block, the block to the right is the block sequentially following the selected at least one block, and the predetermined motion vector is a zero motion vector.<br>
3.	The method of Claim 1, wherein the previous frame is an immediately preceding frame of video data.<br>
4.	The method of Claim 1, wherein selecting alternating blocks comprises using a quincunx sub-sampling pattern.<br>
5.	The method of Claim 1, further comprising, if the determinations are negative, interpolating a motion vector from the motion vectors of the estimated blocks in the neighborhood, and providing the interpolated motion vector to the selected at least one block, and wherein the predetermined motion vector is a zero motion vector.<br>
6.	The method of Claim 1, further comprising determining whether all the blocks of the current frame of video data for which a motion vector has not been estimated have been provided with a motion vector.<br>
7.	The method of Claim 6, wherein the motion vector provided to the blocks of the current frame of video data for which a motion vector has not been estimated is selected from the group consisting of a zero motion vector and a motion vector interpolated from a neighborhood of the block being provided with the motion vector.<br>
8.	The method of Claim 7, further comprising storing the estimated motion vectors of the frame of video data.<br><br>
9.	A method of generating motion vectors for a first plurality of blocks of a frame of data, comprising: estimating a motion vector for each of a second plurality of blocks, the second plurality being a subset of the first plurality; determining for each of a third plurality of blocks, the third plurality being a subset of the first plurality, and being non-overlapping with the second plurality (204), whether a block to the left or a block to the right of each of the third plurality of blocks has an estimated zero motion vector (206), and whether each of the third plurality of blocks was assigned a zero motion vector in a previous frame (206); assigning, to each of the third plurality of blocks for which the determinations are affirmative (208), a zero motion vector; and assigning, to each of the third plurality of blocks for which the determination are negative (210), a motion vector interpolated from the estimated motion vectors of a neighborhood of blocks surrounding, respectively, each of the third plurality of blocks for which the determination are negative.<br>
10.	The method of Claim 9, further comprising selecting the second plurality of blocks as an alternating pattern in a two-dimensional array.<br>
11.	The method of Claim 9, further comprising selecting the second plurality of blocks in accordance with a quincunx sub-sampling pattern.<br>
12.	The method of Claim 9, wherein the second plurality of blocks comprises one half of the first plurality of blocks.<br>
13.	The method of Claim 12, wherein the frame of data comprises video data.<br>
14.	The method of Claim 13, further comprising receiving a plurality of frames of video data.<br>
15.	The method of Claim 14, further comprising storing the estimated motion vector for each of the second plurality of blocks.<br>
16.	The method of Claim 15, wherein the block to the left of each of the third plurality of blocks comprises the block representing the data to be respectively displayed immediately preceding each of the third plurality of blocks.<br>
17.	The method of Claim 16, wherein the block to the right of each of the third plurality of blocks comprises the block representing the data to be respectively displayed immediately subsequent each of the third plurality of blocks.<br>
18.	The method of Claim 17, wherein estimating the motion vector comprises processing pixel information within a block.<br>
19.	The method of Claim 18, further comprising storing the interpolated motion<br>
vectors.<br><br>
20.      An article of manufacture, comprising: a medium upon which machine perceivable instructions are encoded; the instructions such that when perceived and executed by the machine cause the machine to: provide a frame of video data, the frame of video data comprising a plurality of blocks of pixels, the blocks being addressable in a two-dimensional array of rows and columns; select alternating blocks of the frame of video data and estimating a motion vector for the selected blocks; select at least one block of the frame of video data for which a motion vector has not been estimated (204), and determining whether a block to the left or a block to the right of the selected at least one block has an estimated zero motion vector (206), and determining whether the selected at least one block had an estimated zero motion vector in a previous frame (206); and provide, if the determinations are affirmative (208), a zero motion vector to the selected at least one block.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1IGFic3RyYWN0IGdyYW50ZWQucGRm" target="_blank" style="word-wrap:break-word;">3227-chenp-2005 abstract granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1IGNsYWltcyBncmFudGVkLnBkZg==" target="_blank" style="word-wrap:break-word;">3227-chenp-2005 claims granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1IGRlc2NyaXB0aW9uIChjb21wbGV0ZSkgZ3JhbnRlZC5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005 description (complete) granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1IGRyYXdpbmdzIGdyYW50ZWQucGRm" target="_blank" style="word-wrap:break-word;">3227-chenp-2005 drawings granted.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1DSEVOUC0yMDA1IEZPUk0tNiAyNS0wMS0yMDEwLnBkZg==" target="_blank" style="word-wrap:break-word;">3227-CHENP-2005 FORM-6 25-01-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWNvcnJlc3BvbmRuZWNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWNvcnJlc3BvbmRuZWNlLXBvLnBkZg==" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-correspondnece-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWZvcm0gMjYucGRm" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIyNy1jaGVucC0yMDA1LXBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">3227-chenp-2005-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="228142-a-method-and-an-apparatus-for-scheduling-sub-carriers-in-an-orthogonal-frequency-division-multiplexing-ofdm-system.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="228144-pet-food-composition.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>228143</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3227/CHENP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>10/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>06-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>28-Jan-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>01-Dec-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>KONINKLIJKE PHILIPS ELECTRONICS N.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>GROENEWOUDSEWEG 1, NL 5621 BA EINDHOVEN,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DE HAAN, GERARD</td>
											<td>1109 MCKAY DRIVE, M/S 41SJ, SAN JOSE, CA 95131,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>BELLERS, ERWIN</td>
											<td>1109 MCKAY DRIVE, M/S 41SJ, SAN JOSE, CA 95131,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US04/13732</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-05-03</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/467,816</td>
									<td>2003-05-02</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/228143-biased-motion-vector-interpolation-for-reduced-video-artifacts by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 08:43:04 GMT -->
</html>
