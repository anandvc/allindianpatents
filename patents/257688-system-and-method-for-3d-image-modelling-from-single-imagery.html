<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/257688-system-and-method-for-3d-image-modelling-from-single-imagery by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:44:16 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 257688:SYSTEM AND METHOD FOR 3D IMAGE MODELLING FROM SINGLE IMAGERY</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">SYSTEM AND METHOD FOR 3D IMAGE MODELLING FROM SINGLE IMAGERY</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method for deriving three-dimensional measurement information from single images of at least one three dimensional object is provided. The method includes the steps of: (a) obtaining at least one two-dimensional single image of the object, the image consisting of image data and being associated with an image geometry model (IGM); (b) deriving three dimensional coordinate information associated with the image, based on the IGM, and associating the three-dimensional coordinate information with the image data; (c) analyzing the image data so as to: (i) measure the projection of the object using the IGM to derive measurement data including the height and/or point-to-point distances pertaining to the object; and/or (ii) measure the shadow of the object to derive measurement data including the height and/or point-to-point distance pertaining to the object; and (d) obtaining three-dimensional measurements based on the projection and/or shadow measurements of the object.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>SYSTEM, COMPUTER PROGRAM AND METHOD FOR 3D OBJECT MEASUREMENT, MODELING AND MAPPING FROM SINGLE IMAGERY<br>
Field of the Invention<br>
The present invention relates to mapping, surveying, photogrammetry, remote sensing, visualization and simulation, gaming, planning, geomatics, civil engineering, geography, and more particularly relates to the collection of measurement and dimension information of or between objects from single images, and the three-dimensional (3D) models and maps and t he s ubsequent u se of such information in analysis, modeling, mapping and visualization.<br>
Background of the Invention<br>
A conventional m ethod of measuring 3 D objects i s called s tereo-vision that obtains paired stereo images taken of the same objects. When the imagery geometry model (IGM) of each image is given, the 3D coordinate information of the objects can be determined. A photogrammetric method surveys the objects by selecting conjugate points, and thereby measure any dimension using the IGMs based on these points. The 3D models and maps are then generated by using the stereo-vision approaches.<br>
The acquisition of stereo images especially from airborne or satellite sensors is more expensive and needs a longer delivery time compared with acquiring single images. Also the majority of the archived images in the databases maintained by' imagery vendors are single images. Therefore, the use of single images has advantages for applications such as emergency mapping, defense, intelligence, telecommunication and engineering etc.<br>
There is no known system that has been developed to perform 3D measurement, modeling and mapping from the single images. The present invention has resulted in an operational method, computer program and system that can effectively obtain 3D measurements and create 3D object models and maps. The system is comprised of unique utilities and novel algorithms that are designed to make use of object projection, shadow, object geometry, and the IGM.<br><br>
The IGM describes the geometric relationship between the object space and the image space, or vice visa. The two broadly used IGMs include the physical sensor model and met generalized sensor model. The rational function model (RFM) is a kind of generalized sensor model.<br>
The following relevant prior art has been identified:<br>
Jiang, W., Tao, C.V., Hu, Y., Xu, Z., 2003. 3-D measurement from single and stereo high-resolution satellite imagery based on the RFM, ASPRS Annual Conference, 5-9 May, Anchorage, AK, 7 p. (This reference describes several experimental results obtained using RFM based methods from the satellite imagery)<br>
OpenGIS Consortium, 1999. Tlie OpenGIS Abstract Specification - Topic 7: The Earth Imagery Case. (This reference provides an overview of IGMs used in the mapping, remote sensing and geospatial industry).<br>
Tao, C.V., Hu, Y., 2001. A comprehensive study of the rational function model for photogrammetric processing, Photogrammetric Engineering  &amp; Remote Sensing, 67(12): 1347-1357. (This reference provides a detailed mathematical formulation of the RFM sensor model and its experimental study on its accuracy).<br>
Summary of the Invention<br>
In accordance with one aspect of the present invention, there is provided a method for deriving three-dimensional measurement information and/or creating three-dimensional models and maps, from single images of at least one three-dimensional object, the method comprising the steps of: obtaining at least one two-dimensional single image of the object, the image consisting of image data and being associated with an image geometry model (IGM); deriving three-dimensional coordinate information associated with the image, based on the IGM, and associating the three-dimensional coordinate information with the image data; analyzing the image data so as to: measure the projection of the object using the IGM to derive measurement data including the height and/or point-to-point distances pertaining to the object; and/or, measure the shadow of the object to derive measurement data including the height and/or point-to-point distance pertaining to the object; and<br><br>
obtaining three-dimensional measurements based on the projection and/or shadow measurements of the object.<br>
In accordance with another aspect of the present invention, there is provided a system for deriving three-dimensional measurement information and/or creating three-dimensional models and maps, from single images of at least one three-dimensional object, the system comprising: at least one computer; and a computer program operably linked to the computer so as to enable the computer to: obtain at least one two-dimensional single image of the object, the image consisting of image data and being associated with an image geometry model (IGM); derive three-dimensional coordinate information associated with the image, based on the IGM, and associating the three-dimensional coordinate information with the image data; analyze the image data so as to: measure the projection of the object using the IGM to derive measurement data including the height and/or point-to-point distances pertaining to the object; and/or measure the shadow of the object to derive measurement data including the height and/or point-to-point distance pertaining to the object; and obtain three-dimensional measurements based on the projection and/or shadow measurements of the object.<br>
In accordance with a further aspect of the present invention, there is provided a computer usable medium, the computer useable medium comprising instructions for defining a measurement utility on a computer, the measurement utility being operable to: obtain at least one two-dimensional single image of the object, the image consisting of image data and being associated with an image geometry model (IGM); derive three-dimensional coordinate information associated with the image, based on the IGMj and associating the three-dimensional coordinate information with the image data; analyze the image data so as to: measure the projection of the object using the IGM to derive measurement data including the height and/or point-to-point distances pertaining to the object; and/or measure the shadow of the object to derive measurement data including the height and/or point-to-point distance pertaining to the object; and obtain three-dimensional measurements based on the projection and/or shadow measurements of the object.<br>
The present invention provides a method for deriving 3D measurement information and creating 3D models and maps from the single imagery with the IGM<br><br>
support, including the RFM sensor model, where: (i) a single image is available, (ii) both static and dynamic objects are to be measured, (iii) no stereo viewing devices are available, or (iv) conjugate points from stereo image pairs cannot be identified.<br>
The present invention includes a system that enables measurement information to be readily accessed, and used from an image in accordance with the method of the present invention. This system consists of utilities to obtain 3D measurements and to create 3D models and 3D maps from the single image. The system consists generally of a computer system which is adapted to process instructions provided by the computer program of the present invention.<br>
The computer program of the present invention consists of a computer application that includes (1) a measurement utility that enables measurements to be made from a 2D image that supports the IGM, the measurement utility including a projection measurement utility and a shadow measurement utility. The projection measurement utility and the shadow measurement utility co-operate so as to enable point-to-point measurements by operation of the projection measurement utility, the shadow measurement utility, or both, with the support of the IGM; and (2) a model generation utility that efficiently create 3D models and maps based on measurements made by the measurement utility of the invention. With the RFM, the application can be applied for any images (e.g., satellite or aerial) supporting the RFM or the like. The present invention enables the 3D measurements, models and maps from the single images.<br>
Another aspect of the method of the present invention consists of a method for obtaining measurement information, namely, the distance between any two points in the three dimensions from a single image, and for creating 3D models from the measurements and subsequently generating 3D maps from a single image. Specifically, the present invention provides methods for:<br>
1.	Measuring the projection of an object or objects by operation of the projection<br>
measurement utility using the IGM to derive the heights, point-to-point<br>
distances of objects and the like;<br>
2.	Measuring the shadow of an object or objects by operation of the shadow<br>
measurement utility using IGM to derive the heights, point-to-point distance<br><br>
of both static (including buildings, overpasses, bridges, etc.) and dynamic objects (including airplanes in the air). These objects may not have footprints on the ground.<br>
3.	Obtaining the 3D measurements by using the cooperation of projection and/or<br>
shadow data with the IGM.<br>
4.	Creating  3D  models  and maps  by using  model  generation utility  that<br>
implements one or more algorithms.<br>
Another aspect of the method of the present invention is the application of specific algorithms of the present invention in order to take the measurements<br>
described.<br>
The present invention can be applied for any images with the RFM support. This is due to the fact that the RFM is sensor independent and can be universally applied to multiple sensors. Thus the computer program resulted from this invention can lie used for any images without a need to change its underlying sensor model.<br>
Brief Description of the Drawings<br>
A detailed description of the certain embodiments of the invention is provided herein below by way of example only and with reference to the following drawings, in which:<br>
FIG. 1 a; A conceptual drawing of a representative graphic user interface for accessing the functions of the computer program product of the present invention. The toolbar buttons illustrated enable access to the functions of the utilities of the' present invention.<br>
FIG. Ib: A program resource diagram illustrating the resources of the computer program of the present invention.<br>
FIG. 2a; The conceptual drawing of the measurement utility 8 displayed in the image display window.<br><br>
FIG. 2b: A schematic diagram showing the relationship among the projection and the shadow cast in the image, the IGM, the object, and the sun angles, assuming a flat ground surface.<br>
FIG. 3: Illustration of determining the horizontal position (X, Y) by intersecting a plane having the elevation of Z in a single image. The elevation Z is adjusted at some incremental change.<br>
FIG. 4a: A schematic diagram of the height measurement of a building using the projection measurement utility based on the IGM.<br>
FIG. 4b: Illustration of the height measurement of a building using the projection measurement utility of the present invention based on the IGM.<br>
FIG. 5: A diagram showing the relationship between the sun's position and the displacement of an object's shadow.<br>
FIG. 6: A schematic diagram illustrating the method of the present invention, and more specifically showing a method of drawing the projection and the shadow of an object, assuming a non-flat ground surface.<br>
FIG 7a: A block diagram illustrating the present invention, showing the measurement of the object height using the shadow information, for measurable shadows in the image.<br>
FIG 7b: A block diagram illustrating the present invention, showing the measurement of the object height using the shadow information, for un-measurable shadows in the image.<br>
FIG. 8a: A schematic diagram showing the taking of a height measurement using the shadow measuring utility for an object that is a building, starting from its base point.<br>
FIG. 8b: Illustration of the present invention showing the taking of a height measurement using the shadow measuring utility for an object that is a building, starting from its base point.<br>
FIGS. 9a, 9b, 9c and 9d: Illustrations of height measurement in accordance with the present invention using the shadow measurement utility for a) an airplane in the case<br><br>
of FIG. 9a, b) an overpass in the case of FIG. 9b, c) a tree in the case of FIG.9c, d) a chimney in the case of FIG. 9d, starting from their shadow endpoints.<br>
FIG. lOa: Illustration of determination of the base point using the shadow measurement utility of the present invention, where the height of the airplane is shown to be 57.1 m.<br>
FIG. lOb; Illustration of drawing a line mark in accordance with the present invention, the line connecting the base point with the landing point of the runway, and the horizontal distance being shown as being 158.1 m.<br>
FIG. lOc: Illustrating the present invention by raising the base point of the line mark to the height of the airplane, and the slant distance being show to be 165.8 m.<br>
FIG. 11 a: Illustration of operation of the present invention to draw a line mark connecting the base points of the two objects.<br>
FIG. lib: Illustration of the present invention by showing in operation the raising of the base points at the two ends of the line mark to the height of their respective roof.<br>
FIG. 12a: Illustration of one particular aspect of the present invention, whereby the base points of the head point and the tail point of the airplane are determined.<br>
FIG. 12b: Further illustration of the particular aspect of the present invention shown in FIG. 12a: whereby the line connecting the two base points is shown.<br>
FIGS. 13a and 13b: Further illustrate the present invention whereby the heights of a multi-layered building are measured; whereby in FIG. 13a the height of the first layer of the roof is measured and locked, and this height is 31 m, and whereby in FIG. 13b the height of the second layer of the roof relative to the first layer is measured starting from the locked height.<br>
FIG. 14: Aschematic diagram of compensating the s ystematic b iases of the object dimensions measured without using digital terrain models (DTM).<br>
FIGS. 15a, 15b, 15c, 15d and 15e: Illustrations of the base selection method for 3D mapping in accordance with the present invention; whereby in FIG. 15a the base point is selected, whereby in FIGS. 15b and 15c the Z level is changed via the user<br><br>
dynamically updating the annotation and current Z level (as given by the yellow line in actual cases); whereby in FIG. 15d, the top of the building is outlined using a 3D mapping tool (polygon); whereby in FIG. 15e the building footprint is enabled and<br>
displayed.<br>
FIGS. 16a, 16b, and 16c: Illustration of the roof-footprint displacement method for 3D modeling of flat roof buildings in accordance with the present invention: whereby in FIG. 16a, the mapping of the roof outline is shown using the 3D polygon mapping tool; whereby in FIGS. 16b is shown the horizontal displacement of the roof outline to coincide with the base of the building; whereby in FIG. 16c is shown that the 3D building model is constructed.<br>
FIG. 17. A schematic diagram of roof shapes supported in modeling buildings with gable, clipped gable, hip and shed roof shapes.<br>
FIGS. 18a, I8b: Illustration of the creation of the 3D vector maps from 2D vector maps in accordance with the present invention: whereby in FIG. 18a, is shown the selection of 2D mapped vector after import into the computer program; whereby in FIG. 18b, is shown the 2D mapped vector mapped into a 3D vector by raising it to the lop of the building through the use of the IGM.<br>
FIG 19: A system diagram generally illustrating the deployment of the invention for web and network environment.<br>
In the drawings, preferred embodiments of the invention are illustrated by way of examples. It is to be expressly understood that the description and drawings are only for the purpose of illustration and as an aid to understanding, and are not intended as a definition of the limits of the invention.<br>
Detailed Description of the Preferred Embodiment /.         General Description of the Invention<br>
In one aspect of the present invention, a computer program is provided to obtain measurements of single, compound, multiple objects and object-to-object relations from single imagery using measurement utility and subsequently create 3D models and maps using model generation utility. 3D models and maps are conventionally performed using stereo image pairs (generally referred to as "stereo<br><br>
pairs" in this context). The present invention is best understood, in one embodiment thereof, as a software product that is capable of obtaining 3D measurements and producing 3D models and maps from the single images.<br>
The interface of the computer program is best understood by reference to FIG.<br>
1	a. Elements of the computer program of the present invention are best understood in<br>
reference to 1TG. 1 b. Utilities derived from the invention allow for the development<br>
of 3D models and maps by using measurements obtained from a single image.<br>
The method of the present invention is best understood by reference to FIGS.<br>
2	to 17, and is further described below.   The computer program of the present<br>
invention consists of a computer application that is adapted to provide instructions to<br>
a computer to implement the method o f the present invention.   The system o f the<br>
present invention is best understood by reference to FIG. Ib.<br>
In one aspect thereof, the present invention provides the measurement utility 8 designed to obtain 3D measurements of and between objects from single imagery by using the projection, or the shadow, as well as their combination (as shown in FIGS. 1 a and Ib) and model generation utility 9 designed to generate 3D models and maps.<br>
•	This invention allows the collection of a wide range of measurements<br>
as well as their derivatives (e.g., volume).<br>
•	This invention uses the model generation utility 9 to quickly and<br>
effectively construct 3D models (e.g., building) including complex<br>
roof structures and subsequent 3D products (3D site maps and 3D<br>
urban or natural scenes) all from single imagery.<br>
•	As stated earlier, conventionally, 3D models are extracted by using<br>
stereo image pairs. Often special viewing devices are required to<br>
perform the extraction work. With this invention, 3D measurements<br>
and 3D models can be obtained without using stereo images or the<br>
special viewing devices.<br>
•	With the use of RFM as the underlying IGM, the present invention can<br>
be used for any sensor images (satellite and aerial, etc.) with the RFM<br><br>
support and without changing any program configurations. The present invention becomes scalable, flexible and interoperable for any sensor imagery. That is, one program can support multiple sensory images.<br>
•	Moreover, measurements o f many d ynamic o bjects such as vehicles,<br>
airplanes, clouds etc. including their moving features can be obtained<br>
in accordance with the present invention, e.g., the height and bearings<br>
of an airplane. Most airborne or satellite based stereo pairs are not<br>
captured at the same time. Thus the dimensions of the moving objects<br>
are not readily measured using stereo pairs.<br>
Measurements that are enabled by the present invention include: height, distance in 3D dimension, line of sight distance (e.g., distance between two building roof tops, distance between the tower and the receiver), volume, bearings in 3D and their derivatives. 3D models and maps can be generated using measurement information by using model generation utility. 3D models can be buildings, containers, tanks, towers etc. with complex roof structures.<br>
The objects that can be measured in accordance with the present invention<br>
include:<br>
•	A single object on the ground e.g., building, tower, tree etc or 'above'<br>
the ground surface e.g., airplane, bridge, etc.<br>
•	Compound objects: multi-layered complex building roofs, complex<br>
constructions, etc.<br>
•	Multiple objects: a cluster of objects, e.g., volume estimation of a<br>
residential building block, damage assessment of forested area<br>
•	Object-to-object relationships:  measurements relating to  object-to-<br>
object spatial relationships, e.g., the 3D distance between a cellular<br>
tower and a receiver situated at a moving ground vehicle.<br>
The object can be either stationary (e.g., buildings, trees etc.) or dynamic (e.g., airplane, moving vehicle etc.). It also includes real objects and synthetic objects (i.e., computer generated).<br><br>
The present invention is capable of measuring, modeling and mapping objects at various levels of details or ground sampling distances. Single imagery referred to in this disclosure may include:<br>
•	Satellite images<br>
•	Aerial images<br>
•	Ground images, and<br>
•	Other images acquired by sensors with an appropriately calibrated<br>
image geometry model such as the RFM.  The  ground sampling<br>
distances of these images can range from several inches to several<br>
meters.<br>
2.        Description of the Interface<br>
FIG. la provides a conceptual drawing of a representative user interface for accessing the functions of the measurement utility 8 and the model generation utility 9 of the present invention. The user interface is provided in a manner that is known.<br>
•	Burton 1 displays the image coordinates of the mouse in the image<br>
plane.<br>
•	Button  2   displays  the  ground   coordinates   of  the   object  point<br>
corresponding to the image point, and the ground coordinates are<br>
computed using EQU. 1 as shown in FIG. 3. The datum and map<br>
projection are preferably set in a dialog box.<br>
•	Button 3 allows the input of image, IGM and DTM data (optional) to<br>
the program<br>
•	Button 4 allows the output of 3D information including dimensions,<br>
models and maps.<br>
•	Button 5 rums the measurement utility 8 on/off. A dialog box in the<br>
system gives two radio buttons for the selection of either the projection<br>
measurement   utility    12   (or   projection   ruler)   or   the   shadow<br><br>
measurement utility 14 (or shadow ruler) (these utilities are illustrated in FIG. Ib). Button 6 turns the model generation utility 9 on/off. The computer program, in one particular aspect thereof, implements a series of novel algorithms for generating 3D models and maps, as<br>
particularized below.<br>
•	Button 7 displays the drawing results and associate information.<br>
It should be understood that the present invention contemplates the use of alternate user interfaces for enabling an operator to access the functions of the measurement utility 8 and the model generation utility 9.<br>
3.        Measurement Utility<br>
As stated e arlier, the present invention provides a measurement utility 8 to measure the dimensions of and between objects from single imagery with, an IGM. The measurement utility 8 enables the processes of the present invention thereby permitting 3D measurement using the projection or the shadow information or their combination. The measurement utility 8 is best understood as a Windows ™ program that enables the display of single imagery (as described above) in accordance with its imagery geometry, and processing of such single imagery in accordance with the method of the present invention. Specifically, the measurement utility 8 enables an operator to use a mouse or other suitable interface device to point and click on selected points in the image, and thereby take the measurements particularized below.<br>
The measurement utility 8 is programmed in a manner that is known. The disclosure herein illustrates a representative computer application embodiment of the measurement utility 8 of the present invention. As illustrated in FIG. Ib, the measurement utility 8 is linked to a display facility 10 for displaying the images. The measurement utility 8 is also linked to a data input source 11. This input data source 11 stores all the data needed for the 3D measurements of objects, including the image data, the IGM and the DTM (optional). The data input for operation of the measurement utility 8 is either stored to the database (or the file) (not shown), or in other embodiments, analyzed on the fly. The calculator 13 supports the functions of the projection measurement utility 12 and shadow measurement utility 14. The calculator 13 is best understood as a utility that processes the input data in accordance<br><br>
with the methods and equations described herein. The calculator also analyzes the input data based on the model data (IGM or DTM, for example), and therefore is also best understood as a modeler and/or analyzer as well. The model generation udlity 9 is linked to the measurement utility 8. It implements algorithms that allow for the efficient reconstruction of 3D models.<br>
•	The present invention in one embodiment thereof relies on a particular<br>
imaging process determined by the applicable IGM.    The imaging<br>
process generally provides the orientation information of the imagery.<br>
In a particular embodiment of the invention, the IGMs used is the<br>
rational function model, i.e. a sensor model (OGC, 1999; Tao and Hu,<br>
2001)   that   is   capable   of  supporting   multiple   sensors   (sensor<br>
independence). The IGM used can also include the well known models<br>
such   as   those   based   on   collinearity   equations,   direct   linear<br>
transformation and others etc.<br>
•	The images used can be acquired by ground, airborne or satellite<br>
platforms using different imaging sensors such as frame, pushbroom or<br>
SAR etc.<br>
•	The measurement utility 8 is preferably programmed such that it can<br>
combine the projection and shadow of objects so as to measure such<br>
objects (as particularized below).<br>
•	The measurement utility 8 i s also preferably programmed (as stated<br>
earlier) to implement the processes particularized below for measuring<br>
dynamic objects such as airplanes.<br>
•	The measurement utility 8 can measure objects on the ground or above<br>
the ground surface such as overpasses, bridges, viaducts etc. The<br>
objects above the ground do not have physical base points on the<br>
ground.<br>
The measurement utility implements algorithms that are based on projections or shadows of objects as well as both.<br><br>
The conceptual explanation of the relationships between the elements of the measurable projection and shadow (including the base point 15, the tip point 16 and the shadow endpoint 17) is best understood by reference to FIG. 2a. FIG. 2b shows the schematic diagram of the present invention about the relationship among the object, the IGM and the sun angles. An object is extruded vertically on the ground, and its height is h. If the 3D coordinates of the base point are (Xo, YQ, ZQ), the true tip of the object is at (Xo, Y0, Z2). Z0 is the elevation of the bottom of an object, which can be retrieved from the digital terrain model (DTM) or a constant plane, or a value set by user. Z2 is the elevation of the tip of an object.<br>
The following equation is used to solve the (X, Y), as shown in FIG. 3.<br>
(Figure Removed)<br>
where r and c are the row and column coordinates of the selected point in the image; r and c are estimated values, and AX and A7 are corrections.<br>
3.1       Projection Based Measurement Algorithm<br>
The operator can obtain the height measurements by adjusting the elevation Z.<br>
Example 1 - measuring when the full projection is visible<br>
An experiment was conducted to demonstrate advantages of the present invention in connection with projection-based measurement. A projection ruler can be drawn, visualizing adjusted height information iteratively until the ruler line reaches the true tip of the object. In Figure 4a, line 1001 represents the outline of the building. As the operator begins by indicating the base of the building (thick black circle 1002) and then raises the height (thick black line 1003} of the floating cursor. As the cursor is raised iteratively, its position in the image is computed by the IGM on in the real time and the cursor is continuously drawn in the graphic user interface. Once the cursor touches the roof edge in the image (thick black circle 1004), this interactive procedure stops. In actual interface line 1003 will be appeared as green as a representative embodiment of the present invention. The height of the roof, as shown<br><br>
in FIG. 4b is 48.6 m. This operation can be done at the boundary of the object's footprint.<br>
3. 2       Shadow Baaed Measurement Algorithm Measurement on Flat Ground Surface<br>
As shown in FIG 2b, the 3D coordinates of the shadow endpoint are (X\, Y\, Zj), and Z| is equal to Zo for a flat ground surface. The shadow length / of the shadow is determined by the sun's altitude. The relationship among the length / , the object height h and the sun altitude is determined by the following equations on the flat ground surfaces:<br>
where h is the height of the object, Q is the sun's altitude.<br>
In FIG. 2b, assuming the terrain is flat, the coordinate offsets of the shadow endpoint relative to the object's position on ground, as shown in FIG. 5, are obtained<br>
by:<br>
AX - X1 - Xh - 1 • sin(or) = h • sin a / tan QMeasurement on Non-flat Ground Surface<br>
The relationship among the shadow length / on the flat ground and the shadow length s on the slope with an angle of (//, the object height h and the sun altitude is determined by the following equations on non-flat ground surfaces as shown in FIG. 6:<br>
(Figure Removed)<br>
Different cases of terrain relief are examined.<br>
Steps of shadow based measurement<br>
FIG. 7a illustrates the application of the method of the present invention to the measurable shadow of an object. This process flow generally has five steps. The operator selects the base point in the image, whose ground coordinates are calculated using EQU. 1. Then, the operator adjusts the value of the Zby the incremental change AZ. The ground coordinate offsets of the shadow endpoint are obtained using EQU. 3 for flat ground, or EQU. 4 for non-flat ground at the vicinity of the object. The shadow endpoint is cast in the image using the ground-to-image transformation of the IGM, and the shadow ruler is plotted. The process is terminated if the shadow ruler fits the image line well.<br>
FIG. 7b shows the process for the immeasurable shadow of an object. This workflow generally has six steps. The operator should select the shadow endpoint in the image, whose ground coordinates are also calculated using EQU. 1. Then, the operator adjusts the elevation Zby the AZ . The computed offsets are subtracted from the endpoint to estimate the ground coordinates of the base point. Both the projection ruler and the shadow ruler are plotted. The projection ruler is used to judge if it reaches the true tip of the object. The process is terminated if the both rulers fit the visible parts of the projection and the shadow well in the image.<br>
Example 2 -measuring when the full shadow is visible<br>
An experiment was conducted to demonstrate advantages of the present invention for the purpose of • shadow-based measurement. A shadow ruler (in actual interface the line will be appeared as blue as a representative embodiment of the present invention) is drawn on the image in the graphic user interface illustrate herein. Height information is iteratively adjusted until the ruler line fits the whole shadow in the image. As shown in FIG. 8a, the operator begins by locating the end point of the object's shadow (circle 1005) in the image and then raises the height of the floating<br><br>
cursor. As the cursor is raised, the position of the base point is updated as described in FIG. 7b, and their locations in the image are computed by the IGM. A line (dotted line 1006) connecting the base point and shadow endpoint and a second line (1007) connecting the base point and the raised cursor are drawn in the graphic user interface. Once the cursor reaches the top edge of the object in the image (circle 1008), this interactive procedure stops. The height of the roof, as shown in FIG. 8b is 48.4 m, which is close to theheight value measured u sing the projection utility in Example I.<br>
Example 3 —measuring when the projection and shadow are partially visible<br>
Several cases are performed to demonstrate advantages of the present invention of shadow-based measurement for immeasurable projections and shadows. In following cases, the base points of the objects can not be located reliably or do not exist, but the shadow ruler can locate the base point accurately. In FIG. 9 the shadow (1009) is measured by a dotted line, and the projection (1010) is measured by a bold line. The intersection of the two lines is the base point to be located.<br>
FIG. 9a shows the measurement of an airplane in the air. The airplane is in the air and has no physical base point on the ground. The measured height is 57.1 m. In FIG. 9b, an overpass is measured, the dotted line (1011) is the measured shadow length and the thick line (1012) is the measured projected height (13.8 m). In FIG. 9c, a tree is measured, the dotted line (1013) is the measured shadow length and the thick line (1014) is the measured projected height (29.4 m). FIG. 9d shows the measurement of a chimney whose base point can be located accurately, and the height is 100.7 m. The dotted line (1015) is the measured shadow length and the thick line (1016) is the measured projected height, As shown in FIGS 9a to 9d, the base points of these objects can be inferred from the shadow endpoints when using information about the sun's position and the IGMs and in actual cases a representative embodiment of the these inventions of the measured shadow will be appeared as blue line and the measured projection will be appeared as green line.<br>
Example 4 —measuring object-to-object relations<br>
An experiment was conducted to demonstrate advantages of the present invention for dimension measurement between any two points of two objects.<br><br>
As shown in FIG. lOa, the base point of the airplane on the ground is determined using the shadow ruler, and the height of the airplane is 57.1 m (thick line 1017). Then a line mark (dash dot line 1018) is drawn (FIG lOb) to connect the base points and the landing points of the runway of the airport, and this distance on the ground is 15S.I m. Last in FIG lOc, the base point of the line mark is raised to the airplane's height, and the slant distance (dash dot line 1019) becomes 165.8 m.<br>
As shown in FIG. lla, the slant distance (dash dot line 1019) is 193.1 m when connecting the two base points of the two buildings. Both points are raised to their corresponding roof heights using the projection ruler, and the slant distance (dash dot line 1020) becomes 193.3 in in FIG. lib.<br>
Example 5 — measuring the bearing of objects<br>
An experiment was conducted to demonstrate advantages of the present invention of bearing measurement of any object. As shown in FIG. 12a, the base points of the head point (at 1021) and the tail point (at 1022) of the airplane are determined using the shadow ruler. Then a bearing line mark (dash line 1023) is drawn to connect these two base points as shown in FIG. 12b, and the angle is 285.2° under the UTM map projection.<br>
Example 6 — measuring compound objects<br>
An experiment was conducted to demonstrate the advantages of the present invention of height measurement of buildings with complex structures. As shown in FIG. 13, the different levels of a multi-layered building roof can be measured from single images using the projection and/or shadow rulers. In FIG. I3a, the height (line 1024) of the first layer of the roof is measured using the projection ruler and then the height in the system is locked, and this height is 31 m. The height (line 1026) of the second layer of the roof relative to the first layer is measured starting from the locked height, and this height is 5.5 m as shown in FIG. 13b. This shows that the height of the second layer is 36.5 relative to the ground surface.<br>
3.3       Compensation of systematic biases<br><br>
When the measurements are performed with the absence of DTMs and/or GCPs, some systematic biases occur at both vertical and horizontal directions. This results in changes in their dimensions and also makes the positions of the objects measured displaced.<br>
As shown in FIG. 14, the measurement error (A/z) of the object height is determined by the flying height (H), the object height (/i), and the vertical shift (A//) due to the terrain availability as given by<br>
(Figure Removed)<br>
where h' is the measured object height using the measurement utilities. Using EQU. 8a, the systematic errors of the object heights due to the vertical drifts can be compensated automatically for those objects when DTMs become available later. Each object's height is corrected separately since it usually has a different base height.<br>
Similarly, the error of the horizontal dimensions of objects is determined by<br>
(Figure Removed)<br>
where /' and / are the measured and true object dimension, respectively. Using EQU. 8b, the systematic errors due to the vertical drifts can be compensated for automatically in the same manner as described above for those object dimensions measured in 3D when DTMs become available later.<br>
The corrections to the displacements of objects due to the absence of DTMs can be accomplished by the calculation of that displacement for any point of the object. This process involves a few steps. First, both the raw image and the DTM are loaded into the computer system. Second, the measured 3D object models are loaded. In one particular embodiment, a message is popup to indicate if the bias compensation is needed. If so, a point (for instance, the first point) belong to the 3D models is projected to the image plane using the IGM. Then the projected image point is intersected with the DTM using EQU. 1. Third, the difference in the X, Y, and Z coordinates between the original position of that point and its position intersected with<br><br>
the DTM is calculated. Fourth, every point belongs to the 3D model is shifted by the same difference. The updated 3D models are preferably saved back to the disk files.<br>
The corrections to the displacements of objects due to the absence of GCPs can also be accomplished by carrying out a four-step procedure. First, the raw image, GCPs and optionally the DTM are loaded into the computer system, and the IGM is improved by using the GCPs, Second, a point (for instance, the first point) belonging to the 3D models is projected to the image plane using the original IGM. Then the projected image point is intersected with the DTM by using EQU. 1 and the improved IGM. Third, the difference in the X, Y, and Z coordinates between the original position of that point and i ts p osition i ntersected a gain is calculated. Fourth, every point belonging to the 3D model is shifted by the same difference. The updated 3D models are saved back to the disk files.<br>
4.	Collection of Measurements and Their Derivatives<br>
Accordingly, as stated above the computer program of the present invention is operable to collect a wide range of 3D measurements of and between objects. It utilizes the objects' projection, shadow and their combinations by using the measurement utility 8 as particularized above.<br>
Many measurement derivatives can be developed after obtaining the measurements in a manner that is known. These derivatives include but are not limited to volume, bearings, area, height difference, line of sight, etc. Measurements and their derivatives can be used to generate many 3D products for urban planning, landscape analysis, transportation and hydrological watershed analysis, emergency response, disaster mitigation, and so on.<br>
5.	Creation of 3D Models and Maps<br>
The computer program of the present invention creates 3D models and maps by using the model generation utility.<br>
Example 7 - 3D model creation via base selection method<br>
In this approach to mapping a 3D structure the Z level adjustment mode is enabled followed by marking the base of the structure using a mouse or similar pointing device (FIG. 15 a). Also, various key combinations can be used to<br><br>
accommodate locking/unlocking the cursor. The Z level is then adjusted for example using the page up/ page down keys and the change in the Z level (thick line 1027) is visualized to the user (in actual case by a yellow line) in the image plane (FIG. 15 b). When the desired level is reached (FIG. 15 c) the user selects the 3D mapping tool, typically a polygon tool, and outlines the top (thick line 1028, in actual case by a predefined line color) of the structure as shown in FIG. 15d. The Z level adjustment mode can be disabled and the base point of the projected structure can then be checked by enabling the display footprint mode. The foot print mode uses the IGM to draw the projected footprints (dotted line 1029, in actual case it is a dark color of the pre-defined outlined line color) as shown in FIG. 15e. The desired 3D model can then saved into a database or file structure (not shown) if persistence storage is required. It can also be used to generate a 3D virtual scene by capturing the visible faces of the building and using them as textures in 3D visual models (not shown).<br>
Example 8 - 3D model creation via roof-footprint displacement method<br>
The process of performing a 3D building modeling can be accomplished by carrying out telative displacement or motion between the roof and the footprint. This approach to mapping a 3D structure captures its perimeter by first digitizing its roof outline (thick line 1030 as shown in FIG. 16a) as projected in image plane. This outline is then shifted in image plane (FIGS. 16b) to align with the base of the staicture using the IGM. In the example provided, this is accomplished via pressing the page up/ page down keys (FIG. 16b). This algorithm can create 3D models (FIG. 16c) when part of the model footprint is not visible.<br>
Many types of the building roof shapes a re supported in this computerized system. As shown in Figure 17, some typical roof types are fiat, gable, clipped gable, hip and shed roof shapes. The computer program can produce 3D building models with any complex roof types by the combination of the basic roof types.<br>
Example 9 - generation of 3D maps from 2D vectors<br>
The 2D vector coordinates (r, c) are loaded into the computer application, and for each 2D position a Z level coordinate is assigned coinciding with the base level of the mapped feature (FIG. 3). Each feature is then mapped into the 3rd dimension through the following actions:<br><br>
The user selects a feature (thick line 1031, usually denoted by 8 circles) to be mapped (FIG, 18a) into the 3rd dimension and then presses the page up key to change the Z level coordinates of all nodes in the feature. Changes in the Z level are projected into image plane via the IGM giving visual feedback on the changing in Z level. When the desired level is reached (FIG. 18 b) the user ceases changing the Z level and may opt to save the feature to the database (not shown).<br>
6.	Accuracy Assessment<br>
The measurement accuracy has been extensively tested and evaluated. In a summary, these testing results suggest that sub-meter accuracies can be achieved, and are thus acceptable for a wide range of commercial applications. The accuracy is dependent the flying height, object height, terrain availability, image resolution, image pixel measurement, and IGM accuracy.<br>
The present invention also contemplates integration of additional features to enhance the operation of the present invention. For example, processes may be built into the functions of the measurement utility that enable, based on predetermined parameters, more efficient convergence.<br>
7.	Computer Platform<br>
The measurement utility and the model generation utility can be deployed in most popular computerized platform such as a PC, workstation, server, PDA, etc due to its simplicity to deploy, low overhead to computing, less restriction to the IGM (i.e., RFM) and no requirement for stereo viewing devices.<br>
8.	Web or Network Enabled Environment<br>
The measurement utility 8 and the model generation utility 9 are ideal for network-based applications such as web, internet as well as wireless networks given its simplicity to deploy, low overhead to computing, less restriction to the image geometry model and no requirement for stereo viewing devices.<br>
FIG. 19 shows that the invention can be deployed in various forms (shaded component) in a web-enabled environment. It can be deployed as a client application 20, web browser-based plug-ins (ActiveX controls) or Java applets 22, Application server 24 and Portal-based web service 26. The invention can also be embedded in<br><br>
wireless  portals,  PDAs   or  cell-phones  etc.   computerized  platform  with  little modification, in a manner that is known.<br>
9.        Commercial Applications<br>
This invention enables exploitation of the benefits of images for a wide range<br>
of applications including:<br>
•	Obtaining critical facility and target information such as building<br>
height, bridge clearance, road width, runway length, or forest cuts;<br>
•	Creation of 3D site maps of key facilities such as nuclear power plants,<br>
airports, urban cities, critical infrastructures for public safety and<br>
international intelligence;<br>
•	Measuring area of damage (such as forest fire, flood, earthquake)<br>
caused by disasters for insurance audits and emergency response;<br>
•	Modeling and planning for urban development, visualization and<br>
simulation, gaming, government, transportation, civil engineering etc.<br>
Its applications are broad:<br>
•	Defense<br>
•	Environment<br>
•	Homeland Security<br>
•	Telecom<br>
•	Visualization and Simulation<br>
•	Agriculture<br>
•	Local Government<br>
•	Geology<br>
•	Mapping<br><br>
•	Forestry<br>
•	Utilities<br>
•	Real Estate<br>
•	Transportation Planning<br>
•	Insurance<br>
•	Media<br>
•	Entertainment and Gaming<br>
Other variations and modifications of the invention are possible. For example, additional features can be built into the computer program product of the present invention to build on the basic 3D measurement and model data provided herein to provide for example density per square km, urban shadow estimation, etc based on single imagery. The computer product of the present invention can be integrated with other applications. All such modifications or variations are believed to be within the sphere and scope of the invention as defined by the claims appended hereto.<br><br><br><br><br>
We Claim:<br>
1.	A method for deriving three-dimensional measurement information and/or creating<br>
three-dimensional models and maps, from single images of at least one<br>
three-dimensional object, the method comprising the steps of:<br>
(a)	obtaining at least one two-dimensional single image of the object, the image consisting of image data and being associated with an image geometry model (1GM);<br>
(b)	deriving three-dimensional coordinate information associated with the image, based on the IGM, and associating the three-dimensional coordinate information with the image data;<br>
(c)	analyzing the image data so as to:<br>
(i) measure the projection of the object using the IGM to derive measurement data including the height and/or point-to-point distances pertaining to the object; and/or<br>
(ii) measure the shadow of the object to derive measurement data including the height and/or point-to-point distance pertaining to the obj ect; and<br>
(d)	obtaining three-dimensional measurements based on the projection and/or<br>
shadow measurements of the object,<br>
2.	The method as claimed in claim 1, wherein the image data is analyzed by operation of a measurement utility.<br>
3.	The method as claimed in claim 1, wherein the method comprises the step of creating three-dimensional models or maps based on the projection and/or shadow measurements,<br>
4.	The method as claimed in claim 1, wherein the method comprises the step of creating three-dimensional models or maps by operation of a model generation utility that is operable to utilize data provided by the measurement utility to create three-dimensional models or maps.<br>
5.	The method as claimed in claim 1, wherein a Rational Function Model (RFM) is<br>
used as the IGM.<br>
6.	The method as claimed in claim 1, wherein the projection of the object is measured using a projection ruler, and the shadow thereof is measured using a shadow ruler, each of the projection ruler and shadow ruler being accessible via a graphic user interface linked to the measurement utility.<br>
7.	The method as claimed in claim 6, the method comprises the step of an operator using the projection ruler, wherein the projection ruler fits the object's projection in the image, and wherein:<br><br>
(a)	where the projection is measurable, the projection is fully cast in the image from the base point to the true tip of the object; and<br>
(b)	where the projection is not measurable, the method comprises casting the unmeasurable projection.<br>
8.	The method as claimed in claim 6, the method comprises the step of an operator<br>
using the shadow ruler, wherein the shadow ruler fits the object's shadow in the<br>
image, and wherein:<br>
(a)	where the shadow is measurable, the shadow is fully cast in the image from the base point to the endpoint of the shadow; and<br>
(b)	where the shadow is not measurable, the method comprises casting the unmeasurable shadow.<br>
9.	The method as claimed in claim 8, wherein the method comprises the steps for<br>
measuring the shadow of the object where the shadow of the object is measurable:<br>
(a)	a user selecting a base point in the image by operation of a graphic user<br>
interface associated with the image;<br>
(b)	calculating the ground coordinates of the base point using the IGM by operation of a measurement utility;<br>
(c)	adjusting the height of the object by selecting and adjusting the height of the object by operation of the graphic user interface;<br>
(d)	the measurement utility calculating the offsets of the estimated shadow endpoint relative to the base point; and<br>
(e)	the user casting a shadow endpoint of the object to the image by operation of the measurement utility using the 1GM.<br>
10.	The method as claimed in claim 8, wherein the method comprises the steps for<br>
measuring of the shadow of the object where the shadow of the object is not<br>
measurable:<br>
(a)	a user selecting a shadow endpoint in the image by operation of a graphic user interface associated with the image;<br>
(b)	calculating the ground coordinates of the shadow endpoint using the 1GM by operation of a measurement utility;<br>
(c)	adjusting the height of the object by selecting and adjusting the height of the object by operation the graphic user interface;<br>
(d)	the measurement utility calculating the offsets of the estimated shadow endpoint relative to the base point;<br>
(e)	the measurement utility calculating the position of the corresponding projection ruler; and<br>
(f)	the user casting a base point of the object to the image when the projection ruler reaches the true tip of the object by operation of the measurement utility using the 1GM.<br>
11.	The method as claimed in claim 9, wherein the measurement utility calculates the ground<br>
coordinates (X, Y) of the base point by processing the following equation;<br>
(Equation Removed)<br>
where r and c are the row and column coordinates of the selected point in the image;<br>
and c are estimated by substituting the approximate values of X, Y, and Z into the 1GM; X and f are corrections to the initial values; and ar/aX , ar/aY, ac/aX and ac/aY are partial derivatives.<br>
12.	The method as claimed in claim 9, wherein the offsets of the shadow are calculated for<br>
flat ground in the vicinity of the object by processing the following equation:<br>
(Equation Removed)<br>
where h is the height of the object,  is the sun's altitude at the time the image was taken, and 1 is the shadow length,<br>
13.	The method as claimed in claim 9, wherein the offsets of the shadow are calculated for<br>
non-flat ground in the vicinity of the object by processing the following equation:<br>
(Equation Removed)<br>
where<br>
(Equation Removed)<br>
l is the shadow length on the flat ground, s is the shadow length on the slope with an angle of  , the object height is h, and the sun altitude is .<br>
14.	The method as claimed in claim 9, wherein the length of the shadow of the object,<br>
where the object is positioned on a flat surface, and where the coordinates of the<br>
shadow endpoint are (X1, Y1,  Z1 )and    Z1 is equal to    ° for the flat surface, is<br>
calculated by processing the following equation:<br>
(Equation Removed)<br>
where h is the height of the object,  is the sun's altitude at the time the image was<br>
taken.<br>
15.	The method as claimed in claim 1, wherein the three-dimensional measurements include one or more of: (a) height, (b) distance in 3D, (c) line of sight distance, (d) volume, or (e) bearings in 3D.<br>
16.	The method as claimed in claim 1, wherein the method comprises the steps for deriving measurement information from a single image of at least one three-dimensional object, where the full projection of the object is visible in the image, the method comprising the further steps of:<br><br>
(a)	a user selecting a base point in the image by operation of a graphic user interface associated with the image;<br>
(b)	calculating the ground coordinates of the base point using the IGM by operation of a measurement utility;<br>
(c)	adjusting a selected length of the object by selecting and adjusting the selected length of the object by operation of the graphic user interface; and<br>
(d)	the measurement utility calculating the selected length of the object.<br>
17.	The method as claimed in claim 1, wherein the method comprises the steps for deriving<br>
measurement information from a single image of at least one three-dimensional object,<br>
where the full shadow of the three-dimensional object is visible in the image, the method<br>
comprising the further steps of:<br>
(a)	a user drawing a shadow ruler on the image by operation of a graphic user interface associated with the image;<br>
(b)	the measurement utility calculating the coordinates of the shadow endpoint and the base endpoint using the IGM;<br>
(c)	the measurement utility also calculating the coordinates of the endpoint and the base point of the corresponding projection ruler using the IGM;<br>
(d)	the user iteratively adjusting height information associated with the object, by<br>
operation of the graphic user interface, until the shadow ruler fits substantially the entire shadow of the object and/or the projection ruler reaches the true tip of the object; and<br>
(e)     the measurement utility calculating the height of the object using the IGM.<br>
18.	The method as claimed in claim 1, wherein the method comprises the steps for deriving<br>
measurement information from a single image of a three-dimensional object whose base<br>
point is not visible or does not exist comprising the further steps of:<br>
(a)	a user drawing a shadow ruler on the image by operation of a graphic user interface associated with the image;<br>
(b)	the measurement utility calculating the coordinates of the shadow endpoint and the base endpoint using the IGM;<br>
(c)	the measurement utility also calculating the coordinates of the end point and the base point of the corresponding projection ruler using the IGM;<br>
(d)	the user iteratively adjusting height information associated with the object, by operation of the graphic user interface, until the projection ruler reaches the true tip of the object; and<br>
(e)	the measurement utility calculating the height of the object using the IGM.<br><br>
19.	The method as claimed in claim 1, wherein the method comprises the step of compensating for systemic biases occurring in horizontal and vertical directions when capturing the single image.<br>
20.	The method as claimed in claim 3, wherein the method comprises the step of establishing the shape geometry for the object, and using the object shape geometry for creating the three-dimensional models and/or maps.<br>
21.	The method as claimed in claim 3, wherein the method comprises the step of creating 3D models of varying shapes by operation of a model generation utility.<br>
22.	The method as claimed in claim 3, wherein the method comprises the steps of creating 3D models of varying roof structures by operation of a model generation utility.<br>
23.	A system for deriving three-dimensional measurement information and/or creating<br>
three-dimensional models and maps, from single images of at least one<br>
three-dimensional object, the system comprising:<br>
(a)	at least one computer having a processor and a storage; and<br>
(b)	instructions provided by the processor operably linked to the computer so as to enable the computer to:<br>
(i) obtain at least one two-dimensional single image of the object, the image consisting of image data and being associated with a sensor of an image geometry model (1GM);<br>
(ii) derive three-dimensional coordinate information associated with the image using an interface device, based on the 1GM, and associating the three-dimensional coordinate information with the image data;<br>
(iii)   analyze the image data so as to:<br>
(A)	measure the projection of the object using the 1GM to derive measurement data including the height and/or point-to-point distances pertaining to the object; and/or<br>
(B)	measure the shadow of the object to derive measurement data including the height and/or point-to-point distance pertaining to the object; and<br>
(iv) obtain and store the three-dimensional measurements based on the projection and/or shadow measurements of the object.<br>
24.	The system as claimed in claim 23, wherein the instructions provided by the processor are further operably linked to the computer so as to define a model generation utility that is operable to utilize data provided by the measurement utility to create three-dimensional models or maps.<br>
25.	The system as claimed in claim 21, wherein the system further comprises a server computer, wherein the instructions provided by the processor are loaded on a server<br>
computer, the server computer being accessible by the computer via a network the server computer providing access to the functions of the measurement utility via the network at the computer,</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUFic3RyYWN0LSgxMy0wOS0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Abstract-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUNsYWltcy0oMTMtMDktMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Claims-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LUNsYWltcy0oMTgtMTAtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-Claims-(18-10-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMDQtMDctMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-Correspondence Others-(04-07-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMTMtMDktMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Correspondence Others-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMTgtMTAtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-Correspondence Others-(18-10-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMjctMDctMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Correspondence Others-(27-07-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMjktMTItMjAxMCkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Correspondence-Others-(29-12-2010).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMzEtMDctMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Correspondence-Others-(31-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWNvcnJlc3BvbmRlbmNlLW90aGVycy0xLnBkZg==" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-correspondence-others-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LURyYXdpbmdzLSgxMy0wOS0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Drawings-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUZvcm0tMS0oMTMtMDktMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Form-1-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUZvcm0tMS0oMjktMTItMjAxMCkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Form-1-(29-12-2010).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUZvcm0tMTMtKDEzLTA5LTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Form-13-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWZvcm0tMTMtKDMxLTA3LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-form-13-(31-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUZvcm0tMi0oMTMtMDktMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Form-2-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUZvcm0tMy0oMjctMDctMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Form-3-(27-07-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LUdQQS0oMTMtMDktMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-GPA-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LUdQQS0oMTgtMTAtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-GPA-(18-10-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LU90aGVycy1Eb2N1bWVudC0oMzEtMDctMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Others-Document-(31-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1kZWxucC0yMDA2LXBjdC0yMTAucGRm" target="_blank" style="word-wrap:break-word;">3763-delnp-2006-pct-210.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUC0yMDA2LVBldGl0aW9uLTEzNy0oMTMtMDktMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">3763-DELNP-2006-Petition-137-(13-09-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUDIwMDYtQ29ycmVzcG9uZGVuY2UtT3RoZXJzLSgwNy0wNi0yMDEwKS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-DELNP2006-Correspondence-Others-(07-06-2010).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mzc2My1ERUxOUDIwMDYtR1BBLSgwNy0wNi0yMDEwKS5wZGY=" target="_blank" style="word-wrap:break-word;">3763-DELNP2006-GPA-(07-06-2010).pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="257687-a-method-and-an-antenna-for-receiving-millimetre-wave-radiation.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="257689-locating-repeating-media-objects-in-a-media-stream.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>257688</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3763/DELNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>44/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>01-Nov-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>25-Oct-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>30-Jun-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>MICROSOFT AMALGAMATED COMPANY II</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>4850 KEELE STREET, 2ND FLOOR, TORONTO, ONTARIO, M3J 3K1, CANADA.</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>VINCENT C. TAO</td>
											<td>117 LEYBRUN AVENUE RICHMOND HILL , ONTARIO L4C 0J6, CANADA,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>YONG HU</td>
											<td>51 SHOREHAM DRIVE TORONTO, ONTARIO M3N 1S7, CANADA.</td>
										</tr>
										<tr>
											<td>3</td>
											<td>PETER LENSON</td>
											<td>12 HEARTHSTONE CRESCENT COURTICE, ONTARIO L1E 2X7, CANADA.</td>
										</tr>
										<tr>
											<td>4</td>
											<td>ARIE CROITORU</td>
											<td>834 STATE STREET, BANGOR, ME 04401, USA.</td>
										</tr>
										<tr>
											<td>5</td>
											<td>WANSHOU JIANG</td>
											<td>129 LUOYU ROAD, WUHAN, HUBEI 430079, CHINA,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G01C 11/04</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/CA2005/000043</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-01-14</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>2,455,359</td>
									<td>2004-01-16</td>
								    <td>Canada</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/257688-system-and-method-for-3d-image-modelling-from-single-imagery by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:44:17 GMT -->
</html>
