<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/227212-method-and-apparatus-for-processing-multimedia-content by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 06:31:08 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 227212:METHOD AND APPARATUS FOR PROCESSING MULTIMEDIA CONTENT</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR PROCESSING MULTIMEDIA CONTENT</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The present invention relates to a method of processing multimedia content, such as audio or video content, wherein the method comprises the steps of: receiving a data signal comprising said multimedia content; identifying predefined features in the received multimedia content; determining characteristics of the received multimedia content on the basis of a predefined link between one or more of said identified predefined features and one or more characteristics, wherein the links between said features and said characteristics have been made on the basis of real-world knowledge. A parameter can be generated on the basis of the characteristics and may be used for a number of purposes, such as e.g. keyword searches in content, or content rendering based on characteristics and language detection.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
Method and Apparatus for Processing Multimedia Content<br>
The present mvention relates to a method of processing multimedia content, such as audio or video content. The invention also relates to an apparatus for processing multimedia content, such as audio or video content. Furthermore, the mvention relates to a data signal describing multimedia content wherein the data signal further comprises metaÂ¬data. The invention further relates to a storage mediimi comprising a data signal describing multimedia content wherein the data signal further comprises meta-data.<br>
As the number of chaimels available to television viewers has increased, along with the diversity of the programming content available on such channels, it has become increasingly challenging for television viewers to identify television programs of interest.<br>
Historically, television viewers identified television programs of interest by analyzing printed television program guides. Typically, such printed television program guides contained grids listing the available television programs by time and date, channel and title. As the number of television programs has increased, it has become increasingly difficult to effectively identify desirable television programs using such printed guides.<br>
More recently, television program guides have become available in an electronic format, often referred to as electronic program guides (EPGs). Like printed television program guides, EPGs contain grids listing the available television programs by time and date, channel and title. Some EPGs, however, allow television viewers to sort or search the available television programs in accordance with personalized preferences. In addition, EPGs allow on-screen presentation of the available television programs.<br>
While EPGs allow viewers to identify desirable programs more efficiently than conventional printed guides, they suffer from a number of limitations, which, if overcome, may further enhance the ability of viewers to identify desirable programs.<br>
In general, there are recommender and content management systems which, based on meta-data in the muhimedia signal being e.g. a video and/or an audio signal, define properties of the content and thereby give the viewer or listeners further possibilities of identifying specific content. Recommender and content management systems provide added<br><br>
value only if proper meta-data is available. The types of meta-data are numerous, but one type that is currently lacking is that of an affective or emotive description of the content or parts of the content (for instance, scenes or parts of music). Although the MPEG 7 standard foresees the importance of such meta-data, by providing a meta-data tag that is supposed to contain such affective information, it has not been suggested how to determine the information to the tag. One of the reasons for the absence of this kind of information is that a standardized categorization does not exist and labeling by hand is a time-consuming activity. Furthermore, traditional feature extraction (or signal analysis) does not provide such information, because it is not clearly present in the content itself.<br>
It is an object of the present invention to provide a solution to the above-mentioned problems and find a method of determining an affective and emotive description of multimedia content.<br>
This is obtained by a method of processing multimedia content, such as audio or video content, wherein the method comprises the steps of:<br>
receiving a data signal comprising said multimedia content;<br>
identifying predefined features in the received multimedia content;<br>
determining characteristics of the received multimedia content on the basis of a predefined link between one or more of said identified predefined features and one or more characteristics, wherein the links between said features and said characteristics have been made on the basis of real-world knowledge.<br>
A parameter can be generated, which is based on the characteristics and may be used for a number of purposes, such as e.g. keyword searches in content, content rendering based on characteristics and language detection. In one embodiment, characteristics may be determined in real-time during presentation of the content; alternatively, the characteristics may be pre-added to the content. The characteristics based on real-world knowledge may be ambience of the content, such as sadness, happiness, anger, etc. Real-world knowledge includes common-sense reasoning, as well as general knowledge. Therefore, based on detected content in the multimedia content, the real-world knowledge including common sense or generd knowledge can be used to link the content to the characteristics. The characteristics and the content relations may be stored as a rule-base or as an association map. It has previously been described how real-world knowledge can be used for detecting characteristics of text. This can be found in the article by H. Liu, H. Lieberman,<br><br>
T. Selker (2003), A Model of Textual Affect Sensing using Real-World Knowledge, lUI 2003, January 2003, Miami, Florida, USA.<br>
In a specific embodiment, the predefined features in the multimedia content are predefined colors in a video signal. The predefined colors may either be a predefined range of colors or they may be specific predefined colors. The colors used in a scene are often used to communicate with the viewer; this may be e.g. ambience or culture.<br>
In another specific embodiment, the predefined features in the multimedia content are predefined soimd elements in an audio signal. The sound or music used e.g. during a scene is often used to communicate with the viewer and may express e.g. sadness, horror, action, love; besides these ambience characteristics, it may also be culture.<br>
In a specific embodiment, the method further comprises the steps of presenting the content of the multimedia signal in accordance with the determined characteristics. The presentation of the multimedia content may be fiirther optimized during presentation; e.g. by dimming the light in a happy scene or enhancing a color in a specific cultural environment.<br>
In an embodiment, the determined characteristics are added to the multimedia signal as meta-data. The signal may e.g. be stored or broadcast, comprising the meta-data, and the receiver or reader does not have to determine the data in order to use them.<br>
In a specific embodiment, the determined characteristics are the ambience of the received multimedia content. Ambience may e.g. be the atmosphere of an environment and the ambience of multimedia content is relatively simple to determine on the basis of predefined features in multimedia content. The specific colors or sounds are often used to amplify the ambience of the multimedia content for the viewer or listener; as mentioned above, such ambience may e.g. be sadness, horror, action, love.<br>
The invention further relates to an apparatus for processing multimedia content, such as audio or video content, wherein the apparatus comprises:<br>
a receiver adapted to receive a data signal describing said multimedia content;<br>
a processor adapted to identify predefined features in the received multimedia content;<br>
a data base comprising links between one or more of said identified predefined features and one or more characteristics, wherein the links between said features and said characteristics have been made on the basis of real-world knowledge;<br>
a processor adapted to determine the characteristics of the received multimedia content on the basis of the content in said database.<br><br>
In a specific embodiment, the apparatiis is adapted to read the content of a storage medium comprising multimedia content, wherein the receiver is adapted to receive a data signal describing said multimedia content, where said data signal has been read from said storage medium.<br>
The invention also relates to a data signal describing multimedia content, wherein the data signal further comprises meta-data, said meta-data defining characteristics of said multimedia content, and wherein the characteristics have been determined by identifying predefined features in said multimedia content and by determining the characteristics of the received multimedia content on the basis of a predefined link between one or more of said identified predefined features and one or more characteristics, wherein the links between said features and said characteristics have been made on the basis of real-world knowledge.<br>
The invention also relates to an apparatus for processing a data signal as defined hereinbefore, wherein the apparatus comprises:<br>
means for receiving a user request comprising an identification of characteristics of multimedia content,<br>
means for processing said data signal by searching for meta-data defining characteristics similar to the characteristics identified in said user request,<br>
means for presenting the multimedia content in the data signal for the user if the meta-data in said data signal defines characteristics similar to the characteristics identified by said user request.<br>
The apparatus may also be referred to as a content recommender, and by using the meta-data for recommending content it is possible to recommend in accordance with the real-world knowledge-based characteristics defined by the meta-data. This increases the quality of a recommender system by making it possible to recommend in accordance with e.g. the ambience of the multimedia content.<br>
The invention also relates to a storage medium comprising data describing multimedia content, wherein the data further comprises meta-data, said meta-data defining characteristics of said multimedia content, and wherein the characteristics have been determined by identifying predefined features in said multimedia content and by determining the characteristics of the received multimedia content on the basis of a predefined link between one or more of said identified predefined features and one or more characteristics, wherein the links between said features and said characteristics have been made on the basis of real-world knowledge.<br><br>
Preferred embodiments of the invention will be described hereinafter with reference to the Figures, wherein<br>
Fig. 1 illustrates a system according to the present invention;<br>
Fig. 2 illustrates a database comprising links between predefined features and characteristics;<br>
Fig. 3 illustrates a method of determining characteristics in multimedia content according to the present invention;<br>
Fig. 4 illustrates different types of processing and usage of a multimedia signal comprising meta-tags according to the present invention.<br>
In Fig. 1, a system 101 according to the present invention is illustrated, which system comprises a central processor unit (CPU) 103, a receiver 105, and a database 107 which communicates via a communication bus 108. The receiver 105 can receive a multimedia signal (MS) 109 comprising multimedia content data such as audio and/or video data. Such multimedia data may e.g. be received from a device adapted to read multimedia content from a storage medium comprising the muhimedia data, such as a DVD or VCR. Furthermore, the signal may also be received from a receiver adapted to receive broadcast multimedia content, e.g. in a digital TV signal. The database 107 comprises links between predefined features in multimedia content and corresponding characteristics, wherein the links between the features and the characteristics are based on real-world knowledge 111. The CPU 103 running a detection algorithm then uses the contents of the database 107 to determine characteristics of the multimedia content. The detection algorithm may comprise the steps of detecting color elements and/or audio elements in the multimedia content, e.g. by using an audio or video detector. A number of methods of detecting color or audio elements in multimedia content are available, and in order to obtain a higher level of information from the multimedia content, these methods may be combined. One method of detecting color elements is by extracting average color from the pbcel information, which can be done in the RGB color space by using the RGB value of each pixel and then calculating the average RGB value of the whole screen or of regions or objects in the screen. Audio elements may be detected, for example, by detecting zero-crossings in the audio waveform, which may be used for determining the dynamics or tempo of the audio. After having detected features in the<br><br>
multimedia content, the algorithm searches for the detected features in the database 107 and, based on the link from the feature to the characteristics, the algorithm generates a new signal 113 comprising both the multimedia signal (MS) and a meta-tag (MTAG) identifying the characteristics that can be generated.<br>
In Fig. 2, the contents of the database 111 are illustrated, where different predefined features (Fl, F2, F3 ,F4) or combinations of features are linked to different characteristics (CI, C2, C3 C4). The predefined features in the multimedia content may be specific colors, specific types of colors, or specific combinations of colors. Furthermore, the features may be specific sounds or a combination of sound and colors. More generally, the features may be any kind of information about the multimedia content relating to one or more video scenes, video fi-ames and/or a sound or a combination of sounds. These predefined characteristics are then defined and linked to characteristics in the database. According to the general idea of the invention, this linking is based on real-world knowledge.<br>
Multimedia content features and characteristics may be linked accordiag to real-world knowledge in that characteristics such as happiness and holidays are Imked to the predefined features: warm colors, blue skies and Latin music in the multimedia content. Another example of linking features of the content with characteristics on the basis of real-world knowledge may be the following scenario. In some countries (culture-dependent) people in mourning may dress in black clothes, which is associated with sadness. Therefore a characteristic such as sadness may be determined when the multimedia content comprises a scene featuring people wearing black clothes; this decision might have to be made in connection with another decision based on a real-world knowledge link between a feature and a specific culture or type of culture, e.g. in a certain country or area. In audio, similar operations can be performed on the basis of e.g. the speed of the different tones in a tune, where a slow tune is one feature which might imply a scene in which people are being intimate or at least a non-action scene, whereas a veiy fast tune may mean that it is a scene involving a lot of action or at least not a calm scene.<br>
Fig. 3 illustrates how the characteristics are detected in multimedia content. First, in 301, the multimedia signal comprising the multimedia content is received by the system; this may e.g. be received from an internal multimedia content reader/receiver or from an externally connected multimedia content reader/receiver. In 303, predefined features are searched for and identified in the multimedia content on the basis of the content of the database 107, e.g. by searching for specific colors and/or specific sound in the content identified in the database 107.<br><br>
Next, in 305, the characteristic of the content is determined on the basis of the identified features and their corresponding link in the database 107. Finally, in 307, the characteristics of the multimedia content have been determined and the content can be processed, using the additional determined information.<br>
Fig. 4 shows examples of different methods of processing or using multimedia content comprising the additional determined information. In the Figure, the multimedia signal 401 comprising the meta-tag is illustrated as input to a processing device 403. In the example 405, a user may search for specific multimedia content on the basis of the characteristics of the content, e.g. he may search for sad content or action content, or a combination of these characteristics. In 407, the characteristics are used to determine culture and country and thereby determine the language, which information may be used e.g. when converting speech to text or when subtitling video content. In 409, the information is used when presenting the content, where the meta-data may be used when rendermg the content, e.g. by fading the light in a scene or by enhancing specific tones in audio, depending on the characteristics.<br>
The processing may be performed in a content recommender system, which can recommend specific multimedia content on the basis of the characteristics of the multimedia content.- In an example, the multimedia content may be video content, e.g. fi-om a source such as a DVD on which the data comprising the multimedia content and the metaÂ¬data are stored. Alternatively, only the multimedia content may be stored on the DVD and the meta-data generation as described above is performed before the content recommender system processes the content. The content recommender system comprises a device for reading the data on the DVD, and the meta-data can then be used to present specific parts of the multimedia content on the basis of the characteristics identified in the meta-data. More specifically, a user using an input device such as a keyboard or remote control may specify that he only wants to see the happy parts in the content. Then the recommender system searches for the happy characteristics in the meta-data and presents the content with metaÂ¬data identifying the happy characteristic. Alternatively, the recommender may also initially scan the data on the DVD and rate the content on the basis of the detected meta-data, e.g. if a predefined percentage of the content relates to characteristics such as sadness, violence or erotic scenes, the multimedia content should be rated as being unsuitable for children.<br>
It should be noted that the above-mentioned embodiments illustrate rather than limit the invention, and that those skilled in the art will be able to design many alternative embodiments without departing fi'om the scope of the appended claims. In the claims, any<br><br>
reference signs placed between parentheses shall not be construed as limiting the claim. Use of the verb 'comprise' and its conjugations does not exclude the presence of elements or steps other than those stated in a claim. The invention can be implemented by means of hardware comprising several distinct elements, and by means of a suitably programmed computer. In a device claim enumerating several means, several of these means can be embodied by one and the same item of hardware. The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage.<br><br><br>
WE CLAIM:<br>
1.	A method of processing multimedia content, wherein the method comprises<br>
the steps of:<br>
receiving (301) a data signal (109) comprising said multimedia content;<br>
identifying (303) predefined features (Fl, F1+F4, F3, F1+F6) in the received multimedia content;<br>
determining (305) characteristics of the received multimedia content on the basis of a predefined link between one or more of said identified predefined features (Fl, F1+F4, F3, F1+F6) and one or more characteristics (CI, C2, C3, C4), wherein the links between said features and said characteristics have been made on the basis of real-world knowledge (111); characterized in further comprising the step of:<br>
presenting (307) the multimedia content in accordance with the determined characteristics so that colors and/or sounds of the multimedia content are optimized during presentation.<br>
2.	The method as claimed in claim 1, wherein the predefined features (Fl, F1+F4, F3, F1+F6) in the multimedia content are predefined colors in a video signal.<br>
3.	The method as claimed in claim 1, wherein the predefined features (Fl, F1+F4, F3, F1+F6) in the multimedia content are predefined sound elements in an audio signal.<br>
4.	The method as claimed in claims 1 to 3, wherein the determined characteristics are added to the multimedia signal as meta-data.<br>
5.	The method as claimed in claims 1 to 4, wherein the determined characteristics are the ambience of the received multimedia content.<br>
6.	An apparatus for processing multimedia content, such as audio or video content, wherein the apparatus comprises:<br>
a receiver (105) adapted to receive a data signal (109) describing said multimedia content;<br>
a processor (103) adapted to identify predefined features (F1, F1+F4, F3,<br><br>
i<br>
F1+F6) in the received multimedia content; characterized in further comprising:<br>
a database (11) comprising links between one or more of said identified<br>
predefined features (Fl, F1+F4, F3, F1+F6) and one or more characteristics (CI, C2, C3,<br>
C4), wherein the links between said features and said characteristics have been made on the<br>
basis of real-world knowledge (111);<br>
a processor (103) adapted to determine the characteristics of the received<br>
multimedia content on the basis of the content in said database.<br>
7.	The apparatus as claimed in claim 6, wherein the apparatus is adapted to read<br>
the content of a storage medium comprising multimedia content and wherein the receiver is<br>
adapted to receive a data signal describing said multimedia content, where said data signal<br>
has been read from said storage medium.<br>
8.	An apparatus for processing a data signal (401) as claimed in claim 9, wherein<br>
the apparatus comprises:<br>
means for receiving a user request (407) comprising an identification of characteristics of multimedia content,<br>
means for processing (403) said data signal by searching for meta-data defining characteristics similar to the characteristics identified in said user request,<br>
means for presenting (409) the multimedia content in the data signal for the user if the meta-data in said data signal defines characteristics similar to the characteristics identified by said user request characterized in that the means for presenting (409) is arranged for presenting the multimedia content in accordance with the determined characteristics so that colors and/or sounds of the multimedia content are optimized during presentation.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGFic3RyYWN0IGR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 abstract duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGNsYWltcyBkdXBsaWNhdGUucGRm" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 claims duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGNvcnJlc3BvbmRlbmNlIG90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGNvcnJlc3BvbmRlbmNlIHBvLnBkZg==" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 correspondence po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGRlc2NyaXB0aW9uIChjb21wbGV0ZSkgZHVwbGljYXRlLnBkZg==" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 description (complete) duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGRyYXdpbmdzIGR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 drawings duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1DSEVOUC0yMDA2IEZPUk0gMTMucGRm" target="_blank" style="word-wrap:break-word;">1302-CHENP-2006 FORM 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IGZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTMwMi1jaGVucC0yMDA2IHBldGl0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">1302-chenp-2006 petition.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="227211-d-amino-acid-peptides.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="227213-apparatus-for-emitting-a-chemical-agent.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>227212</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1302/CHENP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>07/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>13-Feb-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>05-Jan-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>17-Apr-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>KONINKLIJKE PHILIPS ELECTRONICS N.V</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>Groenewoudseweg 1, NL-5621 BA Eindhoven,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DIEDERIKS, Elmo, M. A</td>
											<td>c/o Prof. Holstlaan 6, NL-5656 AA Eindhoven,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/16</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB2004/051597</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-08-30</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>03103395.4</td>
									<td>2003-09-16</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/227212-method-and-apparatus-for-processing-multimedia-content by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 06:31:09 GMT -->
</html>
