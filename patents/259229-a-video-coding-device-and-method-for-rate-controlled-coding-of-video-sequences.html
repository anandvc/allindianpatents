<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/259229-a-video-coding-device-and-method-for-rate-controlled-coding-of-video-sequences by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 02:47:49 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 259229:A VIDEO CODING DEVICE AND METHOD FOR RATE CONTROLLED CODING OF VIDEO SEQUENCES</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A VIDEO CODING DEVICE AND METHOD FOR RATE CONTROLLED CODING OF VIDEO SEQUENCES</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>This disclosure describes rate control techniques that can improve video coding based on a &#x27;two-pass&#x27; approach. The first pass codes a video sequence using a first set of quantization parameters (QPs) for the purpose of estimating rate-distortion characteristics of the video sequence based on the statistics of the first pass. A second set of QPs can then be defined for a second coding pass. The estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that minimizes distortion of the frames of the video sequence.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM 2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970)<br>
&amp;<br>
THE PATENTS RULES, 2003<br>
COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
"TWO PASS RATE CONTROL<br>
TECHNIQUES FOR VIDEO CODING USING<br>
RATE-DISTORTION CHARACTERISTICS"<br>
QUALCOMM INCORPORATED, a company incorporated in the state of Delaware, U.S., of 5775 Morehouse Drive, San Diego, California 92121-1714, U.S.A<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br>
WO 2007/038230<br><br><br><br>
PCT/US2006/036905<br><br>
TWO PASS RATE CONTROL TECHNIQUES FOR VIDEO CODING USING RATE-DISTORTION CHARACTERISTICS<br>
TECHNICAL FIELD<br>
[0001] This disclosure relates to digital video processing and, more particularly, rate controlled coding of video sequences.<br>
BACKGROUND<br>
[0002] Digital video capabilities can be incorporated into a wide range of devices, including digital televisions, digital direct broadcast systems, wireless communication devices, personal digital assistants (PDAs), laptop computers, desktop computers, digital cameras, digital recording devices, cellular or satellite radio telephones, and the like. Digital video devices can provide significant improvements over conventional analog video systems in creating, modifying, transmitting, storing, recording and playing full motion video sequences.<br>
[0003] A number of different video coding standards have been established for coding digital video sequences. The Moving Picture Experts Group (MPEG), for example, has developed a number of standards including MPEG-1, MPEG-2 and MPEG-4. Other standards include the International Telecommunication Union (ITU) H.263 standard, QuickTime™ technology developed by Apple Computer of Cupertino California, Video for Windows™ developed by Microsoft Corporation of Redmond, Washington, Indeo™ developed by Intel Corporation, RealVideo™ from RealNetworks, Inc. of Seattle, Washington, and Cinepak™ developed by SuperMac, Inc. Furthermore, new standards continue to emerge and evolve, including the ITU H.264 standard and a number of proprietary standards.<br>
[0004] Many video coding standards allow for improved transmission rates of video sequences by coding data in a compressed fashion. Compression can reduce the overall amount of data that needs to be transmitted for effective transmission of video frames. Most video coding standards, for example, utilize graphics and video compression techniques designed to facilitate video and image transmission over a narrower bandwidth than can be achieved without the compression. The MPEG standards and the ITU H.263 and ITU H.264 standards, for example, support video coding techniques that utilize similarities between successive video frames, referred to as temporal or inter-<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
frame correlation, to provide inter-frame compression. Such inter-frame compression is typically achieved via motion estimation and motion compensation coding techniques. In addition, some video coding techniques may utilize similarities within frames, referred to as spatial or intra-frame correlation, to compress the video frames. [0005] A number of rate control techniques have been developed for video coding. Rate control techniques are particularly important in order to facilitate real-time transmission of video sequences, but may also be used in non-real-time coding settings. For rate control, the coding techniques may dynamically adjust the number of bits that are coded per frame. In particular, rate control can restrict the number of bits that are coded per frame in order to ensure that the video sequence can be effectively coded at a given rate and therefore, transmitted over an allocated bandwidth. If the coding techniques are not responsive to scene changes of a video sequence, the bit rate for realtime transmission of the video sequence can vary significantly as the scenes change. Also, for some applications (such as wireless video telephony) bandwidth availability may change while a video sequence is being coded. For these or other reasons, rate control techniques can be used to dynamically adjust the number of bits used per frame during the coding.<br>
SUMMARY<br>
[0006] This disclosure describes rate control techniques that can improve video coding. In particular, this disclosure describes a number of rate control techniques that are based on "two-pass" coding, although additional passes could also be used. The first pass codes a video sequence using a first set of quantization parameters (QPs) for the purpose of estimating rate-distortion characteristics of the video sequence based on the statistics of the first pass. A second set of QPs can then be defined for a second coding pass. Since the first coding pass provides an estimation of the rate-distortion characteristics of the video sequence, the selection of QPs for the second pass can be improved by accounting for inter-frame dependencies.<br>
[0007] A variety of embodiments and variations are described herein. However, two basic alternatives, consistent with this disclosure, are generally proposed. In the first case, the estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that minimizes distortion of the frames of the video sequence. In the second case, the estimated rate-distortion characteristics of the first<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
pass are used to select QPs for the second pass in a manner that minimizes quality fluctuation between the frames of the video sequence, and may also maximize quality at the minimized quality fluctuation in order to achieve low average frame distortion. [0008] In one embodiment, this disclosure provides a video coding device comprising means for coding frames of a video sequence using a set of first quantization parameters (QPs) in a first coding pass, means for obtaining rate-distortion statistics for the coded video sequence of the first coding pass, means for estimating rate-distortion characteristics of the video sequence based on the rate-distortion statistics, and means for selecting a second set of QPs for a second coding pass of the frames in the video sequence based on the estimated rate-distortion characteristics. <br>
[0009] In another embodiment, this disclosure provides a video coding device comprising means for coding frames of the video sequence using a set of first quantization parameters (QPs) a first coding pass, means for obtaining rate-distortion statistics for the coded video sequence, means for estimating rate-distortion characteristics of the video sequence based on the rate-distortion statistics, and means for substantially minimizing quality fluctuation between the frames of the video sequence in a second coding pass using the estimated rate-distortion characteristics to select a second set of QPs for the second coding pass of the frames in the video sequence.<br>
[0010] The rate controlled coding techniques described herein may be implemented in a video coding device in hardware, software, firmware, or any combination thereof. If implemented in software, the software may be executed in a processor, such as a programmable processor used for video coding. The software that executes the techniques may be initially stored in a computer readable medium and may loaded and executed in the processor in order to perform such rate controlled video coding. [0011] Additional details of various embodiments are set forth in the accompanying drawings and the description below. Other features, objects and advantages will become apparent from the description and drawings, and from the claims.<br>
BRIEF DESCRIPTION OF DRAWINGS<br>
[0012] FIG. 1 is a block diagram illustrating an exemplary video coding device according to this disclosure.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
[0013] FIG. 2 is a flow diagram illustrating a two-pass rate controlled video coding<br>
technique according to an embodiment of this disclosure in which rate-distortion<br>
characteristics are estimated and used to define quantization parameters for a video<br>
sequence.<br>
[0014] FIGS. 3-15 are various graphs of data illustrating aspects of the techniques of<br>
this disclosure.<br>
[0015] FIG. 16 is a flow diagram illustrating a two-pass rate controlled video coding<br>
technique according to an embodiment of this disclosure in which quality fluctuation is<br>
minimized for the frames of a video sequence.<br>
[0016] FIGS. 17-26 are additional graphs of data illustrating aspects of the techniques<br>
of this disclosure.<br>
DETAILED DESCRIPTION<br>
[0017] This disclosure describes rate control techniques for video coding. The described techniques are based on a "two-pass" approach in which a first coding pass is used to estimate characteristics of the video sequence, and the estimated characteristics are then used to improve upon the selection of quantization parameters (QPs) for the second pass. This disclosure can take advantage of certain characteristics of frame dependency of rate-distortion characteristics of a video sequence. In particular, this disclosure observes that in many cases (specifically in the cases studied herein) rate and distortion of a current frame are highly dependent upon the QP used in the immediately preceding frame, but that the QPs used for frames before the immediately preceding frame have very little impact on the rate and distortion of a current frame. Using these observations, a significant reduction in computation intensity can be achieved in a coding device by essentially simplifying rate and distortion models to approximations. [0018] The first coding pass codes a video sequence using a first set of QPs for the purpose of estimating rate-distortion characteristics of the video sequence based on the statistics of the first pass. The first set of QPs may be selected in any fashion, such as by assigning the same QP to every frame, or by using a so called "greedy" algorithm that uses a rate budget to determine a QP and then re-allocates the rate budget over the remaining frames to define each subsequent QP. Regardless of how the first set of QPs are selected or determined for the first coding pass, the rate-distortion statistics for the video sequence can be obtained by the first coding pass.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
[0019] After the first coding pass, rate-distortion characteristics of the video sequence can be estimated based on the rate-distortion statistics. The manner in which the rate-distortion characteristics are estimated may vary in different embodiments, but generally comprise the application of rate and distortion models to the rate-distortion statistics obtained in the first coding pass. After the rate-distortion characteristics are estimated, these characteristics are used to select a second set of QPs for a second coding pass of the frames in the video sequence. The second coding pass, then, can be used to ultimately code the video sequence, and the QPs selected for the second coding pass can achieve video quality improvements in such coding. [0020] A variety of embodiments and variations are described herein. However, two basic alternatives, consistent with this disclosure, are generally proposed. In the first case, the estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that minimizes distortion of the frames of the video sequence. In the second case, the estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that rninimizes quality fluctuation between the frames of the video sequence. While distortion minimization can result in the better overall coding on average, minimization of quality fluctuation can reduce or eliminate undesirable flickering problems due to abrupt quality changes. Combinations of these two cases are also contemplated by this disclosure. [0021] FIG. 1 is a block diagram illustrating an exemplary video coding device 10. Video coding device 10 may form part of a digital video device capable of coding and transmitting video data. The video data may be captured from a video camera, retrieved from a video archive, or obtained in another manner. Coding device 10 may be implemented in devices such as digital televisions, digital direct broadcast systems, wireless communication devices, personal digital assistants (PDAs), laptop computers, desktop computers, digital cameras, digital recording devices, cellular or satellite radio telephones, or any telecommunication device with video telephony (VT) capabilities. Coding device 10 may comply with a video coding standard such as MPEG-4, ITU-T H.263, ITU-T H.264, or another video coding standard that requires QP selection for quantized video coding. Coding device 10 may support inter-frame coding techniques such as motion estimation and motion compensation, and may also support other techniques, such as spatial estimation and intra-prediction coding techniques used for intra-frame coding.<br><br>
WO 2007/038230<br><br><br><br>
PCT/US2006/036905<br><br>
[0022] As shown in FIG 1, coding device 10 includes a video coding apparatus 12 to code video sequences, and a video memory 20 to store the video sequences before and after such coding. Device 10 may also include a transmitter 22 to transmit the coded sequences to another device, and possibly a video capture device 18, such as a video camera, to capture video sequences and store the captured sequences in memory 20. The various elements of coding device 10 may be communicatively coupled via a communication bus 15. Various other elements, such as various filters, or other elements may also be included in coding device 10, but are not specifically illustrated for simplicity. The architecture illustrated in FIG 1 is merely exemplary, as the techniques described herein may be implemented with a variety of other architectures. <br>
[0023] Video memory 20 typically comprises a relatively large memory space. Video memory 20, for example, may comprise dynamic random access memory (DRAM), or FLASH memory. In other examples, video memory 20 may comprise a non-volatile memory or any other data storage device.<br>
[0024] Video coding apparatus 12 may comprise a so called "chip set" for a mobile radiotelephone, including a combination of hardware, software, firmware, and/or one or more microprocessors, digital signal processors (DSPs), application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), or various combinations thereof. Video coding apparatus 12 generally includes a video coder 14 coupled to a local memory 18. Video coder 14 may comprise an encoder/decoder (CODEC) for encoding and decoding digital video data. Local memory 18 may comprise a smaller and faster memory space relative to video memory 20. By way of example, local memory 18 may comprise synchronous dynamic random access memory (SDRAM). Local memory 18 may comprise "on-chip" memory integrated with the other components of video coding apparatus 12 to provide for very fast access to data during the processor-intensive coding process. However, memories 20 and 18 may be combined into the same memory part, or may be implemented in a number of other configurations.<br>
[0025] As described herein, video coder 14 implements a "two-pass" coding approach in which a first coding pass is used to estimate characteristics of the video sequence and the second coding pass uses the estimated characteristics to improve upon selection of QPs used in the second pass in order to improve quality of the coding. Rate control unit 30 handles the QP selection process, which uses the estimated characteristics in the first<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
coding pass. The techniques implemented by rate control unit 30 can take advantage of frame dependency by estimating rate-distortion characteristics of a video sequence in order to achieve a significant reduction in computation intensity by essentially simplifying rate and distortion models to approximations.<br>
 [0026] Rate control unit 30 applies a first set of QPs in the first coding pass for the purpose of estimating rate-distortion characteristics of the video sequence based on the statistics of the first pass. After the first coding pass, rate control unit 30 estimates rate-distortion characteristics of the video sequence based on the rate-distortion statistics. Then, rate control unit 30 uses these estimated rate-distortion characteristics to select a second set of QPs for a second coding pass of the frames in the video sequence. The second coding pass, then, can be used to ultimately code the video sequence, and the QPs selected for the second coding pass can achieve video quality improvements in such coding. In accordance with this disclosure, the estimated characteristics can quantify frame dependencies in a manner that allows for improved QP selection in the second pass.<br>
[0027] For each coding pass, during the coding of a given video frame, the current video block to be coded may be loaded from video memory 20 to local memory 18. A search space used in locating prediction video blocks may also be loaded from video memory 20 to local memory 18. The search space may comprise a subset of pixels of one or more of the preceding video frames (or subsequent frames). The chosen subset may be pre-identified as a likely location for identification of a prediction video block that closely matches the current video block to be coded.<br>
[0028] Local memory 18 is loaded with a current video block to be coded and a search space. Motion estimator/spatial estimator 24 compares the current video block to various video blocks in the search space in order to identify a prediction video block. Motion estimator/spatial estimator 24 generally represents a motion estimator that performs motion estimation for inter-frame coding, a spatial estimator that performs spatial estimation for intra-frame coding, or a combined unit that can perform motion estimation and spatial estimation, hi general, the prediction video block is a candidate video block found to provide an adequate match with the current video block for purposes of inter-frame correlation (or intra-frame correlation), which may be the most closely matching candidate video block. The prediction video block is one of many<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
candidate video blocks evaluated during the motion estimation process to identify a video block having a minimum difference value relative to the current video block. [0029] In order to perform the comparisons between the current video block to be coded and the candidate video blocks in the search space of memory 18, motion estimator/spatial estimator 24 may perform sum of absolute difference (SAD) techniques, sum of squared difference (SSD) techniques, or other comparison techniques. In this manner, motion estimator/spatial estimator 24 can determine the difference values for the different candidate video blocks. A lower difference value generally indicates that a candidate video block is a better match, and thus a better candidate for use in motion estimation coding than other candidate video blocks yielding higher difference values. A prediction video block may be identified once a suitable match is found.<br>
[0030] Once a prediction video block is identified by motion estimator/spatial estimator 24 for a video block to be coded, motion compensator/intra-prediction unit 26 creates a residual. The residual is a block of data indicative of differences between the current video block to be coded and the prediction video block identified by motion estimation or spatial estimation. Motion compensator/intra-prediction unit 26 generally represents a motion compensator that performs motion compensation for inter-frame coding, an intra-prediction unit that performs spatial compensation for intra-frame coding, or a combined unit that can perform either motion compensation and intra-prediction depending upon whether inter-frame or intra-frame coding is being used. Motion compensator/intra-prediction unit 26 may fetch the prediction block using a motion vector, and then subtract the prediction block from an input block to generate the residual. The residual typically includes substantially less data than the original video block that is represented by the difference block.<br>
[0031] After motion compensator/intra-prediction unit 26 has created the residual, residual coder 28 may perform one or more residual coding steps, such as discrete cosine transformation (DCT), zig-zag scanning, run length coding, variable length (Huffman) coding, or any other process used in a given coding standard. Numerous other residual coding steps may also be performed.<br>
[0032] Rate control unit 30 may implement one of two alternatives, consistent with this disclosure. In the first case, rate control unit 30 uses the estimated rate-distortion characteristics of the first pass to select QPs for the second pass in a manner that<br><br>
WO 2007/038230<br><br><br><br>
PCT/US2006/036905<br><br>
minimizes distortion across all frames of a video sequence. In the second case, rate control unit 30 uses the estimated rate-distortion characteristics of the first pass to select QPs for the second pass in a manner that minimizes quality fluctuation of the frames of the sequence. While distortion minimization can result in better overall coding on average, minimization of quality fluctuation may be desired to reduce or eliminate flickering problems due to abrupt quality changes. Details of each of these two alternatives is set forth in greater detail below.<br>
[0033] The discussion of FIGS. 2-15 generally outlines the first approach in which the goal is to substantially minimize distortion of a coded video sequence, whereas FIGS. 16-26 generally outline the second approach in which the goal is to substantially minimize quality fluctuation of coded the video sequence. Any details discussed with respect to any of FIGS. 2-26, however, should not be construed as being limited to either approach, as one or more aspects of each approach could also be used in combination according to this disclosure. In the various experiments graphs of test sequences discussed herein, the test sequences are generally Quarter Common Image Format (QCIF) sequences commonly used in video coding to test and compare coding quality.<br>
[0034] FIG 2 is a flow diagram illustrating a technique for rate controlled video coding according to this disclosure. As shown in FIG 2, video coder 14 codes the frames of a video sequence using a first set of QPs (40). Rate control unit 30 then obtains rate-distortion statistics for the coded video sequence of the first coding pass (41). The various other units 24,26 and 28 of video coder 14 may be implemented in the first coding pass using the set of first QPs identified by rate control unit 30. The first set of QPs may be selected in a variety of different ways, or according to any rate control algorithm. In one example, the first set of QPs are dynamically selected by rate control unit 30 based on a so called "greedy" algorithm that selects a QP for a frame based on a rate budget relative to the number of frames in the sequence, but then reallocates the remaining rate budget over the remaining frames. In another example, the same QP may be pre-selected and used for all frames in the first pass, in which case, the QPs in the first set of QPs are identical to one another.<br>
[0035] After the first coding pass, rate control unit 30 estimates rate-distortion characteristics of the video sequence based on the rate-distortion statistics obtained by the first coding pass (42). m general, the process of estimating the rate-distortion<br><br>
WO 2007/038230	 	PCT/US2006/036905<br><br>
characteristics comprises applying a rate model and a distortion model to the rate-distortion statistics. Exemplary mathematical models are described in greater detail below, which can reduce computation complexity to approximations, yet provide very good estimations and good coding results. Again, the estimated characteristics can quantify frame dependencies in a manner that allows for improved QP selection in the second pass.<br>
[0036] Rate control unit 30 then selects a second set of QPs for a second coding pass based on the rate distortion characteristics (43). The second set of QPs are different than the first set of QPs and are selected in order to improve the quality of the coding. The first coding pass may be a lower quality coding pass, but provides the information needed to apply accurate modeling, and account for inter-frame dependencies in the coding of the video sequence. In one example, rate control unit 30 selects the second set of QPs by performing a Lagrangian relaxation operation on the estimated rate-distortion characteristics, as discussed in further detail below. In this case or similar cases, the selection of the second set of QPs may involve substantially minimizing distortion of the frames in the video sequence. In any case, once rate control unit 30 has selected the second set of QPs, video coder 14 codes the video sequence using the second set of QPs (44).<br>
[0037] In video coding, a fundamental problem is to efficiently allocate bits among the frames or choose a QP for each frame to achieve the best overall quality of the video sequence. The difficulty of this problem is mainly due to the coding dependencies of the frames and the consequent cost for searching a candidate space containing exponential number of nodes. In one embodiment of this disclosure, a solution is proposed that uses a set of estimation models to approximate the practical rate and distortion status in the second-pass coding. The models are based on the observation that in many cases the rate and distortion of current frame are highly dependent on the quantization level of its preceding frame, and that the QP selection of the previous frames earlier than the last one has very little impact on the performance of the current frame. The models and observations enable the significant reduction of the candidate space of the problem. Furthermore, by using Lagrangian relaxation and dynamic programming, a constrained problem can be converted into an unconstrained problem and solved by using a shortest path search algorithm. Experimental results have shown<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
significant gains of up to 1.7dB compared to the "greedy" frame-level rate control algorithm used in some conventional CODECs.<br>
[0038] Many conventional rate control schemes are designed for real-time coding applications and adopt a greedy frame-level bit allocation strategy. The greedy frame-level bit allocation strategy assumes that future frames should have uniformly distributed texture complexity. Therefore, the greedy frame-level bit allocation strategy allocates remaining bits equally among the future frames.<br>
[0039] Unfortunately, it is not a trivial task to obtain good frame bit allocation because the rate-distortion (R-D) function of a frame depends on the quantization parameter (QP) choices for the prior coded frames. In other words, generation of the global rate-distortion function for the whole video sequence is very difficult due to the frame dependencies.<br>
[0040] This disclosure proposes a frame-level rate control algorithm based on an accurate rate and distortion estimation model. It has been observed that the frame distortion highly depends on level of quantization of the preceding frame. In addition, the distortion during the second pass coding can be approximated by statistics such as a function of Ihe distortion in the first pass (using the same level of quantization), the energy of the motion-compensated residue in the first pass, and the distortion of the preceding frame in the first pass. It has also been observed that the quantization selection of the frames earlier than the immediately preceding frame has very little impact on the frame distortion of the current frame. With the above observations and the estimated p -QP and D-QP tables for each frame (which can be stored in memory 18), Lagrangian relaxation techniques can be used to find a desirable QP selection for each frame. The value p represents the number of non-zero quantized DCT coefficients in the frame, QP represents the quantization parameter, and D represents distortion.<br>
[0041] Li accordance with one embodiment, the problem can be defined as choosing the QP for each frame in an effort to achieve the best overall quality of the video sequence, based on the statistics collected during the first-pass coding. Although the problem of how to do the first-pass coding is relevant, to simplify the problem, one may assume that a "greedy" frame-level bit allocation algorithm is used to code the frame at the first pass. Of course, other first pass coding techniques could also be used in accordance with the two-pass techniques of this disclosure. In the following, the frame bit rate is<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
modeled as a function of p, which is the number of non-zero quantized DCT coefficients in the frame. Then the bit rate can be represented by:<br>
R = Ap+B	(EQUATION 1)<br>
where A and B are constant modeling parameters. A can represent the average number of bits needed to code a non-zero quantized DCT coefficients and B can represent the bits used for non-texture information, such as prediction modes and motion vectors.<br>
[0042] Let N denote the number of total frames in the processed video sequence. { Q.} denotes the QP. { A\ }denotes the average number of bits per non-zero quantized DCT coefficients. { B{ }denotes the number of bits for coding non-texture information. {p,} denotes the number of non-zero quantized DCT coefficients. {of } denotes the energy of the motion-compensated residue. {Di} denotes the distortion of the ith frame<br>
resulted in the first pass coding, and (i=l, 2, ..., N) identifies the frame of a sequence. The variables identified by a "^" are variables estimated by the first coding pass. Variables without the identifier "A" are generally similarly named second pass variables, e.g., either approximations or second pass variables to be solved. <br>
[0043] Let Rbudget denote the total bit budget for the video sequence, and {Qi}, {Ri} and {D,} the QP, bit rate, and distortion of the ith frame in the second-pass coding. Therefore the problem can be represented by<br><br><br><br>
Both Ri and A are functions of Q1, Q2, .... Qi due to the fact that predictive coding is<br>
used. In addition <br>
[0044] The frame dependencies can be significantly simplified based on an observation that the QP selection of the preceding frame has the major impact on the rate-distortion performance of the current frame. In other words, the /-tuple functions R,{Qi, Q2, —, Qi) and D(Q1, Q2, .... Qi) can be reduced to 2-tuple functions Ri,{Qi-i, Qi) and Di,{Qt.i, Qi) because the selections of Qi, Q2,—, Qi-2 will not cause significant changes on the rate and distortion for the ith frame. This observation has been verified on a sequence referred to as "die football QCIF video sequence," as shown in FIGS. 3-6. [0045] In particular, FIG. 3 plots experimental results of the rate-distortion curves for the fourth frame of a sequence using (QP1 = 10, QP2 = 10) labeled 45, (QP1 = 10, QP2 =<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
20) labeled 46, (QP1 = 20, QP2 = 10) labeled 47, and (QP1 = 20, QP2 = 20) labeled 48. FIG. 4 plots experimental results of the rate-QP curves for the fourth frame of the sequence using (QP1 = 10, QP2 = 10) labeled 51, (QP1 = 10, QP2 = 20) labeled 52, (QP1 - 20, QP2 = 10) labeled 53, and (QP1 = 20, QP2 = 20) labeled 54. FIG. 5 plots experimental results of the rho-QP curves for the fourth frame of the sequence using (QP1 = 10, QP2 = 10) labeled 56, (QP1 = 10, QP2 = 20) labeled 57, (QP1= 20, QP2 = 10) labeled 58, and (QP1 = 20, QP2 = 20) labeled 59. FIG. 6 plots experimental results of the distortion-QP curves of the fourth frame of the sequence using (QP1 = 10, QP2 = 10) labeled 61, (QP1 = 10, QP2 = 20) labeled 62, (QP1 = 20, QP2 = 10) labeled 63, and (QP1 = 20, QP2 = 20) labeled 64.<br>
[0046] For the experiments illustrated by the results of FIGS. 3-6, the QP of the first frame (I-frame) was set to 5, and the QP combinations (10,10), (10,20), (20,10), and (20, 20) were used for the second and third frames. From FIGS. 3-6, it is shown that the selection of QP1 (the QP for the second frame) has very little impact on the rate and distortion of the fourth frame, but that the selection of QP2 (the QP for the third frame) directly affects the performance of the fourth frame. Therefore, one can simplify the problem by only considering the dependencies of the consecutive frames, without sacrificing any significant quality.<br>
[0047] Hence, if one obtains the tables of .R,{gw, Qi) and D,{Qi-1, Qt) for all combinations of the candidates of Qt.i and Qb the problem of Equation 2 can be solved more easily. In the following discussion, accurate estimation models are proposed to approximate the rate and distortion functions by using the information obtained in the first pass coding. Then, the problem of Equation 2 can be solved using Lagrangian relaxation to convert the problem to an unconstrained problem. After converting the problem using Lagrangian relaxation, the unconstrained problem can be mapped into a graph theory problem and solved using a shortest path search algorithm.<br>
 [0048] For a distortion estimation model it is noted that in the first coding pass, one is<br>
able to obtain all the values of D,(QM,q) for q=l, 2, ..., 31, for the ith frame. In<br>
addition, the value of  Qi-1 can also be obtained. Based on the distortion model<br>
proposed by Z. He, Y. Kim, and S. K. Mitra, "Low-Delay Rate Control for DCT Video Coding via p -Domain Source Modeling", IEEE Trans. Circuits and Systems for Video Technology, pp. 928-940, Aug. 2001, one obtains: WO 2007/038230	 	PCT/US2006/036905<br><br><br><br><br>
where at is a model parameter.<br>
[00491 From FIG. 5, one can observe that the rho-QP curve is mainly driven by the QP of the current frame. In other words,                                     holds especially for the cases when Qt is assigned a large number (for example, greater than 15). The term rho refers to the term p as defined herein. From Equations 3 and 4, one can obtain:<br><br>
	(Equation 5)<br>
[0050] Equation 5 was experimentally verified by coding the first three frames of a sequence referred to as the "Football QCIF video sequence." The results of this experiment are illustrated in FIGS. 7 and 8. The first frame (I-frame) of the sequence was coded using QP=5, and the second frame (P-frame) was coded using QP=5,10,15, 20, and 30, respectively. Figure 7 shows the D-QP curve of the 3rd frame for each setting. In FIG. 7, the results for settings (I-frame, P-frame) are labeled as follows: (5, 5) is labeled 71, (5,10) is labeled 72, (5,15) is labeled 73, (5,20) is labeled 74, and (5, 30) is labeled 75.<br>
[0051] In FIG. 8, the actual D-QP curve of the 3rd frame generated by setting QP=10 for the second frame (P-frame) is compared with the estimated D-QP curves from the data produced by the cases that use QP = 5,15,20 and 30 for the second frame and by using Equation 5. ha FIG. 8, the results for settings (I-frame, P-frame) are labeled as follows: actual (5,10) is labeled 81, predicted (5, 5) is labeled 82, predicted (5,15) is labeled 83, predicted (5,20) is labeled 84, and predicted (5,30) is labeled 85. The results indicate that Equation 5 is very accurate.<br>
[0052] In order to estimate               in Equation 5, Mis used to denote the total pixels in the frame, yk (k=1,.., M) the kth original pixel in the frame, xk the kth original pixel in the preceding frame                           the corresponding motion-compensated pixel from the<br>
preceding frame in the first and second pass coding. Here, a special case is considered in which all the video blocks (e.g., macroblocks) use zero motion vectors, which means<br><br><br>
[0055] It can be observed from Equation 6 that the inter-frame dependency of the rate function is reasonably low, and a linear relationship exists between the variance of the motion-compensated residue and the coding error of the reference frame. However, it<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
can be observed that the rate of current frame has certain dependencies on the QP<br>
selection of its preceding frame.<br>
[0056] Denote { A,}, { Bt}, { p,} as the average number of bits per non-zero quantized<br>
DCT coefficients, number of bits for coding non-texture information, and number of non-zero quantized DCT coefficients resulted in the second pass coding. Clearly,<br><br>
[0057] In Equation 11, the value of p, depends on the energy of the motion-compensated residue (which depends on the QP of the preceding frame) and the current frame QP. The accuracy of Equation 11 can be verified by coding a "Football QCIF" sequence (as the same experiment illustrated by the results of  FIGS. 3-6) and estimating the rho-QP curve of the fourth frame (with QP=10 for the second frame and QP=20 for the third frame) from the generated first-pass data, which sets both second and third frame QP=10 and uses Equation 11. As shown in Fig. 9, the estimated rho-QP curve 91 is very close to the actual rho-QP curve 92. Similarly, the number of non-texture bits (B,) is also dependent on the energy of the residue and the QP of current frame, as it is modeled by Equation 12. Using equation 13, one can control the value of At based on the value of p{. The value of At is very stable at bigh-bitrate cases. However, when the<br>
A<br>
p{ is very small, the A, could become unreasonably high.<br>
[0058] So far, this disclosure has developed models for estimating                                       for all combinations of the candidates of Qui and Qt. Assuming the models are accurate, it is possible to develop an desired solution for the problem in Equation 2.<br><br>
•VO 2007/038230	 	PCT/US2006/036905<br><br>
In particular, one can use a Lagrangjan relaxation approach and it leads to a convex hull approximation of the constrained problem.<br>
 [0059J Define a Lagrangjan cost function as:<br><br><br><br>
where l  is the Lagrange multiplier. If there exists a X* such that<br>
                                                                                                                is the desired solution to<br>
Equation 2. Therefore, the task of solving Equation 2 equivalent to the easier task of finding the desired solution to the unconstrained problem that minimizes the cost function Jl({Q,}) and choosing the appropriate Lagrange multiplier to satisfy the<br>
constraint.<br>
[0060] In order to implement the algorithm for solving the problem, one can define a cost function Gk(Qk-i, Qk), which represents the minimum total bit rate and distortion up to and including the kth frame, given that QK-1 and Qk are decision vectors for the (k-i)th and /cth frames. In this case, k=N, GN(QN-1, QN) represents the minimum total bitrate and distortion for all the frames, and thus<br><br>
                                                                                                       (Equation 15)<br>
[0061] One key observation for deriving an efficient algorithm is the fact that given decision vectors Qk-2 and Qk-1 for the (k-2)ad and (k-1)st frames, and the cost function Gk-1{Qk-2,Qk-i), the selection of the next decision vector Qk is independent of the selection of the previous decision vectors Q1, Q2, .... Qk-3. This means that the cost function can be expressed recursively as:<br><br><br>
The recursive representation of the cost function above makes the future step of the<br>
process independent from  its past step,  which is  the  foundation  of dynamic<br>
programming.<br>
[0062] The problem can be converted into a graph theory problem of finding the<br>
shortest path in a directed acyclic graph (DAG). Such an algorithm is much more<br>
efficient than an exhaustive search algorithm with exponential computational<br>
complexity.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
[0063] Experiments were conducted on a number of video clips, and the results of such experiments are discussed in the following text. First, the experiments verified the accuracy of the proposed rate and distortion models by comparing the estimated distortion, A, B and p with their actual values in the second pass coding. As shown in FIGS. 10-13, the results in coding a sequence referred to as the "Mother and Daughter" sequence at 80 kbps demonstrate that the proposed estimate model is quite accurate. [0064] FIG. 10 graphs estimated distortion 101 and actual distortion 102 of the coded "Mother and Daughter" sequence. FIG. 11 compares estimated values of A (labeled 111) with actual values of A (labeled 112) for the coded "Mother and Daughter" sequence. FIG. 12 compares estimated values of p (labeled 121) with actual values of p (labeled 122) for the coded "Mother and Daughter" sequence. FIG. 13 compares estimated values of B (labeled 131) with actual values of B (labeled 132) for the coded "Mother and Daughter" sequence. The accuracy of the estimated values relative to the actual values is apparent from FIGS. 10-13.<br>
[0065] In a second experiment, the "Mother and Daughter" QCIF sequence was coded in ranges of bitrates from 40 kbps to 120 kbps, and the results were compared with two other approaches: (1) Frame-level greedy rate control, which assumes that the future coming frames have uniformly distributed texture complexity and therefore it allocates the remaining bits equally among the future frames; (2) Two-pass rate control using model parameters from the first pass. The results shown in FIG. 14 indicate that the approach in this disclosure has gains of 0.5-0.7dB gain over the other two approaches in all the bitrate ranges. In FIG. 14 the frame-level greedy rate control approach is labeled 141, the approach reusing first-pass model parameters is labeled 142 and the proposed approach with the accurate models defined herein is labeled 143. The improved results of the proposed approach are evident in FIG. 14.<br>
[0066] In a third experiment, a video clip containing various segments with different content complexities by composing by simulating three video scenes: the first 100 frames of a standard QCEF test sequence referred to as "Stefan" containing high activity (fast motion), the first 100 frames of a standard QCIF test sequence referred to as "Container" containing low activity (slow motion), and the first 100 frames of a standard QCIF test sequence referred to as "Carphone" containing medium activity (local face movement). The proposed approach was again compared with the two other algorithms used in the previous experiment. The results are shown in FIG. 15, and<br><br>
WO 2007/038230<br><br><br><br>
PCT/US2006/036905<br><br>
indicate that the proposed algorithm has significant gains of up to 1.7 dB over the other approaches. The improvements decreases when the bitrate increases. The improvements are expected because the proposed algorithm has the advantage of searching through the candidate space to find a more optimal bit allocation solution for the entire video clip. In FIG. 15, the frame-level greedy rate control approach is labeled 151, the approach reusing first-pass model parameters is labeled 152 and the proposed approach with the accurate models defined herein is labeled 153. The improved results of the proposed approach are evident in FIG. 15.<br>
[0067] The techniques outlined above and the results illustrated in FIGS. 3-15 show one embodiment of a model-based two-pass rate control algorithm according to this disclosure. Again, by observing that the quantization parameter selection of the preceding frame has the major impact on the rate-distortion performance of the current frame, the frame dependencies problem was successful simplified and Hie size candidate space was greatly reduced from exponential to polynomial. After that, a set of accurate models were developed for approximating the rate and distortion status during the practical coding. These models directly enabled the ability to generate a candidate space, and to map the problem into a graph theory problem. With Lagrmgian relaxation and dynamic programming, the original constrained problem was converted into an unconstrained problem and solved by the shortest path search algorithm. The experimental results indicate significant gains of up to 1.7dB compared to other existing rate control algorithms.<br>
[0068] FIG. 16 is a flow diagram illustrating a two-pass rate controlled video coding technique according to another embodiment of this disclosure in which quality fluctuation is minimized for the frames of a video sequence. Like FIG. 2, FIG. 16 will be described in the context of video coding device 10 of FIG. 1. As shown in FIG 16, video coder 14 codes the frames of a video sequence using a first set of QPs (160). Rate control unit 30 then obtains rate-distortion statistics for the coded video sequence of the first coding pass (161). The various other units 24,26 and 28 of video coder 14 may be implemented in the first coding pass using the set of first QPs identified by rate control unit 30. The first set of QPs may be selected in a variety of different ways, or according to any rate control algorithm. In one example, the first set of QPs are dynamically selected by rate control unit 30 based on a so called "greedy" algorithm that selects a QP for a frame based on a rate budget relative to the number of frames in the sequence,<br><br>
WO 2007/038230<br><br><br><br>
PCT/US2006/036905<br><br>
but then reallocates the remaining rate budget over the remaining frames. In another example, the same QP may be pre-selected and used for all frames in the first pass, in which case, the QPs in the first set of QPs are identical to one another. Other techniques, however, could be used to define the first set of QPs for the first coding pass.<br>
[0069] After the first coding pass, rate control unit 30 estimates rate-distortion characteristics of the video sequence based on the rate-distortion statistics obtained by the first coding pass (162). In general, the process of estimating the rate-distortion characteristics comprises applying a rate model and a distortion model to the rate-distortion statistics. Rate control unit 30 then selects a second set of QPs for a second coding pass by substantially minimizing quality fluctuation using the rate distortion characteristics (163). In selecting the second set of QPs, rate control unit 30 may also substantially maximize quality of the frames at the substantially minimized quality fluctuation in order to achieve low average frame distortion with the minimized quality fluctuation.<br>
[0070] The second set of QPs are different than the first set of QPs and are selected in order to improve the quality of the coding. In this case, the second set of QPs may not minimize distortion across the full sequence, but address another problem that can degrade video quality. Specifically, the technique of FIG. 16 minimizes fluctuation in the coding quality of the different frames, e.g., the technique minimizes rate-distortion fluctuation. In this manner, flickering problems can be reduced or eliminated. Flickering may otherwise occur when the coding quality drastically changes between two successive frames.   Once rate control unit 30 has selected the second set of QPs by substantially minimizing quality fluctuation (and possibly maximizing quality at the minimized quality fluctuation), video coder 14 codes the video sequence using the second set of QPs (164).<br>
[0071] Like the technique of FIG. 2, in the technique of FIG. 16, the first coding pass may be a lower quality coding pass, but provides the information needed to apply accurate modeling, and account for inter-frame dependencies in the coding of the video sequence. The minimization of rate-distortion may be performed in a wide variety of ways. In one example, substantially minimizing the quality fluctuation comprises substantially minimizing distortion fluctuation at a rate budget for the video sequence. In another example, substantially minimizing the quality fluctuation comprises<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
substantially minimizing QP fluctuation in the second set of QPs at a rate budget for the video sequence. In yet another example, substantially minimizing the quality fluctuation comprises substantially minimizing distortion fluctuation and rate fluctuation at a rate budget for the video sequence. In still another example, substantially minimizing the quality fluctuation comprises minimizing a maximum distortion value associated with the frames of the video sequence. In still another example, substantially minimizing the quality fluctuation comprises reducing a distortion value associated with the frames of the video sequence below a programmable distortion threshold. Additional details of this embodiment are set forth in the following text<br>
[0072] Like the techniques outlined above, the techniques outlined in the following text provide a constant-video-quality oriented two-pass frame-level rate control scheme. However, in the following text, the technique is based on a minimum maximum (MINMAX) distortion criterion. With this framework, given a bit budget for a video sequence, the coder dynamically adjusts the coding parameters for each frame, to minimize the peak maximum frame distortion, which indirectly assures the constant-quality of the reconstituted video sequence. The framework also enables control of the frame-level bitrate fluctuation in the coded sequence with an assigned fluctuation constraint. Based on the iterative adjustment of a threshold, the coder can find a set of coding parameters that satisfy the bit rate constraints. Dynamic programming is applied to improve the coding efficiency. This proposed framework may provide a good choice for bit budget constrained video communication applications, whose goal is to achieve the lowest possible but almost constant distortion, while maintain an acceptable frame-by-frame video quality (i.e., good average PSNR). As noted above, however, the process of substantially minimizing the quality fluctuation can be done in a number of other ways as well.<br>
[0073] The following develops a set of accurate rate and distortion estimation models to approximate the practical rate and distortion status in the second-pass coding. The models are again based on the observation that the rate and distortion of current frame are highly dependent on the QP of its preceding frame, and the QP selection of the previous frames earlier than the last one has very little impact on the performance of the current frame. The models and observations enable the significant reduction of the computational complexity of the process of QP selection in a two-pass approach. By<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
mapping the problem into a graph theory problem, a shortest path algorithm is applied to find the optimal solution efficiently. The proposed techniques have been simulated and tested. The experimental results have shown significant reduction of up to 70% of the peak signal to noise ratio (PSNR) fluctuation compared to the greedy frame-level rate control algorithm.<br>
[0074] There are several alternative meanings for "overall video quality", such as good average quality per frame, constant frame quality, and good perceptual video quality, just to name a few. However, there is generally no standardized unified video quality measurement available to take all aspects into account. In general, the minimum average distortion (MINAVE) criterion is mostly used to measure video distortion. Frame-level rate control algorithms have been proposed in attempts to achieve the best average PSNR of the decoded video sequence. However, conventional solutions with MINAVE criterion sometimes lead to unequal distortion across frames, which cause "flickering problems" due to abrupt quality changes between frames. Some recent study have focused on how to reduce the distortion variation across the sequence while maintain an acceptable per frame PSNR. However, these approaches are mainly designed for real-time applications with stringent delay constraints, and therefore the performance is often poor.<br>
[0075] As an alternative approach to a MINAVE approach, a minimum maximum (MINMAX) distortion approach may be a good choice for applications whose goal is to achieve an almost constant distortion. The philosophy behind this approach is that by minimizing the maximum source distortion, no single source distortion will be extremely high, and hence, the overall quality will be quite constant. This disclosure proposes a two-pass constant-quality rate control algorithm based on the MINMAX criterion. Accurate rate and distortion estimation models are established for frame level QP selection. The models are again based on an observation that the frame distortion highly depends on the level of quantization of its preceding frame, while the quantization selection of frames earlier than the previous frame has very little impact on the frame distortion of the current frame. In the models described herein, the actual distortion during the second pass coding can be approximated by a function of the distortion in the first pass (using the same QP), the energy of the motion-compensated residue in the first pass, and the distortion of the preceding frame in the first pass. In<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
addition, this disclosure studies the impact of reducing rate fluctuation on the proposed rate control scheme and proposes a solution for achieving both tasks. [0076] The proposed technique may represent a hybrid framework that is capable of achieving low fluctuations in both PSNR and bitrate by dynamically choosing the coding parameters using a minimum maximum distortion criterion. Also, the framework may work together with a set of accurate estimation models for frame rate and distortion. Approximations in the calculation can effectively speed up the coding performance by reducing the sampling and space from exponential to polynomial.<br>
 [0077] The problem in this embodiment is that of choosing the quantization parameter for each frame to achieve a decoded video sequence with least quality fluctuation, while maintaining an acceptable overall average PSNR and meeting certain rate fluctuation constraints, based on the statistics collected during the first-pass coding. Although the problem of how to do the first-pass coding is relevant, to simplify the problem, one can assume that a greedy frame-level bit allocation algorithm is used to code the frame at the first pass. Other QP selection techniques, however, could alternatively be used in the first pass.<br>
[0078] A model for the frame bit rate as a function of p, which is the number of nonzero quantized DCT coefficients in the frame, can be represented by:<br>
R = Ap + B, <br>
where A and B are constant modeling parameters, and A represents the average number of bits needed to code a non-zero quantized DCT coefficients and B represents the bits due to non-texture information, such as prediction modes and motion vectors.<br>
 [0079] Let N denote the number of total frames in the processed video sequence, and<br>
                                                                                          the quantization parameter QP, the average number of bits per non-zero quantized DCT coefficients, the number of bits for coding non-texture information, the number of non-zero quantized DCT coefficients, the energy of the motion-compensated residue, and the distortion of the ith frame resulted in the first pass coding, respectively. As used above, the variables identified by a "^" are variables estimated by the first coding pass. Variables without the identifier "A" are generally second pass variables, e.g., either approximations or second pass variables to be solved.<br><br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
[0080] Let Rbudg* denote the total bit budget for the video sequence, RdevjhreshoM the maximum allowed deviation of the actual frame bitrate from the average bitrate, and {Qi}&gt; {Ri} and {Di} the QP, bit rate and distortion of the ith frame in the second-pass coding. Therefore, a representation for the problem is:<br><br>
where both Rt and A are functions of Qt Q2, ..., Qi, due to the nature of the predictive<br>
coding. In addition,  <br>
[0081] In Equation 17, both mean and variance of the distortion are minimized with the given bit budget for the sequence. However, Equation 17 does not guarantee a solution because the QP selection that minimized the mean distortion might not be able to minimize the variance of the distortion, and vice-versa. A weighted approach can be used to modify the problem of Equation 17 into the form of:<br><br>
where a e [0,1] is a weighted factor that defines the relative importance of the mean and variance of the distortion. As expected, increasing a reduces the distortion variances in the cost of increased mean distortion. However, me determination of a is quite difficult without a user's interaction.<br>
[0082] In accordance with this disclosure, the problem can be formalized by:<br><br>
based on the assumptions that a target result is to achieve constant video quality, and that one does not expect a big difference in the mean distortion between the first pass and the second pass.<br>
[0083] Again, frame dependencies can be simplified based on an observation that the QP selection of the preceding frame has the major impact on the rate-distortion performance of the current frame. In other words, given the observations of frame dependencies according to this disclosure, one can reduce the i-tuple functions R,{Q1, Q2, .... Ql and Di(Q1, Q2. .... Ql) to 2-tuple functions Ri(Qi-1 Qi) and Di(Qi-1, Qi) because the selections of Qi, Q2,.... Qi-2 would not cause significant change on the rate and distortion for the ith frame. Hence, if the tables of                                                               are  obtained for all combinations of the candidates of gw and Qi, the problem of Equation 20 can solved directly simplifying the problem into:<br><br><br>
WO 2007/038230	PCT/US2006/036905<br><br><br><br>
This can be done by assuming that the distortion is a non-increasing function of the bit rate for the CODEC. In other words, one assumes that by increasing the number of available bits the CODEC'S performance will either remain the same or improve. Hence, when Dmax sweeps from zero to infinity, R'(Dmax, ) the solution to Equation 22<br>
traces out the staircase-like curve 175 shown in FIG. 17. Therefore, a bisection can be used to find the D* that satisfies R'(Dmax, ) £Rbadged   and therefore solves problem Equation<br>
21.<br>
[0085] In order to implement an algorithm to solve Equation 22, one can create a cost function Ck(Qk-1,Qk), which represents the minimum total rate up to and including the(k-I) frame with the distortion constraint in Equation 22, given that Qk-1 and Qk are QPs for the (k-I)st and kth. frames. Thus, the solution for                                                              is also the<br><br>
desired solution for Equation 22.<br>
[0086] One key observation for deriving an efficient algorithm is the fact that given decision vectors Qt-2 and Qk-1  for the (k-7)st and kth frames, and the cost function Ck-\(Qk-i&gt;Qk-i) &gt;me selection of the next decision vector Qk is independent of the selection of the previous decision vectors Q1, Q2, .... QK-3 This is true because the cost function can be expressed recursively as<br><br><br><br><br><br><br><br><br>
The recursive representation of the cost function above makes any future step of an optimization process independent from the previous steps, which is the foundation of dynamic programming.<br><br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
[0087] With the cost function defined by Equation 23, this problem can be converted into a graph theory problem of finding the shortest path in a directed acyclic graph (DAG). This solution is much more efficient than the exponential computational complexity of an exhaustive search algorithm. [0088] Estimation models can be used for rate and distortion. That is:<br><br>
By replacing the estimated rate and distortion in Equations 25-29 into Equations 22-24, the problem or Equation 5 can be solved efficiently.<br>
[0089] Experiments were conducted on a number of standard video test sequences, including video sequences identified as "Table tennis," "Foreman," and "Dancer," in bitrate ranges from 60 kbps to 120 kbps. The results are reported in the following text. [0090] A first set of experiments focused on the constant-quality features of the algorithm outlined in FIG. 16 by loosening the bitrate fluctuation constraint. The<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
proposed MINMAX approach outlined above was compared with two other approaches:<br>
(1) Frame-level greedy rate control, which assumes that the future coming frames have<br>
uniformly distributed texture complexity and therefore it allocates the remaining bits<br>
equally among the future frames, and (2) a MINMAX approach with higher PSNR<br>
expectation, that is, a MINMAX approach that also seeks constant-quality but requires<br>
same level of average PSNR to be achieved in the second pass as that of the first pass.<br>
The problem formulation is shown in Equation 30 as follows,<br><br><br><br><br><br><br>
where e is a very small number. Equation 30 is very similar to Equation 21 except the additional constraint on the average PSNR.<br>
[0091] In FIGS. 18-20, the testing results on the "Foreman" sequence are shown. In this example, all three approaches have similar rate-distortion performance, but the MINMAX approaches reduced the standard deviation of the frame PSNR by 50%. The detailed PSNR distribution is shown in FIG. 20 to demonstrate the reduction of the PSNR fluctuation by using MINMAX approach. In FIG. 18, the greedy frame level rate control approach is labeled 181, the proposed MINMAX approach is labeled 182, and a modified MINMAX approach that has higher PSNR expectation is labeled 183. In FIG. 19, the greedy frame level rate control approach is labeled 191, the proposed MINMAX approach is labeled 192, and a modified MINMAX approach that has higher PSNR expectation is labeled. 193. In FIG. 20, the greedy frame level rate control approach is labeled 201, and the proposed MINMAX approach is labeled 202.<br>
[0092] Testing results on 'Table tennis" sequence are shown in FIGS. 21-22. As expected, the proposed MINMAX approach has lower average frame PSNR, but it reduces the PSNR fluctuation from the greedy algorithm by 60-70%. The MINMAX approach with higher PSNR expectation obtained PSNR similar to that of the greedy algorithm with the reduction in PSNR fluctuation by 20-30%. In FIG. 21, the greedy frame level rate control approach is labeled 211, the proposed MINMAX approach is labeled 212, and a modified MINMAX approach that has higher PSNR expectation is labeled. 213. In FIG. 22, the greedy frame level rate control approach is labeled 221,<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
the proposed MINMAX approach is labeled 222, and a modified MINMAX approach that has higher PSNR expectation is labeled. 223.<br>
[0093] FIG. 23 is a graph showing detailed PSNR distributions in the "Table tennis" sequence when bitrate equals to 120kbps. FIG. 24 is a graph showing detailed QP distributions in the "Table tennis" sequence when bitrate equals 120kbps. m FIG. 23, the greedy frame level rate control approach is labeled 231, and the proposed MINMAX approach is labeled 232. In FIG. 24, the greedy frame level rate control approach is labeled 241, and the proposed MINMAX approach is labeled 242. <br>
[0094] FIGS. 25 and 26 illustrate the impact of the bitrate fluctuation constraint on the system performance by coding the 'Table tennis" sequence at 120kbps with various settings of the bitrate fluctuation threshold in the range of 5000 and 25000. FIG. 25, specifically, illustrates a curve 251 of the standard deviation of PSNR as a function of a bit rate fluctuation threshold. As expected, the PSNR fluctuation decreases when the threshold increases as shown in FIG. 25.<br>
[0095] The detail rate fluctuation is also compared in FIG. 26. Specifically, curve 261 is corresponds to the rate fluctuation threshold being 10000 and curve 262 corresponds to the rate fluctuation threshold being 25000. Clearly, with a tighter threshold, the resulted bit rate for the sequence is much smoother. It is important to notice that by using this threshold, the techniques can dynamically control the bit rate fluctuation, like using a virtual buffer, to avoid buffer overflow and underflow, as well as maintain a constant-video-quality characteristic of coded video sequence. <br>
[0096] The described MINMAX frame-level rate control algorithm can be used to minimize the peak maximum frame distortion, which indirectly assures the constant-quality of the reconstituted video sequence. The rate fluctuation in a video sequence can be controlled by a programmable threshold in the video coding device. The video coding device can be developed with a set of accurate rate and distortion models based on an observation that the quantization parameter selection of the preceding frame has the major impact on the rate-distortion performance of the current frame. The observation simplifies the frame dependencies problem, and thus reduces the size of the candidate space from exponential to polynomial. The experimental results set forth in the Graphs of FIGS. 17-26 indicate significant reduction of up to 70% of the PSNR standard deviation across the video sequence relative to a conventional greedy algorithm approach.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
[0097] A number of embodiments have been described. In particular, various rate control techniques have been proposed that use a "two-pass" approach in which a first coding pass is used to estimate characteristics of the video sequence, and the estimated characteristics are then used to improve upon the selection of quantization parameters (QPs) for the second pass. More specifically, two basic alternatives, consistent with this disclosure, have been proposed. In the first case, the estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that minimizes distortion of the frames of the video sequence. In the second case, the estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that minimizes quality fluctuation between the frames of the video sequence.<br>
[0098] The techniques described herein may be implemented in hardware, software, firmware, or any combination thereof. If implemented in software, the techniques may be directed to a computer readable medium comprising program code, that when executed in a device that codes video sequences, performs one or more of the techniques described herein. In that case, the computer readable medium may comprise random access memory (RAM) such as synchronous dynamic random access memory (SDRAM), read-only memory (ROM), non-volatile random access memory (NVRAM), electrically erasable programmable read-only memory (EEPROM), FLASH memory, and the like.<br>
[0099] The program code may be stored on memory in the form of computer readable instructions. In that case, a processor such as a DSP may execute instructions stored in memory in order to carry out one or more of the techniques described herein. In some cases, the techniques may be executed by a DSP that invokes various hardware components to accelerate the coding process.  In other cases, the video coder may be implemented as a microprocessor, one or more application specific integrated circuits (ASICs), one or more field programmable gate arrays (FPGAs), or some other hardware-software combination.<br>
[00100]	Although the two approaches have been described separately, various<br>
aspects of the two approaches may also be used in combination. Therefore, various aspects of the different techniques may be combined in still other embodiments contemplated by this disclosure. Also, although two pass approaches have been described, even more passes could also be performed in accordance with this disclosure.<br><br>
WO 2007/038230<br><br><br><br>
PCT/US2006/036905<br><br>
In other words, this disclosure is not limited to a two-pass approach, but is more broadly applicable to any multi-pass approach in which at least two coding passes are used. These and other embodiments are within the scope of the following claims.<br><br><br>
WO 2007/038230	 	PCT/US2006/036905<br><br>
We claim:<br>
1.	A video coding device comprising:<br>
means for coding frames of a video sequence using a set of first quantization parameters (QPs) in a first coding pass;<br>
means for obtaining rate-distortion statistics for the coded video sequence of the first coding pass;<br>
means for estimating rate-distortion characteristics of the video sequence based on the rate-distortion statistics; and<br>
means for selecting a second set of QPs for a second coding pass of the frames in the video sequence based on the estimated rate-distortion characteristics.<br>
2.	The coding device of claim 1, further comprising means for coding the video sequence using the set of second QPs in the second coding pass.<br>
3.	The coding device of claim 1, wherein the means for estimating applies a rate model and a distortion model to the rate-distortion statistics to estimate the rate-distortion characteristics.<br><br><br>
and wherein subscript "i" is an integer that identifies parameters with respect to an ith frame of the video sequence, subscript "i-1" identifies parameters with respect to an ith-l frame of the video sequence, and subscript "i-2" identifies parameters with respect to an ith-2 frame of the video sequence, wherein "A" notation defines respective variables as being first pass variables, and notation without "^" defines respective variables as being second pass variables, wherein "Q" variables are QPs, "D" variables are measures of distortion, "R" variables are measures of rate, "s2i’’'represents energy of motion-compensated residue, "p" variables define a number of non-zero quantized DCT coefficients, "A" variables refer to an average number of bits per non-zero quantized discrete cosine transformed (DCT) coefficients, "B" variables refer to a number of bits used for coding texture information, and "M" is the number of pixels in the frames of the video sequence.<br>
5.        The coding device of claim 1, wherein the means for selecting selects the second set of QPs by performing a Lagrangian relaxation operation on the estimated rate-distortion characteristics.<br>
WO 2007/038230	 	PCT/US2006/036905<br>
6.	The coding device of claim 5, wherein the means for selecting performs the<br>
Lagrangian relaxation operation by obtaining results of:<br><br><br><br>
wherein X is a Lagrange multiplier, J is a cost function, the subscript "i" is an integer that identifies parameters with respect to an ith frame of the video sequence, the subscript "i-1" identifies parameters with respect to an ith-l frame of the video sequence, "Q" variables are QPs, D is a distortion model, R is a rate model, and N is an integer.<br>
7.	The coding device of claim 1, wherein the means for selecting selects the second set of QPs by substantially minimizing distortion of the frames in the video sequence.<br>
8.	The coding device of claim 1, further comprising means for selecting the first set of QPs based on a greedy algorithm that uses a rate budget to define each QP in the first set.<br>
9.	The coding device of claim 1, wherein the QPs in the first set of QPs are identical to one another.<br>
10.	A method comprising:<br>
coding frames of a video sequence using a set of first quantization parameters (QPs) in a first coding pass;<br>
obtaining rate-distortion statistics for the coded video sequence;<br>
estimating rate-distortion characteristics of the video sequence based on the rate-distortion statistics; and<br>
selecting a second set of QPs for a second coding pass of the frames in the video sequence based on the estimated rate-distortion characteristics.<br>
11.	The method of claim 10, further comprising coding the video sequence using the<br>
set of second QPs in the second coding pass.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
12.	The method of claim 10, wherein estimating the rate-distortion characteristics comprises applying a rate model and a distortion model to the rate-distortion statistics.<br>
13.	The method of claim 12, wherein the rate model substantially corresponds to a model given by:<br>
R4 = (Ai)(Pi) + B! wherein the distortion model corresponds to a model given by: <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
and wherein subscript "i" is an integer that identifies parameters with respect to an Ith frame of the video sequence, subscript "i-1" identifies parameters with respect to an Ith-1 frame of the video sequence, and subscript "i-2" identifies parameters with respect to an ifc-2 frame of the video sequence, wherein "A" notation defines respective variables as being first pass variables, and notation without "A" defines respective variables as being second pass variables, wherein "Q" variables are QPs, "D" variables are measures of distortion, "R" variables are measures of rate, "s21’' represents energy of motion-compensated residue, "p" variables define a number of non-zero quantized DCT coefficients, "A" variables refer to an average number of bits per non-zero quantized discrete cosine transformed (DCT) coefficients, "B" variables refer to a number of bits used for coding texture information, and "M" is the number of pixels in the frames of i the video sequence.<br><br>
WO 2007/038230	 <br>
PCT/US2006/036905<br>
14.	The method of claim 10, wherein selecting the second set of QPs comprises performing a Lagrangian relaxation operation on the estimated rate-distortion characteristics.<br>
15.	The method of claim 14, wherein performing the Lagrangian relaxation operation comprises obtaining results of:<br>
wherein A, is a Lagrange multiplier, J is a cost function, the subscript' T' is an integer that identifies parameters with respect to an i* frame of the video sequence, the subscript "i-l" identifies parameters with respect to an i01-! frame of the video sequence, "Q" variables are QPs, D is a distortion model, R is a rate model, and ,N is an integer.<br>
16.	The method of claim 10, wherein selecting the second set of QPs comprises substantially minimizing distortion of the frames in the video sequence.<br>
17.	The method of claim 10, further comprising dynamically selecting the first set of QPs based on a greedy algorithm that uses a rate budget to define each QP in the first set.<br>
18.	The method of claim 10, wherein the QPs in the first set of QPs are identical to one another.<br>
19.	A computer readable medium comprising program code that when executed in a video coding device:<br>
code frames of a video sequence using a set of first quantization parameters (QPs) in a first coding pass;<br>
obtain rate-distortion statistics for the coded video sequence in the first coding pass;<br>
estimate rate-distortion characteristics of the video sequence based on the rate-distortion statistics; and<br>
select a second set of QPs for a second coding pass of the frames in the video sequence based on the estimated rate-distortion characteristics.<br><br>
WO 2007/038230<br>
PCT/US2006/036905<br>
20.	The computer readable medium of claim 19, further comprising program code that upon execution in the video coding device, codes the video sequence using the set of second QPs in the second coding pass.<br>
21.	The computer readable medium of claim 19, wherein the program code applies a rate model and a distortion model to the rate-distortion statistics to estimate the rate-distortion characteristics.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
22.      The computer readable medium of claim 21, wherein the rate model substantially corresponds to a model given by:<br>
R1 = (A,)(pi) + Bi<br>
 wherein the distortion model corresponds to a model given by:<br><br><br><br><br><br><br><br><br><br>
and wherein subscript "i" is an integer that identifies parameters with respect to an ith frame of the video sequence, subscript "i-1" identifies parameters with respect to an ith-1 frame of the video sequence, and subscript "i-2" identifies parameters with respect to an ith-2 frame of .the video sequence, wherein "^" notation defines respective variables as being first pass variables, and notation without "A" defines respective variables as being second pass variables, wherein "Q" variables are QPs, "D" variables are measures of distortion, "R" variables are measures of rate, "^"represents energy of motion-compensated residue, "p" variables define a number of non-zero quantized DCT coefficients, "A" variables refer to an average number of bits per non-zero quantized discrete cosine transformed (DCT) coefficients, "B" variables refer to a number of bits used for coding texture information, and "M" is the number of pixels in the frames of the video sequence.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
23.	The computer readable medium of claim 19, wherein the program code selects the second set of QPs by performing a Lagrangian relaxation operation on the estimated rate-distortion characteristics.<br>
24.	The computer readable medium of claim 23, wherein the program code performs the Lagrangian relaxation operation by obtaining results of:<br><br><br><br><br>
wherein l is a Lagrange multiplier, J is a cost function, the subscript "i" is an integer that identifies parameters with respect to an ith frame of the video sequence, the subscript "i-1" identifies parameters with respect to an ith-l frame of the video sequence, "Q" variables are QPs, D is a distortion model, R is a rate model, and N is an integer.<br>
25.	The computer readable medium of claim 19, wherein the program code selects the second set of QPs by substantially minimizing distortion of the frames in the video sequence.<br>
26.	The computer readable medium of claim 19, wherein the program code dynamically selects the first set of QPs based on a greedy algorithm that uses a rate budget to define each QP in the first set.<br>
27.	The computer readable medium of claim 19, wherein the QPs in the first set of<br>
QPs are identical to one another.<br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
28.	A video coding device comprising:<br>
a video memory that stores a video sequence;<br>
a local memory that stores at least part of the video sequence during video coding; and<br>
a video coder that codes the video sequence by:<br>
coding frames of the video sequence using a set of first quantization parameters (QPs) in a first coding pass,<br>
obtaining rate-distortion statistics for the coded video sequence of the first coding pass,<br>
estimating rate-distortion characteristics of the video sequence based on the rate-distortion statistics,<br>
selecting a second set of QPs for a second coding pass of the frames in the video sequence based on the estimated rate-distortion characteristics, and<br>
coding the video sequence using the second set of QPs in a second coding pass.<br>
29.	The video coding device of claim 28, wherein the video coder includes a motion estimator, a motion compensator, a residual coder, and a rate control unit, wherein the motion estimator, the motion compensator, and the residual coder code the video sequence using the first set of QPs in the first coding pass and code the video sequence using the second set of QPs in the second coding pass, and wherein the rate control unit obtains the rate-distortion statistics, estimates rate-distortion characteristics, and selects the second set of QPs.<br>
30.	The video coding device of claim 29, further comprising a video capture device to capture the video sequence and a transmitter to transmit the coded video sequence of the second coding pass.<br><br><br>
WO 2007/038230	 	PCT/US2006/036905<br>
31.	The video coding device of claim 28, wherein the video coder includes a spatial estimator, an intra-frame prediction unit, a residual coder, and a rate control unit, wherein the spatial estimator, the intra-frame prediction unit, and the residual coder code the video sequence using the first set of QPs in the first coding pass and code the video sequence using the second set of QPs in the second coding pass, and wherein the rate control unit obtains the rate-distortion statistics, estimates rate-distortion characteristics, and selects the second set of QPs.<br>
32.	A video coder that codes the video sequence by:<br>
coding frames of the video sequence using a set of first quantization parameters (QPs) in a first coding pass;<br>
obtaining rate-distortion statistics for the coded video sequence of the first coding pass;<br>
estimating rate-distortion characteristics of the video sequence based on the<br>
rate-distortion statistics;<br>
*■ selecting a second set of QPs for a second coding pass of the frames in the video<br>
sequence based on the estimated rate-distortion characteristics; and<br>
coding the video sequence using the second set of QPs in a second coding pass.<br><br><br><br><br><br>
ABSTRACT<br>
"TWO PASS RATE CONTROL TECHNIQUES FOR VIDEO CODING USING RATE-DISTORTION CHARACTERISTICS"<br>
This disclosure describes rate control techniques that can improve video coding based on a 'two-pass' approach. The first pass codes a video sequence using a first set of quantization parameters (QPs) for the purpose of estimating rate-distortion characteristics of the video sequence based on the statistics of the first pass. A second set of QPs can then be defined for a second coding pass. The estimated rate-distortion characteristics of the first pass are used to select QPs for the second pass in a manner that minimizes distortion of the frames of the video sequence.<br><br><br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQUJTVFJBQ1QoMjQtMi0yMDE0KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-ABSTRACT(24-2-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtYWJzdHJhY3QuZG9j" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ0hJTkEgRE9DVU1FTlQoNy02LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CHINA DOCUMENT(7-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ0xBSU1TKEFNRU5ERUQpLSgyNC0yLTIwMTQpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CLAIMS(AMENDED)-(24-2-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ0xBSU1TKEFNRU5ERUQpLSgyNS0xMC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CLAIMS(AMENDED)-(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ0xBSU1TKE1BUktFRCBDT1BZKS0oMjQtMi0yMDE0KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CLAIMS(MARKED COPY)-(24-2-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ0xBSU1TKE1BUktFRCBDT1BZKS0oMjUtMTAtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CLAIMS(MARKED COPY)-(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtY2xhaW1zLmRvYw==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtY29ycmVzcG9uZGVuY2UoMTMtNS0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-correspondence(13-5-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoMTUtOS0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(15-9-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtY29ycmVzcG9uZGVuY2UoMTYtNC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-correspondence(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoMTktMTAtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(19-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoMTktMTItMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(19-12-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoMjMtOS0yMDEzKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(23-9-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoMjQtOS0yMDEzKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(24-9-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoNy0xLTIwMTQpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(7-1-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtQ09SUkVTUE9OREVOQ0UoNy02LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-CORRESPONDENCE(7-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtY29ycmVzcG9uZGVuY2Utb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtY29ycmVzcG9uZGVuY2UtcmVjZWl2ZWQucGRm" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-correspondence-received.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRFJBV0lORygyNS0xMC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-DRAWING(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRVAgRE9DVU1FTlQoNy02LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-EP DOCUMENT(7-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAxKDE5LTEwLTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 1(19-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAxKDI0LTItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 1(24-2-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAxKDI1LTEwLTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 1(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAxMygxOS0xMC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 13(19-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybSAxOCgxNi00LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form 18(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybSAyKHRpdGxlIHBhZ2UpLSgxNi00LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form 2(title page)-(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAyKFRJVExFIFBBR0UpLSgyNC0yLTIwMTQpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 2(TITLE PAGE)-(24-2-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybSAyNigxNi00LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form 26(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAyNigyNS0xMC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 26(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAzKDE1LTktMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 3(15-9-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybSAzKDE2LTQtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form 3(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAzKDE5LTEyLTIwMTMpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 3(19-12-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtRk9STSAzKDctNi0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-FORM 3(7-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0xOC5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yLTEuZG9j" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-2-1.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yLTIuZG9j" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-2-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yLTMuZG9j" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-2-3.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yLTQuZG9j" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-2-4.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yLmRvYw==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0yNi5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS01LnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtZm9ybS1wY3QtaWItMzA0LnBkZg==" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-form-pct-ib-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtaW50ZXJuYXRpb25hbCBwdWJsaWNhdGlvbiByZXBvcnQoMTYtNC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-international publication report(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtSlAgRE9DVU1FTlQoNy02LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-JP DOCUMENT(7-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtS09SRUFOIERPQ1VNRU5UKDctNi0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-KOREAN DOCUMENT(7-6-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtcGN0LXNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-pct-search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtUEVUSVRJT04gVU5ERVIgUlVMRSAxMzcoMjUtMTAtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-PETITION UNDER RULE 137(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtUkVQTFkgVE8gRVhBTUlOQVRJT04gUkVQT1JUKDI1LTEwLTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-REPLY TO EXAMINATION REPORT(25-10-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LU1VTU5QLTIwMDgtUkVQTFkgVE8gSEVBUklORygyNC0yLTIwMTQpLnBkZg==" target="_blank" style="word-wrap:break-word;">737-MUMNP-2008-REPLY TO HEARING(24-2-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM3LW11bW5wLTIwMDgtd28gaW50ZXJuYXRpb25hbCBwdWJsaWNhdGlvbiByZXBvcnQoMTYtNC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">737-mumnp-2008-wo international publication report(16-4-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="259228-production-and-methodology-for-electronic-grade-di-isopropyl-telluride.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="259230-process.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>259229</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>737/MUMNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>10/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>07-Mar-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>04-Mar-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>16-Apr-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>QUALCOMM INCORPORATED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>5775 MOREHOUSE DRIVE, SAN DIEGO, CALIFORNIA 92121-1714,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>WANG, HAOHONG</td>
											<td>5385 TOSCANA WAY #328, SAN DIEGO, CA 92122,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>MALAYATH, NARENDRANATH</td>
											<td>10710 SABRE HILL DRIVE, #229, SAN DIEGO, CA 92128,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2006/036905</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-09-21</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/719,775</td>
									<td>2005-09-22</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>11/303,617</td>
									<td>2006-12-15</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/259229-a-video-coding-device-and-method-for-rate-controlled-coding-of-video-sequences by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 02:47:50 GMT -->
</html>
