<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/255801-device-and-method-for-generating-an-encoded-stereo-signal-of-an-audio-piece-or-audio-datastream by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:15:07 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 255801:DEVICE AND METHOD FOR GENERATING AN ENCODED STEREO SIGNAL OF AN AUDIO PIECE OR AUDIO DATASTREAM</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">DEVICE AND METHOD FOR GENERATING AN ENCODED STEREO SIGNAL OF AN AUDIO PIECE OR AUDIO DATASTREAM</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Device and method for generating an encoded stereo signal of an audio piece or audio datastream A device for generating an encoded stereo signal from a multi-channel representation includes a multi-channel decoder (11) generating three of more multi-channels from at least one basic channel and parametric information. The three or more multi-channels are subjected to headphone signal processing (12) to generate an uncoded first stereo channel (10a) and an uncoded second stereo channel (10b) which are then supplied to a stereo encoder (13) to generate an encoded stereo file (14) on the output side. The encoded stereo file may be supplied to any suitable player in the form of a CD player or a hardware player such that a user of the player does not only get a normal stereo impression but a multi-channel impression.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
Device and method for generating an encoded stereo signal of an audio piece<br>
or audio datastream<br>
Description<br>
The present invention relates to multi-channel audio technology and, in particular, to<br>
multi-channel audio applications in connection with headphone technologies.<br>
The international patent applications WO 99/49574 (Applicant- LAKE DSP PTY, LTD,<br>
Filing Date: 6 January 1999, Publication Date: 30 September 1999, Country name:<br>
Australia) and WO 99/14983 (Applicant- LAKE DSP PTY. LIMITED, Filing Date: 16<br>
September 1998, Publication Date: 25 March 1999, Country name: Australia) disclose<br>
audio signal processing technologies for driving a pair of oppositely arranged headphone<br>
loudspeakers in order for a user to get a spatial perception of the audio scene via the<br>
two headphones, which is not only a stereo representation but a multi-channel<br>
representation. Thus, the listener will get, via his or her headphones, a spatial<br>
perception of an audio piece which in the best case equals his or her spatial perception,<br>
should the user be sitting in a reproduction room which is exemplarily equipped with a<br>
5.1 audio system. For this purpose, for each headphone loudspeaker, each channel of<br>
the multi-channel audio piece or the multi-channel audio datastream, as is illustrated in<br>
Fig. 2, is supplied to separate filter, whereupon the respective filtered channels<br>
belonging together are added, as will be illustrated subsequently.<br>
On a left side in Fig. 2, there are the multi-channel inputs 20 which together represent a<br>
multi-channel representation of the audio piece or the audio datastream. Such a<br>
scenario is exemplarily schematically shown in Fig. 10. Fig. 10 shows a reproduction<br>
space 200 in which a so-called 5.1 audio system is arranged. The 5.1 audio system<br>
includes a center loudspeaker 201, a front-left loudspeaker 202, a front-right<br>
loudspeaker 203, a back-left loudspeaker 204 and a back-right loudspeaker 205. A 5.1<br>
audio system comprises an additional subwoofer 206 which is also referred to as low-<br>
frequency enhancement channel. In the<br><br>
so-called "sweet spot" of the reproduction space 200, there<br>
is a listener 207 wearing a headphone 208 comprising a left<br>
headphone loudspeaker 209 and a right headphone loudspeaker<br>
210.<br>
The processing means shown in Fig. 2 is formed to filter<br>
each channel 1, 2, 3 of the multi-channel inputs 20 by a<br>
filter HiL describing the sound channel from the<br>
loudspeaker to the left loudspeaker 209 in Fig. 10 and to<br>
additionally filter the same channel by a filter HlR<br>
representing the sound from one of the five loudspeakers to<br>
the right ear or the right loudspeaker 210 of the headphone<br>
208.<br>
If, for example, channel 1 in Fig. 2 were the front-left<br>
channel emitted by the loudspeaker 202 in Fig. 10, the<br>
filter 'HiL would represent the channel indicated by a<br>
broken line 212, whereas the filter HiR would represent the<br>
channel indicated by a broken line 213. As is exemplarily<br>
indicated in Fig. 10 by a broken line 214, the left<br>
headphone loudspeaker 209 does not only receive the direct<br>
sound, but also early reflections at an edge of the<br>
reproduction space and, of course, also late reflections<br>
expressed in a diffuse reverberation.<br>
Such a filter representation is illustrated in Fig. 11. In<br>
particular, Fig. 11 shows a schematic example of an impulse<br>
response of a filter, such as, for example, of the filter<br>
HIL of Fig. 2. The direct or primary sound illustrated in<br>
Fig. 11 by the line 212 is represented by a peak at the<br>
beginning of the filter, whereas early reflections, as are<br>
illustrated exemplarily in Fig. 10 by 214, are reproduced<br>
by a center region having several (discrete) small peaks in<br>
Fig. 11. The diffuse reverberation is typically no longer<br>
resolved for individual peaks, since the sound of the<br>
loudspeaker 202 in principle is reflected arbitrarily<br>
frequently, wherein the energy of course decreases with<br>
each reflection and additional propagation distance, as is<br><br>
illustrated by the decreasing energy in the back portion<br>
which in Fig. 11 is referred to as "diffuse reverberation".<br>
Each filter shown in Fig. 2 thus includes a filter impulse<br>
response roughly having a profile as is shown by the<br>
schematic impulse response illustration of Fig. 11. It is<br>
obvious that the individual filter impulse response will<br>
depend on the reproduction space, the positioning of the<br>
loudspeakers, possible attenuation features in the<br>
reproduction space, for example due to several persons<br>
present or due to furniture in the reproduction space, and<br>
ideally' also on the characteristics of the individual<br>
loudspeakers 201 to 206.<br>
The fact that the signals of all loudspeakers are<br>
superposed at the ear of the listener 207 is illustrated by<br>
the adders 22 and 23 in Fig. 2. Thus, each channel is<br>
filtered by a corresponding filter for the left ear to then<br>
simply add up the signals output by the filters which are<br>
destined for the left ear to obtain the headphone output<br>
signal for the left ear L. In analogy, an addition by the<br>
adder 23 for the right ear or the right headphone<br>
loudspeaker 210 in Fig. 10 is performed to obtain the<br>
headphone output signal for the right ear by superposing<br>
all the loudspeaker signals filtered by a corresponding<br>
filter for the right ear.<br>
Due to the fact that, apart from the direct sound, there<br>
are also early reflections and, in particular, a diffuse<br>
reverberation, which is of particularly high importance for<br>
the space perception, in order for the tone not to sound<br>
synthetic or "awkward" but to give the listener the<br>
impression that he or she is actually sitting in a concert<br>
room with its acoustic characteristics, impulse responses<br>
of the individual filters 21 will all be of considerable<br>
lengths. The convolution of each individual multi-channel<br>
of the multi-channel representation having two filters<br>
already results in a considerable computing task. Since two<br><br>
filters are required for each individual multi-channel,<br>
namely one for the left ear and another one for the right<br>
ear, when the subwoofer channel is also treated separately,<br>
a total amount of 12 completely different filters is<br>
required for a headphone reproduction of a 5.1 multi-<br>
channel representation. All filters have, as becomes<br>
obvious from Fig. 11, a very long impulse response to be<br>
able to not only consider the direct sound but also early<br>
reflections and the diffuse reverberation, which really<br>
only gives an audio piece the proper sound reproduction and<br>
a good spatial impression.<br>
In order to put the well-known concept into practice, apart<br>
from a multi-channel player 220, as is shown in Fig. 10,<br>
very complicated virtual sound processing 222 is required,<br>
which provides the signals for the two loudspeakers 209 and<br>
210 represented by lines 224 and 226 in Fig. 10.<br>
Headphone systems for generating a multi-channel headphone<br>
sound are complicated, bulky and expensive, which is due to<br>
the high computing power, the high current requirement for<br>
the high computing power required and the high working<br>
memory requirements for the evaluations to be performed of<br>
the impulse response and the high volume or expensive<br>
elements for the player connected thereto. Applications of<br>
this kind are thus tied to home PC sound cards or laptop<br>
sound cards or home stereo systems.<br>
In particular, the multi-channel headphone sound remains<br>
inaccessible for the continually increasing market of<br>
mobile players, such as, for example, mobile CD players,<br>
or, in particular, hardware players, since the calculating<br>
requirements for filtering the multi-channels with<br>
exemplarily 12 different filters cannot be realized in this<br>
price segment neither with regard to the processor<br>
resources nor with regard to the current requirements of<br>
typically battery-driven apparatuses. This refers to a<br>
price segment at the bottom (lower) end of the scale.<br><br>
However, this very price segment is economically very<br>
interesting due to the high numbers of pieces.<br>
The object of the present invention is to provide an<br>
efficient signal-processing concept allowing a multi-<br>
channel quality headphone reproduction on simple<br>
reproduction apparatuses.<br>
This object is achieved by a device for generating an<br>
encoded stereo signal according to claim 1 or by a method<br>
for generating an encoded stereo signal according to claim<br>
11 or by a computer program according to claim 12.<br>
The present invention is based on the finding that the<br>
high-quality and attractive multi-channel headphone sound<br>
can be made available to all players available, such as,<br>
for example, CD players or hardware players, by subjecting<br>
a multi-channel representation of an audio piece or audio<br>
datastream, i.e. exemplarily a 5.1 representation of an<br>
audio piece, to headphone signal processing outside a<br>
hardware player, i.e. exemplarily in a computer of a<br>
provider having a high calculating power. According to the<br>
invention, the result of a headphone signal processing is,<br>
however, not simply played but supplied to a typical audio<br>
stereo encoder which then generates an encoded stereo<br>
signal from the left headphone channel and the right<br>
headphone channel.<br>
This encoded stereo signal may then, like any other encoded<br>
stereo signal not comprising a multi-channel<br>
representation, be supplied to the hardware player or, for<br>
example, a mobile CD player in the form of a CD. The<br>
reproduction or replay apparatus will then provide the user<br>
with a headphone multi-channel sound without any additional<br>
resources or means having to be added to devices already<br>
existing. Inventively, the result of the headphone signal<br>
processing, i.e. the left and the right headphone signal,<br>
is not reproduced in a headphone, as has been the case in<br><br>
the prior art, but encoded and output as encoded stereo<br>
data.<br>
Such an output may be storage, transmission or the like.<br>
Such a file having encoded stereo data may then easily be<br>
supplied to any reproduction device designed for stereo<br>
reproduction, without the user having to perform any<br>
changes on his device.<br>
The inventive concept of generating an encoded stereo<br>
signal from the result of the headphone signal processing<br>
thus allows multi-channel representation providing a<br>
considerably improved and more real quality for the user,<br>
to be also employed on all simple and widespread and, in<br>
future, even more widespread hardware players.<br>
In a preferred embodiment of the present invention, the<br>
starting point is an encoded multi-channel representation,<br>
i.e. a parametric representation comprising one or<br>
typically two basic channels and additionally comprising<br>
parametric data to generate the multi-channels of the<br>
multi-channel representation on the basis of the basic<br>
channels and the parametric data. Since a frequency domain-<br>
based method for multi-channel decoding is preferred, the<br>
headphone signal processing is, according to the invention,<br>
not performed in the time domain by convoluting the time<br>
signal by an impulse response, but in the frequency domain<br>
by multiplication by the filter transmission function.<br>
This allows at least one retransformation before the<br>
headphone signal processing to be saved and is of<br>
particular advantage when the subsequent stereo encoder<br>
also operates in the frequency domain, such that the stereo<br>
encoding of the headphone stereo signal, without ever<br>
having to go to the time domain, may also take place<br>
without going to the time domain. The processing from the<br>
multi-channel representation to the encoded stereo signal,<br>
without the time domain taking part or by an at least<br><br>
reduced number of transformations, is interesting not only with regard to the calculating<br>
time efficiency, but puts a limit to quality losses since fewer processing stages will<br>
introduce fewer artifacts into the audio signal.<br>
In particular in block-based methods performing quantization considering a psycho-<br>
acoustic masking threshold, as is preferred for the stereo encoder, it is important to<br>
prevent as may tandem encoding artifacts as possible.<br>
In a particularly preferred embodiment of the present invention, a BCC representation<br>
having one or preferably two basic channels is used as a multi-channel representation.<br>
Since the BCC method operates in the frequency domain, the multi-channels are not<br>
transformed to the time domain after synthesis, as is usually done in a BCC decoder.<br>
Instead, the spectral representation of the multi-channels in the form of blocks is used<br>
and subjected to the headphone signal processing. For this, the transformation functions<br>
of the filters, i.e. the Fourier transforms of the impulse responses, are used to perform a<br>
multiplication of the spectral representation of the multi-channels by the filter<br>
transformation functions. When the impulse responses of the filters are, in time, longer<br>
than a block of spectral components at the output of the BCC decoder, a block-wise<br>
filter processing is preferred where the impulse responses of the filters are separated in<br>
the time domain and are transformed block by block in order to then perform<br>
corresponding spectrum weightings required for measures of this kind, as is, for<br>
example, disclosed in WO 94/01933 (Applicant- LAKE DSP PTY. LIMITED, Filing Date: 5<br>
July 1993, Publication Date: 20 January 1994, Country name: Australia).<br>
Preferred embodiments of the present invention will be detailed subsequently referring<br>
to the appended drawings, in which:<br><br>
Fig. 1 shows a block circuit diagram of the inventive<br>
device for generating an encoded stereo signal;<br>
Fig. 2 is a detailed illustration of an implementation<br>
of the headphone signal processing of Fig. 1;<br>
Fig. 3 shows a well-known joint stereo encoder for<br>
generating channel data and parametric multi-<br>
channel information;<br>
Fig. 4 is an illustration of a scheme for determining<br>
ICLD, ICTD and ICC parameters for BCC<br>
encoding/decoding;<br>
Fig. 5 is a block diagram illustration of a BCC<br>
encoder/decoder chain;<br>
Fig. 6 shows a block diagram of an implementation of the<br>
BCC synthesis block of Fig. 5;<br>
Fig. 7 shows cascading between a multi-channel decoder<br>
and the headphone signal processing without any<br>
transformation to the time domain;<br>
Fig. 8 shows cascading between the headphone signal<br>
processing and a stereo encoder without any<br>
transformation to the time domain;<br>
Fig. 9 shows a principle block diagram of a preferred<br>
stereo encoder;<br>
Fig. 10 is a .principle illustration of a reproduction<br>
scenario for determining the filter functions of<br>
Fig. 2; and<br>
Fig. 11 is a principle illustration of an expected<br>
impulse response of a filter determined according<br>
to Fig. 10.<br><br>
Fig. 1 shows a principle block circuit diagram of an<br>
inventive device for generating an encoded stereo signal of<br>
an audio piece or- an audio datastream. The stereo signal<br>
includes, in an uncoded form, an uncoded first stereo<br>
channel 10a and an uncoded second stereo channel 10b and is<br>
generated from a multi-channel representation of the audio<br>
piece or the audio data stream, wherein the multi-channel<br>
representation comprises information on more than two<br>
multi-channels. As will be explained later, the multi-<br>
channel representation may be in an uncoded or an encoded<br>
form. If the multi-channel representation is in an uncoded<br>
form, it will include three or more multi-channels. With a<br>
preferred application scenario, the multi-channel<br>
representation includes five channels and one subwoofer<br>
channel.<br>
If the multi-channel representation is, however, in an<br>
encoded form, this encoded form will typically include one<br>
or several basic channels as well as parameters for<br>
synthesizing the three or more multi-channels from the one<br>
or two basic channels. A multi-channel decoder 11 thus is<br>
an example of means for providing the more than two multi-<br>
channels from the multi-channel representation. If the<br>
multi-channel representation is, however, already in an<br>
uncoded form, i.e., for example, in the form of 5 + 1 PCM<br>
channels, the means for providing corresponds to an input<br>
terminal for means 12 for performing headphone signal<br>
processing to generate the uncoded stereo signal with the<br>
uncoded first stereo channel 10a and the uncoded second<br>
stereo channel 10b.<br>
Preferably, the means 12 for performing headphone signal<br>
processing is formed to evaluate the multi-channels of the<br>
multi-channel representation each by a first filter<br>
function for the first stereo channel and by a second<br>
filter function for the second stereo channel and to add<br>
the respective evaluated multi-channels to obtain the<br><br>
uncoded first stereo channel and the uncoded second stereo<br>
channel, as is illustrated referring to Fig. 2. Downstream<br>
of the means 12 for performing the headphone signal<br>
processing is a stereo encoder 13 which is formed to encode<br>
the first uncoded stereo channel 10a and the second uncoded<br>
stereo channel 10b to obtain the encoded stereo signal at<br>
an output 14 of the stereo encoder 13. The stereo encoder<br>
performs a data rate reduction such that a data rate<br>
required for transmitting the encoded stereo signal is<br>
smaller than a data rate required for transmitting the<br>
uncoded stereo signal.<br>
According to the invention, a concept is achieved which<br>
allows supplying a multi-channel tone, which is also<br>
referred to as "surround", to stereo headphones via simple<br>
players, such as, for example, hardware players.<br>
The sum of certain channels may exemplarily be formed as<br>
simple headphone signal processing to obtain the output<br>
channels for the stereo data. Improved methods operate with<br>
more complex algorithms which in turn obtain an improved<br>
reproduction quality.<br>
It is to be mentioned that the inventive concept allows the<br>
calculating-intense steps for multi-channel decoding and<br>
for performing the headphone signal processing not to be<br>
performed in the player itself but to be performed<br>
externally. The result of the inventive concept is an<br>
encoded stereo file which is, for example, an MP3 file, an<br>
AAC file, an HE-AAC file or some other stereo file.<br>
In other embodiments, the multi-channel decoding, headphone<br>
signal processing and stereo encoding may be performed on<br>
different devices since the output data and input data,<br>
respectively, of the individual blocks may be ported easily<br>
and be generated and stored in a standardized way.<br><br>
Subsequently, reference will be made to Fig. 7 showing a<br>
preferred embodiment of the present invention where the<br>
multi-channel decoder 11 comprises a filter bank or FFT<br>
function such that the multi-channel representation is<br>
provided in the frequency domain. In particular, the<br>
individual multi-channels are generated as blocks of<br>
spectral values for each' channel. Inventively, the<br>
headphone signal processing is not performed in the time<br>
domain by convoluting the temporal channels with the filter<br>
impulse responses, but a multiplication of the frequency<br>
domain representation of the multi-channels by a spectral<br>
representation of the filter impulse response is performed.<br>
An uncoded stereo signal is achieved at the output of the<br>
headphone signal processing, which is, however, not in the<br>
time domain but includes a left and a right stereo channel,<br>
wherein such a stereo channel is given as a sequence of<br>
blocks of spectral values, each block of spectral values<br>
representing a short-term spectrum of the stereo channel.<br>
In the embodiment shown in Fig. 8, the headphone signal-<br>
processing block 12 is, on the input side, supplied with<br>
either time-domain or frequency-domain data. On the output<br>
side, the uncoded stereo channels are generated in the<br>
frequency domain, i.e. again as a sequence of blocks of<br>
spectral values. A stereo encoder which is based on a<br>
transformation, i.e. which processes spectral values<br>
without a frequency/time conversion and a subsequent<br>
time/frequency conversion being necessary between the<br>
headphone signal processing 12 and the stereo encoder 13,<br>
is preferred as the stereo encoder 13 in this case. On the<br>
output side, the stereo encoder 13 then outputs a file with<br>
the encoded stereo signal which, apart from side<br>
information, includes an encoded form of spectral values.<br>
In a particularly preferred embodiment of the present<br>
invention, a continuous frequency domain processing is<br>
performed on the way from the multi-channel representation<br>
at the input of block 11 of Fig. 1 to the encoded stereo<br><br>
file at the output 14 of the means of Fig. 1, without a<br>
transformation to the time domain and, possibly, a re-<br>
transformation to the frequency domain having to take<br>
place. When an MP3 encoder or an AAC encoder is used as the<br>
-stereo encoder, it will be preferred to transform the<br>
Fourier spectrum at the output of the headphone signal-<br>
processing block to an MDCT spectrum. Thus, it is ensured<br>
according to the invention that the phase information<br>
required in a precise form for the convolution/evaluation<br>
of the channels in the headphone signal-processing block is<br>
converted to the MDCT representation not operating in such<br>
a phase-correct way, such that means for transforming from<br>
the time domain to the frequency domain, i.e. to the MDCT<br>
spectrum, is not required for the stereo encoder, in<br>
contrast to a normal MP3 encoder or a normal AAC encoder.<br>
Fig. 9 shows a general block circuit diagram for a<br>
preferred stereo encoder. The stereo encoder includes, on<br>
the input side, a joint stereo module 15 which is<br>
preferably determining in an adaptive way whether a common<br>
stereo encoding, for example in the form of a center/side<br>
encoding, provides a higher encoding gain than a separate<br>
processing of the left and right channels. The joint stereo<br>
module 15 may further be formed to perform an intensity<br>
stereo encoding, wherein an intensity stereo encoding, in<br>
particular with higher frequencies, provides a considerable<br>
encoding gain without audible artefacts arising. The output<br>
of the joint stereo module 15 is then processed further<br>
using different other redundancy-reducing measures, such<br>
as, for example, TNS filtering, noise substitution, etc.,<br>
to then supply the results to a quantizer 16 which achieves<br>
a quantization of the spectral values using a psycho-<br>
acoustxc masking threshold. The quantizer step size here is<br>
selected such that the noise introduced by quantizing<br>
remains below the psycho-acoustic masking threshold, such<br>
that a data rate reduction is achieved without the<br>
distortions introduced by the lossy quantization to be<br>
audible. Downstream of the quantizer 16, there is an<br><br>
entropy encoder 17 performing lossless entropy encoding of<br>
the quantized spectral values. At the output of the entropy<br>
encoder, there is the encoded stereo signal which, apart<br>
from the entropy-coded spectral values, includes side<br>
information required for decoding.<br>
Subsequently, reference will be made to preferred<br>
implementations of the multi-channel decoder and to<br>
preferred multi-channel illustrations using Figs. 3 to 6.<br>
There are several techniques for reducing the amount of<br>
data required for transmitting a multi-channel audio<br>
signal. Such techniques are also called joint stereo<br>
techniques. For this purpose, reference is made to Fig. 3<br>
showing a joint stereo device 60. This device may be a<br>
device implementing, for example, the intensity stereo (IS)<br>
technique or the binaural cue encoding technique (BCC).<br>
Such a device generally receives at least two channels CHI,<br>
CH2, ..., CHn as input signal and outputs a single carrier<br>
channel and parametric multi-channel information. The<br>
parametric data are defined so that an approximation of an<br>
original channel (CHI, CH2, ..., CHn) may be calculated in a<br>
decoder.<br>
Normally, the carrier channel will include subband samples,<br>
spectral coefficients, time domain samples, etc., which<br>
provide a relatively fine representation of the underlying<br>
signal, whereas the parametric data do not include such<br>
samples or spectral coefficients, but control parameters<br>
for controlling a certain reconstruction algorithm, such<br>
as, for example, weighting by multiplication, time<br>
shifting, frequency shifting, etc. The parametric multi-<br>
channel information thus includes a relatively rough<br>
representation of the signal or the associated channel.<br>
Expressed in numbers, the amount of data required by a<br>
carrier channel is in the range of 60 to 70 kbits/s,<br>
whereas the amount of data required by parametric side<br>
information for a channel is in the range from 1.5 to 2.5<br><br>
kbits/sec. It is to be mentioned that the above numbers<br>
apply to compressed data. A non-compressed CD channel of<br>
course requires approximately tenfold data rates. An<br>
example of parametric data are the known scale factors,<br>
intensity stereo information or BCC parameters, as will be<br>
described below.<br>
The intensity stereo encoding technique is described in the<br>
AES Preprint 3799 entitled "Intensity Stereo Coding" by J.<br>
Herre, K.H. Brandenburg, D. Lederer, February 1994,<br>
Amsterdam. In general, the concept of intensity stereo is<br>
based on a main axis transform which is to be applied to<br>
data of the two stereophonic audio channels. If most data<br>
points are concentrated around the first main axis, an<br>
encoding gain may be achieved by rotating both signals by a<br>
certain angle before encoding takes place. However, this<br>
does not always apply to real stereophonic reproduction<br>
techniques. Thus, this technique is modified in that the<br>
second orthogonal component is excluded from being<br>
transmitted in the bitstream. Thus, the reconstructed<br>
signals for the left and right channels consist of<br>
differently weighted or scaled versions of the same<br>
transmitted■signal. Nevertheless, the reconstructed signals<br>
differ in amplitude, but they are identical with respect to<br>
their phase information. The energy time envelopes of both<br>
original audio channels, however, are maintained by means<br>
of the selective scaling operation typically operating in a<br>
frequency-selective manner. This corresponds to human sound<br>
perception at high frequencies where the dominant spatial<br>
information is determined by the energy envelopes.<br>
In addition, in practical implementations, the transmitted<br>
signal, i.e. the carrier channel, is produced from the sum<br>
signal of the left channel and the right channel instead of<br>
rotating both components. Additionally, this processing,<br>
i.e. generating intensity stereo parameters for performing<br>
the scaling operations, is performed in a frequency-<br>
selective manner, i.e. independently for each scale factor<br><br>
band, i.e. for each encoder frequency partition.<br>
Preferably, both channels are combined to form a combined<br>
or "carrier" channel and, in addition to the combined<br>
channel, the intensity stereo information. The intensity<br>
stereo information depends on the energy of the first<br>
channel, the energy of the second channel or the energy of<br>
the combined channel.<br>
The BCC technique is described in the AES Convention Paper<br>
5574 entitled "Binaural Cue Coding applied to stereo and<br>
multichannel audio compression" by T. Faller, F. Baumgarte,<br>
May 2002, Munich. In BCC encoding, a number of audio input<br>
channels are converted to a spectral representation using a<br>
DFT-b'ased transform with overlapping windows. The resulting<br>
spectrum is divided into non-overlapping portions, of which<br>
each has an index. Each partition has a bandwidth which is<br>
proportional to the equivalent right-angled bandwidth<br>
(ERB) . The inter-channel level differences (ICLD) and the<br>
inter-channel, time differences (ICTD) are determined for<br>
each partition and for each frame k. The ICLD and ICTD are<br>
quantized and encoded to finally reach a BCC bitstream as<br>
side information. The inter-channel level differences and<br>
the inter-channel time differences are given for each<br>
channel with regard to a ■ reference channel. Then, the<br>
parameters are calculated according to predetermined<br>
formulae depending on the particular partitions of the<br>
signal to be processed.<br>
On the decoder side, the decoder typically receives a mono-<br>
signal and the BCC bitstream. The mono-signal is<br>
transformed to the frequency domain and input into a<br>
spatial synthesis block which also receives decoded ICLD<br>
and ICTD values. In the spatial synthesis block, the BCC<br>
parameters (ICLD and ICTD) are used to perform a weighting<br>
operation of the mono-signal, to synthesize the multi-<br>
channel signals which, after a frequency/time conversion,<br>
represent a reconstruction of the original multi-channel<br>
audio signal.<br><br>
In the case of BCC, the joint stereo module 60 is operative to output the channel-side<br>
information such that the parametric channel data are quantized and encoded ICLD or<br>
ICTD parameters, wherein one of the original channels is used as a reference channel<br>
for encoding the channel-side information.<br>
Normally, the carrier signal is formed of the sum of the participating original channels.<br>
The above techniques of course only provide a mono-representation for a decoder which<br>
can only process the carrier channel, but which is not able to process parametric data<br>
for generating one or several approximations of more than one input channel.<br>
The BCC technique is also described in the US patent publication US 2003/0219130 Al<br>
(Applicant- BAUMGARTE FRANK,; FALLER CHRISTOF,; AGERE SYSTEMS INC, Filing<br>
Date: May 24, 2002, Publication Date: November 27, 2003, Country name: United<br>
States), US 2003/0026441 Al (Applicant- FALLER CHRISTOF,; AGERE SYSTEMS INC,<br>
Filing Date: May 4, 2001, Publication Date: February 6, 2003, Country name: United<br>
States) and US 2003/0035553 Al (Applicant- BAUMGARTE FRANK,; CHEN JIASHU,;<br>
FALLER CHRISTOF, Filing Date: November 7, 2001, Publication Date: February 20, 2003,<br>
Country name: United States). Additionally, reference is made to the expert publication<br>
"Binaural Cue Coding. Part II: Schemes and Applications" by T. Faller and F. Baumgarte,<br>
IEEE Trans. On Audio and Speech Proc, Vol. 11, No. 6, November 2003.<br>
Subsequently, a typical BCC scheme for multi-channel audio encoding will be illustrated<br>
in greater detail referring to Figs. 4 and 6.<br>
Fig. 5 shows such a BCC scheme for encoding/transmitting multi-channel audio signals.<br>
The multi-channel audio input signal at an input 110 of a BCC encoder 112 is mixed<br>
down in a so-called downmix block 114. With this example, the original multi-channel<br>
signal at the input 110 is a 5-channel surround signal having a front-left channel, a<br>
front-right channel, a left surround channel, a right surround channel and a center<br>
channel. In the preferred embodiment of the present invention, the downmix block 114<br><br>
generates a sum signal by means of a simple addition of<br>
these five channels into one mono-signal.<br>
Other downmix schemes are known in the art, so that using a<br>
multi-channel input signal, a downmix channel having a<br>
single channel is obtained.<br>
This single channel is output on a sum signal line 115.<br>
Side information obtained from the BCC analysis block 116<br>
is output on a side-information line 117.<br>
Inter-channel level differences (ICLD) and inter-channel<br>
time differences (ICTD) are calculated in the BCC analysis<br>
block, as has been illustrated above. Now, the BCC analysis<br>
block 116 is also able to calculate inter-channel<br>
correlation values (ICC values) . The sum signal and the<br>
side information are transmitted to a BCC decoder 120 in a<br>
quantized and encoded format. The BCC decoder splits the<br>
transmitted sum signal into a number of subbands and<br>
performs scalings, delays and further processing steps to<br>
provide the subbands of the multi-channel audio channels to<br>
be output. This processing is performed such that the ICLD,<br>
ICTD and ICC parameters (cues) of a reconstructed multi-<br>
channel signal at the output 121 match the corresponding<br>
cues for the original multi-channel signal at the input 110<br>
in the BCC encoder 112. For this purpose, the BCC decoder<br>
120 includes a BCC synthesis block 122 and a side<br>
information-processing block 123.<br>
Subsequently, the internal setup of the BCC synthesis block<br>
122 will be illustrated referring to Fig. 6. The sum signal<br>
on the line 115 .is supplied to a time/frequency conversion<br>
unit or filter bank FB 125. At the output of block 125,<br>
there is a number N of subband signals or, in an extreme<br>
case, a block of spectral coefficients when the audio<br>
filter bank 125 performs a 1:1 transformation, i.e. a<br>
transformation generating N spectral coefficients from N<br>
time domain samples.<br><br>
The BCC synthesis block 122 further includes a delay stage<br>
126, a level modification stage 127, a correlation<br>
processing stage 128 and an inverse filter bank stage IFB<br>
129. At the output of stage 129, the reconstructed multi-<br>
channel audio signal having, for example, five channels in<br>
the case of a 5-channel surround system, may be output to a<br>
set of loudspeakers 124, as are illustrated in Fig. 5 or<br>
Fig. 4.<br>
The input signal sn is converted to the frequency domain or<br>
the filter bank domain by means of the element 125. The<br>
signal output by the element 125 is copied such that<br>
several versions of the same signal are obtained, as is<br>
illustrated by the copy node 130. The number of versions of<br>
the original signal equals the number of output channels in<br>
the output signal. Then, each version of the original<br>
signal at the node 130 is subjected to a certain delay di,<br>
d2, ..., di, ..., dN. The delay parameters are calculated by<br>
the side information-processing block 123 in Fig. 5 and<br>
derived from the inter-channel time differences as they<br>
were calculated by the BCC analysis block 116 of Fig. 5.<br>
The same applies to the multiplication parameters ai, a2,<br>
..., ai, ..., aN, which are also calculated by the side<br>
information-processing block 123 based on the inter-channel<br>
level differences as they were calculated by the BCC<br>
analysis block 116.<br>
The ICC parameters calculated by the BCC analysis block 116<br>
are used for controlling the functionality of block 128 so<br>
that certain correlations between the delayed and level-<br>
manipulated signals are obtained at the outputs of block<br>
128. It is to be noted here that the order of the stages<br>
126, 127, 128 may differ from the order shown in Fig. 6.<br>
It is also to be noted that in a frame-wise processing of<br>
the audio signal, the BCC analysis is also performed frame-<br><br>
wise, i.e. temporally variable, and that further a<br>
frequency-wise BCC analysis is obtained, as can be seen by<br>
the filter bank division of Fig. 6. This means that the BCC<br>
parameters are obtained for each spectral band. This also<br>
means that in the case that the audio filter bank 125<br>
breaks down the input signal into, for example, 32 band-<br>
pass signals, the BCC analysis block obtains a set of BCC<br>
parameters for each of the 32 bands. Of course, the BCC<br>
synthesis block 122 of Fig. 5, which is illustrated in<br>
greater detail in Fig. 6, also performs a reconstruction<br>
which is also based on the exemplarily mentioned 32 bands.<br>
Subsequently, a scenario used for determining individual<br>
BCC parameters will be illustrated referring to Fig. 4.<br>
Normally, the ICLD, ICTD and ICC parameters may be defined<br>
between channel pairs. It is, however, preferred that the<br>
ICLD and ICTD parameters are determined between a reference<br>
channel and each other channel. This is illustrated in Fig.<br>
4A.<br>
ICC parameters may be defined in different manners. In<br>
general, ICC parameters may be determined in the encoder<br>
between all possible channel pairs, as is illustrated in<br>
Fig. 4B. There has been the suggestion to calculate only<br>
ICC parameters between the two strongest channels at any<br>
time, as is illustrated in Fig. 4C, which shows an example<br>
in which, at any time, an ICC parameter between the<br>
channels 1 and 2 is calculated and, at another time, an ICC<br>
parameter between the channels 1 and 5 is calculated. The<br>
decoder then synthesizes the inter-channel correlation<br>
between the strongest channels in the decoder and uses<br>
certain heuristic rules for calculating and synthesizing<br>
the inter-channel coherence for the remaining channel<br>
pairs.<br>
With respect to the calculation of, for example, the<br>
multiplication parameters ai, aN based on the transmitted<br>
ICLD parameters, reference is made to the AES Convention<br><br>
Paper No. 5574. The ICLD parameters represent an energy<br>
distribution of an original multi-channel signal. Without<br>
loss of generality, it is preferred, as is shown in Fig.<br>
4A, to take 4 ICLD parameters representing the energy<br>
difference between the respective channels and the front-<br>
left channel. In the side information-processing block 122,<br>
the multiplication parameters ai, ..., aN are derived from<br>
the ICLD parameters so that the total energy of all<br>
reconstructed output channels is the same (or proportional<br>
to the energy of the sum signal transmitted).<br>
In the embodiment shown in Fig. 7, the frequency/time<br>
conversion obtained by the inverse filter banks IFB 129 of<br>
Fig. 6 is dispensed with. Instead, the spectral<br>
representations of the individual channels at the input of<br>
these inverse filter banks are used and supplied to the<br>
headphone signal-processing device of Fig. 7 to perform the<br>
evaluation of the individual multi-channels with the<br>
respective two filters per multi-channel without an<br>
additional frequency/time transformation.<br>
With regard to a complete processing taking place in the<br>
frequency domain, it is to be noted that in this case the<br>
multi-channel decoder, i.e., for example, the filter bank<br>
125 of Fig. 6, and the stereo encoder should have the same<br>
time/frequency resolution. Additionally, it is preferred to<br>
use one and the same filter bank, which is particularly of<br>
advantage in that only a single filter bank is required for<br>
the entire processing, as is illustrated in Fig. 1. In this<br>
case, the result is a particularly efficient processing<br>
since the transformations in the multi-channel decoder and<br>
the stereo encoder need not be calculated.<br>
The input data and output data, respectively, in the<br>
inventive concept are thus preferably encoded in the<br>
frequency domain by means of transformation/filter bank and<br>
are encoded under psycho-acoustic guidelines using masking<br>
effects, wherein in particular in the decoder there should<br><br>
be a spectral representation of the signals. Examples of<br>
this are MP3 files, AAC files or AC3 files. However, the<br>
input data and output data, respectively, may also be<br>
encoded by forming the sum and difference, as is the case<br>
in so-called matrixed processes. Examples of this are Dolby<br>
ProLogic, Logic7 or Circle Surround. The data of, in<br>
particular, the multi-channel representation may<br>
additionally be encoded by means of parametric methods, as<br>
is the case in MP3 surround, wherein this method is based<br>
on the BCC technique.<br>
Depending on the circumstances, the inventive method for<br>
generating may be implemented in either hardware or<br>
software. The implementation may be on a digital storage<br>
medium, in particular on a disc or CD having control<br>
signals which can be read out electronically, which can<br>
cooperate with a programmable computer system such that the<br>
method will be executed. In general, the invention also is<br>
in a computer program product having a program encode<br>
stored on a machine-readable carrier for performing an<br>
inventive method when the computer program product runs on<br>
a computer. Put differently, the invention may also be<br>
realized as a computer program having a program encode for<br>
performing the method when the computer program runs on a<br>
computer.<br><br>
We Claim:<br>
1. A device for generating an encoded stereo signal of an audio piece or an audio<br>
datastream having a first stereo channel and a second stereo channel from a<br>
multi-channel representation of the audio piece or the audio datastream<br>
comprising information on more than two multi-channels, comprising:<br>
means (11) for providing the more than two multi-channels from the multi-<br>
channel representation;<br>
means (12) for performing headphone signal processing to' generate an uncoded<br>
stereo signal with an uncoded first stereo channel (10a) and an uncoded second<br>
stereo channel (10b), the means (12) for performing being formed<br>
to evaluate each multi-channel by a first filter function (HiL) derived from<br>
a virtual position of a loudspeaker for reproducing the multi-channel and<br>
a virtual first ear position of a listener, for the first stereo channel, and a<br>
second filter function (HiR) derived from a virtual position of the<br>
loudspeaker and a virtual second ear position of the listener, for the<br>
second stereo channel, to generate a first evaluated channel and a<br>
second evaluated channel for each multi-channei, the two virtual ear<br>
positions of the listener being different,<br>
to add (22) the evaluated first channels to obtain the uncoded first stereo<br>
channel (10a), and<br><br>
to add (23) the evaluated second channels to obtain the uncoded second<br>
channels to obtain the uncoded second stereo channel (10b); and<br>
a stereo encoder (13) for encoding the uncoded first stereo channel (10a) and<br>
the uncoded second stereo channel (10b) to obtain the encoded stereo signal<br>
(14), the stereo encoder being formed such that a data rate required for<br>
transmitting the encoded stereo signal is smaller than a data rate required for<br>
transmitting the uncoded stereo signal.<br>
2.	The device as claimed in claim 1, wherein the means (12) for performing is<br>
formed to use the first filter function (HiL) considering direct sound, reflections<br>
and diffuse reverberation the second filter function (HiR) considering direct<br>
sound, reflections and diffuse reverberation.<br>
3.	The device as claimed in claim 2, wherein the first and the second filter functions<br>
correspond to a filter impulse response comprising a peak at a small time value<br>
representing the direct sound, several smaller peaks at medium time values<br>
representing the reflections, and a continuous region no longer resolved for<br>
individual peaks and representing the diffuse reverberation.<br>
4.	The device as claimed in one of the preceding claims,<br>
wherein the multi-channel representation comprises one or several basic<br>
channels as well as parametric information for calculating the multi-channels<br>
from one or several basic channels, and<br>
wherein the means (11) for providing is formed to calculate the at least three<br>
multi-channels from the one or the several basic channels and the parametric<br>
information.<br><br>
5.	The device as claimed in claim 4,<br>
wherein the means (11) for providing is formed to provide, on the output side, a<br>
block-wise frequency domain representation for each multi-channel, and<br>
wherein the means (12) for performing is formed to evaluate the block-wise<br>
frequency domain representation by a frequency domain representation of the<br>
first and second filter functions.<br>
6.	The device as claimed in one of the preceding claims,<br>
wherein the means (12) for performing is formed to provide a block-wise<br>
frequency domain representation of the uncoded first stereo channel and the<br>
uncoded second stereo channel, and<br>
wherein the stereo encoder (13) is a transformation-based encoder and is also<br>
formed to process the block-wise frequency domain representation of the<br>
uncoded first stereo channel and the uncoded second stereo channel without a<br>
conversion from the frequency domain representation to a temporal<br>
representation.<br>
7.	The device as claimed in one of the preceding claims,<br>
wherein the stereo encoder (13) is formed to perform a common stereo<br>
encoding (15) of the first and second stereo channels.<br>
8.	The device as claimed in one of the preceding claims,<br>
wherein the stereo encoder (13) is formed to quantize (16) a block of spectral<br>
values using a psycho-acoustic masking threshold and subject it to entropy<br>
encoding (17) to obtain the encoded stereo signal.<br><br>
9.	The device as claimed in one of the preceding claims,<br>
wherein the means (11) for providing is formed as BCC decoder.<br>
10.	The device as claimed in one of the preceding claims,<br>
wherein the means (11) for providing is formed as a multi-channel decoder<br>
comprising a filter bank having several outputs,<br>
wherein the means (12) for performing is formed to evaluate signals at the filter<br>
bank outputs by the first and second filter functions, and<br>
wherein the stereo encoder (13) is formed to quantize (16) the uncoded first<br>
stereo channel in the frequency domain and the uncoded second stereo channel<br>
in the frequency domain and subject it to entropy encoding (17) to obtain the<br>
encoded stereo signal.<br>
11.	A method for generating an encoded stereo signal of an audio piece or an audio<br>
datastream having a first stereo channel and a second stereo channel from a<br>
multi-channel representation of the audio piece or the audio datastream<br>
comprising information on more than two multi-channels, comprising the steps<br>
of:<br>
providing (11) the more than two multi-channels from the multi-channel<br>
representation;<br>
performing (12) headphone signal processing to generate an uncoded stereo<br>
signal with an uncoded first stereo channel (10a) and an uncoded second stereo<br>
channel (10b), the step of performing (12) comprising:<br><br><br>
evaluating each multi-channel by a first filter function (HiL) derived from a<br>
virtual position of a loudspeaker for reproducing the multi-channel and a<br>
virtual first ear position of a listener, for the first stereo channel, and a<br>
second filter function (HiR) derived from a virtual position of the<br>
loudspeaker and a virtual second ear position of the listener, for the<br>
second stereo channel, to generate a first evaluated channel and a<br>
second evaluated channel for each multi-channel, the two virtual ear<br>
positions of the listener being different,<br>
adding (22) the evaluated first channels to obtain the uncoded first stereo<br>
channel (10a), and<br>
adding (23) the evaluated second channels to obtain the uncoded second<br>
stereo channel (10b); and<br>
stereo-coding (13) the uncoded first stereo channel (10a) and the uncoded<br>
second stereo channel (10b) to obtain the encoded stereo signal (14), the step<br>
of stereo-coding being executed such that a data rate required for transmitting<br>
the encoded stereo signal is smaller than a data rate required for transmitting<br>
the uncoded stereo signal.<br><br><br><br>
Abstract<br><br><br>
Device and method for generating an encoded stereo signal of an audio piece<br>
or audio datastream<br>
A device for generating an encoded stereo signal from a multi-channel representation<br>
includes a multi-channel decoder (11) generating three of more multi-channels from at<br>
least one basic channel and parametric information. The three or more multi-channels<br>
are subjected to headphone signal processing (12) to generate an uncoded first stereo<br>
channel (10a) and an uncoded second stereo channel (10b) which are then supplied to a<br>
stereo encoder (13) to generate an encoded stereo file (14) on the output side. The<br>
encoded stereo file may be supplied to any suitable player in the form of a CD player or<br>
a hardware player such that a user of the player does not only get a normal stereo<br>
impression but a multi-channel impression.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-correspondence others 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMgMS4yLnBkZg==" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-correspondence others 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1jb3JyZXNwb25kZW5jZSBvdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1mb3JtIDIucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1ncGEucGRm" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDMwNTIta29sbnAtMjAwNy1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">03052-kolnp-2007-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1BTUFOREVEIENMQUlNUy5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-AMANDED CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1FWEFNSU5BVElPTiBSRVBPUlQgUkVQTFkgUkVDRUlWRUQucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-EXAMINATION REPORT REPLY RECEIVED.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1GT1JNLTMucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-FORM-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1GT1JNLTUucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-FORM-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxMC0wNS0yMDEyKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(10-05-2012)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LSgxOS0wMy0yMDEzKS1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-(19-03-2013)-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNBTkNFTExFRCBQQUdFUy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CANCELLED PAGES-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNBTkNFTExFRCBQQUdFUy5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CANCELLED PAGES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFIE9USEVSUyAxLjMucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CORRESPONDENCE OTHERS 1.3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFIE9USEVSUyAxLjQucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CORRESPONDENCE OTHERS 1.4.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFIE9USEVSUyAxLjUucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CORRESPONDENCE OTHERS 1.5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFIE9USEVSUyAxLjYucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CORRESPONDENCE OTHERS 1.6.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFLTEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CORRESPONDENCE-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUVYQU1JTkFUSU9OIFJFUE9SVC0xLjEucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-EXAMINATION REPORT-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUZPUk0gMTgtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-FORM 18-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUZPUk0gMTgucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-FORM 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUZPUk0gMjYtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-FORM 26-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUZPUk0gMjYucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-FORM 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtRk9STSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUdSQU5URUQtU1BFQ0lGSUNBVElPTi1DT01QTEVURS5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-GRANTED-SPECIFICATION-COMPLETE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgUFJFTElNSU5BUlkgUkVQT1JULnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-INTERNATIONAL PRELIMINARY REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-INTERNATIONAL SEARCH REPORT &amp; OTHERS-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-INTERNATIONAL SEARCH REPORT &amp; OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LU9USEVSUy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-OTHERS-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LVBBLnBkZg==" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzA1Mi1LT0xOUC0yMDA3LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVDEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">3052-KOLNP-2007-REPLY TO EXAMINATION REPORT1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMDMwNTIta29sbnAtMjAwNy5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-03052-kolnp-2007.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="255800-spinning-machine-with-frequency-converters.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="255802-system-for-planning-and-tracking-certification.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>255801</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3052/KOLNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>13/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>29-Mar-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>23-Mar-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>20-Aug-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C 80686 MUNCHEN</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JAN PLOGSTIES</td>
											<td>PESTALOZZISTR. 44 91052 ERLANGEN</td>
										</tr>
										<tr>
											<td>2</td>
											<td>HARALD POPP</td>
											<td>OBERMICHELBACHER STR. 18 90587 TUCHENBACH</td>
										</tr>
										<tr>
											<td>3</td>
											<td>HARALD MUNDT</td>
											<td>ESCHENWEG 34 91058 ERLANGEN</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04S 3/00,G10L 19/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2006/001622</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-02-22</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10 2005 010 057.0</td>
									<td>2005-03-04</td>
								    <td>Germany</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/255801-device-and-method-for-generating-an-encoded-stereo-signal-of-an-audio-piece-or-audio-datastream by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:15:08 GMT -->
</html>
