<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/216349-system-and-method-for-memory-management-of-data-consistency-and-associated-multiprocessor-network by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:33:16 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 216349:SYSTEM AND METHOD FOR MEMORY MANAGEMENT OF DATA CONSISTENCY AND ASSOCIATED MULTIPROCESSOR NETWORK.</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">SYSTEM AND METHOD FOR MEMORY MANAGEMENT OF DATA CONSISTENCY AND ASSOCIATED MULTIPROCESSOR NETWORK.</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to a system and a method of memory management of data consistency relating to a main memory (4) accessible by at least two processors (1, 2), as well as an associated multiprocessor network. The management system comprises an assembly for management of shared access of the processors to a common area (9) of the main memory, referred to as the exchanges area, at least one copy module (12, 13) intended for performing a data copy between at least one first processor comprising at least one cache memory and the exchanges area and at least one transfer module (12, 13) intended for performing a transfer of data between the exchanges area and at least one second processor. Triggering means controlled by the second processors trigger the copy modules and transfer modules when the first processors submit requests involving transfers of data between the first and second processors.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>The present invention relates to a data consistency<br>
memory management system and method, as well as to a<br>
corresponding multiprocessor network.<br>
Fast processors clocked at speeds of more than 100 MHz<br>
generally use cache memories, also referred to simply<br>
as caches, to be able to operate efficiently. Such a<br>
cache duplicates some of the data present in main<br>
memory (such as a synchronous access memory or SDRAM),<br>
over to a memory offering a much faster access time<br>
than the latter. In a conventional system, the cache is<br>
limited in size for reasons of cost and bulk, and only<br>
a small part of the main memory lies in the cache at a<br>
given time. In improved systems, several levels of<br>
caches are cascaded, each level being specified by the<br>
time to access a data item and by its storage capacity.<br>
Customarily, the first cache level allows access to<br>
data at the speed of the processor.<br>
A difficulty appears in a so-called multimaster<br>
environment, where several processors use the same main<br>
memory. Specifically, data consistency must then be<br>
ensured between the main memory and the cache or "the<br>
caches, both in read and write mode, with no risk of<br>
overwriting information.<br>
This is especially salient in a so-called "write-back"<br>
cache mode. In such a mode, writes are performed by the<br>
associated processor directly to the cache and are<br>
carried over into main memory only during operations<br>
for updating the data of the cache (dumping or flush),<br>
whereas in a so-called "write-through" cache mode,<br>
writes are on the contrary carried over in real time<br>
from the cache to the main memory. The write-back mode<br>
is distinguished by its efficiency, since it requires a<br>
smaller frequency of transfers between the cache and<br>
the main memory. However, the consistency of the data<br>
between the cache and the main memory is not ensured at<br>
all times. The reading of data from the main memory by<br>
a processor other than that associated with the cache<br>
currently being used therefore poses a problem.<br>
Another problem, existing in both write-back and write-<br>
through modes, relates to the writing of data in main<br>
memory by a processor, when a cache is currently being<br>
used by another processor. When transferring<br>
information from the cache to the main memory, the data<br>
registered in the latter memory is in fact at risk of<br>
being overwritten.<br>
Several solutions are currently used to remedy these<br>
difficulties, relying on hardware or software means.<br>
They guarantee that at any instant, memory data belongs<br>
to just one of the masters. The hardware means<br>
guaranteeing the consistency of data (such as the so-<br>
called "snoop" technique) customarily implement complex<br>
solutions, in which any master accessing a data item in<br>
main memory must be sure that a subassembly furnished<br>
with a cache does not possess the data item before<br>
manipulating it. If such is the case, the data item is<br>
made available to the main memory or to the master by a<br>
memory write mechanism. In addition to their complexity<br>
and cost of installation, these systems require that<br>
passbands be allocated to the processors. They penalize<br>
the processing times through holdups.<br>
The software means guaranteeing the consistency of data<br>
customarily compel segmented management of the data,<br>
that is to say management organized in such a way that<br>
each master is furnished with one or more dedicated<br>
memory spaces and with a shareable memory area. The<br>
memory spaces dedicated to a master can be accessed<br>
only by the caches associated with this master, the<br>
data not being shared therein with other masters,<br>
whilst the shareable memory area cannot be accessed by<br>
the caches and serves as data exchange area. Another<br>
software means of ensurinq the consistency of data<br>
implements specific processor instructions for managing<br>
caches, capable of manipulating cache data blocks so as<br>
to ensure the cbnsistency of this data between caches<br>
and main memory. This means also compels data<br>
management organized so as to take account of the size<br>
of the data blocks manipulated by these instructions,<br>
in such a way as to preclude different masters from<br>
accessinq the same data blocks through write operations<br>
(risk of overwriting).<br>
In all cases these software techniques require precise<br>
synchronization and an initial overall design<br>
incorporating constraints related to the multiprocessor<br>
operation of the system. Moreover, they require that<br>
there be made available in each of the processors,<br>
management programming adapted to the exchanges of data<br>
between caches and the main memory within all the<br>
processors.<br>
The present invention relates to a system for memory<br>
management of data consistency relating to a main<br>
memory accessible by at least two processors, making it<br>
possible to ensure consistency between caches of one or<br>
more processors and the main memory. The memory<br>
management system of the invention can ensure this<br>
consistency in read and/or write mode in the main<br>
memory, and permits reliable, economic and easy<br>
installation and implementation, in regard to the<br>
existing methods. In particular, it offers these<br>
advantages when the multiprocessor operation results<br>
from an upgrade of a monoprocessor system. Moreover, it<br>
can yield high processing speeds, as compared with the<br>
known hardware means.<br>
The invention also pertains to a multiprocessor network<br>
incorporating a memory management system according to<br>
the invention and to a data consistency memory<br>
management method, having the advantages cited above.<br>
It applies in particular to the audiovisual field,<br>
especially for digital decoders.<br>
To this end, the subject of the invention is a system<br>
for memory management of data consistency relating to a<br>
main memory accessible by at least two processors. At<br>
least one of these processors is furnished with one or<br>
more cache memories associated with at least one area<br>
of the main memory, referred to as the assignment area<br>
of this processor. The management system comprises:<br>
an assembly for management of access of the<br>
processors to at least one common area of the main<br>
memory, referred to as the exchanges area,<br>
one or more copy modules respectively associated<br>
with one or more of the processors furnished with<br>
 at least one_cache memory, hereinafter designated<br>
 as first processors; each of these copy modules is<br>
capable of performing a data copy between a memory<br>
 workspace consisting of one of the cache memories<br>
 and/or the assignment area of the associated first<br>
processor, on the one hand, and the exchanges<br>
area, on the other hand,<br>
and one or more data transfer modules, associated<br><br>
 respectively with one or more Second processors<br>
 capable of exchanging data with the first<br>
 processors; each of these transfer modules is<br>
intended for transferring data between the<br>
exchanges area and the associated second<br>
processor.<br>
According to the invention, the consistency management<br>
system also comprises triggering means controlled by<br>
the second processors, capable of triggering the copy<br>
modules of the first processors and the transfer<br>
modules of the second processors when the first<br>
processors submit requests involving transfers of data<br>
between the memory workspaces of the first processors<br>
and the second processors.<br>
The expressions "copy module" and "transfer module" are<br>
not intended to be understood as specified" physical<br>
objects, but as functional entities which may for<br>
example be grouped together and integrated physically<br>
into one or more hardware supports/ or on the contrary<br>
each dispersed in several supports.<br>
The expression "data" may be understood equally well,<br>
in particular, as references to data in memory and as<br>
command identifiers.<br>
The memory workspace used by the copy module is that<br>
active during the reading or writing of data. Thus,<br>
when the data exchanged with a first processor is<br>
Present in cache, it is the latter which serves as<br>
point of departure in read mode and as point of arrival<br>
in write mode. When conversely the targeted data is in<br>
a memory space of the assignment area which is not<br>
utilized in cache, the data is read or written directly<br>
from or to this assignment area of the main memory. In<br>
all cases the first processor is itself capable of<br>
extracting or of placing the data required, according<br>
to procedures internal to its cache management<br>
operation. In this way, operations for copying to or<br>
from the exchanges area pose no difficulty and enable -<br>
the transfers with a second processor be carried over<br>
to the exchanges area.<br>
The processors with cache memories are therefore<br>
furnished with a cache or with several caches in<br>
cascade, the latter embodiment posing no particular<br>
difficulty.<br>
One or more of the processors fitted with cache<br>
memories may benefit from the consistency management<br>
characteristics of the invention. Preferably, the<br>
consistency memory management system assigns these<br>
characteristics to all the processors with cache<br>
memories. In variant embodiments, only some of these<br>
processors benefit therefrom/ the others using as<br>
necessary other means for managing consistency. The<br>
processors with cache memories furnished with the<br>
consistency management capabilities of the invention<br>
may therefore sometimes play the role of "first<br>
processors" and sometimes that of "second processors".<br>
Thus, the memory management system of the invention<br>
relies on systematic passing through the exchanges area<br>
of all the information to be exchanged (in read mode<br>
and/or in write mode) between a first processor<br>
furnished with cache management and a second processor,<br>
with or without a cache, which passing is controlled by<br>
the second processor.<br>
By contrast, in the known techniques with hardware<br>
means, the information is read or written directly by<br>
the second processor from or to the assignment area of<br>
the first processor in main memory, after the<br>
assignment area and the cache (or caches) are made<br>
consistent. This update prior to any exchange has<br>
drawbacks mentioned above. Additionally, in the known<br>
techniques with software means, the information to be<br>
shared must previously be allocated in an exchanges<br>
area of the main memory, or rely on successive changes<br>
of assignment of areas of the main memory. In all<br>
cases, overall coordination is required and the<br>
individual management of each of the processors with<br>
cache memory must be adapted accordingly. Specifically,<br>
each transfer of data between one of the processors and<br>
the exchanges area is initiated by this processor, so<br>
that a transfer between two processors necessarily<br>
involves the respective means of management of these<br>
processors.<br>
It turns out that these drawbacks are overcome by the<br>
memory management system of the invention. In<br>
particular, by virtue of the carrying over of the<br>
transfers to the exchanges area, the memory management<br>
system circumvents the difficulties related to the<br>
internal management of each processor provided with<br>
cache memories. Moreover, the difficulties of design<br>
and of synchronization of the prior art with software<br>
means are overcome, since a data transfer between two<br>
processors is controlled entirely by one of the two<br>
 processors, on the basis of a request formulated<br>
initially by the other processor.<br>
The system of the invention turns out to be<br>
particularly beneficial when it is applied to a first<br>
processor designed originally to operate in<br>
monoprocessor mode with cache memories. It would in<br>
fact be complex to adapt the programming in this<br>
processor and this would incur substantial risks of<br>
errors. The invention makes it possible to couple this<br>
first processor to a second processor (or more), merely<br>
by supplementing this first processor with a<br>
programming layer for copying data between its memory<br>
workspace and the exchanges area. The control of all<br>
the transfer operations is in fact carried over to the<br>
second processor, for which specific memory management<br>
software is developed.<br>
The copying and transfer which are mentioned target:<br>
 either a copying of a cache or of an assignment<br>
area of one of the first processors to the<br>
exchanges memory, and a transfer from the<br>
exchanges memory to one of the second processors;<br>
the capabilities of the copy modules and transfer<br>
modules and of the triggering means then<br>
correspond to a reading by the second processor,<br>
of data accessible by the first processor; this<br>
characteristic makes it possible to ensure in<br>
write-back mode read-consistency of data processed<br>
by the first processor (this memory consistency is<br>
ensured automatically in write-through mode);<br>
or a transfer from one of the second processors to<br>
the exchanges memory and a copy from the exchanges<br>
memory to a cache or an assignment area of one of<br>
the first processors; the capabilities of the copy<br>
modules and transfer modules and of the triggering<br>
means then correspond to a writing by the second<br>
processor, of data accessible by the first<br>
processor; this characteristic makes it possible<br>
to ensure, in both write-back mode and write-<br>
through mode, write-consistency of data which is<br>
to be processed by the first processor;<br>
or both (consistency capability in both<br>
directions).<br>
The triggering means advantageously comprise<br>
instruction reading means installed in the various<br>
processors in software form, capable of reading and of<br>
interpreting requests transmitted by other processors,<br>
preferably in the exchanges area.<br>
In a first advantageous form of memory allocation, the<br>
second processors are fitted with memory space<br>
allocation modules, capable of allocating common spaces<br>
in the exchanges area. The triggering means are then<br>
capable of triggering the memory space allocation<br>
modules when the first processors submit requests<br>
involving transfers of data between the memory<br>
workspaces of the first processors and the second<br>
processors, by bringing about the allocation of the<br>
common spaces necessary for this data. The memory<br>
management system can thus restrict accesses of the<br>
first processors to the exchanges memory, permitting<br>
only copy accesses (in read mode and/or in write mode).<br>
In a second form of memory allocation, the first<br>
processors are fitted with memory space allocation<br>
modules, capable of allocating common spaces in the<br>
exchanges area. The triggering means (controlled by the<br>
second processors) are then capable of triggering these<br>
memory space allocation modules under the same<br>
circumstances as before. Thus, the first processors<br>
retain mastery of the allocations of space in the<br>
exchanges memory when these allocations are concerned<br>
with their memory workspaces, but under the supervision<br>
of the second processors.<br>
Preferably, the triggering means comprise at least one<br>
interrupt device between the first processors and<br>
second processors capable of exchanging data, said<br>
device being intended to signal an exchange of data<br>
between these processors and to bring about a temporary<br>
interruption of processing operations in progress in<br>
these processors. Such an interrupt device linking one<br>
of the first and one of the second processors<br>
advantageously has the effect of bringing about a<br>
reading of the exchanges area by the second processor,<br>
after the first processor has registered therein a<br>
request executable by the second processor, and vice<br>
versa. This request may pertain in particular to a<br>
processing operation using data, an allocation of<br>
memory space in the exchanges memory, a data copy to or<br>
from this exchanges memory by the first processor,<br>
and/or a transfer operation between the exchanges<br>
memory and the second processor.<br>
The interrupt devices advantageously comprise hardware<br>
mechanisms.<br>
According to a first preferred embodiment of the copy<br>
and transfer modules (reading of data accessible by a<br>
processor with cache memory) , the copy module of at<br>
least one of the first processors is designed to<br>
perform a data copy from the exchanges area to the<br>
memory workspace of the first processor and the<br>
transfer modules of the second processors capable of<br>
exchanging data with the first processor are designed<br>
to transfer data from the second processors to the<br>
exchanges area.<br>
According to a second preferred embodiment of the copy<br>
and transfer modules (writing of data rendered<br>
accessible by a processor with cache memory), the copy<br>
module of at least one of the first processors is<br>
designed to perform a data copy from the memory<br>
workspace of the first processor to the exchanges area<br>
and the transfer modules of the second processors<br>
capable of exchanging data with the first processor are<br>
designed to transfer data from the exchanges area to<br>
the second processors.<br>
Advantageously, the two embodiments are combined. More<br>
precisely/ the capabilities of the first embodiment<br>
(reading) are preferably installed for all the<br>
processors having write-back cache memory management,<br>
and those of the second embodiment (writing), for all<br>
the processors with cache memory (in write-through and<br>
write-back mode). However, the consistency memory<br>
management system advantageously applies both in read<br>
and write mode to all the processors with cache memory,<br>
since its systematic installation makes it possible to<br>
use the same software functions in all these processors<br>
at the cost of minimal adaptations. In variant<br>
embodiments/ the first embodiment (reading) is<br>
implemented without the second. The write-consistency<br>
capabilities are then ensured by other means, such as<br>
for example a cache memory management module capable of<br>
automatically reupdating as necessary the cache memory<br>
used with respect to the exchanges memory, when writing<br>
to the latter.<br>
In a first embodiment of the management of shared<br>
access, the assignment areas of the processors with<br>
cache memories being outside the exchanges area, the<br>
assembly for management of shared access to the<br>
exchanges area is designed for a non-hidden area.<br>
In a second embodiment of the management of shared<br>
access, at least one of the assignment areas of the<br>
processors with cache memories containing the exchanges<br>
area, the assembly for management of shared access to<br>
the exchanges area comprises a hardware device capable<br>
of ensuring the consistency of the said exchange area.<br>
The exchange area is thus hidden but consistent.<br>
The invention also applies to a multiprocessor network<br>
comprising a main memory and at least two processors,<br>
at least one of the processors being furnished with a<br>
cache memory associated with at least one area of the<br>
main memory, referred to as the assignment area of the<br>
processor.<br>
This multiprocessor network is characterized in that it<br>
comprises a data management system in accordance with<br>
the invention.<br>
The invention also relates to a method for memory<br>
management of data consistency relating to a main<br>
memory accessible by at least two processors. At least<br>
one of these processors is furnished with one or more<br>
cache memories associated with at least one area of the<br>
main memory, referred to as the assignment area of the<br>
processor. In the method, the shared access of the<br>
processors to at least one common area of the main<br>
memory, referred to as the exchanges area, is managed<br>
in such a way that during a transfer of data from at<br>
least a first of the processors furnished with one or<br>
more cache memories to a second of the processors,<br>
- a copying of this data from a memory workspace<br>
consisting of one of the cache memories and/or the<br>
assignment area of the first processor, to the<br>
exchanges area is triggered, and<br>
- a transfer of this data from the exchanges area to<br>
the second processor is triggered,<br>
and/or during a transfer of data from the second<br>
processor to the first processor:<br>
a transfer of this data from the second processor<br>
to the exchanges area is triggered/ and<br>
a copying of this data from the exchanges area to<br>
the memory workspace of the first processor is<br>
triggered.<br>
According to the invention, when a request involving a<br>
transfer of data from the memory workspace of the first<br>
processor to the second processor is sent by means of<br>
the first processor and/or when a request involving a<br>
transfer of data from the second processor to the<br>
memory workspace of the first processor is sent by<br>
means of the first processor, the copying and the<br>
transfer of the data are triggered by means of the<br>
second processor.<br>
The invention will be better understood and illustrated<br>
by means of the following examples of embodiment and<br>
implementation, wholly non-limiting, with reference to<br>
the appended figures in which:<br>
Figure 1 is a basic diagram of a digital decoder<br>
incorporating a first data consistency memory<br>
management system in accordance with the invention, and<br>
comprising two processors with cache memories sharing<br>
an exchanges area of a main memory;<br>
Figure 2 illustrates a first step of consistency<br>
management by means of the memory management system of<br>
Figure 1, comprising the sending from a first of the<br>
processors to the second processor, of a processing""<br>
request involving a transfer of data from the first<br>
processor to the second;<br>
Figure 3 illustrates a second step of consistency<br>
management, comprising an allocation of memory space in<br>
the exchanges area by the second processor and the<br>
sending of a data copy request/ addressed from the<br>
second processor to the first processor;<br>
Figure 4 illustrates a third step of consistency-<br>
management, comprising a copying of the data by the<br>
first processor to the exchanges area;<br>
Figure 5 illustrates a fourth step of consistency<br>
management, comprising a reading of the data from the<br>
exchanges area by the second processor and the copying<br>
of this data from an assignment area to the second<br>
processor, in the main memory;<br>
- Figure 6 shows a third step of consistency<br>
management by means of the memory management system of<br>
Figure 1, relating to a transfer of data from the<br>
second processor to the first processor; and<br>
Figure 7 is a basic diagram of a second data<br>
consistency memory management system in accordance with<br>
the invention, comprising a processor with cache memory<br>
and two processors without cache memories, sharing an<br>
exchanges area of a main memory.<br>
In Figures 2 to 6, the memories, as well as the memory<br>
spaces or areas, represented have sizes and layouts<br>
intended to ensure the clarity of the examples, but<br>
which are in no way representative of the sizes and<br>
layouts actually used. By convention, a solid arrow<br>
represents a data transfer in read mode (arrow pointing<br>
from a memory to a processor) or in write read mode<br>
 (arrow pointing from a processor to a memory a dashed<br>
 arrow (Figure 2) represents a pointing to data in<br>
memory; and a slender chain-dotted arrow (Figure 3)<br>
schematically represents a memory space allocation.<br>
A digital decoder 3, represented in Figure 1, comprises<br>
two processors 1 and 2. The processors 1 and 2 are<br>
respectively furnished with software 10 and 11 each<br>
comprising a part 12 and 13 relating to data<br>
communication, which allows the exchange of information<br>
between the two processors 1 and 2. Moreover, they are<br>
respectively provided with caches 5 and 6, managed by<br>
dedicated functionalities of the software 10 and 11. In<br>
variant embodiments, the processors 1 and 2 include<br>
specific systems for managing caches. In other variant<br>
embodiments, they are respectively associated with<br>
systems for managing caches which are external thereto.<br>
The caches b and 6 are of the write-back or write-<br>
through type. In the example set forth, caches of the<br>
write-back type will be considered.<br>
The decoder also comprises a main memory 4, shared by<br>
the two processors 1 and 2: the latter access it<br>
respectively via buses 31 and 32 to nonshareable<br>
assignment memory areas 7 and 8, and to a shareable and<br>
consistent memory area 9 for exchanges. The consistency<br>
of data of the exchanges area 9 is ensured through<br>
hardware. In a variant embodiment, this consistency is<br>
ensured through software/ by virtue of the use of<br>
instructions for managing consistency of data of the<br>
caches 5 and 6. In yet another variant embodiment, this<br>
exchanges area is non-hidden.<br>
Moreover, a hardware interrupt mechanism 14 allows the<br>
two processors 1 and 2 to signal a data exchange<br>
relating to a data processing request from one<br>
processor to the other, and to bring about a temporary<br>
interruption of processing operations in progress in<br>
the processor invoked.<br>
The software 10 and 11 comprise functionalities helping<br>
to ensure the consistency of the data with respect to<br>
the main memory 4 and to their caches 5 and 6. In<br>
particular, the parts 12 and 13 include not only<br>
programs for reading and writing from and to the<br>
exchanges area 9, but also programs for copying<br>
specified data into the exchanges area 9, from the<br>
assignment areas 7 and 8 or the caches 5 and 6.<br>
Moreover, the software 10 and 11 are furnished with<br>
functionalities for allocation of memory space in the<br>
exchanges area 9, for recording specified data. The<br>
capabilities of the software 10 and 11 will become more<br>
clearly apparent through the following description of<br>
an operation for transferring data between the two<br>
processors 1 and 2.<br>
In what follows, the expression memory "area" or<br>
"space" designates a collection of addresses in a given<br>
memory, even if this area or this space encompasses<br>
several discontinuous parts.<br>
During operation, in a first step (Figure 2) , the<br>
processor 1 sends a request to the processor 2. To do<br>
this, it registers information in a memory space 17 of<br>
the exchanqes area 9 and it activates the interrupt<br><br>
mechanism 14 (not shown in Fig.2) to forewarn the processor 2. This<br>
information consists of command identifiers 15 and<br>
references 16 to data contained in a memory space 18 of<br>
the assignment area 7 associated with the processor 1.<br>
In a second step (Figure 3) , the processor 2 reads and<br>
interprets the information in the memory space 17,<br>
interprets the request and allocates in the exchanges<br>
area 9 a memory space 20 necessary for the copying by<br>
the processor 1 of the data referenced in this request.<br>
The processor 2 then sends a memory-to-memory copy<br>
 request to the processor 1, by registering information<br>
in a memory space 19 of the exchanges area 9 and by<br>
activating the interrupt mechanism 14.<br>
 In a third step (Figure 4), the processor 1 interprets<br>
the request contained in the memory space 19 and copies<br>
the data identified by the references 16, into the<br>
memory space 20 allocated in the exchanges area 9. It<br>
copies this data either from the memory space 18 of the<br>
assignment area 7, or from the cache 5, according to a<br>
process internal to the processor 1 (and to the<br>
associated means for manaqinq the cache 5), taking<br>
account of the current content of the cache 5. The<br>
processor 1 then registers in a memory space 21 of the<br>
exchanges area 9, a read request addressed to the<br>
 processor 2, and activates the interrupt mechanism 14.<br><br>
In a fourth step (Figure 5), the processor 2 reads and<br>
interprets the request contained in the memory space<br>
21, and carries out the reading of the data in the<br>
memory space 20. It then uses this data in the cache 6<br>
or the assignment area 8, according to the current<br>
content of the cache 6. For example, the processor 2<br>
 allocates a memory space 22 in the assignment area 8,<br>
in which space it registers the data obtained.<br>
In this way, the data used by the processor 2 is<br>
consistent, since only the master consisting of the<br>
processor 1 reads or writes from or to this assignment<br>
area 7.<br>
Operations for transferring from the processor 2 to the<br>
processor 1 are performed in a similar manner. More<br>
precisely, these operations may be broken down into<br>
three steps. Their differences with regard to the first<br>
three steps mentioned in respect of a transfer from the<br>
processor 1 to the processor 2 are indicated<br>
hereinbelow. For simplicity, the notation and the<br>
representations adopted for the memory spaces are the<br>
same. The first step (Figure 2) is identical to the<br>
previous one.<br>
In the second step (Figure 3), the processor 2<br>
allocates in the exchanges area 9 the memory space 20<br>
necessary for transferring the data generated during<br>
the execution of the request read from the memory space<br>
17. The processor 2 then activates a transfer to the<br>
memory space 20 of the data required, from its<br>
assignment area 8.<br>
In the third and last step (Figure 6), the processor 1<br>
copies data contained in the memory space 20 to its<br>
assignment area 7 and its cache 5.<br>
A similar manner of operation to that described above<br>
is obtained when an initial request involving a<br>
transfer of data between the processors 1 and 2<br>
emanates from the processor 2 instead of from the<br>
processor 1.<br>
In another exemplary embodiment, only the processor 1<br>
benefits from the above consistency management system,<br>
and the consistency of the data between the assignment<br>
memory space 8 and the cache 6 is ensured in some other<br>
manner.<br>
In another embodiment, represented in Figure 7, a<br>
multiprocessor network comprises a first processor 41<br>
furnished with a cache 45 and two other processors 42<br>
and 43 not having such means. The three processors 41-<br>
43 are respectively furnished with software 50-52/<br>
comprising parts 53-55 relating to data communication.<br>
The multiprocessor network also comprises a main memory<br>
44, shared by the three processors 41 to 43: the latter<br>
access it respectively via buses 61 to 63 to a<br>
shareable and consistent memory are 49 for exchanges.<br>
Via the bus 61, the processor 41 also accesses a<br>
nonshareable assignment memory area 47 of the main<br>
memory 44.<br>
Moreover, hardware interrupt mechanisms 56 and 57,<br>
similar to those of the previous embodiment (Figures 1<br>
to 5) link the processor 41 to the processors 42 and 43<br>
respectively.<br>
The software 50 to 52 include functionalities similar<br>
to those described in the previous embodiment (Figures<br>
1 to 5) . Thus, a processing request addressed by the<br>
processor 41 to the processor 42 with reference to data<br>
accessible via the processor 41 involves:<br>
a first step of registering by the processor 41 of<br>
information in the exchanges area 4 9 and of<br>
activation by the processor 41 of the interrupt<br>
mechanism 56;<br>
a second step of subsequent operations executed by<br>
the processor 42: reading and interpretation of<br>
the information in the exchanges area 4 9,<br>
allocation of memory space for the reference data,<br>
in the exchanges area 49, registering in the<br>
exchanges area 4 9 of a data copy request and<br>
activation of the interrupt mechanism 56;<br>
a third step of subsequent operations executed by<br>
the processor 41: reading and interpretation of<br>
 the request in the exchanges area 4 9 and copying<br>
 of the data into the memory space allocated by the<br>
 processor 42; the processor 42 can then utilize<br>
 the data requested.<br>
In variants of the above embodiments, the hardware<br>
interrupt mechanisms 14, 56 and/or 57 are replaced by<br>
software mechanisms, making it possible to trigger<br>
appropriate processing actions. For example, this<br>
mechanism relies on periodic reading by a receiver<br>
processor, of a memory status word set by a requesting<br>
processor.<br>
WE CLAIMS<br>
1. System for memory management of data consistency, said<br>
system ensuring consistency between a main memory (4,44) being<br>
accessible by at least two processors (l-2, 41-43) and caches, at<br>
least one of the said processors (1, 2, 41) being provided with<br>
at least one cache memory (5, 6, 45) associated with at least<br>
one area (7, 8, 47) of the main memory (4, 44), referred to as the<br>
assignment area of the said processor (1, 2 41), said management<br>
system comprising:<br>
— an assembly for management of shared access (12-13,<br>
53-55) of the said processors (1-2, 41-43) to at least<br>
one common area (9, 49) of the main memory (4, 44),<br>
referred to as the exchanges area,<br>
— at least one copy module (12, 13, 53) respectively<br>
associated with at least a first of the said processors<br>
(1, 2, 41) having at least one cache memory (5, 6, 45),<br>
capable of performing a data copy between a memory<br>
workspace consisting of one of said cache memories<br>
(5, 6, 45) and/or the assignment area ( 7, 8, 47) of<br>
the said first processor, on the one hand, and the<br>
exchanges area (9, 49), on the other hand,<br>
and at least one data transfer module (12-13, 54-55),<br>
associated respectively with at least one second<br>
processor (1, 2, 42, 43) capable of exchanging data<br>
with the said first processor (1, 2, 41), intended for<br>
transferring data between the said exchanges area<br>
€9,49) and the said associated second processor (1—2,<br>
42-43).<br>
characterized in that the said system also comprises triggering<br>
means 10-11, 14, 50-52, 56-57 controlled by the second<br>
processors, capable of triggering the copy modules (12, 13, 53)<br>
of the first processors (1, 2, 41) and the transfer modules<br>
(12-13, 54-55) of the second processors (1-2, 42-43) when said<br>
first processors (1, 2, 41) submit requests involving transfers<br>
of data between said memory workspaces of the first processors<br>
(l, 2, 41) and the second processors (1-2, 42—43), said transfers<br>
of data being controlled entirely by said second processors<br>
(1-2, 42-43).<br>
2. System as claimed in claim 1, wherein the said second<br>
processors (1—2, 42—43) are fitted with memory space allocation<br>
nodules (12-13, 53—55), capable of allocating common spaces in<br>
the said exchanges area (9, 49), said triggering means (10—11,<br>
14, 50—52, 56—57) being capable of triggering the said memory<br>
space allocation modules when the said first processors (1,2,41)<br>
submit requests involving transfers of data between the said<br>
memory workspaces of the first processors (1, 2, 41) and the<br>
second processors (1-2, 42—43), by bringing about the allocation<br>
of the common spaces necessary for the said data.<br>
3. System as claimed in one of claims 1 or 2, wherein said<br>
triggering means (10-11, 14, 50-52, 56-57) comprise at least one<br>
interrupt device (14, 56, 57) between the said first processors<br>
(1, 2, 41) and second procesors (1—2, 50—52) capable of<br>
exchanging data, said device being intended to siqnal an<br>
exchange of data between the said processors and to brinq about a<br>
temporary interruption of processing operations in progress in<br>
the said processors.<br>
4. System as claimed in claim 3, wherein the said interrupt<br>
devices (14, 56-57) comprise hardware mechanisms.<br>
5. System as claimed in any one of the preceding claims,<br>
wherein the copy module (12, 13, 53) of at least one of the first<br>
processors (1, 2, 41) is designed to perform a data copy from the<br>
said exchanges area (9, 49) to the said memory workspace of the<br>
said first processor (1, 2, 41) and in that the said transfer<br>
modules (12-13, 50-52) of the second processors (1-2, 42-43)<br>
capable of exchanging data with the said first processor are<br>
designed to transfer data from the said second processors to the<br>
said exchanges area (9, 49).<br>
6. System as claimed in any one of the preceding claims,<br>
wherein the copy module (12, 13, 53) of at least one of the first<br>
processors (1, 2,41) is designed to perform a data copy from the<br>
said memory workspace of the said first processor (1, 2, 41) to<br>
the said exchanges area (9, 49) and in that the said transfer<br>
modules (12-13, 5O-52) of the second processors (1-2, 42-43)<br>
capable of exchanging data with the said first processor are<br>
designed to transfer data from the said exchanges area (9, 49) to<br>
the said second processors.<br>
7. System as claimed in any one of the preceding claims,<br>
wherein the assignment areas (7, 8, 47) of the processors<br>
(1,2, 41) with cache memories (5, 6, 45) being outside the said<br>
exchanges area (9, 49), the assembly for management of shared<br>
access (12-13, 53—55) to the exchanges area (9, 49) is designed<br>
for a nan—hidden area.<br>
8. System as claimed in any one of claims 1 to 7, wherein<br>
at least one of the assignment areas (7, 8, 47) of the processors<br>
(1, 2, 41) with cache memories (5, 6, 45) containing the said<br>
exchanges area (9, 49), the assembly for management of shared<br>
access (12-13, 53—55) to the exchanges area (9, 49) comprises a<br>
hardware device capable of ensuring the consistency of the said<br>
exchange area (9, 49).<br>
9. Multiprocessor network comprising a main memory (4, 44)<br>
and at least two processors (1-2, 41-43), at least one of the<br>
said processors (1, 2, 41) being provided with a cache memory<br>
(5, 6, 45) associated with at least one area (7, 8, 47) of the<br>
main memory (4, 44), referred to as the assignment area of the<br>
said processor (1, 2, 41) characterized in that the said<br>
multiprocessor network comprises a system for memory management<br>
of data consistency as claimed in any one of the preceding<br>
claims.<br>
10. Method for memory management of data consistency, said<br>
method insuring consistency between a main memory (4, 44) being<br>
accessible by at least two processors (1-2, 41-43) and caches, at<br>
least one of the said processors (1, 2, 41) beinq provided with<br>
at least one cache memory (5, 6, 45) associated with at least one<br>
area (7, 8, 47) of the main memory (4, 44), referred to as the<br>
assignment area of the said processor (1, 2, 41), in which the<br>
shared access of the said processors 1-2, 41—43) to at least one<br>
common area (9, 49) of the main memory (4, 44), referred to as<br>
the exchanges area, is managed in such a way that during a<br>
transfer of data from at least a first of the said processors (1,<br>
2, 41) provided with at least one cache memory (5, 6, 45) to a<br>
second of the said processors (1-2, 42-43).<br>
— a copying of the said data from a memory workspace con-<br>
sisting of one of the said cache memories (5, 6, 45)<br>
and/or the assignment area (7, 8, 47) of the first<br>
processor, to the exchanges area (9, 49) is triggered,<br>
and<br>
— a transfer of the said data from the exchanges area<br>
(9, 49) to the second processor (1-2, 42-43) is<br>
triggered,<br>
and/or during a transfer of data from the said second processor<br>
(l-2, 42-43) to the said first processor (l, 2, 41);<br>
— a transfer of the said data from the second processor<br>
(1, 2, 42-43) to the exchanges area (9, 49) is<br>
triggered, and<br>
— a copying of the said data from the exchanges area<br>
(9, 49) to the memory workspace of the first processor<br>
(l, 2, 41) is triggered,<br>
wherein when a request involving a transfer of data from the<br>
memory workspace of the first processor (1, 2, 41) to the second<br>
processor (1—2, 42—43) is sent by means of the first processor<br>
(1, 2, 41) and/or when a request involving a transfer of data<br>
from the second processor (1—2, 42—43) to the memory workspace of<br>
the first processor is sent by means of the first processor (1, 2,<br>
41), the said copying and the said transfer of the data are<br>
triggered by means of the second processor, said transfer of data<br>
being controlled entirely by said second processor (1-2,42—43).<br>
The invention relates to a system and a method of memory<br>
management of data consistency relating to a main memory (4)<br>
accessible by at least two processors (1, 2), as well as an<br>
associated multiprocessor network.<br>
The management system comprises an assembly for management<br>
of shared access of the processors to a common area (9) of the<br>
main memory, referred to as the exchanges area, at least one copy<br>
module (12, 13) intended for performing a data copy between at<br>
least one first processor comprising at least one cache memory<br>
and the exchanges area and at least one transfer module (12, 13)<br>
intended for performing a transfer of data between the exchanges<br>
area and at least one second processor. Triggering means<br>
controlled by the second processors trigger the copy modules and<br>
the transfer modules when the first processors submit requests<br>
involving transfers of data between the first and second<br>
processors.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/documentkol/518-CAL-2001/518-CAL-2001-FORM-27.pdf" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/documentkol/518-CAL-2001/518-CAL-2001-FORM-27.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="216348-a-disazo-dye-and-a-process-for-preparing-the-same.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="216350-glycopeptide-antibiotic-derivatives.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>216349</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>518/CAL/2001</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>11/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>14-Mar-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>12-Mar-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>12-Sep-2001</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON LICENSING S.A.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46 QUAI A. LE ALLO. F-92100 BOULOGNE-BILLANCOURT</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>METAYER JEAN -JACQUES</td>
											<td>88 RUE DE LA GRANDE PIERRE, 35510 CESSON-SEVIGNE</td>
										</tr>
										<tr>
											<td>2</td>
											<td>STEYER JEAN-MARIE</td>
											<td>9 RUE JEAN GUEHENNO F-35220 CHATEAUBOURG</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F 12/02</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>0012152</td>
									<td>2000-09-25</td>
								    <td>France</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/216349-system-and-method-for-memory-management-of-data-consistency-and-associated-multiprocessor-network by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:33:17 GMT -->
</html>
