<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/271484-adaptive-coding-of-a-prediction-error-in-hybrid-video-coding by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:17:44 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 271484:ADAPTIVE CODING OF A PREDICTION ERROR IN HYBRID VIDEO CODING</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">ADAPTIVE CODING OF A PREDICTION ERROR IN HYBRID VIDEO CODING</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The present invention relates to a method for coding a video signal using hybrid coding, comprising: reducing temporal redundancy by block based motion compensated prediction in order to establish a prediction error signal, deciding whether to transform the prediction error signal into the frequency domain, or to maintain the prediction error signal in the spatial domain for encoding.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Bremen,	21. Dezember 2006<br>
Unser Zeichen:	NA2731-01WO BFU/kSC<br>
Anmelder/lnhaber:	NARROSCHKE, MUSMANN<br>
Amtsaktenzeichen:	Neuanmeldung<br>
Matthias Narroschke<br>
MalortiestraÔÅÇe 4, 30419 Hannover<br>
Prof. Dr.-lng. Hans-Georg Musmann<br>
Heckenrosenweg 24, 38259 Salzgitter-Bad<br>
Adaptive coding of a prediction error in hybrid video coding<br>
The invention relates to a method of coding and decoding, a coder and a decoder,<br>
and data signals using adaptive coding of the prediction error.<br>
Up to date standardized video coding methods are based on hybrid coding. Hybrid<br>
coding provides a coding step in the time domain and a coding step in the<br>
 spatial domain. First, the temporal redundancy of video signals is reduced by<br>
using a block based motion compensated prediction between the image block to<br>
be coded and a reference block from an image that has already been transmitted<br>
determined by a motion vector. The remaining prediction error samples are arranged<br>
in blocks and are transformed into the frequency domain resulting in a<br>
block of coefficients. These coefficients are quantised and scanned according to<br>
a fixed and well-known zigzag scanning scheme, which starts with the coefficient<br>
representing the DC value. According to a typical representation, this coefficient<br>
is positioned among the low frequency coefficients in the top left corner of a<br>
block. The zigzag scanning produces a one-dimensional array of coefficients,<br>
 which are entropy-coded by a subsequent coder. The coder is optimised for an<br>
array of coefficients with decreasing energy. Since the order of coefficients within<br><br>
a block is predetermined and fixed, the zigzag scanning produces an array of<br>
coefficients of decreasing energy, if the prediction error samples are correlated.<br>
The subsequent coding step may then be optimised for such a situation. For this<br>
purpose, the latest standard H.264/AVC proposes Context-Based Adaptive Binary<br>
Arithmetic Coding (CABAC) or Context-Adaptive Variable-Length Coding<br>
(CAVLC). However, the coding efficiency of the transform only is high, if the<br>
prediction error samples are correlated. For samples being only marginally correlated<br>
in the spatial domain, the transform is less efficient.<br>
It is an object of the present invention to provide a coding and decoding method,<br>
respective coders and decoders, data signals as well as corresponding systems<br>
and semantics for coding and decoding video signals being more efficient than<br>
the prior art.<br>
According to an aspect of the present invention, a method for coding a video<br>
signal is provided being based on hybrid coding. The method comprises the<br>
steps of reducing temporal redundancy by block based motion compensated<br>
prediction in order to establish a prediction error signal, and deciding whether to<br>
transform the prediction error signal into the frequency domain, or to maintain the<br>
prediction error signal in the spatial domain.<br>
According to a corresponding aspect of the present invention, a coder is provided,<br>
which is adapted to apply hybrid coding of a video signal. The coder includes<br>
means for reducing the temporal redundancy by block based motion<br>
compensated prediction in order to establish a prediction error signal, and means<br>
for deciding whether to transform the prediction error signal into the frequency<br>
domain, or to maintain the prediction error signal in the spatial domain. According<br>
to this aspect of the invention, a concept and corresponding apparatuses, signals<br>
and semantics are provided to decide adaptively whether to process the prediction<br>
error signal in the frequency or in the spatial domain. If the prediction error<br>
samples have only small correlation, the subsequent steps of coding the samples<br>
may be more efficient and they would lead to a reduced data rate compared to<br>
coding the coefficients in the frequency domain. Therefore, an adaptive deciding<br><br>
step and adaptive control means to make the decision are implemented by the<br>
present invention. Accordingly, in view of the prediction error signal, it is decided<br>
whether to use frequency domain transform or to maintain the prediction error<br>
signal in the spatial domain. The subsequent coding mechanisms may be the<br>
same as for the frequency domain, or they may be adapted especially to the<br>
needs of the samples in the spatial domain.<br>
According to another aspect of the invention, the method for coding a video signal,<br>
and in particular the deciding step is based on a cost function. Generally, the<br>
decision whether to use the coefficients in the frequency domain or the samples<br>
in the spatial domain may be based on various kinds of deciding mechanisms.<br>
The decision may be made for all samples within a specific portion of a video<br>
signal at once, or e.g. even for a specific number of blocks, macroblocks, or<br>
slices. The decision may be based on a cost function, as for example a Lagrange<br>
function. The costs are calculated for both, coding in the frequency domain and<br>
coding in the spatial domain. The decision is made for the coding with lower<br>
costs.<br>
According to another aspect of the present invention, the cost function includes<br>
the rate distortion costs for the coding in the spatial and in the frequency domain.<br>
According to still another aspect of the invention, the rate distortion costs may be<br>
calculated by the required rate and the resulting distortion weighted by a Lagrange<br>
parameter. Further, the distortion measure may be the mean square<br>
quantisation error or the mean absolute quantisation error.<br>
According to an aspect of the present invention, the samples in the spatial domain<br>
may be coded by essentially the same methods as being used for the coefficients<br>
in the frequency domain. These methods may include the CABAC or<br>
CAVLC coding methods. Accordingly, only little or no adaption of the coding<br>
mechanisms is necessary, if the adaptive control means decide to switch between<br>
the frequency and the spatial domain. However, it might also be provided<br>
to use different coding schemes for the coefficients in the two domains.<br><br>
According to another aspect of the invention, a method for coding a video signal<br>
is provided, which is based on hybrid coding. According to this aspect of the<br>
invention, the temporal redundancy is reduced by block based motion compensated<br>
prediction, and the samples of the prediction error signal are provided in<br>
the prediction error block in the spatial domain. The samples are scanned from<br>
the prediction error block in order to provide an array of samples in a specific<br>
order. According to this aspect of the invention it is provided that the scanning<br>
scheme is derived from a prediction error image or a prediction image. The scanning<br>
scheme according to this aspect of the invention takes account of the effect<br>
that the zigzag scan according to prior art for the frequency domain may not be<br>
the most efficient scanning order for the spatial domain. Therefore, an adaptive<br>
scanning scheme is provided, which takes account of the distribution of the samples<br>
and the magnitude of the samples in the spatial domain. The scanning<br>
scheme may preferably be based on a prediction error image or a prediction<br>
image. This aspect of the invention takes account of the most probable positions<br>
of the samples having the highest magnitude and samples being most probably<br>
zero. As the coding gain for the frequency domain is mainly based on the phenomenon<br>
that the low frequency components have larger magnitudes, and most<br>
of the high frequency coefficients are zero, a very effective, variable code length<br>
coding scheme like CABAC or CAVLC may be applied. However, in the spatial<br>
domain, the samples having the highest magnitude may be located anywhere<br>
within a block. However, as the prediction error is usually the highest at the<br>
edges of a moving object, the prediction image or the prediction error image may<br>
be used to establish the most efficient scanning order.<br>
According to an aspect of the present invention, the gradients of the prediction<br>
image may be used to identify the samples with large magnitudes. The scanning<br>
order follows the gradients within the prediction image in their order of magnitude.<br>
The same scanning order is then applied to the prediction error image, i.e. the<br>
samples in the prediction error image in the spatial domain.<br>
Further, according to still another aspect of the present invention, the scanning<br>
scheme may be based on a motion vector in combination with the prediction error<br><br>
image of the reference block. The scan follows the magnitudes of the prediction<br>
error in decreasing order.<br>
According to one aspect of the invention, the scanning scheme is derived from a<br>
linearcombination of the gradient of the prediction image and the prediction error<br>
image of the reference block in combination with a motion vector<br>
According to another aspect of the present invention, a specific code for the<br>
coding mechanisms, as for example CABAC or the like is used based on separately<br>
determined probabilities for the coefficients in the frequency domain or the<br>
samples in the spatial domain. Accordingly, the well-known prior art coding<br>
mechanisms may be adapted at least slightly in order to provide the most efficient<br>
coding mechanism for the spatial domain. Accordingly, the switching mechanism<br>
being adaptively controlled in order to code either in the spatial or in the frequency<br>
domain may be further adapted to switch the subsequent coding steps for<br>
the samples or coefficients in the respective domains.<br>
According to an aspect of the present invention, a method for coding a video<br>
signal is provided including a step of quantising the prediction error samples in<br>
the spatial domain by a quantiser, which has either subjectively weighted quantisation<br>
error optimisation or mean squared quantization error optimization. According<br>
to this aspect of the invention, the quantiser used for quantising the samples<br>
in the spatial domain may be adapted to take account of the subjectively<br>
optimal visual impression of a picture. The representative levels and decision<br>
thresholds of a quantiser may then be adapted based on corresponding subjective<br>
or statistical properties of the prediction error signal.<br>
Further, the present invention relates also to a decoding method and a decoding<br>
apparatus in accordance with the aspects set out here above. According to an<br>
aspect of the present invention, a decoder is provided including adaptive control<br>
means for adaptively deciding whether an input stream of a coded video signal<br>
represents the prediction error signal of the coded video signal in the spatial<br>
domain or in the frequency domain. Accordingly, the decoder according to this<br><br>
aspect of the present invention is adapted to decide for an incoming data stream,<br>
i.e. whether the prediction error signal is coded in the frequency or in the spatial<br>
domain. Further, the decoder provides respective decoding means for each of the<br>
two domains, either the spatial or the frequency domain.<br>
Further, according to still another aspect of the present invention, the decoder<br>
comprises a scan control unit for providing a scanning order based on a prediction<br>
signal or a prediction error signal. The scan control unit according to this<br>
aspect of the invention is adapted to retrieve the necessary information about the<br>
scanning order, in which the incoming samples of a block have been scanned<br>
during coding the video signals. Further, the decoder may comprise all means in<br>
order to inverse quantise and inverse transform the coefficients in the frequency<br>
domain or to inverse quantise the samples in the spatial domain. The decoder<br>
may also include a mechanism to provide motion compensation and decoding.<br>
Basically, the decoder may be configured to provide all means in order to implement<br>
the method steps corresponding to the coding steps explained here above.<br>
According to still another aspect of the present invention, a data signal representing<br>
a coded video signal is provided, wherein the coded information of the prediction<br>
error signal in the data signal is partially coded in the spatial domain and<br>
partially coded in the frequency domain. This aspect of the invention relates to<br>
the coded video signal, which is a result of the coding mechanisms as set out<br>
above.<br>
Further, according to still another aspect of the invention, the data signal may<br>
include side information indicating the domain in which a slice, a macroblock, or a<br>
block is coded, in particular information whether a slice, a macroblock or a block<br>
is coded in the spatial or in the frequency domain. As the adaptive control accord-<br>
ing to the present invention provides that the prediction error signal is either<br>
coded in the spatial domain or in the frequency domain, it is necessary to include<br>
corresponding information into the coded video signal. Therefore, the present<br>
invention provides also a specific information, which indicates the domain in<br>
which the specific portion, such as a slice, macroblock, or block has been coded.<br><br>
Further, this aspect of the invention takes also account of the possibility that a<br>
whole macroblock or a whole slice may be coded only in one of the two domains.<br>
So, if for example an entire macroblock is coded in the spatial domain, this may<br>
be indicated by a single flag or the like. Further, even a whole slice may be coded<br>
only in the frequency or in the spatial domain, and a corresponding indicator<br>
could be included for the whole slice into the data stream. This results in a decreased<br>
data rate and a more efficient coding mechanism for the side information.<br>
The aspects of the present invention are explained with respect to the preferred<br>
embodiments which are elucidated by reference to the accompanying drawings.<br>
Fig. 1 shows a simplified block diagram of an encoder implementing as-<br>
pects according to the present invention,<br>
Fig. 2 shows a simplified block diagram of a decoder implementing aspects<br>
of the present invention,<br>
Fig. 3 shows a scanning scheme according to the prior art,<br>
Fig. 4 shows scanning schemes according to the present invention, and<br>
Fig. 5 illustrates the parameters used for an optimised quantiser according<br>
to the present invention.<br>
Fig. 1 shows a simplified block diagram of an encoder according to the present<br>
invention. Accordingly, the input signal 101 undergoes a motion estimation based<br>
on which a motion compensation prediction is carried out in order to provide a<br>
prediction signal 104, which is subtracted from the input signal 101. The resulting<br>
prediction error signal 105 is transformed into the frequency domain 106 and<br>
quantised by an optimised quantiser 107 for the frequency related coefficients.<br>
The output signal 120 of the quantiser 107 is passed to an entropy coder 113<br>
which provides the output signal 116 to be transmitted, stored, or the like. By<br><br>
means of an inverse quantisation block 110 and inverse transformation block<br>
111, the quantised prediction error signal 120 is further used for the next prediction<br>
step in the motion compensated prediction block 103. The inverse quantised<br>
an inverse DCT transformed prediction error signal is added to the prediction<br>
signal and passed to frame memory 122 storing preceding images for the motion<br>
compensation prediction block 103 and the motion estimation block 102. Generally,<br>
the present invention suggests to use in addition to the prior art an adaptively<br>
controlled mechanism 115 to switch between the frequency and the spatial<br>
domain for transforming the prediction error signal 105. The adaptive control<br>
means 115 produce signals and parameters in order to control the adaptive<br>
change between the frequency and the spatial domain. Accordingly, an adaptive<br>
control information signal 121 is asserted to the two switches switching between<br>
the positions A and B. If the transformation is carried out in the frequency domain,<br>
the two switches are in position A. If the spatial domain is used, the<br>
switches are switched to position B. Further, the side information signal 121, i.e.<br>
which of the domains has been used for the coding procedure of a picture is also<br>
passed to the entropy coder 113. Accordingly, an appropriate information for the<br>
device is included into the data stream. Parallel to the frequency transform, via an<br>
alternative path, the prediction error signal 105 is passed to the quantiser 109.<br>
This quantisation block 109 provides optimised quantisation for the prediction<br>
error signal 105 in the spatial domain. The quantised prediction error signal 124<br>
in the spatial domain may be passed to a second inverse quantisation block 112<br>
and further to the back connection to the motion compensation prediction block<br>
103. Additionally, there is a scan control block 114 receiving either the motion<br>
vector 123 and the inverse quantised prediction error signal 118, or the prediction<br>
signal 104 via connection 119. Block 117 serves to encode the motion information.<br>
The adaption control block 115 decides whether a block is to be coded in the<br>
frequency or in the spatial domain, and it generates corresponding side information<br>
to indicate the domain. The decision made by the adaption control means is<br>
based on the rate distortion costs for the coding in the spatial and for coding in<br>
+the frequency domain. The domain having the lower rate distortion costs is se-<br><br>
lected for coding. For example, the rate distortion costs C are calculated by the<br>
required rate R and the resulting distortion D weighted by a Lagrange parameter<br>
L: C=L*R+D. As a distortion measure, the mean squared quantisation error may<br>
be used, but also other measures are applicable, as for example the mean absolute<br>
quantisation error. As Lagrange parameter L, the commonly used Lagrange<br>
parameter for the coder control of H.264/AVC may be used L=0.85*2((Qp-12)/3).<br>
Alternative methods for determining the rate distortion costs are possible.<br>
The adaption control 115 can alternatively control the coding method. This may<br>
be done for example based on the prediction signal or based on the correlation in<br>
the prediction error, or based on the domain, the prediction error is coded in at a<br>
motion compensated position of already transmitted frames.<br>
Fig. 2 shows a simplified block diagram of an architecture of a decoder according<br>
to aspects of the present invention. Accordingly, the coded video data is input to<br>
two entropy decoding blocks 201 and 202. The entropy decoding block 202<br>
decodes motion compensation information, such as motion vectors etc. The<br>
entropy decoding block 201 applies the inverse coding mechanism used in the<br>
coder, as for example decoding according to CABAC or CAVLC. If the encoder<br>
uses a different coding mechanism for the coefficients or the samples in the<br>
spatial domain, the corresponding decoding mechanism is to be used in the<br>
corresponding entropy decoding blocks. Accordingly, the entropy decoding block<br>
201 produces the appropriate signals in order to switch between positions A and<br>
B in order to use either the appropriate inverse quantisation path for the spatial<br>
domain, i.e. the inverse quantisation operation block 206, or the appropriate<br>
blocks according to switch position A, i.e. the inverse quantisation block 203 and<br>
the inverse transform block 204. If the prediction error is represented in the frequency<br>
domain, inverse quantisation block 203 and inverse transformation block<br>
204 apply the corresponding inverse operations. As the samples in the spatial<br>
domain have been arranged in a specific order in accordance with a scan<br>
mechanism according to aspects of the present invention, a scan control unit 205<br>
provides the correct order of the samples for the entropy decoding block 201. If<br>
the encoding has been carried out in the spatial domain, the inverse transform<br><br>
block 204 and the inverse quantization block 203 are bypassed by an inverse<br>
quantisation operation in block 206. The switching mechanism, to switch between<br>
frequency and spatial domain (i.e. position A and B of the switches) is controlled<br>
by the side information sent in the bitstream and decoded by the entropy decoding<br>
block 201. Further, the inverse quantised signal in the spatial domain, or the<br>
inverse quantized and inverse transformed signal in the frequency domain are<br>
summed with the motion compensated prediction picture in order to provide the<br>
decoded video signals 210. The motion compensation is carried out in block 209<br>
based on previously decoded video signal data (previous pictures) and motion<br>
vectors. The scan control unit 205 uses either the prediction image 208, or the<br>
prediction error signal 207 in combination with the motion vector 212 to determine<br>
the correct scan sequence of the coefficients. The scan mechanism may also be<br>
based on both pictures, i.e. the prediction error picture and the prediction picture.<br>
As explained for the coding mechanism with respect to Fig. 1, the scan sequence<br>
during coding may be based on a combination of the prediction error information<br>
207 and the motion compensation vectors. Accordingly, the motion compensation<br>
vectors may be passed via a path 212 to the scan control unit 205. Further, in<br>
correspondence to Fig. 1, there is a frame memory 211 storing the necessary<br>
and previously decoded pictures.<br>
Fig. 3 shows a simplified diagram in order to illustrate the zigzag scan order<br>
according to the prior art. Accordingly, the coefficients, which are the result of a<br>
transform to the frequency domain (for example DCT) are arranged in a predetermined<br>
order as shown in Fig. 3 for a four by four block. These coefficients are<br>
read out in a specific order, such that the coefficients representing the low frequency<br>
portions are located in the first left positions of a one-dimensional array.<br>
The more on the bottom right of the array, the higher the corresponding frequencies<br>
of the coefficients. As blocks to be coded often contain substantial low frequency<br>
coefficients, the high frequency coefficients, or at least a majority of high<br>
frequency coefficients are zero. This situation can effectively be used to reduce<br>
the data to transmit it by for example replacing large sequence of zeros by a<br>
single information about the number of zeros.<br><br>
Fig. 4 shows a simplified illustrative example for a scan mechanism according to<br>
an aspect of the present invention. Fig. 4(a) shows the magnitude of the gradients<br>
in the prediction image for one block. The values in each position of the<br>
block represent the gradient of the prediction image of the current block. The<br>
gradient itself is a vector consisting of a two components representing the gradient<br>
in horizontal and vertical direction. Each component may be determined by<br>
the difference of the two neighboring samples or it may be determined by the<br>
well-known Sobel-operator taking six neighboring samples into account. The<br>
magnitude of the gradient is the magnitude of the vector. If two values have the<br>
same magnitude, a fixed or predetermined scan order may be applied. The scanning<br>
order follows the magnitude of the gradient values in the block as indicated<br>
by the dotted line. Once the scanning order within the gradient prediction image<br>
is established, the same scanning order is applied to the quantised prediction<br>
error samples, which are shown in Fig. 4(b). If the quantised samples in the<br>
spatial domain of the block shown in Fig. 4(b) are arranged in a one-dimensional<br>
array as indicated on the left side of Fig. 4(b) in accordance with the scanning<br>
order established based on the magnitude of the gradients in the prediction image,<br>
the samples having a high value are typically arranged first in the array, i.e.<br>
in the left positions. The right positions are filled with zeros as indicated in Fig.<br>
4(b).<br>
Instead of a scan controlled by the gradient, also other scans as e.g. a predefined<br>
scan or a scan controlled by the quantised prediction error of already transmitted<br>
frames in combination with a motion vector, or combinations thereof can be applied<br>
(the scan control relates to blocks 114 or 205 as explained with respect to<br>
Fig. 1 and Fig. 2). In the case of a scan controlled by the prediction error signal in<br>
combination with a motion vector, the scan follows the magnitudes of the quantized<br>
prediction error samples of the block, the motion vector of the current block<br>
refers to, in decreasing order.<br>
If the motion vector points to fractional sample positions, the required quantized<br>
prediction error samples may be determined using an interpolation technique.<br><br>
This may be the same interpolation technique as used for the interpolation of the<br>
reference image in order to generate the prediction samples.<br>
In the case the scan is controlled by the combination of the prediction image and<br>
the prediction error image in combination with a motion vector, linear combinations<br>
of the magnitudes of the gradients and of the quantized prediction error<br>
samples of the block, the motion vector of the current block refers to, are calculated.<br>
The scan follows the values of these linear combinations. In addition, the<br>
method for the scan determination can be signalled for segments of the sequence,<br>
e.g. for each frame or for each slice or for a group of blocks. According<br>
to the typical standard processing, the motion compensation vectors are already<br>
considered, while the prediction image is determined.<br>
According to another aspect of the present invention, the scanning order may<br>
also be based on the prediction error picture in combination with a motion vector.<br>
Further, combinations of the gradient principle as explained above and the prediction<br>
error picture are conceivable.<br>
Fig. 5 shows a simplified illustration being useful to illustrate the definition of an<br>
optimised quantiser according to aspects of the present invention. Accordingly,<br>
the three parameters a, b, and c are the parameters used to adapt the quantiser.<br>
According to the standard H.264/AVC, rate distortion optimised quantisers for the<br>
coefficients with two different distortion measures are applied. The first measure<br>
is the mean squared quantisation error, the second is the subjectively weighted<br>
quantisation error. According to the H.264/AVC standard, two quantisers for the<br>
prediction error samples are developed. Since the distribution of the prediction<br>
error is close to a Laplacian distribution, scalar a dead-zone plus uniform threshold<br>
quantiser is used in the case of mean squared quantisation error optimisation.<br>
Frg.5 illustrates the parameters a, b, and c of the quantisation and inverse quantisation.<br>
Table 1 shows the parameters a, b, and c, which may be advantageously used<br>
for the commonly used QPs (Quantisation Parameter) in the H.264/AVC coding<br><br>
scheme. The parameters a, b, c are the respective optimised parameters for<br>
mean square quantisation error optimisation. However, this is only an example,<br>
and different or additional parameters may be useful for different applications.<br><br>
For subjectively weighted quantisation error optimisation, a non-uniform quantiser<br>
is proposed with representative levels n, -n and decision thresholds in the middle<br>
of adjacent n which are also shown in table 1. If large prediction errors occur at<br>
the edges, visual masking may be exploited. Accordingly, large quantisation<br>
errors may be allowed at the edges and small ones if the image signal is flat.<br>
H.264/AVC may use more than 4 QPs as shown in Table 1. Then Table 1 has to<br>
be extended. H.264/AVC may use 52 different QPs. The basic idea for determining<br>
the appropriate representative values n, -r, is explained here below with respect<br>
to Fig. 6.<br>
Fig. 6 shows a simplified representation of the measured mean absolute reconstruction<br>
error of a picture element in the case of the subjectively weighted quantisation<br>
in the frequency domain in Fig. 6(a) and in the spatial domain in Fig. 6(b).<br>
The measured mean absolute reconstruction error of subjectively weighted quantisation<br>
in the frequency domain is shown as a function of the absolute value of<br>
the prediction error. For the absolute reconstruction error of subjectively weighted<br>
quantisation in the spatial domain, the representation levels r1 are adjusted such<br>
that the mean absolute reconstruction error is the same for quantisation in the<br>
frequency and spatial domain with respect to the quantisation intervals in the<br><br>
spatial domain. Just as an example, the values r1, r2, r3, and r4 for QP = 26 as<br>
indicated in table 1 are also present in Fig. 6(b) As a rule of thumb, a representative<br>
levels r1 is approximately doubled if the value QP increases by 6. The quantiser<br>
design can also exploit other features of the visual system. Furthermore,<br>
quantisers can be used to create a quantisation error with properties different to<br>
those of the H.264/AVC quantisers.<br>
Entropy coding of the quantised samples in the spatial domain<br>
According to an aspect of the present invention, entropy coding in the spatial<br>
domain may be based on the same methods as for the quantised coefficients in<br>
the frequency domain. For the H.264/AVC standard, two preferred entropy coding<br>
methods are CABAC and CAVLC. However, according to this aspect of the present<br>
invention, instead of coding the quantised coefficients in the frequency domain,<br>
quantised samples in the spatial domain are coded by the above mentioned<br>
methods. As explained above, the scanning order may be changed in<br>
order to provide the same data reduction as for the frequency domain. As set out<br>
above, the scan in the spatial domain may be controlled by the magnitude of the<br>
gradient of the prediction image signal at the same spatial position. According to<br>
this principle, the samples to be coded are arranged in an order of decrease in<br>
gradients, as already explained with respect to Fig. 4(a) and (b). Other scan<br>
mechanisms may also be applied as set out above. Further, separate codes,<br>
which means separate probability models in the case of CABAC, may be used for<br>
the spatial domain according to aspects of the present invention. The code and in<br>
the case of CABAC the initialisation of the probability models may be derived<br>
from the statistics of the quantised samples. The context modelling in the spatial<br>
domain may be done in the same way as in the frequency domain.<br><br>
Coding of the side information<br>
The adaptive control means explained with respect to Fig. 1 generates the information<br>
relating to the domain, in which a block is to be coded. The block size<br>
may be four by four or eight by eight picture elements according to the size of the<br>
transform. However, according to different aspects of the present invention, other<br>
block sizes independent of the size of the transform may be applied. According to<br>
an aspect of the present invention, the side information includes specific flags,<br>
which indicate whether the coding mechanism has adaptively been changed<br>
during coding. If for example all blocks of a slice are coded in the frequency<br>
domain, this may be indicated by a specific bit in the coded video data signal.<br>
This aspect of the invention may also relate to the blocks of a macroblock, which<br>
may all be coded in each of the two domains, or only in one domain. Further, the<br>
concept according to the present aspect of the invention may be applied to mac-<br>
roblocks and information may be included in the data stream which indicates<br>
whether at least one block of a macroblock is coded in the spatial domain. Accordingly,<br>
the flag Slice_FD_SD_coding_flag may be used to indicate whether all<br>
blocks of the current slice are coded in the frequency domain, or whether at least<br>
one block is coded in the spatial domain. This flag may be coded by a single bit.<br>
If at least one block of the slice is coded in the spatial domain, this may be indicated<br>
by the flag MB_FD_SD_coding_flag for each individual macroblock of the<br>
current slice, if all the blocks of the current macroblock are coded in the frequency<br>
domain, or if at least one block is coded in the spatial domain. This flag<br>
may be coded conditioned on the flags of the already coded neighbouring blocks<br>
to the top and to the left. If the last one of a macroblock is coded in the spatial<br>
domain, this may be indicated by the flag FD_or_SD-Flag for each block of the<br>
macroblock to be coded, if the current block is coded in the frequency or in the<br>
spatial domain. This flag may be coded conditioned on the flags of the already<br>
coded neighbouring blocks to the top and to the left. Alternatively, the side infor-<br>
mation may also be coded conditioned by the prediction signal or the prediction<br>
error signal in combination with a motion vector.<br><br>
Syntax and semantics<br>
According to this aspect of the present invention, an exemplary syntax and semantics<br>
allowing the incorporation of the aspects of the present invention into the<br>
H.264/AVC coding scheme is presented. Accordingly, the flag<br>
Slice_FD_SD_coding_flag may be introduced in the slice_header as shown in<br>
table 2. The flag MB_FD_SD_coding_flag may be sent in each macroblock_ayer<br>
as shown in table 3. In the residual_block_cabac it may be signalled by the flag<br>
FD_or_SD_flag if the frequency domain coding or spatial domain coding is supplied<br>
for the current block, this is shown in table 4 here below. A similar scheme<br>
may be applied in other video coding algorithms for the prediction error coding.<br><br><br><br><br>
Claims<br>
1.	Method for coding a video signal using hybrid coding, comprising:<br>
reducing temporal redundancy by block based motion compensated prediction<br>
in order to establish a prediction error signal,<br>
deciding whether to transform the prediction error signal into the frequency<br>
domain, or to maintain the prediction error signal in the spatial domain for encoding.<br>
2.	The method according to claim 1, wherein the step of deciding is based on<br>
a cost function.<br>
3.	The method according to claim 1 or 2, wherein the cost function includes<br>
the rate distortion costs for the coding in the spatial and the coding in the frequency<br>
domain.<br>
4.	The method according to claim 3, wherein the rate distortion costs are<br>
calculated by the required rate (R) and the resulting distortion (D) weighted by a<br>
Lagrange parameter.<br>
5.	The method according to claim 4, wherein the distortion measure is the<br>
mean square quantisation error or the mean absolute quantisation error.<br>
6.	The method according to one of the previous claims, wherein the samples<br>
in the spatial domain are coded by the same method as the coefficients in the<br>
frequency domain.<br>
7.	The method of claim 6, wherein the coding of the coefficients is carried out<br>
according to CABAC or CAVLC.<br>
8.	The method for coding a video signal using a hybrid coding, wherein the<br>
temporal redundancy is reduced by block based motion compensation prediction,<br>
the method comprising:<br><br>
providing the samples of the prediction error signal in a prediction error<br>
block in the spatial domain,<br>
scanning the samples in the prediction error block to provide an array of<br>
samples in a specific order, wherein the scanning scheme is derived from a<br>
prediction error image or a prediction image.<br>
9.	The method of claim 8, wherein the scanning scheme is derived from the<br>
gradient of the prediction image.<br>
10.	The method of claim 8, wherein the scanning scheme is based on a motion<br>
vector in combination with the prediction error image of the reference block.<br>
11.	The method of claim 8, wherein the scanning scheme is derived from a<br>
linearcombination of the gradient of the prediction image and the prediction error<br>
image of the reference block in combination with a motion vector.<br>
12.	The method of one of the previous claims, wherein a specific code for<br>
CABAC is used having separate probabilities for the spatial domain.<br>
13.	The method of one of the previous claims, wherein a specific code for<br>
CAVLC is used for the spatial domain.<br>
14.	The method of one of the previous claims, comprising further quantising the<br>
prediction error samples by a quantiser having subjectively weighted quantisation<br>
error optimisation or mean squared quantisation error optimisation in the spatial<br>
domain.<br>
15.	Data signal representing a coded video signal, comprising coded information<br>
of a prediction error signal being partially coded in the spatial domain and<br>
partially coded in the frequency domain.<br>
16.	The data signal according to claim 15, comprising information relating to the<br>
domain in which a slice, a macroblock, or a block is coded, in particular informa-<br><br>
tion whether a slice, macroblock, or block is coded in the spatial or in the frequency<br>
domain.<br>
17. The data signal of claim 16, comprising a slice_fd_sd_coding_flag, a<br>
mb_fd_sd_coding_flag, and/or a fd_or_sd_flag information relating to the coding<br>
used for a slice, a macroblock, or a block, respectively.<br>
18. Method for decoding a video signal using hybrid coding, comprising:<br>
decoding coded video data effectively in the frequency or the spatial domain,<br>
in accordance with the coding mechanism used for coding the video signal<br>
data.<br>
19.	The decoding method of claim 18, wherein the positions of the prediction<br>
error signal samples received in a one-dimensional array are assigned to locations<br>
in a two-dimensional arrangement are determined based on a previously<br>
received prediction error signal or prediction image.<br>
20.	Coder for coding a video signal using hybrid coding, comprising:<br>
means for reducing the temporal redundancy by block based motion compensated<br>
prediction in order to establish a prediction error signal, and<br>
adaptive control means for deciding whether to transform the prediction<br>
error signal into the frequency domain, or to maintain the prediction error signal in<br>
the spatial domain.<br>
21.	Decoder for decoding a video signal being coded by use of hybrid coding,<br>
comprising adaptive control means (201) for adaptively deciding whether an input<br>
stream of a coded video signal represents the prediction error signal of the coded<br>
video signal in the spatial domain or in the frequency domain.<br>
22.	The decoder of claim 21 comprising further scanning control means for<br>
providing a scanning order based on a prediction signal or a prediction error<br>
signal or on a linearcombination of both.<br><br>
The present invention relates to a method for coding a video signal using hybrid<br>
coding, comprising: reducing temporal redundancy by block based motion compensated prediction in order to establish a prediction error signal, deciding<br>
whether to transform the prediction error signal into the frequency domain, or to<br>
maintain the prediction error signal in the spatial domain for encoding.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=xFUYkVpAN6f0BSV9hp0ZDg==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=xFUYkVpAN6f0BSV9hp0ZDg==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="271483-method-of-an-uplink-harq-operation-at-an-expiry-of-time-alignment-timer.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="271485-acoustic-reconfiguration-devices-and-methods.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>271484</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3094/KOLNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>09/2016</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>26-Feb-2016</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>23-Feb-2016</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>29-Jul-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>NARROSCHKE, MATTHIAS</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>AM LANDERWEG 6, 64850 SCHAAFHEIM GERMANY</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>NARROSCHKE, MATTHIAS</td>
											<td>AN DER LUTHEREICHE 6 63110 RODGAU DUDENHOFEN</td>
										</tr>
										<tr>
											<td>2</td>
											<td>MUSMANN, HANS-GEORG</td>
											<td>HECKENROSENWEG 24, 38259 SALZGITTER GERMANY</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26,H04N 7/50</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2006/012492</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-12-22</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/766,300</td>
									<td>2006-01-09</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/271484-adaptive-coding-of-a-prediction-error-in-hybrid-video-coding by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:17:45 GMT -->
</html>
