<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/264115-method-and-apparatus-for-video-codec-quantization by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:46:28 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 264115:METHOD AND APPARATUS FOR VIDEO CODEC QUANTIZATION</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR VIDEO CODEC QUANTIZATION</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>An encoder, a decoder, and corresponding methods are provided for encoding and decoding video signal data for an image block. The encoder includes a quantizer (2335) for receiving transform coefficients for the image block, and for adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>CROSS-REFERENCE TO RELATED APPLICATIONS<br>
This application claims the benefit of U.S. Provisional Application Serial No. 60/581,019, filed on 18 June, 2004, which is incorporated by reference herein in its entirety.<br>
FIELD OF THE INVENTION<br>
The present invention generally relates to encoders and decoders and, more particularly, to a method and apparatus for quantization in video encoders and decoders."<br>
BACKGROUND OF THE INVENTION<br>
Currently most image and video coding systems and standards such as MPEG-2 and JVT/H.264/MPEG AVC use transform based techniques followed by quantization and entropy coding for performing compression. Turning to FIG. 1, a typical transform based compression system is indicated generally by the reference numeral 100. An input to the transform based compression system 100 is connected in signal communication with an input of a transformer 110. An output of the transformer 110 is connected in signal communication with an input of a quantizer 120. An output of the quantizer 120 is connected in signal communication with an input of an encoder 130. An output of the encoder 130 is connected in signal communication with an input of a decoder 140. An output of the decoder 140 is connected in signal communication with an input of a dequantizer 150. An output of the dequantizer 150 is connected in signal communication with an input of an inverse transformer 160. An output of the inverse transformer 160 is an externally available output of the system 100. The key idea is that such transforms, such as the Discrete Cosine Transform (DCT), de-correlate the image signal and compact the energy of an image block into a few low pass coefficients, which after quantization and de-quantization could still represent the signal rather accurately. Nevertheless, this quantization/de-quantization process needs to be carefully designed in order to have the best possible subjective and objective quality. A great deal of past research was primarily directed to the 8x8 DCT used in JPEG and MPEG-like encoders, and has<br><br>
focused on the design of the quantization process, and in particular with regards to the optimal quantization step size that is to be used, coefficient distribution and dead-zoning mechanisms. One of the most important observations was that coefficient distribution, in most cases, followed a Laplacian distribution that enabled a more accurate modeling and design of the quantization process. This assumption is followed within the design of many modem codecs and encoders, including H.264 in an attempt to improve Rate Distortion (RD) performance.<br>
However, although the Laplacian distribution holds true for many cases (including for some material coded with H.264), due to the introduction of a new smaller (4x4) transform in the H.264 standard, and the consideration of the standard for a wide range of applications including high definition TV, broadcasting, videoconferencing, and so forth, there are cases that such distribution does not always hold true. One such application in particular is the encoding of Film Grain content where distribution can be better approximated for certain coefficients using a Gaussian or generalized Gaussian distribution. This suggests that techniques used to better fit Laplacian distributions might not be appropriate for encoding such content, especially at high bitrates (small quantization step sizes) resulting in poor subjective and objective performance. Although some of the past research also suggests that the distribution could be different (Gaussian, Cauchy, Generalized Gaussian, and so forth), they generally provide rather complex models for the design of the quantization process.<br>
It is well documented that the distribution of the DCT AC coefficients, follows in many cases a Laplacian distribution:<br>
Based on this observation previous research tried to estimate a Laplacian distribution that could fit to the actual coefficient distribution of the source, and based on that design the weighted quantization matrices and the dead-zone that is to be used during quantization. The simplest way to find such a parameter is to use the standard deviation:<br><br>
This estimate is done separately for each one of the AC coefficients, while also the same process is independently applied to the chroma AC coefficients as well.<br>
The above-described process enables an adaptive design of the quantization process, for example for the selection of the optimal reconstruction values or the design of the quantization matrices. Such a process could for example be performed where the quantization factor (Q) that also results in the smallest mean squared error is first determined:<br><br>
It has been claimed that the above could be easily evaluated to determine the best quantization values, and then determine a table of perceptually weighted coefficients experimentally. The decision of the base matrix is then performed by multiplying each MSE-optimal Q with the perceptual weighting, and then collecting them into a matrix, which is finally scaled and rounded as appropriate for the given bitrate.<br>
where r(-) denotes the gamma function<br>
Nevertheless, other work tries to disprove the claim of Laplacian distribution, with the claim that the distribution is closer to Gaussian or a Generalized Gaussian, i.e., following the distribution model:<br><br><br><br><br>
and v and aare positive real values. Note that r(-) for n integer values becomes =* r(«)=(n-l)! while for half integer arguments r(«/2) has another special form which<br>
is:<br>
where nil is a double factorial. The first few values for n=1, 3,5,... are therefore:<br><br><br>
It is immediately observed that for v =1 and v =2, the above generalized Gaussian becomes a Laplacian or Gaussian PDF respectively. Maximum likelihood approach is used for fitting the statistics of a given image or sequence in order to provide the v and a parameters, which are then used in similar fashion as with the Laplacian case to determine the optimal quantization values.<br>
The H.264 standard until recently did not provide any mechanism to benefit from such properties during the quantization process. More specifically, the standard does not specify how the encoder should perform rounding during quantization, while it only specifies how the decoder reconstruction levels are computed using uniform quantization. The H.264 reference software on the other hand made the assumption that coefficients, both DC and AC, satisfied a Laplacian distribution based on which fixed rounding (1/3 for intra and 1/6 for inter coding) was used. Unfortunately, the coefficients are frequently not Laplacian distributed, resulting in very poor subjective and objective performance within many H.264 encoder implementations, especially at<br><br>
higher bitrates and resolutions. This is partly because the standard only considered a 4x4 transform, thus de-correlating coefficients less efficiently, while also the equal step quantizers and the rather aggressive dead-zoning process tends to throw away most of the AC coefficients even at high bitrates. For this purpose, the 8x8 transform was reintroduced in the standard, while also quantization matrices were also adopted allowing a finer tuning of the quantization process. An alternative method was also proposed that allowed a modification of the reconstructed coefficient value with lower complexity than the quantization matrices process. Based on this approach, instead of performing the quantization and de-quantization of a coefficient equal to W using an equation of the form:<br><br>
where Zis the final quantized level, A is the quantization step-size, and f serves as a rounding term for the quantization process (see FIGs. 2A and 2B), quantization is performed using an equation of the form:<br>
where now © is an additional parameter that allows of an offsetting of the final reconstruction value (see FIG. 3). This effectively reduces the probability that a coefficient is set to zero thus resulting possibly in reduced subjective and even objective performance. Turning to FIG. 2A, the relation between an input signal W and an inverse quantized output signal IV'for a uniform quantizer with step-size A and f=A/2 is indicated generally by the reference numeral 200. Turning to FIG. 2B, the relation between an input signal W and an inverse quantized output signal M/'for a uniform quantizer with step-size A and f=A/4 is indicated generally by the reference numeral 250. Turning to FIG. 3, an impact of 0 = A/4 within a quantization process is indicated generally by the reference numeral 300.<br><br>
SUMMARY OF THE INVENTION<br>
These and other drawbacks and disadvantages of the prior art are addressed by the present invention, which is directed to a method and apparatus for quantization in video encoders and decoders.<br>
According to an aspect of the present invention, there is provided an encoder for encoding video signal data for an image block. The encoder includes a quantizer for receiving transform coefficients for the image block, and for adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
According to another aspect of the present invention, there is provided a method for encoding video signal data for an image block. The method includes the steps of receiving transform coefficients for the image block, and adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
According to yet another aspect of the present invention, there is provided a decoder for decoding video signal data for an image block. The decoder comprises a quantizer for receiving transform coefficients for the image block, and for adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
According to a further aspect of the present invention, there is provided a method for decoding video signal data for an image block. The method includes the steps of receiving transform coefficients for the image block, and adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
These and other aspects, features and advantages of the present invention will become apparent from the following detailed description of exemplary embodiments, which is to be read in connection with the accompanying drawings.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The present invention may be better understood in accordance with the following exemplary figures, in which:<br>
FIG. 1 shows a block diagram for a typical transform based compression system according to the prior art;<br><br>
FIGs. 2A and 2B shows plots of the relations between an input signal Wand an inverse quantized output signal W'for a uniform quantizer with step-size A and f=A/2 and f=A/4, respectively;<br>
FIG. 3 shows a plot of an impact of 0 = A/4 within a quantization process;<br>
FIG. 4 shows plots for a distribution of transform coefficients for intra coded blocks for a high texture SD sequence;<br>
FIG. 5 shows plots for a distribution around level 1 (QP 30);<br>
FIG. 6 shows plots for an error contribution around level 1 (QP 30) for the distribution of FIG. 5;<br>
FIG. 7 shows plots for a distribution around level 1 (QP 24);<br>
FIG. 8 shows plots for an error contribution around level 1 (QP 24) for the distribution of FIG. 7;<br>
FIG. 9 shows plots for a distribution of transform coefficients for inter coded blocks for a high texture SD sequence;<br>
FIG. 10 shows plots for a distribution around inter level 1 (QP 24);<br>
FIG. 11 shows plots for an error contribution around level 1 (QP 24) for the distribution of FIG. 10;<br>
FIG. 12 shows plots for a distribution of transform coefficients for intra coded blocks within a low texture QCIF resolution sequence;<br>
FIG. 13 shows plots for a distribution around intra level 1 (QP 24);<br>
FIG. 14 shows plots for an error contribution around level 1 (QP 24) for the distribution of FIG. 13;<br>
FIG. 15 shows plots for a distribution of transform coefficients for inter coded blocks within a low texture QCIF resolution sequence;<br>
FIG. 16A shows a plot of a distribution around inter level 1 (QP 24);<br>
FIG. 16B shows an error contribution around level 1 (QP 24) for the distribution of FIG. 16A;<br>
FIG. 17 shows a diagram for the computation of fusing right trapezoids;<br>
FIG. 18 shows a plot for the selection of 0 through median selection (area equalization);<br>
FIG. 19 shows a diagram for the computation of 0 using right trapezoids;<br>
Fig. 20 shows a flow diagram for a method for quantization based on transform statistics at the picture level;<br><br>
Fig. 21 shows a flow diagram for a method for quantization based on transform statistics at the picture level;<br>
FIG. 22 shows a block diagram for an encoder with transform coefficient consideration for optimized quantization;<br>
FIG. 23 shows a block diagram for an encoder with theta parameter and transform coefficient consideration for optimized quantization; and<br>
FIG. 24 shows a block diagram for a decoder.<br>
DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS<br>
The present invention is directed to method and apparatus for quantization in video encoders and decoders.<br>
Considering that in transform based image and video coding, AC coefficients tend to have sharp concentrations around zero in their distribution, dead-zone quantization is used in an attempt to achieve good rate-distortion performance. Design of the dead-zone quantization methods is usually performed with the assumption that coefficients follow a Laplacian or Gaussian (Normal) distribution. Unfortunately, in most cases, no consideration of the piecewise distribution (with regards to each corresponding quantization interval) is made, which could result in reduced performance. Furthermore, designs are mostly based on objective measurements that could further lead to visual artifacts and substantially reduced subjective quality. In accordance with the principles of the present invention, several methods are provided that could enable improved subjective quality, and also in many cases objective quality, through adaptively selecting the dead-zone parameters depending on image characteristics, quantization step size, and reconstructed level. Although some of the methods only require consideration within an encoder, other strategies also affect the decoder design, and require that additional information is present within the encoded bitstream.<br>
The present description illustrates the principles of the present invention. It will thus be appreciated that those skilled in the art will be able to devise various arrangements that, although not explicitly described or shown herein, embody the principles of the invention and are included within its spirit and scope.<br>
All examples and conditional language recited herein are intended for pedagogical purposes to aid the reader in understanding the principles of the invention and the concepts contributed by the inventor to furthering the art, and are to<br><br>
be construed as being without limitation to such specifically recited examples and conditions.<br>
Moreover, all statements herein reciting principles, aspects, and embodiments of the invention, as well as specific examples thereof, are intended to encompass both structural and functional equivalents thereof. Additionally, it is intended that such equivalents include both currently known equivalents as well as equivalents developed in the future, i.e., any elements developed that perform the same function, regardless of structure.<br>
Thus, for example, it will be appreciated by those skilled in the art that the block diagrams presented herein represent conceptual views of illustrative circuitry embodying the principles of the invention. Similarly, it will be appreciated that any flow charts, flow diagrams, state transition diagrams, pseudocode, and the like represent various processes which may be substantially represented in computer readable media and so executed by a computer or processor, whether or not such computer or processor is explicitly shown.<br>
The functions of the various elements shown in the figures may be provided through the use of dedicated hardware as well as hardware capable of executing software in association with appropriate software. When provided by a processor, the functions may be provided by a single dedicated processor, by a single shared processor, or by a plurality of individual processors, some of which may be shared. Moreover, explicit use of the term "processor" or "controller" should not be construed to refer exclusively to hardware capable of executing software, and may implicitly include, without limitation, digital signal processor ("DSP") hardware, read-only memory ("ROM") for storing software, random access memory ("RAM"), and non-volatile storage.<br>
Other hardware, conventional and/or custom, may also be included. Similarly, any switches shown in the figures are conceptual only. Their function may be carried out through the operation of program logic, through dedicated logic, through the interaction of program control and dedicated logic, or even manually, the particular technique being selectable by the implementer as more specifically understood from the context.<br>
In the claims hereof, any element expressed as a means for performing a specified function is intended to encompass any way of performing that function including, for example, a) a combination of circuit elements that performs that<br><br>
function or b) software in any form, including, therefore, firmware, microcode or the like, combined with appropriate circuitry for executing that software to perform the function. The invention as defined by such claims resides in the fact that the functionalities provided by the various recited means are combined and brought together in the manner which the claims call for. It is thus regarded that any means that can provide those functionalities are equivalent to those shown herein.<br>
In accordance with the principles of the present invention, various embodiments of an apparatus and method are described for the automatic computation of the quantization parameters, such as the dead-zone, the quantization regions for each level, and quantization weighting matrices, that could be used within a transform based image or video encoder. Also disclosed is a new set of quantization offsetting matrices which may be transmitted to the decoder and which provide additional flexibility within the quantization process and can improve subjective and/or objective quality.<br>
In most research on the subject, it is claimed that the AC coefficient distribution in transform-based codecs tends to be Laplacian. This assumption is also followed within the H.264 codec, which tends to especially impact the design of the quantization process. In particular, the dead-zoning process within the H.264 reference software for a coefficient W\s performed through the consideration of a fixed rounding factor fas follows:<br>
where Zis the mapped quantization level, and A is the quantization step-size. By decreasing /, the dead-zone area around the reconstruction value zero is essentially increased, while also for all other levels the quantization region is equally shifted according to f. This process can be better seen in FIG. 2A and FIG. 2b. fwas selected equal to A/3 for intra slices, and A/6 for inter slices in an attempt to approximate such a Laplacian distribution. Turning to FIGs. 2A and 2B, the relations between an input signal W and an inverse quantized (reconstructed) output signal W for a uniform quantizer with step-size A and f=A/2 and f=A/4, respectively, is Indicated generally by the reference numerals 200 and 250, respectively.<br><br>
It can nevertheless be observed (see, e.g., FIGs. 4 through 16B) that this claim is not always true and is highly content and coefficient dependent. In FIG. 4, an intra transform (4x4) coefficient distribution for a high texture SD sequence is indicated generally by the reference numeral 400. In FIG. 5, the intra coefficient distribution around level 1 (QP 30) for this sequence is indicated generally by the reference numeral 500. FIG. 6 shows the error contribution for the above coefficient distribution around level 1 which is indicated generally by the reference numeral 600. However, FIG. 7 illustrates the intra coefficient distribution around level 1 using a smaller quantizer (QP 24) for this sequence, the intra coefficient distribution being indicated generally by the reference numeral 700. Similar to Fig.6, FIG. 8 shows the error contribution for the above coefficient distribution around level 1 which is indicated generally by the reference numeral 800. In FIG. 9, an inter transform (4x4) coefficient distribution for this high texture SD sequence is indicated generally by the reference numeral 900. For this distribution, FIG. 10 shows the distribution around level 1 (QP 24) which is indicated generally by the reference numeral 1000. Turning to FIG. 11, the error contribution for the above coefficient distribution around level 1 is indicated generally by the reference numeral 1100. In comparison, now turning to FIG. 12, an intra transform (4x4) coefficient distribution for a Low texture QCIF sequence is indicated generally by the reference numerall 200. In FIG. 13, the intra coefficient distribution around level 1 (QP 24) for this sequence is indicated generally by the reference numeral 1300. FIG. 14 shows the error contribution for the above coefficient distribution around level 1 which is indicated generally by the reference numeral 1400. In FIG. 15, an inter transform (4x4) coefficient distribution for this low texture QCIF sequence is indicated generally by the reference numeral 1500. For this distribution, FIG. 16A shows the distribution around level 1 (QP 24) which is indicated generally by the reference numeral 1600. Turning to FIG. 16B, the error contribution for the above coefficient distribution around level 1 is indicated generally by the reference numeral 1650. Note that in these figures, the appropriate scaling for each transform coefficient was also considered. It can be observed that for the low resolution and detail content, such as the QCIF sequence shown in FIGs. 12 through 16B, although distribution of the coefficients may be closer to Laplacian, there is a significant difference from one coefficient to another. Assuming Laplacian distribution, higher order coefficients tend to decay faster (smaller decay rate A or larger variance) than lower order ones. This immediately suggests that coefficients<br><br>
need to be handled differently according to their order, instead of assuming a similar distribution model across frequencies. This becomes even more obvious for high resolution content and in particular film or highly textured content, which could also contain noise (e.g., film grain noise), and could significantly impact the coefficient distribution (FIGs. 4 through 11). Such noise tends to represent itself as a low to medium variance among samples, which itself impacts the distribution in being closer to Gaussian. Apparently, by using the fixed rounding parameter fas is used by the H.264 reference software, even if such is modified according to frequency, this kind of distribution is not properly accounted for, resulting in a non optimal quantization process. It is actually observed that especially for.low to medium quantization parameters (corresponding to very high to medium bitrates) that the piecewise distribution within and near a quantization level (and particularly around level 1) can become in certain cases uniform or close to uniform (FIGs. 5,7,10,13). Under these conditions, the selection of /can be rather critical since an inappropriately large dead-zone could result in more than necessary coefficients being quantized to zero, which could lead to reduced objective, and more significantly subjective quality.<br>
This problem tends to be more critical for H.264 considering that the Baseline, Main, and Extended profiles only allow the use of an integer 4x4 transform. The 4x4 transform, although tends to have some very nice properties such as reduction of blocking and ringing artifacts, bit exact implementation, and so forth, it nevertheless has lower de-correlation properties than an 8x8 transform, while also is more sensitive to quantization decisions. In particular, assuming that it is desired to perform quantization of the following block using a quantizer value (QP) of 26 (/is considered as equal to A/2):<br><br>
then the quantization process would result to the following:<br><br>
(Table Removed)  <br>
It is immediately observed that although the original block is described by high vertical and low horizontal activity and although the QP is not very high, all horizontal activity in the reconstructed block is lost. Although the Mean Square Error (MSE) for this particular block is relatively low (7.625), the subjective impact of this process could be rather severe considering that the perceptual characteristics of this block have been severely altered. More specifically, it is observed that the block after reconstruction tends to be rather structured compared to the original thus making it more noticeable and unpleasant to a viewer.<br>
The above is an immediate consequence of the quantization process, and in particular the assignment of a coefficient to level 0 instead of level 1. if all coefficients either horizontally or vertically are set to zero then the resulting outcome would be as above. Nevertheless, such could be avoided by selectively forcing some coefficients (at least one) in the affected dimension to level one instead of zero. Such a process could be performed in various ways. First of all, it needs to be determined whether such a process is necessary or not. In particular, such a characteristic tends to happen if the column-wise or row-wise variance (i.e., the sum of variances for all rows or columns in a block) is relatively small. Such values can be computed as: <br><br>
where x/j corresponds to the pixel value at row and column / and j respectively. If Ti<column_svar or ts are satisfied then the quantization process could be altered to consider such characteristics. furthermore entire macroblock block variance may considered as follows:></column_svar><br><br>
where £?„ and £?/, are the block height and width respectively. More specifically, different processing can be applied if blockVar corresponds to different value regions, or the values of Tt, T2, T3, and T4, could be adapted accordingly (e.g., using a table lookup that depends on blockVar). It is actually recommended that instead of only collecting distribution statistics for the AC coefficients for the entire image, distribution can be additionally collected for regions with different characteristics allowing for more accurate and refined adaptation of the quantization process.<br>
A rather simple method for introducing artificially horizontal or/and vertical variance (as required) within the 4x4 transform is to enforce or increase the probability that AC coefficients at positions (1,0) or/and (0,1) are set to level 1. This can be done by increasing the value of f for those coefficients only if they were originally found to be zero using the original /value. For example, if the above characteristics are satisfied (vertical or horizontal variance), and assuming that it is desired to retain the (1,0) coefficient if possible, then the following process may be performed:<br>
Compute preliminary level zl() of coefficient Wil0as:<br><br>
where fe (4 &gt;/!i) is selected in a way to increase the priority of this coefficient being mapped at level 1.<br>
where 1\ is a preliminary rounding parameter. If zlifl =0 and the above conditions are satisfied, then the final level z, „ is computed as:<br><br><br>
This embodiment, although it can improve the subjective quality for certain cases, may hurt subjective quality for others, while also it never considers impact on the objective quality. Another approach is to first perform a preliminary quantization for all coefficients. This would basically result in a transform matrix Wand a preliminary quantization matrix Zas follows:<br><br><br>
if for all columns with j&gt;0 the Z,; are zero, or/and all Z/;are zero for i&gt;0, then the coefficient among these Z,tJ that is the best to be set to level 1 in terms of a provided<br>
cost is found. This is a minimization problem where the minimum a function J (similar to Rate distortion optimization techniques) needs to be found such as:<br>
= Distortion, j +A* Cost,;. Distortionij can be set using different distortion metrics such as:<br>
Distortiont] =(W/&gt;; - A)2 or as Distortion^ =|W,j - A| ,<br>
while Costij could represent the actual bitrate cost for modifying one coefficient, or even be equal to the distance from the last non zero coefficient in terms of scanning order and can be described in a matrix form as follows:<br><br>
Note that if both horizontal and vertical coefficients need to be changed (i.e., all coefficients except DC were quantized to zero), then a joint cost from altering either<br><br>
horizontal or vertical coefficients while the other dimension is zero (i.e. coefficients at 0,j or i,0) needs to be considered, while on the other hand, while modifying a single coefficient at a position (i,j) with both i and j larger than zero would have an immediate impact on both dimensions and a single cost could be used.<br>
A similar approach may be followed for transforms larger than 4x4 (i.e. 8x8). For the 8x8 transform for example it might be desirable to retain not only a single horizontal or vertical coefficient, but two of them since that may allow a more realistic reconstruction/representation of the original texture. In such a case, selection of the two (or more) coefficients needs to be again performed jointly (by examining all possible combinations), or for simplicity it may also be tried to first optimize each coefficient separately, while in each step the previous coefficient modification is considered within the cost process. More coefficients could also be retained in similar ways for the 4x4 if necessary. More specifically the process can be performed as follows:<br>
The transform matrix Wand a preliminary quantization matrix Zare again computed as follows:<br>
Based on Z, the cost matrix for changing a single coefficient from level 0 to level 1 is computed.<br><br><br>
The coefficient having the smallest RD based cost:<br><br>
is then modified. This will result in a new matrix Z' with:<br><br><br><br>
The second coefficient that is to be modified is again selected using a criterion such as J,j = Distortion,_y+ A*'Cost^ where now Costij is computed based on the new level<br>
matrix Z'. This process can be repeated as necessary depending on the number of additional coefficients necessary to be retained.<br>
Although the subjective quality can somewhat improve for certain cases using the above methods, an alternative method may nevertheless be employed that can improve both subjective and objective quality by better selecting f% based on the coefficient distribution and through minimizing the generated distortion. As before, the preliminary level ZM, of coefficient Wii0 is again computed as follows:<br><br><br><br>
where f-i is a preliminary rounding parameter.<br>
If Z, 0 = 0 and the above conditions are satisfied, then the final level Z, „ is computed as<br><br><br><br>
where f2 (f2 &gt;/i) is selected in a way to increase the priority of this coefficient being mapped at level 1. Now fz can be computed by examining the distribution of the coefficients. Such a distribution could be collected by performing a pre-analysis of the current data, or by assuming that the current distribution would have similar properties as the distribution as previously coded blocks (in the current or previous pictures) of the same type. Assuming that the preliminary level is Z, the distribution<br><br>
area around this level can be computed. This can be done by either considering the exact statistics of the distribution, or through using the model-based methods (e.g. usage of the Laplacian or Gaussian distribution models). The usual method for determining the optimal quantization point for a given distribution region can be selected as approximately the median point of the distribution (i.e., the point that separates the distribution into two equal sized areas A^ - Ar). It should be noted<br>
that this median point is an approximation, by assuming that the piecewise distribution is almost piecewise linear. A more accurate strategy is to use the Lloyd Max method and find the point that minimizes error. By making the piecewise linear distribution, properties from a right trapezoid (i.e., a trapezoid with two right angles) can be used, which can be seen in FIG. 17, to compute fz:<br>
Turning to FIG. 17, the computation of fusing right trapezoids is indicated generally by the reference numeral 1700. We also have:<br><br>
Note that /and the value within the square root need to be both positive.<br>
Other arithmetic integral methods, such as the Simpson or 3/8 methods, could be used instead of the trapezoid one, although those are slightly more complicated. However, a simpler, although less precise, strategy, is to first compute the areas Az.<br>
and Ap from   ZA-—,ZA   and  ZA,ZA+—   respectively by first setting x~ = jc+ = A.<br>
L      2     J       i	2)<br>
Then /2 =—2-A is selected which, although not optimal, is a good enough solution.<br>
Note that jT = 2x/2 while jt*=2x(l-/2). This method may also be combined with the previously described method of subjectively optimizing coefficients, where though now the Z in that process is computed based on the new f2 value.<br>
The above method nevertheless does not carefully consider the distortion incurred by each quantized value. The area computation is made with approximately an equal assumption of the distortion incurred. Instead a more appropriate method would be to consider the actual distortion within such computation. That is, areas Az.<br>
and Az, should be better computed as:<br>
where distortion(&amp;*Z,x) can be a distortion metric between the reconstructed value AxZ and x, such as square difference, i.e. (AxZ-^j, or absolute difference , i.e., AxZ-jJ. frequency^ corresponds to the number of coefficients which value equal to<br>
x. Again our goal is to make Az..= Aj.. A simple method to achieve such a property would be to first compute Az. and Ar using / =—, and by slowly reducing f find the<br>
first position where such a condition or a condition of the form A^ £ A^. is satisfied. A simple algorithm to perform this process can be as follows:<br>
Step 1:	Set /=—- Compute Az. =  Y distortion(kxZ,x)xfrequency(x) and<br>
distortion(Ay.Z,x)Xfrequency(x)<br>
Step 2:	If Af &gt; AT end process.<br>
Step 3:         Set / = /-1. If / =o, set f=1 and end process.<br>
Step 4:	Set \. = Az.-distortion(&amp;xZ,&amp;xZ-f')xfrequency(AxZ-f') and<br>
^ = AZ&gt; +dwtortion(AxZ,AxZ+A-/)x^-egwency(AxZ +A-/). Goto Step 2.<br>
Although the above methods can improve performance (either objective, subjective, or both) the method of artificially introducing higher levels might not always be desirable since it will not also accurately match the original signal. For this purpose, the prior art introduced a 0 parameter that can be transmitted within the bitstream at certain intervals (i.e., every slice) and that basically introduces a translation (shift) of the reconstruction values of all coefficients (see FIG, 3). Turning to FIG. 3, an impact of 0 = A/4 within a quantization process is indicated generally by the reference numeral 300. It is presumed with respect to FIG. 3 that f = A/4. This is similar to the present invention where certain coefficients are selectively adjusted from zero level to level one. It though differs from the present invention because in the prior art a change is required to the codec standard so that the decoder is aware of such an adjustment and can reconstruct the coefficients more accurately, which is not necessary in the present invention. The method proposed in the prior art does not consider that the AC coefficients (including the DC coefficient) tend to have rather different distributions. Instead a better approach would be to design a matrix 0 that is transmitted with the bitstream, which would allow a finer refinement for each different coefficient. This approach is very similar to the prior art consideration of quantization<br>
matrices within H.264 and other codecs. In the H.264 FRExt specification currently 12 different quantization weighting matrices are allowed, which are basically divided according to transform size (4x4 vs 8x8), color components (Y, U, and V), and prediction type (intra vs. inter), since these are the basic components that can contain rather different distribution characteristics. Similarly, 12 different quantization offsetting matrices can now be defined which, instead of scaling, shift the reconstruction levels. It may be desirable to add additional matrices which need to only be available for Macroblock Adaptive Frame-Field coding, and which will distinguish between field and frame macroblocks. Nevertheless, although all reconstruction values may be shifted, it is observed that the most important one is the one related to level 1. This suggests that it might be better in terms of RD performance to only consider a 6 parameter if the level that is to be reconstructed is level 1. In particular in the prior art it was mentioned that the reconstructed value Wy<br>
can be computed as:<br>
where the V/j parameters originate from the inverse transform process and are related to the quantizer value QP. In our case, wj may now be computed considering also<br>
that now © depends on coefficient position as follows:<br>
Another alternative would be to modify 6 according to the level as follows:<br>
For example, g(®tj,Zg) = Ql} » (Zv -i) may be used.<br>
To compute 0, a similar approach may be used as for the computation of f2. The idea here is to find the position within a quantization interval A corresponding to the median value in terms of distribution, or basically leads to dividing A into two equal area regions (see FIG. 18). Turning to FIG. 18, a plot for the selection of 0 through median selection (area equalization) is indicated generally by the reference numeral 1800. This can be done either manually (i.e., computing the full area, and then finding the point which divides the area in half), through the consideration of the model distribution and by performing integral computations, or through the consideration of simple arithmetic methods. In particular, it is observed again from FIG. 18 that our piecewise distribution resembles again to a right trapezoid as can be seen from FIG. 19. Turning to FIG. 19, a diagram for the computation of © using right trapezoids is indicated generally by the reference numeral 1900. The full area can then be computed as:<br>
A point x=A/2+0 is to be found such as the area is divided into two equal area<br>
regions A/2, that is --(ft, + hj =— .<br>
nevertheless, due to similar triangles properties, is also equal tothus replacing /73 in the above equation results=&gt;<br>
Since the negative sign makes little sense, what is then had is:<br>
Replacing also A, the following is obtained:<br>
0 could also be computed by considering the actual distortion and coefficient frequency similar to what was done for the computation of f. Here though, instead of varying /, the first reconstructed value needs to be varied. That is, the intent is to find a reconstruction value A = A-6  such that/1^ (&amp;,/„)« 4. (A,/O). Again this can be done using a similar strategy as with f as follows:<br>
Stepl:	Set/=-|,0=0.<br>
Step 2:	Compute Aj.=  ^distortions-Q,x)x. frequency(x) and<br>
Step 3:	If Az. £ Ar end process.<br>
Step 3:         Set 0=0+1. If ©— — end process.<br>
Step 4:	Goto Step 2.<br>
To further improve performance and the computation of the 0 values, the number of coefficients set to zero may also be considered. In particular, it may be desirable to limit the percentage of a certain AC coefficient, i.e., the AC coefficient at position (i,j), that is forced to zero. Percentage could be computed at a set of macroblocks, slice, picture, GOP, or even sequence level. Such a decision could be made implicitly by providing a predefined percentage value at the encoder, or automatically by considering certain statistics of the sequence such as variance or distortion if a value is set to zero. If the distribution, suggests that using the current<br>
distribution model this percentage is exceeded considerably, then it would be best to further increase the value of 0 to improve quality. A simple way of considering this property is to find the coefficient value that satisfies this percentage relationship for the zero level, and increase the A value used in the above © computation accordingly. For example, assuming that the zero satisfies a percentage X% at<br>
position y (y<a then a new is used equal to and compute as:></a>
0 could also be constrained such as a £ 0 
having to perform a full integration of the distribution within these areas. In general, the trapezoidal approximation may be used with any interval for computing these areas.<br>
Finally the distribution could also be used for the computation of the quantization weighting matrices. Assuming that the weight coefficients are already known based on perceptual analysis, weighting coefficients can be also scaled by trying to equalize the distribution for all coefficients. This could be performed by considering the following: (a) the maximum value of each coefficient and computing its ratio compared to a given value (e.g. compared to the DC); (b) the maximum available value for each coefficient within a specified percentage (e.g. 95%) of the distribution starting from zero; and (c) the maximum available value for each    . coefficient within a specified distinct percentage P/jof the distribution starting from zero.<br>
Although the distribution of all coefficients could be considered, it is usually better to determine which regions are considered more important in terms of subjective quality (usually regions with low variance characteristics), and only use these regions for such computation. Nevertheless, such could also hurt performance, for the remaining regions, thus an alternative would be to perform these computations for the entire Image and for each region separately, and then combine these results<br><br>
(i.e. using weighted average methods based on importance, i.e. subjective impact, number of occurrence etc., of each region), to compute the final weighting matrices.<br>
Turning to Fig. 20, a method for quantization based on transform statistics at the picture level is generally indicated by the reference numeral 2000. The method 2000 is practiced with respect to encoding of image data.<br>
A begin block 2005 passes control to a function block 2010. The function block 2010 initializes distribution arrays, and passes control to a loop limit block 2015. The loop limit block 2015 begins a picture coding loop, and passes control to a function block 2020. The function block 2020 decides picture level quantization parameters, performs picture decisions, and so forth in preparation for encoding, and passes control to a loop limit block 2025. The loop limit block 2025 begins a macroblock coding loop, and passes control to a function block 2030. The function block 2030 determines/selects the quantization parameter of a current macroblock being processed, and passes control to a loop limit block 2035. The loop limit block 2035 begins a prediction mode loop, and passes control to a function block 2040. The function block 2040 performs intra or inter prediction with respect to the current macroblock, and passes control to a loop limit block 2045. The loop limit block 2045 begins a transform loop for all 4x4 blocks (in the current macroblock being processed), and passes control to a function block 2050. The function block 2050 performs a transform of a current 4x4 block being processed, and passes control to a function block 2055. The function block 2055 quantizes the current 4x4 block using an offset of -Yz to obtain level y for every transform coefficient, and passes control to a function block 2060. The function block 2060 checks the distribution arrays to determine the optimal offset fij based on the level ij quantization parameter and I, j, and passes control to a function block 2065. The function block 2065 requantizes the coefficient at position I, j using fgas the new offset, and passes control to a loop limit block 2070. The loop limit block 2070 ends the transform loop and passes control to a loop limit block 2075. The loop limit block 2075 ends the prediction mode loop and passes control to a function block 2080. The function block 2080 updates the distribution arrays, and passes control to a loop limit block 2085. The loop limit block 2085 ends the MB coding loop and passes control to a loop limit block 2090. The loop limit block 2090 ends the picture coding loop and passes control to an end block 2095.<br><br>
Turning to Fig. 21, a method for quantization based on region consideration is generally indicated by the reference numeral 2100. The method 2100 is practiced with respect to encoding of image data.<br>
A begin block 2105 passes control to a function block 2110. The function block 2110 initializes distribution arrays, and passes control to a loop limit block 2115. The loop limit block 2115 begins a picture coding loop, and passes control to a function block 2120. The function block 2120 decides picture level quantization parameters, performs picture decisions, and so forth in preparation for encoding, and passes control to a function block 2122. The function block 2122 analyzes a scene based on content (e.g., using a region segmentation scheme), and passes control to a loop limit block 2125. The loop limit block 2125 begins a macroblock coding loop, and passes control to a function block 2130. The function block 2130 determines/selects the quantization parameter of a current macroblock being processed, determines the region corresponding to the current macroblock, and passes control to a loop limit block 2135. The loop limit block 2135 begins a prediction mode loop, and passes control to a function block 2140. The function block 2140 performs intra or inter prediction with respect to the current macroblock, and passes control to a loop limit block 2145. The loop limit block 2145 begins a transform loop for all 4x4 blocks (in the current macroblock being processed), and passes control to a function block 2150. The function block 2150 performs a transform of a current 4x4 block being processed, and passes control to a function block 2155. The function block 2155 quantizes the current 4x4 block using an offset of Vz to obtain level yfor every transform coefficient, and passes control to a function block 2160. The function block 2160 checks the distribution arrays for a corresponding region(s) to determine the optimal offset fg based on the level ij quantization parameter and I, j, and passes control to a function block 2165. The function block 2165 requantizes the coefficient at position I, j using \\ as the new offset, and passes control to a loop limit block 2170. The loop limit block 2170 ends the transform loop and passes control to a loop limit block 2175. The loop limit block 2175 ends the prediction mode loop and passes control to a function block 2180. The function block 2180 updates the distribution arrays of the corresponding region(s) and global arrays, if available, and passes control to a loop limit block 2185. The loop limit block 2185 ends the MB coding loop and passes control to a loop limit<br><br>
block 2190. The loop limit block 2190 ends the picture coding loop and passes control to an end block 2195.<br>
Turning to FIG. 22, an encoder with transform coefficient consideration for optimized quantization is generally indicated by the reference numeral 2200.<br>
An input to the encoder 2200 is connected in signal communication with a first input of a region analysis and statistics module 2210, an inverting input of an adder 2215, and with a first input of a motion compensator 2220. An output of the adder 2215 is connected in signal communication with an input of a transformer 2225. A first output of the transformer 2225 is connected in signal communication with a second input of the region analysis and statistics module 2210. An output of the region analysis and statistics module 2210 is connected in signal communication with a first input of a prequantizer 2230. An output of the prequantizer 2230 is connected in signal communication with a first input of a quantizer 2235. A second output of the transformer 2225 is connected in signal communication with a second input of the quantizer 2235. A third output of the transformer 2225 is connected in signal communication with a second input of the prequantizer 2230. An output of the quantizer 2235 is connected in signal communication with a first input of a variable length coder (VLC) 2240 and an input of an inverse quantizer 2245. An output of the VLC 2240 is available as an output of the encoder 2200.<br>
A first output of the motion compensator 2220 is. connected in signal communication with a non-inverting input of the adder 2215 and a first input of an adder 2255. A second input of the motion compensator 2220 is connected in signal communication with a first output of a motion estimation and mode decision module 2250. An output of the inverse quantizer 2245 is connected in signal communication with an input of an inverse transformer 2260. An output of the inverse transformer 2260 is connected in signal communication with a second input of the adder 2255. An output of the adder 2255 is connected in signal communication with an input of a loop filter 2275. An output of the loop filter 2275 is connected in signal communication with an input of a picture reference store 2270. An output of the picture reference store is connected in signal communication with a third input of he motion compensator 2220 and an input of the motion estimation and mode decision module 2250. A second output of the motion estimation and mode decision module 2250 is connected in signal communication with a second input of the VLC 2240.<br><br>
Turning to FIG. 23, an encoder with theta parameter and transform coefficient consideration for optimized quantization is generally indicated by the reference numeral 2300.<br>
An input to the encoder 2300 is connected in signal communication with a first input of a region analysis and statistics module 2310, an inverting input of an adder 2315, and with a first input of a motion compensator 2320. An output of the adder 2315 is connected in signal communication with an input of a transformer 2325. A first output of the transformer 2325 is connected in signal communication with a second input of the region analysis and statistics module 2310. A first output of the region analysis and statistics module 2310 is connected in signal communication with a first input of a prequantizer 2330. An output of the prequantizer 2330 is connected in signal communication with a first input of a quantizer 2335. A second output of the transformer 2325 is connected in signal communication with a second input of the quantizer 2335. A third output of the transformer 2325 is connected in signal communication with a second input of the prequantizer 2230. An output of the quantizer 2335 is connected in signal communication with a first input of a variable length coder (VLC) 2340 and a first input of an inverse quantizer 2345. An output of the VLC 2340 is available as an output of the encoder 2300.<br>
A first output of the motion compensator 2320 is connected in signal communication with a non-inverting input of the adder 2315 and a first input of an adder 2355. A second input of the motion compensator 2320 is connected in signal communication with a first output of a motion estimation and mode decision module 2350. An output of the inverse quantizer 2345 is connected in signal communication with an input of an inverse transformer 2360. An output of the inverse transformer 2260 is connected in signal communication with a second input of the adder 2355. An output of the adder 2355 is connected in signal communication with an input of a loop filter 2375. An output of the loop filter 2375 is connected in signal communication with an input of a picture reference store 2370. An output of the picture reference store is connected in signal communication with a third input of he motion compensator 2320 and an input of the motion estimation and mode decision module 2350. A second output of the motion estimation and mode decision module 2350 is connected in signal communication with a second input of the VLC 2340.<br>
A second output of the region analysis and statistics module 2310 is connected in signal communication with an input of a theta derivation module 2380.<br><br>
A first output of the theta derivation module 2380 is connected in signal communication with a second input of the inverse quantizer 2345. A second output of the theta derivation module 2380 is connected in signal communication with a third input of the prequantizer 2330, a third input of a quantizer 2335, and with a third input of the VLC 2340.<br>
Turning to FIG. 24, a decoder is generally indicated by the reference numeral 2400. An input of the decoder 2400 is connected in signal communication to an input of a theta derivation module 2480 and to an input of a variable length decoder (VLD) 2440. An output of the theta derivation module 2480 is connected in signal communication with a first input of an inverse discrete cosine transform (IDCT) module 2499. A first output of the VLD 2440 is connected in signal communication with a first input of a motion compensator 2420. A second output of the VLD 2440 is connected in signal communication with an input of a quantizer 2435. An output of the quantizer 2435 is connected in signal communication with a second input of the IDCT module 2499. An output of the ICDT module 2499 is connected in signal communication with a first input of an adder 2488. An output of the motion compensator 2420 is connected in signal communication with a second input of the adder 2488. An output of the adder 2488 is connected in signal communication with an input of a loop filter 2477. An output of the loop filter 2477 is connected in signal communication with an input of a frame buffer 2466. A first output of the frame buffer 2466 is connected in signal communication with a second input of the motion compensator 2420. A second output of the frame buffer 2466 is available as an output of the decoder 2400.<br>
A description will now be given of some of the many attendant advantages/features of the present invention, according to various illustrative embodiments of the present invention. For example, one advantage/feature is an encoding apparatus and method in which dead-zone quantization is performed adaptively by considering coefficient position and associated distribution. Another advantage/feature is the encoding apparatus and method as described above, wherein adaptation is performed depending on at least one of coding mode (intra or inter), color component, transform size, and if necessary field and frame macroblock coding modes. Yet another advantage/feature is the encoding apparatus and method with adaptation as described above, wherein distribution statistics are collected separately for each different case. A further advantage/feature is the encoding<br><br>
apparatus and method with adaptation as described above, wherein distribution statistics are collected based on region characteristics (variance, edges, and so forth). A still further advantage/feature is the encoding apparatus and method as described above, wherein dead-zone quantization is performed in a two step method, first to determine a preliminary level using a fixed dead-zone/ rounding control, and then based on this level repeat the quantization using a level dependent dead-zone/ rounding control. Also, another advantage/feature is the encoding apparatus and method with 2-step dead-zone quantization as described above, wherein the level dependent rounding control is computed based on the piecewise distribution within that level. Moreover, another advantage/feature is the encoding apparatus and method with 2-step dead-zone quantization and level dependent rounding control as described above, wherein computation is performed using distribution concentrations (distribution areas) within the reconstruction area.   Further, another advantage/feature is the encoding apparatus and method with 2-step dead-zone quantization and also with level dependent rounding control, wherein arithmetic integral methods, such as the trapezoid or simplex approximation methods are used to compute the level dependent rounding control. Additionally, another advantage/feature is the encoding apparatus and method with 2-step dead-zone quantization as described above, wherein distortion is also considered within the computation. Moreover, another advantage/feature is the encoding apparatus and method as described above, wherein certain coefficients originally set to level zero are instead forced to a higher level, in an attempt to improve subjective quality. Also, another advantage/feature is the encoding apparatus and method with coefficient level forcing as described above, wherein such decision is based on Rate Distortion Optimized criteria. Further, another advantage/feature is the encoding apparatus and method as described above, wherein dead-zone quantization is refined through the transmission and consideration of a set of offsetting quantization matrices 0. Also, another advantage/feature is the encoding apparatus and method with dead-zone quantization refined through offsetting matrices as described above, wherein 6 values have different impact at different levels. Moreover, another advantage/feature is the encoding apparatus and method with dead-zone quantization refined through offsetting matrices as described above, wherein G is computed based on image statistics and coefficient distributions. Further, another advantage/feature is the encoding apparatus and method with dead-zone quantization refined through<br><br>
offsetting matrices and 0 computed based on image statistics and coefficient distribution as described above, wherein 6 is computed using distribution concentrations (distribution areas) within the reconstruction area. Additionally, another advantage/feature is the encoding apparatus and method with dead-zone quantization refined through offsetting matrices and © computed based on image statistics and coefficient distribution and on distribution concentrations as described above, wherein arithmetic integral methods, such as the trapezoid or simplex approximation methods are used to compute G. Further, another advantage/feature is the encoding apparatus and method with dead-zone quantization refined through offsetting matrices and © computed based on image statistics and coefficient distribution and on distribution concentrations as described above, wherein distortion is also considered for the computation of ©. Moreover, another advantage/feature is the encoding apparatus and method with dead-zone quantization refined through offsetting matrices as described above, wherein © computation can be adjusted depending on the maximum percentage of coefficients allowed to be coded using level zero. A still further advantage/feature is the encoding apparatus and method as described above, wherein dead-zone quantization considers weighted quantization matrices that are computed based on the distribution characteristics for all coefficients.  Another advantage/feature is the encoding apparatus and method with adaptation, distribution statistic collection based on region characteristics, and dead-zone quantization with weighted matrices computer based on distribution characteristics for all coefficients as described above, wherein only distribution of "most significant regions" is considered for this computation.   Moreover, another advantage/feature is the encoding apparatus and method with adaptation, distribution statistic collection based on region characteristics, and dead-zone quantization with<br>
/<br>
weighted matrices computer based on distribution characteristics for all coefficients as described above, wherein all different regions are considered for the computation of weighted matrices through the use of a weighted averaging method based on subjective impact and occurrence statistics.<br>
These and other features and advantages of the present invention may be readily ascertained by one of ordinary skill in the pertinent art based on the teachings herein. It is to be understood that the teachings of the present invention may be implemented in various forms of hardware, software, firmware, special purpose processors, or combinations thereof.<br><br>
Most preferably, the teachings of the present invention are implemented as a combination of hardware and software. Moreover, the software is preferably implemented as an application program tangibly embodied on a program storage unit. The application program may be uploaded to, and executed by, a machine comprising any suitable architecture. Preferably, the machine is implemented on a computer platform having hardware such as one or more central processing units ("CPU"), a random access memory ("RAM"), and input/output ("I/O") interfaces. The computer platform may also include an operating system and microinstruction code. The various processes and functions described herein may be either part of the microinstruction code or part of the application program, or any combination thereof, which may be executed by a CPU. In addition, various other peripheral units may be connected to the computer platform such as an additional data storage unit and a printing unit.<br>
It is to be further understood that, because some of the constituent system components and methods depicted in the accompanying drawings are preferably implemented in software, the actual connections between the system components or the process function blocks may differ depending upon the manner in which the present invention is programmed. Given the teachings herein, one of ordinary skill in the pertinent art will be able to contemplate these and similar implementations or configurations of the present invention.<br>
Although the illustrative embodiments have been described herein with reference to the accompanying drawings, it is to be understood that the present invention is not limited to those precise embodiments, and that various changes and modifications may be effected therein by one of ordinary skill in the pertinent art without departing from the scope or spirit of the present invention. All such changes and modifications are intended to be included within the scope of the present invention as set forth in the appended claims.<br><br>
1.	An encoder for encoding video signal data for an image block,<br>
comprising:<br>
a quantizer (2335) for receiving transform coefficients for the image block, and for adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
2.	The encoder as defined in Claim 1, wherein said quantizer (2335)<br>
adaptively performs dead-zone quantization depending upon at least one of coding<br>
mode, color component, and transform size.<br>
3.	The encoder as defined in Claim 1, wherein said quantizer (2335)<br>
adaptively performs dead-zone quantization depending upon at least one of field and<br>
frame macroblock coding modes.<br>
4.	The encoder as defined in Claim 2, wherein distribution "characteristics<br>
for the coefficient distributions are collected separately for dead-zone quantization<br>
adaptively performed using each of coding mode, color component, and transform<br>
size, respectively.<br>
5.	The encoder as defined in Claim 2, wherein distribution statistics for the<br>
coefficient distributions are collected based on region characteristics.<br>
6.	The encoder as defined in Claim 5, wherein the region characteristics<br>
include motion, texture, color, variance and edge information.<br>
7.	The encoder as defined in Claim 1, wherein said quantizer (2335)<br>
adaptively performs the dead-zone quantization by determining a preliminary<br>
quantization level using a fixed dead-zone/rounding control, and repeating the dead-<br>
zone quantization based on the preliminary quantization level and using a level<br>
dependent dead-zone/rounding control.<br><br>
8.	The encoder as defined in Claim 7, wherein said quantizer (2335)<br>
computes the level dependent dead-zone/rounding control based upon a piecewise<br>
distribution within a corresponding level.<br>
9.	The encoder as defined in Claim 8, wherein said quantizer (2335)<br>
computes the level dependent dead-zone/rounding control using distribution<br>
concentrations with a reconstructed area of the image block.<br>
10.	The encoder as defined in Claim 7, wherein said quantizer (2335)<br>
computes the level dependent dead-zone/rounding control using an arithmetic<br>
integral process.<br>
11.	The encoder as defined in Claim 10, wherein the arithmetic integral<br>
process comprises at least one of a trapezoid approximation process and a simplex<br>
approximation process.<br>
12.	The encoder as defined in Claim 7, wherein said quantizer (2335)<br>
computes the level dependent dead-zone/rounding control based on distortion<br>
present in the transform coefficients.<br>
13.	The encoder as defined in Claim 1, wherein said quantizer (2335)<br>
forces at least some of the transform coefficients to a higher quantization level to<br>
improve subjective quality, when the at least some of the transform coefficients were<br>
originally set to a level zero.<br>
14.	The encoder as defined in Claim 13, wherein said quantizer (2335)<br>
determines whether to force the at least some of the transform coefficients to the<br>
higher level based on rate distortion optimized criteria.<br>
15.	The encoder as defined in Claim 1, wherein said quantizer (2335)<br>
refines the dead-zoning quantization through transmission and use of a set of<br>
offsetting quantization matrices.<br><br>
16.	The encoder as defined in Claim 15, wherein values within the offsetting<br>
quantization matrices have different impacts at different quantization levels.<br>
17.	The encoder as defined in Claim 15, wherein the offsetting quantization<br>
matrices are computed based on image statistics for the image block and the<br>
coefficient distributions of the transform coefficients for the image block.<br>
18.	The encoder as defined in Claim 17, wherein the offset quantization<br>
matrices are computed using distribution concentrations within a reconstructed area<br>
of the image block.<br><br>
19.	The encoder as defined in Claim 18, wherein the offsetting quantization<br>
matrices are computed using an arithmetic integral process.<br>
20.	The encoder as defined in Claim 19, wherein the arithmetic integral<br>
process comprises at least one of a trapezoid approximation process and a simplex<br>
approximation process.<br>
21.	The encoder as defined in Claim 18, wherein the offsetting quantization<br>
matrices are computed also based on distortion.<br>
22.	The encoder as defined in Claim 15, wherein a computation of the<br>
offsetting quantization matrices is adjusted depending upon a maximum percentage of<br>
transform coefficients allowed to be coded using level zero.<br>
23.	The encoder as defined in Claim 1, wherein said quantizer (2335)<br>
performs the dead-zone quantization using offsetting quantization matrices that are<br>
computed based on distribution characteristics for all of the transform coefficients and<br>
weighted quantization matrices.<br>
24.	The encoder as defined in Claim 23, wherein the offsetting quantization<br>
matrices are computed using a distribution of only most significant image regions<br>
designated based on predefined significance criteria.<br><br>
25.	The encoder as defined in Claim 23, wherein the offsetting quantization<br>
matrices are computed based on at least some different image regions using a<br>
weighted averaging method that is based on a subjective impact of each of the<br>
different image regions and corresponding occurrence statistics.<br>
26.	A method for encoding video signal data for an image block, comprising<br>
the steps of:<br>
receiving transform coefficients for the image block; and adaptively performing (2155) dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
27.	The method as defined in Claim 26, wherein the dead-zone<br>
quantization is adaptively performed depending upon at least one of coding mode,<br>
color component, and transform size.<br>
28.	The method as defined in Claim 26, wherein the dead-zone<br>
quantization is adaptively performed depending upon at least one of field and frame<br>
macroblock coding modes.<br>
29.	The method as defined in Claim 27, further comprising the step of<br>
separately collecting distribution characteristics for the coefficient distributions when<br>
the dead-zone quantization is adaptively performed using each of coding mode, color<br>
component, and transform size, respectively.<br>
30.	The method as defined in Claim 27, wherein distribution statistics for<br>
the coefficient distributions are collected based on region characteristics.<br>
31.	The method as defined in Claim 30, wherein the region characteristics<br>
include motion, texture, color, variance and edge information.<br>
32.	The method as defined in Claim 26, wherein said step of adaptively<br>
performing the dead-zone quantization comprises the steps of:<br>
initially performing (2130) the dead-zone quantization by determining a preliminary quantization level using a fixed dead-zone/rounding control; and<br><br>
repeating (2165) the dead-zone quantization based on the preliminary quantization level and using a level dependent dead-zone/rounding control.<br>
33.	The method as defined in Claim 32, further comprising the step of<br>
computing (2160) the level dependent dead-zone/rounding control based upon a<br>
piecewise distribution within a corresponding level.<br>
34.	The method as defined in Claim 33, further compn'sing the step of<br>
computing the level dependent dead-zone/rounding control using distribution<br>
concentrations with a reconstructed area of the image block.<br>
35.	The method as defined in Claim 32, further comprising the step of<br>
computing the level dependent dead-zone/rounding control using an arithmetic<br>
integral process.<br>
36.	The method as defined in Claim 35, wherein the arithmetic integral<br>
process comprises at least one of a trapezoid approximation process and a simplex<br>
approximation process.<br>
37.	The method as defined in Claim 32, further comprising the step of<br>
computing the level dependent dead-zone/rounding control based on distortion<br>
present in the transform coefficients.<br>
38.	The method as defined in Claim 26, further comprising the step of<br>
forcing at least some of the transform coefficients to a higher quantization level to<br>
improve subjective quality, when the at least some of the transform coefficients were<br>
originally set to a level zero.<br>
39.	The method as defined in Claim 38, wherein said forcing step<br>
comprises the step of determining whether to force the at least some of the transform<br>
coefficients to the higher level based on rate distortion optimized criteria.<br><br>
40.	The method as defined in Claim 26, further comprising the step of<br>
refining the dead-zoning quantization through transmission and use of a set of<br>
offsetting quantization matrices.<br>
41.	The method as defined in Claim 40, wherein values within the offsetting<br>
quantization matrices have different impacts at different quantization levels.<br>
42.	The method as defined in Claim 40, further comprising the step of<br>
computing the offsetting quantization matrices based on image statistics for the<br>
image block and the coefficient distributions of the transform coefficients for the<br>
image block.<br>
43.	The method as defined in Claim 42, wherein said computing step<br>
computes the offset quantization matrices using distribution concentrations within a<br>
reconstructed area of the image block.<br><br>
44.	The method as defined in Claim 43, wherein said computing step<br>
computes the offsetting quantization matrices using an arithmetic integral process.<br>
45.	The method as defined in Claim 44, wherein the arithmetic integral<br>
process comprises at least one of a trapezoid approximation process and a simplex<br>
approximation process.<br>
46.	The method as defined in Claim 43, wherein said computing step<br>
computes the offset quantization matrices based on distortion.<br>
47.	The method as defined in Claim 40, further comprising the step of<br>
adjusting a computation of the offsetting quantization matrices depending upon a<br>
maximum percentage of transform coefficients allowed to be coded using level zero.<br>
48.	The method as defined in Claim 26, wherein said step of adaptively<br>
performing the dead-zone quantization uses quantization offsetting matrices that are<br>
computed based on distribution characteristics for all of the transform coefficients.<br><br>
49.	The method as defined in Claim 48, further comprising the step of<br>
computing the offsetting quantization matrices using a distribution of only most<br>
significant image regions designated based on predefined significance criteria.<br>
50.	The method as defined in Claim 48, further comprising the step of<br>
computing the offsetting quantization matrices based on at least some different image<br>
regions using a weighted averaging method that is based on a subjective impact of<br>
each of the different image regions and corresponding occurrence statistics.<br>
51.	A decoder for decoding video signal data for an image block,<br>
comprising:<br>
a quantizer (2435) for receiving transform coefficients for the image block, and for adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
52.	The decoder as defined in Claim 51, wherein said quantizer (2435)<br>
adaptively performs dead-zone quantization depending upon at least one of coding<br>
mode, color component, and transform size.<br>
53.	The decoder as defined in Claim 51, wherein said quantizer (2435)<br>
adaptively performs dead-zone quantization depending upon at least one of field and<br>
frame macroblock coding modes.<br>
54.	The decoder as defined in Claim 51, wherein said quantizer (2435)<br>
refines the dead-zoning quantization through transmission and use of a set of<br>
offsetting quantization matrices.<br>
55.	The decoder as defined in Claim 54, wherein values within the offsetting<br>
quantization matrices have different impacts at different quantization levels.<br>
56.	A method for decoding video signal data for an image block, comprising<br>
the steps of:<br>
receiving transform coefficients for the image block; and<br><br>
adaptively performing dead-zone quantization based on coefficient positions and coefficient distributions of the transform coefficients.<br>
57.	The method as defined in Claim 56, wherein the dead-zone<br>
quantization is adaptively performed depending upon at least one of coding mode,<br>
color component, and transform size.<br>
58.	The method as defined in Claim 56, wherein the dead-zone<br>
quantization is adaptively performed depending upon at least one of field and frame<br>
macroblock coding modes.<br>
59.	The method as defined in Claim 56, further comprising the step of<br>
refining the dead-zoning quantization through transmission and use of a set of<br>
offsetting quantization matrices.<br>
60.	The method as defined in Claim 59, wherein values within the offsetting<br>
quantization matrices have different impact at different quantization levels.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjctMTAtMjAxNF9BbWVuZGVkIGNsYWltc19DbGVhbi5wZGY=" target="_blank" style="word-wrap:break-word;">27-10-2014_Amended claims_Clean.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjctMTAtMjAxNF9PdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">27-10-2014_Others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjctMTAtMjAxNF9TRVIgUmVwbHkucGRm" target="_blank" style="word-wrap:break-word;">27-10-2014_SER Reply.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjctMTAtMjAxNF9zcGVjLnBkZg==" target="_blank" style="word-wrap:break-word;">27-10-2014_spec.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LUFic3RyYWN0LSgyMS0wMi0yMDE0KS5wZGY=" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-Abstract-(21-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWFzc2lnbm1lbnRzLnBkZg==" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-assignments.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LUNsYWltcy0oMjEtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-Claims-(21-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMjEtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-Correspondence Others-(21-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1ERUxOUC0yMDA2LUNvcnJlc3BvbmRlbmNlLU90aGVycyAoMDYtMDQtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">7369-DELNP-2006-Correspondence-Others (06-04-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1ERUxOUC0yMDA2LUZvcm0tMTggKDA2LTA0LTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">7369-DELNP-2006-Form-18 (06-04-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LUZvcm0tMi0oMjEtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-Form-2-(21-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LUZvcm0tMy0oMjEtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-Form-3-(21-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1ERUxOUC0yMDA2LUZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">7369-DELNP-2006-Form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LXBjdC0yMjAucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-pct-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LXBjdC0yMzcucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-pct-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LXBjdC0zMDYucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-pct-306.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LXBjdC1yZXF1ZXN0IGZvcm0ucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-pct-request form.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LXBjdC1zZWFyY2ggcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-pct-search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NzM2OS1kZWxucC0yMDA2LVBldGl0aW9uLTEzNy0oMjEtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">7369-delnp-2006-Petition-137-(21-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QuanBn" target="_blank" style="word-wrap:break-word;">abstract.jpg</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=QW1lbmRlZCBjbGFpbXNfQ2xlYW4ucGRm" target="_blank" style="word-wrap:break-word;">Amended claims_Clean.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=T3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">Others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=U0VSIFJlcGx5LnBkZg==" target="_blank" style="word-wrap:break-word;">SER Reply.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=c3BlYy5wZGY=" target="_blank" style="word-wrap:break-word;">spec.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="264114-fixtures-for-mounting-speakers-in-ceiling.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="264116-method-for-thickening-and-thickening-apparatus.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>264115</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>7369/DELNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>50/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>12-Dec-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>08-Dec-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>06-Dec-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON LICENSING</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46, QUAI A. LE GALLO, F-92100 BOULOGNE-BILLANCOURT (FR)</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>TOURAPIS, ALEXANDROS, MICHAEL</td>
											<td>1550 VISTA CLUB CIRCLE, #304, SANTA CLARA, CALIFORNIA 95054 (US)</td>
										</tr>
										<tr>
											<td>2</td>
											<td>BOYCE, JILL, MACDONALD</td>
											<td>3 BRANDYWINE COURT, MANALAPAN, NEW JERSEY 07726 (US)</td>
										</tr>
										<tr>
											<td>3</td>
											<td>YIN, PENG</td>
											<td>65 WARWICK ROAD, WEST WINDSOR, NEW JERSEY 08550 (US)</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26, H04N 7/50</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2005/019647</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-06-03</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/581,019</td>
									<td>2004-06-18</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/264115-method-and-apparatus-for-video-codec-quantization by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 23:46:29 GMT -->
</html>
