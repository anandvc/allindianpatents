<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/230482-method-of-encoding-a-sequence-of-pictures-and-apparatus-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 11:15:58 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 230482:METHOD OF ENCODING A SEQUENCE OF PICTURES AND APPARATUS THEREOF</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD OF ENCODING A SEQUENCE OF PICTURES AND APPARATUS THEREOF</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The present invention relates to a method of encoding a sequence of pictures, a picture being divided into blocks of data, said encoding method comprising the steps of: - computing a residual error block from a difference between a current block contained in a cuqent picture and a candidate area using of a prediction function, -computing an entropy of the residual error block, -computing an overall error between said current block and said candidate area, -estimating a power consumption of a video processing device adapted to implement said prediction function, -computing a rate-distortion value on the basis of the entropy, the overall error and the estimated power consumption of the video processing device, -applying the preceding steps to a set of candidate areas using a set of pre,diction functions in order to select a prediction function according to the rate- distortion value.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
lYit-uiuu ui encoding ior nanaaeia apparatus<br>
FIELD OF THE INVENTION<br>
The present invention relates to a method of encoding a sequence of pictures, a picture being divided into blocks of data, said method being based on a predictive block-based encoding technique.<br>
This invention is particularly relevant for products embedding a digital video encoder such as, for example, home servers, digital video recorders, camcorders, and more particularly mobile phones or personal digital assistants, said apparatus comprising an embedded camera able to acquire and to encode video data before sending it.<br>
BACKGROUND OF THE INVENTION<br>
In a conventional video encoder, most of the memory transfers and, as a consequence, a large part of the power consumption, come from motion estimation. Motion estimation consists in searching for the best match between a current block and a set of several candidate reference blocks according to a rate distortion criterion, a difference between the current block and a candidate reference block forming a residual error block.<br>
The paper entitled "Rate Distortion Optimization for Video Compression", by G. Sullivan, T. Wiegand, IEEE Signal Processing Magazine, pp. 74-90, Nov. 1998 describes a method of computing a rate-distortion value. This value c is computed from an entropy h of the residual error block and on a reconstruction error mse derived from said residual error block, as given by equation (1):<br><br>
where X\ is a weighting coefficient.<br>
This helps for selecting the best mode to encode the current block according to an expected bit-rate. The best reference block that is selected is the one that minimizes the rate-distortion value. Then the residual error block is entropy coded and transmitted with its associated motion vector and/or encoding mode.<br>
But such a rate-distortion value is not optimal, especially in the case of a video encoder embedded in a portable apparatus having limited power.<br>
SUMMARY OF THE INVENTION<br><br>
It is an object of the invention to propose an encoding method, which allows the power consumption of a video processing device, i.e. a video decoder or a video encoder, to be reduced.<br>
To this end, the video encoding method in accordance with the invention is characterized in that it comprises the steps of:<br>
computing a residual error block from a difference between a current block contained in a current picture and a candidate area using a prediction function,<br>
computing an entropy of the residual error block,<br>
computing an overall error between said current block and said candidate area,<br>
estimating a power consumption of a video processing device adapted to implement said prediction function,<br>
computing a rate-distortion value on the basis of the entropy, the overall error and the estimated power consumption of the video processing device,<br>
applying the preceding steps to a set of candidate areas using a set of prediction functions in order to select a prediction function according to the rate-distortion value.<br>
As a consequence, the invention is able to select, at the encoding stage, the prediction function, i.e. the best encoding mode, from among all available ones thanks to a new rate-distortion value taking into account the power consumption of the prediction process. In other words, the classical rate-distortion value receives an estimation of the power consumption as a third dimension, to become a power-rate-distortion value, allowing a better tradeoff between power consumption, bit-rate or bandwidth, and visual quality.<br>
According to a first embodiment of the invention, the rate-distortion value takes into account an estimated power consumption of the prediction functions by a video decoder for decoding the corresponding encoded sequence of pictures, by favoring power-friendly prediction functions.<br>
According to another embodiment of the invention, the rate-distortion value takes into account the power consumption required by the video encoder in order to perform the prediction.<br>
The present invention also relates to a video encoder implementing said video encoding method.<br>
It relates to a handheld apparatus comprising said video encoder and a power supply for supplying said video encoder.<br><br>
It finally relates to a computer program product comprising program instructions for implementing, when said program is executed by a processor, the video encoding method in accordance with the invention.<br>
These and other aspects of the invention will be apparent from and will be elucidated with reference to the embodiments described hereinafter.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The present invention will now be described in more detail, by way of example, with reference to the accompanying drawings, wherein:<br>
Fig. 1 is a block diagram of a conventional video encoder,<br>
Fig. 2 is a block diagram of a conventional video decoder,<br>
Fig. 3 is a block diagram showing the encoding method in accordance with the invention,<br>
Fig. 4 represents a current block and its neighborhood, from which spatial prediction functions are computed,<br>
Fig. 5 represents two blocks in two successive frames, from which a temporal prediction function is computed,<br>
Fig. 6 represents a histogram of a block in a past frame, from which a temporal prediction function is computed for a current collocated block.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
The present invention relates to a method for adapting the encoding process, and more especially the prediction step, as a function of the power consumption of a video encoder and/or decoder. The encoding process is adapted to take into account, for example, the battery level of said encoder and/or decoder.<br>
Said method is more especially dedicated to handheld devices, such as mobile phones or embedded cameras, which have limited power, and that have to deal with the encoding and decoding of video sequences.<br>
It can be used within MPEG-4 or H.264 video encoder, or any equivalent rate-distortion-based video encoder. The method can be extended to audio, and still images encoding/decoding.<br>
The present invention is based on the following considerations. Let us consider a conventional video architecture comprising a central processing unit CPU, coupled with a dedicated co-processor, and an external memory module. For years, the central processing<br><br>
unit CPU has been considered as the greediest of these three elements in terms of power consumption, implying that the computational complexity of an algorithm also determined its energy consumption. Now, the repartition is more balanced between the computational load and the memory accesses. And given the current evolution, a predominance of the latter can be foreseen soon. Consequently, having such architecture in mind, low-power applications require a significant reduction of memory accesses compared to current algorithms. Furthermore, the locality of these accesses is important too, because a memory module closer to the CPU means less energy dissipation when accessing data.<br>
In the case of a conventional video encoder as depicted in Fig. 1, the above-described elements are adapted to perform Discrete Cosine Transformation DCT (11), scalar quantization Q (12), variable length coding VLC (13), inverse quantization IQ (14), Inverse Discrete Cosine Transformation IDCT (15), motion compensation MC (16) and motion estimation ME (18). The motion compensation and motion estimation modules are coupled to the external frame memory module MEM (17).<br>
In the case of a conventional video encoder as depicted in Fig. 2, the above-described elements are adapted to perform variable length coding VLD (21), inverse quantization IQ (22), Inverse Discrete Cosine Transformation IDCT (22), motion compensation MC (24) and block reconstruction REC (25). The motion compensation module is coupled to the external frame memory module MEM (26).<br>
The bottleneck in terms of power consumption is the amount of transfers between the different units of these video architectures. The present invention is based on the observation that most of the memory transfers come from motion estimation and motion compensation. These motion operations represent many accesses to pixels, and so to the external memory module. The larger the search range, the larger the size of the memory and consequently the power dissipation.<br>
According to the present invention, the objective is to select, at the encoding stage, the best prediction function among available ones, by also taking into account the power consumption of the prediction process. The present invention proposes three different cases in which the use of a new rate-distortion criterion can increase the overall power-consumption/bit-rate/visual quality tradeoff, either at the decoder level, or at the encoder level, or for both.<br><br>
Fig. 3 is a block diagram showing the encoding method in accordance with the invention. Said method is able to encode a sequence of pictures, a picture being divided into blocks of data.<br>
It comprises a first step ReseC (33) of computing a residual error block from a I     difference between a current block contained in a current picture and one candidate area thanks to the use of a prediction function.<br>
The prediction function is chosen among a set of prediction functions. A prediction function is defined as a way to predict, in a current frame, a current block, i.e. the one that is intended to be encoded, based on pixels from other areas, located either in the same frame, or in a previous or future frame.<br>
A prediction function of the set is, for example, based on conventional motion estimation. Said conventional motion estimation consists in searching for a candidate reference block within in a reference picture, i.e. a past or future picture, said block corresponding to a current block contained in a current picture. Said candidate reference block, i.e. the candidate area, is searched within a predetermined area of the reference picture called the search area. In the example of the MPEG2 standard, the search area is limited to 256 lines for decoding. It will be apparent to a person skilled in the art that the size of the search area can be reduced depending on the computational resources.<br>
Another prediction function pfl is based on H.264 Intra Prediction. For a given pixel x(i,j) in a current block X to encode, a residual value r(i j) is computed from the left-adjacent column A and the top-adjacent line B of the block X, as described in Fig. 4, A and B forming in this example the candidate area. The residual value r(i j) is computed as follows:<br>
r(i,j) = x(i,j)-avg(A,B),<br>
where avg(A,B) is a function able to compute the average value of the segments A and B. This first prediction function is particularly adapted to homogeneous areas.<br>
Another prediction function pf2 is based on H.264 Intra Vertical Prediction. With the notations given in Fig. 4, the residual value is computed as follows:<br>
r(i,j) = x(i,j)-b(i).<br>
This spatial prediction function is particularly adapted to vertically homogeneous areas.<br>
Another prediction function pf3 is based on H.264 Intra Horizontal Prediction. With the notations given in Fig. 4, the residual value is computed as follows:<br>
r(i,j) = x(i,j)-a(j). This spatial prediction function is particularly adapted to horizontally homogeneous areas.<br><br>
Several other spatial predictions are also possible. They have in common to only use A and B segments, or to apply invertible functions on X, in order to be decodable.<br>
Another prediction function pf4 is based on Fig. 5 representing a block X of pixels x(i,j) in a current frame F(t) and a corresponding block Y of pixels y(ij) having the same position in the immediately past frame F(t-l), the block Y forming in this case the candidate area. This function is called "Collocated Temporal Prediction". With the notations given in Fig. 5, the residual value is computed as follows:<br><br>
This temporal prediction function is particularly adapted to static areas.<br>
An extension of this prediction function called "Collocated Restricted Motion Estimation"<br>
and for which motion estimation is performed within the collocated block only can also be<br>
used.<br>
Another prediction function pf5, called "Temporal Histogram Prediction", uses a histogram of the collocated block in the previous frame. If, for example, hi and h2 are two maximums of the histogram, as given in Fig. 6, the residual value is computed as follows:<br>
r(i, j) = x(i, j) - hi or r(i, j) = x(i, j) - h2,<br>
depending on the proximity of the value x(ij) with the values hi and h2. For that purpose, one bit is transmitted to inform the decoder of this choice. This temporal prediction function is also adapted to static areas.<br>
The present invention is based on the fact that these different prediction functions have different power consumptions. For example temporal prediction functions are more power consuming than spatial prediction functions, as they require many accesses to the external memory module containing reference frames.<br>
It is to be noted that these prediction functions are depicted as an example and that other prediction functions can be used without departing from the scope of the invention. It is also to be noted that the concurrent prediction functions can be applied to data blocks having different size, such as for example 16x16, 16x8, 8x16, 8x8, 8x4, 4x8 or 4x4 pixels.<br>
The encoding method comprises a second step HC (34) of computing an entropy h of the residual error block. Said step is able to determine the minimal number of bits necessary for the entropy coding of the residual error block. The entropy h is computed according to a principle known to a person skilled in the art, using the following formula:<br><br><br>
where pi is the probability of a data value to be present in a block of pixels and I is typically equal to 255 if pixel values are 8-bit values.<br>
The encoding method comprises a third step MetC (32) of computing an overall error between the current block and the candidate area.<br>
The step of computing an overall error is based, for example, on the computing of the mean square error MSE, the expression of the MSE being:<br><br>
where k x 1 is the size of the current block.<br>
The computing step is based, as another example, on the computing of the mean absolute error MAE, the expression of the MAE being:<br><br>
It will be apparent to a person skilled in the art that the overall error can be computed by using other different functions based on values of the current block and values of the candidate area.<br>
The encoding method comprises a fourth step PowC (37) of estimating a power consumption of a video processing device, i.e. a video encoder or decoder, adapted to implement the prediction function. The estimation is performed as a function of the following parameters.<br>
The estimation step is able to estimate the power consumption of the video processing device from a set of parameters SoP (36). These power consumption parameters are of course the characteristics of the prediction functions, that is to say the computational and transfer parameters of the prediction function. The computational parameters are for example:<br>
the amount of operations (addition, multiplication, etc)<br>
the amount of conditional jumps and basic functions, such as computing of absolute values, minimum values, maximum values, etc. The transfer parameters are for example:<br>
the memory requirements (type, size, etc),<br>
the amount of memory transfers.<br><br>
These power consumption parameters are optionally platform information, that is to say technical characteristics of the video processing device. These technical characteristics are for example:<br>
the characteristics of the processor, notably its working frequency,<br>
the size of cache memory,<br>
the size of embedded memory,<br>
the size of external memory,<br>
the power consumption for basic operations (gates),<br>
the power consumption for the exchange between the different memories and the processor.<br>
These power consumption parameters are optionally power supply information, such as, for example, the current battery level of the video processing device.<br>
Power consumption evaluation is a tricky problem. An accurate measure is obtained only if the chip exists. However, measurements based on software are possible, at the price of a lower accuracy.<br>
The present invention is able to compute the power consumption of the critical parts of the algorithm, as a function of the number of memory accesses, the locality of the memory, and the computational cost, with relative weights as given below:<br><br>
These weights have been determined assuming a standard architecture (CPU + memory + co-processor), as it will stand in the next few years, that is to say with a high payload for memory accesses, compared to the one for computations.<br>
The encoding method comprises a fifth step PRDC (35) of computing a rate-distortion value on the basis of the entropy of the residual error block, the overall error and the estimated power consumption of the video processing device.<br>
According to a first embodiment of the invention, the estimation step is able to estimate the power consumption of a video decoder for the prediction functions of the set.<br>
The power-rate-distortion value is then used at the encoder level, in order to reduce the power consumption of the decoder by favoring power-friendly prediction functions.<br>
The distortion value depends as usual on the entropy h of the residual data, and on the reconstruction error "ove" between the current block and the candidate area. The power<br><br>
consumption required to decode the current prediction function is also taken into account, to increase the overall power-distortion/bit-rate tradeoff at the decoder side. A significant power gain can thus compensate a slight encoding efficiency loss. The distortion value c in accordance with the invention is computed as given below:<br><br>
where   X]   and   A,2are  weighting  factors,   powerdecoder ()  represents  the  power<br>
consumption required at the decoder to perform the prediction and parameters are the elements that permit the estimation of the power consumption. These parameters have been described above.<br>
Depending on the type and protocol of communication, more or less information about the decoder is available for the encoder. In equation (2) the result of the power estimation can come from the weighting of the prediction function characteristics by the platform information. The availability of these parameters makes the decoding power estimation more or less precise.<br>
According to a variant of this first embodiment, the receiving device is able to send during the initialization of a communication between an emitting device and said receiving device, its major power consumption characteristics, above-referred to as platform information, which could be used directly by the encoder of the emitting device to estimate the power consumption of the decoder of the receiving device more accurately in equation (2).<br>
Alternatively, if this information is not available, the encoder is able make the assumption of a standard decoding platform, for example with a standard ARM9 processor, with a predetermined amount of embedded RAM, and external memory, and usual transfer costs.<br>
Besides, if the receiving device is able to sent at regular moments its battery level to<br>
the emitting/encoding device, the latter can act directly on X2, to increase or decrease the importance of the power used by the decoder. For example, if the battery level decreases, X2<br>
is increased in order to reinforce the importance of the power consumption value on the choice the prediction function. As a consequence, high consuming prediction functions are penalized.<br>
According to a second embodiment of the invention, the estimation step is able to estimate the power consumption of a video encoder for a prediction function of the set.<br><br>
At the encoder, if all the concurrent prediction functions are computed, it is not possible to save the encoding power consumption. However, a selection of the number of evaluated prediction functions allows the power consumption of the encoder level to be reduced.<br>
According to the invention, the selection depends on a power-rate-distortion value calculated through a learning stage. This learning stage consists in testing a few pictures with all the prediction functions. The tested pictures can be the first pictures of a sequence of pictures or some pictures just after a scene cut. Indeed, between two scene cuts, it is assumed that a given sequence has stable temporal and spatial characteristics. A learning stage can consequently select the most appropriate prediction functions, in order to avoid testing systematically all the prediction functions available at the encoder. This selection is based on the proposed power-rate-distortion value as given below:<br><br>
where ^3 is a weighting factor playing the same role as X2 and powerencoder( )<br>
represents the power consumption required at the encoder to perform the prediction. The parameters are the ones described above. Platform information are of course available, and the battery level is required only if power scalability needs to be applied.<br>
It is possible to merge both approaches, as proposed in equation (4). In this case, encoder and decoder devices are working hand in hand to optimize the end-to-end power-quality tradeoff.<br><br>
For example if a mobile phone having a high battery level is encoding a sequence of pictures and is transmitting the encoded sequence to a second mobile phone having a low battery level. As a consequence, the decoder of the second mobile phone requires low power consuming prediction functions. In this case the weighting factor A,2is high and the<br>
weighting factor A,3 is low. Everything is done to penalize high power consuming prediction functions and then to take into account the low battery level of the second mobile phone.<br>
The encoding method comprises a sixth step of applying the preceding steps to a set of candidate areas SoC (31) using of a set of prediction functions in order to select a best prediction function and a corresponding best candidate area from the power-rate-distortion value. To this end, the distortion values of the evaluated prediction functions are stored into a<br><br>
memory RES (38) and the best prediction, i.e. the one that minimizes the power-rate-distortion value, is selected for encoding the current block.<br>
Any reference sign in the following claims should not be construed as limiting the claim. It will be obvious that the use of the verb "to comprise" and its conjugations do not exclude the presence of any other steps or elements besides those defined in any claim. The word "a" or "an" preceding an element or step does not exclude the presence of a plurality of such elements or steps.<br><br><br>
CLAIMS<br>
1	A method of encoding a sequence of pictures, a picture being divided into<br>
blocks of data, said encoding method comprising the steps of:<br>
computing a residual error block from a difference between a current block contained in a current picture and a candidate area using a prediction function,<br>
computing an entropy of the residual error block,<br>
computing an overall error between said current block and said candidate area,<br>
estimating a power consumption of a video processing device adapted to implement said prediction function,<br>
computing a rate-distortion value on the basis of the entropy, the overall error and the estimated power consumption of the video processing device,<br>
applying the preceding steps to a set of candidate areas using a set of prediction functions in order to select a prediction function according to the rate-distortion value.<br>
2	A video encoding method as claimed in claim 1, wherein the estimation step is<br>
able to use the power consumption of a video decoder for a prediction function of the set.<br>
3	A video encoding method as claimed in claim 1, wherein the estimation step is<br>
able to compute, for a given number of pictures, the power-rate-distortion value of the<br>
different prediction functions of the set and to select, for the encoding of following pictures,<br>
the prediction functions that minimize the power-rate-distortion value.<br>
4	A video encoding method as claimed in claim 1, wherein the estimation step is<br>
able to estimate the power consumption of the video processing device from computational<br>
and transfer parameters of the prediction functions.<br>
5	A video encoding method as claimed in claim 4, wherein the estimation step is<br>
able to estimate the power consumption of the video processing device from technical<br>
characteristics of the video processing device.<br>
6	A video encoding method as claimed in claim 1, wherein the rate-distortion<br>
value depends on a product of the estimated power consumption and a weighting factor, said<br>
weighting factor being dependent on a power supply level of the video processing device.<br><br>
7	A video encoder for encoding a sequence of pictures, a picture being divided<br>
into blocks of data, said video encoder comprising means for implementing the steps of the<br>
video encoding method as claimed in claim 1.<br>
8	A handheld apparatus comprising a video encoder as claimed in claim 7, and a<br>
power supply for supplying said video encoder.<br>
9	A computer program product comprising program instructions for<br>
implementing, when said program is executed by a processor, a video encoding method as<br>
claimed in a claim 1.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS0yMDA1LnJ0Zg==" target="_blank" style="word-wrap:break-word;">3559-2005.rtf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1IGFic3RyYWN0LWR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005 abstract-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1IGNsYWltcy1kdXBsaWNhdGUucGRm" target="_blank" style="word-wrap:break-word;">3559-chenp-2005 claims-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1IGRlc2NyaXB0aW9uIChjb21wbGV0ZSktZHVwbGljYXRlLnBkZg==" target="_blank" style="word-wrap:break-word;">3559-chenp-2005 description (complete)-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1IGRyYXdpbmdzLWR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005 drawings-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWNvcnJlc3BvbmRuZWNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWZvcm0gMjYucGRm" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzU1OS1jaGVucC0yMDA1LXBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">3559-chenp-2005-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="230481-process-for-the-production-of-cross-linked-gelatin-microbeadlets.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="230483-a-device-and-method-for-supplying-a-lap-sheet-to-a-device-that-processes-the-lap-sheet.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>230482</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3559/CHENP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>13/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>27-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>26-Feb-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>27-Dec-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>NXP B.V</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HIGH TECH CAMPUS 60, 5656 AG EINDHOVEN,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JUNG, JOEL</td>
											<td>SOCIETE CIVILE SPID, 156 BOULEVARD HAUSSMANN, F-75008 PARIS,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>BOURGE, ARNAUD</td>
											<td>SOCIETE CIVILE SPID, 156 BOULEVARD HAUSSMANN, F-75008 PARIS,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB04/02109</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-06-22</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>03300041.5</td>
									<td>2003-06-27</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/230482-method-of-encoding-a-sequence-of-pictures-and-apparatus-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 11:15:59 GMT -->
</html>
