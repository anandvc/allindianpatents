<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/233533-a-method-for-generating-an-encoded-audio-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:45:37 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 233533:&quot;A METHOD FOR GENERATING AN ENCODED AUDIO SIGNAL&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;A METHOD FOR GENERATING AN ENCODED AUDIO SIGNAL&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method for generating an encoded audio signal, the signal comprising an audio presentation description, comprising steps of receiving sound source data, generating a parametric description of said sound source, based on the received data, the parametric description comprising information which allows spatialization in a 2D coordinate system; linking the parametric description of said sound source with the audio signals of said sound source data, characterized by adding an additional 1D value to said parametric description which allows in a 2D visual context a spatialization of said sound source in a 3D domain; and generating the encoded audio signal from said parametric description linked to said sound source data and said additional 1D value.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>The present invention relates to a method for generating an encoded audio signal.<br>
The invention relates to a method and to an apparatus for coding and decoding a presentation description of audio signals, especially for the spatialization of MPEG-4 encoded audio signals in a 3D domain.<br>
Background<br>
The MPEG-4 Audio standard as defined in the MPEG-4 Audio standard ISO/IEC 14496-3:2001 and the MPEG-4 Systems stan¬dard 14496-1:2001 facilitates a wide variety of applications by supporting the representation of audio objects. For the combination of the audio objects additional information -the so-called scene description - determines the placement in space and time and is transmitted together with the coded audio objects.<br>
For playback the audio objects are decoded separately and composed using the scene description in order to prepare a single soundtrack, which is then played to the listener.<br>
For efficiency, the MPEG-4 Systems standard ISO/IEC 14496--1:2001 defines a way to encode the scene description in a . binary representation, the so-called Binary Format for Scene Description (BIFS). Correspondingly, audio scenes are de¬scribed using so-called AudioBIFS.<br>
A scene description is structured hierarchically and can be represented as a graph, wherein leaf-nodes of the graph form the separate objects and the other nodes describes the proc¬essing, e.g. positioning, scaling, effects. The appearance and behavior of the separate objects can be controlled using parameters within the scene description nodes.<br><br>
Invention<br>
The invention is based on the recognition of the following fact. The above mentioned version of the MPEG-4 Audio standard defines a node named "Sound" which allows spatialization of audio signals in a 3D domain. A further node with the name "Sound2D" only allows spatialization on a 2D screen. The use of the "Sound" node in a 2D graphical player is not specified due to different implementations of the properties in a 2D and 3D player. However, from games, cinema and TV applications it is known, that it makes sense to provide the end user with a fully spatialized "3D-Sound" presentation, even if the video presentation is limited to a small flat screen in front. This is not possible with the defined  "Sound" and "Sound2D" nodes.<br>
Therefore, a problem to be solved by the invention is to overcome the above mentioned drawback. This problem is solved by the coding method disclosed in claim 1 and the corresponding decoding method disclosed in claim 5.<br>
In principle, the inventive coding method comprises the generation of a parametric description of a sound source including information which allows spatialization in a 2D coordinate system. The parametric description of the sound source is linked with the audio signals of said sound source. An additional ID value is added to said parametric description which allows in a 2D visual context a spatialization of said sound source in a 3D domain.<br>
Separate sound sources may be coded as separate audio objects and the arrangement of the sound sources in a sound scene may be described by a scene description having first nodes corresponding to the separate audio objects and second nodes describing the presentation of the audio objects. A field of a second node may define the 3D spatialization of a<br>
sound source.<br>
Advantageously, the 2D coordinate system corresponds to the screen plane and the ID value corresponds to a depth information perpendicular to said screen plane.<br>
Furthermore, a transformation of said 2D coordinate system values to said 3 dimensional positions may enable the movement of a graphical object in the screen plane to be mapped to a movement of an audio object in the depth perpendicular to said screen plane.<br>
The inventive decoding method comprises, in principle, the reception of an audio signal corresponding to a sound source linked with a parametric description of the sound source. The parametric description includes information which allows spatialization in a 2D coordinate system. An additional ID value is separated from said parametric description. The sound source is spatialized in a 2D visual contexts in a 3D domain using said additional ID value.<br>
Audio objects representing separate sound sources may be separately decoded and a single soundtrack may be composed from the decoded audio objects using a scene description having first nodes corresponding to the separate audio objects and second nodes describing the processing of the audio objects. A field of a second node may define the 3D spatialization of a sound source.<br>
Advantageously, the 2D coordinate system corresponds to the screen plane and said ID value corresponds to a depth information perpendicular to said screen plane.<br>
Furthermore, a transformation of said 2D coordinate system values to said 3 dimensional positions may enable the movement of a graphical object in the screen plane to be mapped<br>
to a movement of an audio object in the depth perpendicular to said screen plane.<br>
Exemplary embodiments<br>
The Sound2D node is defined as followed:<br><br>
Sound2D {<br>
exposedField exposedField exposedField field<br><br>
SFFloat	intensity	1.0<br>
SFVec2f	location	0,0<br>
SFNode	source	NULL<br>
SFBool	spatialize	TRUE<br><br>
and the Sound node, which is a 3D node, is defined as followed :<br><br>
Sound {<br>
exposedField exposedField exposedField exposedField exposedField exposedField exposedField exposedField exposedField field<br><br>
SFVec3f<br>
SFFloat<br>
SFVecSf<br>
SFFloat<br>
SFFloat<br>
SFFloat<br>
SFFloat<br>
SFFloat<br>
SFNode<br>
SFBool<br><br>
direction<br>
intensity<br>
location<br>
maxBack<br>
maxFront<br>
minBack<br>
minFront<br>
priority<br>
source<br>
spatialize<br><br>
0, 0, 1<br>
1.0<br>
0, 0, 0<br>
10.0<br>
10.0<br>
1.0<br>
1.0<br>
0.0<br>
NULL<br>
TRUE<br><br>
In the following the general term for all sound nodes (Sound2D, Sound and DirectiveSound) will be written in lower-case e.g. 'sound nodes'.<br>
In the simplest case the Sound or Sound2D node is connected<br><br>
via an AudioSource node to the decoder output. The sound nodes contain the intensity and the location information.<br>
From the audio point of view a sound node is the final node before the loudspeaker mapping. In the case of several sound nodes, the output will be summed up. From the systems point of view the sound nodes can be seen as an entry point for the audio sub graph. A sound node can be grouped with non-audio nodes into a Transform node that will set its original location.<br>
With the phaseGroup field of the AudioSource node, it is possible to mark channels that contain important phase relations, like in the case of  "stereo pair", "multichannel" etc. A mixed operation of phase related channels and non-phase related channels is allowed. A spatialize field in the sound nodes specifies whether the sound shall be spatialized or not. This is only true for channels, which are not member of a phase group.<br>
The Sound2D can spatialize the sound on the 2D screen. The standard said that the sound should be spatialized on scene of size 2m x 1.5m in a distance of one meter. This explanation seems to be ineffective because the value of the location field is not restricted and therefore the sound can also be positioned outside the screen size.<br>
The Sound and DirectiveSound node can set the location everywhere in the 3D space. The mapping to the existing loudspeaker placement can be done using simple amplitude panning or more sophisticated techniques.<br>
Both Sound and Sound2D can handle multichannel inputs and basically have the same functionalities, but the Sound2D node cannot spatialize a sound other than to the front.<br><br>
A possibility is to add Sound and Sound2D to all scene graph profiles, i.e. add the Sound node to the SF2DNode group.<br>
But, one reason for not including the "3D" sound nodes into the 2D scene graph profiles is, that a typical 2D player is not capable to handle 3D vectors (SFVec3f type) , as it would be required for the Sound direction and location field.<br>
Another reason is that the Sound node is specially designed for virtual reality scenes with moving listening points and attenuation attributes for far distance sound objects. For this the Listening point node and the Sound maxBack, max-Front, minBack and minFront fields are defined.<br>
According one embodiment the old Sound2D node is extended or a new Sound2Ddepth node is defined. The Sound2Ddepth node could be similar the Sound2D node but with an additional depth field.<br>
Sound2Ddepth {<br>
exposedField	SFFloat	intensity	1.0<br>
exposedField	SFVec2f	location	0,0<br>
exposedField	SFFloat	depth	0.0<br>
exposedField	SFNode	source	NULL<br>
field	SFBool	spatialize	TRUE<br>
The intensity field adjusts the loudness of the sound. Its value ranges from 0.0 to 1.0, and this value specifies a factor that is used during the playback of the sound.<br>
The location field specifies the location of the sound in the 2D scene.<br>
The depth field specifies the depth of the sound in the 2D scene using the same coordinate system than the location<br><br>
field. The default value is 0.0 and it refers to the screen position.<br>
The spatialize field specifies whether the sound shall be spatialized. If this flag is set, the sound shall be spati-alized with the maximum sophistication possible.<br>
The same rules for multichannel audio spatialization apply to the Sound2Ddepth node as to the Sound (3D) node.<br>
Using the Sound2D node in a 2D scene allows presenting surround sound, as the author recorded it. It is not possible to spatialize a sound other than to the front. Spatialize means moving the location of a monophonic signal due to user interactivities or scene updates.<br>
With the Sound2Ddepth node it is possible to spatialize a sound also in the back, at the side or above of the listener. Supposing the audio presentation system has the capability to present it.<br>
The invention is not restricted to the above embodiment where the additional depth field is introduced into the Sound2D node. Also, the additional depth field could be inserted into a node hierarchically arranged above the Sound2D node.<br>
According to a further embodiment a mapping of the coordinates is performed. An additional field dimensionMapping in the Sound2DDepth node defines a transformation, e.g. as a 2 rows x 3 columns Vector used to map the 2D context coordinate-system (ccs) from the ancestor's transform hierarchy to the origin of the node.<br>
The node's coordinate system (ncs) will be calculated as follows:<br>
ncs =  ccs x dimensionMapping.<br><br>
The location of the node is a 3 dimensional position, merged from the 2D input vector location and depth {location.x location.y depth} with regard to ncs.<br>
Example: The node's coordinate system context is {xi, yi&gt;. dimensionMapping is {1, 0, 0,   0, 0, 1}. This leads to ncs={ xi; 0, yi} , what enables the movement of an object in the y-dimension to be mapped to the audio movement in the depth.<br>
The field 'dimensionMapping' may be defined as MFFloat. The same functionality could also be achieved by using the field data type 'SFRotation' that is an other MPEG-4 data type.<br>
The invention allows the spatialization of the audio signal in a 3D domain, even if the playback device is restricted to 2D graphics.<br><br><br><br>
We claim:<br>
1.	A method for generating an encoded audio signal, the signal comprising<br>
an audio presentation description, comprising steps of:<br>
receiving sound source data;<br>
generating a parametric description of said sound source, based on the received data, the parametric description comprising information which allows spatialization in a 2D coordinate system; linking the parametric description of said sound source with the audio signals of said sound source data;<br>
characterized by<br>
adding an additional 1D value to said parametric description which allows in a 2D visual context a spatialization of said sound source in a 3D domain; and generating the encoded audio signal from said parametric description linked to said sound source data and said additional 1D value.<br>
2.	Method as claimed in claim 1, wherein separate sound sources are coded as separate audio objects and the arrangement of the sound sources in a sound scene is described by a scene description having first nodes corresponding to the separate audio objects and second nodes describing the presentation of the audio objects, and wherein a field of a second node defines the 3D spatialization of a sound source.<br>
3.	Method as claimed in claim 1 or 2, wherein said 2D coordinate system corresponds to the screen plane and said 1D value corresponds to a depth information perpendicular to said screen plane.<br><br>
4.	Method as claimed in claim 3, wherein a transformation of said 2D coordinate system values to said 3 dimensional positions enables the movement of a graphical object in the screen plane to be mapped to a movement of an audio object in the depth perpendicular to said screen plane.<br>
5.	Method for decoding an encoded audio signal generated as claimed in claim 1, the method comprising steps of:<br>
receiving said encoded audio signal, the signal comprising an audio source signal corresponding to a sound source and a parametric description of said sound source, wherein said parametric description is linked to said audio source signal and comprises information which allows spatialization in a 2D coordinate system;<br>
separating an additional 1D value from said parametric description; and spatializing in a 2D visual context said sound source in a 3D domain using said additional 1D value.<br>
6.	Method as claimed in claim 5, wherein audio objects representing separate sound sources are separately decoded and a single soundtrack is composed from the decoded audio objects using a scene description having first nodes corresponding to the separate audio objects and second nodes describing the processing of the audio objects, and wherein a field of a second node defines the 3D spatialization of a sound source.<br>
7.	Method as claimed in claim 5 or 6, wherein said 2D coordinate system corresponds to the screen plane and said 1D value corresponds to a depth information perpendicular to said screen plane.<br><br>
8. Method as claimed in claim 7, wherein a transformation of said 2D coordinate system values to said 3 dimensional positions enables the movement of a graphical object in the screen plane to be mapped to a movement of an audio object in the depth perpendicular to said screen plane.<br><br><br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUFic3RyYWN0LSgxMC0wNC0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Abstract-(10-04-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUNsYWltcy0oMTAtMDQtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Claims-(10-04-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMDItMDUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Correspondence-Others-(02-05-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSktMTAtMDQtMjAwOC5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-description (complete)-10-04-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUZvcm0tMS0oMTAtMDQtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Form-1-(10-04-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUZvcm0tMi0oMTAtMDQtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Form-2-(10-04-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUZvcm0tMy0oMTAtMDQtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Form-3-(10-04-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LUdQQS0oMDItMDUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-GPA-(02-05-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1kZWxucC0yMDA1LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">1668-delnp-2005-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LVBldGl0aW9uLTEzNy0oMDItMDUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Petition-137-(02-05-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTY2OC1ERUxOUC0yMDA1LVBldGl0aW9uLTEzOC0oMDItMDUtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">1668-DELNP-2005-Petition-138-(02-05-2008).pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="233532-a-clothes-refreshing-appliance.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="233534-a-fuel-system-for-improving-the-fuel-efficiency-of-an-engine.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>233533</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1668/DELNP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>14/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>27-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>30-Mar-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>25-Apr-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON LICENSING S.A.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46 QUAI ALPHONSE LE GALLO, F-92100 BOULOGNE-BILLANCOURT, FRANCE.</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JEAN SPILLE</td>
											<td>KLEINES FELD 58, 30966 HEMMINGEN, GERMANY.</td>
										</tr>
										<tr>
											<td>2</td>
											<td>JURGEN SCHMIDT</td>
											<td>AKAZIENSTR. 5B, 31515 WUNSTORF, GERMANY.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04S 3/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP03/13394</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2003-11-28</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>02026770.4</td>
									<td>2002-12-02</td>
								    <td>EUROPEAN UNION</td>
								</tr>
								<tr>
									<td>2</td>
									<td>03016029.5</td>
									<td>2003-07-15</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/233533-a-method-for-generating-an-encoded-audio-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:45:38 GMT -->
</html>
