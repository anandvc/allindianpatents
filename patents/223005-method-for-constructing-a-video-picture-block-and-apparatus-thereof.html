<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/223005-method-for-constructing-a-video-picture-block-and-apparatus-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:05:36 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 223005:METHOD FOR CONSTRUCTING A VIDEO PICTURE BLOCK AND APPARATUS THEREOF</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD FOR CONSTRUCTING A VIDEO PICTURE BLOCK AND APPARATUS THEREOF</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method for constructing a sequence of video pictures is disclosed. A region of a video picture that is supposed to be used as a predictor to construct a block corresponding to a second picture in a video sequence is ignored when an error correction technique is used to construct the predictor region (405). The invention applies information corresponding to a region from an alternative picture (410) in the video sequence as replacement for the predictor region. This replacement information is then used as the basis to predictively construct the block in accordance with a video decoding operation (415).</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FIELD OF THE INVENTION<br>
[0001] This invention relates towards the field of correcting errors in a<br>
sequence of video pictures for a decoding operation.<br>
BACKGROUND OF THE INVENTION<br>
[0002] With the development of communications networks (network<br>
fabric) such aslhe Internet and the wide acceptance of broadband connections, there<br>
is a demand by consumers for video and audio services (for example, television<br>
programs, movies, video conferencing, radio programming) that can be selected and<br>
delivered on demand through a communication network. Video services, referred to<br>
as media objects or streaming audio/video, often suffer from quality issues due to the<br>
bandwidth constraints and the bursty nature of communications networks generally<br>
used for streaming media delivery. The design of a streaming media delivery system<br>
therefore must consider codecs (encoder/decoder programs) used for delivering<br>
media objects, quality of service (QoS) issues in presenting delivered media objects,<br>
and the transport of information over communications networks used to deliver media<br>
objects, such as audio and video data delivered in a signal.<br>
[0003] Codecs are typically implemented through a combination of software<br>
and hardware. This system is used for encoding data representing a media object at<br>
a transmission end of a communications network and for decoding data at a receiver<br>
end of the communications network. Design considerations for codecs include such<br>
issues as bandwidth scalability over a network, computational complexity of<br>
encoding/decoding data, resilience to network losses (loss of data), and<br>
encoder/decoder latencies for transmitting data representing media streams.<br>
Commonly used codecs utilizing both Discrete Cosine Transformation (DCT) (e.g<br>
H.263+) and non-DCT techniques (e.g., wavelets, integer transforms, and fractals)<br>
are examples of codecs that consider these above detailed issues. Codecs are also<br>
used to compress and decompress data because of the limited bandwidth available<br>
through a communications network.<br>
[0004] Commonly used video based codecs for standards such as MPEG-2<br>
(Motion Picture Standards Group Standard ISO/IEC 13818-1:2000) and ITU-T H.264/<br>
MPEG AVC (ISO/IEC 14496-10) compress video data into a sequence of video<br>
pictures or pictures that utilize techniques as intra-frame and inter-frame encoding, as<br>
known in the art. When inter-frame encoding is performed, each sequence of video<br>
pictures will have at least one reference picture that is used as the basis to construct<br>
the other pictures in the video sequence using other video data and coding<br>
techniques according to a selected video standard. In addition, video codecs use a<br>
technique called error concealment to cover up errors in received data of a video<br>
picture where data from a reference picture is used to conceal or replace the faulty<br>
data in such a video picture.<br>
[0005] When data is used from a reference picture for the purposes of<br>
error concealment, the data of the reference picture itself may be incomplete or<br>
corrupted. Hence, a codec may unintentionally use corrupted data from a reference<br>
picture to generate other pictures in a sequence of video pictures, where the<br>
corrupted data causes further errors to propagate among the generated pictures.<br>
Accordingly, it would be desirable and highly advantageous to have a video codec to<br>
minimize the error propagation in a sequence of video pictures as to minimize the<br>
corruption of displayed video pictures.<br>
SUMMARY OF THE INVENTION<br>
[0006] A method for constructing a sequence of video pictures is disclosed.<br>
A predictor picture for predicting a video picture in a video sequence is ignored when<br>
an error correction technique is used to construct the video picture. The invention<br>
applies information from other pictures in the sequence, as reference pictures, to<br>
predict the video picture being constructed. The other pictures representing a<br>
reference picture for predicting at least one region of the video picture.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
[0007] FIG. 1 is a block diagram of an exemplary digital video receiving<br>
system that operates according to the principles of the invention is shown.<br>
[0008] FIG. 2 is a sequence of video pictures, according to an illustrative<br>
embodiment of the invention.<br>
[0009] FIG. 3 is a sequence of video pictures, according to an illustrative<br>
embodiment of the invention.<br>
[0010] FIG. 4 is a block diagram illustrating the construction of a video<br>
picture from data representing a sequence of video pictures for a video decoding<br>
operation.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
[0011] As used herein, multimedia related data that is encoded and is later<br>
transmitted represents a media object. The terms information and data are also used<br>
synonymously throughout the text of the invention as to describe pre or post encoded<br>
audio/video data. The term media object includes audio, video, textual, multimedia<br>
data files, and streaming media files. Multimedia files comprise any combination of<br>
text, image, video, and audio data. Streaming media comprises audio, video,<br>
multimedia, textual, and interactive data files that are delivered to a user's device via<br>
the Internet or other communications network environment and begin to play on the<br>
user's computer/ device before delivery of the entire file is completed. One<br>
advantage of streaming media is that streaming media files begin to play before the<br>
entire file is downloaded, saving users the long wait typically associated with<br>
downloading the entire file. Digitally recorded music, movies, trailers, news reports,<br>
radio broadcasts and live events have all contributed to an increase in streaming<br>
content on the Web. In addition, the reduction in cost of communications networks<br>
through the use of high-bandwidth connections such as cable, DSL, T1 lines and<br>
wireless networks (e.g., 2.5G or3G based cellular networks) are providing Internet<br>
users with speedier access to streaming media content from news organizations,<br>
Hollywood studios, independent producers, record labels and even home users<br>
themselves. Additionally, the term video decoding and constructing are analogous<br>
terms for creating or generating a region of a video picture, such as a block, from<br>
video data.<br>
[0012] Referring to FIG. 1, a block diagram of an exemplary digital video<br>
receiving system that operates according to the principles of the invention is shown.<br>
The video receiver system includes an antenna 10 and input processor 15 for<br>
receiving and digitizing a broadcast carrier modulated with signals carrying audio,<br>
video, and associated data, a demodulator 20 for receiving and demodulating the<br>
digital output signal from input processor 15, and a decoder 30 outputting a signal<br>
that is trellis decoded, mapped into byte length data segments, de-interleaved, and<br>
Reed-Solomon error corrected. The corrected output data from decoder unit 30 is in<br>
the form of an MPEG compatible transport data stream containing program<br>
representative multiplexed audio, video, and data components.<br>
The video receiver system further includes a communication interface 80 that may be<br>
connected by telephone lines, Ethernet, cable, and the like to a server 83 or<br>
connection service 87 such that data in various formats (e.g., MPEG, HTML, and/or<br>
JAVA) can be received by the video receiver system over the telephone lines.<br>
[0013] A processor 25 processes the data output from decoder 30 and/or<br>
modem 80 such that the processed data can be displayed on a display unit 75 or<br>
stored on a storage medium 105 in accordance with requests input by a user via a<br>
remote control unit 125. More specifically, processor 25 includes a controller 115 that<br>
interprets requests received from remote control unit 125 via remote unit interface<br>
120 and appropriately configures the elements of processor 25 to carry out user<br>
requests (e.g., channel, website, and/or on-screen display (OSD)). In one exemplary<br>
mode, controller 115 configures the elements of processor 25 to provide MPEG<br>
decoded data and an OSD for display on display unit 75. In another exemplary mode,<br>
controller 115 configures the elements of processor 25 to provide an MPEG<br>
compatible data stream for storage on storage medium 105 via storage device 90<br>
and store interface 95. In a further exemplary mode, controller 115 configures the<br>
elements of processor 25 for other communication modes, such as for receiving<br>
bidirectional (e.g. Internet) communications via server 83 or connection service 87.<br>
[0014] Processor 25 includes a decode PID selection unit 45 that identifies<br>
and routes selected packets in the transport stream from decoder 30 to transport<br>
decoder 55. The transport stream from decoder 30 is demultiplexed into audio, video,<br>
and data components by transport decoder 55 and is further processed by the other<br>
elements of processor 25, as described in further detail below.<br>
[0015] The transport stream provided to processor 25 comprises data<br>
packets containing program channel data, ancillary system timing information, and<br>
program specific information such as program content rating, program aspect ratio,<br>
and program guide information. Transport decoder 55 directs the ancillary information<br>
packets to controller 115 that parses, collates, and assembles the ancillary<br>
information into hierarchically arranged tables. Individual data packets comprising me<br>
user selected program channel are identified and assembled using the assembled<br>
program specific information. The system timing information contains a time<br>
reference indicator and associated correction data (e.g. a daylight savings time<br>
indicator and offset information adjusting for time drift, leap years, etc.). This timing<br>
information is sufficient for a decoder to convert the time reference indicator to a time<br>
clock (e.g., United States east coast time and date) for establishing a time of day and<br>
date of the future transmission of a program by the broadcaster of the program. The<br>
time clock is useable for initiating scheduled program processing functions such as<br>
program play, program recording, and program playback. Further, the program<br>
specific information contains conditional access, network information, and<br>
identification and linking data enabling the system of FIG. 1 to tune to a desired<br>
channel and assemble data packets to form complete programs.<br>
[0016] v Transport decoder 55 provides MPEG compatible video, audio, and<br>
sub-picture streams to MPEG decoder 65. The video and audio streams contain<br>
compressed video and audio data representing the selected channel program<br>
content. The sub-picture data contains information associated with the channel<br>
program content such as rating information, program description information, and the<br>
like.<br>
[0017] MPEG decoder 65 cooperates with a random access memory<br>
(RAM) 67 to decode and decompress the MPEG compatible packetized audio and<br>
video data from unit 55 and provides decompressed program representative pixel<br>
data to display processor 70 as to form a sequence of video pictures and portions<br>
corresponding to such video pictures. Decoder 65 also assembles, collates and<br>
interprets the sub-picture data from unit 55 to produce formatted program guide data<br>
for output to an internal OSD module (not shown). The OSD module cooperates with<br>
RAM 67 to process the sub-picture data and other information to generate pixel<br>
mapped data representing subtitling, control, and information menu displays including<br>
selectable menu options and other items for presentation on display device 75. The<br>
control and information menus that are displayed enable a user to select a program<br>
to view and to schedule future program processing functions including tuning to<br>
receive a selected program for viewing, recording of a program onto storage medium<br>
105, and playback of a program from medium 105.<br>
[0018] The control and information displays, including text and graphics<br>
produced by the OSD module (not shown), are generated in the form of overlay pixel<br>
map data under direction of controller 115. The overlay pixel map data from the OSD<br>
module is combined and synchronized with the decompressed pixel representative<br>
data from MPEG decoder 65 under direction of controller 115. Combined pixel map<br>
data representing a video program on the selected channel together with associated<br>
sub-picture data is encoded by display processor 70 and output to device 75 for<br>
display.<br>
[0019] The principles of the invention may be applied to terrestrial, cable,<br>
satellite, DSL, Internet or computer network broadcast systems in which the coding<br>
type or modulation format may be varied. Such systems may include, for example,<br>
non-MPEG compatible systems, involving other types of encoded data streams and<br>
other methods of conveying program specific information. Further, although the<br>
disclosed system is described as processing video data that is processed into a<br>
sequence of video pictures, this is exemplary only. The architecture of FIG. 1 is not<br>
exclusive. Other architectures may be derived in accordance with the principles of the<br>
invention to accomplish the same objectives.<br>
[0020] The preferred embodiment of the invention is explained in view of<br>
the I, B, and P pictures used for a video coding standard as MPEG-2, although it is to<br>
be appreciated that the concepts of the present invention apply to other video coding<br>
standards. As shown in FIG. 2, a sequence of video pictures 200 comprises picture<br>
205 represent an I or P picture, picture 210 being a P picture, and picture 215<br>
represents a P or B picture. Picture 215 is the current picture in a sequence of video<br>
pictures, where picture 215 is predicted from information from picture 210. Such<br>
predictions use prediction regions (such as blocks / regions from one picture) to<br>
predictively construct a block corresponding to a second picture of a sequence of<br>
video pictures.<br>
[0021] A block section of picture 215, denoted with an X2 is shown, where<br>
such an area is constructed from a region from picture 210 utilizing a motion vector<br>
corresponding to X2) as known in the art. When the video data representing picture<br>
210 was received, the video data contained errors where an error concealment<br>
technique was applied to conceal such errors. Different error concealment and error<br>
correction techniques are known in the art, as to be found in the article entitled "Error<br>
Concealment Algorithms for Robust Decoding of MPEG Compressed Video" written<br>
by Huifang Sun et al. as published in Signal Processing Image Communication 10<br>
(1997) pages 249-268. In the present example, the block containing the Xi in picture<br>
210 was a block constructed in view of at least one error concealment technique. .<br>
[0022] The present invention introduces the concept of producing an error<br>
map that is stored in memory that keeps track of blocks and segments of a video<br>
picture that are received in error. When picture 210 is constructed using error<br>
concealment techniques, the blocks that were fixed by error concealment techniques<br>
are denoted in such a map. The map may exist as an array where the coordinates of<br>
the error corrected/concealed blocks are stored in decoder 65 by their coordinates<br>
such as (i, j) in the picture and by the order number of the picture as in the sequence<br>
of video pictures. Those skilled in the art will appreciate other implementations to<br>
store such error map information.<br>
[0023] When picture 215 is constructed, the map is consulted where a<br>
determination is made if the block currently being constructed is predictably<br>
constructed in view of a predictor region (such as a block) that was previously error<br>
concealed in picture 210. If the block region was previously error concealed from<br>
picture 210, as denoted with block YT, information from another video picture, such as<br>
picture 205, is used to construct the affected block of picture 215. Hence, the<br>
information to construct the block denoted with an X2 in picture 215 uses information<br>
from the block region denoted with Yo in picture 205 as a predictor block instead of Y-i<br>
from picture 210. For purposes of the invention, the regions of a picture capable of<br>
being used as predictor region described in this disclosure may take the form of<br>
blocks, macroblocks, circles, or any other polygon required to implement the<br>
principles of the invention.<br>
[0024] In the present invention, a block denoted with an X-i in picture 210<br>
represents a region that was constructed in view of an error concealment technique,<br>
where information indicating such an error is recorded in the error map.<br>
[0025] When constructing a block in view of a corresponding motion vector,<br>
an embodiment of the invention considers whether the predictor block supposed to<br>
be used to constructively predict the constructed block was impacted by an error<br>
concealment operation, For example, block X2 in picture 215 has a corresponding<br>
motion vector where block X2 is supposed to be generated in view of the motion<br>
vector and predictor block XT of picture 210. The invention consults with the error<br>
map to determine if block X-i of picture 210 was constructed by using an error<br>
concealment operation. If this case is true, the invention will utilize information from<br>
block X0 and the motion vector to construct block X2. If not, the invention will use<br>
information derived from picture 210 to construct block X2. In a preferred embodiment<br>
of the invention, the motion vector corresponding to a block (such as X2) is scaled in<br>
relation to the distance of the picture corresponding to the block being constructed<br>
(X2) and the reference picture from which the block (X0) is used to modify the motion<br>
vector. Any other method of scaling such motion vectors may be used in accordance<br>
with the principles of the present invention. The term 'distance1 is known in the art as<br>
from MPEG-2 as to describe the relative temporal reference values between two<br>
pictures in a sequence of pictures.<br>
[0026] In an alternative embodiment of the present invention, the invention<br>
excludes the use of the picture as a reference picture if a predetermined number<br>
corresponding to the number of errors is exceeded when constructing such a<br>
reference picture. Hence, in the present invention, if picture 210 contains a number<br>
of blocks that were produced in view of error concealment techniques, the<br>
construction of picture 215 would utilize video information from picture 205 as a<br>
predictor region instead of the predictor region that was supposed to be used from<br>
picture 210.<br>
[0027] The invention alternatively could also use pictures 205 and 210 as a<br>
reference pictures for picture 215, where a boundary-smoothing test, such a test is<br>
known in the art, is used to determine which reference picture produces a better<br>
result when constructing a block corresponding to picture 215. The reference picture<br>
with the better result is used as the basis for constructing the block for picture 215<br>
[0028] When using weighting factors to construct pictures from each other,<br>
the invention may scale such a weighting factor in view of the relative distance<br>
between an error concealed picture and the picture being constructed versus a<br>
selected reference picture and the picture being constructed. In the illustrative<br>
embodiment of the present invention, picture 210 uses error concealment techniques<br>
to construct the picture. Hence, when picture 215 is produced, a weighting factor for<br>
picture 210 is used and scaled based on the relative distances between picture 215<br>
and picture 210 compared to the distance from picture 205 (used as the reference<br>
picture because picture 210 has errors) to the distance of picture 215.<br>
[0029] The principles of the present invention apply when performing a<br>
bipredictive coding operation to construct video pictures. Referring to FIG. 3, a<br>
sequence of video pictures 300 is presented with pictures 305 and 315 being an I, P<br>
or B picture, and picture 310 being a B picture. In the present example, picture 310 is<br>
constructed using information from pictures 305 and 315. In the case where a region<br>
of picture 305 was constructed using an error concealment technique (block AI in the<br>
picture 305), the invention utilizes information from picture 315 as the reference<br>
picture (block A3) to predict an applicable region of picture 310 (block A2). The<br>
principles of this embodiment of the present invention also apply where picture 305 is<br>
used to predict picture 310, when error concealment techniques are used for<br>
constructing picture 315. In this case the invention would predictively construct a<br>
block for picture 310 in view of picture 305, not picture 315.<br>
[0030] An alterative embodiment of the invention exists for constructing a<br>
bipredictive picture from other pictures sequence of video pictures. Referring to FIG.<br>
3, picture 305 had a region of the picture constructed using error concealment<br>
techniques. Block Ci of picture 305 is the region of the picture impacted by the error<br>
concealment operation. When constructing picture 310, this illustrative embodiment<br>
of the invention uses information from the previous picture in front of picture 305, in<br>
this case picture 302 that is either an I, B, or P picture. Hence, two predictors are<br>
averaged to construct block C2 of bipredictive picture 310 by adjusting the motion<br>
vector corresponding to block C2 in view of a block C0from picture 302 and using the<br>
normal predictor from picture 315, from block Ca.<br>
[0031] When choosing between the two listed embodiments for<br>
constructing a B type picture, the weighting factors for both pictures 305 and 315 may<br>
be considered for deciding which technique yields better results. If the weighting<br>
factor for picture 315 is larger than the weighting factor for picture 305, a<br>
corresponding block from picture 315 alone is used as the predictive block for<br>
generating the corresponding block of picture 310. Otherwise, picture 310 is<br>
constructed bi-predictively by using a corresponding block of picture 302 instead of<br>
picture 305 with the appropriately scaled weighting factor being applied with the<br>
normal use of the corresponding block of picture 315.<br>
 [0032] FIG. 4 shows an illustrative embodiment of a block diagram for<br>
constructing a video picture from data representing a sequence of video pictures, as<br>
described above. Step 405 performed by decoder 65 determines if a region (such as<br>
a block) corresponding to a predictive picture that will be used to construct a block<br>
corresponding to a video picture was constructed by use of an error concealment or<br>
error correction technique. Decoder 65, for example, could use the error map<br>
described above to achieve such an operation, although any of the techniques<br>
described above may be used. The block being considered to be constructed in this<br>
example may have a shape that is not square, for example the block may actually be<br>
rectangular, circular, or any other type of polygon shape, depending on the<br>
requirements of the video standard for constructing such as block. For example, the<br>
generation of a region of picture 210 that was to be used to generate a corresponding<br>
block of picture 215 (as a predictor region) required error concealment when such a<br>
region was constructed.<br>
[0033] If true, step 410 then has decoder 65 select an alternative picture<br>
from the sequence of video pictures to be used as a reference picture to predictively<br>
construct the block corresponding to the video picture. This may have the invention<br>
selecting a picture either before or after the video picture in order to predictively<br>
construct a block. Such a determination may be done in terms of the embodiments<br>
described above. In the present example, picture 205 is selected as an alterative<br>
picture and an alternative predictor region will be selected from said alternative<br>
picture.<br>
[0034] Step 415 then is the actual construction of the block corresponding<br>
to the video picture by using the video data corresponding to the reference picture as<br>
a replacement for the regions of the predictive picture that were constructed using an<br>
error concealment/correction operation. Hence, decoder 65 uses regions such as<br>
blocks from the reference picture as an alternative predictor region to construct<br>
corresponding regions of the video picture, instead of regions of the predictive<br>
picture. Completing the present example, a region of picture 205 is used to<br>
predictively construct the block corresponding to the video picture instead of the<br>
region from picture 210 that was error corrected. If a picture is bi-predictively<br>
encoded, a second alternative picture may be used in the predictive decoding<br>
process, in accordance with the principles described above.<br>
 [0035] The present invention may be embodied in the form of computerimplemented<br>
processes and apparatus for practicing those processes. The present<br>
invention may also be embodied in the form of computer program code embodied in<br>
tangible media, such as floppy diskettes, read only memories (ROMs), CD-ROMs,<br>
hard drives, high density disk, or any other computer-readable storage medium,<br>
wherein, when the computer program code is loaded into and executed by a<br>
computer, the computer becomes an apparatus for practicing the invention. The<br>
present invention may also be embodied in the form of computer program code, for<br>
example, whether stored in a storage medium, loaded into and/or executed by a<br>
computer, or transmitted over some transmission medium, such as over electrical<br>
wiring or cabling, through fiber optics, or via electromagnetic radiation, wherein, when<br>
the computer program code is loaded into and executed by a computer, the computer<br>
becomes an apparatus for practicing the invention. When implemented on a generalpurpose<br>
processor, the computer program code segments configure the processor to<br>
create specific logic circuits.<br><br><br><br><br>
CLAIMS<br>
1.	A method for constructing a video picture block from video data<br>
representing a sequence of video pictures comprising the steps of:<br>
determining (405) a region of a predictive picture that was constructed using error correction;<br>
selecting (410) an alternative picture from said sequence of video pictures as a reference picture to predictively construct said block; and<br>
constructing (415) said video picture block using data from said reference picture to replace said region.<br>
2.	The method of claim 1, wherein<br>
said region corresponds to at least one of: a block, macroblock, and polygon.<br>
3.	The method of claim 1, wherein<br>
said determining step uses an error map to determine said region of a predictive picture that was constructed by error correction.<br>
4.	The method of claim 3, wherein said constructing step modifies a motion<br>
vector for said video block by using information from a block from said reference<br>
picture and scaling said motion vector in view of said block from said reference<br>
picture.<br>
5.	The method of claim 1, wherein said constructing step uses a block from<br>
said reference picture to replace a block from the predictive picture that was<br>
constructed by error correction; and<br>
said block from said reference picture is used as a basis for predicatively constructing said video picture block.<br><br>
6.	The method of claim 5, wherein said predictive operation is associated with the construction of a B picture from a reference picture selected from at least one of: a B picture, a P picture, and an I picture.<br>
7.	The method of claim 1, wherein said reference picture is sequentially before said predictive picture in said sequence of video pictures.<br>
8.	The method of claim 7, wherein said construction step modifies a motion vector corresponding to said block of said video picture by using information from a block from said reference picture and scaling said motion vector, said motion vector is determined by scaling said motion vector depending on the distance between said video picture and said reference picture utilizing the relative temporal reference values of the corresponding pictures in said sequence of pictures.<br>
9.	The method of claim 1, wherein a region from said reference picture is used as a predictor for constructing said video picture when a number of errors is exceeded when error correcting said predictive picture.<br>
1.0.      The method of claim 1 comprising the additional steps of:<br>
performing a boundary smoothing test for testing the use of said reference picture for constructing said video picture;<br>
performing a boundary smoothing test for testing the use of said predictive picture for constructing said video picture; and<br>
selecting data from either said predictive picture or said reference picture in view of the results from said boundary smoothing test.<br>
11.      The method of claim 1, wherein said construction step uses a weighting factor to predictively construct said video picture, said weighting factor being changed from corresponding to said predictive picture to said reference picture.<br>
12       The method of claim 1, wherein<br><br>
said construction step uses a weighting factor to predictively construct said video picture, said weighing factor being calculated from a weighting factor based on said predictive picture; and<br>
said weighing factor is scaled based on the relative distance between said predictive picture and said video picture in said sequence of video pictures to the relative distance between said reference picture and said video picture in said sequence of video pictures.<br>
13.	The method of claim 1, wherein<br>
said video picture is a bi-predictively encoded picture using data from said reference picture and said predictive picture, and<br>
said construction step is a decoding operation using data from said reference picture instead of data from said predictive picture.<br>
14.	The method of claim 1, wherein<br>
said video picture is a bi-predictively encoded picture using data from said reference picture and said predictive picture,<br>
said video picture block has a motion vector related to itself where said region of said predictive picture is used with said motion vector to construct said video picture block,<br>
a region from an second alternative picture is used to adjust said motion vector corresponding to said video picture block; and<br>
said data representing a predictor region from the reference picture and said adjusted motion vector are used to predictively construct said block being constructed.<br>
15.	Apparatus for constructing a video picture block from video data<br>
representing a sequence of video pictures in a decoding operation, comprising:<br><br>
means for determining (405) a region of a predictive picture that was constructed by using error correction where such a region is to be used as a predictive region for constructing said video picture block;<br>
means for selecting (410) an alternative picture from said sequence of video pictures as a reference picture to predictively construct said video picture block; and<br>
means for predictively constructing (415) said video picture block using data corresponding to said reference picture as a replacement for said region of the predictive picture that was constructed using error correction.<br><br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUFic3RyYWN0LTE1LTA1LTIwMDgucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Abstract-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNsYWltcy0oMDUtMDgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Claims-(05-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNsYWltcy0oMzAtMDctMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Claims-(30-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNsYWltcy0xNS0wNS0yMDA4LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Claims-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMDUtMDgtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Correspondence-Others-(05-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNvcnJlc3BvbmRlbmNlLU90aGVycy0xMy0wMi0yMDA4LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Correspondence-Others-13-02-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNvcnJlc3BvbmRlbmNlLU90aGVycy0xNS0wNS0yMDA4LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Correspondence-Others-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUNvcnJlc3BvbmRlbmUtT3RoZXJzLSgzMC0wNy0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Correspondene-Others-(30-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSktMDUtMDgtMjAwOC5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-description (complete)-05-08-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSktMTUtMDUtMjAwOC5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-description (complete)-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSktMzAtMDctMjAwOC5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-description (complete)-30-07-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LURyYXdpbmdzLTE1LTA1LTIwMDgucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Drawings-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUZvcm0tMS0oMzAtMDctMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Form-1-(30-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUZvcm0tMS0xNS0wNS0yMDA4LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Form-1-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tMTMtKDA1LTA4LTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-13-(05-08-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUZvcm0tMi0xNS0wNS0yMDA4LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Form-2-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUZvcm0tMjYtMTUtMDUtMjAwOC5wZGY=" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Form-26-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LUdQQS0oMzAtMDctMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-GPA-(30-07-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LXBjdC0xMDEucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-pct-101.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LXBjdC0yMTAucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-pct-210.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LXBjdC0yMjAucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-pct-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1kZWxucC0yMDA1LXBjdC0zMDQucGRm" target="_blank" style="word-wrap:break-word;">2901-delnp-2005-pct-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjkwMS1ERUxOUC0yMDA1LVBldGl0aW9uLTEzNy0xNS0wNS0yMDA4LnBkZg==" target="_blank" style="word-wrap:break-word;">2901-DELNP-2005-Petition-137-15-05-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QuanBn" target="_blank" style="word-wrap:break-word;">abstract.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="223004-a-manifold-system-for-an-injection-molding-system.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="223006-a-manhole-cover.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>223005</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2901/DELNP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>44/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>31-Oct-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>02-Sep-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>29-Jun-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON LICENSING S.A.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46, QUAI A. LE GALLO, BOULOGNE F-92648, FRANCE</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>PANDIT, PURVIN, BIBHAS</td>
											<td>914 COVENTRY LANE, SOMERSET, NEW JERSEY 08873 (US)</td>
										</tr>
										<tr>
											<td>2</td>
											<td>BOYCE, JILL, MACDONALD</td>
											<td>3 BRANDYWINE COURT, MANALAPAN, NEW JERSEY 077267 (US)</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2004/001781</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-01-23</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/442,110</td>
									<td>2003-01-23</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/223005-method-for-constructing-a-video-picture-block-and-apparatus-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 07:05:37 GMT -->
</html>
