<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/260935-method-for-coding-and-decoding-an-image-sequence-encoded-with-spatial-and-temporal-scalability by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 02:27:22 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 260935:&quot;METHOD FOR CODING AND DECODING AN IMAGE SEQUENCE ENCODED WITH SPATIAL AND TEMPORAL SCALABILITY &quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;METHOD FOR CODING AND DECODING AN IMAGE SEQUENCE ENCODED WITH SPATIAL AND TEMPORAL SCALABILITY &quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to a method which is characterised in that the resolution selected for the movement i information and the complexity of the interpolation filters used during a temporal filtering operation compensated in movement, depend on a decoding scenario, namely flow, temporal and spatial resolutions selected for the decoding either in terms of the corresponding temporal decomposition or of a combination of said parameters. The inventive method can be applied to so-called scalable video encoders/decoders, for example in the field of videotelephony or video transmission on the internet.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>METHOD FOR CODING AND DECODING AN IMAGE SEQUENCE ENCODED WITH<br>
SPATIAL AND TEMPORAL SCALABILITY<br>
The invention relates to a method of video coding and decoding of<br>
a picture sequence coded with spatial and temporal scalability, by hierarchical<br>
temporal analysis exploiting the motion compensated temporal filtering.<br>
The scope is that of video compression based on spatial and/or<br>
temporal scalability diagrams also known as "scalables". This involves for<br>
example a 2D+t wavelet coding comprising a motion compensated temporal<br>
filtering.<br>
A scalable coding-extraction-decoding system is illustrated in<br>
figure 1.<br>
The source pictures are transmitted to a scalable video coding<br>
circuit 1. The original bitstream obtained is processed by an extractor 2 to give<br>
an extracted bitstream. This bitstream is decoded by the decoding circuit 3<br>
which supplies the decoded video at the output.<br>
The scalability enables an original bitstream to be generated from<br>
which one can extract binary sub-streams adapted to sets of data such as flow,<br>
spatial resolution, temporal frequency, etc. For example, if the original scalable<br>
bitstream was generated from a 25 Hz, 720x480 pixel resolution video<br>
sequence without any bitstream constraints, a sub-bitstream, for example with a<br>
360x240 pixel resolution of parameters 1 Mb/s, 12.5 Hz, itself scalable, can be<br>
obtained after extracting the suitable data from this bitstream. The decoding of<br>
this extracted sub-bitstream will generate a 12.5 Hz video of size 360x240<br>
pixels.<br>
In existing approaches to scalable video compression, the coding<br>
and decoding proceed in an identical manner, without taking into account<br>
operating conditions such as the level of temporal decomposition, bit-rate,<br>
spatial resolution of the decoded video... In particular, if the decoding involves<br>
motion compensation between pictures, this compensation is applied identically,<br>
without taking into account the size of the pictures or the bit-rate of the video to<br>
be decoded. This results in a degraded picture quality, particularly when the<br>
picture resolution becomes small with respect to the size of the interpolation<br>
filters used for the motion compensation.<br>
The invention aims to overcome the disadvantages described<br>
above.<br>
One of the purposes of the invention is a decoding method of a<br>
picture sequence coded with spatial and temporal scalability, the coded data<br>
comprising motion information, comprising a hierarchical temporal synthesis<br>
step carrying out a motion compensated temporal filtering, or MCTF, of pictures<br>
at a frequency decomposition level, from the said motion information, to provide<br>
pictures at a lower decomposition level, characterized in that, during a motion<br>
compensated temporal filtering operation, the resolution chosen for the use of<br>
the motion information and the complexity of the interpolation filters used<br>
depend on the decoding scenario, namely spatial and temporal resolutions and<br>
the bit-rate selected for the decoding or else the corresponding temporal<br>
decomposition level or a combination of these parameters.<br>
According to a particular implementation, the number of<br>
coefficients of the interpolation filter used for the motion compensation depends<br>
on the decoding scenario or the temporal decomposition level.<br>
According to a particular implementation, the hierarchical temporal<br>
synthesis is a decoding of wavelet coefficients with motion compensated<br>
filtering.<br>
The invention also relates to a coding method of a picture<br>
sequence of a given spatial resolution, with spatial and temporal scalability,<br>
comprising a hierarchical temporal analysis step carrying out a motion<br>
compensated temporal filtering, or MCTF, of pictures at a frequency<br>
decomposition level, from motion information between these pictures, to provide<br>
pictures at a higher decomposition level, characterized in that, during a motion<br>
compensated temporal filtering operation, the resolution chosen for the use of<br>
the said motion information and the complexity of the interpolation filters used<br>
depend upon the said spatial resolution of the source pictures or the<br>
corresponding temporal decomposition level.<br>
The method, according to a particular implementation, comprises<br>
a motion estimation step computed between two pictures at a given level of<br>
decomposition to perform the motion compensation and in that the computation<br>
accuracy of the motion estimation depends on the temporal decomposition level<br>
or the said spatial resolution of the source pictures.<br>
The temporal analysis step is for example a wavelet coding<br>
operation with motion compensated filtering.<br>
The invention also relates to a decoder for the implementation of<br>
the previously described decoding method, characterized in that it comprises a<br>
motion configuration choice circuit to determine the motion resolution and the<br>
interpolation filter to use in the motion compensation for the motion<br>
compensated filtering, depending on the decoding scenario, namely the spatial<br>
and temporal resolutions and the bit-rate selected for the decoding or the<br>
corresponding temporal decomposition level or a combination of these<br>
parameters.<br>
The invention also relates to a coder for the implementation of the<br>
previously described coding method, characterized in that it comprises a motion<br>
configuration choice circuit to determine the interpolation filter to be used by the<br>
temporal analysis circuit for the motion compensation depending on the said<br>
spatial resolution of the source pictures or the corresponding temporal<br>
decomposition level.<br>
According to a particular embodiment, the coder is characterized<br>
in that it comprises a motion configuration choice circuit to determine the<br>
accuracy of the motion computed by the motion estimation circuit, depending on<br>
the said spatial resolution of the source pictures or of the corresponding<br>
temporal decomposition level.<br>
The accuracy of the motion and the interpolation filters used for<br>
the motion compensation in the coding and decoding process are adapted<br>
according to different parameters, such as the temporal decomposition level at<br>
which one proceeds. These filters are adapted, for the decoding, at the bit-rate<br>
of the decoded flow, to the spatial or temporal resolution of the decoded video.<br>
Owing to this adaptive motion compensation, the quality of the pictures is<br>
improved, the complexity of the processing operations is reduced.<br>
Other specific features and advantages will emerge more clearly<br>
from the following description, the description provided as a non-restrictive<br>
example and referring to the annexed drawings wherein:<br>
- figure 1 a coding system according to prior art,<br>
- figure 2, a simplified coding diagram,<br>
- figure 3, a temporal filtering of GOP,<br>
- figure 4, a temporal filtering on two pictures,<br>
- figure 5, a decoding circuit,<br>
- figure 6, a flow chart for the motion configuration choice,<br>
- figure 7, a second flow chart for the motion configuration choice.<br>
We consider a 2D+t wavelet based coding/decoding diagram<br>
operating a wavelet analysis/synthesis along the motion trajectories. The<br>
system operates on group of pictures or GOPs.<br>
The overall architecture of the coder is described in figure 2.<br>
The source pictures are transmitted to a temporal analysis circuit<br>
4 that carries out a motion compensated temporal analysis or MCTF, acronym<br>
of motion compensation temporal filtering, to obtain the different frequency<br>
temporal bands The picture are transmitted to a motion estimation circuit 7 that<br>
computes the motion fields. These fields are sent to a "pruning" circuit 10 that<br>
carries out a "pruning" or a simplification of the motion information computed by<br>
the motion estimation circuit to control the cost of the motion. The motion fields<br>
simplified in this manner are sent to the temporal analysis circuit so as to define<br>
the analysis filters. They are also sent to a coding circuit 11 that codes the<br>
simplified motion fields.<br>
The resulting pictures of the temporal analysis are sent to a spatial<br>
analysis circuit 5 that performs a subband coding of the low bandwidth picture<br>
and of the high bandwidth pictures obtained by the temporal analysis. The<br>
spatio-temporal wavelet coefficients thus obtained are finally coded by an<br>
entropic coder 6. This coder provides a set of binary packets at its output<br>
corresponding to the layers of superposed scalabilities, both in quality, in spatial<br>
and temporal resolutions. A packetizer 12 performs the fusion of these binary<br>
packets with the motion data coming from the coding circuit 11 to provide the<br>
final scalable bitstream.<br>
The pictures at the different levels of temporal decomposition are<br>
sent by the temporal analysis circuit 4 to the motion estimation circuit 7<br>
comprising a first motion configuration choice circuit. This circuit, not shown in<br>
the figure, defines the operating conditions of the motion estimation circuit<br>
according to the different decomposition levels of the pictures. Optionally, the<br>
motion information, once simplified via the pruning circuit 10, is sent to the<br>
temporal analysis circuit through a mode switching circuit 9. This circuit is used<br>
to test the quality of the motion estimation by testing for example the number of<br>
pixels connected between the current picture and the previous picture, to a<br>
given decomposition level, and can impose on the temporal analysis circuit an<br>
intra mode coding or a predictive mode coding, that is a filtering of the current<br>
picture with the following picture and not the previous picture, when this motion<br>
quality is insufficient. The choice between the intra and predictive mode<br>
depends for example on the quality of the motion estimation between the<br>
current picture and the following picture. The temporal analysis circuit<br>
comprises a second motion configuration choice circuit, also not shown in the<br>
figure, that determines, according to the decomposition levels of the pictures<br>
and/or the spatial resolution of the source picture, the configuration to adopt for<br>
the motion compensation used in this temporal analysis.<br>
Figure 3 shows in a summary manner the motion compensated<br>
temporal filtering operations performed by the temporal analysis circuit 4, with a<br>
4-level decomposition for GOPs comprising in this example, 16 pictures shown<br>
in thick lines.<br>
The filtering mode used is called "lifting". Instead of using a<br>
complex filtering for the wavelet coding, using a linear filter of a great length, in<br>
our example the filtering will be carried out on a group of 16 pictures, this<br>
filtering method consists, in a known manner, of "factorising" the filter by using<br>
limited length filters, for example two if it is decided to filter the samples two by<br>
two, this filtering being renewed for each decomposition level. One therefore<br>
considers the case in which the filtering in the direction of motion is carried out<br>
on pairs of pictures. The low frequency and high frequency filtering on each of<br>
the pairs of the GOP, produces respectively 8 low temporal frequency images<br>
(t-L) and 8 high temporal frequency images (t-H) at the first temporal<br>
decomposition level.<br>
The low temporal frequency images are then decomposed again<br>
according to the same method. The low pass filtering of these pictures provides<br>
4 new low temporal frequency pictures t-LL and the high pass filtering of these<br>
same pictures provides 4 high temporal frequency pictures t-LH. The third<br>
decomposition level provides 2 low temporal frequency pictures t-LLL and 2<br>
high temporal frequency pictures t-LLH. The fourth and last level provides a low<br>
temporal frequency picture t-LLLL and a high temporal frequency picture t-<br>
LLLH.<br>
This temporal decomposition is a 5 band temporal decomposition<br>
that therefore generates 1 t-LLLL picture, 1 t-LLLH picture, 2 t-LLH pictures, 4 <br>
LH pictures, and 8 t-H pictures per GOP of 16 pictures. The t-L, t-LL, t-LLL<br>
pictures and naturally the original pictures are ignored for the downstream<br>
coding as they are at the origin of the decomposition into subbands to provide<br>
de-correlated pictures at each level. This decomposition thus enables a new<br>
distribution of the energy by generating a useful picture with a low temporal<br>
frequency t-LLLL, which represents an average of the set of the GOP and in<br>
which is concentrated the energy and four levels of pictures of low energy high<br>
temporal frequency pictures, namely 5 frequency bands. It is these pictures that<br>
are sent to the spatial analysis circuit for spatial decomposition into subbands.<br>
To perform the filtering, a motion field is estimated between each<br>
pair of pictures to be filtered and this for each level. This is the function of the<br>
motion estimator 7.<br>
The filtering of a pair of source pictures A and B consists by<br>
default of generating a temporal low frequency picture L and a temporal high<br>
frequency picture H, according to the following equations:<br>
H = (A-MC(B))/j2<br>
where MC(I) corresponds to the motion compensated picture I.<br>
The sum relates to the low pass filtering, the difference, to the<br>
high-pass filtering.<br>
Figure 4 is a simplified illustration of the temporal filtering of the<br>
two successive pictures A and B, the picture A being the first picture according<br>
to the time axis and according to the order of display, giving a low frequency<br>
picture L and a high frequency picture H.<br>
The motion estimation is performed with respect to a reference<br>
picture, from the current picture to the reference picture. For each pixel of the<br>
current picture, a search is made for its corresponding pixel, if it exists, in the<br>
reference picture, and the corresponding motion vector is assigned to it. The<br>
pixel of the reference picture is then said to be connected.<br>
Obtaining the picture L requires a motion compensation of the<br>
picture A. This compensation is achieved by motion estimation of the picture B<br>
to the picture A taking A as the reference picture, a motion and therefore a<br>
vector thus being assigned to each pixel of the picture B. The value of a pixel of<br>
L equals, at the nearest shape factor, the sum of the luminance of the<br>
corresponding pixel of the picture B and the luminance of the pixel or subpixel<br>
of A pointed by the motion vector assigned to the corresponding pixel of the<br>
picture B. An interpolation is necessary when this vector does not point to a<br>
pixel of the picture A. This concerns forward prediction from a past reference<br>
picture and computation of forward vectors by referring to the MPEG standard.<br>
Obtaining the picture H requires a motion compensation of the<br>
picture B. This compensation is achieved by motion estimation of the picture A<br>
to the picture B taking B as the reference picture, a motion and therefore a<br>
vector thus being assigned to each pixel of the picture A. The value of a pixel of<br>
H equals, at the nearest shape factor, the difference of the luminance of the<br>
corresponding pixel of the picture A and the luminance of the pixel or subpixel<br>
of B pointed by the motion vector assigned to the corresponding pixel of the<br>
picture A. An interpolation is necessary when this vector does not point to a<br>
pixel of the picture B. This concerns backward prediction from a future<br>
reference picture and computation of backward vectors by referring to the<br>
MPEG standard.<br>
In a practical manner, only a motion vector field is computed, from<br>
A to B or from B to A. The other motion vector field is deducted from the first,<br>
generating non-connected pixels, that is not assigned a motion vector and<br>
corresponding to holes in the reverse motion vector field.<br>
In a practical manner, the low and high frequency pictures are<br>
computed as follows:<br>
B-M<br>
This filtering, equivalent to the filtering described, consists in first<br>
calculating the picture H. This picture is obtained from point to point difference<br>
of the picture B and the motion compensated picture A. Hence, a certain value<br>
is removed from a pixel B, interpolated if necessary, pointed by the<br>
displacement vector in A, motion vector computed during the motion estimation<br>
of the picture B to the picture A.<br>
The picture L is then deducted from the picture H and no longer<br>
the picture B, by addition of the picture A to the reverse motion compensated<br>
picture H. MC._B(H) corresponds to a motion "decompensation" of the picture<br>
(H). Hence, one adds, to a pixel of A or more exactly to a standardised value of<br>
the luminance of the pixel, a certain value, interpolated if necessary, located, in<br>
the picture H, at the base of a displacement vector B to A and pointing the A<br>
pixel.<br>
The same reasoning can be applied at the level of a picture block<br>
instead of a pixel.<br>
The motion estimation circuit 7 operates for example a motion<br>
estimation algorithm by block matching. A current block picture is correlated to<br>
the blocks of a search window in the reference picture to determine the motion<br>
8<br>
vector corresponding to the best correlation. This search is carried out not only<br>
on the blocks of the search window obtained by successive horizontal and<br>
vertical displacements of a pixel but also on the interpolated blocks if the<br>
accuracy required is less than a pixel. This interpolation consists in computing<br>
the luminance values of the subpixels for the generation of picture blocks<br>
obtained by successive displacements of a value less than the distance<br>
between two pixels. For example, for an accuracy of a quarter of a pixel, a<br>
correlation test is performed every quarter of a pixel, horizontally and vertically.<br>
This interpolation uses filters called motion estimation interpolation filters.<br>
The pictures for which a motion compensated temporal filtering is<br>
to be carried out are sent to the motion estimator 7 so that it can estimate the<br>
motion between two pictures. This circuit comprises a first motion configuration<br>
choice circuit that receives, in addition to the decomposition level information of<br>
the pictures, other information such as the spatial resolution of the source<br>
pictures. This circuit decides on the motion configuration according to this level<br>
and/or the spatial resolution. Hence, for example, the accuracy in the<br>
computation of the motion values depends on the temporal decomposition level<br>
of the pictures processed. This accuracy is all the lower as the decomposition<br>
level is high. The interpolation filters of the motion estimator are configured to<br>
be adapted to the motion accuracy. A configuration example is given below.<br>
The temporal analysis circuit 4, as indicated above, realizes<br>
motion compensations for the temporal filtering of the pictures. These motion<br>
compensation operations require interpolation operations using interpolation<br>
filters, and this for each level of decomposition. The second motion<br>
configuration choice, in this temporal analysis circuit, which can be different<br>
from the first, implements a processing algorithm adapting the accuracy of the<br>
motion and the complexity of the interpolation filter for the motion compensation<br>
according to the temporal decomposition level of the pictures to motion<br>
compensate. As for the first motion configuration choice circuit, these different<br>
adaptations or configurations can also depend on the spatial resolution of the<br>
source pictures processed.<br>
Naturally, a coder only comprising one of these configuration<br>
choice circuits falls within the scope of the invention.<br>
A decoder according to the invention is described in figure 5. The<br>
binary flow received by the decoder is transmitted at the input of an entropic<br>
decoding circuit 13 that carries out the reverse operations of the entropic coding<br>
circuit of the coder. Among other things, it decodes the spatio-temporal wavelet<br>
coefficients and, if necessary, the coding modes. This binary flow is sent in<br>
parallel to the input of a motion decoding circuit 14 that decodes the motion<br>
fields received in the binary flow to send them to the temporal synthesis circuit.<br>
The entropic decoding circuit 13 is linked to a spatial synthesis circuit 15 that<br>
reconstructs the images corresponding to the different temporal subbands. The<br>
temporal wavelet coefficients coming from the spatial synthesis circuit are sent<br>
to a temporal synthesis circuit 16 that reconstructs the output pictures from<br>
temporal synthesis filters. The temporal synthesis circuit comprises a motion<br>
configuration choice circuit, not shown in the figure, that determines, according<br>
to the decoding conditions and/or picture decomposition levels, the<br>
configuration to adopt for the motion compensation used in this temporal<br>
synthesis. The temporal synthesis circuit is linked to a post-processing circuit <br>
whose output is the output of the decoder. This involves for example postfiltering<br>
enabling the artefacts such as the block effects to be reduced.<br>
In the case where the coder uses other coding modes other than<br>
the MCTF mode, for example the intra mode and the predictive mode, a<br>
temporal filter switch mode is used to receive this coding mode information<br>
coming from the entropic decoding circuit 13 and to send it to the temporal<br>
synthesis circuit 16 that subsequently carries out the filter switches.<br>
The motion configuration choice circuit receives the bit-rate,<br>
resolution, spatial and temporal resolution information and the temporal<br>
decomposition networks. From this information or an item of this information, it<br>
chooses, for the temporal synthesis, a motion compensation configuration. The<br>
temporal synthesis circuit adapts the interpolation filter according to this chosen<br>
configuration.<br>
The binary flow bit-rate received by the decoder corresponds to<br>
the extracted bitstream. The scalable coder generally sends the highest bit-rate<br>
that is the original bitstream, as seen above, and the extractor, which can be<br>
controlled by the decoder, extracts the bitstream corresponding to the<br>
resolutions required. The bit-rate information received is available to the<br>
decoder.<br>
The spatial, temporal and bit-rate information define a decoding<br>
scenario. This scenario depends for example on the display used by the<br>
decoder, the bit-rate available to receive the data. It is from this information<br>
and/or the temporal decomposition level that the temporal synthesis circuit is<br>
configured regarding the interpolation filters.<br>
An example of adaptation of the accuracy of the motion and the<br>
interpolation filter that depends on this accuracy is given below, for the motion<br>
estimation operations of the coder or the motion compensation operations in the<br>
coder or decoder:<br>
jcojTfjgjjration<br>
The configuration filter 2 is very similar to the one used in the<br>
MPEG-4 part 10 standard (reference ITU-T Rec. H.264 ISO/IEC 14496-10<br>
AVC).<br>
Figure 6 shows a decision flow chart implemented by the motion<br>
configuration choice circuit belonging to the temporal analysis circuit.<br>
Step 20 determines if the resolution of the source picture supplied<br>
to the coder is less than that of the QCIF format, from Quarter Common<br>
Intermediate Format, and corresponding to 176 columns, 120 lines. In the<br>
affirmative, the next step is step 23 that decides on the configuration 1.<br>
In the negative, the next step is step 21, which checks the<br>
temporal decomposition level. If this level is strictly greater than 2, the next step<br>
is step 23, the configuration 1 is chosen. Otherwise, the next step is step 22,<br>
which decides on the configuration 2.<br>
Figure 7 shows a decision flow chart for the decoder.<br>
The step 24 determines whether the resolution of the picture<br>
supplied by the decoder and corresponding to the binary flow extracted is less<br>
than that of the QCIF format, 176 columns, 120 lines. In the affirmative, the next<br>
step is step 26 that chooses the configuration 1.<br>
In the negative, the next step is step 25, which checks the<br>
temporal decomposition level. If this level is strictly greater than 2, the next step<br>
is step 26, the configuration 1 is used. Otherwise, the next step is step 27. This<br>
step 27 determines whether the resolution of the picture to decode is equal to<br>
that of the SD format, from Standard Definition, 720 columns, 480 lines and<br>
whether the bit-rate of the binary flow is less than 1.5 Mb/s. In the affirmative,<br>
the next step is the step 26, which decides on the configuration 1.<br>
In the negative, the step 28 is the next step. This step 28<br>
determines whether the resolution of the picture to decode is equal to that of the<br>
GIF format, 352 columns, 240 lines and whether the bit-rate is less than<br>
700 kbits/s. In the affirmative, the next step is the step 26 that imposes the<br>
configuration 1.<br>
In the negative, the configuration 2 is imposed on the temporal<br>
filtering circuits.<br>
The interpolation filter is for example of 8-coefficient FIR type,<br>
acronym for Finite Impulse Response. The filtering is carried out by convolution,<br>
thus taking into account the luminances of the 4 pixels preceding and following<br>
the subpixel to be computed.<br>
For different positions at the subpixel s at %, 1/z, and %, three<br>
different interpolation filters of the previous type can be used. The value of a<br>
coefficient n is given by the formula:<br>
s is the subpixel position, s = Vi, V2, or %, n is the number of the<br>
coefficient and h(m) the attenuation filter or Hamming window.<br>
The FIR filter can be deduced by weighting by a Hamming window<br>
and truncation of these weighted filters.<br>
For s = - , the coefficients are:<br>
 [-0.0110 0.0452 -0.1437 0.8950 0.2777 -0.0812 0.0233 -0.0053]<br>
For s =•- - , the coefficients are:<br>
2<br>
[-0.0053 0.0233 -0.0812 0.2777 0.8950 -0.1437 0.0452 -0.0110]<br>
For s - - , the coefficients are:<br>
4<br>
[-0.0105 0.0465 -0.1525 0.6165 0.6165 -0.1525 0.0465 -0.0105]<br>
With these filters, one can interpolate to %, V2 and % of a pixel.<br>
The interpolation is first done according to the horizontal dimension, then the<br>
vertical. The interpolation to 1/8 of a pixel is next carried out by a bilinear<br>
interpolation from the positions of the % of a pixel.<br>
The example of adaptation given above at the level of the coder<br>
can be applied in the same manner at the level of the decoder.<br>
Generally, the principle is to use a limited accuracy of motion and<br>
simple interpolation filters when one operates with limited picture qualities, that<br>
is a low bit-rate, on pictures of a small size and at high temporal decomposition<br>
levels. Conversely, when one processes good quality pictures, high spatial<br>
resolution, high bit-rates, low temporal decomposition rates, one uses a high<br>
accuracy of motion and sophisticated interpolation filters. The justification for<br>
this principle is that when the pictures to filter are poor in frequency content or<br>
of limited resolution, it is not useful to use highly evolved interpolation filters or a<br>
very great accuracy of motion.<br>
The applications of the invention relate to the video<br>
coders/decoders known as "scalable" used for data compression/decompression,<br>
for example in the domain of video telephony or video transmission over<br>
internet.<br><br><br><br><br><br><br>
Decoding method of a picture sequence coded with spatial and<br>
temporal scalability, the coded data comprising motion information, comprising<br>
a hierarchical temporal synthesis step (16) carrying out a motion compensated<br>
temporal filtering, or MCTF, of pictures at a frequency decomposition level, from<br>
the said motion information, to provide pictures at a lower decomposition level,<br>
characterized in that, during a motion compensated temporal filtering operation,<br>
the resolution chosen for the use of the motion information and the complexity<br>
of the interpolation filters used depend on a decoding scenario, namely spatial<br>
and temporal resolutions and the bit-rate selected for the decoding or else the<br>
corresponding   temporal   decomposition   level   or  a  combination   of these<br>
parameters.<br>
Method according to claim 1, characterized in that the number<br>
of coefficients of the interpolation filter (16) used for the motion compensation<br>
depends on the decoding scenario or the temporal decomposition level.<br><br>
Method  according  to  claim   1,   characterized   in  that  the<br>
hierarchical temporal synthesis step (16) is a decoding of wavelet coefficients<br>
with motion compensated filtering.<br>
Coding method of a picture sequence of a given spatial<br>
resolution, with spatial and temporal scalability,  comprising a hierarchical<br>
temporal analysis step (4) carrying out a motion compensated temporal filtering,<br>
or  MCTF,  of pictures  at  a frequency decomposition  level,  from  motion<br>
information  between  these  pictures  (7),  to  provide  pictures  at  a  higher<br>
decomposition  level,  characterized  in that,  during  a motion  compensated<br>
temporal filtering operation (4), the resolution chosen for the use of the said<br>
motion information and the complexity of the interpolation filters used (9)<br>
depends upon the said  spatial  resolution  of the source  pictures  or the<br>
corresponding temporal decomposition level.<br>
Method according to claim 4, characterized in that it comprises<br>
a step of motion estimation (7) computed between two pictures at a given level<br>
of decomposition to perform the motion compensation (4) and in that the<br><br>
computation accuracy of the motion estimation (7) depends on the temporal decomposition level or the said spatial resolution of the source pictures.<br>
Method   according  to  claim  4,   characterized   in  that  the<br>
hierarchical temporal analysis  step  (4)  is  a  wavelet coding with  motion<br>
compensated filtering.<br>
Decoder for the implementation of the method according to<br>
claim 1, characterized in that it comprises a motion configuration choice circuit<br>
(16) to determine the motion resolution and the interpolation filter to use in the<br>
motion compensation (16) for the motion compensated filtering, depending on<br>
the decoding scenario, namely the spatial and temporal resolutions and the bit-<br>
rate selected for the decoding or the corresponding temporal decomposition<br>
level or a combination of these parameters.<br>
Coder for the implementation of the method according to<br>
claim 4, characterized in that it comprises a motion configuration choice circuit<br>
(4) to determine the interpolation filter to be used by the temporal analysis<br>
circuit for the motion compensation (4) depending on the said spatial resolution<br>
of the source pictures or the corresponding temporal decomposition level.<br>
Coder for the implementation of the method according to<br>
claim 4,  characterized in that it comprises a motion configuration choice<br>
circuit (7) to determine the accuracy of the motion computed by the motion<br>
estimation circuit (7) depending on the said spatial resolution of the source<br>
pictures or of the corresponding temporal decomposition level.<br><br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LUNsYWltcy0oMDQtMDQtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-Claims-(04-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMDQtMDQtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-Correspondence Others-(04-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMDctMTAtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-Correspondence Others-(07-10-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LURyYXdpbmdzLSgwNC0wNC0yMDE0KS5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-Drawings-(04-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LUZvcm0tMy0oMDctMTAtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-Form-3-(07-10-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LUdQQS0oMDQtMDQtMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-GPA-(04-04-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDUxOS1kZWxucC0yMDA2LVBldGl0aW9uLTEzNy0oMDctMTAtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">4519-delnp-2006-Petition-137-(07-10-2013).pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="260934-waxing-device-for-a-textile-machine-producing-cross-wound-bobbins.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="260936-method-and-apparatus-for-the-purification-of-ground-water.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>260935</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>4519/DELNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>22/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>30-May-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>29-May-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>04-Aug-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON LICENSING</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46 QUAI A. LE GALLO, 92100 BOULOGNE-BILLANCOURT, FRANCE</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>EDOUARD FRANCOIS</td>
											<td>18 ALLE DU LOCAR, F-35890 BOURG DES COMPTES, FRANCE</td>
										</tr>
										<tr>
											<td>2</td>
											<td>JEROME VIERON</td>
											<td>5 ALLEE JEAN PERRIN, F-35137 BEDEE, FRANCE</td>
										</tr>
										<tr>
											<td>3</td>
											<td>GUILLAUME BOISSON</td>
											<td>12 RUE JEAN MALO-RENAULT, F-35000 RENNES, FRANCE</td>
										</tr>
										<tr>
											<td>4</td>
											<td>GWENAELLE MARQUANT</td>
											<td>LIEU DIT L&#x27;HOTEL HAREL, F-35630 LA CHAPELLE CHAUSSEE, FRANCE</td>
										</tr>
										<tr>
											<td>5</td>
											<td>PHILIPPE ROBERT</td>
											<td>7 ALLEE DU BOIS LOUET, F-35235 THORIGNE FOUILLARD, FRANCE.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/FR05/050108</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-02-21</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>0450419</td>
									<td>2004-03-02</td>
								    <td>France</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/260935-method-for-coding-and-decoding-an-image-sequence-encoded-with-spatial-and-temporal-scalability by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 02:27:23 GMT -->
</html>
