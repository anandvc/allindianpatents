<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/225797-method-and-device-for-motion-estimation-and-compensation-for-panorama-image by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:32:23 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 225797:METHOD AND DEVICE FOR MOTION ESTIMATION AND COMPENSATION FOR PANORAMA IMAGE</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND DEVICE FOR MOTION ESTIMATION AND COMPENSATION FOR PANORAMA IMAGE</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A device and a method for motion estimation and compensation to be performed on a panorama image with a 360 ° omni-directional view based on that a spatial relation between left and right borders of the panorama image is very high. Accordingly, it is possible to improve an image quality through effective and precise estimation and compensation for the motion of the panorama image. In particular, it is possible to improve the image quality at the right and left edges of the panorama image.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>F0RM2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970)<br>
&amp;<br>
THE PATENTS RULES, 2003<br>
COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
"METHOD AND DEVICE FOR MOTION ESTIMATION AND COMPENSATION FOR PANORAMA IMAGE"<br>
a)	INDUSTRY ACADEMIC COOPERATION FOUNDATION KYUNGHEE UNIVERSITY a Non-propit academy entity of korea of 1, Seochun-ri, Kiheung-eup, Yongin-si, Gyeonggi-do, Republic of Korea<br>
b)	SAMSUNG ELECTRONICS CO., LTD a Korean corporation of 416, Maetan-dong, Yeongtong-gu, Suwon-si, Gyeonggi-do 442-742, Republic of Korea<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br>
■   /*-<br>
WO 2006/016783	PCT/KR2005/002639<br>
Description<br>
METHOD AND DEVICE FOR MOTION ESTIMATION AND<br>
COMPENSATION FOR PANORAMA IMAGE<br>
Technical Field<br>
[1]	The present general inventive concept relates to motion estimation and com-<br>
pensation for a panorama image, and more particularly, to a method and apparatus to estimatea motion of a panorama image containing 360 ° omni-directional image information, and a method and apparatus to compensate for the motion of the panorama image.<br>
Background Art<br>
[2]	An omni-directional video camera system is capable of acquiring a 360 ° omni-<br>
directional view from a single viewpoint. The omni-directional video camera system includes a camera to which a special mirror, such as a hyperboloid mirror, or a special lens, such as a fish-eye lens, is installed, or a plurality of cameras.<br>
[3]	Three-dimensional (3D) realistic broadcasting may be applied to omni-directional<br>
video coding. As an example of a 3D realistic broadcasting service, a viewer's terminal receives all image information regarding scenes viewed from diverse viewpoints, such as the viewpoints of a pitcher, a catcher, a hitter, and an audience on a first base side in a baseball game, and the viewer can select a desired viewpoint to view one of the scenes from the desired viewpoint<br>
[4]	An image captured by the omni-directional camera system has characteristics cor-<br>
responding to a 3D cylindrical environment and thus is transformed into a two-dimensional (2D) plane image. In this case, the 2D plane image is a panorama image with a 360 ° omni-directional view, and omni-directional video coding is performed on the 2D panorama image.<br>
[51	In a motion estimation technique, which is one of image coding techniques, a<br>
motion vector is computed by detecting a data unit, which is most similar to a data unit in a current frame, from a previous frame using a predetermined evaluation function, the motion vector represents a position difference between the data units, and, in general, 16 ' 16 macro blocks are used as the data blocks but the sizes of macro blocks are not limited, and for instance, the data units may be 16x 8,8x16, or 8x8 macro blocks.<br>
[6]	A conventional motioa estnnatioa<br>
blocks will now be described in greater detail. First, a motion vector of a current macro block of a current frame is predicted using a plurality of previous macro blocks of a previous frame adjacent to a position cx)nespxrad1ng to the oirrent macro block of the<br><br>
WO 2006/016783	PCT/KR2005/002639<br>
current frame. FIG. 1 illustrates a plurality of previous macro blocks A, B, C, and Dof<br>
the previous frame used to estimate the motion vector of a current macro block x of<br>
the current frame. The previous macro blocks A through D are encoded before coding of the current macro block X.<br>
[7]	However, sometimes, some of previous macro blocks adjacent to the current macro<br>
block X are unavailable in estimating the motion vector of the current macro block X according to the position of the current macro block X in the current frame. FIG. 2A illustrates a case where the previous macro blocks B, C, and D required for estimation of the motion vector of the current macro block X are not present. In this case, the motion vector of the current macro block X is set to 0.<br>
[8]	FIG. 2B illustrates a case where the previous macro blocks A and D are not present.<br>
In this case, the motion vectors of the previous macro blocks A and D are set to 0, and the motion vector of the current macro block X is set to a median value of the motion vectors of the previous macro blocks A through D.<br>
[9]	FIG. 2C illustrates a case where the previous macro block C is not present. In this<br>
case, the motion vector of the previous macro block C is set to 0, and the motion vector of the current macro block X is set to the median value of the motion vectors of the previous macro blocks A through D.<br>
[10]	After predicting the motion vector of the current macro block X, the similarity<br>
between each reference macro block in a reference frame indicated by the predicted motion vector and the current macro block X is computed using a predetermined evaluation function. Next, a reference macro block that is most similar to the current macro block X is detected from the reference frame within a predetermined search range. In general, a sum of absolute differences (SAD) function, a sum of absolute transformed differences (SATD) function, or a sum of squared differences (SSD) function is used as the predetermined evaluation function.<br>
[11]	During detection of the most similar reference macro block within the pre-<br>
determined search range, some or all pixels of the reference macro blocks may be present outside thepredeterminedsearchrange. In this case, as illustrated in FIG. 3, it is necessary to pad values of the pixels on left and right borders of the most similar reference macro block pixels to an outside of the left and right borders, respectively, to perform motion estimation and compensation. This motion estimation and compensation is referred to as motion estimation and compensation in an unrestricted motion vector (UMV) mode.<br>
[12]	HG.4A illustrates a c^liiidricd<br>
illustrates a panorama image with a 360 ° omni-directional view, taken along with a line X of the cylindrical image of FIG. 4A. Referring to FIG. 4B, a left side A and a right side B of a human-shaped object shown in FIG. 4A are positioned at the right and<br><br>
WO 2006/016783	PCT/KR2005/002639<br>
left borders of the panorama image, respectively. That is, a spatial relation between the right and left borders of the panorama image with the 360 ° omni-directional view is very high.<br>
[13]	Thus, it is ineffective to perform the conventional motion estimation and com-<br>
pensation on a panorama image with an omni-directional view without considering characteristics of the panorama image. Thus, a method of effectively estimating and compensating for the motion of a panorama image with an omni-directional view is required. Disclosure of Invention<br>
Technical Solution<br>
[14]	The present general inventive concept provides a method and apparatus to ef-<br>
fectively and precisely estimatea motion of a panorama image containing omnidirectional image information.<br>
[15]	The present general inventive concept also provides a method and apparatus to ef-<br>
fectively and precisely compensate for a motion of a panorama image containing omn directional image information.<br>
Advantageous Effects<br>
[16]	According to the presentgeneralinventive concept, motion estimation and com-<br>
pensation are performed on a panorama image with a 360 ° omni-directional view based on that the spatial relation between right and left borders of the panorama image is very high, thereby increasing the efficiency and precision of motion estimation and compensation. Accordingly, it is possible to improve image quality, in particular, the image quality at the right and left borders of the panorama image.<br>
Description of Drawings<br>
[17]	FIG. 1 is a diagram illustrating a plurality of previous macro blocks available for<br>
conventional estimation of a motion vector for a current macro block;<br>
[18]	FIGS. 2A through 2C are diagrams illustrating cases where previous macro blocks<br>
to be used for estimation of a motion vector of a current macro block are not present;<br>
[ 19]	FIG. 3 is a diagram illustrating a conventional method of padding a reference<br>
image;<br>
[20]	FIG. 4A is a diagram illustrating a cylindrical image with a 360 ° omni-directional<br>
view;<br>
[21]	FIG. 4B is a diagram illustrating a two-dimensional (2D) image corresponding to<br>
the cylindrical image of FIG. 4A;<br>
[22]	HG. 5 is a block diagram inusta*ing<br>
of a panorama image according to an embodiment of the preaentgeaeral inventive concept;<br><br>
WO 2006/016783	PCT/KR2005/00^639<br>
[23]	FIGS. 6A and 6B are flowcharts illustrating a method of estimating the moti on of a<br>
panorama image according to an embodiment of the presentgeneral inventive concept;<br>
[24]	FIG. 7A is a diagram illustrating selection of previous maCTO blOCkS tO be U&amp;ed fOT<br>
estimation of a motion vector of a current macro block according to an embodiment of the presentgeneral inventive concept;<br>
[25]	FIG. 7B is a diagram illustrating selection of previous macro blocks to be used for<br>
estimation of a motion vector of a current macro block according to another embodiment of the presentgeneral inventive concept;<br>
[26]	FIG. 8A is a diagram illustrating a case where a reference macro block parti ally<br>
overlaps with a reference image;<br>
[27]	FIG. 8B is a diagram illustrating a case where a reference macro block is positioned<br>
outside a reference image;<br>
[28]	FIG. 9 is a diagram illustrating a method of padding a reference image acco rding to<br>
an embodiment of the presentgeneral inventive concept;<br>
[29]	FIG. 10 is a diagram illustrating a motion vector of a current macro block;<br>
[30]	FIG. 11 is a block diagram illustrating a decoding unit that decodes a motion vector<br>
of a panorama image according to an embodiment of the presentgeneralinven-tiveconcept; and<br>
[31]	FIG. 12 is a flowchart illustrating a method of compensating for a motion o f a<br>
panorama image according to an embodiment of the presentgeneral inventive concept<br>
Best Mode<br>
[32]	The foregoing and/or other aspects of the present general inventive conceptmay be<br>
achieved by providing a method of estimating a motion of a current panorama image containing 360 ° omni-directional view information, the method comprising estimating a motion vector of a current data unit of the panorama image using motion vectors of a plurality of previous reference data units of a reference image adjacent to the current data unit, when one or more pixels of one of the reference data units indicated by the estimated motion vector are present outside one of left and right borders of a reference image, padding an image in a predetermined range from the other border of the reference image outside the one of the left and right borders; obtaining values of all pixels of the reference data unit from the padded reference image; and determining a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
[33]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing a JBcthod of estimating a nx)tioii of a cunient panorama image containing 360 ° onmHJBttCtkmal view information, tfre method OTPiprising estimating a motion vector of acanvtt data umt of the vectors of a plurality of previous reference data units adjaceit to me current data unit,<br><br>
ft<br>
WO 2006/016783	PCT/KR2005/002639<br>
when one or more pixels of one of reference data unit indicated by the estimated motion vector are present outside one of left and right borders of the reference image,<br>
obtaining values of all pixels of the one of the reference data units of the reference image from a cylindrical image which is obtained by connecting the left and right borders of the reference image when the reference image is the cylindrical image, and determining a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
[34]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing an apparatus to compensate for a motion of a panorama image containing 360 ° omni-directional view information, the apparatus comprising a memory to store a reference image to be used for motion estimation of the panorama image, and motion vectors of a plurality of previous reference data units adjacent to a current data unit of the panorama image, and a motion estimating unit to estimate a motion vector of the current data unit using the motion vectors of the plurality of the previous data units, when one or more pixels of one of the reference data units indicated by the estimated motion vector are present outside one of left and right borders of the reference image, padding an image in a predetermined range from the other border of the reference image outside the one of the left and right borders,to obtain values of all pixels of the reference data unit from the padded reference image, and to determine a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
[35]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing an apparatus to estimate a motion of a panorama image containing 360 ° omni-directional view information, the apparatus comprising a memory to store a reference image to be used for motion estimation of the panorama image, and motion vectors of a plurality of previous reference data units of the reference image adjacent to a current data unit of the panorama image, and a motion estimating unit to estimate a motion vector of the current data unit using the motion vectors of the plurality of the previous data units, when one or more pixels of one of the reference data units indicated by the estimated motion vector are present outside one of left and right borders of the reference image, to obtain values of all pixels of the reference data unit from a cylindrical image obtained by connecting the left and right<br>
borders of the reference image on an assumption that the reference image is the<br>
cylindrical image, and to determine a similarity between the current data unit and the<br>
reference data unit using a rjwdetermiiiedevaraation function.<br>
[36]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing a method of compensating ftw a motion of a panorama image containing 360 ° omni-directional view information, the method comprising<br><br>
*1<br>
WO 2006/016783	PCT/KK2005/002639<br>
receiving a motion vector of a current data unit of the panorama image, when one or more pixels of one of reference data units of a reference image indicated by the motion<br>
vector of the current data unit are present outside one of left and right borders of the reference image, padding the reference image in a predetermined range from the other border of the reference image outside the one of the left and right borders of the reference image, obtaining values of all pixels of the reference data unit from the padded reference image, and reproducing the current data unit using the values of the pixels of the reference data unit.<br>
[37]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing a method of compensating for a motion of a panorama image containing 360 ° omni-directional view information, the method comprising receiving a motion vector of a current data unit of the panorama image, when one or more pixels of one of reference data units of a reference image indicated by the motion vector of the current data unit are present outside one of left and right borders of the reference image, obtaining values of all pixels of the reference data unit from a cylindrical image which is obtained by connecting the left and right borders of the reference image when the reference image is the cylindrical image; and reproducing the current data unit using the values of the pixels of the reference data unit.<br>
[38]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing an apparatus to compensate for a motion of a panorama image containing 360 ° omni-directional view information, the apparatus comprising a memory to store a reference image to be used for motion estimation of the panorama image, and a motion compensating unit to receive a motion vector of a current data unit of the panorama image, when one or more pixels of one of reference data units of a reference image indicated by the motion vector of the current data unit are present outside one of left and right borders of the reference image, to padthe reference image in a predetermined range from the other border of the reference image outside the one of the left and right borders of the reference image,to obtain values of all pixels of the reference data unit from the padded reference image, and to reproduce the current data unit using the values of the pixels of the reference data unit.<br>
[39]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing an apparatus to compensate for the motion of a panorama image containing 360 ° omni-directional view information, the apparatus comprising a memory to store a reference image to be used for motion estimation of the panorama image; and a motion compensating unit to recajw amotion vector of a current data unit of the paaoraam image, when one or mare fixete of reference data units of a reference image indicated by me riwriOT vector of the current data unit are present outside one of left and right borders of the reference image, to obtain values of<br><br>
WO 2006/016783	PCT/KR2005/002639<br>
all pixels of the reference data unit from a cylindrical image which is obtained by connecting the left and rights borders of the reference image when the reference image is the cylindrical image; and reproducing the current data unit using the values of the pixels of the reference data unit.<br>
[40]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing a n apparatus to estimate a motionvectorof a panorama image containing 360 ° omni-directional view information, the apparatus comprisinga memory to store a reference image having first and second borders and first and second reference data units disposed adjacent to the first border and the second border, re-spectively,within the reference image,anda motion estimating unit to receive a current data unit of a current image and the reference data units of the reference image from the memory, and to estimate a motion vector of the current data unit using one of the first and second reference data units of the reference image which is not included in a search area when the other one of the first and second reference data units is included in the search area.<br>
[41 ]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing a n apparatus to generate a panorama image containing 360 ° omni-directional view information, the apparatus comprising a decoding unit to decode a bitstream having data corresponding to a current image and a reference image, and togenerate a motion vector of a current data unit of the current image to correspond to a search area of the reference image which includes a first reference data unit disposed on a first border of the reference image.a panorama image motion compensating unit to generate a reference macro blockofthe first reference data unit of the reference image usinga second reference data unit disposed on a second border of the reference image which is not included in the search area according to die motion vector,and an output unit to generate die current image according to the reference macro block and data corresponding to the decoded bitstream.<br>
[42]	The foregoing and/or other aspects of the present general inventive concept may<br>
also be achieved by providing a n apparatus having an encoder and a decoder to estimate a motion vector of a panorama image containing 360 ° omni-directional view information. The encoder comprises a memory to store a reference image having first and second borders and first and second reference data units disposed adjacent to the first border and die second border, respectively, within the reference image,a motion estimating unit to receive a current data unit of a current image and die reference data units of die reference image from die memory, and to estimate a motion vector of die current data unit using one ofme fust and second reference (fata units of die reference image which is not included in a search area when die odier one of die first and second reference data units is included in die search area,a panorama image motion com-<br><br>
WO 2006/016783	PCT/KR2005/O02639<br>
pensating unit to generate a reference macro block according to the motion vector and the reference image,anda coding unit togenerate an bitstream according to the current image and the reference macro block. The decoder comprises a decoding unit to decode the bitstream having data corresponding tothecurrent image and the reference image, and to generate the motion vector ofthe current data unit of the current image to correspond to the search area of the reference image which includes the first reference data unit disposed on the first border of the reference image,a second panorama image motion compensating unit to generate the reference macro block of the first reference data unit of the reference image using the second reference data unit disposed on the second border of the reference image which is not included in the search area according to the motion vector,and an output unit to generate the current image according to the reference macro block and data corresponding to the decoded bitstream.<br>
[43]	[0012] The foregoing and/or other aspects of the present general inventive concept<br>
may also be achieved by providing a method of estimating a motion vector of a panorama image containing 360 ° omni-directional view information, the method comprising storing a reference image having first and second borders and first and second reference data units disposed adjacent to the first border and the second border, respectively, within the reference image,and receiving a current data unit of a current image and the reference data units of the reference image from the memory, and estimating a motion vector of the current data unit using one of the first and second reference data units of the reference image which is not included in a search area when the other one of the first and second reference data units is included in the search area.<br>
[44]	[0013] The foregoing and/or other aspects of the present general inventive concept<br>
may also be achieved by providing a method of generating a panorama image<br>
containing 360 ° omni-directional view information, the method comprising decoding<br>
a bitstream having data corresponding to a current image and a reference image,<br>
generatinga motion vector of a current data unit of the current image to correspond to a<br>
search area of the reference image which includes a first reference data unit disposed<br>
on a first border of the reference image, generatinga reference macro block of the first<br>
reference data unit of the reference image using a second reference data unit disposed<br>
on a second border of the reference image which is not included in the search area<br>
according to the motion vector,and generating the current image according to the<br>
reference macro block and data corresponding to the decoded bitstream.<br>
[45]	|0O14] The foregoing and/or other aspects of the preseitf jgeneral inventive concept<br>
may also be achieved by provide<br>
panorama image containing 360 ° omni-directional view mfdrmation, the method comprising storing a reference image having fast and second borders and first and<br><br>
WO 2006/016783	PCT/KR2005/002639<br>
second reference data units disposed adjacent to the first border and the second border, respectively, within the reference image,receiving a current data unit of a current<br>
image and the reference data units of the reference image from the memory, estimating a motion vector of the current data unit using one of the first and second reference data units of the reference image which is not included in a search area when the other one of the first and second reference data units is included in the search area,generating a reference macro block according to the motion vector and the reference image,generating a bitstream according to the current image and the reference macro block,decoding the bitstream having data corresponding to the current image and the reference image, generating the motion vector of the current data unit of the current image to correspond to the search area of the reference image which includes the first reference data, unit disposed on the first border of the reference image,generating the reference macro block of the first reference data unit of the reference image using the second reference data unit disposed on the second border of the reference image which is not included in the search area according to the motion vector,and generating the current image according to the reference macro block and data corresponding to the decoded bitstream.<br>
Mode for Invention<br>
[46]	Reference will now be made in detail to the embodiments of the present general<br>
inventive concept, examples of which are illustrated in the accompanying drawings, wherein like reference numerals refer to the like elements throughout. The embodiments are described below in order to explain the present general inventive con-ceptwhilereferring to the figures.<br>
[47]	FIG. 5 is a block diagram illustrating an encoding unit that encodes a motion vector<br>
of a panorama image according to an embodiment of the presentgeneral inventive concept. Referring to FIG. 5, the encoding unit includes a transforming unit 110, a quantizing unit 115, an inverse quantizing unit 120, an inverse transforming unit 125, an adding unit 130, a clipping unit 140, a frame memory 150, a panorama image motion estimation unit 160, a panorama image motion compensation unit 170, a subtraction unit 180, and a variable-length coder (VLC) 190.<br>
[48]	The transforming unit 110 receives an input panorama image and transforms the<br>
received panorama image through predetermined transformation to output transform coefficients. The input panorama image is a panorama image with a 360 ° omnidirectional view as shown in FIG. 4B, taken along a line X of a cylindrical image shown in FIG. 4A. The fwateniwiaed transform performed fay the mmfiarmiag unit 110 may be a discrete cosine tmnfoim (DCT)inunitsof 8'8 blocks.<br>
[49]	The quantizing unit 115 p^»«^w the transform c^ffkieatsrecw<br>
transforming unit 110. After the quantised transform coefficients we inversely<br><br>
Vt\ <br>
WO 2006/016783<br><br>
PCT/KR2005/002639<br><br>
quantized by the inverse quantizing unit 120 and inversely transformed by the inverse transforming unit 125, the input panorama image is reproduced. The reproduced panorama image is normalized by the clipping unit 140 and stored in the frame memory 150. The panorama image stored in the frame memory 150 is used as a reference panorama image in motion estimation and compensation of a newly input panorama image. The adding unit 130may have a predetermined value, receivethe reproduced panorama image,modify the reproduced panorama imageusingthepredeter-minedvalue, andoutput one of the reproduced panorama image and the modified panorama image to the clipping unitl40 and the panorama image motion compensation unit 170 as the reproduced panorama image. It is possible that the modified panorama image is the same as the reproduced panorama image according to the predetermined value.<br>
[50]	The panorama image motion estimation unit 160 performs motion estimation, using<br>
the reference panorama image stored in the frame memory 150. Specifically, the panorama image motion estimation unit 160 receives information regarding the current panorama image, obtains a motion vector of the current panorama image by performing motion estimation on the current panorama image using the reference panorama image stored in the frame memory 150, and outputs the motion vector to the VLC 190. Motion estimation and compensation are performed in units of predetermined blocks referred to as data units. In this embodiment, the data units may be 16x16 macro blocks.<br>
[51]	The panorama image motion compensation unit 170 performs the motion com-<br>
pensation. In detail, the panorama image motion compensation unit 170 receives the motion vector of a current macro block ofthe current panorama image from the panorama image motion estimation unit 160 and thereference panorama image of the frame memory 150, and outputs a reference macro block corresponding to the current macro block to the subtraction unit 180 using themotion vector ofthe current macro block of the current panorama image and the reference panorama image ofthe frame memory 150. The panorama image motion compensation unit 170 may use the reproduced panorama image and the motion vector togeneratethe reference macro block. The subtraction unit 180 outputs a restdualsignal between the current macro block and the reference macro block to the transforming unit 110. The residual signal is transformed by the transforming unit 110, quantized by the quantizing unit 115, and variable-length coded by the VLC 190. The motion vector of the current macro block generated by the panorama image motion estiinationunh 16^ is k^itt directly to and variable-length c»ded by the VLC 190.<br>
[52]	The operation of the panorama image motion estimation writ 160 will now be<br>
described in greater detail with reference toFIGS. 6Aand6B. FIGS. 6A and 6B are<br><br>
WO 2006/016783	PCT/KR2005/MJ2639<br>
flowcharts illustrating a method of estimating the motion of a panorama imagJ according to an embodiment of the presentgeneral inventive concept. Referring<br>
toFlGS. 5, 6A, and 6B, the panorama image motion estimation unit 160 estllr&amp;ies a motion vector of a current data unit using motion vectors of a plurality of previous data units adjacent to the current data unit (S310). As illustrated in FIG. 1, a data unit X is a current data unit, and the data units A, B, C and D are previous data units required for estimation of a motion vector of the current data unit X. In this embodiment, the data units may be 16x16 macro blocks. The current data unit X is included in a current frame, and the plurality of previous data units A, B, C and D are included in a previous frame.<br>
[S3]	In detail, the panorama image motion estimation unit 160 detects the motion vectors<br>
of the previous macro blocksA, B, C, and D stored in an internal memory (not shown). When all the previous macro blocksA through D are present, the motion vector of the current macro block X is estimated according to predetermined or conventional motion estimation, using the detected motion vectors.<br>
[54]	However, at least one of the previous macro blocks A through D may not be<br>
present. FIG. 7 A illustrates a case where the previous macro blocks A and D are not. present in a panorama image, and thus, their motion vectors are unavailable for motion estimation of the current macro block X. FIG. 7B illustrates a case where the previous macro block C is not present in a panorama image, and thus, its motion vector is unavailable for motion estimation of the current macro block X.<br>
[55]	As described above, a spatial relation between the right and left borders of a<br>
panorama image with a 360 ° omni-directional view is very high. That is, a distance between the right and left borders of the panorama image is substantially 0. According to this embodiment of the presentgeneral inventive concept, when one or more of the previous macro blocks A, C, and D required for estimation of the motion vector of the current macro block X are not present, the motion vectors of the previous macro blocks required for motion estimation are determined using the above characteristics of the panorama image. For instance, referring to FIG. 7A, a previous macro block D' at a right side of the panorama image and on a Y-axis on which the previous macro block D is positioned is substantially the same as the previous macro block D. Accordingly, a motion vector of the previous macro block D' is considered to be the same as that of the previous macro block D and can be used in estimation of the motion vector of the current macro block X. In contrast, when the motion vector of a previous macro block at aright side of the panorama image and on an Y-axis on which the previous macro block A is positioned, is predicted after motion estimation of the current macro block X , there is no available motion vector for the previous macro block A. Accordingly, the motion vector of the previous macro block A required for estimation of the motion<br><br>
1213<br><br>
WO 2006/016783<br><br>
PCT/KR2005/M32639<br><br>
vector of the current macro block X is set to 0.<br>
[56]	Referring to FIG. 7B, a previous macro block C at a left side of the panorama<br>
image and on an Y-axis on which the previous macro block C is positioned, u   substantially the same as the previous macro block C. Thus, a motion vector of the previous macro block C is considered the same as that of the previous macro block C and thus is used in estimation of the motion vector of the current macro block X.<br>
[57]	Referring back toFIGS. 6A and 6B, after the motion vector of the current ltiacro<br>
block X(or current data unit) is estimated in operation S310, the panorama hrage motion estimation unit 160 determines whether the reference macro block indi cated by the estimated motion vector is present in a reference image (or reference panorama image)in operation S315. The reference image is stored in the frame memory 150.<br>
[58]	If all pixels of the reference macro block indicated by the motion vector of the<br>
current macro block X are present in the reference image, the pixels of the reference macro block are fetched from the frame memory 150 (S335), and the similarity between the current macro block X and the reference macro block is determined using a predetermined evaluation function (S335).<br>
[59]	However, when some or all of the pixels of the reference macro block indicated by<br>
the motion vector of the current macro block X are present outside one of right and left borders of the reference image, an image present in a predetermined range of the reference image from the other border is padded outside the one of the right and left borders (S320).<br>
[60]	FIG. 8A illustrates a case where the reference macro block is positioned at a border<br>
of the reference image. FIG. 8B illustrates a case where the reference macro block is positioned outside the reference image.<br>
[61]	Referring to FIG. 3, conventional motion estimation and compensation are<br>
performed after padding values of pixels at a left border of a reference image to the outside of the left border and pixels at a right border of the reference image to the outside of the right border. In contrast, the embodiment of the present general inventive concept is based on that the spatial relation between the right and left borders of a panorama image with a 360 ° omni-directional view is very high. Referring to FIG. 9, an outside region 480 of a left border region 450 of a reference image 400 is padded with the values of pixels at a right border region 470 of the reference image 400. An outside region 460 of the right border region 470 is padded with the values of<br>
pixels at the left bonder region 450.<br>
(62]	Next, after paddrngtrwrefewncemiage in ooer^^<br>
motion estimation unit 160 fetches afi pixel values of the reference macro block from the padded reference image in the frame mernory 150 (S325). Thereafter, tte siintfarity between the current macro block X and me reference macro block is evaluated using a<br><br>
tftf<br><br>
WO 2006/016783<br><br>
PCT/KR2005A) 02639<br><br>
predetermined evaluation function (S335). In general, a sum of absolute differences (SAD) function, a sum of absolute transformed differences (SATD) function, or a sum<br>
of squared differences (SSD) function is used as the predetermined evaluation function.<br>
[63]	Alternatively, when the reference image is a cylindrical image obtained by<br>
connecting the right and left borders of the reference image, it is possible to obtain the values of all pixels of a reference data unit from the cylindrical image without padding the reference image. Specifically, the reference image is a two-dimensional (2D) plane image such as that shown in FIG. 4B, and the cylindrical image such as that shown in FIG. 4A is obtained by connecting the right and left borders of the 2D plane image. That is, when the reference image is a cylindrical image, the values of all pixe 1 values of the reference data unit can be obtained from the cylindrical image.<br>
[64]	Next, the panorama image motion estimation unit 160 changes a position of the<br>
reference macro block in a predetermined search range and determines the similarity between the changed reference macro block and the current macro block X (S340 and S345). After the evaluation of the similarity between the current macro block X and each of a plurality of reference macro blocks in the predetermined search range, the panorama image motion estimation unit 160 determines a reference macro block that is the most similar to the current macro block X from the plurality of reference macro blocks, and generates a motion vector of the determined reference macro block (S350).<br>
[65]	FIG. 10 is a diagram illustrating a motion vector of a current macro block 510. In<br>
FIG. 10, a reference numeral 530 denotes the macro block that is most similar to the current macro block 510 and present on the padded reference image, and a reference numeral 540 denotes the macro block that corresponds to the macro block 530 and is present on the non-padded image 500. When the macro block 530 is the most similar to the current macro block 510, a reference numeral 550 denotes the motion vector of the current macro block 510. When the reference macro block 540 is the most similar to the current macro block 510, a reference numeral 560 denotes the motion vector of the current macro block 510. That is, the motion vector of the current macro block 510 may be one of the motion vectors 550 and 560. However, a motion vector of a macro block that does not fall within a predetermined search range may not be transmitted to a decoder (not shown). Therefore, the motion vector 550 of the reference macro block 530 maybe determined as the motion vector of the current macro block 510.<br>
[66]	A method and apparatus for compensating for the motion of a panorama image<br>
according to an embodiment of the present general inventive concept will now be described<br>
[67]	FIG. 11 is a block diagram of a decoding unit that decodes a motion vector of a<br>
panorama image according to an embodiment of the present invention. Referring to<br><br>
14) f<br>
WO 2006/016783	PCT/KR2005/) 02639<br>
FIG. 11, the decoder includes a variable-length decoder (VLD) 710, an inverse quantizing unit 720, an inverse transforming unit 730, an adding unit 740, a panorama image motion compensating unit 750, a clipping unit 760, and a frame memory 770.<br>
[68]	The VLD 710 decodes an input bitstream using a variable-length coding/<br>
decodingmethod. A motion vector and a residual signal between a macro bloc It and a reference macro block output from the VLD 710 are input to the panorama im age m otion compensating unit 750 and the inverse quantizing unit 720, respectively.<br>
[69]	The frame memory 770 stores a reference panorama image obtained by sequentially<br>
inputting the input bitstream to the inverse quantizing unit 720, the inverse transforming unit 730, and the clipping unit 760. The reference panorama image stored in the frame memory 770 is used for compensation for the motion of a newly input panorama image (current panorama image).<br>
[70]	The panorama image motion compensating unit 750 performs motion compensation<br>
using the reference panorama image stored in the frame memory 770. In detail, the panorama image motion compensating unit 750 receives a motion vector of a current macro block of the panorama image from an encoder such as that shown in FIG. 5, reads a reference macro block of a previous frame corresponding to the current macro block in the frame memory 770, and outputs the read reference macro block to the adding unit 740. Then, the adding unit 740 receives the residual signal between the current macro block and the reference macro block that are inversely quantized by the inverse quantizing unit 720 and inversely transformed by the inverse transforming 730.<br>
[71]	The adding unit 740 reproduces the current macro block using the residual signal<br>
between the current macro block and the reference macro block, and the reference macro block input from the panorama image motion compensating unit 750. The clipping unit 760 normalizes the reproduced current macro block output from the adding unit 740.<br>
[72]	The operation of the panorama image motion compensating unit 750 will now be<br>
described in greater detail. FIG. 12 is a flowchart illustrating a method of compensating for the motion of a panorama image according to an embodiment of the pre-sentgeneral inventive concept.<br>
[73]	Referring toFIGS. 11 and 12, the panorama image motion compensating unit 750<br>
receives a motion vector of a current data unit on which motion estimation is to be performed from the VLD 710 (S910). In this embodiment, data units may be 16 ' 16<br>
macro blocks.<br>
[741	Next, the paiwraminiageinotioncam^<br>
reference macro Week mdicated by the nation veaor of tfie current n»cro Hock is present in a reference image (S920). The reference image is stored in the frame memory 770.<br><br>
tftt<br><br>
WO 2006/016783<br><br>
PCT/KR2005/KJ2639<br><br>
[75]	When pixels of the reference macro block indicated by the motion vector oif the<br>
current macro block are present in the reference image, the values of all pixels of the<br>
reference macro block are read from the frame memory 770 (S950), and the current macro block is reproduced (S960). The adding unit 740 reproduces the current macro block, using the residual signal between the current macro block and the refeience macro block output from the inversely transforming unit 730 and the reference macro block output from the panorama image motion compensating unit 750.<br>
[76]	However, as illustrated in FIG. 8A or 8B, when some or all of the pixels of the<br>
reference macro block indicated by die motion vector of the current macro block are positioned outside one of left and right borders of the reference image, an image in a predetermined range from the other border of the reference image is padded outside the one of the left and right borders (S930). According to the present invention, as  illustrated in FIG. 9, regions outside of the reference image are padded based on that the spatial relation between right and left borders of a panorama image with a 360 ° omnidirectional view is very high.<br>
[77]	Next, after padding the reference image in operation S930, the panorama image<br>
motion compensating unit 750 reads the values of all pixels of the reference macro block from the padded reference image from the frame memory 770 (S940).<br>
[78]	Alternatively, when the reference image is a cylindrical image obtained by<br>
connecting the left and right borders of the reference image, it is possible to obtain the values of all pixels of the reference data unit from the cylindrical image without padding the reference image. More specifically, the reference image is a 2D plane image such as that shown in FIG. 4B, and the cylindrical image such as mat shown in FIG. 4B is obtained by connecting the left and right borders of the 2D plane image. That is, if the reference image is the cylindrical image, the values of all pixels of the reference data unit can be obtained from the cylindrical image.<br>
[791	Lastly, the adding unit 740 reproduces the current macro block using the residual<br>
signal between the current macro block and the reference macro block and the reference macro block input from the panorama image motion compensating unit 750 (S960).<br>
[801	The present general inventive concept may be embodied as computer readable code<br>
in a computer readable medium. Here, the computer readable medium may be any recording apparatus capable of storing data that is read by a computer system, e.g., a<br>
read-only memory (ROM), a random access memory (RAM), a compact disc (CD)-ROM, a magnetic tape, a floppy disk, an optical data storage device, and so on. Abo, the computer readable medium may be a carrier wave mat transmits data via the Internet, for example. The computer readable medium can be distributed among computer systems mat are interconnected through a network, and the present invention<br><br>
«m<br><br>
WO 2006/016783<br><br>
PCT/KR2005O02639<br><br>
may be stored and implemented as a computer readable code in the distributed system.<br>
[81]	As described above, according to the presentgeneralinventive concept, motion<br>
estimation and compensation are performed on a panorama image with a 360 ° omnidirectional view based on that the spatial relation between right and left bord&amp;rs of the panorama image is very high, thereby increasing the efficiency and precision of motion estimation and compensation. Accordingly, it is possible to improve image quality, in particular, the image quality at the right and left borders of the panorama image.<br>
[82]	Although a few embodiments of the present general inventive concept have been<br>
shown and described, it will be appreciated by those skilled in the art that chuiges may be made in these embodiments without departing from the principles and spirit of the general inventive concept, the scope of which is defined in the appended claims and their equivalents.<br><br>
vr\t<br>
WO 2006/016783	PCT/KR2005/MJ2639<br>
Claims<br>
[1]	What is claimed is:<br>
1. A method of estimating a motion of a panorama image containing 3(0 ° omnidirectional view information, the method comprising: estimating a motion vector of a current data unit of the panorama image using motion vectors of a plurality of previous reference data units adjacent to the current data unit;<br>
when one or more pixels of one of the reference data units indicated by the estimated motion vector are present outside one of left and right borders of the reference image, padding the reference image in a predetermined range from the other border of the reference image outside the one of the left and right borders; obtaining values of all pixels of the one of the reference data units from the padded reference image; and<br>
determining a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
[2]	2. The method of claim 1, wherein when the one or more of die plurality of the<br>
previous data units is present outside one of the left and right borders of the panorama image, the estimating of the motion vector of the current data unit comprises:<br>
determining the plurality of the previous data units from a cylindrical image which is obtained by connecting the left and right borders of the reference image when the reference image is the cylindrical image.<br>
[3]	3. The method of claim 1, wherein the plurality of the previous data units<br>
comprise:<br>
a first data unit disposed adjacent to a position corresponding toa left side of the current data unit;<br>
a second data unit disposed adjacent to a position correspondingtoa top of the current data unit;<br>
a third data unit disposed adjacent to a right sideof die second data unit; and a fourth data unit disposed adjacent to both the first and second data units.<br>
[4]	4. The method of claim 1, further comprising:<br>
determining the one of the reference data units which is the most similar to the<br>
current data unit in a predetermined search range; and<br>
determining the motion vector representing the determined reference data unit<br>
[5]	5.ArnediadofestmiatiiigaiiiotiOTof	omni-<br>
directional view information, the method comprising: estimating a motion vector of a current data unit of the panorama image, using<br><br>
WO 2006/016783	PCT/KR2OO50 U2639<br>
motion vectors of a plurality of previous reference data units adjacent to the current data unit;<br>
when one or more pixels of one of the reference data units indicated byi the estimated motion vector are present outside one of left and right borders of the reference image, obtaining values of all pixels of one of the reference data units of the reference image from a cylindrical image which is obtained by connecting the left and right borders of the reference image when the reference image is the cylindrical image; and<br>
determining a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
6.	The method of claim 5, wherein when at least one of the plurality of the<br>
previous reference data units is present outside one of the left and right borders<br>
of the panorama image, the estimating of the motion vector of the current data<br>
unit comprises:<br>
determining the plurality of the previous reference data units from a cylindrical image which is obtained by connecting the left and right borders of the reference image on when the panorama image is the cylindrical image.<br>
7.	The method of claim S, wherein the plurality of the previous data units<br>
comprise:<br>
a first data unit disposed adjacent to a position corresponding toa left side of the<br>
current data unit;<br>
a second data unit disposed adjacent to a position corresponding toa top of the<br>
current data unit;<br>
a third data unit disposed adjacent to a right sideof the second data unit; and<br>
a fourth data unit disposed adjacent to both the first and second data units.<br>
8.	The method of claim 5, further comprising:<br>
determining the one of die reference data units which is the most similar to the<br>
current data unit in a predetermined search range; and<br>
determining the motion vector representation of the determined reference data<br>
unit.<br>
9.	An apparatus to compensate for a motion of a panorama image containing 360<br>
° omni-directional view information, the apparatus comprising:<br>
a memory to store a reference image to be used for motion estimation of a panorama image, and motion vectors of a plurality of previous reference data<br>
units adjacent to a current data ant of the paiwrama image; and<br>
anwtionestiinatinguiuttoestisuBearaotionvecu^<br>
using the motion vectors of the plurality of the l^ewnce data units, when one or<br>
more pixels of one of the reference data units indkatetfby the estimated motion<br><br>
WO 2006/016783	PCT/KR2005/*O2639<br>
vector are present outside one of left and right borders of the reference image, to padthe reference image in a predetermined range from the other border o f the reference image outside the one of the left and right borders,t() obtain VilueS of all pixels of the reference data unit from the padded reference image, and to determine a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
[10]	10. The apparatus of claim 9, wherein when the one of the plurality of th e<br>
reference data units is present outside one of the left and right borders of the panorama image, the motion estimating unit determines the plurality of the reference data units from a cylindrical image which is obtained by connecting the left and right borders of the panorama image when the panorama image is the cylindrical image.<br>
[11]	11. The apparatus of claim 9, wherein the plurality of the reference data units<br>
comprise:<br>
a first data unit disposed adjacent to a position corresponding toa left side of the current data unit;<br>
a second data unit disposed adjacent to a position corresponding toa top of the current data unit;<br>
a third data unit disposed adjacent to a right side to the second data unit; aad a fourth data unit disposed adjacent to both the first and second data units.<br>
[12]	12. The apparatus of claim 9, wherein the motion estimating unit determines<br>
theone of the reference data units which is the most similar to the current data unit in a predetermined search range, and determines the motion vector representing the determined reference data unit.<br>
[13]	13. An apparatus for estimating amotion of a panorama image containing 360 °<br>
omni-directional view information, the apparatus comprising: a memory to store a reference image to be used for motion estimation of a panorama image, and motion vectors of a plurality of previous reference data units adjacent to a current data unit of the panorama image; and a motion estimating unit to estimate a motion vector of the current data unit using the motion vectors of the plurality of the reference data units, when oneor more pixels of the one of the reference data units indicated by the estimated motion vector are present outside one of left and right borders of die reference image, to obtain values of all pixels of the one of the reference data units from a cylindrical image obtained by connecting the left and right borders of the reference image when the reference image is the cylindrical image, and to determine a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br><br>
WO 2006/016783	PC17KR2005/HO2639<br>
[14]	14. The apparatus of claim 13, wherein when the one of the plurality of the<br>
reference data units is present outside one of the left and right borders of the<br>
panorama image, the motion estimating unit determines the plurality of the reference data units from a cylindrical image obtained by connecting ths left and right borders of the panorama image when the panorama image is the cylindrical image.<br>
[15]	15. The apparatus of claim 13, wherein the plurality of the reference data units<br>
comprise:<br>
a first data unit disposed adjacent to a position corresponding toa left sid e of the current data unit;<br>
a second data unit disposed adjacent to a position corresponding toa top of the current data unit;<br>
a third data unit disposed adjacent to a right sideof the second data unit; and a fourth data unit disposed adjacent to both the first and second data units.<br>
[16]	16. The apparatus of claim 13, wherein the motion estimating unit determines<br>
one of the reference data units which is the most similar to the current data unit in a predetermined search range, and determines the motion vector representing the determined reference data unit<br>
[17]	17. A method of compensating for a motion of a panorama image containing 360<br>
° omni-directional view information, the method comprising: receiving a motion vector of a current data unit of a panorama image; when one or more pixels of one of reference data units of apanoramareference image indicated by the motion vector of the current data unit are present outside one of left and right borders of the reference image, padding an image in a predetermined range from the other border of the reference image outside the one of the left and right borders of the reference image;<br>
obtaining values of all pixels of the reference data unit from the padded reference image; and<br>
reproducing the current data unit using the values of the pixels of the reference data unit.<br>
[18]	18. A method of compensating for a motion of a panorama image containing 360<br>
° omni-directional view information, the method comprising: receiving a motion vector of a current data unit of the panorama image; when one or more pixels of a reference data unit of a reference image indicated by the motion vector of the current data unit are presentoutsideoBeofleftand right borders of the reference image, obtaining values of all pixels of the eae of the reference data mats from a cjiiadMcal image which is obtained the left and right borders of the reference image when the reference image is the<br><br>
I<br><br>
WO 2006/016783	PCT/KR2OO50O2639<br>
cylindrical image; and<br>
reproducing the current data unit using the values of the pixels of the one of the<br>
reference data units.<br>
[19]	19. An apparatus to compensate for a motion of a panorama image containing<br>
360 ° omni-directional view information, the apparatus comprising: a memory to store a reference image to be used for motion estimation of a panorama image; and<br>
a motion compensating unit to recover a motion vector of a current data unit of the panorama image, when one or more pixels of one of reference data u nits of the reference image indicated by the motion vector of the current data unit are present outside one of left and right borders of the reference image, to pad the reference image in a predetermined range from the other border of the reference image outside the one of the left and right borders of the reference image,to obtain values of all pixels of the one of the reference data units from the padded reference image, and to reproduce the current data unit using the values of the pixels of the reference data unit.<br>
[20]	20. An apparatus to compensate for the motion of a panorama image containing<br>
360 ° omni-directional view information, the apparatus comprising: a memory to store a reference image to be used for motion estimation of a current panorama image; and<br>
a motion compensating unit to receive a motion vector of a current data unit of the panorama image, when one or more pixels of one of reference data units of the reference image indicated by die motion vector of die current data unit are present outside one of left and right borders of the reference image, to obtain<br>
values of all pixels of the one of the reference data units from a cylindrical image<br>
which is obtained by connecting the left and rights borders of the reference<br>
image when the reference image is the cylindrical image, and to reproduce the<br>
current data unit using the values of the pixels of the reference data unit.<br>
[211	21. A computer readable medium having embodied thereon a program for<br>
executing a method of estimating a motion vector of a panorama image containing 360 ° omni-directional view information, the method comprising: estimating a motion vector of a current data unit of a current panorama image using motion vectors of a plurality of previous reference data units adjacent to the current data unit;<br>
wheo oiie or more pixels of one of ref^^<br>
image indicated by the estimated rrwdon vector are rjreJent outside one of left and right borders of a reference image, padding me rcfeence image in a predetermined range fiom tine other border of the reference image outside the one of<br><br>
WO 2006/016783	PCT/KR2005/IO2639<br>
the left and right borders;<br>
obtaining values of all pixels of the one of the reference data units from the<br>
padded reference image; and<br>
determining a similarity between the current data unit and the reference data unit<br>
using a predetermined evaluation function.<br>
[22]	22. A computer readable medium having embodied thereon a program for<br>
executing a method of estimating the motion of a panorama image containing 360 ° omni-directional view information, the method comprising: estimating a motion vector of a current data unit of a current panorama image using motion vectors of a plurality of previous reference data units adjacent to the current data unit;<br>
when one or more pixels of oneof reference data units of a reference image indicated by the estimated motion vector are present outside one of left and right borders of the reference image, obtaining values of all pixels of the reference image from a cylindrical image which is obtained by connecting the left and right borders of the reference image when die reference image is die cylindrical image; and<br>
determining a similarity between the current data unit and the reference data unit using a predetermined evaluation function.<br>
[23]	23. A computer readable medium having embodied thereon a program for<br>
executing a method of compensating for a motion of a panorama image containing 360 ° omni-directional view information, the method comprising: receiving a motion vector of a current data unit of a current panorama image; when one or more pixels of one of reference data units of a reference image indicated by the motion vector of the current data unit are present outside one of left and right borders of the reference image, padding the reference image in a predetermined range from the other border of the reference image outside the one of the left and right borders of the reference image;<br>
obtaining values of all pixels of the reference data unit from the padded reference image; and<br>
reproducing the current data unit using the values of the pixels of the reference data unit.<br>
[24]	24. A computer readable medium having embodied thereon a program for<br>
executing a method of compensating for a motion of a panorama image containing 360 ° omni-directional view information, the method comprising: receiving a motion vector fflf a current data unit of a panorama image; when one or more pixels of one of reference data units of a reference image indicated by the motion vector of the current data unit are present outside one of<br><br>
WO 2006/016783	PCT/KR2005/0O2639<br>
left and right borders of the reference image, obtaining values of all pixels of the reference data unit from a cylindrical image which is obtained by connec ting the<br>
left and right borders of the reference Image when the reference image IS tne cylindrical image; and<br>
reproducing the current data unit using the values of the pixels of the reference data unit.<br>
[25]	25. An apparatustoestimatea motionvectorof a panorama image containing 360 °<br>
omni-directional view information, the apparatus comprising: a memory to store a reference imagehaving firstand secondbordersandfirst and secondreferencedata units disposedadjacent tothe first border and the second border, respectively,within the reference image.and<br>
a motion estimating unit to receive a current data unit of a current image and the reference data units of the reference image from the memory, and to estimate a motion vector of the current data unit using one of die first and second reference data units of the reference image which is not included in a search area when the other one of the first and second reference data units is included in the search area.<br>
[26]	26. The apparatus of claim 25, whereinthe reference imagecomprisesa cylindrical<br>
imageformedwhenthe first and second borders are connected, and the first and second reference data units comprise first and second macro blocks, respectively, having a spatial relationshiptherebetweenand disposed adjacent to each other in the cylindrical image.<br>
[27]	27. The apparatus of claim 25, wherein the reference image and the current im-<br>
agecomprisepanorama images, and thesearching area includesone of the first and second reference data units disposed in an outside of a searching areaof the motion vector of the current data unit while the other one of the first and second reference data units is disposedwithinthe searching area.<br>
[28]	28. The apparatus of claim 25, further comprising:<br>
a panorama image motion compensating unitto generate a reference macro block according tothe motion vector and the. reference image; and an encodingunit to generatea signal corresponding tothe reference image according to the reference macro block and the current image, a second unit to generate the motion vector according toa codedsignal corresponding tothe quantized transformcoefficients, andto generatea residual sig-Mlacoirdingtothecoded signal;<br>
asecowirjaiwraniaiiriagenTOtioncojnpeaisad	refer*<br>
encemacro Mock aocotdiag totbemotioa vector, and a thiid unit to generate the current image accordmg to tte referee* nuicro block<br><br>
WO 2006/016783	PCT/KR2005/00 2639<br>
and the residual signal.<br>
29]	29. The apparatus of claim 28, further comprising:<br>
a second unit to generate the motion vector according to a Coded Signal Corresponding to the quantized transform coefficients, and to generate a residual signal according to the coded signal;<br>
a second panorama image motion compensating unit to generate the reference macro block according to the motion vector; and<br>
a third unit to generate the current image according to the reference macro block and the residual signal.<br>
[30]	30. An apparatus to generate a panorama image containing 360 ° omni-di-<br>
rectional view information, the apparatus comprising: a decoding unit to decode a bitstream having data corresponding to a current image and a reference image, and to generate a motion vector of a current data unit of the current image to correspond to a search area of the reference i mage which includes a first reference data unit disposed on a first border of the reference image;<br>
a panorama image motion compensating unit to generate a reference macro block of the first reference data unit of the reference image using a second reference data unit disposed on a second border of the reference image which is not included in the search area according to the motion vector;and an output unit to generate the current image according to the reference macro block and data corresponding to the decoded bitstream.<br>
[31]	31. An apparatus to estimate a motion vector of a panorama image containing<br>
360 ° omni-directional view information, the apparatus comprising: an encoder comprising:<br>
a memory to store a reference image having first and second borders and first and second reference data units disposed adjacent to the first border and the second border, respectively, within the reference image, a motion estimating unit to receive a current data unit of a current image and the reference data units of the reference image from the memory, and to estimate a motion vector of the current data unit usingone ofthe first and second reference data units of the reference image which is not included in a search area when the other one of the first and second reference data units is included in the search area,<br>
a panorama image motion compensating nnit to generate a reference macro block according to the motion vector and the reference image,and a coding unit to generate an bitstream according to ihe current image and the* reference macro Mock; and<br><br>
WO 2006/016783	PCT/KR2OO5/O0 2639<br>
a decoder comprising:<br>
a decoding unit to decode the bitstream having data corresponding to the current<br>
image and the reference image, and to generate the motion vector of the current<br>
data unit of the current image to correspond to the search area of the reference image which includes the first reference data unit disposed on the first bo rder of the reference image,<br>
a second panorama image motion compensating unit to generate the reference macro block of the first reference data unit of the reference image using t he second reference data unit disposed on the second border of the reference image which is not included in the search area according to the motion vector,and an output unit to generate the current image according to the reference m aero block and data corresponding to the decoded bitstream.<br>
[32]	32.A method of estimating a motion vector of a panorama image containing 360<br>
° omni-directional view information, the method comprising: storing a reference image having first and second borders and first and second reference data units disposed adjacent to the first border and the second border, respectively, within the reference image; and<br>
receivinga current data unit of a current image and the reference data units of the reference image from the memory, and estimating a motion vector of the current data unit using one of the first and second reference data units of the reference image which is not included in a search area when the other one of the first and second reference data units is included in the search area.<br>
[33]	33. The method of claim 32, further comprising:<br>
generating a reference macro block according to the motion vector and the reference image; and<br>
generating the reference image according to the reference macro block and the current image.<br>
[34]	34.A method of generating a panorama image containing 360 ° omni-directional<br>
view information, the method comprising:<br>
decoding a bitstream having data corresponding to a current image and a reference image, and generating a motion vector of a current data unit of the current image to correspond to a search area of the reference image which includes a first reference data unit disposed on a first border of the reference<br>
image;<br>
generating a reference macro block of the first reference data unit of the<br>
ref erence image using a second reference data unit disposed on a second border<br>
of the reference image which is not included in the search aiea according to the<br>
motion vector, and<br><br>
WO 2006/016783	l'( ' T/KK.'Oovoo •<. l></.>
generating the current image according to the reference macro block ami dala<br>
corresponding to the decoded bitstream.<br>
[35]	35. A method of estimating a motion vector of a panorama image containing 360<br>
0 omni-difectional view information, the method comprising:<br>
storing a reference image having first and second borders and first and second<br>
reference data units disposed adjacent to the first border and the second border,<br>
respectively, within the reference image;<br>
receiving a current data unit of a current image and the reference data units of the<br>
reference image from the memory, and estimating a motion vector of the current<br>
data unit using one of the first and second reference data units of the reference<br>
image which is not included in a search area when the other one of the first and<br>
second reference data units is included in the search area;<br>
generating a reference macro block according to the motion vector and the<br>
reference image;<br>
generating a bitstream according to the current image and the reference macro<br>
block;<br>
decoding the bitstream having data corresponding to the current image and the<br>
reference image, and generating the motion vector of the current data unit of the<br>
current image to correspond to the search area of the reference image which<br>
includes the first reference data unit disposed on the first border of the reference<br>
image;<br>
generating the reference macro block of the first reference data unit of the<br>
reference image using the second reference data unit disposed on the second<br>
border of the reference image which is not included in the search area according<br>
to the motion vector, and<br>
generating the current image according to the reference macro block and data<br>
corresponding to the decoded bitstream.<br><br><br>
Dated this 03rd day of February, 2007<br><br>
ABSTRACT<br>
"METHOD AND DEVICE FOR MOTION ESTIMATION AND COMPENSATION FOR PANORAMA IMAGE"<br>
A device and a method for motion estimation and compensation to be performed on a panorama image with a 360 ° omni-directional view based on that a spatial relation between left and right borders of the panorama image is very high. Accordingly, it is possible to improve an image quality through effective and precise estimation and compensation for the motion of the panorama image. In particular, it is possible to improve the image quality at the right and left edges of the panorama image<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctYWJzdHJhY3QoMTMtMTAtMjAwOCkuZG9j" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-abstract(13-10-2008).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctYWJzdHJhY3QoMTMtMTAtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-abstract(13-10-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctYWJzdHJhY3QuZG9j" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY2FuY2VsbGVkIHBhZ2VzKDA1LTAyLTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-cancelled pages(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY2xhaW1zKGdyYW50ZWQpLSgwNS0wMi0yMDA3KS5kb2M=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-claims(granted)-(05-02-2007).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY2xhaW1zKGdyYW50ZWQpLSgwNS0wMi0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-claims(granted)-(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY2xhaW1zLmRvYw==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY29ycmVzcG9uZGVuY2UoMjQtMTItMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-correspondence(24-12-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY29ycmVzcG9uZGVuY2UoaXBvKS0oMjEtMTEtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-correspondence(ipo)-(21-11-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY29ycmVzcG9uZGVuY2Utb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctY29ycmVzcG9uZGVuY2UtcmVjZWl2ZWQucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-correspondence-received.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZHJhd2luZygwNS0wMi0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-drawing(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAxKDA1LTAyLTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 1(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAxKDA2LTA4LTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 1(06-08-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAxOCgwNS0wMi0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 18(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAyKGdyYW50ZWQpLSgwNS0wMi0yMDA3KS5kb2M=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 2(granted)-(05-02-2007).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAyKGdyYW50ZWQpLSgwNS0wMi0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 2(granted)-(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAyNigwNi0wOC0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 26(06-08-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSAzKDEzLTEwLTIwMDgpLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 3(13-10-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybSA1KDAzLTAyLTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form 5(03-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS0yLmRvYw==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS0yLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS01LnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaWItMzAxLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ib-301.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaWItMzA0LnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ib-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaWItMzA3LnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ib-307.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaWItMzA4LnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ib-308.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaWItMzExLnBkZg==" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ib-311.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaXBlYS00MDkucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ipea-409.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaXBlYS00MTYucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-ipea-416.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaXNhLTIxMCgwNS0wMi0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-isa-210(05-02-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaXNhLTIyMC5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-isa-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctZm9ybS1wY3QtaXNhLTIzNy5wZGY=" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-form-pct-isa-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctcGN0LXNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-pct-search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTgzLW11bW5wLTIwMDctcGV0aXRpb24gdW5kZXIgcnVsZSAxMzcoMTMtMTAtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">183-mumnp-2007-petition under rule 137(13-10-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="225796-storage-container-external-container-for-kneading-and-transporting-the-container-and-kneader.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="225798-low-power-direct-digital-synthesizer-with-analog-interpolation.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>225797</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>183/MUMNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>07/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>13-Feb-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>02-Dec-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>05-Feb-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INDUSTRY ACADEMIC COOPERATION FOUNDATION KYUNGHEE UNIVERSITY</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>1, Seochun-ri, Kiheung-eup, Yongin-si, Gyeonggi-do</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>PARK, GWANG-HOON</td>
											<td>B-302 Donga Villa, 45 Bundang-dong, Bundang-gu, Seongnam-si, Gyeonggi-do</td>
										</tr>
										<tr>
											<td>2</td>
											<td>SON, SUNG-HO</td>
											<td>(401) 7-96 Gwangmyeong 1-dong, Gwangmyeong-si</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/32</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2005/002639</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-08-12</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/601,137</td>
									<td>2004-08-13</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>10-2004-0081353</td>
									<td>2004-10-12</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/225797-method-and-device-for-motion-estimation-and-compensation-for-panorama-image by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:32:24 GMT -->
</html>
