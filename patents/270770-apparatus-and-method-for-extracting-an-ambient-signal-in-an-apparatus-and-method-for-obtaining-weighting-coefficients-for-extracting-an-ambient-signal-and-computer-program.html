<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/270770-apparatus-and-method-for-extracting-an-ambient-signal-in-an-apparatus-and-method-for-obtaining-weighting-coefficients-for-extracting-an-ambient-signal-and-computer-program by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:35:47 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 270770:APPARATUS AND METHOD FOR EXTRACTING AN AMBIENT SIGNAL IN AN APPARATUS AND METHOD FOR OBTAINING WEIGHTING COEFFICIENTS FOR EXTRACTING AN AMBIENT SIGNAL AND COMPUTER PROGRAM</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">APPARATUS AND METHOD FOR EXTRACTING AN AMBIENT SIGNAL IN AN APPARATUS AND METHOD FOR OBTAINING WEIGHTING COEFFICIENTS FOR EXTRACTING AN AMBIENT SIGNAL AND COMPUTER PROGRAM</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>An apparatus for extracting an ambient signal from an input audio signal comprises a gain-value determinator configured to determine a sequence of time-varying ambient signal gain values for a given frequency band of the time-frequency distribution of the input audio signal in dependence on the input audio signal. The apparatus comprises a weighter configured to weight one of the sub-band signals representing the given frequency band of the time- frequency-domain representation with the time-varying gain values, to obtain a weighted sub-band signal. The gain- value determinator is configured to obtain one or more quantitative feature-values describing one or more features of the input audio signal and to provide the gain-value as a function of the one or more quantitative feature values such that the gain values are quantitatively dependent on the quantitative values. The gain value determinator is configured to determine the gain values such that ambience components are emphasized over non-ambience components in the weighted sub-band signal.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Apparatus and Method for Extracting an Ambient Signal in an<br>
Apparatus and Method for Obtaining Weighting Coefficients<br>
for Extracting an Ambient Signal and Computer Program<br>
Description<br>
Technical Field<br>
Embodiments according to the invention relate to an<br>
apparatus for extracting an ambient signal and to an<br>
apparatus for obtaining weighting coefficients for<br>
extracting an ambient signal.<br>
Some embodiments according to the invention are related to<br>
methods for extracting an ambient signal and to methods for<br>
obtaining weighting coefficients.<br>
Some embodiments according to the invention are directed to<br>
a low-complexity extraction of a front signal and an<br>
ambient signal from an audio signal for upmixing.<br>
Background<br>
In the following, an introduction will be given.<br>
1 Introduction<br>
Multi-channel audio material is becoming more and more<br>
popular also in the consumer home environment. This is<br>
mainly due to the fact that movies on DVD offer 5.1 multi-<br>
channel sounds and therefore even home users frequently<br>
install audio playback systems, which are capable of<br>
reproducing multi-channel audio.<br>
Such a setup may e.g. consist of three speakers (L, C, R)<br>
in the front, two speakers (Ls, Rs) in the back and one low<br>
frequency effects channel (LFE). For convenience, the given<br>
explanations are related to 5.1 systems. They apply to any<br>
other multi-channel systems with minor modifications.<br>
Multi-channel systems provide several well-known advantages<br>
over two-channel stereo reproduction, e.g.:<br>
• Advantage 1: Improved front image stability even off<br>
the optimal (central) listening position. Due to the<br>
center channel the "sweet-spot" is enlarged. The term<br>
"sweet-spot" denotes the area of listening positions<br>
where an optimal sound impression is perceived.<br>
• Advantage 2: An increased experience of "envelopment"<br>
and spaciousness is created by the rear channel<br>
speakers.<br>
Nevertheless, there exists a huge amount of legacy audio<br>
content with two audio channels ("stereo") or even only one<br>
("mono"), e.g. old movies and television series.<br>
Recently, various methods for generating a multi-channel<br>
signal from an audio signal with fewer channels have been<br>
developed (see Section 2 for an overview of the related<br>
conventional concepts). The process of generating a multi-<br>
channel signal from an audio signal with fewer channels is<br>
called "upmixing".<br>
Two concepts of upmixing are widely known.<br>
1. Upmixing with additional information guiding the upmix<br>
process. The additional information may be either<br>
"encoded" in a specific way in the input signal or may be<br>
stored additionally. This concept is frequently called<br>
"guided upmix".<br>
2. The "blind upmix", whereas a multi-channel signal is<br>
obtained from the audio signal exclusively without any<br>
additional information.<br>
Embodiments according to the present invention are related<br>
to the latter, i.e. the blind upmix process.<br>
In the literature, an alternative taxonomy for upmix<br>
processes is reported. Upmix processes may follow either<br>
the Direct/Mihient-Concept or the '¦'¦ In-the-band"-Concept or<br>
a mixture of both. These two concepts are described in the<br>
following.<br>
A. Direct/Ainbient-Concept<br>
The "direct sound sources" are reproduced through the three<br>
front channels in a way that they are perceived at the same<br>
position as in the original two-channel version. The term<br>
"direct sound source" is used to describe a sound coming<br>
solely and directly from one discrete sound source (e.g. an<br>
instrument), with little or without any additional sounds,<br>
e.g. due to reflections from the walls.<br>
The rear speakers are fed with ambient sounds (ambience-<br>
like sounds). Ambient sounds are those forming an<br>
impression of a (virtual) listening environment, including<br>
room reverberation, audience sounds (e.g. applause),<br>
environmental sounds (e.g. rain), artistically intended<br>
effect sounds (e.g. vinyl crackling) and background noise.<br>
Figure 23 illustrates the sound image of the original two-<br>
channel version and Figure 24 shows the same for an upmix<br>
following the Direct/Ambient-Concept.<br>
B. "In-the-band"-Concept<br>
Following the "In-the-band"-Concept, every sound, or at<br>
least some sounds (direct sound as well as ambient sounds)<br>
may be positioned all around the listener. The position of<br>
a sound is independent of its characteristics (i.e. whether<br>
it is a direct sound or an ambient sound) and only<br>
dependent on the specific design of the algorithm and its<br>
parameter settings. Figure 25 illustrates the sound image<br>
of the "In-the-band"-Concept.<br>
Apparatus and methods according to the invention relate to<br>
the direct/ambient concept. The following section gives an<br>
overview of conventional concepts in the context of<br>
upmixing an audio signal with m channels to an audio signal<br>
with n channels, with m 
2 Conventional concepts in blind upmixing<br>
2 .1 Upmixing of mono recordings<br>
2.1.1 Pseudo-stereophonic processing<br>
Most of the techniques to produce a so-called "pseudo-<br>
stereophonic" signal are not signal adaptive. This means<br>
that they process any mono signal in the same way, no<br>
matter what the content is. Those systems often work with<br>
simple filter structures and/or time delays to decorrelate<br>
the output signals, e.g. by processing two copies of the<br>
one-channel input signal by a pair of complementary comb<br>
filters [Sch57]. A comprehensive overview of such systems<br>
can be found in [Fal05] .<br>
2.1.2 Semi-automatic mono to stereo upmixing using<br>
sound source formation<br>
The authors propose an algorithm to identify signal<br>
components (e.g. time-frequency bins of a spectrogram)<br>
which belong to the same sound source and should therefore<br>
be panned together [LMT07]. The sound source formation<br>
algorithm considers principles of stream segregation<br>
(derived from the Gestalt principles) : continuity in time,<br>
harmonic relations in frequency and amplitude similarity.<br>
Sound sources are identified using clustering methods<br>
(unsupervised learning). The derived "time-frequency-<br>
clusters" are further grouped into larger sound streams<br>
using (a) information on the frequency range of the objects<br>
and (b) timbral similarities. The authors report the use of<br>
a sinusoidal modeling algorithm (i.e. the identification of<br>
sinusoidal components of a signal) as a front end.<br>
After the sound source formation, the user selects sound<br>
sources and applies panning weights to them. It should be<br>
noted that (according to some conventional concepts) many<br>
of the proposed methods (sinusoidal modeling, stream<br>
segregation) do not perform reliable when processing real-<br>
world signals of average complexity.<br>
2.1.3 Ambience extraction using Non-negative Matrix<br>
Factorization<br>
A time-frequency distribution (TFD) of the input signal is<br>
computed, e.g. by means of Short-term Fourier Transform. An<br>
estimate of the TFD of the direct signal components is<br>
derived by means of the numerical optimization method of<br>
Non-negative Matrix Factorization. An estimate of the TFD<br>
of the ambient signal is obtained by computing the<br>
difference of the TFD of the input signal and the estimate<br>
of the TFD of the direct signal (i.e. the approximation<br>
residual). The re-synthesis of the time signal of the<br>
ambient signal is carried out using the phase spectrogram<br>
of the input signal. Additional post-processing is<br>
optionally applied in order to improve the listening<br>
experience of the derived multi-channel signal [UWHH07].<br>
2.1.4 Adaptive spectral panoramization (ASP)<br>
A method for the panoramization of a mono signal for<br>
playback using a stereo sound system is described in<br>
[VZA06]. The processing incorporates an STFT, the weighting<br>
of the frequency bins used for the re-synthesis of the left<br>
and right channel signal, and the inverse STFT. The time-<br>
varying weighting factors are derived from low-level<br>
features computed from the spectrogram of the input signal<br>
in sub-bands.<br>
2.2 Upmixing of stereo recordings<br>
2.2.1 Matrix decoders<br>
Passive matrix decoders compute a multi-channel signal<br>
using a time-invariant linear combination of the input<br>
channel signals.<br>
Active matrix decoders (e.g. Dolby Pro Logic II [DreOO],<br>
DTS NE0:6 [DTS] or HarmanKardon/Lexicon Logic 7 [Kar] )<br>
apply an analysis of the input signal and perform signal-<br>
dependent adaptation of the matrix elements (i.e. the<br>
weights for the linear combination). These decoders use<br>
inter-channel differences and signal adaptive steering<br>
mechanisms to produce multi-channel output signals. Matrix<br>
steering methods aim at detecting prominent sources (e.g.<br>
dialogues). The processing is performed in the time domain.<br>
2.2.2 A method to convert stereo to multi-channel sound<br>
Irwan and Aarts present a method to convert a signal from<br>
stereo to multichannel [lAOl]. The signal for the surround<br>
channels is calculated by using a cross-correlation<br>
technique (an iterative estimation of the correlation<br>
coefficient is proposed in order to reduce the<br>
computational load).<br>
The mixing coefficients for the center channel are obtained<br>
using Principal Component Analysis (PCA). PCA is applied to<br>
calculate a vector, which indicates the direction of the<br>
dominant signal. Only one dominant signal can be detected<br>
at a time. The PCA is performed using an iterative gradient<br>
descent method (which is less demanding with respect to<br>
computational load compared to the standard PCA using an<br>
eigenvalue decomposition of the covariance matrix of the<br>
observation). The computed vector of direction is similar<br>
to the output of a goniometer if all decorrelated signal<br>
components are neglected. The direction is then mapped from<br>
a two-to a three-channel representation to create the 3<br>
front channels.<br>
2.2,3 An unsupervised adaptive filtering approach of 2-<br>
to-5 channel upmix<br>
The authors propose an improved algorithm compared to the<br>
method by Irwan and Aarts. The originally proposed method<br>
is applied to each sub-band [LD05] . The authors assume w-<br>
disjoint orthogonality of the dominant signals. The<br>
frequency decomposition is carried out using either a<br>
Pseudo Quadrature Mirror Filterbank or a wavelet-based<br>
octave filter-bank. A further extension to the method by<br>
Irwan and Aarts is the use of an adaptive step size for the<br>
iterative computation of the (first) principal component.<br>
2.2.4 Ambience Extraction and Synthesis from Stereo<br>
Signals for Multi-channel Audio Upmix<br>
Avendano and Jot propose a frequency-domain technique to<br>
identify and extract the ambience information in stereo<br>
audio signals [AJ02].<br>
The method is based on the computation of an inter-channel<br>
coherence index and a non-linear mapping function that<br>
allows for the determination of the time-frequency regions<br>
that consist mostly of ambience components. Ambient signals<br>
are subsequently synthesized and used to feed the surround<br>
channels of the multi-channel playback system.<br>
2.2.5 Descriptor based spatialization<br>
The authors describe a method for one-to-n upmixing, which<br>
can be controlled by an automated classification of the<br>
signal [MPA"'05] . The paper contains some errors; therefore<br>
it might be that the authors aimed at different goals than<br>
described in the paper.<br>
The upmix process uses three processing blocks: the "upmix<br>
tool", artificial reverberation and equalization. The<br>
"upmix tool" consists of various processing blocks,<br>
including the extraction of an ambient signal. The method<br>
for the extraction of an ambient signal ("spatial<br>
discriminator") is based on the comparison of the left and<br>
right signal of a stereo recording in the spectral domain.<br>
For upmixing mono-signals, artificial reverberation is<br>
used.<br>
The authors describe 3 applications: l-to-2 upmixing, 2-to-<br>
5 upmixing, and l-to-5 upmixing.<br>
Classification of the audio signal The classification<br>
process uses a supervised learning approach: Low-level<br>
features are extracted from the audio signal and a<br>
classifier is applied to classify the audio signal into one<br>
of three classes: music, voices or any other sounds.<br>
A particularity of the classification process is the use of<br>
a genetic programming method to find<br>
• optimal features (as compositions of different<br>
operations)<br>
• optimal combination of the obtained low-level features<br>
• the best classifier from a set of available<br>
classifiers<br>
• the best parameter setting for the chosen classifier<br>
l-to-2 upmixing The upmix is done using reverberation<br>
and equalization. If the signal contains voice, the<br>
equalization is enabled and reverberation is disabled.<br>
Otherwise, the equalization is disabled and reverberation<br>
is enabled. No dedicated processing aiming at the<br>
suppression of speech in the rear channels is incorporated.<br>
2-to-5 upmixing The authors aim at building a multi-<br>
channel soundtrack whereas detected voices are attenuated<br>
by muting the center channel.<br>
l-to-5 upmixing The multi-channel signal is generated<br>
using reverberation, equalization and the "upmix tool"<br>
(which generates a 5.1 signal from a stereo signal. The<br>
stereo signal is the output of the reverberation and the<br>
input to the "upmix tool".). Different presets are used for<br>
music, voices and all other sounds. By controlling<br>
reverberation and equalization, a multi-channel soundtrack<br>
is build that keeps voices in the center channel and has<br>
music and other sounds in all channels.<br>
If the signal contains voice, the reverberation is<br>
disabled. Otherwise, reverberation is enabled. Since the<br>
extraction of the rear-channel signal relies on a stereo<br>
signal, no rear-channel signal is generated when<br>
reverberation is disabled (which is the case for voices).<br>
2.2.6 Ambience-based upmixing<br>
Soulodre presents a system, which creates a multi-channel<br>
signal from a stereo signal [Sou04]. The signal is<br>
decomposed into so-called "individual source streams" and<br>
"ambience streams". Based on these streams a so-called<br>
"Aesthetic Engine" synthesizes the multi-channel output. No<br>
further technical details of the decomposition and the<br>
synthesis steps are given.<br>
2.3 Upmixing of audio signals with arbitrary number<br>
of channels<br>
2.3.1 Multichannel surround format conversion and<br>
generalized up-mix<br>
The authors describe a method based on spatial audio coding<br>
using an intermediate mono downmix and introduce an<br>
improved method without the intermediate downmix. The<br>
improved method comprises passive matrix upmixing and<br>
principles known from Spatial Audio Coding. The<br>
improvements are gained at the expense of increased data<br>
rate of the intermediate audio [GJ07a].<br>
2.3.2 Primary-ambient signal decomposition and vector-<br>
based localization for spatial audio coding and<br>
enhancemen t<br>
The authors propose a separation of the input signal into a<br>
primary (direct) signal and an ambient signal using<br>
Principal Component Analysis (PCA) [GJ07b].<br>
The input signal is modeled as the sum of a primary<br>
(direct) signal and an ambient signal. It is assumed that<br>
the direct signals have substantially more energy than the<br>
ambient signal and both signals are uncorrelated.<br>
The processing is carried out in the frequency domain. The<br>
STFT coefficients of the direct signal are obtained from<br>
the projection of the STFT coefficients of the input signal<br>
onto the first principal component. The STFT coefficients<br>
of the ambient signal are computed from the difference of<br>
the STFT coefficients of the input signal and the direct<br>
signal.<br>
Since only the (first) principal component (i.e. the<br>
eigenvector of the covariance matrix corresponding to the<br>
largest eigenvalue) is needed, a computationally efficient<br>
alternative for the eigenvalue decomposition used in<br>
standard PCA is applied (which is an iterative<br>
approximation). The cross-correlation needed for the PCA<br>
decomposition is also estimated iteratively. The direct and<br>
ambient signal add up to the original, i.e. no information<br>
is lost in the decomposition.<br>
Summary<br>
In view of the above, there is a need for a low-complexity<br>
extraction of an ambient signal from an input audio signal.<br>
Some embodiments according to the invention create an<br>
apparatus for extracting an ambient signal on the basis of<br>
a time-frequency-domain representation of an input audio<br>
signal, the time-frequency-domain representation<br>
representing the input audio signal in terms of a plurality<br>
of sub-band signals describing a plurality of frequency<br>
bands. The apparatus comprises a gain-value determinator<br>
configured to determine a sequence of time-varying ambient<br>
signal gain values for a given frequency band of the time-<br>
frequency-domain representation of the input audio signal<br>
in dependence on the input audio signal. The apparatus<br>
comprises a weighter configured to weight one of the sub-<br>
band signals representing the given frequency band of the<br>
time-frequency-domain representation with the time-varying<br>
gain values to obtain a weighted sub-band signal. The gain-<br>
value determinator is configured to obtain one or more<br>
quantitative feature values describing one or more features<br>
or characteristics of the input audio signal, and to<br>
provide the gain-values as a function of the one or more<br>
quantitative feature values, such that the gain values are<br>
quantitatively dependent on the quantitative feature<br>
values. The gain-value determinator is configured to<br>
provide the gain-values such that ambient components are<br>
emphasized over non-ambient components in the weighted sub-<br>
band signal.<br>
Some embodiments according to the invention provide an<br>
apparatus for obtaining weighting coefficients for<br>
extracting an ambient signal from an input audio signal.<br>
The apparatus comprises a weighting coefficient<br>
determinator configured to determine the weighting<br>
coefficients such, that gain values obtained on the basis<br>
of a weighted combination, using the weighting coefficients<br>
(or defined by the weighting coefficients), of a plurality<br>
of quantitative feature values describing a plurality of<br>
features of a coefficient-determination input audio signal<br>
approximate expected gain-values associated with the<br>
coefficient-determination input audio signal.<br>
Some embodiments according to the invention provide methods<br>
for extracting an ambient signal and for obtaining<br>
weighting coefficients.<br>
Some embodiments according to the invention are based on<br>
the finding that an ambient signal can be extracted from an<br>
input audio signal in a particularly efficient and flexible<br>
manner by determining quantitative feature values, for<br>
example a sequence of quantitative feature values<br>
describing one or more features of the input audio signal,<br>
as such quantitative feature values can be provided with<br>
limited computational effort and can be translated into<br>
gain-values efficiently and flexibly. By describing one or<br>
more features in terms of one or more sequences of<br>
quantitative feature values, gain values can easily be<br>
obtained, which are quantitatively dependent on the<br>
quantitative feature values. For example, simple<br>
mathematical mappings can be used to derive the gain-values<br>
from the feature-values. In addition, by providing the<br>
gain-values such that the gain-values are quantitatively<br>
dependent on the feature values, a fine-tuned extraction of<br>
the ambient components from the input audio signal can be<br>
obtained. Rather than making a hard decision as to which<br>
components of the input audio signal are the ambient<br>
components and which components of the input audio signal<br>
are non-ambient components, a gradual extraction of the<br>
ambient components can be performed.<br>
In addition, the usage of quantitative feature values<br>
allows for a particularly efficient and precise combination<br>
of feature values describing different features.<br>
Quantitative feature values can, for example, be scaled or<br>
processed in a linear or a non-linear way according to<br>
mathematical processing rules.<br>
In some embodiments in which multiple feature values are<br>
combined to obtain a gain value, details regarding the<br>
combination {for example, details regarding a scaling of<br>
different feature values) can be adjusted easily, for<br>
example by adjusting respective coefficients.<br>
To summarize the above, a concept for extracting an ambient<br>
signal comprising a determination of quantitative feature<br>
values and also comprising a determination of gain values<br>
on the basis of the quantitative feature values may<br>
constitute an efficient and low-complexity concept of<br>
extracting an ambient signal from an input audio signal.<br>
In some embodiments according to the invention, it has been<br>
shown to be particularly efficient to weight one or more of<br>
the sub-band signals of the time-frequency-domain<br>
representation of the input audio signal. By weighting one<br>
or more of the sub-band signals of the time-frequency-<br>
domain representation, a frequency-selective or specific<br>
extraction of ambient signal components from the input<br>
audio signal can be achieved.<br>
Some embodiments according to the invention create an<br>
apparatus for obtaining weighting coefficients for<br>
extracting an ambient signal from an input audio signal.<br>
Some of these embodiments are based on the finding that<br>
coefficients for an extraction of an ambient signal can be<br>
obtained on the basis of a coefficient-determination-input-<br>
audio-signal, which can be considered as a "calibration<br>
signal" or "reference signal" in some embodiments. By using<br>
such a coefficient-determination input audio signal,<br>
expected gain values of which are for example known or can<br>
be obtained with moderate effort, coefficients defining a<br>
combination of quantitative feature values can be obtained,<br>
such that the combination of quantitative feature values<br>
results in gain values which approximate the expected gain<br>
values.<br>
According to said concept, it is possible to obtain a set<br>
of appropriate weighting coefficients, such that an ambient<br>
signal extractor configured with these coefficients may<br>
perform a sufficiently good extraction of ambient signals<br>
(or ambient components) from input audio signals, which are<br>
similar to the coefficient-determination-input-audio-<br>
signal .<br>
In some embodiments according to the invention, the<br>
apparatus for obtaining weighting coefficients allows for<br>
an efficient adaptation of an apparatus for extracting an<br>
ambient signal to different types of input audio signals.<br>
For example, on the basis of a "training signal", i.e. a<br>
given audio signal which serves as the coefficient-<br>
determination-input-audio-signal, and which may be adapted<br>
to the listening preferences of a user of an ambient signal<br>
extractor, an appropriate set of weighting coefficients can<br>
be obtained. In addition, by providing the weighting<br>
coefficients, optimal usage can be made of the available<br>
quantitative feature values describing different features.<br>
Further details, effects and advantages of embodiments<br>
according to the invention will be described subsequently.<br>
Brief Description of the Drawings<br>
Embodiments according to the invention will subsequently be<br>
described taking reference to the enclosed Figs, in which:<br>
Fig. 1 shows a block schematic diagram of an apparatus for<br>
extracting an ambient signal, according to an embodiment<br>
according to the invention;<br>
Fig. 2 shows a detailed block schematic diagram of an<br>
apparatus for extracting an ambient signal from an input<br>
audio signal, according to an embodiment according to the<br>
invention;<br>
Fig. 3 shows a detailed block schematic diagram of an<br>
apparatus for extracting an ambient signal from an input<br>
audio signal, according to an embodiment according to the<br>
invention;<br>
Fig. 4 shows a block schematic diagram of an apparatus for<br>
extracting an ambient signal from an input audio signal,<br>
according to an embodiment according to the invention;<br>
Fig. 5 shows a block schematic diagram of a gain value<br>
determinator, according to an embodiment according to the<br>
invention;<br>
Fig. 6 shows a block schematic diagram of a weighter,<br>
according to an embodiment according to the invention;<br>
Fig. 7 shows a block schematic diagram of a post processor,<br>
according to an embodiment according to the invention;<br>
Figs. 8a and 8b show extracts from a block schematic<br>
diagram of an apparatus for extracting an ambient signal,<br>
according to embodiments according to the invention;<br>
Fig. 9 shows a graphical representation of the concept of<br>
extracting feature values from a time-frequency-domain<br>
representation;<br>
Fig. 10 shows a block diagram of an apparatus or a method<br>
for performing an l-to-5 upmixing, according to an<br>
embodiment according to the invention;<br>
Fig. 11 shows a block diagram of an apparatus or of a<br>
method for extracting an ambient signal, according to an<br>
embodiment according to the invention;<br>
Fig. 12 shows a block diagram of an apparatus or a method<br>
for performing a gain computation, according to an<br>
embodiment according to the invention;<br>
Fig. 13 shows a block schematic diagram of an apparatus for<br>
obtaining weighting coefficients, according to an<br>
embodiment according to the invention;<br>
Fig. 14 shows a block schematic diagram of another<br>
apparatus for obtaining weighting coefficients, according<br>
to an embodiment according to the invention;<br>
Figs.15a and 15b show block schematic diagrams of apparatus<br>
for obtaining weighting coefficients, according to<br>
embodiments according to the invention;<br>
Fig. 16 shows a block schematic diagram of an apparatus for<br>
obtaining weighting coefficients, according to an<br>
embodiment according to the invention;<br>
Fig. 17 shows an extract of a block schematic diagram of an<br>
apparatus for obtaining weighting coefficients, according<br>
to an embodiment according to the invention;<br>
Figs. 18a and 18b show block schematic diagrams of<br>
coefficient determination signal generators, according to<br>
embodiments according to the invention;<br>
Fig. 19 shows a block schematic diagram of a coefficient-<br>
determination signal generator, according to an embodiment<br>
according to the invention;<br>
Fig. 20 shows a block schematic diagram of a coefficient-<br>
determination signal generator, according to an embodiment<br>
according to the invention;<br>
Fig. 21 shows a flow chart of a method for extracting an<br>
ambient signal from an input audio signal, according to an<br>
embodiment according to the invention;<br>
Fig. 22 shows a flow chart of a method for determining<br>
weighting coefficients, according to an embodiment<br>
according to the invention;<br>
Fig. 23 shows a graphical representation illustrating a<br>
stereo playback;<br>
Fig. 24 shows a graphical representation illustrating a<br>
direct/ambient concept; and<br>
Fig. 25 shows a graphical representation illustrating an<br>
in-the-band-concept.<br>
Detailed Description of the Embodiments<br>
Apparatus for extracting an ambient signal - first<br>
embodiment<br>
Fig. 1 shows a block schematic diagram of an apparatus for<br>
extracting an ambient signal from an input audio signal.<br>
The apparatus shown in Fig. 1 is designated in its entirety<br>
with 100. The apparatus 100 is configured to receive an<br>
input audio signal 110 and to provide at least one weighted<br>
sub-band signal on the basis of the input audio signal such<br>
that ambience components are emphasized over non-ambience<br>
components in the weighted sub-band signal. The apparatus<br>
100 comprises a gain value determinator 120. The gain value<br>
determinator 120 is configured to receive the input audio<br>
signal 110 and to provide a sequence of time varying<br>
ambient signal gain values 122 (also briefly designated as<br>
gain-values) in dependence on the input audio signal 110.<br>
The gain-value determinator 120 comprises a weighter 130.<br>
The weighter 130 is configured to receive a time-frequency-<br>
domain representation of the input audio signal or at least<br>
one sub-band signal thereof. The sub-band signal may<br>
describe one frequency band or one frequency sub-band of<br>
the input audio signal. The weighter 130 is further<br>
configured to provide the weighted sub-band signal 112 in<br>
dependence on the sub-band signal 132, and also in<br>
dependence on the sequence of time-varying ambient signal<br>
gain values 122.<br>
Based on the above structural description, the<br>
functionality of the apparatus 100 will be described in the<br>
following. The gain-value determinator 120 is configured to<br>
receive the input audio signal 110 and to obtain one or<br>
more quantitative feature values describing one or more<br>
features or characteristics of the input audio signal. In<br>
other words, the gain value determinator 120 may, for<br>
example, be configured to obtain a quantitative information<br>
characterizing one feature or characteristic of the input<br>
audio signal. Alternatively, the gain-value determinator<br>
120 nay be configured to obtain a plurality of quantitative<br>
feature values (or sequences thereof) describing a<br>
plurality of features of the input audio signal. Thus,<br>
certain characteristics of the input audio signal, also<br>
designated as features (or, in some embodiments, as "low-<br>
level features") may be evaluated for providing the<br>
sequence of gain-values. The gain-value determinator 120 is<br>
further configured to provide the sequence 122 of time-<br>
varying ambient signal gain-values as a function of the one<br>
or more quantitative feature values (or the sequences<br>
thereof).<br>
In the following, the term "feature" will sometimes be used<br>
to designate a feature or a characteristic in order to<br>
shorten the description.<br>
In some embodiments, the gain-value determinator 120 is<br>
configured to provide the time-varying ambient signal gain-<br>
values such that the gain-values are quantitatively<br>
depencent on the quantitative feature values. In other<br>
words, in some embodiments the feature values may take<br>
multiple values (in some cases more than two values, and in<br>
some cases even more than ten values, and in some cases<br>
even a quasi-continuous number of values), and the<br>
corresponding ambient signal gain-values may follow (at<br>
least over a certain range of feature values) the feature<br>
values in a linear or non-linear way. Thus, in some<br>
embodim.ents, a gain-value may increase monotonically with<br>
an increase of one of the one or more corresponding<br>
quantitative feature-values. In another embodiment, the<br>
gain-value may decrease monotonically with an increase of<br>
one of the one or more corresponding values.<br>
In seme embodiments, the gain-value determinator may be<br>
configured to generate a sequence of quantitative feature<br>
values descr-.binq a temporal evolution of a first feature.<br>
Accordingly, the gain-value determinator may, for example,<br>
be configured to map the sequence of feature-values<br>
describing the first feature on a sequence of gain-values.<br>
In some other embodiments, the gain value determinator may<br>
be configured to provide or calculate a plurality of<br>
sequences of feature-values describing a temporal evolution<br>
of a plurality of different features of the input audio<br>
signal 110. Accordingly, the plurality of sequences of<br>
quantitative feature-values may be mapped to a sequence of<br>
gain-values.<br>
To surrimarize the above, the gain-value determinator may<br>
evaluate one or more features of the input audio signal in<br>
a quantitative way and may provide the gain values based<br>
thereon.<br>
The weighter 130 is configured to weight a portion of a<br>
frequency spectrum of the input audio signal 110 (or even<br>
the complete frequency spectrum) in dependence on the<br>
sequence of time-varying ambient signal gain-values 122.<br>
For this purpose, che weighter receives at least one sub-<br>
band signal 132 (or a plurality of sub-band signals) of a<br>
time-frequency-domain representation of the input audio<br>
signal.<br>
The gain-value determinator 120 may be configured to<br>
receive the input audio signal either in a time-domain<br>
representation or in a time-frequency-domain<br>
representation. However, it has been found that the process<br>
of extracting the ambient signal can be performed in a<br>
particularly efficient manner if the weighting of the input<br>
signal is performed by the weighter using a time-frequency-<br>
domain of the input audio signal 110. The weighter 130 is<br>
configured to weight the at least one sub-band signal 132<br>
of the input audio signal in dependence on the gain values<br>
122. The weighter 130 is configured to apply the gain<br>
values of the sequence of gain values to the one or more<br>
sub-band signals 132 to scale the sub-band signals, to<br>
obtain one or more weighted sub-band signals 112.<br>
In some embodiments, the gain-value determinator 120 is<br>
configured such that features of the input audio signal are<br>
evaluated, which characterize (or at least provide an<br>
indication) wherher the input audio signal 110 or a sub-<br>
band thereof (represented by a sub-band signal 132) is<br>
likely to represent an ambient component or a non-ambient<br>
component of an aadio signal. However, the feature values<br>
processed by the gain value determinator may be chosen to<br>
provide a quantitative information regarding a relationship<br>
between ambient components and non-ambient components<br>
within the input audio signal 110. For example, the feature<br>
values may carry an information (or at least an indication)<br>
regarding a relationship between ambient components and<br>
non-am.bient components in the input audio signal 110, or at<br>
least an information describing an estimate thereof.<br>
Accordingly, the gain-value determinator 130 may be<br>
configured to generate the sequence of gain-values such<br>
that ambience comiponents are emphasized with respect to<br>
non-ambience components in the weighted sub-band signal<br>
112, weighted in accordance with the gain-values 122.<br>
To sum.marize the above, the functionality of the apparatus<br>
100 is based on a determination of a sequence of gain-<br>
values on the basis of one or more sequences of<br>
quantitative feauure-values describing features of the<br>
input audio signal 110. The sequence of gain-values is<br>
generated such that the sub-band signal 132 representing a<br>
frequency band of the input audio signal 110 is scaled with<br>
a large gain value if the feature-values indicate a<br>
comparatively large "ambience-likeliness" of the respective<br>
time-frequency bin and such that the frequency band of the<br>
input audio signal 110 is scaled with a comparatively small<br>
gain-value if the one or more features considered by the<br>
gain-value determinator indicate a comparatively low<br>
"ambier.ce-likeli HGSs" of the respective time-frequency bin.<br>
Apparatus for Rxtractinq an ambient signal - second<br>
embodiment<br>
Taking reference now to Fig. 2, an optional extension of<br>
the apparatus 10? shown in Fig. 1 will be described. Fig. 2<br>
shows a detailed block schematic diagram of an apparatus<br>
for extracting an ambient signal from an input audio<br>
signal. The apparatus shown in Fig. 2 is designed in its<br>
entirely with 200.<br>
The apparatus 2Cr, is configured to receive an input audio<br>
signal 210 and •...o provide a plurality of output sub-band<br>
signals 212a to 2'.2d, some of which may be weighted.<br>
The apparatus 2C-C may, for example, comprise an analysis<br>
filterfcank 215, which may be considered as optional. The<br>
analysis filterbar.k 216 may, for example, be configured to<br>
receive the inpu' audio signal content 210 in a time-domain<br>
representation and to provide a time-frequency-domain<br>
representation of the input audio signal. The time-<br>
frequency-donair. representation of the input audio signal<br>
may, for example, describe the input audio signal in terms<br>
of a plurality of sub-band signals 218a to 218d. The sub-<br>
band signals 218a to 218d may, for example, represent a<br>
temporal evolution of an energy, which is present in<br>
different sub-bands or frequency bands of the input audio<br>
signal 210. Tor example, the sub-band signals 218a to 218d<br>
may represent a sequence of Fast Fourier transform<br>
coefficients for subsequent (temporal) portions of the<br>
input audio signal 210. For example, the first sub-band<br>
signa". 21Ba m.ay describe a temporal evolution of an energy,<br>
which IS present in a given frequency sub-band of the input<br>
audio signal in subsequent temporal segments, which may be<br>
overlaoping or non-overlapping. Similarly, the other sub-<br>
band signals 218b to 218d may describe a temporal evolution<br>
of energies present m other sub-bands.<br>
The gain-value determinator may (optionally) comprise a<br>
plurality of quantitative feature value determinators 250,<br>
252, 254. The quantitative feature value determinators 250,<br>
252, 2 54 may, : r^. some embodiments, be part of the gain-<br>
value determinator 220. However, in other embodiments, the<br>
quanti:.ative fea:,':re value determinators 250, 252, 254 may<br>
be external to r.he gain-value determinator 220. In this<br>
case, -...he gain-value determinator 220 may be configured to<br>
receive quantitative feature values from external<br>
quantitative feature value determinators. Both receiving<br>
externally generated quantitative feature values and<br>
internally generating quantitative feature values will be<br>
considered as "ootaining" quantitative feature values.<br>
The quantitative feature value determinators 250, 252, 254<br>
may, for example, be configured to receive an information<br>
about the input audio signal and to provide quantitative<br>
feature values 25Ga, 252a, 254a describing, in a<br>
quantitative manner different features of the input audio<br>
signal.<br>
In some embodiments, the quantitative feature value<br>
deterninators 250, 252, 254 are chosen to describe, in<br>
terms of corresponding quantitative feature values 250a,<br>
252a, 254a, features of the input audio signal 210, which<br>
provide an indication with respect to an ambience-<br>
component-conter.t of the input audio signal 210 or with<br>
respect to a relationship between an ambience-component-<br>
content and a ron-am.bience-component-content of the input<br>
audio signal 21';.<br>
The gain value determinator- 220 further comprises a<br>
weighting combiner 260. The weighting combiner 260 may be<br>
configured to receive the quantitative feature values 250a,<br>
252a, 254a and ro provide, on the basis thereof, a gain-<br>
value 222 (or a sequence of gain values) . The gain value<br>
222 (or the sequence of gain values) may be used by a<br>
weighter unit to weight one or more of the sub-band signals<br>
218a, 218b, 21Bc, 218d. For example, the weighter unit<br>
(also sometimes designated briefly as "weighter") may<br>
comprise, for example, a plurality of individual scalers or<br>
individual weighters 270a, 270b, 270c. For example, a first<br>
individual weighter 270a may be configured to weight a<br>
first sub-band signal 218a in dependence on the gain value<br>
(or sequence of gain values) 222. Thus, the first weighted<br>
sub-band signal 212a is obtained. In some embodiments, the<br>
gain value (or sequence of gain values) 222 may be used to<br>
weight additional sub-band signals. In an embodiment, an<br>
optional second individual weighter 270b may be configured<br>
to weight the second sub-band signal 218b to obtain the<br>
second weighted sub-band signal 212b. Further, a third<br>
individual weighter 270c may be used to weight the third<br>
sub-band signal 218c to obtain the third weighted sub-band<br>
signal 212c. It can be seen from the above discussion that<br>
the gain value (or the sequence of gain values) 222 can be<br>
used to weight one or more of the sub-band signals 218a,<br>
218b, 218c, 218d representing the input audio signal in the<br>
form of a time-frequency-domain representation.<br>
Quantitative-feature-value determinators<br>
In the following, various details regarding the<br>
quantitative-feature-value determinators 250, 252, 254 will<br>
be described.<br>
The quantitative feature value determinators 250, 252, 254<br>
may be configured to use the different types of input<br>
information. For example, the first quantitative feature<br>
value determinator 250 miay be configured to receive, as an<br>
input information, a time-domain representation of the<br>
input audio signal, as shown in Fig. 2. Alternatively, the<br>
first quantitative feature value determinator 250 may be<br>
configured to receive an input information describing the<br>
overall spectrum of the input audio signal. Thus, in some<br>
embodiments, at least one quantitative feature value 250a<br>
may (optionally) be calculated on the basis of the time-<br>
domain representation of the input audio signal or on the<br>
basis of another representation describing the input audio<br>
signal in its entirety (at least for a given period in<br>
time).<br>
The second quantitative feature value determinator 252 is<br>
configured to receive, as an input information, a single<br>
sub-band signal, for example, the first sub-band signal<br>
218a. Thus, the second quantitative-feature-value<br>
determinator may, for example, be configured to provide the<br>
corresponding q-.:.antitative-feature-value 252a on the basis<br>
of a single sub-oand signal. In an embodiment in which the<br>
gain value 222 (or the sequence thereof) is applied only to<br>
a single sub-band signal, the sub-band signal to which the<br>
gain value 222 is applied, may then be identical to the<br>
sub-band signal used by the second quantitative feature<br>
value determma'-or 222.<br>
The third quantitative feature value determinator 254 may,<br>
for example, be configured to receive, as an input<br>
information, a plurality of sub-band signals. For example,<br>
the third quantitative feature value determinator 254 is<br>
configured to receive, as an input information, the first<br>
sub-band signal 218a, the second sub-band signal 218b and<br>
the third sub-band signal 218c. Thus, the quantitative<br>
feature value determinator 254 is configured to provide the<br>
quantitative feature value 254a on the basis of a plurality<br>
of sub-band signals. In an embodiment in which the gain<br>
value 222 (cr a sequence thereof) is applied to weight a<br>
plurality of sub-band signals (for example, the sub-band<br>
signals 218a, 218b, 218c), the sub-band signals to which<br>
the gain value 222 is applied, may be identical to the sub-<br>
band signals evaluated by the third quantitative feature<br>
value determinator 254.<br>
To summarize the above, the gain value determinator 222<br>
may, in some embodiments, comprise a plurality of different<br>
quantitative feature value determinators configured to<br>
evaluate different input information in order to obtain a<br>
plurality of different feature values 250a, 252a 254a. In<br>
some embodiments, one or more of the feature value<br>
determinators may be configured to evaluate features on the<br>
basis of a bread band representation of the input audio<br>
signal (for example, on the basis of the time-domain<br>
representation of the input audio signal), while other<br>
feature value determinators may be configured to evaluate<br>
only a portion of a frequency spectrum of the input audio<br>
signal 210, or even only a single frequency band or<br>
frequency sub-band.<br>
Weighting<br>
In the followinc, some details regarding the weighting of<br>
the quantitative feature values, which is performed, for<br>
example, by the weighting combiner 260, will be described.<br>
The weighting combiner 2 60 is configured to obtain, on the<br>
basis of the quantitative feature values 250a, 252a, 254a<br>
provided by the quantitative feature value determinators<br>
250, 252, 254, the gain values 222. The weighting combiner<br>
may, for example, be configured to linearly scale the<br>
quantitative feature values provided by the quantitative<br>
feature value determinators. In some embodiments, the<br>
weighting combiner may be considered to form a linear<br>
combination of the quantitative feature values, wherein<br>
different weights (which may, for example, be described by<br>
respective weighting coefficients) may be associated to the<br>
quantitative feature values. In some embodiments, the<br>
weighting combiner may also be configured to process the<br>
feature values provided by the quantitative feature value<br>
determinators ;.n a non-linear way. The non-linear<br>
processing may, for example, be performed prior to the<br>
combination or as an in:,eger part of the combination.<br>
In some embodiments, the weighting combiner 260 may be<br>
configured to be adjustable. In other words, in some<br>
embodiments, the weighting combiner may be configured such<br>
that weights associated with the quantitative feature<br>
values of the different quantitative feature value<br>
determinators are adjustable. For example, the weighting<br>
combiner 260 may be configured to receive a set of<br>
weighting coefficients, which may, for example, have an<br>
impact on a non-linear processing of the quantitative<br>
feature values 25Ca, 252a, 254a and/or on a linear scaling<br>
of the quantitative feature values 250a, 252a, 254a.<br>
Details regarding the weighting process will be<br>
subsequently described.<br>
In some embcdim.ents, the gain value determinator 220 may<br>
comprise an optional weight adjuster 270. The optional<br>
weight adjuster 270 may be configured to adjust the<br>
weighting of the quantitative feature values 250a, 252a,<br>
254a perform.ed by the weighting combiner 260. Details<br>
regarding the determination of the weighting coefficients<br>
for the weighting of the quantitative feature values will<br>
be subsequently described, for example, taking reference to<br>
Figs. 14 to 20.Saia determination of the weighting<br>
coefficients may for example be performed by a separate<br>
apparatus or by the weight adjuster 270.<br>
Apparatus for extracting an ambient signal - third<br>
embodiment<br>
In the following, another embodiment according to the<br>
invention will be described. Fig. 3 shows a detailed block<br>
schematic diagram of an apparatus for extracting an ambient<br>
signal from an input audio signal. The apparatus shown in<br>
Fig. 3 is designated in its entirety with 300.<br>
However, it should be noted that throughout the present<br>
description, identical reference numerals are chosen to<br>
designate identical means, signals or functionalities.<br>
The apparatus 300 is very similar to the apparatus 200.<br>
However, the apparatus 300 comprises a particularly<br>
efficient set of feature value determinators.<br>
As can be seen from Fig. 3, a gain value determinator 320,<br>
which takes the place of the gain value determinator 220<br>
shown in Fig. 2, comprises, as a first quantitative feature<br>
value determinator, a tonality feature value determinator<br>
350. The tonality feature value determinator 350 may, for<br>
example, be configured to provide, as a first quantitative<br>
feature value, a quantitative tonality feature value 350a.<br>
Moreover, the gain value determinator 320 comprises, as a<br>
second quantitative feature value determinator, an energy<br>
feature value determinator 352, which is configured to<br>
provide, as a second quantitative feature value, an energy<br>
feature value 352a.<br>
Furthermore, the gain value determinator 320 may comprise,<br>
as a third quantitative feature value determinator, a<br>
spectral centroid feature value determinator 354. The<br>
spectral centroid feature value determinator may be<br>
configured to provide, as a third quantitative feature<br>
value, a spectral centroid feature value describing a<br>
centroid of a frequency spectrum of the input audio signal<br>
or of a portion of the frequency spectrum of the input<br>
audio signal 210.<br>
Accordingly, the weighting combiner 260 may be configured<br>
to combine, in a linearly and/or non-linearly weighted<br>
manner, the tonality feature value 350a (or a sequence<br>
thereof), the energy feature value 352a (or a sequence<br>
thereof) and the spectral centroid feature value 354a (or a<br>
sequence thereof) to obtain the gain value 222 for<br>
weighting the sub-band signals 218a, 218b, 218c, 218d (or,<br>
at least, one of the sub-band signals).<br>
Apparatus for extracting an ambient signal - fourth<br>
embodiment<br>
In the following, a possible extension of the apparatus 300<br>
will be discussed, taking reference to Fig. 4. However, the<br>
concepts described with reference to Fig. 4 can also be<br>
used independent on the configuration shown in Fig. 3.<br>
Fig. 4 shows a block schematic diagram of an apparatus for<br>
extracting an ambient signal. The apparatus shown in Fig. 4<br>
is designated in its entirety with 400. The apparatus 400<br>
is configured to receive, as an input signal, a multi-<br>
channel mpjt audio signal 410. In addition, the apparatus<br>
400 is configured to provide at least one weighted sub-band<br>
signal 412 on the basis of the multi-channel input audio<br>
signal 4]0.<br>
The apparatus 400 comprises a gain value determinator 420.<br>
The gain value determinator 420 is configured to receive an<br>
information describing a first channel 410a and a second<br>
channel 4 10b of the Tulti-channel input audio signal.<br>
Moreover, the gain value determinator 420 is configured to<br>
provide, on the basis of an information describing the<br>
first channel 410a and the second channel 410b of the<br>
multi-channel input audio signal, a sequence of time-<br>
varying ambient signal gain values 422. The time varying<br>
ambient signal gain values 422 may, for example, be<br>
equivalent to the time-varying gain values 222.<br>
Moreover, the apparatus 400 comprises a weighter 430<br>
configured to weight at least one sub-band signal<br>
describ'ng the multi-channel input audio signal 410 in<br>
dependence on the time-varying ambient signal gain values<br>
422.<br>
The weiqhter 4 30 may, for example, comprise the<br>
functionality of the weighter 130 or of the individual<br>
weighters 270a, 270b, 270c.<br>
Taking reference now to the gain value determinator 420,<br>
the gain value determinator 420 may be extended, for<br>
example, with reference to the gain value determinator 120,<br>
the gam value determinator 220 or the gain value<br>
determinator 32C, in that the gain value determinator 420<br>
is configured to obtain one or more quantitative channel-<br>
relationship feature values. In other words, the gain value<br>
determinator 42C may be configured to obtain one or more<br>
quantitative feature values describing a relationship<br>
between zwo or more of the channels of the multi-channel<br>
input signal 410.<br>
For example, the gain value determinator 420 may be<br>
configured to obtain an information describing a<br>
correla:. ion between two of the channels of the multi-<br>
channe] inp-.;t audio signal 410. Alternatively, or in<br>
additio:;, ti-.o gain value determinator 420 may be configured<br>
to obta-in a quantitative feature value describing a<br>
relationship between intensities of signals of a first<br>
channel of the multi-channel input audio signal 410 and of<br>
a second channel of the input audio signal 410.<br>
In som;e emb'" dimients, the gain value determinator 420 may<br>
comprise one or more channel-relationship gain value<br>
determmators configured to provide one or more feature<br>
values (or sequences of feature values) describing one or<br>
more channel-relationship features. In some other<br>
embodiments, in the channel-relationship feature value<br>
determinators may be external to the gain value<br>
determinator 420.<br>
In some embodiments, zhe gain value determinator may be<br>
configured r,o determine the gain values by combining, for<br>
example in a weighted manner, one or more quantitative<br>
channel relationship feature values describing different<br>
channel relationship features. In some embodiments, the<br>
gain value determinator 420 may be configured to determine<br>
the sequence of time-varying ambient signal gain values 422<br>
only on the basis of one or more quantitative channel<br>
relation feaLure values, for example, without considering<br>
quantitative single-channel feature values. However, in<br>
some other embodiments, the gain value determinator 420 is<br>
configured ".:o combine, for example in a weighted manner,<br>
one or more quantitative channel relationship feature<br>
values (describing one or more different channel-<br>
relationship features) and one or more quantitative single<br>
channel fear/ure values (describing one or more single<br>
channel features). Thus, in some embodiments, both single<br>
channel features, which are based on a single channel of<br>
the multi-channel input audio signal 410, and channel<br>
relationship features, which describe a relationship<br>
between two or more channels of the multi-channel input<br>
audio signal 410, can be considered to determine the time-<br>
varying ambient signal gain values.<br>
Thus, in soi'.e embodiments according to the invention, a<br>
particularly meaningful sequence of time varying ambient<br>
signal gain values can be obtained by taking into<br>
consideration both single channel features and channel<br>
relationship features. Accordingly, the time-varying<br>
ambient sicrial gain values can be adapted to the audio<br>
signal cnanr-icl to be weighted with said gain values, while<br>
still taking into consideration precious information, which<br>
can be obtained from evaluating a relationship between<br>
multiple channels.<br>
Gain value determinator details<br>
In the following, details regarding the gain value<br>
determinator will be described taking reference to Fig. 5.<br>
Fig. 5 shows a detailed block schematic diagram of a gain<br>
value determinator. The gain value determinator shown in<br>
Fig. 5 is designated in its entirety with 500. The gain<br>
value deter:r.inator 500 may, for example, take over the<br>
functionality of the gain value determinators 120, 220,<br>
320, 420 described herein.<br>
Non-linear Preprocessor<br>
The gain value determinator 500 comprises an (optional)<br>
non-linear pre-processor 510. The non-linear pre-processor<br>
510 may be configured to receive a representation of one or<br>
more input a::dio signals. For example, the non-linear pre-<br>
processor "10 may be configured to receive a time-<br>
frequency-dcmain representation of an input audio signal.<br>
However, ir some embodiments, the non-linear pre-processor<br>
510 may bo configured to receive, alternatively or<br>
additionally, a time-domain representation of the input<br>
audio signal. In some further embodiments, the non-linear<br>
pre-processor may be configured to receive a representation<br>
of a first channel of an input audio signal (for example, a<br>
time-dom.ain representation or a time-frequency-domain<br>
representation) and a representation of a second channel of<br>
the input audio signal. The non-linear pre-processor may<br>
further be configured to provide a pre-processed<br>
representation of one or more channels of the input audio<br>
signal or a': least a portion (for example, a spectral<br>
portion) of the pre-processed representation to a first<br>
quantitative :eature value determinator 520. Moreover, the<br>
non-linear i.re-processor may be configured to provide<br>
another pre-orocessed representation of the input audio<br>
signal (or a portion thereof) to a second quantitative<br>
feature value determinator 522. The representation of the<br>
input audio signal provided to the first quantitative<br>
feature value determinator 520 may be identical to, or<br>
different from, the representation of the input audio<br>
signal provided to the second quantitative feature value<br>
determinauor 522.<br>
However, it should be noted that the first quantitative<br>
feature valui. determinator 520 and the second quantitative<br>
feature va' ue determinator may be considered as<br>
representing two or more feature value determinators, for<br>
example K fe.":ture value determinators, with K&gt;=1 or K&gt;=2.<br>
In other woris, the gain value determinator 500 shown in<br>
Fig. 5 can oe extended by further quantitative feature<br>
value determ.. lators, as desired and described herein.<br>
Details regarding the functionality of the non-linear<br>
preprocessor ¦.¦ill be described below. However, it should be<br>
noted that tie preprocessing may comprise a determination<br>
of magr.iiude values, energy values, logarithmic magnitude<br>
values, loga: :thmic energy values of the input audio signal<br>
or a spectr-il representation thereof or other nonlinear<br>
preprocessinc: of the input audio signal or a spectral<br>
reoresentatic "i thereof.<br>
Feature value postprocessors<br>
The gain value determinator 500 comprises a first feature<br>
value post-processor 530 configured to receive a first<br>
feature value- (or a sequence of first feature values) from<br>
the first quantitative feature value determinator 520.<br>
Moreover, a .-;econd feature value post-processor 532 may be<br>
coupled to the second quantitative feature value<br>
determma'cor 522 to receive from the second quantitative<br>
feature val.ie determinator 522 a second quantitative<br>
feature value, (or a sequence of second quantitative feature<br>
values). The first feature value post-processor 530 and the<br>
second feature value post-processor 532 may, for example,<br>
be configuied to provide respective post-processed<br>
quantitative; feature values.<br>
For example, the feature value post-processors may be<br>
configured to process the respective quantitative feature<br>
values such "hat a range of values of the post-processed<br>
feature values is limited.<br>
Weighting Cor.biner<br>
The gain value determinator 500 further comprises a<br>
weighting combiner 540. The weighting combiner 540 is<br>
configured to receive the post-processed feature values<br>
from the fe;-;cure value post-processors 530, 532 and to<br>
provide, on che basis thereof, a gain value 560 (or a<br>
sequence of gain values). The gain value 560 may be<br>
equivalent to the gain value 122, the gain value 222, the<br>
gain val'.je 322 or to the gain value 422.<br>
In the following, some details regarding the weighting<br>
combiner 540 will be discussed. In some embodiments, the<br>
weighting combiner 540 may, for example, comprise a first<br>
non-linear processor 542. The first non-linear processor<br>
542 may, for example, be configured to receive the first<br>
post-processed quantitative feature value and to apply a<br>
non-linear mapping to the post-processed first feature<br>
value, to provide non-linearly processed feature values<br>
542a. Moreover, the weighting combiner 540 may comprise a<br>
second non-linear processor 544, which may be configured to<br>
be similar -,0 the first non-linear processor 542. The<br>
second non-linear processor 544 may be configured to non-<br>
linearly map the post-processed second feature value to a<br>
non-linearly processed feature value 544a. In some<br>
embodimenr.s, parameters of non-linear mappings performed by<br>
the nor.-]ir:ear processors 542, 544 may be adjusted in<br>
accordance with respective coefficients. For example, a<br>
first non-linear weighting coefficient may be used to<br>
determine the mapping of the first non-linear processor 542<br>
and the second non-linear weighting coefficient may be used<br>
to determine ::he mapping performed by the second non-liner<br>
processor. 54 4.<br>
In some embodiments, the one or more of the feature value<br>
post-processors 530, 532 may be omitted. In other<br>
embodim.tr.rs, one or all of the non-linear processors 542,<br>
544 may be om.itted. In addition, in some embodiments, the<br>
f unctior.a". ities of the corresponding feature value post-<br>
processors 530,532 and non-linear processors 542, 544 may<br>
be meltf?d into one unit.<br>
The weighting combiner 540 further comprises a first<br>
weighte:" or scaler 550. The first weighter 550 is<br>
configurod Lo receive the first non-linearly processed<br>
quantitaiive feature value (or, in cases where the non-<br>
linear processing is omitted, the first quantitative<br>
feature value) 542a and to scale the first non-linearly<br>
processed quantitative value in accordance with a first<br>
linear ,-.eich: ing coefficient to obtain a first linearly<br>
scaled auanticative feature value 550a. The weighting<br>
combiner 54C further comprises a second weighter or scaler<br>
552. The second weighter 552 is configured to receive the<br>
second r.on-1 i nearly processed quantitative feature value<br>
544a :;;,:, in cases where the non-linear processing is<br>
omitted, the second quantitative feature value) and to<br>
scale S::i:d value in accordance with a second linear<br>
weightin;^ coefficient to obtain a second linearly scaled<br>
quantita;. Ive r^eature value 552a.<br>
The we: q'-^ri'ig comibiner 540 further comprises a combiner<br>
556. The: combiner 556 is configured to receive the first<br>
linearly scaled quantitative feature value 550a and the<br>
second linearly scaled quantitative feature value 552a. The<br>
combiner 556 is configured to provide, on the basis of said<br>
values, the gain value 560. For example, the combiner 555<br>
may be configured to perform a linear combination (for<br>
example, a summation or an averaging operation) of the<br>
first linearly scaled quantitative feature value 550a and<br>
of the second linearly scaled quantitative feature value<br>
552a.<br>
To sumiTiarize -.he above, the gain value determinator 500 may<br>
be configured to provide a linear combination of<br>
quantitative feature values determined by a plurality of<br>
quantirar.ive feature value determinators 520, 522. Prior to<br>
the weighted linear combination, one or more non-linear<br>
post-processing steps may be performed on the quantitative<br>
feature values, for example to limit a range of values<br>
and/or to modify a relative weighting of small values and<br>
large values.<br>
It shou^ i be noted that the structure is the gain value<br>
determinanor 50C shown in Fig. 5 should be considered<br>
exemplary only in order to facilitate the understanding.<br>
However, any of the functionalities of the blocks of the<br>
gain va". ue determinator 500 could be implemented in a<br>
different, circuit structure. For example, some of the<br>
functiona'.. i tic-;S could be combined into a single unit. In<br>
addition, the functionalities described with reference to<br>
Fig. 5 could be performed by shared units. For example, a<br>
single teatu:e value post-processor could be used to<br>
perform, for example in a time-sharing manner, the post-<br>
processing of the feature values provided by a plurality of<br>
quantita'-ive feature value determinators. Similarly, the<br>
functionality of the non-linear processors 542, 544 could<br>
be performed, in a time-sharing manner, by a single non-<br>
linear processor. In addition, a single weighter could be<br>
used to .fulfill the functionality of the weighters 550,<br>
552.<br>
In some embodiments, the functionalities described with<br>
reference to Fig. 5 could be performed by a single tasking<br>
or multi-'iasking computer program. In other words, in some<br>
embodiments, a completely different circuit topology can be<br>
chosen to implement the gain value determinator, as long as<br>
the desired functionality is obtained.<br>
Direct signal Extraction<br>
In the ::ollov:ing, some further details will be described<br>
with respect "o an efficient extraction of both an ambient<br>
signal and a front signal (also designated as "direct<br>
signal") ;:rom. an input audio signal. For this purpose. Fig.<br>
6 shows a block schematic diagram of a weighter or weighter<br>
unit according to an embodiment according to the invention.<br>
The weighy.er or weighter unit shown in Fig. 6 is designated<br>
in its eni;irety with 600.<br>
The weichcer or weighter unit 600 may, for example, take<br>
the place of zhe weighter 130, of the individual weighters<br>
270a, 270, 270c or of the weighter 430.<br>
The weightier 500 is configured to receive a representation<br>
of the input audio signal 610 and to provide both a<br>
representatioi-i of an ambient signal 620 and of a front<br>
signal or a non-ambient signal or a "direct signal" 630. It<br>
should be noted that in some embodiments, the weighter 600<br>
may be configured to receive a time-frequency-domain<br>
representatiori of the input audio signal 610 and to provide<br>
a time-frequency-domain representation of the ambient<br>
signal 620 ar.d of the front signal or non-ambient signal<br>
630.<br>
However, naturally, the weighter 600 may also comprise, if<br>
desired, a time-domain to time-frequency-domain converter<br>
for convert.ir.g a time-domain input audio signal into a<br>
time-frequencv-domain representation and/or one or more<br>
time-freque:icy-domain to time-domain converters to provide<br>
time-domain cutpuc signals.<br>
The weighter 600 may, for example, comprise an ambient<br>
signal weighter 640 configured to provide a representation<br>
of the ambienc signal 620 on the basis of a representation<br>
of the inpi.t audio signal 610. In addition, the weighter<br>
600 may comprise a front signal weighter 650 configured to<br>
provide a representation of the front signal 630 on the<br>
basis of a representation of the input audio signal 610.<br>
The weighter 600 is configured to receive a sequence of<br>
ambient sicnal gain values 660. Optionally, the weighter<br>
600 may be configured to also receive a sequence of front<br>
signal gai:: values. However, in some embodiments, the<br>
weighter 600 may be configured to derive the sequence of<br>
front signal gain values from the sequence of ambient<br>
signal gain values, as will be discussed in the following.<br>
The ambient signal weighter 640 is configured to weight one<br>
or more frequency bands (which may, for example, be<br>
represented by one or more sub-band signals) of the input<br>
audio signal in accordance with the ambient signal gain<br>
values to cbrain the representation of the ambient signal<br>
620, for example in the form of one or more weighted sub-<br>
band signals. Similarly, the front signal weighter 650 is<br>
configured to weight one or more frequency bands or<br>
frequency sub-bands of the input audio signal 610, which<br>
may, for e&gt;;arT.ple, be represented in terms of one or more<br>
sub-band signals, to obtain a representation of the front<br>
signal 63C, for example, in the form of one or more<br>
weighted suD-oand signals.<br>
However, in some embodiments, the ambient signal weighter<br>
640 and the, :"ront signal weighter 650 may be configured to<br>
weight a given frequency band or frequency sub-band<br>
(representc "i, for example, by a sub-band signal) in a<br>
complementary way to generate the representation of the<br>
ambient signal 620 and the representation of the front<br>
signal 630. For example, if an ambient signal gain value<br>
for a specific frequency band indicates that the specific<br>
frequency band should be given a comparatively high weight<br>
in the ambient signal, the specific frequency band is<br>
weighted comparatively high when deriving the<br>
representation of the ambient signal 620 from the<br>
representdticn of the input audio signal 610, and the<br>
specific fraquency band is weighted comparatively low when<br>
deriving the representation of the front signal 630 from<br>
the ' representation of the input audio signal 610.<br>
Similr-;rly, i:' the ambient signal gain value indicates that<br>
the specific frequency band should be given a comparatively<br>
low weight in the ambient signal, the specific frequency<br>
band : s given a low weight when deriving the representation<br>
of the ambient signal 620 from the representation of the<br>
input audio signal 510, and the specific frequency band is<br>
given a comparatively high weight when deriving the<br>
representattc n of the front signal 630 from the<br>
repre;-entat.Lcn of the input audio signal 610.<br>
In s,me embodiments, the weighter 600 may thus be<br>
configured to obtain, on the basis of the ambient signal<br>
gain \alues 660, the front signal gain values 652 for the<br>
front signal, weighter 650, such that the front signal gain<br>
valuer 652 tncrease with decreasing ambient signal gain<br>
value?: 660 ar.d vice-versa.<br>
Accorcjingly, in some embodiments, the ambient signal 620<br>
and the f ron: signal 630 may be generated such that a sum<br>
of enorgies of the ambient signal 620 and of the front<br>
signa. 630 is equivalent to (or proportional to) an energy<br>
of the input audio signal 610.<br>
frequency-domain to time-domain conversion 1150, which may,<br>
for example, be effected using a synthesis filterbank.<br>
Thus, a time-domain representation y of the ambient<br>
components of the input audio signal x is obtained on the<br>
basis of the time-frequency-domain representation Yi to Yn<br>
of the ambient components of the input audio signal.<br>
However, it should be noted that the weighted sub-band<br>
signals provided by the multiplication 1130, 1132 may also<br>
serve as an output signal of the process shown in Fig. 11.<br>
Gain value determination<br>
In the following, the gain computation process will be<br>
described taking reference to Fig. 12. Fig. 12 shows a<br>
block diagram of a gain computation process for one sub-<br>
band of the ambient signal extraction process and of the<br>
front signal extraction process using low-level features<br>
extraction. Different low-level features are computed (for<br>
example designated with LLFl to LLF n) from the input<br>
signal x. The gain factor (for example, designated with g)<br>
is computed as a function of the low-level features (for<br>
example, using a combiner).<br>
Taking reference to Fig. 12, a plurality of low-level<br>
feature computations is shown. For example, a first low-<br>
level feature computation 1210 and a n-th low-level feature<br>
computation 1212 are used in the embodiment shown in Fig.<br>
12. The low-level feature computation 1210, 1212 is<br>
performed on the basis of the input signal x. For example,<br>
the calculation or determination of the low-level features<br>
may be performed on the basis of the time-domain input<br>
audio signal. However, alternatively, the computation or<br>
determination of the low-level features may be performed on<br>
the basis of one or more sub-band signals Xi to Xn.<br>
Moreover, feature values (for example, quantitative feature<br>
values) obtained from the computation or determination<br>
1210, 1212 of the low-level features may be combined, for<br>
exair.ple, using a combiner 1220 (which may for example be a<br>
weighting combiner). Thus, the gain value g may be obtained<br>
on the basis of a combination of the results of the low-<br>
level feature determination or a low-level feature<br>
calculation 1210, 1212.<br>
Concept for determining weighting coefficients<br>
In the following, a concept for obtaining weighting<br>
coefficients for weighting a plurality of feature values,<br>
to obtain a gain value as a weighted combination of the<br>
feature values, will be described.<br>
Apparatus for determining weighting coefficients - first<br>
embodiment<br>
Fig. 13 shows a block schematic diagram of an apparatus for<br>
obtaining weighting coefficients. The apparatus shown in<br>
Fig. 13 is designated in its entirety with 1300.<br>
The apparatus 1300 comprises a coefficient determination<br>
signal generator 1310, which is configured to receive a<br>
basis signal 1312 and to provide, on the basis thereof, a<br>
coefficient determination signal 1314. The coefficient<br>
determination signal generator 1310 is configured to<br>
provide the coefficient determination signal 1314 such that<br>
characteristics of the coefficient determination signal<br>
1314 with respect to ambience components and/or with<br>
respect to non-ambience components and/or a relationship<br>
between ambience components and non-ambience components are<br>
known. In some embodiments, it is sufficient if an estimate<br>
of such an information related to ambience components or<br>
non-ambience components is known.<br>
For example, the coefficient determination signal generator<br>
131C may be configured to provide, in addition to the<br>
coefficient determination signal 1314, an expected gain<br>
value information 1316. The expected gain value information<br>
1316 describes, for example directly or indirectly, a<br>
relationship between ambience components and non-ambience<br>
components of the coefficient determination signal 1314. In<br>
other words, the expected gain value information 1316 can<br>
be considered as a side information describing ambience-<br>
component related characteristics of the coefficient<br>
determination signal. For example, the expected gain value<br>
information may describe an intensity of ambience<br>
components in the coefficient determination audio signal<br>
(for example for a plurality of time-frequency bins of the<br>
coefficient determination audio signal). Alternatively, the<br>
expected gain value information may describe an intensity<br>
of non-ambience components in the coefficient determination<br>
audio signal. In some embodiments, the expected gain value<br>
information may describe a ratio between intensities of<br>
ambience components and non-ambience components. In some<br>
other embodiments, the expected gain value information may<br>
describe a relationship between an intensity of an ambience<br>
component and a total signal intensity (ambience and non-<br>
ambience components) or a relationship between an intensity<br>
of a non-ambience component and a total signal intensity.<br>
However, other information derived from the above mentioned<br>
information may be provided as the expected gain value<br>
information. For example, an estimate of RAoliti, k) defined<br>
below or an estimate of G(m,k) may be obtained as the<br>
expected gain value information.<br>
The apparatus 1300 further comprises a quantitative feature<br>
value determinator 1320 configured to provide a plurality<br>
of quantitative feature values 1322, 1324 describing, in a<br>
quantitative way, features of the coefficient determination<br>
signal 1314.<br>
The apparatus 1300 further comprises a weighting<br>
coefficient determinator 1330, which may, for example, be<br>
configured to receive the expected gain value information<br>
1316 and the plurality of quantitative feature values 1322,<br>
1324 provided by the quantitative feature value<br>
determinator 1320.<br>
The weighting coefficient determinator 1320 is configured<br>
to provide a set of weighting coefficients 1332 on the<br>
basis of the expected gain value information 1316 and the<br>
quantitative feature values 1322, 1324, as will be<br>
described in detail in the following.<br>
Weighting coefficient determinator, first embodiment<br>
Fig. 14 shows a block schematic diagram of a weighting<br>
coefficient determinator according to an embodiment<br>
according to the invention.<br>
The weighting coefficient determinator 1330 is configured<br>
to receive the expected gain value information 1316 and the<br>
plurality of quantitative feature values 1322, 1324.<br>
However, in some embodiments, the quantitative feature<br>
value determinator 1320 may be a part of the weighting<br>
coefficient determinator 1330. Moreover, the weighting<br>
coefficient determinator 1330 is configured to provide the<br>
weighting coefficient 1332.<br>
Regarding the functionality of the weighting coefficient<br>
determinator 1330, it can generally be said that the<br>
weighting coefficient determinator 1330 is configured to<br>
determine the weighting coefficient 1332 such that gain<br>
values obtained, using the weighting coefficients 1332, on<br>
the basis of a weighted combination of the plurality of<br>
quantitative feature values 1322, 1324 (describing a<br>
plurality of features of the coefficient determination<br>
signal 1314, which can be considered as an input audio<br>
signal) approximate gain values associated with the<br>
coefficient determination audio signal. The expected gain<br>
values may, for example, be derived from the expected gain<br>
value information 1316.<br>
In other words, the weighting coefficient determinator may,<br>
for example, be configured to determine which weighting<br>
coefficients are required to weight the quantitative<br>
feature values 1322, 1324 such that the result of the<br>
weighting approximates the expected gain values described<br>
by the expected gain value information 1316.<br>
In other words, the weighting coefficient determinator may,<br>
for example, be configured to determine the weighting<br>
coefficients 1332 such that a gain value determinator<br>
configured according to the weighting coefficients 1332<br>
provides a gain value, which deviates from an expected gain<br>
value described by the expected gain value information 1316<br>
by no more than a predetermined maximum allowable<br>
deviation.<br>
Weighting coefficient determinator, second embodiment<br>
In rhe following, some specific possibilities for<br>
implementing the weighting coefficient determinator 1330<br>
will be described.<br>
Fig. 15a shows a block schematic diagram of a weighting<br>
coefficient determinator according to an embodiment<br>
according to the invention. The weighting coefficient<br>
determinator shown in Fig. 15a is designated in its<br>
entirety with 1500.<br>
The weighting coefficient determinator 1500 comprises, for<br>
example, a weighting combiner 1510. The weighting combiner<br>
1510 may, for example, be configured to receive the<br>
plurality of quantitative feature values 1322, 1324 and a<br>
set of weighting coefficients 1332. Moreover, the weighting<br>
combiner 1510 may, for example, be configured to provide a<br>
gain value 1512 (or a sequence thereof) by combining the<br>
quantitative feature values 1322, 1324 in accordance with<br>
the weighting coefficients 1332. For example, the weighting<br>
combiner 1510 may be configured to perform a similar or<br>
identical weighting, like the weighting combiner 260. In<br>
some embodiments, the weighting combiner 260 may even be<br>
used to implement the weighting combiner 1510. Thus, the<br>
weighting co-Tibiner 1510 is configured to provide a gain<br>
value 1512 (or a sequence thereof).<br>
The weighting coefficient determinator 1500 further<br>
comprises a similarity determinator or difference<br>
determinator 1520. The similarity determinator or<br>
difference determinator 1520 may, for example, be<br>
configured to receive the expected gain value information<br>
1316 describing expected gain values and the gain values<br>
1512 provided by the weighting combiner 1510. The<br>
similarity determinator/difference determinator 1520 may,<br>
for example, be configured to determine a similarity<br>
measure 1522 describing, for example in a qualitative or<br>
quantitative manner, the similarity between the expected<br>
gain values described by the information 1316 and the gain<br>
values 1512 provided by the weighting combiner 1510.<br>
Alternatively, the similarity determinator/difference<br>
determinator 1520 may be configured to provide a deviation<br>
measure describing a deviation therebetween.<br>
The weighting coefficient determinator 1500 comprises a<br>
weighting coefficient adjuster 1530, which is configured to<br>
receive the similarity information 1522 and to determine,<br>
on Che basis thereof, whether it is required to change the<br>
weighting coefficients 1332 or whether the weighting<br>
coefficients 1332 should be kept constant. For example, if<br>
the similarity information 1522 provided by the similarity<br>
determinator/difference determinator 1520 indicates that a<br>
difference or deviation between the gain values 1512 and<br>
solver 1560. The equation system solver or optimization<br>
problem solver 1560 is configured to receive an information<br>
1316 describing expected gain values, which may be<br>
designated with gexpected- The equation system<br>
solver/optimization problem solver 1560 may further be<br>
configured to receive a plurality of quantitative feature<br>
values 1322, 1324. The equation system solver/optimization<br>
problem solver 1560 may be configured to provide a set of<br>
weighting coefficients 1332.<br>
Assuming that the quantitative feature values received by<br>
the equation system solver 1560 are designated with mi and<br>
further assuming that weighting coefficients are, for<br>
example, designated with 0(i and 3i, the equation system<br>
solver may, for example, be configured to solve a non-<br>
linear system of equations of the form:<br>
gexpected,! i^^y designate an expected gain value for a time-<br>
frequency bin having index 1. mi,i designates an i-th<br>
feature value for the time-frequency bin having index 1. A<br>
plurality of L time-frequency bins may be considered for<br>
solving the system of equations.<br>
Accordingly, linear weighting coefficients ai and non-<br>
linear weighting coefficients (or exponent weighting<br>
coefficients) Pi can be determined by solving a system of<br>
equations.<br>
In an alternative embodiment, an optimization can be<br>
performed. For example, a value determined by<br>
can be minimized by determining a set of appropriate<br>
weighting coefficient ai, pi- Here, (.)designates a vector<br>
of differences between expected gain values and gain values<br>
obtained by weighting feature values mi,i. The entries of<br>
the vector of differences may relate to different time-<br>
frequency bins, designated with index 1 = 1...L. M • I I<br>
designates a mathematical distance measure, for example a<br>
mathematical vector norm.<br>
In other words, the weighting coefficients may be<br>
determined such that the difference between the expected<br>
gain values and the gain value obtained from a weighted<br>
combination of the quantitative feature values 1322, 1324<br>
is minimized. However, it should be noted that the term<br>
"minimized" should not be considered here in a very strict<br>
way. Rather, the term minimizing expresses that the<br>
difference is brought below a certain threshold.<br>
Weighting coefficient determinator, fourth embodiment<br>
Fig. 16 shows a block schematic diagram of another<br>
weighting coefficient determinator, according to an<br>
embodiment according to the invention. The weighting<br>
coefficient determinator shown in Fig. 16 is designated in<br>
its entirety with 1600.<br>
The weighting coefficient determinator 1600 comprises a<br>
neural net 1610. The neural net 1610 may, for example, be<br>
configured to receive the information 1316 describing the<br>
expected gain values as well as a plurality of quantitative<br>
feature values 1322, 1324. Moreover, the neural net 1610<br>
may, for example, be configured to provide the weighting<br>
coefficients 1332. For example, the neural net 1610 may be<br>
configured to learn weighting coefficients, which result,<br>
when applied to weight the quantitative feature values<br>
1322, 1324, in a gain value, which is sufficiently similar<br>
to an expected gain value described by the expected gain<br>
value information 1316.<br>
Further details will subsequently be described.<br>
Apparatus for determining weighting coefficients - second<br>
embodiment<br>
Fig. 17 shows a block schematic diagram of an apparatus for<br>
determining weighting coefficients according to an<br>
embodiment according to the invention. The apparatus shown<br>
in Fig. 17 is similar to the apparatus shown in Fig. 13.<br>
Accordingly, identical means and signals are designated<br>
with identical reference numerals.<br>
The apparatus 1-700 shown in Fig. 17 comprises a coefficient<br>
determination signal generator 1310, which may be<br>
configured to receive a basis signal 1312. In an<br>
embodiment, the coefficient determination signal generator<br>
1310 may be configured to add an ambient signal to the<br>
basis signal 1312 to obtain the coefficient determination<br>
signal 1314. The coefficient determination signal 1314 may,<br>
for example, be provided in a time-domain representation or<br>
in a time-frequency-domain representation.<br>
The coefficient determination signal generator may further<br>
be configured to provide the expected gain value<br>
information 1316 describing expected gain values. For<br>
example, the' coefficient determination signal generator<br>
1310 may be configured to provide the expected gain value<br>
information on the basis of internal knowledge regarding an<br>
addition of the ambient signal to the basis signal.<br>
Optionally, the apparatus 1700 may further comprise a time-<br>
domain to time-frequency-domain converter 1316, which may<br>
be configured to provide the coefficient determination<br>
signal 1318 in a time-frequency-domain representation.<br>
Moreover, the apparatus 1700 comprises a quantitative<br>
feature value determinator 1320, which may, for example,<br>
comprise a first quantitative feature value determinator<br>
1320a and a second quantitative feature value determinator<br>
1320b. Thus, the quantitative feature value determinator<br>
1320 is configured to provide a plurality of quantitative<br>
feature values 1322, 1324.<br>
Coefficient determination signal generator - first<br>
embodiment<br>
In the following, different concepts of providing the<br>
coefficient determination signal 1314 will be described.<br>
The concepts described with reference to Figs. 18a, 1.8b, 19<br>
and 20 ar.e applicable both to a time-domain representation<br>
and to a time-frequency-domain representation of the<br>
signal.<br>
Fig. 18a shows a block schematic diagram of a coefficient<br>
determination signal generator. The coefficient<br>
determination signal generator shown in Fig. 18a is<br>
designated in its entirety with 1800. The coefficient<br>
determination signal generator 1800 is configured to<br>
receive, as an input signal 1810, an audio signal with<br>
negligible ambient signal components.<br>
Moreover, the coefficient determination signal generator<br>
1800 may comprise an artificial-ambient-signal generator<br>
1820 configured to provide an artificial ambient signal on<br>
the basis of the audio signal 1810. The coefficient-<br>
determination-signal generator 1800 also comprises an<br>
ambient signal adder 1830 configured to receive the audio<br>
signal 1810 and the artificial ambient signal 1822 and to<br>
add the artificial ambient signal 1822 to the audio signal<br>
1810 to obtain the coefficient determination signal 1832.<br>
Moreover, the coefficient determination signal generator<br>
1800 may be configured to provide, for example, on the<br>
basis of parameters used for generating the artificial<br>
ambient signal 1822 or used for combining the audio signal<br>
1810 with the artificial ambient signal 1822, an<br>
information about the expected gain value. In other words,<br>
the knowledge regarding modalities of the generation of the<br>
artificial ambient signal and/or about the combination of<br>
the artificial ambient signal with the audio signal 1810 is<br>
used to obtain the expected gain value information 1834.<br>
The artificial-ambient-signal generator 1820 may, for<br>
example, be configured to provide, as the artificial<br>
ambient signal 1822, a reverberation signal based on the<br>
audio signal 1810.<br>
Coefficient determination signal generator - second<br>
embodiment<br>
Fig, 18b shows a block schematic diagram of a coefficient<br>
determination signal generator according to another<br>
embodiment according to the invention. The coefficient<br>
determination signal generator shown in Fig. 18b is<br>
designated in its entirety with 1850.<br>
The coefficient determination signal generator 1850 is<br>
configured to receive an audio signal 1860 with negligible<br>
ambient signal components and, in addition, an ambient<br>
signal 1862. The coefficient determination signal generator<br>
1850 also comprises an ambient signal adder 1870 configured<br>
to combine the audio signal 1860 (having negligible ambient<br>
signal components) with the ambient signal 1862. The<br>
ambient signal adder 1870 is configured to provide the<br>
coefficient' determination signal 1872.<br>
Moreover, as the audio signal with negligible ambient<br>
signal components and the ambient signal are available in<br>
an isolated form in the coefficient determination signal<br>
generator 1850, an expected gain value information 1874 can<br>
be derived therefrom.<br>
For example, the expected gain value information 1874 may<br>
be derived such that the expected gain value information is<br>
descriptive of a ratio of magnitudes of the audio signal<br>
and the ambient signal. For example, the expected gain<br>
value information may describe such ratios of intensities<br>
for a plurality of time-frequency bins of a time-frequency-<br>
domain representation of the coefficient determination<br>
signal 1872 (or of the audio signal 1860). Alternatively,<br>
the expected gain value information 1874 may comprise an<br>
information about intensities of the ambient signal 1862<br>
for a plurality of time-frequency bins.<br>
Coefficient determination signal generator - third<br>
embodiment<br>
Taking reference now to Figs. 19 and 20, another approach<br>
for determining the expected gain value information will be<br>
discussed. Fig. 19 shows a block schematic diagram of a<br>
coefficient determination signal generator according to an<br>
embodiment according to the invention. The coefficient<br>
determination signal generator shown in Fig. 19 is<br>
designated in its entirety with 1900.<br>
The coefficient determination signal generator 1900 is<br>
configured to receive a multi-channel audio signal. For<br>
example, the coefficient determination signal generator<br>
1900 may be configured to receive a first channel 1910 and<br>
a second channel 1912 of the multi-channel audio signal.<br>
Moreover, the coefficient determination signal generator<br>
1910 may comprise a channel-relationship based feature-<br>
value determinator, for example, a correlation-based<br>
feature-value determinator 1920. The channel relationship-<br>
based feature value determinator 1920 may be configured to<br>
provide a feature value, which is based on a relationship<br>
between two or more of the channels of the multi-channel<br>
audio signal.<br>
In some embodiments, such a channel-relationship-based<br>
feature-value may provide a sufficiently reliable<br>
information regarding an ambience-component content of the<br>
multi-channel audio signal without requiring additional<br>
pre-knowledge. Thus, the information describing the<br>
relationship between two or more channels of the multi-<br>
channel audio signal obtained by the channel-relationship-<br>
based feature-value determinator 1920 may serve as an<br>
expected-gain-value information 1922. Moreover, in some<br>
embodiments, a single audio channel of the multi-channel<br>
audio signal may be used as a coefficient determination<br>
signal 1924.<br>
Coefficient determination signal generator - fourth<br>
embodiment<br>
A similar concept will be subsequently described with<br>
reference to Fig. 20. Fig. 20 shows a block schematic<br>
diagram of a coefficient determination signal generator<br>
according to an embodiment according to the invention. The<br>
coefficient determination signal generator shown in Fig. 20<br>
is designated in its entirety with 2000.<br>
The coefficient determination signal generator 2000 is<br>
similar to the coefficient determination signal generator<br>
1900 such that identical signals are designated with<br>
identical reference numerals.<br>
However, the coefficient determination signal generator<br>
2000 comprises a multi-channel to single-channel combiner<br>
2010 configured to combine the first channel 1910 and the<br>
second channel 1912 (which are used for determining the<br>
channel-relationship-based feature value by the channel-<br>
relationship-based feature value determinator 1920) to<br>
obtain the coefficient determination signal 1924. In other<br>
words, rather than using a single channel signal of the<br>
multi-channel audio signal, a combination of the channel<br>
signals is used to obtain the coefficient determination<br>
signal 1924.<br>
Taking reference to the concept described with respect to<br>
Figs. 19 and 20, it can be noted that a multi-channel audio<br>
signal can be used to obtain the coefficient determination<br>
signal. In typical multi-channel audio signals, a<br>
relationship between the individual channels provides an<br>
information with respect to an ambience-component content<br>
of the multi-channel audio signal. Accordingly, a multi-<br>
channel audio signal can be used for obtaining the<br>
coefficient determination signal and for providing an<br>
expected gain value information characterizing the<br>
coefficient determination signal. Therefore, a gain value<br>
determinator, which operates on the basis of a single<br>
channel of an audio signal, can be calibrated (for example,<br>
by determining respective coefficients) making use of a<br>
stereo signal or a different type of multi-channel audio<br>
signal. Thus, by using a stereo signal or a different type<br>
of multi-channel audio signal, coefficients for an ambient<br>
extractor can be obtained, which coefficients may be<br>
applied (for example after obtaining the coefficients) for<br>
the processing of a single channel audio signal.<br>
Method for extracting an ambient signal<br>
Fig. 21 shows a flowchart of a method for extracting an<br>
ambient signal on the basis of a time-frequency-domain<br>
representation of an input audio signal, the representation<br>
representing the input audio signal in terms of a plurality<br>
of sub-band signals describing a plurality of frequency<br>
bands. The method shown in Fig. 21 is designated in its<br>
entirety with 2100.<br>
The method 2100 comprises obtaining 2110 one or more<br>
quantitative feature values describing one or more features<br>
of the input audio signal.<br>
The method 2100 further comprises determining 2120 a<br>
sequence of time-varying ambient signal gain values for a<br>
given frequency band of a time-frequency-domain<br>
representation of the input audio signal as a function of<br>
the one or more quantitative feature values, such that the<br>
gain values are quantitatively dependent on the<br>
quantitative feature values.<br>
The method 2100 further comprises weighting 2130 a sub-band<br>
signal representing the given frequency band of the time-<br>
frequency-domain representation with the time-varying gain<br>
values.<br>
In some embodiments, the method 2100 may be operational to<br>
perform the functionality of the apparatus described<br>
herein.<br>
Method for obtaining weighting coefficients<br>
Fig. 22 shows a flowchart of a method for obtaining<br>
weighting coefficients for parameterizing a gain value<br>
determinator for extracting an ambient signal from an input<br>
audio signal. The method shown in Fig. 22 is designated in<br>
its entirety with 2200.<br>
The method 2200 comprises obtaining 2210 a coefficient<br>
determination input audio signal, such that an information<br>
about ambience -components present in the input audio signal<br>
or an information describing a relationship between<br>
ambience components and non-ambience components is known.<br>
The method 2200 further comprises determining 2220<br>
weighting coefficients such that gain values obtained on<br>
the basis of a weighted combination, according to the<br>
weighting coefficients, of a plurality of quantitative<br>
feature values describing a plurality of features of the<br>
coefficient determination input audio signal approximate<br>
expected gain values associated with the coefficient<br>
determination input audio signal.<br>
The methods described herein may be supplemented by any of<br>
the features and functionalities described also with<br>
respect to the inventive apparatus.<br>
Computer Programs<br>
Depending on certain implementation requirements of the<br>
inventive methods, the inventive methods can be implemented<br>
in hardware or in software. The implementation can be<br>
performed using a digital storage medium, for example a<br>
floppy disk, a DVD, a CD, a ROM, a PROM, an EPROM, an<br>
EEPROM or a FLASH memory, having electronically readable<br>
control signals stored thereon, which cooperate with a<br>
programmable computer system such that the inventive method<br>
is performed. Generally, the present invention is,<br>
therefore, a computer program product with a program code<br>
stored on a machine readable carrier, the program code<br>
being operative for performing the inventive method when<br>
the computer program product runs on a computer. In other<br>
words, the inventive method is, therefore, a computer<br>
program having a program code for performing the inventive<br>
method when the computer program runs on a computer.<br>
3 Descrip'tion of a method according to another<br>
embodiment.<br>
3 .1 Problem description<br>
A method according to an embodiment aims at the extraction<br>
of a front signal and an ambient signal suited for blind<br>
upmixing of audio signals. The multi-channel surround sound<br>
signal may be obtained by feeding the front channels with<br>
the front signal and by feeding the rear channels with the<br>
ambient signal.<br>
Various methods for the extraction of an ambient signal<br>
already exist:<br>
1. using NMF .(see Section 2.1.3)<br>
2. using a time-frequency mask depending on the<br>
correlation of the left and right input signal (see<br>
Section 2.2.4)<br>
3. using PCA and a multi-channel input signal (see<br>
Section 2.3.2)<br>
Method 1 relies on an iterative numeric optimization<br>
technique whereas a segment of a few seconds length (e.g.<br>
2...4 seconds) is processed at a time. Consequently, the<br>
method is of high computational complexity and has an al-<br>
gorithmic delay of at least the aforementioned segment<br>
length. In contrast, the inventive method is of low<br>
computational complexity and has a low algorithmic delay<br>
compared to Method 1.<br>
Methods 2 and 3 rely on distinct differences between the<br>
input channel signals, i. e. they do not produce an<br>
appropriate ambience signal if all input channel signals<br>
are identical or nearly identical. In contrast, the<br>
inventive method is able to process mono signals or multi-<br>
channel signals which are identical or nearly identical.<br>
In summary, the advantages of the proposed method are as<br>
follows:<br>
• Low complexity<br>
• Low delay<br>
• Works for monophonic and nearly monophonic input<br>
signals as well as for stereophonic input signals<br>
3.2 Method description<br>
A multi-channel surround signal (e.g. in 5.1 or 7.1 format)<br>
is obtained by extracting an ambient signal and a front<br>
signal from the input signal. The ambient signal is fed<br>
into the rear channels. The center channel is used to<br>
enlarge the sweet spot and plays back the front signal or<br>
the original input signal. The other front channels play<br>
back the front signal or the original input signal (i.e.<br>
the left front channel plays back the original left front<br>
signal or a processed version of the original left front<br>
signal). Figure 10 shows a block diagram of the upmix<br>
process.<br>
The extraction of the ambient signal is carried out in the<br>
time-frequency domain. The inventive method computes time-<br>
varying weights (also designated as gain values) for each<br>
sub-band signal using low-level features (also designated<br>
as quantitative feature values) measuring the "ambience-<br>
likeliness" of each subband signal. These weights are<br>
applied prior to the re-synthesis to compute the ambient<br>
signal. Complementary weights are computed for the front<br>
signal.<br>
Examples for typical characteristics of ambience are:<br>
• Ambient sounds are rather quiet sounds compared to<br>
direct sounds.<br>
• Ambient sounds are less tonal than direct sounds.<br>
Appropriate low-level features for the detection of such<br>
characteristic are described in Section 3.3:<br>
• Energy features measure the quietness of a signal<br>
component<br>
• Tonality features measure the noisiness of a signal<br>
component<br>
The time-varying gain factors g(o),T) with sub-band index q<br>
and time index t are derived from the computed features<br>
mi(u,T) using for instance Equation 1<br>
with K being the number of features and the parameters ai<br>
and Pi used for the weighting of the different features.<br>
Figure 11 illustrates a block diagram of the ambience<br>
extraction process using low-level feature extraction. The<br>
input signal x is a one-channel audio signal. For the<br>
processing of signals with more channels, the processing<br>
may be applied to each channel separately. The analysis<br>
filter-bank separates the input signal into N frequency<br>
bands (N &gt; 1), e.g. using for instance an STFT (Short-Term<br>
Fourier Transform) or digital- filters. The output of the<br>
analysis filter-bank are N sub-band signals Xi, 1 ^ i ^ N.<br>
The gain factors gi, 1 ^ i ^ N, are obtained by computing<br>
one ore more low-level features from sub-band signals Xi<br>
and combining the feature values, as illustrated in Figure<br>
11. Each sub-band signal Xi is then weighted using the gain<br>
factor gi.<br>
A preferred extension to the described process is the use<br>
of groups of sub-band signals instead of single sub-band<br>
signals: Sub-band signals can be grouped to form groups of<br>
sub-band signals. The processing described here can be<br>
carried out using groups of sub-band signals, i.e. low-<br>
level features are computed from one or more groups of sub-<br>
band signals (whereas each group contains one or more sub-<br>
band signals) and the derived weighting factors are applied<br>
to the corresponding sub-band signals (i.e. to all sub-<br>
bands belonging to the particular group).<br>
An estimate for a spectral representation of the ambience<br>
signal is obtained by weighting one or more of the sub-<br>
bands with the corresponding weight gi. The signal which<br>
will feed the front channels of the multi-channel surround<br>
signal is processed in a similar way with complementary<br>
weights as used for the ambient signal.<br>
The additional play-back of the ambient signal results in<br>
more ambient signal components (compared to the original<br>
input signal). The weights for the computation of the front<br>
signal are computed as being in an inverse proportion to<br>
the weights for the computation of the ambient signal.<br>
Consequently, each resulting front signal contains less<br>
ambient signal components and more direct signal components<br>
compared to the corresponding original input signal.<br>
The ambient signal is (optionally) further enhanced (with<br>
respect to the perceived quality of the resulting surround<br>
sound signal) using additional post-processing in the<br>
spectral domain and resynthesized using the inverse process<br>
of the analysis filter-bank (i.e. the synthesis filter-<br>
bank), as shown in Figure 11.<br>
The post-processing is detailed in Section 7. It should be<br>
noted that some postprocessing algorithms can be carried<br>
out in either the spectral domain or the temporal domain.<br>
Figure 12 shows a block diagram of the gain computation<br>
process for one sub-band (or one group of sub-band signals)<br>
based on the extraction of low-level features. Various low-<br>
level features are computed and combined, yielding the gain<br>
factor.<br>
The resulting gains can be further post-processed using<br>
dynamic compression and low-pass filtering (both in time<br>
and in frequency).<br>
3.3 Features<br>
The following section describes features that are suitable<br>
for characterizing ambience-like signal quality. In<br>
general, the features characterize an audio signal (broad-<br>
band) or a particular frequency region (i.e. a sub-band) or<br>
a group of sub-bands of an audio signal. The computation of<br>
features in sub-bands requires the use of a filter-bank or<br>
time-frequency transform.<br>
The computation is explained here using a spectral<br>
representation X(k),i) of the audio signal x[k], with u<br>
being the sub-band index and time index x . A spectrum (or<br>
one range of a spectrum) is denoted by Sk, with k being the<br>
frequency index.<br>
Feature computation using the signal spectrum may process<br>
different representations of the spectrum, i.e. magnitudes,<br>
energy, logarithmic magnitudes or energy or any other non-<br>
linear processed spectrum (e.g. X°'^"^) . If not noted<br>
otherwise, the spectral representation is assumed to be<br>
real-valued.<br>
Features computed in adjacent sub-bands can be subsumed' to<br>
characterize a group of sub-bands, e.g. by averaging the<br>
feature values of the sub-bands. Consequently, the tonality<br>
for a spectrum can be computed from the tonality values for<br>
each spectral coefficient of the spectrum, e.g. by<br>
computing their mean value.<br>
It is desired that values range of the computed features is<br>
[0, 1] or a different predetermined interval. Some feature<br>
computations described below do not result in values within<br>
that range. In these cases, appropriate mapping functions<br>
are applied, for example to map values describing a feature<br>
to a predetermined interval. A simple example for a mapping<br>
function is given in Equation 2.<br>
The mapping can for example be performed using the post-<br>
processor 530, 532.<br>
3.3.1 Tonality Fea'tures<br>
The term Tonality as used here describes "a feature<br>
distinguishing noise versus tone quality of sounds".<br>
Tonal signals are characterized by a non-flat signal<br>
spectrum, whereas noisy signals have a flat spectrum.<br>
Consequently, tonal signals are more periodic than noisy<br>
signals, whereas noisy are more random than tonal signals.<br>
Therefore, tonal signal are predictable from preceding<br>
signal values with a small prediction error, whereas noisy<br>
signals are not well-predicable.<br>
In the following, a plurality .of features will be described<br>
which can be used to quantitatively describe a tonality. In<br>
other words, the features described here can be used to<br>
determine a quantitative feature value, or can serve as a<br>
quantitative feature value.<br>
Spectral Flatness Measure: Spectral Flatness Measure<br>
(SFM) is computed as the ratio of the geometric mean value<br>
and the arithmetic mean value of the spectrum S.<br>
Alternatively, Equation 4 can be used, yielding the<br>
identical result.<br>
 (4)<br>
A feature value may be derived from SFM(S).<br>
Spectral Crest Factor: The Spectral Crest Factor is<br>
computed as the ratio of the maximum value and the mean<br>
value of the spectrum X (or S).<br>
A quantitative feature value may be derived from SCF(S).<br>
Tonality compu'tation using peak detection: In I SO/I EC<br>
11172-3MPEG-1 Psychoacoustic Model 1 (recommended for<br>
Layers 1 and 2) [IS093] a method is described to<br>
discriminate between tonal and non-tonal components, which<br>
is used to determine of the masking threshold for<br>
perceptual audio coding. The tonality of a spectral<br>
coefficient Si is determined by examining the levels of<br>
spectral values within a frequency range Af surrounding the<br>
frequency corresponding to Si. Peaks (i.e. local maxima)<br>
are detected if the energy of Xj, exceeds the energies of<br>
its surrounding values Si+k, with e.g. k e [-4, -3, -2, 2,<br>
3, 4]. If the local maximum exceeds its surrounding values<br>
by 7 dB or more, it is classified as tonal. Otherwise, the<br>
local maximum may be classified as not tonal.<br>
A feature value can be derived describing whether a maximum<br>
is tonal or not. Also, a feature value may be derived<br>
describing, for example, how many tonal time-frequency bins<br>
are present within a given neighbourhood.<br>
Tonality computation using the ratio of nonlinearly<br>
processed copies: The non-flatness of a vector is<br>
measured as ratio of two nonlinearly processed copies of<br>
the spectrum S as shown in Equation 6 with a &gt; (3.<br>
Two particular implementations are shown in Equation 7 and<br>
A quantitative feature value may be derived from F(S).<br>
Tonality confutation using the ratio of differently<br>
filtered spectra: The following tonality measure is<br>
described in US-Patent 5,918,203 [HEG'99] .<br>
The tonality of a spectral coefficient Sk for frequency<br>
line k is computed from the ratio 9 of two filtered copies<br>
of the spectrum S, whereas the first filter function H has<br>
a differentiating characteristic and the second filter<br>
function G has an integrating characteristic or a<br>
characteristic which is less strongly differentiating than<br>
the first filter, and c and d are integer constants which,<br>
depending on the filters parameters, are chosen such that<br>
the delays of the filters are compensated for in each case.<br>
 (9)<br>
A particular implementation is shown in Equation 10, where<br>
H is the transfer function of a differentiating filter.<br>
e(k) = H(Sk^c) (10)<br>
A quantitative feature value can be derived from 6*^ or from<br>
e(k) .<br>
Tonality computation using periodicity functions: The<br>
aforementioned tonality measures use the spectrum of the<br>
input signal and derive a measure of tonality from the non-<br>
flatness of the spectrum. The tonality measures (from which<br>
a feature value can be derived) can also be computed using<br>
a periodicity function of the input time signal instead of<br>
its spectrum. A periodicity function is derived from the<br>
comparison of a signal with its delayed copy.<br>
The similarity or difference of both are given as a<br>
function of the lag (i.e. the time delay between both<br>
signals). A high degree of similarity (or a low difference)<br>
between a signal and its (by lag i) delayed copy indicates<br>
a strong periodicity of the signal with period t.<br>
Examples for periodicity functions are the autocorrelation<br>
function and the Average Magnitude Difference Function<br>
[dCK03] . The autocorrelation function rxx("t) of a signal x<br>
is shown in Equation 11, with integration window size W.<br>
Tonality computation using the prediction of spectral<br>
coefficients: The tonality estimation using the prediction<br>
of the complex spectral coefficients Xi from preceding<br>
coefficients bins Xi-i and Xi-2 is described in ISO/IEC<br>
11172-3 MPEG-1 Psychoacoustic Model 2 (recommended for<br>
Layer 3).<br>
The current values for the magnitude Xo(o,i) and phase<br>
^((0,1) of the complex spectral coefficient X(a),T)<br>
Xo («,!)£"' can be estimated from the previous values<br>
according to Equations 12 and 13.<br><br><br>
The normalized Euclidean distance between the estimated and<br>
actually measured values (as shown in Equation 14) is a<br>
measure for the tonality, and can be used to derive a<br>
quantitative feature value.<br>
The tonality for one spectral coefficient can also be<br>
computed from the prediction error P(co) (see Equation 15,<br>
with X(a),T) being complex-valued) such that large<br>
prediction errors result in small tonality values.<br>
P(q,t) = X(a),T) - 2X(Q,T - 1) + X(u,T - 2) (15)<br>
Tonality computation using prediction in the time domain:<br>
The signal x[k] a time index k can be predicted from<br>
preceding samples using Linear Prediction, whereas the<br>
prediction error is small for periodic signals and large<br>
for random signals. Consequently, the prediction error is<br>
in inverse proportion to the tonality of the signal.<br>
Accordingly, a quantitative feature value can be derived<br>
from the prediction error.<br>
3.3.2 Energy features<br>
Energy features measure the instantaneous energy within a<br>
sub-band. The weighting factor for the ambience extraction<br>
of a particular frequency band will be lower at times when<br>
the energy content of the frequency band is high, i.e. the<br>
particular time-frequency tile is very likely to be a<br>
direct signal component.<br>
Additionally, energy features can also be computed from<br>
adjacent (with respect to time) sub-band samples of the<br>
same sub-band. Similar weighting is applied if the sub-band<br>
signal features high energy in the near past or future. An<br>
example is shown in Equation 16. The feature M(u,t) is<br>
computed from the maximum value of adjacent sub-band<br>
samples within the interval T-k<t with i></t>
determining the observation window size.<br>
M{a),T) = max([X((o,T - k) X(o,t + k) ] ) (16)<br>
Both, the instantaneous sub-band energy and the maximum of<br>
the sub-band energy measured in the near past or future are<br>
treated as separate features (i.e. different parameters for<br>
the combination as described in Equation 1 are used).<br>
In the following, some extensions to a low-complexity<br>
extraction of a front signal and an ambient signal from an<br>
audio signal for upmixing will be described.<br>
The extensions concern the feature extraction, the post-<br>
processing of the features and the method of the derivation<br>
of the spectral weights from the features.<br>
3.3.3. Extensions to the feature set<br>
In the following, optional extensions of the above<br>
described feature set will be described.<br>
The above description describes the usage of tonality<br>
features and energy features. The features are computed<br>
(for example) in the Short-term Fourier transform (STFT)<br>
domain and are functions of time index m and frequency<br>
index k. The representation in the time-frequency domain<br>
(as obtained e.g. by means of the STFT) of a signal x[n]- is<br>
written as X(m, k). In the case of processing stereo<br>
signals, the left channel signal is termed Xi[k.] and the<br>
right channel signal is X2[k]. The superscript "'" denotes<br>
complex conjugation.<br>
One or more of the following features may optionally be<br>
used:<br>
3.3.3.1 Features evaluating the inter-channel coherence<br>
or correlation<br>
Definition of coherence: Two signals are coherent if<br>
they are equal with possibly a different scaling and delay,<br>
i.e. their phase difference is constant.<br>
Definition of correlation: Two signals are correlated if<br>
they are equal with possibly a different scaling.<br>
Correlation between two signals of length N each is often<br>
measured by means of the normalized cross-correlation<br>
coefficient r<br>
where x denotes the mean value of x[k]. To track the<br>
changes of the signal characteristic over time, the sum<br>
operator is often replaced by a first order recursive<br>
filter in practice, e.g. the computation of z[k]<br>
4k] = X-- ^lj] ^^^ ^^ approximated by<br>
z [k] = Az[k - 1] + (1 - X)x[k] (21)<br>
with "forgetting factor" A. This computation is in the<br>
following termed "moving average estimation (MAE)", fmae(z)-<br>
Ambient signal components in the left and right channel of<br>
a stereo recording are in general weakly correlated. When<br>
recording a sound source in a reverberant room with a<br>
stereo microphone technique, both microphone signals are<br>
different because the paths from the sound source to the<br>
microphones are different (mainly because of the<br>
differences in the reflection patterns). In artificial<br>
recordings the decorrelation is introduced by means of<br>
artificial stereo reverberation. Consequently, an<br>
appropriate feature for ambience extraction measures the<br>
correlation or coherence between the left and right channel<br>
signals.<br>
The inter-channel short-time' coherence (ICSTC) function<br>
described in [AJ02] is a suitable feature. The ICSTC O is<br>
computed from the MAE of the cross-correlation $12 between<br>
the left _ and right channel signals and the MAE of the<br>
energies On of the left signal and O22 of the right signal.<br>
 (22)<br>
with<br>
 (23)<br>
In fact, the formula of the ICSTC described in [AJ02] is<br>
nearly identical to the normalized cross-correlation<br>
coefficient, where the only difference is that no centering<br>
of the data is applied (centering means removing the mean<br>
as shown in Equation 20:<br>
^centered ~ ^ ~ X )<br>
In [AJ02], an ambience index (that is a feature indication<br>
the degree of "ambience-likeness") is computed from the<br>
ICSTC by non-linear mapping, e.g. using the hyperbolic<br>
tangent.<br>
3.3.3.2 Inter-channel level difference<br>
Features based on the inter-channel level differences<br>
(ICLD) are used to determine the prominent position of a<br>
sound source within the stereo image (panorama). A source<br>
s[k] is amplitude-panned to a particular direction by<br>
applying a panning coefficient a to weight the magnitude of<br>
s[k] in xi[k] and X2[k] according to<br>
When computed for a time-frequency bin, the ICLD-based<br>
features deliver a cue to determine the position (and the<br>
panning coefficient a) of the sound source which dominates<br>
the particular time-frequency bin.<br>
One ICLD-based feature is the panning index ¥(m,k) as<br>
described in [AJ04].<br>
A computationally more efficient alternative to the panning<br>
index as described above is computed using<br>
The additional advantage of S(m, k) compared to ^(m,k) is<br>
that it is identical to the panning coefficient a, whereas<br>
'P(m, k) only approximates a. The formula in Equation 27 is<br>
inspired by the computation of the centroid (center of<br>
gravity) of a function f(x) of the discrete variable x s<br>
{-1, 1} and f(-l) = |Xi(m,k)| and f(l) = |X2(m,k)|.<br>
3.3.3.3 Spectral centroid<br>
The spectral centroid T of a magnitude spectrum or a range<br>
of a magnitude spectrum ISrI of length N is computed<br>
according to<br>
The spectral centroid is a low-level feature that<br>
correlates (when computed over the whole frequency range of<br>
a spectrum) to the perceived brightness of a sound. The<br>
spectral centroid is measured in Hz or dimensionless when<br>
normalized to the maximum of the frequency range.<br>
4 Feature grouping<br>
Feature grouping is motivated by the desire to reduce the<br>
computational load of the further processing of the<br>
features and/or to evaluate the progression of the features<br>
over time.<br>
The described features are computed for each block of data<br>
(from which the Discrete Fourier transform is computed) and<br>
for each frequency bin or set of adjacent frequency' bins.<br>
Feature values computed from adjacent blocks (which usually<br>
overlap) might be grouped together and represented by one<br>
or more of the following functions f(x), whereas the<br>
feature values computed over a group of adjacent frames (a<br>
"super-frame") are taken as arguments x:<br>
• variance or standard deviation<br>
• filtering (e.g. first or higher order differences,<br>
weighted mean value or other low-pass filtering)<br>
• Fourier transform coefficients<br>
The feature grouping may for example be performed by one of<br>
the combiners 930, 940.<br>
5 Computation of the spectral weights using supervised<br>
regression or classification<br>
In the following, we assume that an audio signal x[n] is<br>
additively composed of a direct signal component d[n] and<br>
an ambient signal component a[n]<br>
x[n] = d[n] + a[n] (29)<br>
The present application describes the computation of the<br>
spectral weights as a combination of the feature values<br>
with parameters, which may for example be heuristically<br>
determined parameters (confer, for example, section 3.2).<br>
Alternatively, the spectral weights may be determined from<br>
an estimate of the ratio of the magnitude of the ambient<br>
signal components to the magnitude of the direct signal<br>
components. We define the magnitude ratio of ambient signal<br>
to direct siq<br>
 (30)<br>
The ambient signal is computed using an estimate of the<br>
magnitude ratio of ambient signal to direct signal<br>
RAD{m,k). Spectral weights G(m,k) for the ambience<br>
extraction are computed using<br>
 (31)<br>
and the magnitude spectrogram of the ambient signal is<br>
derived by spectral weighting<br>
|A(m,k) I = G(m,k) |X(m,k) I (32)<br>
This approach is similar to the spectral weighting (or<br>
short-term spectral attenuation) for noise reduction of<br>
speech signals, whereas the spectral weights are computed<br>
from estimates of the time-varying SNR in sub-bands, see<br>
e.g. [Sch04].<br>
The main issue is the estimation of RAD(ni,k). Two possible<br>
approaches are described in the following: (1) supervised<br>
regression and (2) supervised classification.<br>
It should be noted that these approaches are able to<br>
process features computed from frequency bins and from sub-<br>
bands (i.e. groups of frequency bins) together.<br>
For example: The ambience index and the panning index are<br>
computed per frequency bin. The spectral centroid, spectral<br>
flatness and energy are computed for bark bands. Although<br>
these features are computed using different frequency<br>
resolution, there are process together using the same<br>
classifier / regression method.<br>
A neural net (multi-layer perceptron) is applied to the<br>
estimation of RAD(m, k). There are two options: to estimate<br>
RAD(m,k) for all frequency bins using one neural net or two<br>
use more neural net whereas each neural net estimates<br>
RAD(m,k) for one or more frequency bins.<br>
Each feature is fed into one input neuron. The training of<br>
the net is described in Section 6. Each output neuron is<br>
asigned to the RAD{m,k) of one frequency bin.<br>
5.2 Classification<br>
Similar to the regression approach, the estimation of<br>
RAD(m,k) using the classification approach is done by means<br>
of neural nets. The reference values for the training are<br>
quantized into intervals of arbitrary size, whereas each<br>
interval represents one class (e.g., one class could<br>
include all RAD(iTi,k) in the interval [0.2, 0.3)). With n<br>
being the number of intervals, the number of output neurons<br>
is n-times larger compared to the regression approach.<br>
6. Training<br>
The main issue for the training is the proper choice of<br>
reference values RAD(m,k). We propose two options (whereas<br>
the first option is the preferred one) :<br>
1. using reference values measured from signals where the<br>
direct signal and the ambient signal are separately<br>
available<br>
2. using correlation-based features computed from stereo<br>
signals as reference values fro the processing of mono<br>
signals<br>
6.1 Option 1<br>
This option requires audio signals with prominent direct<br>
signals components and negligible ambient signal (x[n] *i<br>
d[n]) components, e.g. signals recorded in a dry<br>
environment.<br>
For example, the audio signal 1810, 1860 may be considered<br>
as such signals with dominant direct components.<br>
An artificial reverberation signal a[n] is generated by<br>
means of a reverberation processor or by convolution with a<br>
room impulse response (RIR) , which might be sampled in a<br>
real room. Alternatively, other ambient signals can be<br>
used, e.g. recordings of applause, wind, rain, or other<br>
environmental noises.<br>
The reference values used for the training are then<br>
obtained from the STFT representation of d[n] and a[n]<br>
using Equation 30.<br>
In some embodiments, based on a knowledge of the direct<br>
signal component and of the ambient signal component the<br>
magnitude ratio can be determined according to equation 30.<br>
Subsequently, an expected gain value can be obtained on the<br>
basis of the magnitude ration, for example using equation<br>
31. This expected gain value can be used as the expected<br>
gain value information 1316, 1834.<br>
6.2 Option 2<br>
The features based on the correlation between the left and<br>
right channel of a stereo recording deliver powerful cues<br>
for the ambience extraction processing. However, when<br>
processing mono signals, these cues are not available. The<br>
presented approach is able to process mono signals.<br>
A valid option for choosing the reference values for<br>
training is to use stereo signals, from which the<br>
correlation- based features are computed and used as<br>
reference values (for example for obtaining expected gain<br>
values).<br>
The reference values may for example be described by the<br>
expected gain value information 1920, or the expected gain<br>
value information 1920 may be derived from the reference<br>
values.<br>
The stereo recordings may then be down-mixed to mono for<br>
the extraction of the other low-level features, or the low-<br>
level features may be computed from the left and right<br>
channel signals separately.<br>
Some embodiments applying the concept described in this<br>
section are shown in Figs. 19 and 20.<br>
An alternative solution is to compute the weights G(m,k)<br>
from the reference values RAodn, k) according to Equation 31<br>
and to use G(m,k) as reference values for the training. In<br>
this case, the classifier / regression method outputs the<br>
estimates for the spectral weights G(m,k).<br>
7. Post-processing of the ambient Signal<br>
The following section describes appropriate post-processing<br>
methods for the enhancement of the perceived quality of the<br>
ambient signal.<br>
In some embodiments, the post processing may be performed<br>
by the post processor 700.<br>
7.1 Nonlinear processing of sub-band signals<br>
The derived ambient signal (for example represented by<br>
weighted sub-band signals) does not contain ambience<br>
components only, but also direct signal components (i.e.<br>
the separation of ambience and direct signal components is<br>
not perfect). The ambient signal is post-processed in order<br>
to enhance its ambient-to-direct ratio, i.e. the ratio of<br>
the amount of ambient components to direct components. The<br>
applied post-processing is motivated by the observation,<br>
that ambient sounds are rather quiet compared to direct<br>
sounds. A simple method for attenuating loud sounds while<br>
preserving quiet sound is to apply a non-linear compression<br>
curve to the coefficients of the spectrogram (e.g. to the<br>
weighted sub-band signals).<br>
An example for an appropriate compression curve is given in<br>
Equation 17, where c is a threshold and the parameter p<br>
determines the degree of compression, with 0 
Another example for a nonlinear modification is y = x"^,<br>
with 0 
than large values. One example for this function is y =<br>
Vx , wherein x may for example represent values of the<br>
weighted sub-band signals and y may for example represent<br>
values of the post processed weighted sub-band signals.<br>
In some embodiments, the nonlinear processing of the sub-<br>
band signals described in this section may be performed by<br>
the nonlinear compressor 732.<br>
7.2 Introduction of a time delay<br>
A few milliseconds (e.g. 14 ms) delay is introduced into<br>
the ambient signal (for example compared to the front<br>
signal or direct signal) to improve the stability of the<br>
front image. This is a result of the precedence effect,<br>
which occurs if two identical sounds are presented such<br>
that the onset of one sound A is delayed relative to the<br>
onset of the other sound B and both are presented at<br>
different directions (with respect to the listener). As<br>
long as the delay is within an appropriate range, the sound<br>
is perceived as coming from the direction from where sound<br>
B is presented [LCYG99].<br>
By introducing the delay to the ambient signal, the direct<br>
sound sources are better localized in the front of the<br>
listener even if some direct signal components are<br>
contained in the ambient signal.<br>
In some embodiments, the introduction of a time delay<br>
described in this section may be performed by the delayer<br>
734.<br>
7.3 Signal adaptive equalization<br>
To minimize the timbral coloration of the surround sound<br>
signal, the ambient signal (for example represented in<br>
terms of weighted sub-band signals) is equalized to adapt<br>
its long-term power spectral density (PSD) to the input<br>
signal. This is carried out in a two-stage process.<br>
The PSD of both, the input signal x[k] and the ambience<br>
signal a[k] are estimated using the Welch method, yielding<br>
l"^(co) and ll^{(j)), respectively. The frequency bins of |A(a), t)|<br>
are weighted prior to the resynthesis using the factors<br>
The signal adaptive equalization is motivated by the<br>
observation that the extracted ambient signal tends to<br>
feature a smaller spectral tilt than the input signal, i.e.<br>
the ambient signal may sound brighter than the input<br>
signal. In many recordings, the ambient sounds are mainly<br>
produced by room reverberations. Since many rooms used for<br>
recordings have smaller reverberation time for higher<br>
frequencies than for lower frequencies, it is reasonable to<br>
equalize the ambient signal accordingly. However, informal<br>
listening tests have shown that the equalization to the<br>
long-term PSD of the input signal turns out to be a valid<br>
approach.<br>
In some embodiments, the signal adaptive equalization<br>
described in this section may be performed by the timbral<br>
coloration compensator 736.<br>
7.4 Transient Suppression<br>
The introduction of a time delay into the rear channel<br>
signals (see Section 7.2) evokes the perception of two<br>
separate sounds (similar to an echo) if transient signal<br>
components are present [WNR73] and the time delay exceeds a<br>
signal-dependent value (the echo threshold [LCYG99]) . This<br>
echo can be attenuated by suppressing the transient signal<br>
components in the surround sound signal or in the ambient<br>
signal. Additional stabilization of the front image is<br>
achieved by the transient suppression since the appearance<br>
of localizable point sources in the rear channels is<br>
significantly reduced.<br>
Considering that ideal enveloping ambient sounds are<br>
smoothly varying over time, a suitable transient<br>
suppression method reduces transient components without<br>
affecting the continuous character of the ambience signal.<br>
One method that fulfils this requirement has been proposed<br>
in [WUD07] and is described here.<br>
First, time instances where transients occur (for example<br>
in the ambient signal represented in terms of weighted sub-<br>
band signals) are detected. Subsequently, the magnitude<br>
spectrum belonging to a detected transient region is<br>
replaced by an extrapolation of the signal portion<br>
preceding the onset of the transient.<br>
Therefore all values |X{(i),Tt) I exceeding the running mean<br>
Vi(co) by more than a defined maximum deviation are replaced<br>
by a random variation of ij{o) within a defined variation<br>
interval. Here, subscript t indicates frames belonging to a<br>
transient region.<br>
To assure smooth transitions between modified and<br>
unmodified parts, the extrapolated values are cross-faded<br>
with the original values.<br>
Other transient suppression methods are described in<br>
[WUD07].<br>
In some embodiments, transient suppression described in<br>
this section can be performed by the transient reducer 738.<br>
7.5 Decorrelation<br>
The correlation between the two signals arriving at the<br>
left and right ear influences the perceived width of a<br>
sound source and the ambience impression. To improve the<br>
spaciousness of the impression, the inter-channel<br>
correlation between the front channel signals and/or<br>
between the rear channel signals (e.g. between two rear<br>
channel signals based on the extracted ambient signals) is<br>
decreased.<br>
Various methods for the decorrelation of two signals are<br>
appropriate and are described in the following.<br>
Comb filtering: Two decorrelated signals are obtained by<br>
processing two copies of a one-channel input signal by a<br>
pair of complementary comb filters [Sch57].<br>
Allpass filtering: Two decorrelated signals are obtained<br>
by processing two copies of a one-channel input signal by a<br>
pair of different allpass filters.<br>
Filtering with flat transfer functions: Two decorrelate<br>
signals are obtained by filtering two copies of a one-<br>
channel input signal with two different filters with a flat<br>
transfer function (i.e. impulse response has a white<br>
spectrum).<br>
The flat transfer function ensures that the timbral<br>
coloration of the output signals is small. Appropriate FIR<br>
filters can be constructed by using a white random numbers<br>
generator and applying a decaying gain factor to each<br>
filter coefficient.<br>
An example is shown in Equation 19, where hk, k 
filter coefficients, rk are outputs of a white random<br>
process, and a and b are constant parameters determining<br>
the envelope of hk such that b ^ aN<br>
hk = rk(b - ak) (19)<br>
Adaptive Spectral Fanoramization: Two decorrelated signals<br>
are obtained by processing two copies of a one-channel<br>
input signal by ASP [VZA06] (see Section 2.1.4). The<br>
application of ASP for the decorrelation of the rear<br>
channel signals and of the front channel signals is<br>
described in [UWI07].<br>
Delaying the sub-band signals: Two decorrelated signals<br>
are obtained by decomposing the two copies of a one-channel<br>
input signal into sub-bands (e.g. using a filter-bank of a<br>
STFT), introducing different time delays to the sub-band<br>
signals and re-synthesizing the time signals from the<br>
processed sub-band signals.<br>
In some embodiments, the decorrelation described in this<br>
section may be performed by the signal decorrelator 740.<br>
In the following, some aspects of embodiments according to<br>
the invention will be briefly summarized.<br>
Embodiments according to the invention create a new method<br>
for the extraction of a front signal and an ambient signal<br>
suited for blind upmixing of audio signals. The advantages<br>
of some embodiments of the method according to the<br>
invention are multi-faceted: Compared to a previous method<br>
for one-to-n upmixing, some methods according to the<br>
invention are of low computational complexity. Compared to<br>
previous methods for two-to-n upmixing, some methods<br>
according to the invention perform successfully even if<br>
both input channel signals are identical (mono) or nearly<br>
identical. Some methods according to the invention do not<br>
depend on the number of input channels and are therefore<br>
well-suited for any configuration of input channels. Some<br>
methods according to the invention are preferred by many<br>
listeners when listening to the resulting surround sound<br>
signal in listening tests.<br>
To summarize, some embodiments are related to a Low-<br>
complexity extraction of a front signal and an ambient<br>
signal from an audio signal for upmixing.<br>
8 Glossary<br>
ASP Adaptive Spectral Panoramization<br>
NMF Non-negative Matrix Factorization<br>
PCA 'Principal Component Analysis<br>
PSD Power spectral density<br>
STFT Short-term Fourier Transform<br>
TFD Time-frequency Distribution<br>
References<br>
[AJ02] Carlos Avendano and Jean-Marc Jot. Ambience<br>
extraction and synthesis from stereo signals for<br>
multi-channel audio upmix. In Proc. of the<br>
ICASSP, 2002.<br>
[AJ04] Carlos Avendano and Jean-Marc Jot. A frequency-<br>
domain approach to multi-channel upmix. J. Audio<br>
Eng. Soc., 52, 2004.<br>
[dCK03] Alain de Cheveigne and Hideki Kawahara. Yin, a<br>
fundamental frequency estimator for speech and<br>
music. Journal of the Acoustical Society of<br>
America, 111 (4):1917-1930, 2003.<br>
[DreOO] R. Dressier. Dolby Surround Pro Logic 2 Decoder:<br>
Principles of operation. Dolby Laboratories<br>
Information, 2000.<br>
[DTS] DTS. An overview of DTS NEo:6 multichannel,<br>
http://www.dts.com/media/uploads/pdfs/DTS%20Neo6%<br>
20Overview.pdf.<br>
[Fal05] C. Faller. Pseudostereophony revisited. In Proc.<br>
of the AES 118nd Convention, 2005.<br>
[GJ07a] M. Goodwin and Jean-Marc Jot. Multichannel<br>
surround format conversion and generalized upmix.<br>
In Proc. of the AES 30th Conference, 2007.<br>
[GJ07b] M. Goodwin and Jean-Marc Jot. Primary-ambient<br>
signal decomposition and vector-based<br>
localization for spatial audio coding and<br>
enhancement. In Proc. of the ICASSP, 2007.<br>
[HEG+99] J. Herre, E. Eberlein, B. Grill, K. Brandenburg,<br>
and H. Gerhauser. US-Patent 5,918,203, 1999.<br>
[lAOl] R. Irwan and R. M. Aarts. A method to convert<br>
stereo to multichannel sound. In Proc. of the AES<br>
19th Conference, 2001.<br>
[IS093] ISO/MPEG. ISO/IEC 11172-3 MPEG-1. International<br>
Standard, 1993.<br>
[Kar] Harman Kardon. Logic 7 explained. Technical<br>
report.<br>
[LCYG99] R. Y. Litovsky, H. S. Colburn, W. A. Yost, and S.<br>
J. Guzman. The precedence effect. JAES, 1999.<br>
[LD05] Y. Li and P.F. Driessen. An unsupervised adaptive<br>
filtering approach of 2-to-5 channel upmix. In<br>
Proc. of the AES 119th Convention, 2005.<br>
[LMTG7] M. Lagrange, L.G. Martins, and G. Tzanetakis.<br>
Semi-automatic mono to stereo upmixing using<br>
sound source formation. In Proc. of the AES 122th<br>
'Convention, 2007.<br>
[MPA+05] J. Monceaux, F. Pachet, F. Armadu, P. Roy, and A.<br>
Zils. Descriptor based spatialization. In Proc.<br>
of the AES 118th Convention, 2005.<br>
[Sch04] G. Schmidt. Single-channel noise suppression<br>
based on spectral weighting. Eurasip Newsletter,<br>
2004.<br>
[Sch57] M. Schroeder. An artificial stereophonic effect<br>
obtained from using a single signal. JAES, 1957.<br>
[Sou04] G. Soulodre. Ambience-based upmixing. In Workshop<br>
at the AES 117th Convention, 2004.<br>
[UWHH07] C. Uhle, A. Walther, 0. Hellmuth, and J. Herre.<br>
Ambience separation from mono recordings using<br>
Non-negative Matrix Factorization. In Proc. of<br>
the AES 30th Conference, 2007.<br>
[UWI07] C. Uhle, A. Walther, and M. Ivertowski. Blind<br>
one-to-n upmixing. In AudioMostly, 2007.<br>
[VZA06] V. Verfaille, U. Zolzer, and D. Arfib. Adaptive<br>
digital audio effects (A-DAFx): A new class of<br>
sound transformations. IEEE Transactions on<br>
Audio, Speech, and Language Processing, 2006.<br>
[WNR73] H. Wallach, E.B. Newman, and M.R. Rosenzweig. The<br>
precedence effect in sound localization. sJ. Audio<br>
Eng. Soc, 21:817-826, 1973.<br>
[WUD07] A. Walther, C. Uhle, and S. Disch. Using<br>
transient suppression in blind multi-channel<br>
upmix algorithms. In Proc. of the AES 122nd<br>
Convention, 2007.<br>
In the following, some embodiments according to the invention<br>
will be described.<br>
An embodiment according to the invention comprises an<br>
apparatus 100 for extracting an ambient signal 112 on the<br>
basis of a time-frequency-domain representation of an input<br>
audio signal 110, the time-frequency-domain representation<br>
representing the input audio signal 110 in terms of a<br>
plurality of sub-band signals 132 describing a plurality of<br>
frequency bands. The apparatus comprises a gain-value<br>
determinator 112 configured to determine a sequence 122 of<br>
time-varying ambient signal gain-values for a given frequency<br>
band of the time-frequency-domain representation of the input<br>
audio signal 110 in dependence on the input audio signal. The<br>
apparatus also comprises a weighter 130 configured to weight<br>
one of the sub-band signals 132 representing the , given<br>
frequency band of the time-frequency-domain representation<br>
with the time-varying ambient signal gain-values 122, to<br>
obtain a weighted sub-band signal 112. The gain value<br>
determinator 120 . is configured to obtain one or more<br>
quantitative feature values describing one or more features or<br>
characteristics of the input audio signal 110 and to provide<br>
the gain values 122as a function of the one or more<br>
quantitative feature values, such that the gain values are<br>
quantitatively dependent on the quantitative feature values,<br>
to allow for a fine-tuned extraction of the ambient components<br>
from the input audio signal. The, gain value determinator 120<br>
also is configured to provide the gain values such that<br>
ambience components are emphasized over non-ambience<br>
components in the weighted sub-band signal 112. Furthermore,<br>
the gain value determinator 120 is configured to obtain a<br>
plurality of different quantitative feature values describing<br>
a plurality of different features or characteristics of the<br>
input audio signal and to combine the different quantitative<br>
Description pages containing deleted claims for all countries except EP<br>
feature values to obtain the sequence 122 of time-varying gain<br>
values, such that the gain-values are quantitatively dependent<br>
on the quantitative feature values. The gain value<br>
determinator also is configured to weight the different<br>
quantitative feature values differently according to weighting<br>
coefficients. Moreover, the gain value determinator is<br>
configured to combine at least a tonality feature . value<br>
describing a tonality of the input audio signal and an energy<br>
feature value describing an energy within a sub-band of the<br>
input audio signal, to obtain the gain values.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain at least one quantitative<br>
feature value describing an ambience-likeliness of the sub-<br>
band signal representing the given frequency band.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to scale the different quantitative<br>
feature values in a non-linear way.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain at least one quantitative<br>
single-channel feature value describing a feature of a single<br>
audio signal channel, to provide the gain values using the<br>
single channel feature value.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to provide the gain values on the<br>
basis of a single audio channel.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain a multi-band feature<br>
value describing the input audio signal over a frequency range<br>
comprising a plurality of frequency bands.<br>
Description pages containing deleted claims for all countries except EP<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain a narrow- band feature<br>
value describing the input audio signal over a frequency range<br>
comprising a single frequency band.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain a broad-band feature<br>
value describing the input audio signal over a frequency range<br>
comprising an entirety of frequency bands of the time-<br>
frequency-domain representation.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to combine different feature values<br>
describing portions of the input audio signal having different<br>
bandwidths, to obtain the gain values.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to preprocess the time-frequency-<br>
domain representation of the input audio signal in a non-<br>
linear way, and to obtain a quantitative feature value on the<br>
basis of the preprocessed time-frequency-domain<br>
representation.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to post process the obtained<br>
feature values in a non-linear way, to limit a range of values<br>
of the feature values, to obtain post processed feature<br>
values.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain a quantitative feature<br>
value describing a tonality of the input audio signal, to<br>
determine the gain values.<br>
Description pages containing deleted claims for all countries except EP<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain one or more quantitative<br>
channel-relationship values describing a relationship between<br>
two or more channels of the input audio signal.<br>
In one embodiment of the apparatus 100, one of the one or more<br>
quantitative channel-relationship values describes a<br>
correlation or a coherence between two channels of the input<br>
audio signal.<br>
In one embodiment of the apparatus 100, one of the one or more<br>
quantitative channfel-relationship values describes an inter-<br>
channel short-time coherence.<br>
In one embodiment of the apparatus 100, one of the one or more<br>
quantitative channel-relationship values describes a position<br>
of a sound source on the basis of two or more channels of the<br>
input audio signal.<br>
In one embodiment of the apparatus 100, one of the one or more<br>
quantitative channel-relationship values describes an inter-<br>
channel level difference between two or more channels of the<br>
input audio signal.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain, as one of the one or<br>
more quantitative channel-relationship values, a panning<br>
index.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to determine a ratio between a<br>
spectral value difference and a spectral value sum for a given<br>
time-frequency bin, to obtain a panning index for the given<br>
time-frequency bin.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to obtain a spectral-centroid<br>
feature-value describing a spectral centroid of a spectrum of<br>
the input audio signal or of a portion of the spectrum of the<br>
input audio signal.<br>
In one embodiment of the apparatus 100, the gain value<br>
determinator is configured to provide a gain value, for<br>
weighting a given one of the sub-band signals, in dependence<br>
on a plurality of sub-band signals represented by the time-<br>
frequency-domain representation.<br>
In one embodiment of the apparatus 100, the weighter is<br>
configured weight a group of sub-band signals with a common<br>
sequence of time-varying gain-values.<br>
In one embodiment of the apparatus 100, the apparatus further<br>
comprises a signal post processor configured to post process<br>
the weighted sub-band signal or a signal based thereon, to<br>
enhance an ambient-to-direct radio and to obtain a post<br>
processed signal in which an ambient-to-direct ratio is<br>
enhanced. The signal post processor is configured to attenuate<br>
loud sounds in the weighted sub-band signal or in the signal<br>
based thereon while preserving quite sounds, to obtain the<br>
post processed signal, or the signal post processor is<br>
configured to apply a non-linear compression to the weighted<br>
sub-band signal or to the signal based thereon.<br>
In one embodiment of the apparatus 100, the apparatus further<br>
comprises a signal post processor configured to post process<br>
the weighted sub-band signal or a signal based thereon, to<br>
Description pages containing deleted claims for all countries except EP<br>
obtain a post- processed signal, wherein the signal post<br>
processor is configured to delay the weighted sub-band signal<br>
or the signal based thereon in a range between 2 milliseconds<br>
and 70 milliseconds, to obtain a delay between a front signal<br>
and an ambient signal based on the weighted sub-band signal.<br>
In one embodiment of the apparatus 100, the apparatus further<br>
comprises a signal post processor configured to post process<br>
the weighted sub-band signal or a signal based thereon, to<br>
obtain a post processed signal, wherein the post processor is<br>
configured to perform a frequency-dependent equalization with<br>
respect to an ambient signal representation based on the<br>
weighted sub-band signal, to counteract a timbral coloration<br>
of the ambient signal representation.<br>
In one embodiment of the apparatus 100, the post processor is<br>
configured to perform the frequency dependent equalization<br>
with respect to the ambient signal representation based on the<br>
weighted sub-band signal, to obtain, as the post processed<br>
ambient signal representation, an equalized ambient signal<br>
representation, wherein the post processor is configured to<br>
perform the frequency dependent equalization to adapt a long<br>
term power spectral density of the equalized ambient signal<br>
representation to the input audio signal.<br>
In one embodiment of the apparatus 100, the apparatus further<br>
comprises a signal post processor configured to post process<br>
the weighted sub-band signal or a signal based thereon, to<br>
obtain a post processed signal, wherein the signal post<br>
processor is configured to reduce transients in the weighted<br>
sub-band signal or in the signal based thereon.<br>
In one embodiment of the apparatus 100, the apparatus further<br>
comprises a signal post processor configured to post process<br>
Description pages containing deleted claims for all countries except E?<br>
the weighted sub-band signal or a signal based thereon, to<br>
obtain a post processed signal, wherein the post processor is<br>
configured to obtain, on the basis of the weighted sub-band<br>
signal or the signal based thereon, a left ambient signal and<br>
a right ambient signal, such that the left ambient signal and<br>
the right ambient signal are at least partially de-correlated.<br>
In one embodiment of the apparatus 100, the apparatus is<br>
configured to also provide a front signal on the basis of the<br>
input audio signal, wherein the weighter is configured to<br>
weight one of the sub-band signals representing the given<br>
frequency band of the time-frequency-domain representation<br>
with varying front-signal gain-values, to obtain a weighted<br>
front-signal sub-band signal, wherein the weighter is<br>
configured such that the time-varying front-signal gain-values<br>
decrease with increasing ambient-signal gain-values.<br>
In one embodiment of the apparatus 100, the weighter is<br>
configured to provide the time'-varying front-signal gain-<br>
values such that the front-signal gain-values are<br>
complementary to the ambient-signal gain-values.<br>
In one embodiment of the apparatus 100, the apparatus<br>
comprises a time-frequency-domain to time-domain converter<br>
configured to provide a time-domain representation of the<br>
ambient signal in dependence on the one or more weighted sub-<br>
band signals.<br>
In one embodiment of the apparatus 100, the apparatus is<br>
configured to extract the ambient signal on the basis of a<br>
mono input audio signal.<br>
An embodiment according to the invention comprises a multi-<br>
channel audio signal generator for providing a multi-channel<br>
Description pages containing deleted claims for all countries except EP<br>
audio signal comprising at least one ambient signal on the<br>
basis of one or more input audio signals. The multi-channel<br>
audio signal generator comprises an ambient signal extractor<br>
1010 configured to extract an ambient signal on the basis of a<br>
' time-frequency-domain representation of the input audio<br>
signal, the time-frequency-domain representation representing<br>
the input audio signal in terms of a plurality of sub-band<br>
signals describing a plurality of frequency bands. The ambient<br>
signal extractor comprises a gain-value determinator<br>
configured to determine a sequence of time-varying ambient<br>
signal gain-values for a given frequency band of the time-<br>
frequency-domain representation of the input audio signal in<br>
dependence on the input audio signal, and a weighter<br>
configured to weight one of the sub-band signals representing<br>
the given frequency band of the time-frequency-domain<br>
representation with the time-varying gain-values, to obtain a<br>
weighted sub-band signal. The gain value determinator is<br>
configured to obtain one or more quantitative feature values<br>
describing one or more features or characteristics of the<br>
input audio signal and to provide the gain values as a<br>
function of the one or more quantitative feature values, such<br>
that the gain values are quantitatively dependent on the<br>
quantitative feature values to allow for a fine-tuned<br>
extraction of the ambient components from the input audio<br>
signal. The gain value determinator also is configured to<br>
provide the gain values such that ambience components are<br>
emphasized over non-ambience components in the weighted sub-<br>
band signal. Furthermore, the gain value determinator 120 is<br>
configured to obtain a plurality of different quantitative<br>
feature values describing a plurality of different features or<br>
characteristics of the input audio signal and to combine the<br>
different quantitative feature values to obtain the sequence<br>
122 of time-varying gain values, such that the gain-values are<br>
• quantitatively dependent on the quantitative feature values.<br>
Description pages containing deleted claims for all countries except EP<br>
The gain value determinator also is configured to weight the<br>
different quantitative feature values differently according to<br>
weighting coefficients. Moreover, the gain value determinator<br>
is configured to combine at least a tonality feature value<br>
describing a tonality of the input audio signal and an energy<br>
feature value describing an energy within a sub-band of the<br>
input audio signal, to obtain the gain values. The multi-<br>
channel audio signal generator further comprises an ambient<br>
signal provider 1020 configured to provide the one or more<br>
ambient signals on .the basis of the weighted sub-band signal.<br>
In one embodiment of the multi-channel audio signal generator,<br>
the multi-channel audio signal generator is configured to<br>
provide the one or more ambient signals as one or more rear<br>
channel audio signals.<br>
In one embodiment of the multi-channel audio signal generator,<br>
the multi-channel audio signal generator is configured to<br>
provide one or more front channel audio signals on the basis<br>
of the one or more input audio signals.<br>
An embodiment according to the invention comprises an<br>
apparatus 1300 for obtaining, on the basis of a coefficient<br>
determination input audio signal, weighting coefficients for<br>
parameterizing a gain-value determinator for extracting an<br>
ambient signal from an input audio signal. The apparatus 1300<br>
comprises a weighting coefficient determinator 1300 configured<br>
to determine the weighting coefficients such that gain values<br>
obtained on the basis of a weighted combination, using the<br>
weighting coefficients, of a plurality of different<br>
quantitative feature-values 1322, 1324 describing a plurality<br>
of. different features or characteristics of the coefficient-<br>
determination input audio signal, the feature values<br>
comprising at least a tonality feature value describing a<br>
Description pages containing deleted claims for all countries except EP<br>
tonality of the input audio signal and an energy feature value<br>
describing an energy within a subband of the input audio<br>
signal, approximate expected gain values 1310 associated with<br>
the coefficient determination audio signal, wherein the<br>
expected gain values describe an intensity of ambience<br>
components or of non-ambience components in the coefficient<br>
determination input audio signal, or an information derived<br>
therefrom, for a plurality of time-frequency bins of the<br>
coefficient-determination input audio signal.<br>
In one embodiment of the apparatus 1300, the apparatus<br>
comprises a coefficient-determination-signal generator<br>
configured to provide the coefficient-deterraination-signal on<br>
the basis of a reference audio signal comprising only<br>
negligible ambient signal components. The coefficient-<br>
determination-signal generator is configured to combine the<br>
reference audio signal with ambient signal components, to<br>
obtain the coefficient determination signal, and to provide an<br>
information describing the ambient signal components or a<br>
relationship between the ambient signal components and direct<br>
signal components of the reference audio signal to the<br>
weighting- coefficient determinator, to describe the expected<br>
gain values.<br>
In one embodiment of the apparatus 1300, the coefficient-<br>
determination-signal generator comprises an artificial<br>
ambient-signal generator configured to provide the ambient<br>
signal components on the basis of the reference audio signal.<br>
In one embodiment of the apparatus 1300, the apparatus<br>
comprises a coefficient-determination-signal generator,<br>
wherein the coefficient-determination-signal generator is<br>
configured to provide the coefficient-determination-signal and<br>
an information describing the expected gain values on the<br>
Description pages containing deleted claims for all countries except EP<br>
basis of a multi-channel reference audio signal. The<br>
coefficient-determination-signal generator is configured to<br>
determine an information describing a relationship between two<br>
or more channels of the multi-channel reference audio signal<br>
to provide the information describing the expected gained<br>
values,<br>
In one embodiment of the apparatus 1300, the coefficient-<br>
determination-signal generator is configured to determine a<br>
correlation-based quantitative feature value describing a<br>
correlation between two or more of the channel signals of the<br>
multi-channel reference audio signal to provide the<br>
information describing the expected gained values.<br>
In one embodiment of the apparatus 1300, the coefficient-<br>
determination-signal generator is configured to provide one<br>
channel of the multi-channel reference audio signal as the<br>
coefficient- determination-signal.<br>
In one embodiment of the apparatus 1300, the coefficient<br>
determination signal generator is configured to combine two or<br>
more of the channels of the multi-channel reference audio<br>
signal to obtain the coefficient-determination-signal.<br>
In one embodiment of the apparatus 1300, the weighting<br>
coefficient determinator is configured to determine the<br>
weighting coefficients using a regression method, a<br>
classification method or a neural net, wherein the<br>
coefficient-determination-signal is used as a training signal,<br>
wherein the expected gain values serve as reference values and<br>
wherein the coefficients are determined.<br>
We claim:<br>
An apparatus (100) for extracting an ambient signal (112)<br>
on the basis of a time-frequency-domain representation of<br>
an input audio signal (110), the time-frequency-domain<br>
representation representing the input audio signal (110)<br>
in terms of a plurality of sub-band signals (132)<br>
describing a plurality of frequency bands, the apparatus<br>
comprising:<br>
a gain-value determinator (112) configured to determine a<br>
sequence (122) of time-varying ambient signal gain-values<br>
for a given frequency band of the time-frequency-domain<br>
representation of the input audio signal (110) in<br>
dependence on the input audio signal;<br>
a weighter (130) configured to weight one of the sub-band<br>
signals (132) representing the given frequency band of the<br>
time-frequency-domain representation with the time-varying<br>
ambient signal gain-values (122), to obtain a weighted<br>
sub-band signal (112);<br>
wherein the gain value determinator (120) is configured to<br>
obtain one or more quantitative feature values describing<br>
one or more features or characteristics of the input audio<br>
signal (110) and to provide the gain values (122)as a<br>
function of the one or more quantitative feature values,<br>
such that the gain values are quantitatively dependent on<br>
the quantitative feature values, to allow for a fine-tuned<br>
extraction of the ambient components from the input audio<br>
signal; and<br>
wherein the gain value determinator (120)is configured to<br>
provide the gain values such that ambience componen'ts are<br>
emphasized over non-ambience components in the weighted<br>
sub-band signal (112);<br>
wherein the gain value determinator (120) is configured<br>
to obtain a plurality of different quantitative feature<br>
values describing a plurality of different features or<br>
characteristics of the input audio signal and to combine<br>
the different quantitative feature values to obtain the<br>
sequence (122) of time-varying gain values, such that the<br>
gain-values are quantitatively dependent on the<br>
quantitative feature values;<br>
wherein the gain value determinator is configured to<br>
weight the different quantitative feature values<br>
differently according to weighting coefficients; and<br>
wherein the gain value determinator is configured to<br>
combine at least a tonality feature value describing a<br>
tonality of the input audio signal and an energy feature<br>
value describing an energy within a sub-band of the input<br>
audio signal, to obtain the gain values.<br>
The apparatus according to claim 1, wherein the gain value<br>
determinator is configured to determine the time-varying<br>
gain values on the basis of the time-frequency-domain<br>
representation of the input audio signal.<br>
The apparatus according to claim 1 or 2, wherein the gain<br>
value determinator is configured to combine the different<br>
feature values using the relationship<br><br>
to obtain the gain values,<br>
wherein co designates a sub-band index,<br>
wherein x designates a time index,<br>
wherein i designates a running variable,<br>
wherein K represents a number of feature-values to be<br>
combined,<br>
wherein mi(co,T) designates a i-th feature value for a sub-<br>
band having frequency index co and a time having time<br>
index x,<br>
wherein ai designates a linear weighting coefficient for<br>
the i-th feature value,<br>
wherein Pi designates an exponential weighting coefficient<br>
for the i-th feature value,<br>
wherein g ((B,x) designates a gain value for a sub-band<br>
having frequency index © and a time having time index x.<br>
The apparatus according to one of claims 1 to 3, wherein<br>
the gain value determinator comprises a weight adjuster<br>
configured to adjust weights of different features to be<br>
combined.<br>
The apparatus according to one of claims 1 to 4, wherein<br>
the gain value determinator is configured to combine at<br>
least the tonality feature value, the energy feature value<br>
and a spectral centroid feature value describing a<br>
spectral centroid of a spectrum of the input audio signal<br>
or of a portion of the spectrum of the input audio signal,<br>
to obtain the gain values.<br>
The apparatus according to one of claims 1 to 5, wherein<br>
the gain value determinator is configured to combine a<br>
plurality of feature values describing identical features<br>
or characteristics associated with different time-<br>
frequency-bins of the time-frequency domain<br>
representation, to obtain a combined feature value.<br>
The apparatus according to claim 6, wherein the gain value<br>
determinator is configured to obtain, as the quantitative<br>
feature value describing the tonality,<br>
a spectral flatness measure, or<br>
a spectral crest factor, or<br>
a ratio of at least two spectral values obtained using<br>
different non-linear processing of copies of a spectrum of<br>
the input audio signal, or<br>
a ratio of at least two spectral values obtained using<br>
different non-linear filtering of copies of a spectrum of<br>
the input signal, or<br>
a value indicating a presence of a spectral peak.<br>
a similarity value describing a similarity between the<br>
input audio signal and a time-shifted version of the input<br>
audio signal, or<br>
a prediction error value describing a difference between a<br>
predicted spectral coefficient of the time-frequency-<br>
domain representation and an actual spectral coefficient<br>
of the time-frequency-domain representation.<br>
The apparatus according to one of claims 1 to 9, wherein<br>
the gain value determinator is configured to obtain at<br>
least one quantitative feature value describing an energy<br>
within a sub-band of the input audio signal, to determine<br>
the gain values.<br>
The apparatus according to claim 8, wherein the gain value<br>
determinator is configured to determine the gain values<br>
such that the gain value for a given time-frequency bin of<br>
the time-frequency-domain description decreases with<br>
increasing energy in the given time-frequency bin, or with<br>
increasing energy in a time-frequency bin within an<br>
neighborhood of the given time-frequency bin.<br>
The apparatus according to claim 8 or 9, wherein the gain<br>
value determinator is configured to treat an energy in a<br>
given time-frequency bin and a maximum energy or average<br>
energy in a predetermined neighborhood of the given time-<br>
frequency bin as separate features.<br>
The apparatus according to claim 10, wherein the gain<br>
value determinator is configured to obtain a first<br>
quantitative feature value describing an energy of the<br>
given time-frequency bin and a second quantitative feature<br>
value describing a maximum energy or an average energy in<br><br>
a predetermined neighborhood of the given time-frequency<br>
bin, and to combine the first quantitative feature value<br>
and the second quantitative feature value to obtain the<br>
gain value.<br>
2. The apparatus according to one of claims 1 to 11, wherein<br>
the gain value determinator is configured to obtain one or<br>
more quantitative channel-relationship values describing a<br>
relationship between two or more channels of the input<br>
audio signal.<br>
3. The apparatus according to one of claims 1 to 12, wherein<br>
the apparatus is configured to also provide a front signal<br>
on the basis of the input audio signal,<br>
wherein the weighter is configured to weight one of the<br>
sub-band signals representing the given frequency band of<br>
the time-frequency-domain representation with varying<br>
front-signal gain-values, to obtain a weighted front-<br>
signal sub-band signal,<br>
wherein the weighter is configured such that the time-<br>
varying front-signal gain-values decrease with increasing<br>
ambient-signal gain-values.<br>
4. A multi-channel audio signal generator for providing a<br>
multi-channel audio signal comprising at least one ambient<br>
signal on the basis of one or more input audio signals,<br>
the apparatus comprising:<br>
an ambient signal extractor (1010) configured to extract<br>
an ambient signal on the basis of a time-frequency-domain<br>
representation of the input audio signal, the time-<br>
frequency-domain representation representing the input<br><br><br>
audio signal in terms of a plurality of sub-band signals<br>
describing a plurality of frequency bands,<br>
the ambient signal extractor comprising:<br>
a gain-value determinator configured to determine a<br>
sequence of time-varying ambient signal gain-values for a<br>
given frequency band of the time-frequency-domain<br>
representation of the input audio signal in dependence on<br>
the input audio signal, and<br>
a weighter configured to weight one of the sub-band<br>
signals representing the given frequency band of the time-<br>
frequency-domain representation with the time-varying<br>
gain-values, to obtain a weighted sub-band signal,<br>
wherein the gain value determinator is configured to<br>
obtain one or more quantitative feature values describing<br>
one or more features or characteristics of the input audio<br>
signal and to provide the gain values as a function of the<br>
one or more quantitative feature values, such that the<br>
gain values are quantitatively dependent on the<br>
quantitative feature values to allow for a fine-tuned<br>
extraction of the ambient components from the input audio<br>
signal, and<br>
wherein the gain value determinator is configured, to<br>
provide the gain values such that ambience components are<br>
emphasized over non-ambience components in the weighted<br>
sub-band signal;<br>
wherein the gain value determinator (120) is configured to<br>
obtain a plurality of different quantitative feature<br>
values describing a plurality of different features or<br><br>
characteristics of the input audio signal and to combine<br>
the different quantitative feature values to obtain the<br>
sequence (122) of time-varying gain values, such that the<br>
gain-values are quantitatively dependent on the<br>
quantitative feature values;<br>
wherein the gain value determinator is configured to<br>
weight the different quantitative feature values<br>
differently according to weighting coefficients; and<br>
wherein the gain value determinator is configured to<br>
combine at least a tonality feature value describing a<br>
tonality of the input audio signal and an energy feature<br>
value describing an energy within a sub-band of the input<br>
audio signal, to obtain the gain values; and<br>
an ambient signal provider (1020) configured to provide<br>
the one or more ambient signals on the basis of the<br>
weighted sub-band signal.<br>
5. An apparatus (1300) for obtaining, on the basis of a<br>
coefficient determination input audio signal, weighting<br>
coefficients for parameterizing a gain-value determinator<br>
for extracting an ambient signal from an input audio<br>
signal, the apparatus comprising:<br>
a weighting coefficient determinator (1300) configured to<br>
determine the weighting coefficients such that gain values<br>
obtained on the basis of a weighted combination, using the<br>
weighting coefficients, of a plurality of different<br>
quantitative feature-values (1322, 1324) describing a<br>
plurality of different features or characteristics of the<br>
coefficient-determination input audio signal, the feature<br>
values comprising at least a tonality feature value<br><br>
describing a tonality of the input audio signal and an<br>
energy feature value describing an energy within a subband<br>
of the input audio signal, approximate expected gain<br>
values (1310) associated with the coefficient<br>
determination audio signal, wherein the expected gain<br>
values describe an intensity of ambience components or of<br>
non-ambience components in the coefficient determination<br>
input audio signal, or an information derived therefrom,<br>
for a plurality of time-frequency bins of the coefficient-<br>
determination input audio signal.<br>
16. The apparatus according to claim 15, wherein the apparatus<br>
comprises a coefficient-determination-signal generator<br>
configured to provide the coefficient-determination-signal<br>
on the basis of a reference audio signal comprising only<br>
negligible ambient signal components,<br>
wherein the coefficient-determination-signal generator is<br>
configured to combine the reference audio signal with<br>
ambient signal components, to obtain the coefficient<br>
determination signal, and<br>
to provide an information describing the ambient signal<br>
components or a relationship between the ambient signal<br>
components and direct signal components of the reference<br>
audio signal to the weighting- coefficient determinator,<br>
to describe the expected gain values.<br>
17. The apparatus according to claim 15 or 16, wherein.the<br>
apparatus comprises a coefficient-determination-signal<br>
generator, wherein the coefficient-determination-signal<br>
generator is configured to provide the coefficient-<br>
determination-signal and an information describing the<br>
expected gain values on the basis of a multi-channel<br>
reference audio signal,<br>
wherein the coefficient-determination-signal generator is<br>
configured to determine an information describing a<br>
relationship between two or more channels of the multi-<br>
channel reference audio signal to provide the information<br>
describing the expected gained values.<br>
.8. A method (2100) for extracting an ambient signal on the<br>
basis of a time-frequency-domain representation of an<br>
input audio signal, the time-frequency-domain<br>
representation representing the input audio signal in<br>
terms of a plurality of sub-band signals describing a<br>
plurality of frequency bands, the method comprising:<br>
obtaining (2110) a plurality of different quantitative<br>
feature-values describing one or more features or<br>
characteristics of the input audio signal;<br>
determining (2120) a sequence of time-varying ambient-<br>
signal gain-values for a given frequency band of the time-<br>
frequency-domain representation of the input audio signal<br>
as a function of the one or more quantitative feature-<br>
values, such that the gain-values are quantitatively<br>
dependent on the quantitative feature-values;<br>
wherein determining the sequence of time-varying ambient-<br>
signal gain-values comprises combining the different<br>
quantitative feature values, wherein the different<br>
quantitative feature values are weighted differently<br>
according to weighting coefficients, and<br>
wherein at least a tonality feature value describing a<br>
tonality of the input audio signal and an energy feature<br>
value describing an energy within a sub-band of the input<br>
audio signal are combined, to obtain the gain values; and<br>
weighting (2130) a sub-band signal representing the given<br>
frequency band of the time-frequency-domain representation<br>
with the time-varying gain-values.<br>
A method (2200) for obtaining weighting coefficients for<br>
parameterizing a gain value determination for extracting<br>
an ambient signal from an input audio signal, the method<br>
comprising:<br>
obtaining (2210) a coefficient-determination-signal, such<br>
that an information about ambient components present in<br>
the coefficient-determination-signal or an information<br>
describing a relationship between an ambient-component and<br>
a non-ambient component is known; and<br>
determining (2220) the weighting coefficients such that<br>
gain-values obtained on the basis of a weighted<br>
combination, according to the weighting coefficients, of a<br>
plurality of different quantitative feature-values,<br>
describing a plurality of different features or<br>
characteristics of the coefficient- determination-signal,<br>
approximate expected gain-values associated with the<br>
coefficient-determination-signal,<br>
wherein the expected gain values describe an intensity of<br>
the ambient components or of non-ambience components' in<br>
the coefficient-determination-signal, or an information<br>
derived therefrom, for a plurality of time-frequency bins<br>
of the coefficient-determination signal, and<br><br>
wherein the feature values comprise at least a tonality<br>
feature value describing a tonality of the input audio<br>
signal and an energy feature-value describing an energy<br>
within a subband of the input audio signal.<br>
20. A computer program for performing a method according to<br>
claim 18 or 19, when the computer program runs, on a<br>
computer.<br><br><br>
An apparatus for extracting an ambient signal from an input<br>
audio signal comprises a gain-value determinator configured<br>
to determine a sequence of time-varying ambient signal gain<br>
values for a given frequency band of the time-frequency<br>
distribution of the input audio signal in dependence on the<br>
input audio signal. The apparatus comprises a weighter<br>
configured to weight one of the sub-band signals<br>
representing the given frequency band of the time-<br>
frequency-domain representation with the time-varying gain<br>
values, to obtain a weighted sub-band signal. The gain-<br>
value determinator is configured to obtain one or more<br>
quantitative feature-values describing one or more features<br>
of the input audio signal and to provide the gain-value as<br>
a function of the one or more quantitative feature values<br>
such that the gain values are quantitatively dependent on<br>
the quantitative values. The gain value determinator is<br>
configured to determine the gain values such that ambience<br>
components are emphasized over non-ambience components in<br>
the weighted sub-band signal.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=5Nd41xwPiH3KLOfkN1dc3g==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=5Nd41xwPiH3KLOfkN1dc3g==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="270769-motorcycle-including-a-protective-bar-portion-of-a-cantilevered-structure.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="270771-thermoset-dessicant-product-and-method-for-making-the-same.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>270770</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1115/KOLNP/2010</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>04/2016</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>22-Jan-2016</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>18-Jan-2016</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>26-Mar-2010</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>FRAUNHOFER-GESELLSCHAFT ZUR FÖRDERUNG DER ANGEWANDTEN FORSCHUNG E.V.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HANSASTRASSE 27C, 80686 MÜNCHEN, GERMANY</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JUERGEN HERRE</td>
											<td>HALLESTRASSE 24 91054 BUCKENHOF, GERMANY</td>
										</tr>
										<tr>
											<td>2</td>
											<td>FALKO RIDDERBUSCH</td>
											<td>ADAM-KRAFT-STRASSE 57 90419 NUERNBERG, GERMANY</td>
										</tr>
										<tr>
											<td>3</td>
											<td>ANDREAS WALTER</td>
											<td>BIRKENGRABEN 14A 96052 BAMBERG, GERMANY</td>
										</tr>
										<tr>
											<td>4</td>
											<td>OLIVER MOSER</td>
											<td>TENNENLOHERSTRASSE 32A 91058 ERLANGEN, GERMANY</td>
										</tr>
										<tr>
											<td>5</td>
											<td>CHRISTIAN UHLE</td>
											<td>STINZINGSTRASSE 29 91056 ERLANGEN, GERMANY</td>
										</tr>
										<tr>
											<td>6</td>
											<td>STEFAN GEYERSBERGER</td>
											<td>OTTO-ROTH-STRASSE 90 97076 WUERZBURG, GERMANY</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04S 5/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2008/002385</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2008-03-26</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/975,340</td>
									<td>2007-09-26</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/270770-apparatus-and-method-for-extracting-an-ambient-signal-in-an-apparatus-and-method-for-obtaining-weighting-coefficients-for-extracting-an-ambient-signal-and-computer-program by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:35:48 GMT -->
</html>
