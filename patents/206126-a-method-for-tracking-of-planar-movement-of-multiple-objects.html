<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/206126-a-method-for-tracking-of-planar-movement-of-multiple-objects by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 05:44:23 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 206126:A METHOD FOR TRACKING OF PLANAR MOVEMENT OF MULTIPLE OBJECTS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A METHOD FOR TRACKING OF PLANAR MOVEMENT OF MULTIPLE OBJECTS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>ABSTRACT A novel method is disclosed for tracking the motion of multiple objects using special marker geometries. The marker geometry is such that the segmented marker region can be automatically recognized with less computational effort than conventional pattern matching approaches and with greater robustness. The marker geometry allows determination of the orientation from a single marker thereby eliminating the need for using an additional marker merely for determining orientation. The method is made more reliable by use of a identification tag as part of the marker that positively identifies a marker from the rest of the markers and overcomes the difficulty encountered by many automatic tracking systems in re-establishing track after it is lost. r 8 ptc vm</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM - 2<br>
THE PATENTS ACT, 1970<br>
(39 OF 1970)<br>
COMPLETE SPECIFICATION (See section 10)<br>
TITLE OF THE INVENTION<br>
"A Method for Tracking of Planar Movement of Multiple Objects"<br>
(a) INDIAN INSTITUTE OF TECHNOLOGY Bombay (b) having administrative office at Powai, Mumbai 400076, State of Maharashtra, India and (c) an autonomous educational Institute, and established in India under the Institutes of Technology Act 1961<br>
The following specification particularly describes the nature of the invention and the manner in which it is to be performed<br><br>
ORIGINAL<br>
GRANTED<br>
8-12-2006<br><br>
FIELD OF THE INVENTION<br>
The present invention relates to novel method for tracking planar movement of multiple objects from sequence of digital images using markers.<br>
BACKGROUND OF INVENTION<br>
Tracking of objects from a sequence of images requires automatic identification of the objects of interest. The approaches used to accomplish this include recognition based on the radiation characteristics and reflective properties of the object itself or of a tag or marker attached to the object. Use of markers, when permissible, assist in tracking by facilitating automatic recognition of the objects. Marker based tracking systems are already in use for motion analysis for switchgears and other high speed mechanisms, crash testing of automobiles, human and animal gait studies, an aid to improving the performance of sportsmen and for assisting sports commentators.<br>
Description of Prior Art<br>
US Patent no. 5,008,804, entitled Robotic Television Camera Dolly system uses checkerboard markers painted or pasted on the floor to position and align a dolly to a specified marker. Camera Dollies are conceived of having sensors at the bottom to sense a transition from dark to light. The dolly is operated by first moving in open loop (dead reckoning motion) to bring the sensors on the target marker. The patent teaches method for centering the dolly on the marker and aligning it along the marker. No camera image is used and four sensors are used to locate the dolly with respect to the marker. The marker is fixed and the system will not work if the marker were moving on an object.<br>
U.S. Patent No. 5,617,335 entitled System for and Method of Recognizing and Tracking Target Mark uses a marker design with a flat white triangular shape fixed above a black circle. It teaches a histogram based approach to determine the three-dimensional coordinates of an object with respect to a tracking camera mounted on a robotic arm. The system suffers from the following shortcomings:<br>
•	The marker being a three dimensional object cannot be attached to objects which are moving very closed to other objects due to problem of interference and will be unsuitable for use on most planar mechanisms.<br>
•	The system does not process multiple markers and therefore does not track multiple bodies.<br>
•	The patent does not disclose how track can be re-established if it gets lost due to occlusion during a move. Occlusion occurs when one of the markers on an object is not seen fully in the imaging system due to another object coming between the marker and the imaging system.<br><br>
U.S. Patent No. 5,731,785 entitled System and Method for Locating Objects Including an Inhibiting Feature is aimed at tracking of objects by "an electronic code generating system or device carried by the object in a portable housing". The system treats these active markers or beacons as point sources of energy and is based on triangulation of each unique signal to locate and identify an object. The system suffers from the following drawbacks:<br>
•	Each marker or beacon needs a source of power and cannot be attached to objects on the scale of most mechanism in machines due to space limitations.<br>
•	The system is based on use of GPS and is not suitable for tracking small motions such as in machine parts. Also for this reason, the accuracy of motion detection is low.<br>
•	The system is not capable of determining the orientation of object but only the location.<br>
US Patent no. 6,079,862, entitled Automatic tracking lighting equipment uses a marker attached to an object to be tracked based on a video signal. It consists of a tracking apparatus consisting of means for picking up an image in a specified area, means for detecting a marker attached to an object to be tracked based on a first video signal from said image pickup means, etc. The patent teaches control of floodlights based on the location of the marker image in video camera. The aim is to automatically control the lighting system so that the object being tracked remains well lit. In a preferred embodiment, the system uses infrared source of radiation and an infrared sensitive camera to accomplish the task. The system suffers from the following shortcoming:<br>
•	The system only tracks one marker and is not suitable for multiple object<br>
tracking.<br>
U.S. Patent No. 6,567,116 entitled Multiple Object Tracking System issued to Aman et al (May 2003) teaches the use of two types of cameras - tracking type with special filter to only capture objects printed with special inks and filming type that does not use any special filter and captures visual image. Tracking camera uses narrow band radiation which is not in the spectrum of the visible light. Identification markers made using special ink are placed on moving objects which are seen in the tracking type of cameras. There are a multitude of such pairs of cameras and special radiation sources attached overhead of the region of interest. The system suffers from the following drawbacks:<br>
•	The patent does not teach the actual process for identifying a marker or the actual method for determining the position and orientation of various marker.<br>
•	The system requires special energy sources and filters to isolate the markers in the images of the tracking type cameras, which increases the cost of the system.<br>
One of the oldest commercially available motion measurement system called SELSPOT used a number of infrared LEDs mounted on a moving object such as<br><br>
a moving person. Multiple cameras are used to identify the trajectory points of each of the LEDs in the image. In this approach LEDs can be turned on in turn so that only one LED emits radiation at a time and the correspondence of points in the different cameras can be done easily. However, such systems suffer from the following drawbacks:<br>
•	The markers require power source for use and may need wires from the power source that may interfere with the motion.<br>
•	The markers cannot be used in most machine motion studies, where the parts are constrained to move in close vicinity due to limitation of space.<br>
•	If the LEDs are powered intermittently, then different points of interests are located at different instants of time, causing some uncertainty in the relative locations and orientations of different moving bodies.<br>
More recent commercial systems have been developed by VICON Motion Systems, USA and Vannier Photoelec, France. The Autotrack® ver.3 tracking software from Vennier Photoelec has been used for crash testing of automobiles. It most commonly uses checkerboard markers and other symmetric markers. Only the location of the markers (i.e., the center point of the markers) is utilized by this system. The system suffers from the following drawbacks:<br>
•	Orientation of the markers is not determined and a minimum of two markers are necessary to be able determine the orientation of an arbitrarily moving object.<br>
•	When the markers are occluded, the system may loose automatic track and a manual intervention is required.<br>
•	The system is also prone to losing track due to variation in light levels or noise in the image.<br>
Many applications require tracking systems for automatically estimating the motion of multiple moving objects that may enter and exit the scene or get partly or fully obscured in some part of the motion. Given that markers provide standard image patterns, there is a long felt need to utilize markers to achieve computationally efficient and robust tracking with estimation of orientation, positive object recognition but without the requirement of special energy sources and filters for radiation in non-visible frequency band.<br>
SUMMARY OF INVENTION<br>
The main object of the invention is to determine position and orientation of moving markers using special marker geometries, coupled with the use of tags to positively identify markers, in order to estimate the motion of objects undergoing planar motion.<br>
Another object of the invention is to eliminate the need to have additional markers merely to be able to compute the orientation of an object.<br><br>
Yet another object of the Invention is to enable a multitude of markers In a scene without mixing up of markers.<br>
Yet another object of the Invention is to provide a robust method to automatically establish track or re-establish It after the track Is lost.<br>
Thus in accordance with this invention, the method uses markers, which are pasted, painted or attached in some other manner, on one or more objects whose motion, in a plane or parallel planes, is to be estimated. An Image acquisition system placed with Image sensor axis near normal to the planes of motion captures the motion of the moving objects in a digital form and passes on the image information to a data processing system. An appropriate system processes the image data to separate the regions consisting of the markers from the rest of the scene by computing properties of the marker geometry, based on which the marker position and orientation are determihed IrL the Image frame of reference, which correspond to the position and orientation of the moving object, in question injhe world coordinate frame of reference.<br>
As described above, the totality of marker comprises a geometrical marker shape that has less than two axes of symmetry and an identification tag In a background. The marker shape has an interior of different colour, reflectivity or luminosity as compared to Its background, such that a thresh-holding of the Image will yield different binary value for the pixels In the marker and those In the background. The region of image consisting of the pixels of the marker geometry is called the marker region.<br>
Various properties can be computed for the marker region, including a number of moments which remain invariant for a given shape with respect to translation, rotation and scaling of the shape, called Invariant moments. In general, such moment values of any shape do not remain strictly constant in a digital Image due to the presence of discrete pixels of finite dimensions. According to this Invention, the marker geometry used Is such that the Invariant moments computed for the marker regions show little variation In their values for changes In orientation and scaling or have invariant moments well separated from similar Invariant moments of other regions present in the Image. Such properties of marker region allow computationally efficient methods to automatically recognize It in spite of variations In orientation and size of the markers.<br>
According to this Invention, the marker geometry used is such that once it Is detected. Its position and orientation can be determined from the location of all the pixels belonging to the marker region. For determining the orientation without any ambiguity, the marker geometry Is chosen to have less than two axes of symmetry. Having determined the position and orientation of the marker, this invention teaches to locate a region containing the Identification tag, which allows for positive identification of a marker.<br><br>
DETAILED DESCRIPTION<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
Fig 1 shows shapes, which are evaluated for desirable properties as markers. Fig 1(a) shows an asymmetric "L"-shaped marker geometry (1) with the two limbs of constant width and lengths in the proportion of two to one, with the longer limb truncated with a steep sloped line. Fig 1(b) shows an asymmetric "L"-shaped marker geometry (2) with the two limbs of constant widths and lengths in the proportion of two to one, with both the limbs truncated with a sloped line (2). Fig 1(c) shows an asymmetric "L"-shaped marker geometry with two pointing limbs of similar proportions and with outer edges being perpendicular to each other (3). Fig 1(d) shows an asymmetric "L"-shaped marker geometry with two pointing limbs of similar proportions and with one outer and one inner edge perpendicular to each other (4). Fig 1(e) shows an asymmetric.right angle triangular shaped marker geometry with perpendicular sides in the ratio of two to one (5). Fig 1(f) shows a symmetric triangular shaped marker geometry with a single axis of symmetry (6). Fig 1(g) shows a symmetric rectangular shaped marker geometry with two axes of symmetry (7). Fig. 1(h) shows a symmetric elliptical shaped marker geometry with a cross inside with two axes of symmetry (8). Fig 1(1) shows a symmetric elliptical shaped marker geometry with a triangular cut out with a single axis of symmetry (9). The major axis of the ellipse is the axis of symmetry in this geometry. Fig 1(j) shows an asymmetric elliptical shaped marker geometry with a quadrant removed (10).<br>
Fig 2 shows the variation in the first four invariant moments for the marker geometries shown in Fig 1 in the form of graphs. Curves labeled (11), (21), (25) and (29) correspond to the shape labeled as (4) in Fig 1. Curves labeled (12), (22), (26) and (30) correspond to the shape labeled as (3) in Fig 1. Curves labeled (13), (23) and (27) correspond to the shape labeled as (1) in Fig 1. Curve labeled (14), (24) and (28) correspond to the shape labeled as (2) in Fig 1. Curve labeled (15) corresponds to the shape labeled as (5) in Fig 1. Curve labeled (16) corresponds to the shape labeled as (6) in Fig 1. Curve labeled (17) corresponds to the shape labeled as (9) in Fig 1. Curve labeled (18) corresponds to the shape labeled as (8) in'Fig 1. Curve labeled (19) corresponds to the shape labeled as (10) in Fig 1. Curve labeled (20) corresponds to the shape labeled as (7) in Fig 1.<br>
Fig 3(a) shows one of the embodiments of the marker (1) with a numeric identification tag (33) and the bounding box for the marker (32). The coordinate frame of reference of the image frame is also shown (31). Fig 3(b) shows the outline of the marker geometry (35) and the bounding box for the identification tag (34) separately. Fig 3(c) shows three clearly identifiable points on the marker, namely the concave corner (36), the centroid (37) and the convex corner, further¬most from the centroid (38). Fig 3(d) shows the vector (39) joining the centroid (37) to the farthest point from the centroid (38). Fig 3(e) shows the numeric identification tag (40). Fig 3(f) shows the angle (41), representing the orientation<br><br>
of the marker, made in the counter-clockwise direction by the vector (39) with the positive X-axis of the image coordinate frame of reference (31) and the position of the point denoting the marker location (36) with respect to the image coordinate frame of reference (31).<br>
Fig 4 shows different embodiments of the marker geometries and of the identification tags. Fig 4(a) is the same marker geometry shown in Fig 1(a) (1) with numeric identification tag (33) and the bounding box (32) for the marker. Fig. 4(b) is the same marker geometry shown in Fig 1(b) (2) with the identification tags consisting of a number of diamonds (42). Fig 4(c) shows another embodiment of asymmetric marker geometry (44) with a bar-code identification tag (43). Fig 4(d) shows yet another embodiment of asymmetric marker geometry (46) with an alphabetical identification tag (45). Fig 4(e) is the same marker geometry shown in Fig 1(d) (4) with the alphabetic tag in a different orientation (47). Fig 4(f) shows yet another embodiment of asymmetric marker geometry (49) with an alphanumeric identification tag (48).<br>
Figure 5 illustrates an embodiment of the system we propose for multiple object tracking. The means for acquisition of the image is shown in (51). The motion of the mechanism shown above is in plane (52). The line of sight for this means is near normal to the plane of motion of the mechanism. Markers are firmly attached to multiple objects in this mechanism that are to be tracked. The frame (53) is fixed. The driving link for the mechanism is (54). Markers have been affixed on link (55) of the mechanism. Marker (56) is completely visible to the image acquisition means. Marker (57) on link (55) is occluded. The X and Y axes of a world coordinate frame of reference on an immovable link of mechanism (53) are indicated by (58).<br>
Figure 6 illustrates the mechanism shown in figure 5, when viewed near normally. The data processing system (59) takes the digital images of the mechanism as its input. The output (60) from the data processing system (59) is in the form of position in terms of the X and Y co-ordinates and orientation with respect to the X axis for different markers frame by frame.<br>
Figure 7 shows the main steps of the proposed method. The first step is initialization of relevant details related to the marker geometry (100). Then the intensity values of pixels from the first frame are read (101). The threshold is then estimated (102). Using this threshold, the image is segmented (103). Thereafter, identification of markers is done (104). This involves finding the location and orientation of the marker. If there are more frames to process (106), the intensity values of pixels in the next frame are read (107). The steps estimation of threshold (102), segmentation (103) and identification of (104) are then repeated for ail subsequent images.<br>
Figure 8 shows the initialization step (100) of figure 7 in more detail. Centralized Hu moments are used as a non-limiting example of property that is invariant<br><br>
under translatiorv,orieiitajtlQri-and scaling. First the marker geometry template is loaded to the data processing system f95). Then the loaded image is segmented (96). The Hu Moments are then calculated (97) for the segmented region and stored as the ideal Hu Moments.<br>
Figure 9 illustrates step (103) of figure 7 in more detail. The image is read into an array of integer values representing the intensity for each pixel (111). The threshold is obtained from step (102) of figure 7. At the end of one pass through the image frame, all the pixels of a region are assigned a common label distinct from the labels of other regions. Beginning with the topmost row (113), each row is scanned pixel by pixel from left to right. Each pixel is assigned an integer value called 'label'. The procedure for assigning labels is as follows: For the pixel under consideration a comparison is made between the pixel intensity and the threshold limit (114):<br>
1.	If the pixel intensity is outside the threshold limit of a marker pixel, it is labeled zero (119).<br>
2.	If the intensity is within the threshold limit of a marker pixel, the labels of its left and top neighbours (115) are examined and the label assignment is done based on the labels of these neighbours (116) as described below:<br>
i. If both neighbours have zero labels (124), a new region is created with a new label (125) and the pixel is labeled with this label (118).<br>
ii. If one of the neighbours has zero labels while the other has non-zero label, the current pixel is added to that region of pixels with the non¬zero label (117) and the pixel is assigned the same label (118).<br>
iii. If both have different non-zero labels, the two regions are merged into a single region and the current pixel is added to this region (127). The label for the new region is the label of the top neighbour of the current pixel (118).<br>
The steps (120) and (123) check if the last column and the last row are reached respectively. If there are more columns to process (122), the pixel in the next column is processed. If there are more rows to process (128), the first pixel (121) in the next row is processed. If there are no more rows to process, the method terminates. Whenever a pixel is added to a region, sums of the row and column numbers of all pixels in the region as well as a pixel count of the region is updated (126), wherein,<br>
1.	Row number of a pixel is the index of the row in which the pixel belongs, with the topmost row in the frame having the index zero.<br>
2.	Column number of a pixel is the index of the column in which the pixel belongs, with the leftmost column in the frame having the index zero.<br>
This enables calculation of the centroid of each region at the end of the scan without the need for another pass through the regions.<br>
Figure 10 illustrates step (104) of figure 7 in more detail. The processing begins with the first region (157) obtained from the segmentation step (103) of figure 7. If the number of pixels in the region is too less (154), the region is rejected (155).<br><br>
The centralized Hu moments of the region are calculated (145). These centralized Hu moment values are then compared to the centralized Hu moment values for the standard marker gegrnetry. If all centralized Hu moment values for a region are not within pre'-s|pecified tolerance limits of the centralized Hu moment values for the standard marker template (147), the region is rejected as amarker (155). Otherwise the orientation of the potential marker is computed (149). This involves finding the positions of clearly identifiable points of the marker geometry. The tag pattern on the region is identified (150). If the tag pattern is valid (150), the region is accepted as a marker. If the region being processed is the last region (153), the method terminates. Othenwise the next region is considered (156) and the above steps are repeated.<br>
Figure 11 illustrates step (102) of figure 7 in more detail, which is the process for estimation of the threshold intensity value for a given frame. An initial value of threshold is chosen for the frame (171). The segmentation process is carried out using this value as threshold (172). Identification of individual markers is then done based on the tag-patterns of the markers (173). A count of the markers identified is kept, corresponding to the intensity value used as threshold (174). The next intensity value (176) is then used as threshold, and the above steps are repeated for this threshold value. These steps are repeated for a set of intensity values (175). Next, those threshold values are identified for which maximum count of the markers is obtained. The median of this set of threshold values is used as an estimate for the threshold for the current frame (177).<br>
The invention is now illustrated with non-limiting example.<br>
Referring to the geometrical shapes shown in figure 1, we will use the first four Hu moments which are invariant with respect to rotation and scaling of the shape.  The  centralized   Hu   moments  (represented   by   Φ1.Φ2.Φ3,Φ4  are<br>
computed as follows:<br><br><br><br>
wherein, x and y are the row and column indices respectively for a pixel and n is the total number of pixels in the region.<br>
All the required summations i.e., Σx, Σx2 Σx3 Σxy, Σx2y, Σxy2 Σy, Σy2, Σy3 involving the row and column numbers are maintained during a pass through the pixels of segmented regions.<br>
For continuous geometric shape, the summations are replaced by integral operations and result in constant values when the shape in question is rotated or scaled. However, for an image segment the constancy is not obtained due to the fact that a pixel has finite size. Due to this fact, a segment boundary that is not aligned with pixels cannot be represented exactly in the digital image and the rotated images effectively have an altered shape and therefore the invariant moment actually deviates. This deviation for shapes given in Fig 1 is plotted for 36 different orientations in graphs shown in Fig 2.<br>
Referring to Fig 2, it can be seen that for most shapes the invariant higher invariant moments rapidly decrease. It is for this reason that invariant moments higher than four are not practically usable in most cases. It can be noted that marker geometries (3) and (4) have significantly higher invariant moment compared to other shapes considered. Therefore these shapes are easy to distinguish from other shapes even based on comparison of a single invariant moment and the reliability of recognition is improved by considering more invariant moments.<br>
It is also worth noting that invariant moments corresponding to marker geometries having curved boundaries (8), (9) and (10) and having more than one axis of symmetry (7) are comparatively smaller and are less easy to distinguish from common shapes that may be found in the scene and therefore are not suitable as markers.<br>
Referring to curves (13), (14), (23) and (24), it can be noticed that marker geometry (1) displays the least percentage deviation with change in orientation in<br><br><br>
the image compared to other marker geometries. This is a desired property that helps in the marker geometry being recognized reliably. This fact can be better seen from the table below.<br>
Table 1<br><br>
The steps to track multiple moving objects required in this method are now described.<br>
The image acquisition device is positioned with the optical axis near-normal to the plane of motion of objects as shown in figure (5). Marker geometry such as (1) is attached to the objects whose motion is to be measured. The markers are black in color while the background is white. Identification tags (33), (48), (43) and (42) located in the quadrant defined by the two limbs are of numeric, alpha¬numeric, barcode or symbolic type and are black in color. The high contrast between the marker and background and the identification tag and background causes a threshold operation based on the image intensities to result in pixels in the marker and tag regions to yield binary value of one and the background pixels value of zero.<br>
At least one marker is pasted on each moving object to be tracked which does not get occluded during the motion. More markers are pasted on links that get occluded during motion so that at least one marker remains visible in the image. A unique identification tag number is used on each marker. Markers attached to fixed bodies can serve as reference as these are not expected to move from frame to frame of the image sequence.<br>
The output of the image acquisition device is timed electrical signals, which are converted into a matrix of intensity values using image-acquisition hardware. The<br><br><br>
matrix of intensity values in each image is processed using data processing system. Each image in the sequence is associated with a time, with respect to a datum, at which the image is acquired. In determining the motion of the objects, the information of the position, orientation of the markers and the time instant of the frame are required. If necessary, the image can be preprocessed. In preprocessing, random noise can be reduced and the quality of the image enhanced to improve the fidelity of distinguishing the markers from the background.<br>
The task performed by the data processing system is shown in figure 6 and figure 7. The image frame input consists of pixels. A pixel is said to be 'connected' to another if they share a common side. A set of 'connected' pixels is said to form a 'region', wherein connected pixels are as defined above, if every pixel in this set is connected to at least one other pixel. Any two connected pixels are called 'neighbours'. The first task in the extraction of the markers is to divide the image into regions in the image-array composed of groups of interconnected pixels having similar intensity values. This step is known as segmentation and can be accomplished using standard method like Rosenfeld method. For each of the regions, invariant moment values are calculated, as already illustrated<br>
The values corresponding to each of the regions are compared with the pre¬determined values of the invariant moments for the marker geometry being used. If the deviations are within pre-defined limits, the region is treated as a potential marker. Else no further computations are performed in this region of the image. A first estimate of orientation is obtained from the location of two clearly identifiable points. A refined estimate of orientation is then obtained for each marker based on the slopes of clearly identifiable straight boundary lines of the marker region. The size of the marker region in terms of the size of the 'standard marker' is calculated based on the distances between the centroid of the marker region and the pixel farthest from the centroid. From the 'size' of the marker region and the geometry of the 'standard marker', the end points of the clearly identifiable straight boundary lines are located. Next least squares fit line is fit through those pixels that satisfy the following conditions:<br>
1.	They are 'close' to imaginary lines joining the end points. A pixel is said to be 'close' to a line if it lies within a two pixel-distance of that line.<br>
2.	They are 'boundary' pixels. A pixel is said to be a boundary pixel if not all of its top, bottom, left and right neighbors are members of the region with the same label.<br>
The slope of this line gives the orientation with respect to a reference line on the standard marker. Based on the geometric features of the marker being used, the computation of the four corners of the bounding box defining the identification tag can be accomplished. Knowing the tag bounding box and the orientation of the marker, the tag bounding box image can be rotated to straighten the characters and symbols of the identification tag.<br><br><br>
The identification tag is then extracted from the bounding box corresponding to the potential marker, analyzed and interpreted. If interpretation results in a valid tag ID then the potential marker is confirmed otherwise, it is rejected.<br>
The recognition of a segmented region as a marker is made reliable from the shape of the marker, as the invariant moments of the chosen shapes are distinctly different from other objects in the scene and are found to have less variation in the invariant moments with respect to change in orientation and scaling.<br>
Knowing the positions and orientations of a multitude of markers on a body of interest at different times, the motion of the body is inferred from well established principles of Kinematics. From the motion of different bodies in the image sequence, the relationship between motions of different bodies can be accurately inferred.<br>
Since each marker contains an identification tag, the method described here automatically establishes track as soon as a new marker enter the scene or if an occluded marker becomes visible again.<br><br><br>
We claim:<br>
1.	A method for tracking planar movement of multiple objects with reference to<br>
world coordinate frame of reference using markers from a sequence of digital<br>
images each having an image coordinate frame of reference wherein the<br>
sequence of digital images is obtained from an image acquisition system<br>
placed such that the line of sight of the image acquisition device is near<br>
normal to the planes of the motion of objects to be tracked and processing of<br>
the sequence of digital images is performed by data processing system in<br>
steps comprising:<br>
•	segmenting image into regions based on image pixel intensities<br>
•	identifying regions that belong to markers based on a property of marker geometry<br>
•	obtaining orientation of markers and identifying individual markers by analyzing the tag pattern located at a known position and orientation with respect to the marker geometry,<br>
wherein segmenting of images involves<br>
•	considering each pixel intensity and dividing the entire image into regions<br>
•	assigning a label to each pixel such that processed pixels belonging to the same region have a common label<br>
•	optionally tracking centroid of each region<br>
wherein identifying a marker region involves<br>
•	computing property that is invariant to translation, rotation and scaling, of each region and comparing it with the said properties of the marker geometry to obtain marker regions<br>
•	obtaining positions of identifiable points such as centroid and further most corner point from the centroid of the marker region<br>
•	obtaining the location and orientation of the marker with respect the image coordinate frame of reference and thereby obtaining the location and orientation of the object in the world coordinate frame of reference<br>
wherein a marker comprises a marker geometry and a unique tag pattern for identification in a contrasting background wherein the marker geometry has less than two axes of symmetry and facilitates reduction in variance of said property of marker geomety with respect to translation, rotation and scaling.<br>
2.	A method for tracking planar movement of multiple objects using markers<br>
from a sequence of digital images as claimed in claim 1 wherein<br>
segmenting of image is carried out in a data processing system using an<br>
intensity threshold value chosen as the median of the range of threshold<br>
values for which the maximum number of markers are identified.<br><br><br>
3.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein segmenting of image is carried out in a data processing system using a color threshold value chosen as the median of the range of color threshold values for which the maximum number of markers are identified.<br>
4.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein property for identifying marker region is a set of invariant moments such as Hu invariant moments.<br>
5.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein orientation of marker region is obtained using variant moments.<br>
6.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein a clearly identifiable point of the marker region is a corner point farthest from the centroid of the marker region.<br>
7.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein a clearly identifiable point of the marker region is a corner point nearest from the centroid of the marker region.<br>
8.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images of claim 1 wherein orientation of marker is obtained from the line passing through the centroid and a clearly identifiable point of the marker region.<br>
9.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images of claim 1 wherein orientation of marker is obtained from the line passing through two clearly identifiable points of the marker region.<br>
10.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein orientation of marker is obtained from the longest straight line of boundary of the marker.<br>
11.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein a measure of orientation of marker is based on first finding the boundary pixels of a straight line edge of the marker region and then boundary pixels are considered to obtain the best estimate of the slope of the said edge.<br><br><br>
12.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein centroid of a region is tracked during the segmentation process.<br>
13.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein the image acquired the by the image acquisition device is monochromatic.<br>
14.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein the image acquired the by the image acquisition device is in color.<br>
15.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein marker is located using its corner point closest to the centroid.<br>
16.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images of as claimed in claim 1 wherein marker is located using its corner point farthest from the centroid.<br>
17.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images of claim 1 wherein marker is located by the centroid of the region.<br>
18.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein the tag pattern for identifying a marker is numerals.<br>
19.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein the tag pattern for identifying a marker is a set of letters of the alphabet.<br>
20.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein the tag pattern for identifying a marker is a bar code.<br>
21.	A method for tracking planar movement of multiple objects using markers from a sequence of digital images as claimed in claim 1 wherein the tag pattern for identifying a marker is the size of an identification mark.<br><br><br>
22.   A method for tracking planar movement of multiple objects from a sequence of images wherein the marker as claimed in claim 1 wherein the tag pattern for identifying a marker is a combination of numerals, letters of the alphabet, barcode, identification mark.<br>
Dated this 14th Day of December 2004<br>
Agent on behalf of Applicant Dr. Prabuddha Ganguli<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1hYnN0cmFjdCgwOC0xMi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1278-mum-2003-abstract(08-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1hYnN0cmFjdC0oOC0xMi0yMDA0KS5kb2M=" target="_blank" style="word-wrap:break-word;">1278-mum-2003-abstract-(8-12-2004).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1jYW5jZWxsZWQgcGFnZXMoMDgtMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1278-mum-2003-cancelled pages(08-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1jbGFpbShncmFudGVkKS0oOC0xMi0yMDA2KS5kb2M=" target="_blank" style="word-wrap:break-word;">1278-mum-2003-claim(granted)-(8-12-2006).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1jbGFpbXMoZ3JhbnRlZCktKDA4LTEyLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1278-mum-2003-claims(granted)-(08-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1jb3JyZXNwb25kZW5jZSgxMi0xMi0yMDA2KS5wZGY=" target="_blank" style="word-wrap:break-word;">1278-mum-2003-correspondence(12-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1jb3JyZXNwb25kZW5jZShpcG8pLSgxOC0wNC0yMDA3KS5wZGY=" target="_blank" style="word-wrap:break-word;">1278-mum-2003-correspondence(ipo)-(18-04-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDEoMTItMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 1(12-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDEoMTgtMDEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 1(18-01-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDEzKDA4LTEyLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 13(08-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDE5KDE1LTEyLTIwMDQpLnBkZg==" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 19(15-12-2004).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDIoZ3JhbnRlZCktKDA4LTEyLTIwMDYpLnBkZg==" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 2(granted)-(08-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDIoZ3JhbnRlZCktKDgtMTItMjAwNikuZG9j" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 2(granted)-(8-12-2006).doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDMoMTYtMTItMjAwMykucGRm" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 3(16-12-2003).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDMoMTgtMDEtMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 3(18-01-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1mb3JtIDUoMDgtMTItMjAwNikucGRm" target="_blank" style="word-wrap:break-word;">1278-mum-2003-form 5(08-12-2006).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTI3OC1tdW0tMjAwMy1wb3dlciBvZiBhdHRvcm5leSgxNi0xMi0yMDAzKS5wZGY=" target="_blank" style="word-wrap:break-word;">1278-mum-2003-power of attorney(16-12-2003).pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="206125-a-method-for-preparing-electro-powder.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="206127-substituted-phenylcyclohexanecarboxamides.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>206126</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1278/MUM/2003</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>42/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>17-Oct-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>18-Apr-2007</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>16-Dec-2003</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INDIAN INSTITUTE OF TECHNOLOGY BOMBAY</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>INDIAN INSTITUTE OF TECHNOLOGY, BOMBAY, POWAI, MUMBAI 400 076</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>BHARTENDU SETH</td>
											<td>DEPARTMENT OF MECHANICAL ENGINEERING, INDIAN INDTITUTE OF TECHNOLOGY, BOMBAY, POWAI, MUMBAI 400 0-76,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>RAHUL RAJ</td>
											<td>C/O SRI RUP KAMAL, QR. NO. 6066, SECTOR 4/F, BOKARO STEEL CITY, JHARKAHAND-827004</td>
										</tr>
										<tr>
											<td>3</td>
											<td>AMRISH CHANDRAKANT ACHARYA</td>
											<td>002, &quot;ASHWINI&quot; -A WING, APNA GHAR SOCIETY, SWAMI SAAMARTH NAGAR, ANDHERI (WEST), MUMBAI-400 053</td>
										</tr>
										<tr>
											<td>4</td>
											<td>KOUSTUBH MOHAIR</td>
											<td>I-104, MAYFLOWER PARK, MALLAPUR, HYDERABAD 500076.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H 04 N 7/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td></td>
									<td></td>
								    <td>NA</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/206126-a-method-for-tracking-of-planar-movement-of-multiple-objects by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 05:44:24 GMT -->
</html>
