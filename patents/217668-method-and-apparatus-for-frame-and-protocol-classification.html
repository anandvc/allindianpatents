<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/217668-method-and-apparatus-for-frame-and-protocol-classification by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 11:59:54 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 217668:&quot;METHOD AND APPARATUS FOR FRAME AND PROTOCOL CLASSIFICATION&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;METHOD AND APPARATUS FOR FRAME AND PROTOCOL CLASSIFICATION&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A system and method of frame protocol classification and processing in a system for data processing (e.g., switching or routing data packets or frames). The present invention includes analyzing a portion of the frame according to predetermined tests, then storing key characteristics of the packet for use in subsequent processing of the frame. The key characteristics for the frame (or input information unit) include the type of layer 3 protocol used in the frame, the layer 2 encapsulation technique, the starting instruction address, flags indicating whether the frame uses a virtual local area network, and the identity of the data flow to which the frame belongs. Much of the analysis is preferably done using hardware so that it can be complet...</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>The invention relates to a method and apparatus for frame<br>
and protocol classification.<br>
Field of the Invention<br>
The present invention relates to communication network apparatus such as is used to link together information handling systems or computers of various types and capabilities and to components and methods for data processing in such an apparatus.  More particularly, the present invention relates to an improved system and method for managing data flow'in a processing, device coupled to a data transmission network, including a method and system for handling a plurality of input information units (otherwise known as "packets* or "frames') which may be simultaneously processed by a plurality of independent processors and which input information units can have one of a variety of different protocols.<br>
Background Art<br>
The present embodiment is related to the following documents, all of which are assigned to the assignee of the present invention.<br>
Patent application S.N. 09/384,691, filed August 27, 1999 by Brian Bass et al. , entitled 'Network Processor Processing Complex and Methods", sometimes referred to herein as the Network Processing Unit Patent or NPU<br>
Patent.<br>
U.S. Patent 5,724,348 entitled "Efficient Hardware/Software Interface for a Data Switch" issued March 3, 1998, which patent is sometimes referred to as the Interface Patent.<br>
Patent application S.N. 09/330,968 filed June 11, 1999 and entitled "High Speed Parallel/Serial Link for Data Communications", sometimes referred to as the Link Patent.<br>
Various patents and applications assigned to IBM for its multiprotocol switching services, sometimes referred to as "MSS", some of which include Cedric Alexander as cin inventor, and which are sometimes referred to as the MSS Patents.<br><br>
The description of the present embodiment which follows is based on a presupposition that the reader has a basic knowledge of network data communications and the routers and switches which are useful in such network communications.  la particular, this description presupposes familiarity with the International Standards Organization ("ISO") model of network architecture which divides network operation into layers.  A typical architecture based on the ISO model extends from a Layer 1 (which is sometimes referred to as "LI*) being the physical pathway or media through which signals are passed upward through Layers 2 (or "L2") , 3 (or "L3"), and so forth to Layer 7 (or "L7") which is the layer of application programming resident in a computer system linked to the network.  Throughout this document, references to such layers as LI, L2, L3 are intended to refer to the corresponding layer of the network architecture.  The present description also presupposes a fundamental understanding of the bit strings, known as packets or frames, used in network communication.<br>
Bandwidth considerations (or the amount of data which a system can handle in a unit of time) are becoming more and more important in today's view of network operations.  Network traffic has increased dramatically in recent years, driven largely by the explosive growth of the internet (a public network of loosely linked computers sometimes referred to as the worldwide web) and, to a lesser extent, the growth in popularity of private data transmission networks or intranets.  The internet and intranets involve the transmission of large amounts of information between remote locations to satisfy-an ever-growing need for remote access to information and emerging applications.  The internet has opened up to large numbers of users in -geographically disperse areas an exploding amount of remote information and enabled a variety of new applications, such as e-commerce, which has resulted in the increased and ever-increasing load on networks.  Other applications, such as e-mail, file transfer and database access further add load to the networks, some of which are already under strain due to high levels of network traffic.<br>
Traffic over networks is also becoming more and more diverse.  At one time, some networks were used primarily for a certain type of communications traffic, such as voice on a telephone network and digital data over a data transmission network.  Of course, in addition to the voice signals, a telephone network would also carry a limited amount of "data" (such as the calling number and the called number, for routing and billing purposes), but<br><br>
"the primary use for some networks had, at one point in time, been substantially homogenous packets.<br>
Presently, however, voice and data traffic are increasingly converging onto the same networks.  As the internet continues to expand and the technology improve in areas like reliability and security, it has presented an opportunity to transmit many different kinds of information, including mixtures of different types of information, such as voice and data, relatively simultaneously.<br>
Data is currently transmitted over the Internet (through the Internet Protocol or IP) at no charge, and voice traffic typically follows the path of lowest cost. Technologies such as voice over IP (VoIP) and voice over asynchronous transfer mode or ATM (VoATM) or voice over frame relay (VoFR) are cost-effective alternatives for transmission of voice traffic in today's environment.  As these services migrate, the industry will be addressing issues such as the changing cost structure and concerns over the trade off between cost of service and quality of service in the transmission of information between processors.<br>
Aspects of quality of service include the capacity or bandwidth, the response time (how long does it take to process a frame) and the flexibility of the processing (does it respond to different protocols and frame configurations, such as different encapsulation or frame header methods).<br>
Those using a resource will consider the quality of service as well as the cost of service, with the tradeoffs depending on the situation presented.<br>
Some prior art systems which route data packets require 'that the packets be of a single protocol or format, or one of a limited number of such protocols or formats which are permitted.  Such a system has advantages of increased speed and responsiveness because of the relative simplicity of the design when packets of only one type of protocol (or a limited number of protocols) are found in the system, since the system can be tailored for the permitted protocol(s) .  When the entire data transmission system was under the control of a single entity, it was easy for the controlling entity to enforce a single standard transmission protocol on users (either users followed the permitted protocol(s) or didn't use the network, because the network was programmed to accommodate only the specified protocol(s) and<br><br>
could not handle variations in the protocols, even seemingly minor variations).<br>
However, freimes from even a communications "standard" like Ethernet can be formatted using one of several protocols and can be encapsulated into a message using different encapsulation techniques. These different protocols and encapsulation techniques provide a varying amount of data, typically at the beginning of a frame and before other key information such as the beginning of the L3 message.  Thus, key information from an Ethernet frame can be located in different places within the frame, depending on the Ethernet L3 protocol or form of Ethernet and the encapsulation technique, if one is present.  A system which provides processing of the L3 message needs to find it first, and that can be a challenge in a multi-protocol system. So, for example, Ethernet DIX Version 2 differs from Ethernet 802.3, IPX over Ethernet differs from IPX over Ethernet 802.3 which itself has three different formats (Novell Proprietary, LLC and SNAP). Further, each version of IPX may or may not support a virtual LAN (or VLAN) using the so-called IEEE 802.Iq standard, which also has the effect of changing the format of the frame, and thus the location of the L3 message.<br>
In those prior systems in which frames in a multitude of protocols were supported, it was sometimes necessary to provide a significant amount of overhead (such as computer programming sometimes including more than one hundred lines of code with comparisons and branching instructions) to identify the protocol and to translate a frame from one protocol to another, or to remove unnecessary information (such as encapsulation information) from a frame.  Such multiple protocol processing was time consuming and, further, often took a variable amount of time to identify the protocol.  When such systems required a variable amount of time to identify the protocol and provide the necessary processing, the system would have to be configured to allow the longest time necessary (to handle the worst case), slowing down the processing of all frames to the worst case or creating the possibility that some frames would not be processed in the time allowed for categorization.<br>
Most processors start processing from a common beginning of an instruction set (the same place for all data) and set flags which the processor reads selectively when it needs to determine where to go and which instructions to execute.  Thus, the execution of many processors performs a number of tests to determine what kind of data it has and where to begin the<br><br>
substantive processing, tests which involve a number of cycles and could involve a lot of processing.<br>
Multi-processor systems for handling data are known in the prior art which utilize rigid first-in-first-out processing of data.  While this works fine when the processing occurs in a routine fashion, such a system becomes bound up and stops functioning when the processing of one input is delayed. The delay of the processing of one input has the effect of stopping the processing of others.<br>
Other prior art systems are known which keep track of input message units during processing.  These systems have the limitation and disadvantage that a significant amount of processing power must be devoted to keep track of where each information unit is in the system, and some do not accommodate additional input information units, such as from new data flows or from internally generated messages.<br>
Thus, the prior art systems for handling data packets had undesirable disadvantages and limitations which had an effect either on the versatility of the system or the speed with which it could operate, or both.  Other disadvantages and limitations of the prior art systems will be apparent to those skilled in the art in view of the following description of the present invention.<br>
Summary of the Invention<br>
The present embodiment of the invention overcomes the disadvantages and limitations of the prior art systems by providing a simple, yet effective, way of managing the data flow over a network of frames or packets which were created using one of a plurality of different permitted message protocols and which may or may not employ a virtual local area network (or VLAN) system. By analyzing each packet or frame in a quick and efficient manner, the type of frame and key characteristics of the frame can be determined and saved for future reference and processing regarding that frame, for example, in a network processor of the type described in the NPU Patent referenced above.<br>
It is an advantage of the present embodiment that it is quick and efficient in the handling of packets having different protocols and provides<br><br>
for faster and easiesr processing of the packets, allowing the entire system to operate at a high rate of frame processing.<br>
The present embodiment allows a router or switch to process successive packets or frames in varying formats without knowing in advance in what format the particular frame or packet was created.  This embodiment includes identifying the layer 2 (L2) encapsulation format of the message or packet and then applying stored rules to identify the L2 encapsulation, the L3 protocol and the presence of a virtual local area network (VLAN). As a result of such determination, the processor is ready to run at a starting instruction address; that is, the processor is preconditioned with the instruction's starting address which is based on the identification of the frame. The processor thus has a starting instruction address as well as a pointer to the beginning of the L3 header in the data portion of the frame as well as flags indicating the protocol, VLAN presence and the encapsulation format.<br>
The present embodiment has the advantage that it sets up and stores key information about a packet during the initial processing of the packet, then that stored information about the packet or frame can be used later in the processing to advantage, allowing quicker and more efficient processing of the packet in its later stages, for example, by network processing unit complexes described in the NPU Patent.<br>
The present embodiment has the advantage that it allows input packets or frames from a single data flow to be assigned to one of a plurality of independent processors for processing, then allows the output (processed) packets or frames to be reassembled into the same order in which the input packets or frames were received.<br>
The present embodiment has the advantage that multiple data flows can be processed without influencing each other, and one data flow will not block the other data flows.  That is, when the processing of one data flow is halted awaiting completion of the processing of one portion thereof, the processing of the other data flows can continue.<br>
The present embodiment also allows a flushing of the system or immediate dispatching of completed frames without regard to order, if<br><br>
desired, overriding the normal operation of handling each data flow in the order in which it was received.<br>
The present embodiment also has the advantage that it is efficient in its use of buffers and storage devices and that it operates quickly, so that the speed of the processing is not reduced by the overhead of managing the data flows.<br>
The present embodiment contemplates that it can be implemented on the same semiconductor substrate as an array of network processors and their associated storage components, allowing for fast data transmission between the components.<br>
The present embodiment can also be implemented in hardware, rather than software, and the required format tests can be completed in a uniform time regardless of the format and how many comparisons must be made before the format or encapsulation techniques is determined.  In the design shown, within two cycles of the clock, the classification of a frame can be completed, with the necessary indicators set to indicate what kind of a frame is present (e.g., what encapsulation technique and what layer 3 protocol were used) and whether a virtual LAN (or VLAN) is supported as well as key information about the frame. During the same two cycles, a frame can be routed by a dispatcher to an idle network processing unit (as described in the referenced NPU Patent) .  As a result of the processing of the frame to determine the protocol and encapsulation method, a starting address for the processor can be determined and passed to the processor so that the processor can begin its work on the frame, pre-loaded with the starting address (a pointer to the relevant instruction storage) and other relevant information for its processing. This pre-loading of the processor with a starting address for processing is sometimes referred to as preconditioning of the processor and enables processor efficiency -- it need not go through a number of test instructions and jump instructions based on the results of the test, but instead starts at the initial address for the particular format of message presented.<br>
The system of the present embodiment also has the advantage that the classification and preprocessing of a frame? can occur in parallel with the distribution of that frame to a network processing complex. This parallel<br><br>
processing allows for more efficient handling of frames and allows the system to operate faster.<br>
Through the use of the present embodiment, multiple processing units may be independent one of the other, yet process the same data flow without allowing portions to get into a different and undesirable order. The output of processed packets or frames for a given data flow will be in the same order as the system received input packets or frames from that data flow, unless overridden by a flush command.<br>
Finally, the present embodiment allows for the insertion of new data flows and the creation of packets or frames by the system without affecting the processing which maintains the order of the data flows received from the network.<br>
One enhancement to the present embodiment allows not only the preconditioning of the processor (storing the address of the first instruction) but also storing of additional addresses of instructions for later execution. In this way, the processor has the address of the first instruction and also the address for instructions at later branch (or fork) points, avoiding unnecessary testing (if condition, then go to instruction^ otherwise go to instruction#2) in the execution of the code. This allows the code to execute more efficiently.<br>
Thus the present invention provides an apparatus comprising a semiconductor substrate; N processing units fabricated on the substrate, where N &gt; 1: first internal data memory fabricated on said substrate, said data memory for storing information accessible to said N processing units; a dispatcher operatively coupled to the N processing units for receiving and transmitting to one of the N processing units an input information unit; a classifier coupled to the dispatcher, said classifier including a comparison unit for determining a data format for an input information unit and for generating and storing in the internal data memory output indicators for the input information unit output indicators indicating the data foimat of the input information unit and a starting address for the input information unit, indicators and the starting address which are available to the one of the N processing units during its processing the input information unit and used in the processing of the input information unit; and a completion unit carried on the semiconductor substrate and operatively connected to the N processing units for receiving the information unit processed by the one of the N processing units.<br>
Other objects and advantages of the present embodiment will be apparent to those skilled in the relevant art in view of the following description of the preferred embodiment, taken together with the accompanying drawings and the appended claims.<br>
Brief Description of the Drawings<br>
Having thus set forth some of the limitations and disadvantages of the prior art and some objects and advantages of the present invention, other objects and advantages will be apparent to those skilled in the relevant art in view of the following description of the drawings illustrating the present invention of an improved routing system and method in which:<br><br>
Fig.1 is a block diagram for an interface device including embedded processor complex which is described in the NPU patent and is useful in practicing the present invention;<br>
Fig. 2 is a block diagram of an embedded processor complex of type shown in Fig. 1, with a classifier hardware assist useful in the present invention;<br>
Figs. 3A-3T are diagrams illustrating the various Ethernet protocol formats used in the hardware classifier of the present invention;<br>
Fig. 4 is a flow chart of the classifier hardware assist of the present invention, showing the logic used by the classifier to process frame portions in the present invention;<br>
Fig. 5 is a functional diagram illustrating the classifier of the present invention;<br>
Fig. 6 is an alternate embodiment of the hardware classifier of the present invention with optional enhancements shown, allowing a series of addresses to be stored in a stack in addition to the address of the first instruction;<br>
Fig. 7 is a schematic illustration of the queues associated with each frame;<br>
Fig. 8 is a detailed view of the completion unit of the present invention, with two label stores for each of the N processors;<br>
Fig. 9 is a schematic illustration of the format of a label store for keeping track of the data flow being handled by each of the N processors;<br>
Fig. 10 is a flow chart illustrating the logic which is performed by the completion unit in receiving and processing an indication that a new frame has been dispatched to one of the processing units;<br>
Fig. 11 is a flow chart illustrating the logic process performed by the completion unit when processing a report that the processing of a frame has been completed; and<br><br>
Fig. 12 is another view of the completion unit of Fig. 8, containing data to illustrate the operation of the completion unit in its preferred embodiment.<br>
Detailed Description of the Preferred Embodiment<br>
In the following description of the preferred embodiment, the best implementations of practicing the invention presently known to the inventors will be described with some particularity.  However, this description is intended as a broad, general teaching of the concepts of the present invention in a specific embodiment but is not intended to be limiting the present invention to that as shown in this embodiment, especially since those skilled in the relevant art will recognize many variations and changes to the specific structure and operation shown and described with respect to these figures.<br>
Fig. 1 is a functional block diagram of a processing system suitable for attachment to a data transmission network for receiving, processing and re-transmit ting data to the network in the form of packets or information units (also sometimes referred to as frames, terms which, for the purpose of the present document, will be used interchangeably) .  As shown in Fig. 1, the system for data processing includes a plurality of subassemblies, which, as described in the NPU Patent, are advantageously integrated into a single substrate.  The integration of the entire assembly on a single substrate allows for closely packing the various components of the system, reducing the time needed for communication between components and therefore increasing the speed at which the system can operate.  The use of a single substrate for the multiple processors and supporting logic and memory can also reduce the incidence of failures due to interconnection and increase the resistance to noise or other stray signals which might corrupt the date transmission in the network.<br>
The sub-assemblies mounted on substrate 10 are arranged into an upside configuration and a downside configuration, with the "upside" configuration {sometimes also referred to as an "ingress") referring to those components relating to data inbound to the chip from a data transmission network (up to or into the chip) and "downside" (sometimes referred to as an "egress") referring to those components whose function is to transmit data from the chip toward the data transmission network in an outbound fashion (away from<br><br>
the  chip or down and into the network).  Data flows follow the respective arrangements of the upside and downside configurations; thus, there is a upside data flow and a downside data flow in the system of Fig. 1.     The upside or ingress configuration elements include an<br>
Enqueue-Dequeue-Scheduling UP (EDS-UP) logic 16, multiple multiplexed MAC's-UP  (PMM-UP) 14, Switch Data Mover-UP (SDM-UP) 18, System Interface (SIF) 20, Data Align Serial Link A (DASL-A) 22 and Data Align Serial Link B (DASL-B) 24.  Data links are more fully described in the Link Patent referenced above, and reference should be made to that document for a greater understanding of this portion of the system.  It should be understood that the preferred embodiment of the present invention uses the data links as more fully described in that patent, other systems can be used to advantage with the present invention, particularly those which support relatively high data flows and system requirements, since the present invention is not limited to those specific auxiliary devices such as the data links which are employed in the preferred embodiment.<br>
The components depicted on the downside (or egress) of the system include data links DASL-A 26 and DASL-B 28, system interface SIF 30, switch data mover SDM-DN 32, enqueue-dequeue-scheduler EDS-DN 34 and multiple multiplexed MAC'S for the egress PMM-DN 36. The substrate 10 also includes a plurality of internal static random access memory components (S-RAM's),a traffic management scheduler (TRAFFIC MGT SCHEDULER) 40 and an embedded processor complex 12 described in greater depth  in the NPU Patent referenced above. An interface device 38 is coupled by the respective DMU busses to PMM 14, 36. The interface device 38 could be any suitable apparatus for connecting to the LI circuitry, such as Ethernet physical (ENET PHY) devices or asynchronous transfer mode framing equipment (ATM FRAMER) , both of which are examples of devices which are well known and generally available for this purpose in the trade. The type and size of the interface device are determined, at least in part, by the network media to which the present chip and its system are attached.  A plurality of external dynamic random access memory devices (D-RAMS) and a S-RAM are available for use by the chip.<br>
While here particularly disclosed for networks in which the general data flow outside the relevant switching and routing devices is passed through electric conductors such as wires and cables installed in buildings, the present invention contemplates that the network switches and components thereof could be used in a wireless environment as well.  For example, the<br><br>
media access control (MAC) elements herein disclosed may be replaced with suitable radio frequency devices, such as those made from silicon germanium technology, which would result in the connection of the device disclosed directly to a wireless network. Where such technology is appropriately employed, the radio frequency elements can be integrated into the VLSI structures disclosed herein by a person of skill in the appropriate arts. Alternatively, radio frequency or other wireless response devices such as infrared (IR) response devices can be mounted on a blade with the other elements herein disclosed to achieve a switch apparatus which is useful with wireless network apparatus.<br>
The arrows show the general flow of data within the interface system shown in Fig. 1.  Frames of data or messages received from an Ethernet MAC 14 off the ENET PHY block 38 via the DMU bus are placed in internal data store buffers 16a by the EDS-UP device 16.   The frames may be identified as either normal frames or guided frames, which then relates to method and location of the subsequent processing in the plurality of processors.<br>
Fig. 2 is a block diagram of a processing system 100 which can employ the present invention to advantage.  In this Fig. 2, a plurality of processing units 110 are located between a dispatcher unit 112 and a completion unit 114.  Each incoming frame F (from a network, not shown, attached to the present data processing system) is received and stored into an UP data store 116 which is connected to the processing units 110 through an interface UP DS i/f 117 which has the capability to read and write data to the data store.  The frames are sequentially removed by the dispatcher 112 and assigned to one of the plurality of processing units 110, based on a determination by the dispatcher 112 that the processing unit is available to process the frame.  This indication could be that the one processing unit to which the frame F is assigned has sent a signal to the dispatcher 112 indicating that that particular processing unit was idle and available for work, although alternate methods of assigning work (such as a round-robin allocation or a least recently used algorithm) could also be employed to advantage in the present system. Greater detail on the structure and function of the processing units 110 in particular, and the processing system in general, can be found in the NPU Patent references above.<br>
Interposed between the dispatcher 112 and the plurality of processing units 110 is a hardware classifier assist 118 as will be described in greater detailed later in this document, particularly in connection with Figs. 4 and<br><br>
5.  Also associated with the plurality of processing units 110 is an instruction storage 122 (shown in Fig. 4) where a plurality of different instruction sets are stored for retrieval and execution by the individual processing units 110. As will be described later, the starting instruction in the instruction storage 122 is addressed in accordance with an address which is based on the type of message -- its protocol and encapsulation method --as determined by the hardware classifier assist 118.<br>
A completion unit 114 is operatively coupled between the plurality of processors 110 and the down enqueue system (labeled DM Enqueue - element 34 in Fig. 1) as well as an UP enqueue system (element 16 in Fig. 1).  The DN Enqueue system 34 is used to send processed frames out from the processing complex down to the network or other system to which the complex is attached and the UP enqueue system 16 is used to send processed frames to the switch fabric.  The dispatcher 112 can be designed to assign and store identification information related to each frame and to the processing unit assigned to process such frame.  Such identification information can then be used by the completion unit 114 to ensure that processed frames making up. a single data flow are forwarded in the order in which they were received. This aspect of the present invention will be discussed in more detail later in this specification.<br>
Fig. 3 (consisting of its various sub-illustrations, Figs. 3A-3T) depicts a plurality of message formats (components and variations on the Ethernet message format) which the present processing system is programmed to accept and process, although the repertoire of message or frame formats is something that can be varied by those skilled in the art to fit the environment of the system under consideration. The present system can also be redesigned to accept other message formats, including those message formats and variations which may be designated in the future. As such, the message formats of Fog. 3 are for the purpose of illustration of different formats of<br>
frames with different protocol and encapsulation types, and the present invention is a flexible system designed to accept various different protocol and encapsulation formats and to provide an assist to the processing of those frames by providing a pointer to the type of encapsulation and protocol and to provide a starting address in the instruction storage for the processor handling a given frame.<br><br>
Fig. 3A illustrates the generic or base Ethernet message format, which is sometimes called Ethernet Version 2.0/DIX. This is a message format where the message includes a destination address DA, a source address SA, a block indicating the type of message (Type), the message text or data, and a trailer for cyclical redundancy checking or CRC for message integrity verification. The destination address DA and the source address SA are both specified as 6 bytes (48 bits) and the block indicating Type is specified as 2 bytes, while the CRC trailer is specified as 4 bytes.  In general, the rest of the message -- the Data — can be of any length, up to 1500 bytes, although, as will be seen later, some types of Ethernet provide limits on this flexibility to achieve other advantages. The source address SA can indicate either that the message is an individual message, destined for a single network address on one node on the network or that it is a multicast or a broadcast message.  A multicast message is directed to a group of nodes on the network and a broadcast is directed to all stations. The block indicating Type is 16 bits which identifies the higher layer protocol which is used.  Each registered Ethernet protocol is given a unique type code , a value which is always greater than the maximum value in the length field of the Ethernet 802.3 length field, to allow the field to coexist.  The data field is typically from 46-1500 bytes in length, assuming that the upper layers will ensure that the minimum field length of 46 bytes is met prior to passing data to the MAC layer. Messages which are longer than the allowed length of a frame must be split into a plurality of messages which are shorter than the maximum allowed length of the data field.<br>
Fig. 3B illustrates a variation on the general Ethernet style which is referred to as the IEEE 802.3 Ethernet format. It is similar to the format of the generic Ethernet message format of Fig. 1, except that the type field is replaced by a length field LEN, which is 16 bits which indicates the length of the data field which follows, excluding any pad. This standard imposes a minimum size length of the packet as 64 bytes, so the data field Data must be at least 46 bytes.  If the actual data for the data field Data is less than 46 bytes, then the MAC layer must add place savers (padding characters) to the LLC data field t:o make the minimum size before sending the packet over the network. However, the length field is the length without the padding characters, which allows a receiving system to identify and disregard any padding characters which have been added.<br><br>
Fig. 3C illustrates a Tag Control Information Format for the Ethernet messages, particularly with reference to the IEEE standard 802.Iq. It consists of 3 bits of user priority, 1 bit of Canonical Format Indicator or CFI and 12 bits of VID or Virtual LAN (or VLAN) Identifier. A virtual LAN or local area network is an identification of a group of nodes which have been identified as a virtual local area network by defining the addresses as comprising a VLAN, allowing those nodes which are not physically associated to be logically associated and addressed as a group, rather than individually.<br>
Fig. 3D illustrates an Embedded RIP (or E-RIF) format which is used in some Ethernet protocol message formats, again following IEEE standard 802.Iq. In this format, a route type RT is indicated by the first 3 bits, a length LTH by the next 5 bits (indicating the length in bytes of the total E-RIF portion, including the E-RIF route control and E-RIF Route Descriptor), and a route descriptor direction D by one bit (normally a *0* indicating to traverse the route descriptor in forward order, but it is a "1" in some specially routed frames to indicate that the route descriptor is in reverse order). The E-RIF format includes a largest frame indicator of 6 bits and a Non Canonical Format Indicator (NCFI) of 1 bit.  The route type RT is either OOX, Olx, 10X or 11X to indicate that the frame is either a specially routed frame, a transparent frame, all route explorer frame or a spanning tree explorer frame, respectively.  The largest frame LF field is 1470 bytes or less, according to the IEEE 802.3 Standard for Ethernet.  The NCFI indicates either chat the MAC addresses specified are in the non-canonical form (if 0) or in canonical form (if 1).<br>
Fig. 3E illustrates the E-RIF Route Descriptor Format as including a local area network identification LAN ID of 12 bits and a bridge number (Bridget) of 4 bits. An E-RIF Route Descriptor Format field is also well known in the industry and this usage follows the standard for such fields.<br>
Fig. 3F and Fig. 3G illustrate components of LLC formats for use in an Ethernet message, including an 802.2 LPDU format in Fig. 3F and a Generic SNAP format in Fig. 3G. The LPDU format of Fig. 3F includes a Destination Service Access Point DSAP of 1 byte (8 bits), a Source service access point SSAP of 1 byte and a control field Control of 1-2 bytes  including command(s), response(s), sequence number(s) and poll/final bits.  In this context, a service access point is 6 bits plus a U bit and a final bit (an<br><br>
individual I bit for the destination service access point and a C bit for command/response indicator for the source). Fig. 3G illustrates the SNAP format, including three bytes indicating the organization (the Organizationally Unique Identifier, or OLJI) and two bytes indicating the type assigned to the format under Internet Standard 0002.  Examples of the type field are 0800 for IP, 8137 for IPX, 0806 for ARP, 8035 for RARP, 8100 for 802.Iq VLAN, 86DD for IPv6, 80DB for Appletalk and 80F3 for Appletalk AARP.<br>
Fig. 3H illustrates the format of a message in the IPX over Ethernet format including an Ethernet MAC header and an IPX header, with the Ethernet MAC header having a source address SA and a destination address DA of 6 bytes each, followed by a two byte type of 8137 indicating that this frame is of the IPX format. The IPX header then includes the components indicated, namely 2 bytes for a check sum, 2 bytes for the packet length, 1 byte for TC, 1 byte for PT, 4 bytes for the destination network, 6 bytes for the destination node, 2 bytes for the destination socket, 4 bytes for the source node, 6 bytes for the source node and 2 bytes for the source socket.<br>
Fig. 31 shows the message format for IPX over a proprietary version of Ethernet 802.3 (sometimes referred to as a Novell format) including an Ethernet 802.3 MAC header where the length of the message is specified in the third field (rather than a type in the IPX over Ethernet shown in Fig. 3H) . The check sum in this format is set to "FFFF" according to its protocol.<br>
Fig. 3J illustrates an IPX over Ethernet 802.3 with 802.2, where the message includes a MAC header with an IPX header (like those shown in Fig. 3H) separated by the LLC LPDU fields for the 802.2.<br>
Fig. 3K illustrates the format of an IPX frame over 802.3 with SNAP where, like the format described in connection with Fig. 3J, the message includes an 802.3 MAC header, followed by the LLC LPDU field and concluding with the IPX header.  Disposed between the LLC LPDU portion and the IPX header is the SNAP field for indicating the OUI and an Etype of 8137.<br>
Fig. 3L illustrates the format of an IPX over Ethernet with 802.Iq VLAN support, where the type field is indicated as 8100 and the VLAN packet is disposed between the Ethernet MAC header and the IPX header (the IPX header being in the same format as described in connection with Figs. 3H, 3J and 3K above).  The VLAN packet includes the TCI field of 2 bytes and a length LEN<br><br>
or e-type field of 2 bytes, then a e-rif control field  and a variable number of e-rif descriptor fields, the number of which being indicated by the formula {LEN-2)/2.<br>
Fig. 3M illustrates the format for an IPX over Ethernet 802.3 (proprietary) using 802.Iq VLAN support. The type field is 8100 and the VLAN Packet is similar to that in the previous VLAN example, Fig. 3L.  The IPX header is similar to that shown in the earlier 802.3 proprietary frame. Fig. 31, with the checksum field set equal to "FFFF*.<br>
Fig. 3N shows the frame arrangement for a. frame using the IPX over Ethernet 802.3 with VLAN support. It includes a 802.3 MAC Header with a type of 8100 indicating the presence of a VLAN packet (like Fig. 3M) , a VLAN Packet (also in a format like Fig. 3M) , an LLC LPDU (similar to that shown and described in connection with Fig. 3J) , and an IPX header (as shown in Fig. 3H).<br>
Fig. 30 shows the configuration or format of a message in the IPX over Ethernet 802.3 with SNAP and VLAN support using 802.Iq. It is similar to the format of Fig. 3N, with the addition of a SNAP field between the LLC LPDU field and the IPX Header.<br>
Fig. 3P shows the format of IPv4 over Ethernet where the message includes an Ethernet MAC header and an IPv4 header. The length of each of the fields is shown in this view.<br>
Fig. 3Q illustrates the message format for IPv4 over Ethernet 802.3 with 802.2, showing the MAC header followed by the LLC LPDU, then the IPv4 header.<br>
Fig. 3R illustrates the message format for an IPv4 frame over Ethernet 802.3 with SNAP where the 802.3 MAC header is followed by the LLC LPDU, then the IPv4 header (and with a optional trailer for UDP or TCP, if applicable) .<br>
Fig. 3S illustrates the message format for IPv4 over Ethernet with 802. Iq VLAN Support. This format has the features of the IPv4 as well as the VLAN Packet seen in other instances of the 802.Iq VLAN support.<br><br>
Fig. 3T illustrates the message format for IPv4 over Ethernet 802.3 (with 802.2) with 802.Iq VLAN Support, combining the attributes of IPv4 over 802.3 with 802.2 with the message characteristics of the VLAN Packet.<br>
In each of Fig. 3H through 3T, the bottom line represents the Layer 3 (or L3) portion of the frame or message, and, because of the variations in size of the material which precedes the L3 portion of the message, the L3 portion of the message begins at different places, depending on the type of message — the protocol and encapsulation method.  Although the processing of an L3 message is desired (ignoring the encapsulation), it may be difficult in a multi-protocol and multi-encapsulation system to find the beginning of the L3 message. Further, since the instructions carried out by the one of the plurality of processors 110 on the frame depend on the type of frame protocol and encapsulation method, it is desirable that something (in this case, the hardware classifier assist 118) provide a pointer to the correct starting instruction for the processor into the instruction memory 122.<br>
Fig. 4 illustrates a block diagram for the classifier hardware assist shown as element 118 in Fig. 2, along with selected portions of the instruction memory 122 and one of the plurality of processing units 110. The classifier hardware assist 118 operates on 128 bit segments associated with the input information unit (or frame), which 128-bits segments are sometimes called "FISH" and are received by the classifier hardware assist 118 (as well as one of the individual processing units 110) from the dispatcher 112.  This classification function operates on up to the first 3 FISH (or the first 384 bits associated with a frame, sometimes called FISH1, FISH2 and FISH3 to distinguish one FISH from another).  The first FISH (FISH1) is not actually the received frame, but a set of information related to that frame, such as what port the frame came in on, a default code entry point 291 and an indicator 292 (yes or no) whether to enable frame classification using the hardware classifier of the present invention.<br>
At the block 210, the type of Ethernet is compared at varying places in the frame to determine if the fields match a presently-configured protocol, for example, a first Ethernet version (e.g., IPx) or a second Ethernet version (e.g., IPv4).  At the block 220, it is determined whether the SAP (service access point) field matches a presently-configured protocol, again as specified in a register (e.g., a specific stored value, indicating a type of protocol). The system also determines whether a SNAP field representing a<br><br>
different type of encapsulation is present (a specific field such as "AAAA03" in block 240 and detects the presence of a virtual local area network (VLAN) usage in the message at block 250.  Block 260 is classification control, which, when enabled by the enable classification 292, is responsible for storing the parameters associated with the frame and providing an output indicative of the protocol type, a layer 3 pointer, and classification flags on lines 270, 272, 274.<br>
A control entry point for each message (the beginning of processing, the address of the first instruction in the instruction memory 122} can be determined in advance for each defined format and stored in a table 280. That is, for a ETYPE = 0 and no VLAN, then control entry point (the beginning address) is address 122a in the instruction memory, and for an ETYPE = 1 and without the VLAN, the control entry point is address 122b. Similarly, for ETYPE = 0 with a VLAN and ETYPE = 1 with VLAN, the respective control entry points (the place at which the processing of the actual message begins) are instruction 122c and 122d, respectively. Processing will begin at instruction 122f for frames with an ERIF field and at instruction 122f for default programs, where the protocol or encapsulation method is not found.<br>
In any event, a default control entry point is contained in FISH1 of the message and is read at block 290.  Block 295 then determines whether to use the default control entry point -- if hardware classification is enabled at line 295 and no different control entry point is determined from the block 280, then the default entry is used; otherwise the control entry point from the table 280 is used.<br>
The lines 270, 272 (with the classification flags and the L3 base address determined by the hardware classifier assist 118, respectively) from the hardware classifier 118 are fed to the individual processor 110 which is assigned to process the frame and are stored in general purpose registers llOa associated with the one processing unit which is processing the frame which is stored in data memory llOb.  The output line 276 from the device 295 provides the starting address for the instruction memory 122 for the particular type of frame, data which is stored in instruction control logic llOc. An ALU (arithmetic/logic unit) is a part of the processing unit 110. The processor 110  uses the instruction counter in the instruction control logic llOc to fetch an instruction from the instruction memory 122 .  In this way, based on the protocol and encapsulation method as determined by the<br><br>
hardware classifier assist 118, the processing unit 110 is preconditioned with the starting address of the instruction set which is appropriate for the frame being processed, and appropriate flags indicating the type of frame are set to allow the processor 110 to begin processing the frame using the correct instructions.<br>
Fig. 5 illustrates the logic that this used in determining the categorization of the message format. This begins at block 310 where FISH2 is selected, then at block 320 bytes 13-14 of the frame (the two bytes which would include the type information in a frame which includes the 6 byte destination address DA and the 6 byte source address SA followed by the type) are tested.  If these bytes match the content for either ETYPEO or ETYPE1, then the process identifies the protocol information by setting the appropriate flag at block 323 and concludes the process at block 325. Otherwise, if the type block is less than 0600H (hexadecimal) , then the frame is in the Ethernet 802.3 frame format and not the Ethernet V2. ODIX format) and the field is a length field rather than a type field and it is processed on the left side of the diagram of Fig. 5. If this type block is 8100, then the frame  is a frame which employs the 802. Iq VLAN support (see, for example, Figs. 3L, 3M, 3N, 30, 3S and 3T) and it is processed on the right side of the diagram of Fig. 5. If the type field if it is anything else, then control passes to block 325 where classification is considered complete without recording any protocol information, since this frame is apparently an unknown protocol.<br>
If at the block 320 it was determined that the bytes 13-14 were less than 0600H, then at block 322 bytes 15-17 are analyzed to determine whether they are known as a SAP field or an LLC or Logical Link Control field of the type (e.g, AAAA03 used in Fig. 3K) . If this field is recognized as one of the SAP fields, then the SAP field is set and protocol information is saved at block 323 before considering the classification complete at block 325. If this is a SNAP field, then control continues to block 324 where FISH3 is obtained and bytes 2-6 of it are analyzed for a recognized ETYPE. If the ETYPE is recognized, then the protocol information is saved at block 323 before exiting at block 325.<br>
If at block 320 it was determined that the bytes 13-14 were equal to 8100 indicating that this is a virtual local area network (VLAN) as specified in IEEE standard 802. Iq, then the existence of the VLAN is saved at block<br><br>
330, then at block 340, the presence of a CFI field is checked.  If it is present, then classification is complete and control passes to block 325. If not, then at block 350, bytes 1-2 of FISH3 are tested to determine whether they provide a known ETYPE (like the test at block 320) or a length (less than 0600H) . If  they provide an ETYPE, then the protocol information is saved at block 323 and control passes to block 325 where the classification is considered complete.  If the field in block 350 is not recognized as an ETYPE, then the classification process is considered complete at block 325. If the test at block 350 provided a length (less than 0600H), then at block 360, bytes 3-5 are tested for a known SAP.  If it is AAAA03, then control passes to block 370 for determination of the bytes 6-10 for a known ETYPE.<br>
Fig. 6 illustrates an improved version of the hardware classifier, particularly of the elements of Fig. 4. In this Fig. 6,  the hardware classifier includes the elements of Fig. 4 with an improvement to the instruction control logic HOc including, instead of a single beginning address, a series of addresses stored in an instruction stack llOd.  This instruction stack includes the initial instruction address, followed by other addresses needed when the processor reaches a fork or branch, to avoid further testing or conditional statements at later branches. The starting addresses then are stored in order in a stack and removed from the stack when a branch instruction is needed.<br>
For further information about the definitional content of Ethernet messages of various protocols or encapsulation techniques, the reader is directed to the appropriate standard or reference guide for Ethernet frame construction.  Some generally available documents which may be useful in the understanding of Ethernet protocols and encapsulation techniques and the standards and options related thereto are: ISO/IEC Final CD 15802-3, IEEE P802.1D/D15, November 24, 1997, Annex C; IEEE Draft Standard 802.1Q/D9 dated February 20, 1998; RFC 1700 - Assigned Numbers by J. Reynolds and J. Postel, October, 1994 (a document which is also available at<br>
http://www/isi.edu/rf c-editor/rfc .html) ; IBM Token Ring Network Architecture Reference; and IBM LAN Bridge and Switch Summary. Publication Number SG24-5000-00, Version 1.3, January, 1996, particularly Chapter 1.1.1.<br>
The hardware classifier may be designed in various ways including through the use of one of a variety of generally available software tools for designing and manufacturing logic designs in a hardware (or in the actual<br><br>
implementation on the silicon substrate) configuration, as well as being designed by traditional design by hand by a logic designer. In this example, the desired tests are programmed using a software language known as VLSI hardware definition language, or shortened to (VHDL), and then put through a known piece of software (such as one marketed by IBM or one marketed by-Synopsis) to create a design with the necessary gates and logic to accomplish the desired tests in a hardware fashion. Other similar design systems exist and can be used to advantage, so that the designer of the logic need not know the structure of the gates or their location, only their logical function of desired inputs and tests and outputs.<br>
As mentioned above, it may be desirable in some systems to include in the processing system of the present invention the capability to forward processed frames of a data flow in the order in which they were received, independent which processors are assigned to process each frame.  In such a system, the dispatcher 112, after identifying an available processing unit and assigning a received frame to the processing unit for processing, will create and store identifying information for the frame and the processing unit to which it was assigned.<br>
Frames typically arrive with identifying information such as a message number (sometimes referred to as a MAC) and the address of the source (sometimes designated as SA) and destination (sometimes designated as DA) of the frame.  The location and content of such information may vary depending on the format of the message and its encapsulation technique, but this information allows the frame to be properly routed to the destination through the system and the switches and routers arid to be assembled into a complete message in the proper order, even if the entire message is longer than a single frame. Typically, the components of a message are referred to as a data flow and each portion of the data flow would include the same identifying information (such as a MAC, SA and DA) .  The actual label (or identifying information) assigned to an input frame by the dispatcher 112 unit may be created in a variety of ways, such as the MAC-SA+DA, or by logically XOR-ing the LID with the MID fields in other message formats.<br>
As shown in Fig. 7, storage in three lists or queues may be created for each frame. First, a queue 400 of processed frames is defined to hold completed work (an output or processed frame, received from the processor which processed a given frame), requiring a buffer or memory space for at<br><br>
least one completed frame for each processor, shown as frame-0 to frame-N where processors identified as NPU-0 through NPU-N are coupled to the respective frame. When the dispatcher 112 sends a frame to a processing unit, it sends the identifier for that frame to a second memory or queue 410 which includes storage locations 0 through n, corresponding to the respective network processing units NPU-0 through NPU-N. When a frame with the identifier or label m is sent to NPU-0, then the memory 0 corresponding to the label for the NPU-0 is sent the identified m for storage, indicating that NPU-0 is processing an input information unit whose identifier is m.  It will be recalled that a later frame which has the same identifier m will belong to the same data flow and a frame which has a different identifier or label will represent a different data flow. Thus, if an input information unit having the label of 0 is received and dispatched to NPU-1, then a 0 is recorded in the storage 1 corresponding to NPU-1. Then, if later a second input information unit from the same data flow (also with a label of 0) is received by the dispatcher 112 and assigned to processor NPU-N, the memory N also has stored the label of 0 representing that information unit being assigned to processor N.<br>
The third memory 420 includes storage for each of the labels currently being processed by the n processing units. For each of the labels, the identifier of the processor assigned is stored, and, since the listing occurs sequentially, the first processor assigned to a particular message flow appears first in the memory.  In this case, for label m, an entry 0 in memory 422 indicates that NPU-0 is processing an input information unit from that flow and for the label 0, a first unit is being processed by processor NPU-N as shown by memory 424 and a second unit is being processed by processor NPU-1 as shown by memory 426. For a given flow,  the order in which the input information units arrived at the dispatcher is to be maintained so that the subsequent transmission of the same data flow can occur in the same order in which it was received, so it will be seen that the label memory 424,426 have the NPUs or processing units listed in the order in which the input frames were received from the network and dispatched to the N processors.<br>
Fig. 8 illustrates a more detailed structure of the completion unit 114 used in processing input frames and employing the data management techniques described. The completion unit 114 as shown in this embodiment communicates with a plurality of round robin devices for distributing the output (e.g., processed information units) of the processing units, not shown in this Fig.<br><br>
4. The plurality of round robin devices include an up-round robin 450 and two down round robin devices, one round robin identified as 460 for target ports (a small number of frequently used ports addressed specifically) and one round robin 470 for general distribution (processed information addressed to other ports than the specifically addressed target ports).<br>
Logical AND gates 452, 462, 472 provide the gating for the round robins 450, 460, 470, respectively. For the AND gate 452 which provides a frame to the UP round robin 450, the inputs are that it be an UP frame (from the block UP associated with the Ready FCB page 510), that the frame be a valid frame (the indicator VF that it is a valid frame, ready for transmission), that the label field be valid in the associated frame label field (M01 through M92) and that the label be associated with a head (or earliest) frame of a data flow.<br>
The dispatcher 112 provides two pieces of information to the label enqueue 480 when a frame is dispatched to a given processor — a label for the frame on line 482 and the identity of the processor to which the frame has been assigned on line 484.  The label for the frame identifies the data flow to which  the frame belongs, which, in the preferred embodiment, is based on the MAC plus the source address less the destination address, with the objective of providing a unique identifier for each data flow so that frames from the same data flow will have the same label and frames from different data flows will have different labels or identifiers.<br>
Fig. 9 illustrates a format for the label field element 500 storing information associated with each of the N processors. Each of the N processors has two such label fields associated with it, one for the frame being processed and one for a frame which has been processed and is awaiting transfer out from the processing complex.  The processed frame ready to be transferred is held in a memory or storage 510 which is sometimes referred top as a Ready FCB Page and one of these storage exists for each of the N processors.<br>
The label field element 500 includes a label L, a head field H, a valid field V, a tail field T and a next field N.  The label L is derived from the message content and represents a unique identifier for each of the data flows. The head field H identifies the beginning of a data flow or a chain of related frames currently being handled by the N processing units, either as<br><br>
work being processed or processed frames awaiting transfer out of the processing complex. Each data flow being processed in the processing complex of N processors has a head or beginning (or first-received frame for that data flow) somewhere in the N processors, and that beginning is identified as its "head" with a 1 in the head field H for its associated label field element.  Similarly, each data flow in the processors also has a last frame currently in the N processors, and that last frame is identified as the tail by a 1 in the tail field T.<br>
The valid field V indicates whether the processor contains real data (as it would from processing) indicated by a 1 in the valid field or if it does not, which is indicated by a 0 in the valid field V. When the processing first begins, no real or valid data exists in the system, so the valid field V is set to 0 as part of the initialization of the system.  Later, as data is read out of the Ready FCB page 510. for a given processor , then the valid field V corresponding to that processors FCB Page is set to 0, indicating that the processor no longer has valid information corresponding to that label (since the information in the FCB page has already been passed along to the round robins; although the processor may still have valid information in the other label field associated with that processor because the processor itself may be working on a different frame) . The next field N indicates the label field associated with the next frame in the same data flow -- an other one of the 2N label fields associated with the N processors. A label enqueue 480 receives a message from the dispatcher for each input information unit or frame that a given frame has been dispatched with its identifier for the data flow and the processor to which the frame has been dispatched.<br>
Fig. 10 illustrates the flow of the label enqueue 480 of Fig. 4. As a frame is dispatched from the dispatcher 112 to one of the n processors, at block 600 a label for an input information unit or frame is sent to the label enqueue 480 on line 482 and an identification of which of  the n processors is handling the frame on line 484. The first processing by the label enqueue 550 is at block 602 to determine whether  the valid field V is 1 for the one storage to which the first label field points. If the valid field V is 1, then the storage pointed to is occupied, cind the data should be stored in the other storage as indicated by block 606, otherwise the storage pointed to should be used at block 604. Next, at block 650, the valid field V for the appropriate storage is set to 1 to indicate that valid data is stored in that storage and at block 640 the tail indicator T for the current storage<br><br>
.Location is set to indicate that this is the last of the current data stream<br>
(until the next frame for the same data flow is received, at which time the<br>
tail field T is reset).  Next, at block 610 the label is compared with the<br>
current labels being handled by any of the processors (of course, the valid<br>
field V must be 1 for these, indicating that this is a valid frame).  The<br>
result of this comparison is either that the current label equals one already<br>
in process in which case control passes to block 670 or that it does not<br>
match any label currently in process, in which case control passed to block<br>
630.  If there is a match with one of the current labels, then the frame is a<br>
part of an existing data flow, so at block 670 the tail field T of the<br>
previous end of the data flow is reset  (so T=0) and the next field pointer<br>
for that label field is set to point to the current frame's location. Then at<br>
block 680, the head field H is set to 0 indicating that the current frame is<br>
not the head of a data flow.  If the label for the current frame was not<br>
equal to any label currently stored, then the current frame is a new data<br>
flow and the current frame is the beginning of it, so the head field H is set<br>
to 1 to indicate that status at block 630.  After the processing of block 630<br>
or block 680 to set up the appropriate flags, particularly the head field H,<br>
the process of linking to existing dataflows and setting up the fields or<br>
flags is done.	. .<br>
At Fig. 11 the process for processing out or delivering a frame out of the processors is shown.  First, the first field indicator is flipped so that the pointer points to the other storage as the first or next field for the processor at block 710. Then, at block 720 the valid field V is reset to 0, indicating that the data is no longer valid (the frame has been dispatched out, and the data does not represent a frame currently being processed). Block 725 tests whether the tail field T is set (T=l) indicating that this is the last frame of a particular data flow. If it is, then control passes to block 740, indicating that the process is done. If not, at block 730, then the next frame in the succession is located (by the pointer in the next field) and its head bit or flag H is set to indicate that it is the first frame in that data flow presently in the processors. Then, from block 730 the setting of flags is done as indicated by block 740.<br>
Fig. 12 illustrates the system of the present invention by an example, illustrating how several data flows could be accommodated by the completion unit described above with the logic of Fig. 10.  The N processors with the dispatcher 112 and the completion unit have been working for some time, so<br><br>
Fig. 12 represents a snapshot of data stored in a portion of the completion unit, particularly with reference to the label storage. As shown in this figure, the label enqueue is coupled to the plurality of label memories, two for each of the N processors. Each of the processors also has associated with it an output buffer (sometimes referred to as the Ready FCB Page) for those processed frames which are awaiting transmission to the three round robins shown. Associated with each of the pair of label memories is the first label memory to indicate which of the label memories was received first (and, when both label memories are valid, the first label represents the one which is in the Ready FCB Page buffer and the second or later-received label represents the one currently being processed in the respective processor). Five separate data flows are depicted in this figure, although the number of data flows which are in progress at any given time depend on the system (particularly its size and the network traffic) and can vary over time. In this example, the ten processors are identified as processors 0 through 9 and the label memories are identified as memories M01 and M02 for processor 0 through label memories M91 and M92 for processor 9, although the number of processors is a design choice and subject to change, if desired. A first data flow with identifier A starts at label memory M01 as shown by the indication (H=l) that label memory M01 (and the corresponding reference to processor 0) represents a head of a chain or data flow. The next field N of label memory M01 points to label memory M21 to indicate that the processor 2 is handling the next information unit associated with this data flow. The next field of the label memory M21 points to label memory M52 which indicates that processor 5 has the next portion of this data flow. The set tail field for the label memory M52 indicates that this is the final portion of this data flow currently being processed in the N processors. The data flow sequence in this example is shown by arrows Al pointing from label memory M01 to label memory M21 and arrow A2 pointing from label memory M21 to label memory M52, to illustrate the logic connection between elements of the data flow (the arrows logically represent the pointers in the next field and do not exist physically in the actual implementation) . Similarly, a data flow from label memory M02 to label memory Mil indicates by arrow A3 an order in the same data flow (although a different data flow from that described in connection with label memories M01, M21 and M52) . A third data flow is indicated with arrow A4 in connection with label memories M31 and M42,'with a fourth data flow indicated by arrow A5 between label memories M71 and M72. Finally, a fifth data flow is indicated at label memory M41 which has no arrow since it is a data flow presently including only a single label memory.  This label memory M41 is<br><br>
both the head and the tail of the data flow and has no next field, since there is no other label memory associated with this data flow.<br>
It will be remembered that, when there are two label memories associated with a single processor, one of the label memories represents a completed or processed information unit stored in a buffer and sometimes referred to as a Ready FCB Page, ready for transfer to the appropriate round robin unit for transmission from the processing complex, either up or down as the case may be, indicating that, for transfers up that it will be transferred to the interface device and for transfers down that it is being transferred back toward the data transmission network. In this case, processor 0, processor 4 and processor 7 include data in both of the associated label memories. Associated with each Ready FCB Page is also an UP field (indicating whether this is an up or a down page), as well as an indicator as to whether, if this is a down page, the frame is addressed to a target port or a general port, which determines whether to transfer a down page to the down target port round robin or to the general port round robin. If the earlier-received frame for processor 0 was the label memory M02 and that is both a head of a data flow and an up frame chosen by the up round robin device for the next transmission out of the processor complex and its buffer, then the FCB Page and associated data fields are removed from the Ready FCB Page, transferring the information to the up round robin.  Then, the first label indicator is toggled to indicate that the other label memory M01 for processor 1 is now the first, and the valid field V for the label memory M02 is set to 0 indicating that this label memory is no longer active or valid and the valid field VF for the associated FCB page is reset to 0.<br>
The present invention supports new data flows without disturbing the existing data flows and without needing to know about a new data flow in advance.  A packet representing a new data flow (for example, a message from one of the processing units about its status) is simply stored with its identifying data and no reference to another data flow. Its lack of an identifier will not match the identifier for any of the existing data flows with a "no label" field set, a message which can go anytime.<br>
The present invention also allows for a flush command to override the processing of the data flows in respective order by allowing the system to process completed frames in the order in which those completed frames are received, ignoring the chaining of label field (the next pointers and the<br><br>
requirement that a given frame be a head before having access to the round robin devices which forward the frames) . This may be accomplished by forcing "no label field" on the FCB Page.<br>
A single data flow will remain blocked until the head of the data flow • has been processed, since in normal operation (without the flush alternative) only frames which are the head of the message flow will be considered for sending out to the round robins by the completion unit. However, each data flow has its own head, so one data flow may be blocked but the other data flows can continue to process and send out completed information units to the round robins without interruption or hindrance and without intervention. This is particularly useful in the instance where a single data flow is halted (for example, a processor fails or cannot process one element of a single data flow) since the other data flows are not halted.  Otherwise, the entire processing would stop until the single data flow blockage were rectified.<br>
Of course, many modifications of the present invention will be apparent to those skilled in the relevant art in view of the foregoing description of the preferred embodiment, taken together with the accompanying drawings. For example, the actual type of implementing hardware for the classifier is subject to many design choices, and the particular choices described depend on the message content, and the method of message encapsulation and the processing to be done.  Many modifications can be made to the system implementation and the message configuration which the system can handle without departing from the spirit of the present invention.  The labels which are stored could be generated in other ways not based on the message content, or could simply be a consecutive numbering of data flows identified by the dispatcher.  Many other modifications and adaptations to the present system could be employed to advantage without departing from the spirit of the present invention, and some of the advantages of the present invention could be achieved without the corresponding use of other related features. Accordingly, the foregoing description of the preferred embodiment should be considered as merely illustrative of the principles of the present invention and not in limitation thereof.<br><br><br><br><br><br><br><br><br>
We claim:<br>
1.	An apparatus comprising:<br>
•	a semiconductor substrate;<br>
•	N processing units (110) fabricated on the substrate, where N&gt;1;<br>
•	first internal data memory fabricated on said substrate, said data memory for<br>
storing information accessible to said N processing units;<br>
•	a dispatcher (112) operatively coupled to the N processing units for receiving<br>
and transmitting to one of the N processing units an input information unit;<br>
•	a classifier (118) coupled to the dispatcher, said classifier including a<br>
comparison unit (114) for determining a data format for an input information<br>
unit and for generating and storing in the internal data memory output<br>
indicators for the input information unit output indicators indicating the data<br>
format of the input information unit and a starting address for the input<br>
information unit, indicators and the starting address which are available to the<br>
one of the N processing units during its processing the input information unit<br>
and used in the processing of the input information unit; and<br>
•	a  completion  unit  (114)   carried  on  the  semiconductor  substrate  and<br>
operatively connected to the N processing units (110) for receiving the<br>
information unit processed by the one of the N processing units (110).<br><br>
2.	An apparatus as claimed in claim 1 wherein the comparison unit includes a test<br>
for a virtual local area network field contained in the input information data and<br>
the generated output indicators include an indicator for identifying the presence of<br>
the virtual local area network field in the input information unit.<br>
3.	An apparatus as claimed in claims 1 or 2 further wherein the indicators further<br>
include the identity of the one of the N processing units (110) to which the input<br>
information unit was assigned.<br>
*' •<br>
4.	An apparatus as claimed in claim 3 and further including a flag indicating that the<br>
processed information units (110) are to be transmitted from the substrate in the<br>
order in which the processed information units are received, with said completion<br><br>
unit (114) responding to the flag to dispatch processed information units as they are completed by one of the N processing units (110).<br>
5.	An apparatus as claimed in claim 4 wherein the classifier (118) includes a system<br>
for generating; and storing in the internal data memory an identifier for each input<br>
information unit indicating its data flow and linking later information units from<br>
the same data flow to the earlier information unit from the same data flow, with<br>
the earlier one in the processors (110) being identified as the first information unit<br>
in a particular data flow and the transmission of information units from the<br>
processing units (110) is limited to those information units which are identified as<br>
the first information unit for the particular data flow.<br>
6.	An apparatus as claimed in claims 1 to 5 wherein the dispatch unit (112) further<br>
stores sequentially in a queue an identifier for each information unit and the<br>
identity of the processing unit to which the information unit was dispatched for<br>
processing; and wherein<br>
•	the completion unit (114) is further coupled to the sequential queue and utilizes<br>
the identifier for each information unit assigned by the dispatcher and the identity<br>
of the processing unit to which the information unit was dispatched in order to<br>
assemble the processed information units in the same order in which the<br>
information units were received.<br>
7.	A method of processing an input information unit comprising the steps of:<br>
•	receiving the input information unit at a dispatcher (112);<br>
•	sending the input information unit from the dispatcher (112) to one of a plurality<br>
of processors (110) for processing;<br>
•	reading selected bits from the input information unit while the information unit is<br>
being sent from the dispatcher (112) to the one of the plurality of processors<br>
(110);<br>
•	testing the read bits from the input information unit against known indicators<br>
identifying predetermined types of input information units to identify the type and<br><br>
protocol of the input information unit or that the input information unit does not meet any predetermined identifying type of input information unit; and<br>
•	based on the results of the testing of bits from the input information unit, storing<br>
indicators of the type of input information unit and other information about that<br>
input information unit; and<br>
•	using at the one of a plurality of processing units (110) the stored indicators and<br>
the other stored information about the input information unit in the processing of<br>
the input information unit.<br><br>
8.	A method as claimed in claim 7 wherein the step of generating the indicators and<br>
storing the indicators occurs while the input information unit is being sent to one<br>
of the plurality of processors (110) so that, when the one of the plurality of<br>
processors (110) processes the input information unit, the indicators and the other<br>
information have been determined and stored and the one of the plurality of<br>
processors (110) uses the indicators and other information about the input<br>
information unit in processing that input information unit.<br>
9.	A method as claimed in claim 7 or 8 and further including the step of generating a<br>
starting address for the further processing of the input information unit based on<br>
the content of the input information unit and the step of using the stored indicators<br>
at the one of the plurality of processing units (110) includes using the starting<br>
address.<br>
10.	A method as claimed in claim 7, 8 or 9 wherein the step of reading and testing is<br>
accomplished in hardware, whereby the process is accomplished in fewer<br>
processing cycles than if the reading and testing was accomplished by executing a<br>
series of stored instructions.<br>
11.	A method as claimed in claim 10 wherein the step of using hardware to<br>
accomplish the identification of the type of input information unit and storing<br>
indicators is accomplished within two machine cycles, whereby the step of using<br>
the indicators in one of the plurality of processing units (110) occurs earlier than<br><br>
if the tests were accomplished by executing a series of programmed instructions in sequence.<br>
12.      A method as claimed in claims 7 to 1 1 arid further including the steps of:<br>
•	generating and storing an identifier for the input information unit;<br>
•	storing in association with the identifier the identity of the processing unit to<br>
which the information unit was assigned; and<br>
•	using the identifier and the identity of the processing unit (110) to which the<br>
information unit was assigned to transmit processed information units in the order<br>
in which they were received.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWNvcnJlc3BvbmRlbmNlLXBvLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-correspondence-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWZvcm0tMTkucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-form-19.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLXBjdC0xMDEucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-pct-101.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLXBjdC0yMTAucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-pct-210.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLXBjdC0yMjAucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-pct-220.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMDA1OTUtZGVsLXBldGl0aW9uLTEzOC5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-00595-del-petition-138.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="217667-detergent-compositions.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="217669-battery-constructions-having-reduced-collector-assembly-volume.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>217668</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>IN/PCT/2002/0595/DEL</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>17/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>25-Apr-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>28-Mar-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>11-Jun-2002</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>INTERNATIONAL BUSINESS MACHINES CORPORATION,</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>ARMONK, NEW YORK,10504, USA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JENKINS STEVEN KENNETH</td>
											<td>2728 ANDERSON DRIVE, RALEIGH, NC 27608, U.S.A.</td>
										</tr>
										<tr>
											<td>2</td>
											<td>LEAVENS ROSS BOYD</td>
											<td>123 WILANDER DRIVE, CARY, NC 27511, U.S.A</td>
										</tr>
										<tr>
											<td>3</td>
											<td>SIEGEL MICHAEL STEVEN</td>
											<td>10625 LOWERY DRIVE, RALEIGH, NC 27615, U.S.A.</td>
										</tr>
										<tr>
											<td>4</td>
											<td>VERPLANKEN FABRICE JEAN</td>
											<td>9152 ROUTE DE CAGNES, F-06610 LA GAUDE, FRANCE</td>
										</tr>
										<tr>
											<td>5</td>
											<td>BASS BRIAN MITCHELL</td>
											<td>4021 OLD STURBRIDGE DRIVE, APEX, NC 27502, U.S.A.</td>
										</tr>
										<tr>
											<td>6</td>
											<td>CALVIGNEC JEAN LOUIS</td>
											<td>112 SPRING HOLLOW LANE, CARY, NC 27511, U.S.A.</td>
										</tr>
										<tr>
											<td>7</td>
											<td>DAVIS GORDON TAYLOR</td>
											<td>97603 FRANKLIN RIDGE, CHAPEL HILL, NC 27514, U.S.A.</td>
										</tr>
										<tr>
											<td>8</td>
											<td>GALLO ANTHONY MATTEO</td>
											<td>3308 CORSHAM DRIVE, APEX, NC 27502, U.S.A.</td>
										</tr>
										<tr>
											<td>9</td>
											<td>HEDDES MARCO</td>
											<td>4109 GRAND MANOR COURT #308, RALEIGH, NC 27615, U.S.A.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04L 29/06</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/GB00/04950</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2000-12-21</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>09/479,028</td>
									<td>2000-01-07</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>09/479,027</td>
									<td>2000-01-07</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/217668-method-and-apparatus-for-frame-and-protocol-classification by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 11:59:55 GMT -->
</html>
