<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/251638-improving-error-resilience-using-out-of-band-directory-information by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:48:37 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 251638:IMPROVING ERROR RESILIENCE USING OUT OF BAND DIRECTORY INFORMATION</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">IMPROVING ERROR RESILIENCE USING OUT OF BAND DIRECTORY INFORMATION</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method and apparatus to improve error resiliency in processing a multimedia bitstream is described. A directory of header information is generated for a multimedia bitstream. The directory information comprises packet header information associated with the multimedia bitstream. The directory information may be transmitted to a receiver along with the multimedia bitstream. A receiver of the multimedia bitstream and the directory can utilize the header information to identify and locate packets within and subsequent to erroneous data in the received bitstream. By identifying and locating packets that may otherwise be discarded, the receiver may be able to improve error recovery and decoding of the multimedia data.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM 2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970)<br>
&amp;<br>
THE PATENTS RULES, 2003<br>
COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
"IMPROVING ERROR RESILIENCE USING OUT OF BAND DIRECTORY INFORMATION"<br>
QUALCOMM INCORPORATED, an American Company of 5775<br>
Morehouse Drive, San Diego, California 92121-1714,<br>
United States of America<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
 IMPROVING ERROR RESILIENCE USING OUT OF BAND DIRECTORY<br>
INFORMATION<br>
CROSS-REFERENCE TO RELATED APPLICATIONS <br>
[0001] The present Application for Patent claims priority to Provisional Application No. 60/789,454 entitled "Improving Error Resilience Using Out of Band Directory Information" filed April 4, 2006, and assigned to the assignee hereof, and to Provisional Application No. 60/680,809 entitled "Methods and Apparatus for Improving Packet Error Resiliency Using Out-Of-Band Directory Information" filed May 13, 2005, and assigned to the assignee hereof, both of which are hereby expressly incorporated by reference herein.<br>
BACKGROUND OF THE INVENTION Field of the Invention<br>
[0002]       This invention relates to methods and apparatus for encoding and decoding digital data with error management schemes. <br>
Description of the Related Art<br>
[0003] Due to the explosive growth and great success of the Internet and wireless communication, as well as increasing demand for multimedia services, streaming media over the Internet and mobile/wireless channels has drawn tremendous attention. In heterogeneous Internet Protocol (IP) networks, video is provided by a server and can be streamed by one or more clients. Wired connections include dial-up, integrated services digital network (ISDN), cable, digital subscriber line protocols (collectively referred to as xDSL), fiber, local area networks (LAN), wide area networks (WAN) and others. The transmission mode can be either uni-cast or multi-cast.<br>
[0004] Similar to the heterogeneous IP network is mobile/wireless communication. Transport of multimedia content over mobile/wireless channels is very challenging because these channels are often severely impaired due to multi-path fading, shadowing, inter-symbol interference, and noise disturbances. Some other reasons such as mobility and competing traffic also cause bandwidth variations and loss. The channel noise and the number of users being served determine the time-varying property of channel environments.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
[0005] The demands of higher data rates and higher quality of service in both heterogeneous DP networks and mobile communication systems are growing rapidly. However, factors such as limited delay times, limited transmit power, limited bandwidth and multi-path fading continue to restrict the data rates handled by practical systems. In multimedia communications, particularly in error-prone environments, error resilience of the transmitted media is critical in providing the desired quality of service because errors in even a single decoded value can lead to decoding artifacts propagating spatially and temporally. Various encoding measures have been used to reduce errors while maintaining a necessary data rate, however all of these techniques suffer from problems with errors arriving at the decoder side.<br>
[0006] Through the use of a source encoder, data is compressed - conveying the maximum information by expending the minimum number of bits, followed by a channel encoder that tends to maximize the capacity of the transmission channel for a given probability of error in receiving these bits.<br>
[0007] Channel coding, for example, Reed-Solomon coding, is used to improve the robustness of the source-coded data. Joint source-channel coding methodologies have been used to provide varying levels of error protection to source coded data with varying levels of importance or to enable rate adaptation of coded video data to available network bandwidth through partitioning and dropping packets. This is because the common transport protocols do not deliver corrupted data to the source decoder.<br>
[0008] Source coding techniques such as reversible variable length coding (e.g. in MPEG-4) have been used for error recovery by decoding the packet in the reverse order when corrupt packets are in fact received. There is a compromise in coding efficiency with source coding techniques, which translates to quality of decoded video for a given bit rate.<br>
[0009] Hybrid coding standards, such as MPEG-1, MPEG-2, MPEG-4 (collectively referred to as MPEG-x), H.261, H.262, H.263, and H.264 (collectively referred to as H.26x), use resynchronization points in the bitstream as the main method of handling errors at the decoder.<br>
[0010] Another reason that can cause data loss in excess of the initial corruption is due to incorrect codeword emulation. The identification of the initial bit error position is not a trivial task and typically is not possible without a special design<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
supporting the identification of bit error positions in a MAC layer or physical layer component. Hence, upon detecting bitstream corruption, the decoder may have to stop decoding and move forward in the bitstream to find the next resynchronization point, and in the process necessarily skipping a sizeable amount of potentially healthy data. Although emulation of a different codeword, which is the same length as the original, i.e. authentic, codeword might seem to be less of a problem with respect to the sequence of events described above, this is actually not the case. There are many ways in which this kind of an error may lead to failures in a decoder's correct bitstream interpretation. For example, in most current codecs there are objects in the bitstream (compression related parameters) whose values influence the syntax of the following portion of the bitstream. Hence, an incorrect value for such an object can lead to an incorrect bitstream interpretation.<br>
[0011] Due to the variable packet lengths commonly used in the hybrid coding standards, information necessary for decoding the variable lengths packets (e.g., packet lengths and/or synchronization information) must be transmitted to the decoding apparatus in order to properly decode the bitstream. Because the common transport protocols rely on various layers of header information (e.g., transport layer headers and/or synchronization layer headers) to deliver this necessary variable packet length and/or synchronization information, the source decoder has a limited ability to handle an erroneous bitstream, with dropping of packets and resynchronization being the most common solution. An improved method of handling bit errors that lead to error propagation and data loss due to problems such as synchronization loss and incorrect codeword emulation, is needed.<br>
SUMMARY OF THE INVENTION<br>
[0012] A method of processing multimedia data is provided. The method includes receiving the multimedia data and generating a directory comprising at least a portion of header information associated with the multimedia data. In some aspects the method further includes transmitting the multimedia data and transmitting the directory.<br>
[0013] A processor for processing multimedia data is provided. The processor is configured to receive the multimedia data, and to generate a directory comprising at least a portion of header information associated with the multimedia data.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
In some aspects, the processor is also configured to transmit the multimedia data, and to transmit the directory.<br>
[0014] An apparatus for processing multimedia data is provided. The apparatus includes a receiver to receive the multimedia data, and a generator to generate a directory comprising at least a portion of header information associated with the multimedia data. In some aspects, the apparatus also includes a transmitter to transmit the multimedia data and the directory.<br>
[0015] An apparatus for processing multimedia data is provided. The apparatus includes means for receiving the multimedia data, and means for generating a directory comprising at least a portion of header information associated with the multimedia data. In some aspects, the apparatus also includes means for transmitting the multimedia data and the directory.<br>
[0016] A computer readable medium embodying a method of processing multimedia data is provided. The method includes receiving the multimedia data, and generating a directory comprising at least a portion of header information associated with the multimedia data. In some aspects, the method also includes transmitting the multimedia data, and transmitting the directory.<br>
[0017] A method of processing multimedia data is provided. The method includes receiving a multimedia data stream, and receiving a directory comprising at least a portion of header information associated with the multimedia data stream. In some aspects, the method also includes decoding some of the multimedia data stream using the directory.<br>
[0018] A processor for processing multimedia data is provided. The processor is configured to receive a multimedia data stream, and receive a directory comprising at least a portion of header information associated with the multimedia data stream. In some aspects the processor is also configured to decode some of the multimedia data stream using the directory.<br>
[0019] An apparatus for processing multimedia data is provided. The apparatus includes a receiver to receive a multimedia data stream and to receive a directory comprising at least a portion of header information associated with the multimedia data stream, and a memory to store at least a portion of the received directory. In some aspects, the apparatus also includes a decoder to decode at least a portion of the multimedia data stream using the directory.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
[0020] An apparatus for processing multimedia data is provided. The apparatus includes means for receiving a multimedia data stream, and for receiving a directory comprising at least a portion of header information associated with the multimedia data stream, and means for storing at least a portion of the directory. In some aspects, the apparatus also includes means for decoding at least a portion of the multimedia data stream using the directory.<br>
[0021] A computer readable medium embodying a method of processing multimedia data is provided. The method includes receiving a multimedia data stream, and receiving a directory comprising at least a portion of header information associated with the multimedia data stream. In some aspects the method also includes decoding some of the multimedia data stream using the directory.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
[0022] FIG. 1 is an illustration of an example of a communication system for delivery of streaming video.<br>
[0023] FIG. 2 is a block diagram of an example of a multi-layer protocol stack used for dividing tasks in the encoder device 105 and the decoder device 110 of FIG. 1.<br>
[0024] FIG. 3 is a flow diagram illustrating an example of a method for processing streaming multimedia data.<br>
[0025] FIG. 4 is an illustration of an example of a multiple layer packetization scheme<br>
[0026] FIG. 5 is a flow diagram illustrating an example of a method for processing streaming multimedia data.<br>
[0027] FIG. 6 shows a block diagram illustrating an example of an apparatus for processing multimedia data.<br>
[0028] FIG. 7 shows a block diagram illustrating another example of an apparatus for processing multimedia data.<br>
DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT <br>
[0029]       A method and apparatus to improve packet error resiliency in decoding a multimedia data stream, is described.   An encoder device may identify header information associated with various packets contained in one or more layers<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
(e.g., a transport layer and/or a synchronization layer) of the multimedia data stream. The header information may include a packet size, a packet number, a location of another header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate or a number of associated packets in a group of packets. A directory of the header information is generated and transmitted to a decoder to be used by the in case some of the original header information within the data stream is lost in transmission or is received in error. In some aspects, the directory containing the header information is transmitted over a communication link such as a channel other than the communication link over which the data packets containing the original headers are transmitted. Thus, a decoder receiving the directory may use the header information for locating a data packet in a received multimedia data stream. Li a case where erroneous packets are received by the decoder, the decoder may use the directory header information to facilitate recovery of data that would have been lost. In the following description, specific details are given to provide a thorough understanding of the embodiments. However, it will be understood by one of ordinary skill in the art that the embodiments may be practiced without these specific details. For example, electrical components may be shown in block diagrams in order not to obscure the embodiments in unnecessary detail. In other instances, such components, other structures and techniques may be shown in detail to further explain the embodiments. It is also understood by skilled artisans that electrical components, which are shown as separate blocks, can be rearranged and/or combined into one component.<br>
[0030] It is also noted that some embodiments may be described as a process, which is depicted as a flowchart, a flow diagram, a structure diagram, or a block diagram. Although a flowchart may describe the operations as a sequential process, many of the operations can be performed in parallel or concurrently and the process can be repeated. In addition, the order of the operations may be re-arranged. A process is terminated when its operations are completed. A process may correspond to a method, a function, a procedure, a subroutine, a subprogram, etc. When a process corresponds to a function, its termination corresponds to a return of the function to the calling function or the main function.<br>
[0031] Figure 1 is an illustration of an example of a communication system for delivery of streaming video.  System 100 includes encoder device 105 and decoder<br><br>
WO 2006/124854 		PCT/US2006/018853<br><br>
device 110.   Communication devices such as the encoder device 105 and the decoder<br>
device 110 may use a multi-layer protocol stack used for distributing tasks. Upper layer<br>
components in the encoder device 105 and the decoder device 110 may include multiple<br>
applications such as, for example video or audio encoders and/or decoders.   Some<br>
embodiments may include multiple streams of information that are meant to be decoded<br>
simultaneously.  In these cases, synchronization tasks of the multiple streams may also<br>
performed in upper layer components.   In the encoder device 105, an upper layer<br>
component may provide encoded timing information in the bitstream that is transmitted<br>
over a wireless network and/or a wired network 150.   In the decoder device 110, an<br>
upper layer component may parse the multiple streams of information such that the<br>
associated applications decode them at about the same time.<br>
[0032] Lower layer components in the encoder device 110 may include various schemes to provide for error resiliency. Error prone channels such as the wired and/or wireless network 150 may introduce errors into the bitstream received by the decoder device 110. Such error resiliency schemes provided in lower layer components may include one or more error control coding schemes, interleaving schemes and other schemes that are known to those of skill in the art. Lower layer components in the decoder device 110 may include the corresponding error decoding components that enable detection and correction of errors. Some errors that are introduced over the wired and/or wireless network 150 may not be correctable by the lower layer components of the decoder device 110. For those errors that are not correctable, solutions such as requesting retransmission of corrupt components by lower layer components of the encoder device 105 may not be feasible for some situations.<br>
[0033] Figure 2 is a block diagram of an example of a multi-layer protocol stack used for dividing tasks in the encoder device 105 and the decoder device 110. Upper layer components of the encoder device 105 are distributed in one or more of an application layer 206 and a synchronization layer 207. Lower layer components of the encoder device 105 are distributed into one or more of a transport layer 216, a stream and/or medium access control (MAC) layer 217, and a physical layer 218. Similarly, Upper layer components of the decoder device 110 are distributed in one or more of an application layer 211 and a synchronization layer 212. Lower layer components of the decoder device 110 are distributed into one or more of a transport layer 221, a stream and/or medium access control (MAC) layer 222, and a physical layer 223.   Those of<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
skill in the art will recognize these layers and be familiar with the allocation of various tasks among them.<br>
[0034] With reference to Figures 1 and 2, the encoder device 105 further includes a header information identifier 115, a header directory generator 120, a multimedia encoder 125, a memory component 130, a processor 135, and a receiver/transmitter 140. Processor 135 generally controls the overall operation of the exemplary encoder device 105.<br>
[0035] Header information identifier component 115 identifies information, e.g., in headers related to various layers of communication, regarding the packetization of multimedia data. In some examples, packetization is performed at various levels to allow multiple streams of data to be split up (parsed) in the encoding process and to be reassembled during decoding using, at least in part, header information that was added by the various layers of the encoder. For example, the synchronization layer 207 may add header information identifying multiple types of packets being linked with multiple decoder components that may decode the multiple types of packets simultaneously. The synchronization layer header information may include fields identifying a data sequence time, a data sequence duration, the destination decoder component (e.g., audio, video and closed caption), frame number, packet number and other information. Synchronization layer packets may be variable length in some examples. This may be due to the various encoding schemes such as, for example, digital compression schemes including variable length coding schemes.<br>
[0036] Other types of packets that may be identified by the header information identifier 115 may include fixed length packets such as may be utilized in the transport layer 216. Transport layer packets may be fixed length in order to support various error coding schemes, modulation schemes and other schemes that use fixed length packets. The transport headers may contain information identifying the number of transport layer packets that were parsed from a single synchronization layer packet. If the synchronization layer packet is variable length, then the number of transport layer packets needed to contain the data may be variable as well.<br>
[0037] The header information identifier 115 can also identify information for use by a decoder to identify the length, e.g., in bits or bytes, of the various packets. Since some packets are of variable length, and even fixed length packets from different sources may be of different length, the packet length may be needed to reconstruct<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
packets. Depending on the nature of the packet length information, positions of packets within another packet (e.g., locations of several transport layer packets with one larger synchronization layer packet) may also be determined indirectly (using, e.g., accumulated packet size information) or directly. Details of how a decoder may use the various forms of header information identified by the header information component 115 will be discussed below.<br>
[0038] The header directory generator 120 takes at least some of the information identified by the header information identifier 115 and generates a directory. The directory may include header information related to various layers, such as the application layer 206, the synchronization layer 207, the transport layer 217 and others. The information may be used by a decoder device in recovering from various errors including, identifying the size of erroneous packets received in error, identifying the next available packet in order to resynchronize and others. Header information from the header directory can be used to replace the lost or erroneous original header information within the data stream.<br>
[0039] The multi-media encoder 125 may include subcomponents including a transformer/quantizer component that transforms and/or quantizes video (or audio or closed caption text) data from the spatial domain to another domain, such as the frequency domain in the case of DCT (discrete cosine transform). The multimedia encoder may also include an entropy encoder component. The entropy encoder component may use a context-adaptive variable length coding (CAVLC). Encoded data may include quantized data, transformed data, compressed data, or any combinations thereof. Memory component 130 is used to store information such as raw video data to be encoded, encoded video data to be transmitted, header information, the header directory, or intermediate data being operated on by the various encoder components.<br>
[0040] In this example, the receiver/transmitter component 140 contains circuitry and/or logic used to receive data to be encoded from external source 145. External source 145 could be, for example, external memory, the Internet, a live video and/or audio feed, and receiving the data can include wired and/or wireless communications. Transmitter 140 also contains circuitry and/or logic, e.g. a transmitter, to transmit (Tx) encoded data over Network 150. Network 150 can be part of a wired system such as telephone, cable, and fiber optic, or a wireless system. In the case of wireless communication systems, network 150 can comprise, for example, part of a code<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
division multiple access (CDMA or CDMA2000) communication system or alternately, the system can be a frequency division multiple access (FDMA) system, an orthogonal frequency division multiple access (OFDMA) system, a time division multiple access (TDMA) system such as GSM/GPRS (General Packet Radio Service)/EDGE (enhanced data GSM environment) or TETRA (Terrestrial Trunked Radio) mobile telephone technology for the service industry, a wideband code division multiple access (WCDMA), a high data rate (lxEV-DO or lxEV-DO Gold Multicast) system, or in general any wireless communication system employing a combination of techniques.<br>
[0041] The transmitted data may include multiple bitstreams, such as video, audio and/or closed caption. In some examples the transmitted data also includes at least a portion of the header directory. In some examples the header directory is transmitted on a different channel (virtual or actual) other than the channel over which the multiple bitstreams are transmitted.<br>
[0042] It should be noted that encoder device 105 is a simplified example for purposes of explanation. Accordingly, one or more elements of encoder device 105 shown in Figure 1 and/or 2 may be omitted, rearranged and/or combined. For example, processor component 135 may be external of encoder device 105.<br>
[0043] Decoder device 110 contains similar components as encoder device 105, including header information identifier 155, packet locator 160, multimedia decoder 165, memory component 170, flagger 172, receiver 175, processor 180, and parser 182. Decoder device 110 receives encoded multimedia data that has been transmitted over network 150 or from external storage 185. The receiver 175 contains circuitry and/or logic used for receiving (Rx) encoded data in conjunction with network 150, as well as logic for receiving encoded data from external storage 185. External storage 185 could be, for example, external RAM or ROM, or a remote server. In addition to receiving multimedia bitstreams, the receiver 175 can receive the header directory that was generated in the header directory generator 120.<br>
[0044] The multimedia decoder 165 contains circuitry and/or logic used in decoding the received encoded multimedia bitstreams. Subcomponents of the multimedia decoder 165 may include a dequantization component, an inverse transform component, and various error recovery components. Correctly received packets can be decoded by the corresponding components of the application layer 211. The error recovery  components   may  include   lower   level   error   detection   and  correction<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
components (such as Reed-Solomon coding and/or Turbo-coding) as well as upper layer error recovery and/or error concealment used to replace and/or conceal data not correctable by the lower layer methods. The various error recovery components may benefit from the information contained in the header directory that was generated by the header directory generator 120 of the encoder device 105. Subcomponents of the multimedia decoder 165 may reside in the application layer 211, the synchronization layer 212, the transport layer 221, the stream/MAC layer 222, the physical layer 223 or combinations thereof.<br>
[0045] The header information identifier 155 contains circuitry and/or logic used in identifying information (e.g., header information) contained in the received header directory. When an erroneous packet is received by the decoder device 110, the header information identifier 155 identifies information in the header directory that may be used to identify the location of a subsequent packet in the bitstream. Header information in the header directory may also be used to replace the erroneously received header information in the erroneous packet or to locate and remove an extra erroneously received header in the packet. Packet locator 160 contains circuitry and/or logic used in locating the packet using the identified header directory information. In some examples, higher layer packets (e.g., application layer packets) that are located inside an erroneous lower level packet (e.g., a transport layer and/or synchronization layer packet) may be flagged as being erroneous. Flagger 172 contains circuitry and/or logic used in flagging erroneous packets. By flagging packets that may be erroneous due to their location in another erroneous packet, higher layer components (e.g., application layer components) may make error recovery decisions. The application layer 211 components may use the header directory information and the packet locator 160 in locating the erroneous application layer packets to perform various error recovery actions.<br>
[0046] Since multiple bitstreams may be received by the decoder device 110, the erroneous packets may be located in the multiple bitstreams. Parser 182 may be used at the lower layers as well as the synchronization layer 212 to parse the correctly received and erroneous packets and forward them to the appropriate application layer 211 components of the multimedia decoder 165. In addition, the necessary header directory information may also be forwarded from the transport layer 221 to the upper layers (e.g., the synchronization layer 212 and/or the application layer 211) to allow identification   of   erroneous   packets   for   purposes   of   error   recovery   and/or<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
resynchronization of the bitstream. The transport layer 221 usually removes the transport layer header information from the packets that are forwarded to the upper layers.<br>
[0047] The decoded multimedia data can be displayed with display component 190, stored in external storage 185, or stored in internal memory component 170. Display component 190 can be an integrated part of the decoder device 110. The display component 190 contains such parts as video and/or audio display hardware and logic, including a display screen and/or speakers. The display component 190 may also be an external peripheral device. In this example, the receiver 175 also contains logic used to communicate the decoded multimedia data to external storage component 185 or display component 190.<br>
[0048] It should also be noted that the decode device 110 is a simplified example for purposes of explanation. Therefore, one or more elements of decoder device 110 shown in Figures 1 and/or 2 may be omitted, rearranged and/or combined. For example, the processor 180 may be external of the decoder device 110.<br>
[0049] Figure 3 is a flow diagram illustrating an example of a method for processing streaming multimedia data. Method 300 is a method of generating a directory comprising header information for use in a decoder to improve error resiliency. The method 300 starts by receiving, at state 305, a bitstream of multimedia data. Multiple bitstreams, e.g., video, audio and/or closed caption text may be included in a single bitstream. Receiving means such as the receiver/transmitter 140 of Figure 1 may receive the multimedia bitstream at state 305.<br>
[0050] After receiving the bitstream at state 305, the method identifies header information, at optional state 310, associated with the multimedia data in the bitstream. As discussed above, the header information may include information from multiple layers. Figure 4 shows an illustration of an example of a multiple layer packetization scheme. In this example, application layer packets 405A and 405B may be fixed and/or variable length packets. A synchronization layer appends a synchronization layer header (sync header) 410 to each application layer packet 405A and 405B, resulting in sync layer packets 406A and 406B (the sync layer packets 406A and 406B in Figure 4 include a sync layer header 410 and the application layer packets 405A and 405B, respectively). The sync layer packets 406A and 406B are men input to the transport layer.   In this example, the transport layer packets are fixed length.  The<br><br>
WO 2006/124854	    -	PCT/US2006/018853<br>
transport layer breaks down the sync layer packets into portions corresponding to the transport layer packet size and appends transport layer headers 415 to the resulting transport layer packets. In this example, the sync layer packet 406A comprising the application layer packet 405A is split into two transport layer packets 420A and 420B, where packet 420B includes the remaining portion 425B of the sync layer packet 406A and a first portion 425C of the sync layer packet 406B. In this example, an additional transport layer header 415 is appended to the portion 425C of the transport layer packet 420B , preceding the start of the next sync layer packet 406B. A third transport layer packet 420D contains the next portion 425D of the sync layer packet 406B.<br>
[0051] The sync layer headers 410 and the transport layer headers 415 may contain similar information directed to enable a decoder to reassemble the synchronization layer packets and application layer packets. A header may include information such as a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and/or a number of associated packets in a group. In addition, header information may include stream identification information identifying the associated packet as belonging to a video bitstream, an audio bitstream, and/or a closed caption bitstream.<br>
[0052] Identifying means such as the header information identifier 115 of Figure 1 may identify the header information in the multimedia bitstream at optional state 310.<br>
[0053] The method 300 then generates, at state 315, a header information directory based on at least a portion of the header information identified, at state 310, in the multimedia bitstream. The directory may contain information pertaining to headers from multiple layers, e.g., the application layer, the sync layer and/or the transport layer, as well as other types of headers. The information contained in the directory can be used by a decoder to locate packet boundaries in a bitstream that contains erroneous data, to replace missing header information and/or to remove erroneous header information.<br>
[0054] In some examples, the header information directory contains information identifying the boundaries of each of the packets, where the packets can be from any layer (e.g., transport, synchronization, application, or a combination thereof). The header information for a packet may identify the layer that the header corresponds<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
 to, the size of the packet and any other packets located within the packet as well as other information as discussed above.  In other examples, a separate directory, or a distinct part of the directory, may be directed to separate layers (e.g., a transport layer directory, a sync layer directory etc.).<br>
[0055] An example of a transport layer directory as generated at state 315 will now be discussed. This example represents the sync layer and transport layer relationship depicted in Figure 4. In some examples such as the one shown in Figure 4 (e.g., systems having fixed length transport layer packets, i.e. 122 bytes/packet), each transport layer header is a fixed length (e.g., a single byte long) and appears at least at the beginning of each transport layer packet. The format of the header may include an END FLAG field, where the END FLAG field can be a 1 bit flag that can be set to 1 if the current packet is the last segment of the sync layer packet and to 0 otherwise. The transport layer header may also include a BYTEJDFFSET field that may indicate the number of bytes used by the last segment of the sync layer packet (this also indicates where the next transport layer header may be found, as shown in Figure 4 where a second transport layer header 415 in transport layer packet 420B is located between packet portions 425B and 425C). If a transport layer packet is less than 128 bytes then a 7 bit B YTE_OFFSET field may be sufficient. If there is no additional transport header in the current transport layer packet, then the BYTE_OFFSET field may be set to the length of the transport layer packet.<br>
[0056] The directory generated with this transport header information may include the fields listed in Table 1.<br>
Table 1<br>
Field Name	Field Description<br>
NUMBER_OF_PACKETS	The number of packets listed in this header directory listing<br>
(NUMBER_OF_PACKETS -1) records of the following type	<br>
PACKETJDFFSET	The number of bytes where the next packet starts<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
BYTE_OFFSET	The number of bytes within the<br>
	current packet where another packet<br>
	and/or packet header starts<br>
[0057] The NUMBER_OF_PACKETS field represents the number of packets being sent in the bitstream that are covered by the header directory message, i.e., subsequent records of PACKET_OFFSET and BYTE_OFFSET. The PACKET_OFFSET field entries point to the next packet in the group of packets. PACKET_OFFSET may be a number of bytes or bits or other number of data units to the end boundary of the packet. The BYTEJDFFSET field is used to locate an extra transport layer header within a packet such as the transport layer header 415 between the transport layer packet portions 425B and 425C in Figure 4. In this example the valid range of the BYTE_OFFSET is 1 to 121. If more than one extra transport layer header may occur within a single transport layer packet, then another field defining the number of BYTEJDFFSET entries within a single packet can be used. In some examples, the PACKETJDFFSET and/or BYTEJDFFSET values are cumulative and represent the distance to advance in the bitstream from the last located packet header position that includes all previous advances.<br>
[0058] The size of the fields may be preset or variable. For example, the NUMBERJDFJPACKETS field may be limited to a single byte, in which case a group of up to 255 sequentially numbered packets could be represented before the field would repeat. Therefore, if more than 255 transport layer packets may be required to fit the data of/a' single sync layer packet (using the example parsing shown in Figure 4), then more bits may be required. The directory may contain one of the sets of entries as shown in Table 1 for predetermined groups of related packets. For example, each packet represented by the information in Table 1 may be contained in a single group of video data such as a frame, or a slice. Also, an audio or closed caption bitstream may have a separate directory containing similar fields.<br>
[0059] In examples like this with fixed transport layer headers, upper layer components (e.g., sync layer and/or application layer) can use this known fixed header size to strip the headers on delivery and adjust the PACKETJDFFSET and BYTEJDFFSET entries in the header directory accordingly.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
[0060] An example of a synchronization layer header directory generated at state 315 will now be discussed. In this example, a single synchronization layer packet (e.g., the sync layer header 410 and the application layer packet 405A) contains the video, audio and/or closed caption data of a frame of data. Other partitioned groups of data (e.g., a portion of a frame) could also be contained in a synchronization layer packet. The sync layer header directory can include fields similar to those listed in Table 1 above. In this example, however, the packets and the associated headers represent sync layer packets and headers. The sync layer packets would be made up of a number of transport layer packets (with the transport headers stripped) also referred to as blocks. An example of the sync layer header directory fields are listed in Table 2<br>
Table 2<br>
Field Name	Field Description<br>
NUMBER_OF_PACKETS	The number of sync layer packets listed in this header directory listing<br>
(NUMBER_OF_PACKETS -1) records of the following type	<br>
BLOCK_OFFSET	The number of transport layer packets (blocks) where the next sync layer packet starts<br>
BYTE_OFFSET	The number of bytes within the transport layer packet indicated by BLOCKJDFFSET where the next sync layer packet starts<br>
[0061] The NUMBER JDF_PACKETS field represents the number of transport layer packets that are covered by the subsequent records of BLOCKJDFFSET and BYTE_OFFSET. In addition, the NUMBER_OF_PACKETS field also represents the number of transport layer packets in a frame of video, audio and/or closed caption data to be displayed simultaneously. In examples where the size of the transport layer packets is fixed, the number of bits to advance is known by specifying the number of packets, as in this example. The BLOCKJDFFSET field points to the next sync layer packet (and the next multimedia frame in this example) in the group of sync layer packets being covered. The group of sync layer packets may be a predetermined number<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
of frames. BLOCK_OFFSET may also be a number of bytes or bits or other number of data units. The BYTEJDFFSET field is used to locate the start of the next sync layer packet when it occurs within a transport layer packet such as the portion 425C comprising the start of the second sync layer packet 406B (including sync header 410 and application layer packet 405B) contained in the transport layer packet 420B shown in Figure 4. In some examples, the BLOCK_OFFSET values are cumulative and represent the number of transport layer packets to advance in the bitstream from the last located block position that includes all previous advances.<br>
[0062] The size of the fields may be preset or variable. For example, the NUMBER_OF_PACKETS field may be limited to a single byte, in which case a group of up to 255 sequentially numbered transport layer packets could be represented before the field would repeat. Therefore, if more than 255 transport layer packets may be required to fit the data of a single sync layer packet (using the example parsing shown in Figure 4), then more bits may be required. The directory may contain one of the sets of entries as shown in Table 1 for predetermined groups of related packets. For example, each packet represented by the information in Table one may be contained in a single group of video data such as a frame, or a slice. Also, an audio or closed caption bitstream may have a separate directory containing similar fields.<br>
[0063] In addition to the data contained in Table 2, the sync layer header directory, or a message containing the header directory information of Table 2, may also include one or more of the sync layer header directory fields listed in Table 3.<br>
Table 3<br>
Field Name	Field Description<br>
MESSAGEJD	A field used to indicate that the message is a sync layer directory message<br>
STREAMJD	A field identifying the type of application (e.g., audio, video, and/or closed caption) that the header directory information is associated with<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
SIZEJDF_BLOCK_OFFSET	The number of bits used to represent the BLOCK_OFFSET field shown in Table 2<br>
SEQUENCEJTIME	A field specifying a sequence time to display the frame represented by the packets covered by this set.<br>
FRAME_NUMBER	Identifies a unique frame number in a audio, video and/or closed caption sequence of other frames.<br>
ENHANCEMENT_FLAG	Signals whether this frame refers to a video CODEC base layer or an enhancement layer (e.g., in a multilayer coding scheme).<br>
RAP_FLAG	This field indicates whether the frame following is a random access frame (e.g., an intra-coded frame) for reacquisition of a bitstream.<br>
FRAME_RATE	In systems where frame rate can change dynamically, this field may indicate to a decoder when to display the frame.<br>
UNREFERENCED JFRAME_FLAG	Signals whether a frame is a reference frame, (e.g., indicates whether the frame is used as a reference in the reconstruction of one or more other frames).<br>
RESERVED	Reserved bits to provide padding for byte alignment of the header.<br>
[0064] Generating means such as the header directory generator shown in Figure 1 may generate the header information directory at state 315.<br>
[0065] The method 300 continues to optional state 320 where the multimedia data stream is transmitted. As discussed above in relation to Figure 1, the multimedia data may be transmitted over the wired and/or wireless network 150. In this example, the header directory is transmitted at optional state 325. In some examples, the transmitting of the multimedia data at state 320 and the transmitting of the header directory at state 325 are done over separate channels.  This may be done in order to<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
provide different error protection levels or provide channel diversity, which may<br>
improve the error resiliency at a receiver.   In some examples the one or both of the<br>
multimedia data stream or the header directory can be transmitted (states 320 or 325<br>
respectively) over a virtual channel. A virtual channel may provide a degree of freedom<br>
to provide error protection that may be adjusted separately for the multimedia data and<br>
the header directory. Transmitting means such as the receiver/transmitter 140 shown in<br>
Figure 1 may transmit the multimedia data stream at optional state 320, as well as<br>
transmit the header directory at optional state 325.<br>
[0066] It should be noted that any one of the blocks illustrated in the flowchart shown in Figure 3 may be omitted, rearranged in order, or combined with one or more other blocks.<br>
[0067] Figure 5 is a flow diagram illustrating an example of a method for processing streaming multimedia data. The method 500 can be performed by the decoder device 110 shown in Figure 1. The method 500 illustrates a use of the header information directory, generated using the method 300 discussed above, to improve error resiliency in the decoder device 110. Decoder device 110 receives , at state 505, a multimedia data stream comprising video, audio and/or closed caption data. The data may be encoded as discussed above where encoded data includes quantized data, transformed data, compressed data and combinations thereof. The multimedia data may include packetized data where the packetization may be performed at multiple levels. Receiving means such as the receiver 175 shown in Figure 1 may receive the multimedia data at state 505.<br>
[0068] The decoder device 110 also receives, at state 510, the header information directory. The header information directory may be contained in a message including one or more of the fields shown and described in Tables 1, 2 and 3 above. The directory may be received in separate parts such as a transport layer header directory as shown in Table 1 and a synchronization layer header directory as shown in Tables 2 and 3. The header information directory may be received over the same channel as the multimedia data is received 505. The header information directory may be received over a different channel than the multimedia data was received. In some examples one or both of the multimedia data and the header information directory can be received (at states 505 and 510, respectively) over a virtual channel. After receiving the header information directory, some or all of the header information directory may be stored into<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
memory at state 510. Memory storing means such as the memory module 180 or the external storage module 185 shown in Figure 1 may be used to store the header information directory at state 510.<br>
[0069] At optional state 515, after receiving the multimedia data, the decoder device 110 may detect and correct errors that were introduced to the bitstream during transmission over the network 150. Various error detection and correction schemes known to those of skill in the art may be used to detect and correct the errors. Some errors may be uncorrectable and may result in erroneous packets. Erroneous packets may be marked (e.g., by setting a field to a value that indicates a packet to be in error) by flagging means such as the flagger 172 shown in Figure 1. Marking erroneous packets as erroneous enables upper layer components to more easily identify the erroneous packets and initiate error recovery schemes. Erroneous packets may also be identified in the upper layers as being erroneous without any flagging information.<br>
[0070] At optional state 520, the correct packets and the erroneous packets are forwarded to the upper layers (e.g., the synchronization layer and the application layer). In addition to forwarding the packets of the multimedia data, the header information directory is also forwarded or at least made available to the upper layers if needed. The multimedia packets forwarded to the upper layers may have one or more lower layer headers stripped and the header directory information that relates to packet size may be modified to reflect the removal of the lower layer headers.<br>
[0071] The decoder device 110 decodes correctly received multimedia data packets at state 525. Decoding may include dequantizing, inverse transforming, decompressing and combinations thereof. The multimedia data packets may be in multiple bitstreams (e.g., video, audio and or closed caption) that may be decoded and played simultaneously. Since erroneous packets were forwarded at state 520, the decoding may be delayed until error recovery and/or resynchronization of decoding can take place.<br>
[0072] When erroneous data is encountered, the header directory information can be used to identify individual subsequent packets (by identifying the packet boundaries locations), and possibly identify the application layer components that they are destined to, in order to better recover from the erroneous data. The decoder device 110 identifies, at optional state 530, header information contained in the header information directory that is associated with the erroneous packets in the bitstream. The<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
decoder device 110 then locates, at optional state 535 the identified packet, e.g., using the PACKET_OFFSET information contained in the header directory, to advance to the subsequent packet in the bitstream. The identification at state 530 can be performed at any layer when an error is encountered including the transport layer, the synchronization layer and the application layer.<br>
[0073] Referring to Figure 4, assume that the second transport layer packet 420B (including partial transport layer packet portions 425B and 425C) is erroneous. Since it is erroneous, a decoder may not know that there is an extra transport layer header 415 located in the middle of the transport layer packet 420B. As discussed above, the extra transport layer header 415 is the start of the second synchronization layer packet 406B including sync header 410 and the application layer packet 405B. With the use of the header information directory, the location of the extra transport layer header 415 may be identified by referring to the BYTE_OFFSET field (shown in Table 1) of the header information record associated with the erroneous transport layer packet 420B. The transport layer then locates, at state 535, the extra transport layer packet header and parses the erroneous transport layer packet, strips the transport layer headers and forwards the two sync layer packets, both flagged as erroneous, to the synchronization layer. The synchronization layer can then identify the application layer components, using the information shown in Table 2 and 3, to forward the erroneous application layer packets 405A and 405B to their appropriate application layer component. Parsing means such as the parser 182 shown in Figure 1 can perform the parsing described above.<br>
[0074] As in this example, the identification at state 530 can take place, at least in part, at the synchronization layer, when information such as STREAM_ID shown in Table 3 , is included in the header information directory. Individual application layer packets may be flagged and forwarded to the application components where they were destined to be decoded. In other examples, the directory header information may be forwarded (and possibly adjusted to reflect removal of any lower layer header data) to the application layer components where the identification of header information and location of packets at state 535 can take place. Identifying means such as the header information identifier 155 shown in Figure 1 can identify 530 the directory header information associated with a packet (or packets) located subsequent to<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
erroneous data. Locating means such as the packet locator 160 shown in Figure 1 can locate the subsequent packet(s) at state 535.<br>
[0075] After identifying the directory header information and locating one or more subsequent packets, the method 500 can perform error recovery to recover erroneous packets and/or resume decoding at the subsequent packet at optional state 540. Application layer components can utilize the identified and located packets to improve their error recovery schemes. In some examples, identified and located packets may be non-erroneous and the decoder can continue decoding with the packets obtained using the header directory information. Simply being able to identify the location of packets that would otherwise be unavailable (in the case of variable length packets) can be used to identify the areas of the bitstream that are erroneous. By identifying these areas, error recovery methods may be able to save and/or replace some of the data located subsequent to the erroneous data in the bitstream that may otherwise be discarded.<br>
[0076] It should be noted that any one of the blocks illustrated in the flowchart shown in Figure 5 may be omitted, rearranged in order, or combined with one or more other blocks.<br>
[0077] An example provides an apparatus for processing multimedia data. The example apparatus includes means for receiving the multimedia data, and means for generating a directory, where the directory includes at least a portion of header information associated with the multimedia data. The means for receiving the multimedia data may comprise the receiver/transmitter 140 of Figure 1. The means for generating the directory may comprise the header directory generator 120 of Figure 1.<br>
[0078] An example provides an apparatus for processing multimedia data. The example apparatus includes means for receiving a multimedia data stream, and for receiving a directory comprising at least a portion of header information associated with the multimedia data stream. The example apparatus also includes means for storing at least a portion of the directory. The means for receiving may comprise the receiver 175 of Figure 1. The means for storing the directory may comprise the memory module 170 of Figure 1.<br>
[0079] Figure 6 shows a block diagram illustrating an example of an apparatus for processing multimedia data. The example apparatus 600 of Figure 6 includes means for receiving the multimedia data, and means for generating a directory,<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
where the directory includes at least a portion of header information associated with the multimedia data. The means for receiving the multimedia data may comprise a receiver 605 of Figure 6. The means for generating the directory may comprise a header directory generator 610 of Figure 6.<br>
[0080] Figure 7 shows a block diagram illustrating an example of an apparatus for processing multimedia data. The example apparatus includes means for receiving a multimedia data stream, and for receiving a directory comprising at least a portion of header information associated with the multimedia data stream. The example apparatus also includes means for storing at least a portion of the directory. The means for receiving may comprise a receiver 705 of Figure 7. The means for storing the directory may comprise the memory storage module 710 of Figure 7.<br>
[0081] The examples given above have been depicted with headers and header information, where the header has been depicted as being at the front of a packet. It should be noted that the header information could be located at other position in a packet or in a separate bitstream from the packet.<br>
[0082] Those of ordinary skill in the art would understand that information and signals may be represented using any of a variety of different technologies and techniques. For example, data, instructions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description may be represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof.<br>
[0083] Those of ordinary skill would further appreciate that the various illustrative logical blocks, modules, and algorithm steps described in connection with the examples disclosed herein may be implemented as electronic hardware, firmware, computer software, middleware, microcode, or combinations thereof. To clearly illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the disclosed methods.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br>
[0084] The various illustrative logical blocks, components, modules, and circuits described in connection with the examples disclosed herein may be implemented or performed with a general purpose processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor, but in the alternative, the processor may be any conventional processor, controller, microcontroller, or state machine. A processor may also be implemented as a combination of computing devices, e.g., a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration.<br>
[0085] The steps of a method or algorithm described in connection with the examples disclosed herein may be embodied directly in hardware, in a software module executed by a processor, or in a combination of the two. A software module may reside in RAM memory, flash memory, ROM memory, EPROM memory, EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such that the processor can read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processor. The processor and the storage medium may reside in an Application Specific Integrated Circuit (ASIC). The ASIC may reside in a wireless modem. In the alternative, the processor and the storage medium may reside as discrete components in the wireless modem.<br>
[0086] The previous description of the disclosed examples is provided to enable any person of ordinary skill in the art to make or use the disclosed methods and apparatus. Various modifications to these examples will be readily apparent to those skilled in the art, and the principles defined herein may be applied to other examples and additional elements may be added.<br>
[0087] Thus, methods and apparatus to generate a header information directory comprising header information associated with a multimedia bitstream, and methods and apparatus to receive and use the header information directory to provide error management of the multimedia bitstream, have been described.<br><br>
WO 2006/124854								PCT/US2006/018853<br><br>
We Claim:<br>
WHAT IS CLAIMS IS:<br>
1.	A method of processing multimedia data, comprising:<br>
receiving the multimedia data; and<br>
generating a directory comprising at least a portion of header information associated with the multimedia data.<br>
2.	The method of Claim 1, further comprising:<br>
transmitting the multimedia data; and<br>
transmitting the directory.<br>
3.	The method of Claim 1, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
4.	The method of Claim 2, wherein transmitting the multimedia data comprises transmitting over a first communication link and wherein transmitting the directory comprises transmitting over a second communication link.<br>
5.	The method of Claim 4, wherein the first or second communication link comprises a virtual channel.<br>
6.	The method of Claim 1, wherein the directory further comprises stream identification information identifying a packet in the multimedia data as at least one of an audio packet, a video packet and a closed caption packet.<br>
7.	The method of Claim 1, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data.<br>
8.	The method of Claim 1, further comprising transmitting information identifying a message containing the directory information.<br>
9.	A processor for processing multimedia data, the processor configured to:<br>
receive the multimedia data; and<br>
generate a directory comprising at least a portion of header information associated with the multimedia data.<br><br>
WO 2006/124854	                                                                PCT/US2006/018853<br>
10.	The processor of Claim 9, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
11.	The processor of Claim 9, wherein the directory further comprises stream identification information identifying a packet in the multimedia data as at least one of an audio packet, a video packet and a closed caption packet.<br>
12.	The processor of Claim 9, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data.<br>
13.	An apparatus for processing multimedia data, comprising:<br>
a receiver to receive the multimedia data; and<br>
a generator to generate a directory comprising at least a portion of header information associated with the multimedia data.<br>
14.	The apparatus of Claim 13, further comprising:<br>
a transmitter to transmit the multimedia data and the directory.<br>
15.	The apparatus of Claim 13, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
16.	The apparatus of Claim 14, wherein the transmitter transmits the multimedia data over a first communication link, and transmits the directory over a second communication link, wherein the first or second communication link comprises a virtual channel.<br>
17.	The apparatus of Claim 13, wherein the directory further comprises stream identification information identifying a packet in the multimedia data as at least one of an audio packet, a video packet and a closed caption packet.<br>
18.	The apparatus of Claim 13, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data.<br>
19.	The apparatus of Claim 14, wherein the transmitter transmits information identifying a message containing the directory information.<br>
20.	An apparatus for processing multimedia data, comprising:<br><br>
WO 2006/124854	 		PCT/US2006/018853<br><br>
means for receiving the multimedia data; and<br>
means for generating a directory comprising at least a portion of header information associated with the multimedia data.<br>
21.	The apparatus of Claim 20, further comprising:<br>
means for transmitting the multimedia data and the directory.<br>
22.	The apparatus of Claim 20, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
23.	The apparatus of Claim 20, wherein the directory further comprises stream identification information identifying a packet in the multimedia data as at least one of an audio packet, a video packet and a closed caption packet.<br>
24.	The apparatus of Claim 20, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data.<br>
25.	The apparatus of Claim 21, wherein the transmitting means further comprises means for transmitting information identifying a message containing the directory information.<br>
26.	A computer readable medium embodying a method of processing multimedia data, the method comprising:<br>
receiving the multimedia data; and<br>
generating a directory comprising at least a portion of header information associated with the multimedia data.<br>
27.	The computer readable medium of Claim 26, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
28.	The computer readable medium of Claim 26, wherein the directory further comprises stream identification information identifying a packet in the multimedia data as at least one of an audio packet, a video packet and a closed caption packet.<br><br>
WO 2006/124854	 		PCT/US2006/018853<br>
29.	The computer readable medium of Claim 26, wherein the directory<br>
further comprises a plurality of records, wherein a record comprises information<br>
regarding a location of a packet in the multimedia data.<br>
30.	A method of processing multimedia data, comprising:<br>
receiving a multimedia data stream; and<br>
receiving a directory comprising at least a portion of header information associated with the multimedia data stream.<br>
31.	The method of Claim 30, further compri sing:<br>
decoding at least a portion of the multimedia data stream using the directory.<br>
32.	The method of Claim 30, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data stream.<br>
33.	The method of Claim 32, further comprising locating a packet in the multimedia data stream based on one or more of the plurality of received records.<br>
34.	The method of Claim 30, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
35.	The method of Claim 30, wherein receiving the multimedia data stream comprises receiving over a first communication link and wherein receiving the directory comprises receiving over a second communication link.<br>
36.	The method of Claim 35, wherein the first or second communication link comprises a virtual channel.<br>
37.	The method of Claim 30, wherein the directory further comprises stream identification information identifying a packet in the multimedia data stream as at least one of an audio packet, a video packet and a closed caption packet.<br>
38.	The method of Claim 30, wherein the multimedia data stream comprises multiple packets and at least one of the packets is erroneous, the method further comprising:<br>
identifying a portion of the directory information associated with a packet located subsequent to the erroneous packet in the multimedia data stream; and<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
using the identified portion of directory information in locating the subsequent packet in the multimedia data stream.<br>
39.	The method of Claim 38, wherein the subsequent packet is located within<br>
the erroneous packet, the method further comprising:<br>
parsing the subsequent packet from the erroneous packet; and flagging the parsed packet as being erroneous.<br>
40.	A processor for processing multimedia data, the processor configured to:<br>
receive a multimedia data stream; and<br>
receive a directory comprising at least a portion of header information associated with the multimedia data stream.<br>
41.	The processor of Claim 40, wherein the processor is further configured<br>
to:<br>
decode at least a portion of the multimedia data stream using the directory.<br>
42.	The processor of Claim 40, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data stream, and further wherein the processor is further configured to locate one of the packets in the multimedia data stream based on one or more of the plurality of received records.<br>
43.	The processor of Claim 40, wherein the multimedia data stream comprises multiple packets and at least one of the packets is erroneous and the processor is further configured to:<br>
identify a portion of the directory information associated with a packet located subsequent to the erroneous packet in the multimedia data stream; and<br>
locate the subsequent packet in the multimedia data stream using the identified portion of directory information.<br>
44.	The processor of Claim 43, wherein the subsequent packet is located<br>
within the erroneous packet and the processor is further configured to:<br>
parse the subsequent packet from the erroneous packet; and flag the parsed packet as being erroneous.<br>
45.	An apparatus for processing multimedia data, comprising:<br><br>
WO 2006/124854 	                                         PCT/US2006/018853<br>
a receiver to receive a multimedia data stream and to receive a directory comprising at least a portion of header information associated with the multimedia data stream; and<br>
a memory to store at least a portion of the received directory.<br>
46.	The apparatus of Claim 45, further comprising:<br>
a decoder to decode at least a portion of the multimedia data stream using the directory.<br>
47.	The apparatus of Claim 45, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data stream.<br>
48.	The apparatus of Claim 47, further comprising a locator to locate one of the packets in the multimedia data stream based on one or more of the plurality of received records.<br>
49.	The apparatus of Claim 45, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
50.	The apparatus of Claim 45, wherein the directory further comprises stream identification information identifying a packet in the multimedia data stream as at least one of an audio packet, a video packet and a closed caption packet.<br>
51.	The apparatus of Claim 45, wherein the multimedia data stream comprises multiple packets and at least one of the packets is erroneous, the apparatus further comprising:<br>
an identifier to identify a portion of the directory header information associated with a packet located subsequent to the erroneous packet in the multimedia data stream; and<br>
a locator to locate the subsequent packet in the multimedia data stream using the identified portion of directory header information.<br>
52.	The apparatus of Claim 51, wherein the subsequent packet is located<br>
within the erroneous packet, the apparatus further comprising:<br>
a parser to parse the subsequent packet from the erroneous packet; and a flagger to flag the parsed packet as being erroneous.<br>
53.	An apparatus for processing multimedia data, comprising:<br><br>
WO 2006/124854	PCT/US2006/018853<br><br>
means for receiving a multimedia data stream, and for receiving a directory comprising at least a portion of header information associated with the multimedia data stream; and<br>
means for storing at least a portion of the directory.<br>
54.	The apparatus of Claim 53, further comprising:<br>
means for decoding at least a portion of the multimedia data stream using the directory.<br>
55.	The apparatus of Claim 53, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data stream.<br>
56.	The apparatus of Claim 55, further comprising:<br>
means for locating a packet in the multimedia data stream based on one or more of the plurality of received records.<br>
57.	The apparatus of Claim 53, wherein the header information comprises one or more of a packet size, a packet number, a location of a header within a packet, a data sequence time, a data sequence duration, a frame time, a frame number, a random access point flag, a frame rate and a number of associated packets in a group.<br>
58.	The apparatus of Claim 53, wherein the directory further comprises stream identification information identifying a packet in the multimedia data stream as at least one of an audio packet, a video packet and a closed caption packet.<br>
59.	The apparatus of Claim 53, wherein the multimedia data stream comprises multiple packets and at least one of the packets is erroneous, the apparatus further comprising:<br>
means for identify a portion of the directory information associated with a packet located subsequent to the erroneous packet in the multimedia data stream; and<br>
means for locating the subsequent packet in the multimedia data stream using the identified portion of directory information.<br>
60.	The apparatus of Claim 59, wherein the subsequent packet is located<br>
within the erroneous packet, the apparatus further comprising:<br>
means for parsing the subsequent packet from the erroneous packet; and means for flagging the parsed packet as being erroneous.<br><br>
WO 2006/124854	 	PCT/US2006/018853<br><br>
61.	A computer readable medium embodying a method of processing<br>
multimedia data, the method comprising:<br>
receiving a multimedia data stream; and<br>
receiving a directory comprising at least a portion of header information associated with the multimedia data stream.<br>
62.	The computer readable medium of Claim 61, wherein the method further<br>
comprises:<br>
decoding at least a portion of the multimedia data stream using the directory.<br>
63.	The computer readable medium of Claim 61, wherein the directory further comprises a plurality of records, wherein a record comprises information regarding a location of a packet in the multimedia data stream, and further wherein the method further comprises locating a packet in the multimedia data stream based on one or more of the plurality of received records.<br>
64.	The computer readable medium of Claim 61, wherein the multimedia data stream comprises multiple packets and at least one of the packets is erroneous, the method further comprising:<br>
identifying a portion of the directory information associated with a packet located subsequent to the erroneous packet in the multimedia data stream; and<br>
using the identified portion of directory information in locating the subsequent packet in the multimedia data stream.<br>
65.	The computer readable medium of Claim 64, wherein the subsequent<br>
packet is located within the erroneous packet, the method further comprising:<br>
parsing the subsequent packet from the erroneous packet; and flagging the parsed packet as being erroneous.<br><br><br><br><br>
ABSTRACT<br>
"Improving Error Resilience Using out Of Band Directory Information"<br>
A method and apparatus to improve error resiliency in processing a multimedia bitstream is described. A directory of header information is generated for a multimedia bitstream. The directory information comprises packet header information associated with the multimedia bitstream. The directory information may be transmitted to a receiver along with the multimedia bitstream. A receiver of the multimedia bitstream and the directory can utilize the header information to identify and locate packets within and subsequent to erroneous data in the received bitstream. By identifying and locating packets that may otherwise be discarded, the receiver may be able to improve error recovery and decoding of the multimedia data.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWFic3RyYWN0LmRvYw==" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUFGRklEQVZJVCgxMi0zLTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-AFFIDAVIT(12-3-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUFGRklEQVZJVCgyOC0xMi0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-AFFIDAVIT(28-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNMQUlNUyhBTUVOREVEKS0oMTItMy0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CLAIMS(AMENDED)-(12-3-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNMQUlNUyhBTUVOREVEKS0oOC0xMi0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CLAIMS(AMENDED)-(8-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNMQUlNUyhNQVJLRUQgQ09QWSktKDgtMTItMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CLAIMS(MARKED COPY)-(8-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWNsYWltcy5kb2M=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNPUFkgT0YgSVBSUCg4LTEyLTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-COPY OF IPRP(8-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNPUlJFU1BPTkRFTkNFKDItMi0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CORRESPONDENCE(2-2-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWNvcnJlc3BvbmRlbmNlKDItNi0yMDA4KS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-correspondence(2-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNPUlJFU1BPTkRFTkNFKDI4LTEyLTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CORRESPONDENCE(28-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNPUlJFU1BPTkRFTkNFKDMwLTYtMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CORRESPONDENCE(30-6-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNPUlJFU1BPTkRFTkNFKDUtMy0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CORRESPONDENCE(5-3-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUNPUlJFU1BPTkRFTkNFKDktOC0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-CORRESPONDENCE(9-8-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWNvcnJlc3BvbmRlbmNlLXJlY2VpdmVkLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-correspondence-received.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LURSQVdJTkcoOC0xMi0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-DRAWING(8-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUZPUk0gMSgzMC02LTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-FORM 1(30-6-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0gMTMoMzAtNi0yMDExKS0ucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form 13(30-6-2011)-.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0gMTMoMzAtNi0yMDExKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form 13(30-6-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0gMih0aXRsZSBwYWdlKS0oMjktMTEtMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form 2(title page)-(29-11-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0gMygyLTYtMjAwOCkucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form 3(2-6-2008).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUZPUk0gMyg5LTgtMjAxMSkucGRm" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-FORM 3(9-8-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LUZPUk0gNSgzMC02LTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-FORM 5(30-6-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tMi5kb2M=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tcGN0LWliLTMwNC5wZGY=" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-pct-ib-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LWZvcm0tcGN0LWlzYS0yMzcucGRm" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-form-pct-isa-237.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LU1BUktFRCBDT1BZKDEyLTMtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-MARKED COPY(12-3-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LVBFVElUSU9OIFVOREVSIFJVTEUtMTM3KDItMi0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-PETITION UNDER RULE-137(2-2-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVCg4LTEyLTIwMTEpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-REPLY TO EXAMINATION REPORT(8-12-2011).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LVJFUExZIFRPIEhFQVJJTkcoMTItMy0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-REPLY TO HEARING(12-3-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1NVU1OUC0yMDA3LVNQRUNJRklDQVRJT04oQU1FTkRFRCktKDEyLTMtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2000-MUMNP-2007-SPECIFICATION(AMENDED)-(12-3-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjAwMC1tdW1ucC0yMDA3LXdvIGludGVybmF0aW9uYWwgcHVibGljYXRpb24gcmVwb3J0KDI5LTExLTIwMDcpLnBkZg==" target="_blank" style="word-wrap:break-word;">2000-mumnp-2007-wo international publication report(29-11-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="251637-a-decorative-plaster-coating.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="251639-a-papermakers-fabric.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>251638</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2000/MUMNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>13/2012</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>30-Mar-2012</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>27-Mar-2012</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>29-Nov-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>QUALCOMM INCORPORATED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>5775 MOREHOUSE DRIVE, SAN DIEGO, CALIFORNIA 92121-1714,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>NAGARAJ THADI M.</td>
											<td>11820-2 CYPRESS CANYON ROAD, SAN DIEGO, CALIFORNIA 92121</td>
										</tr>
										<tr>
											<td>2</td>
											<td>SILBERGER AMNON</td>
											<td>8779 GILMAN DRIVE #A, SAN DIEGO, CALIFORNIA 92037</td>
										</tr>
										<tr>
											<td>3</td>
											<td>COLLINS BRUCE</td>
											<td>11730 ANGELIQUE STREET, SAN DIEGO, CALIFORNIA 92131</td>
										</tr>
										<tr>
											<td>4</td>
											<td>WALKER GORDON KENT</td>
											<td>14484 HUNTINGTON GATE DRIVE, POWAY, CALIFORNIA 92064</td>
										</tr>
										<tr>
											<td>5</td>
											<td>LOUKAS MIKE</td>
											<td>6351 PASEO SERRO, CARLSBAD, CALIFORNIA 92009</td>
										</tr>
										<tr>
											<td>6</td>
											<td>RAVEENDRAN VIJAYALAKSHMI R.</td>
											<td>4272 CALLE MAR DE BALLENAS, SAN DIEGO, CALIFORNIA 92130</td>
										</tr>
										<tr>
											<td>7</td>
											<td>.</td>
											<td>4460 CALLE MAR DE ARMONIA, SAN DIEGO, CALIFORNIA 92130</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04L12/66</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2006/018853</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2006-05-15</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/789,454</td>
									<td>2006-04-04</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/680,809</td>
									<td>2005-05-13</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/251638-improving-error-resilience-using-out-of-band-directory-information by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:48:38 GMT -->
</html>
