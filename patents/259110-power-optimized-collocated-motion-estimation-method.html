<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/259110-power-optimized-collocated-motion-estimation-method by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:15:28 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 259110:POWER OPTIMIZED COLLOCATED MOTION ESTIMATION METHOD</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">POWER OPTIMIZED COLLOCATED MOTION ESTIMATION METHOD</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The present invention relates to a method of motion estimation for use in a device adapted to process a sequence of frames, a frame being divided into blocks of data samples. Said motion estimation method comprises a step of computing a residual error block associated with a motion vector candidate (MV) on the basis of a current block (cb) contained in a current frame (CF) and of a reference block (rb) contained in a reference frame (RF), said reference block having a same position in the reference frame as the current block has in the current frame. The motion vector candidate defines a relative position of a virtual block (vb) containing a first reference portion (rbp1) of the reference block with reference to said reference block. The residual error block is then computed from a first difference between data samples of the first reference portion and corresponding data samples of a first current portion (cbp1) of the current block, and a second difference between a prediction of data samples of a second reference portion (pred) of the virtual block, which is complementary to the first reference portion, and data samples of a second current portion (cbp2) of the current block, which is complementary to the first current portion.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Power optimized collocated motion estimation method<br>
FIELD OF THE INVENTION<br>
The present invention relates to a motion estimation method and device adapted to process a sequence of frames, a frame being divided into blocks of data samples.<br>
The present invention relates to a predictive block-based encoding method comprising such a motion estimation method. It also relates to the corresponding encoder.<br>
The present invention finally relates to a computer program product for implementing said motion estimation method.<br>
This invention is particularly relevant for products embedding a digital video encoder such as, for example, home servers, digital video recorders, camcorders, and more particularly mobile phones or personal digital assistants, said apparatus comprising an embedded camera able to acquire and to encode video data before sending it.<br>
BACKGROUND OF THE INVENTION<br>
In a conventional video encoder, most of the memory transfers and, as a consequence, a large part of the power consumption, come from motion estimation. Motion estimation consists in searching for the best match between a current block and a set of several candidate reference blocks according to a rate distortion criterion, a difference between the current block and a candidate reference block forming a residual error block from which a distortion value is derived. However, such a motion estimation method is not optimal, especially in the case of a video encoder embedded in a portable apparatus having limited power.<br>
Several authors have developed low-power methods. Some of them propose computational simplifications: such methods are not sufficient anymore. Others try to minimize memory accesses.<br>
In the spatial domain, the paper entitled "A Low Power Video Encoder with Power, Memory and Bandwidth Scalability", by N. Chaddha and M. Vishwanath, 9th International Conference on VLSI Design, pp. 358-263, January 1996, proposes a technique based on hierarchical vector quantization which enables the ability for the encoder to change its power consumption depending on the available bandwidth and on the required video quality.<br>
In the temporal domain, the paper entitled "Motion Estimation for Low-Power Devices", by C. De Vleeschouwer and T. Nilsson, ICIP2001, pp. 953-959, September 2001, proposes to simplify the conventional motion estimation but at the cost of a lower compression performance.<br><br>
Disadvantages of these states of the art are that either the motion estimation method reduces the video quality too much, or that it does not achieve a sufficient memory transfer saving.<br>
SUMMARY OF THE INVENTION<br>
It is an object of the invention to propose an efficient way to reduce memory transfer, while keeping satisfying visual quality.<br>
To this end, the motion estimation method in accordance with the invention is characterized in that it comprises a step of computing a residual error block associated with a motion vector candidate on the basis of a current block contained in a current frame and of a reference block contained in a reference frame, said reference block having a same position in the reference frame as the current block has in the current frame, the motion vector candidate defining a relative position of a virtual block containing a first reference portion of the reference block with reference to said reference block, the residual error block being computed from:<br>
a first difference between data samples of the first reference portion and corresponding data samples of a first current portion of the current block, and<br>
a second difference between a prediction of data samples of a second reference portion of the virtual block, which is complementary to the first reference portion, and data samples of a second current portion of the current block, which is complementary to the first current portion.<br>
On the one hand, the motion estimation method in accordance with the invention uses only a restricted set of data samples, which is a reference block having a same position in the reference frame as the current block has in the current frame. Said reference block is also called the collocated block. Thanks to the use of said reduced set of data samples, the motion estimation method according to the invention is an efficient way to reduce memory transfer at the encoder and at the decoder. Moreover, reducing the energy dissipation of a corresponding video encoding circuit increases the reliability of said circuit and allows a significant attenuation of the cooling effort. Therefore production costs are greatly lowered.<br>
On the other hand, said motion estimation method is adapted to determine a motion vector between the first reference portion of the reference block and the first current portion of the current block, i.e. by only taking into account portions of said current and reference blocks which are similar. Said motion vector can vary from (-N+l,-N+l) to (N-1,N-1) if the reference block comprises NxN data samples. In addition, the motion estimation method is<br><br>
adapted to predict missing data samples, i.e. the data samples that belong to the second reference portion of the virtual block. As we will see in further detail later on, this prediction can be done according to different modes. Thanks to the determination of a motion vector and to the prediction of corresponding missing data samples, the motion estimation method according to the invention is capable of keeping a satisfying visual quality.<br>
These and other aspects of the invention will be apparent from and will be elucidated with reference to the embodiments described hereinafter.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
The present invention will now be described in more detail, by way of example, with<br>
reference to the accompanying drawings, wherein:<br>
Fig. 1 is a block diagram of a conventional video encoder,<br>
Fig. 2 illustrates a conventional motion estimation method,<br>
Figs. 3A and 3B illustrate the motion estimation method in accordance with the<br>
invention,<br>
Fig. 4 corresponds to a first embodiment of said motion estimation method,<br>
Fig. 5 corresponds to a second embodiment of said motion estimation method, and<br>
Fig. 6 corresponds to a third embodiment of said motion estimation method.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
The present invention relates to a method of motion estimation for use in a device adapted to process a sequence of frames, a frame being divided into blocks of data samples, for example pixels in the case of video data samples. Said device is, for example, an encoder adapted to encode said sequence of frames.<br>
The present invention is more especially dedicated to the encoding of video frames. It can be used within MPEG-4 or H.264 video encoder, or any equivalent distortion-based video encoder. However, it will be apparent to a person skilled in the art that it is also applicable to the encoding of a sequence of audio frames or any other equivalent encoding.<br>
It is to be noted that the present invention is not limited to encoding but can be applied to other types of processing, such as for example, image stabilization wherein an average of the different data blocks of a video frame is computed in order to determine a global motion of said frame. Such an image stabilization process can be implemented in a camcorder, in a television receiver, or in a video decoder after the decoding of an image.<br><br>
The motion estimation method may be implemented in handheld devices, such as mobile phones or embedded cameras, which have limited power and which are adapted to encode sequences of video frames.<br>
Fig. 1 depicts a conventional video encoder for encoding an input data block IN. Said encoder comprises:<br>
a subtractor for delivering a main residual error block,<br>
a discrete cosine transform DCT unit (11) and a quantizing Q unit (12) for transforming and quantizing successively the main residual error block,<br>
a variable length coding VLC unit (13) for delivering a variable length coded data block from the quantized data block,<br>
an inverse quantizing IQ unit (14) and inverse discrete cosine transform IDCT unit (15) for delivering an auxiliary residual error block from the quantized data block,<br>
a motion compensation MC unit (16) for delivering a motion compensated data block to an adder and to the subtractor using a motion vector, the subtractor being adapted to subtract the motion compensated data block from the input data block,<br>
an adder for summing the motion compensated data block and the auxiliary residual error block,<br>
a motion estimation ME unit (18) for finding, in a reference frame, a reference data block associated to the input data block, as well as its corresponding motion vector, and<br>
an external frame memory module MEM (17) to which the motion compensation and motion estimation units are coupled.<br>
These conventional encoders are based on DCT transformation, scalar quantization, and motion estimation/compensation (ME/MC). The latter is clearly the most power consuming. When a block is encoded, the motion estimation unit ME looks for the best match for a current block cb in a current frame CF, among several blocks belonging to a search area SA in reference frames RFl to RF3, as shown in Figure 2. This represents many accesses to pixels, and so to the memory. The larger the search area is, the larger the size of the memory and consequently the power dissipation.<br>
The present invention proposes to replace the conventional motion estimation by a so-called 'collocated motion estimation', which is a restricted way of doing motion estimatipn, with a search area comprising a reduced set of pixels. In order to maintain a correct encoding<br><br>
efficiency while using less data, it is here proposed to modify the motion estimation process, and to mix it with a spatio-temporal prediction of missing pixels.<br>
Figs. 3A and 3B illustrate the motion estimation method in accordance with the invention.<br>
Said motion estimation method comprises a step of dividing a frame into blocks of pixels of equal size, for example of NxN pixels, where N is an integer.<br>
Then it comprises a step of computing a residual error block associated with a motion vector candidate MV on the basis of a current block cb contained in a current frame CF and of a reference block rb contained in a reference frame RF. According to the invention, the reference block has the same position (i j) in the reference frame as the current block has in the current frame. In other words, the reference block is colloated to the current block. The motion vector candidate MV defines a relative position of a virtual block vb containing a first reference portion rbpl of the reference block rb with reference to said reference block.<br>
The residual error block is then computed from:<br>
a first difference between data samples of the first reference portion rbpl and corresponding data samples of a first current portion cbpl of the current block, the first current portion cpbl corresponding to a translation of the projection in the current frame of the first reference portion according to the motion vector candidate MV, and<br>
a second difference between a prediction of data samples of a second reference portion pred of the virtual block, which is complementary to the first reference portion, and data samples of a second current portion cbp2 of the current block, which is complementary to the first current portion.<br>
In other words, let us note r(x,y) the residual error block value of a pixel of position (x,y) that will be encoded. The residual error block value is computed as follows:<br>
r(x,y) = if(x + vx,y + vy)ε rb<br>
rb(x + vx,y + vy)-cb(x,y)<br>
else<br>
pred(rb,cb(x,y))<br>
where pred(rb,cb(x,y)) is a predictor that uses the reference block and the current block to be encoded, and where (vx,vy) are the coordinates of the motion vector.<br>
In general, values of pixels of the second reference portion pred are predicted from values of pixels of the reference block rb but this is not mandatory, as we will see later on.<br><br>
Such a motion estimation method is called collocated motion estimation method. With said collocated motion estimation, the best match of the current block cb, i.e. the block to be encoded, is searched in the reference block rb. To this end, said motion estimation method is adapted to test different motion vector candidates MV between a first reference portion of the reference block and a first current portion of the current block, a predetermined motion vector candidate corresponding to portions of predetermined size. Said motion vector candidate can thus vary from a motion vector Mvmin of coordinates (-N+1, -N+l) to a motion vector Mvmax of coordinates (N-l, N-l) if the reference block comprises NxN pixels.<br>
The step of computing a residual error block is repeated for a set of motion vector candidates. The motion estimation method in accordance with the invention further comprises a step of computing a distortion value for the motion vector candidates of the set on the basis of their associated residual error block values. The motion estimation method finally comprises a step of selecting the motion vector candidate having the smallest distortion value.<br>
This process is called block matching and is based, for example, on the computing of the sum of absolute differences SAD according to a principle known to a person skilled in the art. The computing step is based, as other examples, on the computing of the mean absolute error MAE on the computing of the mean square error MSE. It will be apparent to a person skilled in the art that the distortion value can be computed using other equivalent calculations. For example, it can be based on a sum of an entropy h of the residual error block and on the mean square error MSE.<br>
The residual error block and the selected motion vector are transmitted according to a conventional encoding scheme.<br>
Except for the motion vector candidate (0,0), some pixels are always missing for the computation of the distortion value. Several ways of predicting the missing pixels can be used.<br>
Fig. 4 illustrates a first embodiment of said motion estimation method called collocated prediction. In such an embodiment, a value of a pixel p' of the second reference portion pred is derived from a value of the pixel corresponding to a translation of the pixel of the second reference portion according to the opposite of the motion vector candidate MV. In other words, the missing pixel p' is predicted on the basis of the pixel rb(x,y) collocated to the current pixel cb(x,y) as follows:<br><br>
pred(rb, cb(x, y)) = rb(x, y) - cb(x, y).<br>
It is to be noted in Figs. 4 to 6 that the arrow diffl represents the computation of the first difference between pixels of the first reference portion rbpl and corresponding pixels of the first current portion cbpl and that the arrow dif£2 represents the computing of the second difference.<br>
Fig. 5 illustrates a second embodiment of the motion estimation method called edge prediction. In such an embodiment, a value of a pixel of the second reference portion is predicted on the basis of a first interpolation of a pixel value of the reference block. Said prediction is defined as follows:<br>
pred(rb,cb(x,y)) = rb(proj(x),proj(y))-cb(x,y),<br>
where the projO function is adapted to determine the symmetric p" of the pixel p' of the second reference portion pred with reference to a horizontal and/or vertical edge of the reference block and to take the value of said symmetric pixel p" as the reference value rb(x",y"), as shown in Fig. 5.<br>
Fig. 6 illustrates a third embodiment of said motion estimation method. It is called spatial interpolation prediction. In this embodiment, a value of a pixel of the second reference portion pred is derived from an interpolation of values of several pixels of the first reference portion. For example, the value of the pixel p' of the second reference portion is interpolated from the pixels belonging to the reference block rb that are on the same line or column as the pixel p'.<br>
According to another embodiment of the invention, a single prediction value pred_value is derived from the reference block rb. The corresponding residual error block value is computed as follows:<br>
r(x, y) = cb(x, y) - pred _ value<br>
pred_value is set to the mean of the reference block rb values or the median of said values.<br>
Still according to another embodiment of the invention, strictly spatial prediction is performed. In that case, the reference block is not used. The prediction value pred_value is an average or a median value of a line L of pixels on top of the current block or of a column C of pixels at the left of the current block as shown on Fig. 3 A. As another option, the prediction value can be a constant value, 128 for example if pixel values are comprised between 0 and 255.<br>
It will be apparent to a person skilled in the art that other methods can be proposed to determine the prediction value. For instance, it can be the most frequent value, i.e. the peak<br><br>
of an histogram of the reference block rb, or a value related to the line L, the column C and/or the reference block rb.<br>
The drawings and their description hereinbefore illustrate rather than limit the invention. It will be evident to a person skilled in the art that there are numerous alternatives that fall within the scope of the appended claims.<br>
For example the motion estimation method in accordance with the invention can be used either with only one prediction function, or with several prediction functions as above described, each prediction function being concurrent, as well as motion vectors are themselves concurrent, and selected via the distortion criterion.<br>
The collocated motion search can be based on a three-dimensional recursive search 3DRS, or a Hierarchical Block Matching Algorithm HBMA algorithm. Sub-pixel refinement can be adopted in the same way. The motion is not restricted to a translation; it can support affine models for instance.<br>
The proposed invention can be applied in any video encoding device were accesses to an external memory represent a bottleneck, either because of limited bandwidth or because of high power consumption. The latter reason is especially crucial in mobile devices, where extended battery lifetime is a key feature. It replaces the conventional motion estimation in any kind of encoder. It can be used, for example, in net-at-home, or transcoding applications.<br>
The motion estimation method in accordance with the invention can be implemented by means of items of hardware or software, or both. Said hardware or software items can be implemented in several manners, such as by means of wired electronic circuits or by means of an integrated circuit that is suitable programmed, respectively. The integrated circuit can be contained in an encoder. The integrated circuit comprises a set of instructions. Thus, said set of instructions contained, for example, in an encoder memory may cause the encoder to carry out the different steps of the motion estimation method. The set of instructions may be loaded into the programming memory by reading a data carrier such as, for example, a disk. A service provider can also make the set of instructions available via a communication network such as, for example, the Internet.<br>
Any reference sign in the following claims should not be construed as limiting the claim. It will be obvious that the use of the verb "to comprise" and its conjugations do not<br><br>
exclude the presence of any other steps or elements besides those defined in any claim. The word "a" or "an" preceding an element or step does not exclude the presence of a plurality of such elements or steps.<br>
CLAIMS<br>
1	A method of motion estimation for use in a device adapted to process a sequence of<br>
 frames, a frame being divided into blocks of data samples, said motion estimation method<br>
 comprising a step of computing a residual error block associated with a motion vector<br>
 candidate (MV) on the basis of a current block (cb) contained in a current frame (CF) and of<br>
 a reference block (rb) contained in a reference frame (RF), said reference block having a<br>
 same position in the reference frame as the current block has in the current frame, the motion<br>
 vector candidate defining a relative position of a virtual block (vb) containing a first<br>
 reference portion (rbpl) of the reference block with reference to said reference block, the<br>
 residual error block being computed from:<br>
a first difference between data samples of the first reference portion and corresponding data samples of a first current portion (cbpl) of the current block, and<br>
a second difference between a prediction of data samples of a second reference portion (pred) of the virtual block, which is complementary to the first reference portion, and data samples of a second current portion (cbp2) of the current block, which is complementary to the first current portion.<br>
2	A motion estimation method as claimed in claim 1, wherein data samples values of<br>
3	 the second reference portion are predicted from data samples values of the reference block.<br>
4	A motion estimation method as claimed in claim 2, wherein a data sample value of the<br>
5	 second reference portion is derived from a data sample value of the reference block which is<br>
6	 collocated to a current data sample of the current block.<br>
7	A motion estimation method as claimed in claim 2, wherein a data sample value of the<br>
8	 second reference portion is derived from an interpolation of at least one data sample value of<br>
9	 the reference block.<br>
10	A motion estimation method as claimed in claim 1, wherein the step of computing a<br>
11	 residual error block is repeated for a set of motion vector candidates, the motion estimation<br>
12	 method further comprising a step of computing a distortion value for the motion vector<br>
13	 candidates of the set on the basis of their associated residual error block values.<br><br>
14	A motion estimation method as claimed in claim 5, further comprising a step of<br>
15	 selecting the motion vector candidate having the smallest distortion value.<br>
16	A motion estimation method as claimed in claim 6, wherein the second difference is<br>
17	 computing according to different prediction modes, which are concurrent for the selection of<br>
18	 the motion vector candidate having the smallest distortion value.<br>
19	A predictive block-based encoding method for encoding a sequence of frames, said<br>
20	 encoding method comprising a motion estimation method as claimed in claim 1 for<br>
21	 computing a motion vector to a desired accuracy, said encoding method further comprising a<br>
22	 step of coding said motion vector and its associated residual error block.<br>
23	A motion estimation device adapted to process a sequence of frames, a frame being<br>
24	 divided into blocks of data samples, said device comprising means for computing a residual<br>
25	 error block associated with a motion vector candidate (MV) on the basis of a current block<br>
26	 (cb) contained in a current frame and of a reference block (rb) contained in a reference frame,<br>
27	 said reference block having a same position in the reference frame as the current block has in<br>
28	 the current frame, the motion vector candidate defining a relative position of a virtual block<br>
29	 (vb) containing a portion (rbpl) of the reference block with reference to said reference block,<br>
30	 the computing means being configured such that the residual error block is computed from:<br>
a first difference between data samples of the first reference portion and corresponding data samples of a first current portion (cbpl) of the current block, and<br>
a second difference between a prediction of data samples of a second reference portion (pred) of the virtual block, which is complementary to the first reference portion, and data samples of a second current portion (cbp2) of the current block, which is complementary to the first current portion.<br>
10	An encoder for encoding a sequence of frames comprising a motion estimation device<br>
11	 as claimed in claim 9 for computing a motion vector to a desired accuracy, and means for<br>
12	 coding said motion vector and its associated residual error block.<br>
13	A computer program product comprising program instructions for implementing,<br>
14	 when said program is executed by a processor, a motion estimation method as claimed in<br>
15	 claim 1.<br>
Dated   this    25    day of   April   2006<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgIEVYQU1JTkFUSU9OIFJFUE9SVCBSRVBMWSBSRUNFSVZFRC4gICAwMi0xMS0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006    EXAMINATION REPORT REPLY RECEIVED.   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgIEZPUk0tMSAgIDAyLTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006    FORM-1   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgIEZPUk0tMyAgIDAyLTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006    FORM-3   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgIEZPUk0tNSAgIDAyLTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006    FORM-5   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgIE9USEVSIFBBVEVOVCBET0NVTUVOVCAgIDAyLTExLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006    OTHER PATENT DOCUMENT   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgQU1FTkRFRCBDTEFJTVMgICAwMi0xMS0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   AMENDED CLAIMS   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgQU1FTkRFRCBQQUdFUyBPRiBTUEVDSUZJQ0FUSU9OICAgMDItMTEtMjAxMi5wZGY=" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   AMENDED PAGES OF SPECIFICATION   02-11-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgQVNTSUdOTUVOVCAgMzEtMTAtMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   ASSIGNMENT  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgQ09SUkVTUE9OREVOQ0UgT1RIRVJTICAwNC0xMC0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   CORRESPONDENCE OTHERS  04-10-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgQ09SUkVTUE9OREVOQ0UgT1RIRVJTICAyNi0xMi0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   CORRESPONDENCE OTHERS  26-12-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgQ09SUkVTUE9OREVOQ0UgT1RIRVJTICAzMS0xMC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   CORRESPONDENCE OTHERS  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgRk9STS0xICAzMS0xMC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   FORM-1  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgRk9STS0yICAzMS0xMC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   FORM-2  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgRk9STS01ICAzMS0xMC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   FORM-5  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgRk9STS02ICAzMS0xMC0yMDEzLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   FORM-6  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICAgUE9XRVIgT0YgQVRUT1JORVkgIDMxLTEwLTIwMTMucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006   POWER OF ATTORNEY  31-10-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBBTUVOREVEIENMQUlNUyAgMjYtMTItMjAxMi5wZGY=" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  AMENDED CLAIMS  26-12-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBBTUVOREVEIENMQUlNUyAgMjktMDctMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  AMENDED CLAIMS  29-07-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBBU1NJR05NRU5UICAxNC0wNi0yMDEwLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  ASSIGNMENT  14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBDT1JSRVNQT05ERU5DRSBPVEhFUlMgMjktMDctMjAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  CORRESPONDENCE OTHERS 29-07-2013.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2ICBmb3JtLTEgIDE0LTA2LTIwMTAucGRm" target="_blank" style="word-wrap:break-word;">1408-chenp-2006  form-1  14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBGT1JNLTEzICAxNi0wNC0yMDA3LnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  FORM-13  16-04-2007.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBGT1JNLTE4ICAyMy0xMC0yMDA3LnBkZg==" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  FORM-18  23-10-2007.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBGT1JNLTIgIDE0LTA2LTIwMTAucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  FORM-2  14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBGT1JNLTUgIDI2LTEyLTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  FORM-5  26-12-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBGT1JNLTYgIDA3LTAyLTIwMDgucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  FORM-6  07-02-2008.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBGT1JNLTYgIDE0LTA2LTIwMTAucGRm" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  FORM-6  14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1DSEVOUC0yMDA2ICBQT1dFUiBPRiBBVFRPUk5FWSAgMTQtMDYtMjAxMC5wZGY=" target="_blank" style="word-wrap:break-word;">1408-CHENP-2006  POWER OF ATTORNEY  14-06-2010.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWNvcnJlc3BvbmRuZWNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWZvcm0gMjYucGRm" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTQwOC1jaGVucC0yMDA2LXBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">1408-chenp-2006-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="259109-process-for-treating-cracked-naphtha-streams.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="259111-monoclonal-antibodies-to-hepatocyte-growth-factor.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>259110</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1408/CHENP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>09/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>28-Feb-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>25-Feb-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>25-Apr-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>ENTROPIC COMMUNICATIONS, INC</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>6290 SEQUENCE DRIVE SAN DIEGO, CA 92121, USA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JUNG, Joël</td>
											<td>JUNG, Joel, c/o Societe Civile SPID, 156 Boulevard Haussmann, F-75008 PARIS</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB2004/003469</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-10-20</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>03300179.3</td>
									<td>2003-10-27</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/259110-power-optimized-collocated-motion-estimation-method by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:15:29 GMT -->
</html>
