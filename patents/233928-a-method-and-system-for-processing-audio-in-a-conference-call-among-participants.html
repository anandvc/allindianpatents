<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/233928-a-method-and-system-for-processing-audio-in-a-conference-call-among-participants by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:58:36 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 233928:A METHOD AND SYSTEM FOR PROCESSING AUDIO IN A CONFERENCE CALL AMONG PARTICIPANTS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A METHOD AND SYSTEM FOR PROCESSING AUDIO IN A CONFERENCE CALL AMONG PARTICIPANTS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The present invention provides a method and system for providing media services in Voice over IP telephony. A switch is coupled between one or more audio sources and a network interface controller. The switch can be a packet switch or a cell switch (304). The present invention further provides a method and system for distributed conference bridge processing in Voice over IP telephony. A distributed conference bridge multi-casts mixed audio content of a conference call in a way that reduces replication work at the mixing device. The present invention also provides a method and system for noiselessly switching between independent audio streams. Such noiseless switching preserves valid RTP information at the time of switch over.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>METHOD AND SYSTEM FOR PROCESSING AUDIO IN A<br>
CONFERENCE CALL AMONG PARTICIPANTS<br>
BACKGROUND OF THE INVENTION<br>
Field of the Invention<br>
The invention relates generally to audio communication over a network.<br>
Background Art<br>
Audio has long been carried in telephone calls over networks. Traditional<br>
circuit-switched time division multiplexing (TDM) networks including public-<br>
switched telephone networks (PSTN) and plain old telephone networks (POTS)<br>
were used. These circuit-switched networks establish a circuit across the network<br>
for each call. Audio is carried in analog and/or digital form across the circuit in<br>
real-time.<br>
The emergence of packet-switched networks, such as the local area<br>
networks (LANs), and the Internet, now requires that audio be carried digitally<br>
in packets. Audio can include but is not limited to voice, music, or other type of<br>
audio data. Voice over Internet Protocol systems (also called Voice over IP or<br>
VOIP systems) transport the digital audip data belonging to a telephone call in<br>
packets over packet-switched networks instead of traditional circuit-switched<br>
networks. In one example, a VOIP system forms two or more connections using<br>
Transmission Control Protocol/Internet Protocol (TCP/IP) addresses to<br>
accomplish a connected telephone call. Devices that connect to a VOIP network<br>
must follow standard TCP/IP packet protocols in order to intemperate with other<br>
devices within the VOIP network. Examples of such devices are IP phones,<br>
integrated access devices, media gateways, and media servers.<br>
A media server is often an endpoint in a VOIP telephone call. The media<br>
server is responsible for ingress and egress audio streams, that is, audio streams<br>
which enter and leave a media server respectively. The type of audio produced<br>
by a media server is controlled by the application that corresponds to the<br>
telephone call such as voice mail, conference bridge, interactive voice response<br>
(IVR), speech recognition, etc. In many applications, the produced audio is not<br>
predictable and must vary based on end user responses. Words, sentences, and<br>
whole audio segments such as music must be assembled dynamically in real time<br>
as they are played out in audio streams.<br>
Packet-switched networks, however, can impart delay and jitter in a<br>
stream of audio carried in a telephone call. A real-time transport protocol (RTP)<br>
is often used to control delays, packet loss and latency in an audio stream played<br>
out of a media server. The audio stream can be played out using RTP over a<br>
network link to a real-time device (such as a telephone) or a non-real-time device<br>
(such as an email client in unified messaging). RTP operates on top of a protocol<br>
such as the User Datagram Protocol (UDP) which is part of the IP family. RTP<br>
packets include among other things a sequence number and a timestamp. The<br>
sequence number allows a destination application using RTP to detect the<br>
occurrence of lost packets and to ensure a correct order of packets are presented<br>
to a user. The timestamp corresponds to the time at which the packet was<br>
assembled. The timestamp allows a destination application to ensure<br>
synchronized play-out to a destination user and to calculate delay and jitter. See,<br>
D. Collins, Carrier Grade Voice over IP,Mc-Grsw Hill: United States, Copyright<br>
2001, pp. 52-72, the entire book of which is incorporated in its entirety herein by reference.<br>
A media server at an endpoint in a VOIP telephone call uses protocols<br>
such as RTP to improve communication quality for a single audio stream. Such<br>
media servers, however, have been limited to outputting a single audio stream of<br>
RTP packets for a given telephone call.<br>
A conference call links multiple parties over a network in a common call.<br>
Conference calls were originally carried out over a circuit-switched network such<br>
as a plain old telephone system (POTS) or public switched telephone network<br>
(PSTN). Conference calls are now also carried out over packet-switched<br>
networks, such as local area networks (LANs) and the Internet. Indeed, the<br>
emergence of voice over the Internet systems (also called Voice over IP or VOIP<br>
systems) has increased the demand for conference calls over networks.<br>
Conference bridges connect participants in conference calls. Different<br>
types of conference bridges have been used depending in part upon the type of<br>
network and how voice is carried over the network to the conference bridge. One<br>
type of conference bridge is described in U.S. Pat. No. 5,436,896 (see the entire<br>
patent). This conference bridge 10 operates in an environment where voice<br>
signals are digitally encoded in a 64Kbps data stream (FIG. 1, col. 1, Ins. 21-26).<br>
Conference bridge 10 has a plurality of inputs 12 and outputs 14. Inputs 12 are<br>
connected through respective speech detectors 16 and switches 18 to a common<br>
summing amplifier 20. Speech detector 16 detects speech by sampling an input<br>
data stream and determining the amount of energy present over time. (col. 1, Ins.<br>
36-39). Each speech detector 16 controls a switch 18. When no speech is present<br>
switch 18 is held open to reduce noise. During a conference call, inputs 12 of all<br>
participants who are speaking are coupled through summing amplifier 20 to each<br>
of the outputs 14. Subtracters 24 subtract each participant's own voice data<br>
stream. A number of participants 1-n then can speak and hear each other in the<br>
connections made through conference bridge 10. See, '896 patent, col. 1, In, 12-<br>
col. 2, In. 16.<br>
Digitized voice is now also being carried in packets over packet-switched<br>
networks. The '896 patent describes one example of asynchronous mode transfer<br>
(ATM) packets (also called cells). To support a conference call in this<br>
networking environment, conference bridge 10 converts input ATM cells to<br>
network packets. Digitized voice is extracted from the packets and processed in<br>
conference bridge 12 as described above. The summed output digitized voices<br>
is re-converted from network packets back to ATM cells prior to being sent to<br>
participants 1-n. See, '896 patent, col. 2, In. 17-col. 2, In. 36.<br>
The '896 patent also describes a conference bridge 238 shown in FIGs. 2<br>
and 3 which processes ATM cells without converting and re-converting the ATM<br>
cells to network packets as in conference 10. Conference bridge 238 has inputs<br>
302-306, one from each of the participants, and outputs 308-312, one to each of<br>
the participants. Speech detectors 314-318 analyze input data aggregated in<br>
sample and hold buffers 322-326. Speech detectors 314-318 report the detected<br>
speech an/or volume of detected speech to controller 320. See, 4896 patent, col.<br>
4, Ins. 26-39.<br>
Controller 320 is coupled to a selector 328, gain control 329 and replicator<br>
330. Controller 320 determines which of the participants is speaking based on<br>
the outputs of speech detectors 314-318. When one speaker (such as participant<br>
1) is talking, controller 320 sets selector 328 to read data from buffer 322. The<br>
data moves through automatic gain control 329 to replicator 330. Replicator<br>
replicates the data in the ATM cell selected by selector 328 for all participants<br>
except the speaker. See, '896 patent, col. 4, In. 40-col. 5, In. 5. When two or<br>
more speakers are speaking, the loudest speaker is selected in a given selection<br>
period. The next loudest speaker is then selected in a subsequent selection<br>
period. The appearance of simultaneous speech is kept up by scanning speech<br>
detectors 314-318 and reconfiguring selector 328 at appropriate interval such as<br>
six milliseconds. See, '896 patent, col. 5, Ins. 6-65.<br>
Another type of conference bridge is described in U.S. Pat. No. 5,983,192<br>
(see the entire patent). In one embodiment, a conference bridge 12 receives<br>
compressed audio packets through a real-time transport protocol (RTP/RTCP).<br>
See, '192 patent, col. 3, In. 66-col. 4, In. 40. Conference bridge 12 includes<br>
audio processors 14a-14d. Exemplary audio processor 14c associated with a site<br>
C (i.e., a participant C) includes a switch 22 and selector 26. Selector 26 includes<br>
a speech detector which determines which of other sites A, B, or D has the<br>
highest likelihood of speech. See, '192 patent, col. 4, Ins. 40-67. Alternatives<br>
include selecting more than one site and using an acoustic energy detector. See,<br>
' 192 patent, col. 5, Ins. 1-7. In another embodiment described in the' 192 patent,<br>
the selector 26/switches 22 output a plurality of loudest speakers in separate<br>
streams to local mixing end-point sites. The loudest streams are sent to multiple<br>
sites. See, '192 patent, col. 5, Ins. 8-67. Configurations of mixer/encoders are<br>
also described to handle multiple speakers at the same time, referred to as<br>
"double-talk" and "triple-talk." See, '192 patent, col. 7, In. 20-col. 9, In. 29.<br>
Voice-over-the-Intemet (VOIP) systems continue to require an improved<br>
conference bridge. For example, a Softswitch VOIP architecture may use one or<br>
more media servers having a media gateway control protocol such as MGCP<br>
(RFC 2705). See, D. Collins, Carrier Grade Voice over IP, Mc-Graw Hill:<br>
United States, Copyright 2001, pp. 234-244, the entire book of which is<br>
incorporated in its entirety herein by reference. Such media servers are often used<br>
to process audio streams in VOIP calls. These media servers are often endpoints<br>
where audio streams are mixed in a conference call. These endpoints are also<br>
referred to as "conference bridge access points" since the media server is an<br>
endpoint where media streams from multiple callers are mixed and provided<br>
again to some or all of the callers. See, D. Collins, p. 242.<br>
As the popularity and demand for IP telephony and VOIP calls increases,<br>
media servers are expected to handle conference call processing with carrier<br>
grade quality. Conference bridges in a media server need to be able to scale to<br>
handle different numbers of participants. Audio in packet streams, such as<br>
RTP/RTCP packets, needs to be processed in real-time efficiently.<br>
BRIEF SUMMARY OF THE INVENTION<br>
The present invention provides a method and system for providing media<br>
services in Voice over IP telephony. In one embodiment, a switch is coupled<br>
between multiple audio sources and a network interface controller. The switch<br>
can be a packet switch or a cell switch. Internal and/or external audio sources<br>
generate audio streams of packets. Any type of packet can be used. In one<br>
embodiment, an internal packet includes a packet header and a payload.<br>
In one embodiment, the packet header has information that identifies<br>
active speakers whose audio is mixed. The payload carries the digitized mixed<br>
audio. According to a feature of the present invention, one fully mixed audio<br>
stream of packets and a number of partially mixed audio streams of packets are<br>
generated by an audio source (e.g. a DSP). The fully mixed audio stream<br>
includes the audio content of a group of identified active speakers. Packet header<br>
information identifies each of the active speakers in the fully mixed stream. In<br>
one example, the audio source inserts conference identification numbers (CIDs)<br>
associated with the respective active speakers into header fields in the packets.<br>
The audio source inserts mixed digital audio from the active speakers into the<br>
payload of the packets. The mixed digital audio corresponds to speech or other<br>
type of audio that is input by the active speakers in the conference call.<br>
Each of the partially mixed audio streams includes the audio content of<br>
the group of identified active speakers minus the audio content of a respective<br>
recipient active speaker. The recipient active speaker is the active speaker within<br>
the group of active speakers towards which a partially mixed audio stream is<br>
directed. The audio source inserts into the packet payloads the digital audio from<br>
the group of identified active speakers minus the audio content of the recipient<br>
active speaker. In this way, the recipient active speaker will not receive audio<br>
corresponding to their own speech or audio input. Packet header information<br>
identifies the active speakers whose audio content is included in the respective<br>
partially mixed audio stream. In one example, the audio source inserts one or<br>
more conference identification numbers (CIDs) into TAS and IAS header fields<br>
of packets. The TAS (Total Active Speakers) field lists CIDs of all of the current<br>
active speaker calls in the conference call. The IAS field (Included Active<br>
Speakers) lists CIDs of the active speakers whose audio content is in the<br>
respective partially mixed stream. In one embodiment, the audio source (or<br>
"mixer" since it is mixing audio) dynamically generates the appropriate fully<br>
mixed and partially mixed audio streams of packets having CDD information and<br>
mixed audio during the conference call. The audio source retrieves the<br>
appropriate CID information of conference call participants from a relatively<br>
static look-up table generated and stored at the initiation of the conference call.<br>
For example, in a conference call where there are 64 participants of which<br>
3 are identified as active speakers (1-3), then one fully mixed audio stream will<br>
contain audio from all 3 active speakers. This fully mixed stream is eventually<br>
sent to each of the 61 passive participants. Three partially mixed audio streams<br>
are also generated. A first partially mixed stream 1 contains audio from speakers<br>
2-3 but not speaker 1. A second partially mixed stream 2 contains audio from<br>
speakers 1-3 but not speaker 2. A third partially mixed stream 3 contains audio<br>
from speakers 1 -2 but not speaker 3. The first through third partially mixed audio<br>
streams are eventually sent to speakers 1-3 respectively. In this way only four<br>
mixed audio streams need be generated by the audio source.<br>
The fully mixed audio stream and a number of partially mixed audio<br>
streams are sent from the audio sources (e.g. DSPs) to a packet switch. A cell<br>
layer can also be used. The packet switch multicasts each fully mixed and<br>
partially mixed audio stream to a network interface controller (NIC). The NIC<br>
then processes each packet to determine whether to forward the packet for the<br>
fully mixed or partially mixed audio stream to a participant. This determination<br>
can be made in real-time based on a look-up table at the NIC and the packet<br>
header information in the multicasted audio streams.<br>
In one embodiment, during initialization of the conference call, each<br>
participant in the call is assigned a CID. A switched virtual circuit (SVC) is also<br>
associated with the conference call participant. A look-up table is generated and<br>
stored which includes entries for the conference call participants. Each entry<br>
includes the network address information (e.g, IP, UDP address information) and<br>
CID of a respective conference call participant. Look-up tables can be stored for<br>
access by both the NIC processing packets and the audio source(s) mixing audio<br>
during a conference call.<br>
The packet switch multicasts each fully mixed and partially mixed audio<br>
stream on all of the SVCs assigned to the conference call to the NIC. The NIC<br>
processes each packet arriving on the SVCs and in particular examines packet<br>
headers to determine whether to discard or forward the packet for the fully mixed<br>
or partially mixed audio stream to a participant. One advantage of the present<br>
invention is that this packet processing determination can be performed quickly<br>
and in real-time during a conference call based on packet header information and<br>
CID information obtained from the lookup table. In one embodiment, the<br>
network packet which is sent includes the participant's network address<br>
information (IP/UDP) obtained from the look-up table, RTP packet header<br>
information (timestamp/sequence information), and audio data.<br>
In sum, advantages of the present invention include providing conference<br>
bridge processing using fewer resources with less bandwidth and processing than<br>
is typically required in mixing devices in other conference bridges. A conference<br>
bridge system and method of the present invention multicasts in a way that<br>
relieves the mixing device of the work of replication. For a conference call with<br>
N participants and c active speakers, an audio source only needs to generate c +<br>
1 mixed audio streams (one fully mixed audio stream and c partially mixed audio<br>
streams). Work is distributed to the a multicaster in a switch which performs<br>
replication and multicasts the mixed audio streams. A further advantage is that<br>
a conference bridge according to the present invention can scale to accommodate<br>
large numbers of participants. For example, if N = 1000 participants, and c = 3<br>
active speakers then an audio source only need generate c + 1 = 4 mixed audio<br>
streams. Packets in multicasted audio streams are processed at a NIC in real-time<br>
to determine the appropriate packets for output to a participant in the conference<br>
call. In one example, internal egress packets having a header and payload are<br>
used in the conference bridge to further reduce processing work at an audio<br>
source mixing the audio for the conference call.<br>
In addition, as the use of audio networking increases and the number of<br>
users and applications rise, there is an increasing need for multiple audio streams<br>
even in a given telephone call. The inventors recognized that multiple audio<br>
streams need to be switched dynamically without introducing RTP errors in calls<br>
placed in an audio networking environment such as a voice over IP network.<br>
Such RTP errors can cause unwanted noises such as clicks, pops, etc.<br>
The present invention provides a method and system for noiselessly<br>
switching between independent audio streams. Such noiseless switching<br>
preserves valid RTP information at the time of switch over. For established<br>
VOIP calls, the present invention can noiselessly switch audio from one audio<br>
source to another. This switching system is dynamic and can scale to handle<br>
many calls.<br>
In embodiments of the present invention, a switch is used to direct audio<br>
data from multiple audio sources to a network interface controller. The switch<br>
can be a cell switch or a packet switch. The audio sources can be internal audio<br>
sources and/or external audio sources. The network interface controller (NIC)<br>
can be any interface with an IP network and includes one or more packet<br>
processors. An egress audio controller controls the operation of internal audio<br>
sources, the switch and the network interface controller to carry out noiseless<br>
switching according to the present invention.<br>
In one feature of the invention, priority information is used by a network<br>
interface controller to determine which audio stream from an internal or external<br>
audio source is transmitted in an established VOIP telephone call. Consider the<br>
case of two internal audio sources. The audio sources generate respective audio<br>
streams of internal egress packets for one destination egress audio channel. In<br>
one embodiment, each internal egress packet includes a payload carrying audio<br>
and control header information. The control header information has priority<br>
information. This priority information is then used by a network interface<br>
controller to determine which audio stream is transmitted because only one RTP<br>
stream can be output at a given time for each VOIP call.<br>
In one feature of the invention, the internal egress packets are smaller than<br>
IP packets and consist of payload and control header information only. In this<br>
way, processing work required to create complete IP packets need not be carried<br>
out by internal audio sources such as DSPs but is distributed to the packet<br>
processors in the network interface controller.<br>
According to further feature, a cell switch is used which is a fully meshed<br>
cell switch such as an ATM cell switch that has plenty of available bandwidth.<br>
The internal egress packets for the different audio streams are converted to cells.<br>
The cell switch combines merged cells from different sources and delivers them<br>
across a switched virtual circuit (SVC) to a NIC. The SVC is associated with one<br>
egress output audio channel serving an established telephone call.<br>
In one embodiment, an egress audio controller is used to control noiseless<br>
switching of audio in VOIP telephone calls. This noiseless switching according<br>
to the present invention is also referred to herein as a "noiseless switch over." In<br>
one embodiment, noiseless switch over of additional audio is carried out for calls<br>
in which this service is available. In this way, an extra charge may be made for<br>
providing a noiseless switch over service. In other embodiments, noiseless<br>
switch over is performed for any call.<br>
Certain call events which involve additional audio trigger the noiseless<br>
switch over. This noiseless switch over is carried out using the noiseless<br>
switching system and method of the present invention. Examples of call events<br>
include but are not limited to the following conditions: an emergency condition,<br>
a call signaling condition, a call event based on callee or caller information, or a<br>
request for different audio information. The request for audio information can be<br>
any audio request such as a request for advertisements, news sports, financial,<br>
music or other audio content.<br>
Audio sources can generate any type of audio. For example, an audio<br>
stream of egress packets can include audio payloads representing voice, music,<br>
tones, and/or any other sound.<br>
The egress audio controller can be a stand-alone unit or a part of a call<br>
control and audio feature manager in an audio processing platform. The present<br>
invention can be implemented in a media server, audio processor, router, packet<br>
switch, or audio processing platform.<br>
Another embodiment involves the switching of audio streams including<br>
an audio stream from an external audio source. In this case, a NIC receives IP<br>
packets containing the audio stream and converts the IP packets to internal egress<br>
packets. At this point, the internal egress packets are processed as if they were<br>
generated by an internal audio source. The internal egress packets may include<br>
priority information. The internal egress packets may be sent as packets or cells<br>
across a SVC through a switch to the NIC. When the external audio stream has<br>
a relatively high priority and switch over is to proceed, a packet processor at the<br>
NIC generates IP packets with synchronized header information (such as RTP<br>
information) and sends the IP packets to a destination device.<br>
In one embodiment, a noiseless switch over system according to the<br>
invention involves the switching of audio streams only from internal audio<br>
sources such as DSPs. In another embodiment, a noiseless switch over system<br>
according to the invention involves the switching of audio streams from internal<br>
audio sources and external audio sources. In another embodiment, a noiseless<br>
switch over system according to the invention involves the switching of audio<br>
streams only from external audio sources in which case the switch over system<br>
acts a general switch for audio streams and no internal DSPs are required.<br>
Further embodiments, features, and advantages of the present inventions,<br>
as well as the structure and operation of the various embodiments of the present<br>
invention, are described in detail below with reference to the accompanying<br>
drawings.<br>
BRIEF DESCRIPTION OF THE ACCOMPANYING DRAWINGS<br>
The accompanying drawings, which are incorporated herein and form a<br>
part of the specification, illustrate the present invention and, together with the<br>
description, further serve to explain the principles of the invention and to enable<br>
a person skilled in the pertinent art to make and use the invention.<br>
In the drawings:<br>
FIG. 1 is a diagram of a media server in a voice over the Internet example<br>
environment according to the present invention.<br>
FIG. 2 is a diagram of an example media server including media services<br>
and resources according to the present invention.<br>
FIGs. 3 A and 3B are diagrams of an audio processing platform according<br>
to an embodiment of the present invention.<br>
FIG. 4 is a diagram of a audio processing platform as shown in FIG. 3<br>
according to an example implementation of the present invention.<br>
FIG. 5A is a flow diagram showing the establishment of a call and ingress<br>
packet processing according to an embodiment of the present invention.<br>
FIG. 5B is a flow diagram showing egress packet processing and call<br>
completion according to an embodiment of the present invention.<br>
FIGs. 6A-6F are diagrams of noiseless switch over systems according to<br>
embodiments of the present invention.<br>
FIG. 6A is diagram of a noiseless switch over system that carries out cell<br>
switching of independent egress audio streams generated by internal audio<br>
sources according to an embodiment of the present invention.<br>
FIG. 6B is diagram of audio data flow in a noiseless switch over system<br>
that carries out cell switching of independent egress audio streams generated by<br>
internal audio sources according to an embodiment of the present invention.<br>
FIG. 6C is diagram of a noiseless switch over system that carries out cell<br>
switching between independent egress audio streams generated by internal and/or<br>
external audio sources according to an embodiment of the present invention.<br>
FIG. 6D is diagram of audio data flow in a noiseless switch over system<br>
that carries out cell switching between independent egress audio streams<br>
generated by internal and/or external audio sources according to an embodiment<br>
of the present invention.<br>
FIG. 6E is diagram of audio data flow in a noiseless switch over system<br>
that carries out packet switching between independent egress audio streams<br>
generated by internal and/or external audio sources according to an embodiment<br>
of the present invention.<br>
FIG. 6F is diagram of a noiseless switch over system that carries out<br>
switching between independent egress audio streams generated by external audio<br>
sources according to an embodiment of the present invention.<br>
FIG. 7A is a schematic illustration of an IP packet with RTP information.<br>
FIG. 7B is a schematic illustration of an internal packet according to one<br>
embodiment of the present invention.<br>
FIG. 8 is a flow diagram showing the switching functionality according<br>
to one embodiment of the present invention.<br>
FIG. 9A, 9B, and 9C are flow diagrams showing the call event processing<br>
for audio stream switching according to one embodiment of the present invention.<br>
FIG. 10 is a block diagram of a distributed conference bridge according<br>
to one embodiment of the present invention.<br>
FIG. 11 is an example look-up table used in the distributed conference<br>
bridge of FIG. 10.<br>
FIG. 12 is a flowchart diagram of the operation of the distributed<br>
conference bridge of FIG. 10 in establishing a conference call.<br>
FIGs. 13A, 13B, and 13C are flowchart diagrams of the operation of the<br>
distributed conference bridge of FIG. 10 in processing a conference call.<br>
FIG. 14A is a diagram of an example internal packet generated by an<br>
audio source during a conference call according to one embodiment of the present<br>
invention.<br>
FIG. 14B is a diagram that illustrates example packet content in a fully<br>
mixed audio stream and set of partially mixed audio streams according to the<br>
present invention.<br>
FIG. 15 is a diagram that illustrates example packet content after the<br>
packets of FIG. 14 have been multicasted and after they have been processed into<br>
IP packets to be sent to appropriate participants in a 64 participant conference call<br>
according to the present invention.<br>
The present invention will now be described with reference to the<br>
accompanying drawings. In the drawings, like reference numbers indicate<br>
identical or functionally similar elements. Additionally, the left-most digit(s) of<br>
a reference number identifies the drawing in which the reference number first<br>
appears.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
I. Overview and Discussion<br>
The present invention provides a method and system for distributed<br>
conference bridge processing in Voice over IP telephony. Work is distributed<br>
away from a mixing device such as a DSP. In particular, a distributed conference<br>
bridge according to the present invention uses internal multicasting and packet<br>
processing at a network interface to reduce work at an audio mixing device. A<br>
conference call agent is used to establish and end a conference call. An audio<br>
source such as a DSP mixes audio of active conference call participants. Only<br>
one fully mixed audio stream and a set of partially mixed audio streams need to<br>
be generated. A switch is coupled between the audio source mixing audio content<br>
and a network interface controller. The switch includes a multi-caster. The<br>
multi-caster replicates packets in the one fully mixed audio stream and a set of<br>
partially mixed audio streams and multi-casts the replicated packets to links (such<br>
as SVCs) associated with each call participant. A network interface controller<br>
processes each packet to determine whether to discard or forward the packet for<br>
the fully mixed or partially mixed audio stream to a participant. This<br>
determination can be made in real-time based on a look-up table at the NIC and<br>
the packet header information in the multicasted audio streams.<br>
In one embodiment, a conference bridge according to the present<br>
invention is implemented in a media server. According to embodiments of the<br>
present invention, the media server can include a call control and audio feature<br>
manager for managing the operations of the conference bridge.<br>
The present invention is described in terms of an example voice over the<br>
Internet environment. Description in these terms is provided for convenience<br>
only. It is not intended that the invention be limited to application in these<br>
example environments. In fact, after reading the following description, it will<br>
become apparent to a person skilled in the relevant art how to implement the<br>
invention in alternative environments known now or developed in the future.<br>
II. Terminology<br>
To more clearly delineate the present invention, an effort is made<br>
throughout the specification to adhere to the following term definitions as<br>
consistently as possible.<br>
The term noiseless according to the present invention refers to switching<br>
between independent audio streams where packet sequence information is<br>
preserved. The term synchronized header information refers to packets having<br>
headers where packet sequence information is preserved. Packet sequence<br>
information can include but is not limited to valid RTP information.<br>
The term digital signal processor (DSP) includes but is not limited to a<br>
device used to code or decode digitized voice samples according to a program or<br>
application service.<br>
The term digitized voice or voice includes but is not limited to audio byte<br>
samples produced in a pulse code modulation (PCM) architecture by a standard<br>
telephone circuit compressor/decompressor (CODEC).<br>
The term packet processor refers to any type of packet processor that<br>
creates packets for a packet-switched network. In one example, a packet<br>
processor is a specialized microprocessor designed to examine and modify<br>
Ethernet packets according to a program or application service.<br>
The term packetized voice refers to digitized voice samples carried within<br>
a packet.<br>
The term real time protocol (RTP) stream of audio refers to the sequence<br>
of RTP packets associated with one channel of packetized voice.<br>
The term switched virtual circuit (SVC) refers to a temporary virtual<br>
circuit that is set up and used only as long as data is being transmitted. Once the<br>
communication between the two hosts is complete, the SVC disappears. In<br>
contrast, a permanent virtual circuit (PVC) remains available at all times.<br>
HI. Audio Networking Environment<br>
The present invention can be used in any audio networking environment.<br>
Such audio networking environments can include but are not limited to a wide<br>
area and/or local area network environment. In example embodiments, the<br>
present invention is incorporated within an audio networking environment as a<br>
stand-alone unit or as part of a media server, packet router, packet switch or other<br>
network component. For brevity, the present invention is described with respect<br>
to embodiments incorporated in a media server.<br>
Media servers deliver audio on network links over one or more circuit-<br>
switched and/or packet-switched networks to local or remote clients. A client can<br>
be any type of device that handles audio including but not limited to a telephone,<br>
cellular phone, personal computer, personal data assistant (PDA), set-top box,<br>
console, or audio player. FIG. 1 is a diagram of a media server 140 in an voice<br>
over the Internet example environment according to the present invention. This<br>
example includes a telephone client 105, public-switched telephone network<br>
(PSTN) 110, Softswitch 120, gateway 130, media server 140, packet-switched<br>
network(s) 150, and computer client 155. Telephone client 105 is any type of<br>
phone (wired or wireless) that can send and receive audio over PSTN 110. PSTN<br>
110 is any type of circuit-switched network(s). Computer client 155 can be a<br>
personal computer.<br>
Telephone client 105 is coupled through a public-switched telephone<br>
network (PSTN) 110, gateway 130 and network 150 to media server 140. In this<br>
example, call signaling and control is separated from the media paths or links that<br>
carry audio. Softswitch 120 is provided between PSTN 110 and media server<br>
140. Softswitch 120 supports call signaling and control to establish and remove<br>
voice calls between telephone client 105 and media server 140. In one example,<br>
Softswitch 120 follows the Session Initiation Protocol (SIP). Gateway 130 is<br>
responsible for converting audio passing to and from PSTN 110 and network 150.<br>
This can include a variety of well-known functions such as translating a circuit-<br>
switched telephone number to an Internet Protocol (IP) address and vice versa.<br>
Computer client 155 is coupled over network 150 to media server 140.<br>
A media gateway controller (not shown) can also use SIP to support call signaling<br>
and control to establish and breakdown links such as voice calls between<br>
computer client 155 and media server 140. An application server(not shown) can<br>
also be coupled to media server 140 to support VOL? services and applications.<br>
The present invention is described in terms of these example<br>
environments. Description in these terms is provided for convenience only. It is<br>
not intended that the invention be limited to application in these example<br>
environments involving a media server, router, switch, network component, or<br>
stand-alone unit within a network. In fact, after reading the following description,<br>
it will become apparent to a person skilled in the relevant art how to implement<br>
the invention in alternative environments known now or developed in the future.<br>
IV. Media Server, Services and Resources<br>
FIG. 2 is a diagram of an example media platform 200 according to one<br>
embodiment the present invention. Platform 200 provides scalable VOIP<br>
telephony. Media platform 200 includes a media server 202 coupled to<br>
resource(s) 210, media service(s) 212, and interface(s) 208. Media server 202<br>
includes one or more applications 210, a resource manager 220 and audio<br>
processing platform 230. Media server 202 provides resources 210 and services<br>
212. Resources 210 include, but are not limited to modules 21 la-f, as shown in<br>
FIG 2. Resource modules 21 la-f include conventional resources such as play<br>
announcements/collect digits IVR resources 211a, tone/digit voice scanning<br>
resource 21 lb, transcoding resource 21 lc, audio record/play resource 21 Id, text-<br>
to-speech resource 21 le, and speech recognition resource 21 If. Media services<br>
212 include, but are not limited to, modules 213a-e, as shown in FIG. 2. Media<br>
services modules 213a-e include conventional services such as telebrowsing<br>
213a, voice mail service 213b, conference bridge service 213c, video streaming<br>
213d, and a VOIP gateway 213e.<br>
Media server 202 includes an application central processing unit (CPU)<br>
210, a resource manager CPU 220, and an audio processing platform 230.<br>
Application CPU 210 is any processor that supports and executes program<br>
interfaces for applications and applets. Application CPU 210 enables platform<br>
200 to provide one or more of the media services 212. Resource manager CPU<br>
220 is any processor that controls connectivity between resources 210 and the<br>
application CPU 210 and/or audio processing platform 230. Audio processing<br>
platform 230 provides communications connectivity with one or more of the<br>
network interfaces 208. Media platform 200 through audio processing platform<br>
230 receives and transmits information via network interface 208. Interface 208<br>
can include, but it not limited to, Asynchronous Transfer Mode (ATM) 209a,<br>
local area network (LAN) Ethernet 209b, digital subscriber line (DSL) 209c,<br>
cable modem 209d, and channelized T1-T3 lines 209e.<br>
V. Audio Processing Platform with a Packet/Cell Switch for Noiseless<br>
Switching of Independent Audio Streams<br>
In one embodiment of the present invention, audio processing platform<br>
230 includes a dynamic fully-meshed cell switch 304 and other components for<br>
the reception and processing of packets, such as Internet Protocol (IP) packets.<br>
Platform 230 is shown in FIG. 3A with regard to audio processing including<br>
noiseless switching according to the present invention.<br>
As illustrated, audio processing platform 230 includes a call control and<br>
audio feature manager 302, cell switch 304 (also referred to as a packet/cell<br>
switch to indicate cell switch 304 can be a cell switch or packet switch), network<br>
connections 305, network interface controller 306, and audio channel processors<br>
308. Network interface controller 306 further includes packet processors 307.<br>
Call control and audio feature manager 302 is coupled to cell switch 304, network<br>
interface controller 306, and audio channels processors 308. In one<br>
configuration, call control and audio feature manager 302 is connected directly<br>
to the network interface controller 306. Network interface controller 306 then<br>
controls packet processor 307 operation based on the control commands sent by<br>
call control and audio feature manager 302.<br>
In one embodiment, call control and audio feature manager 302 controls<br>
cell switch 304, network interface controller 306 (including packet processors<br>
307), and audio channel processors 308 to provide noiseless switching of<br>
independent audio streams according to the present invention. This noiseless<br>
switching is described further below with respect to FIGs. 6-9. An embodiment<br>
of the call control and audio feature manager 302 according to the present<br>
invention is described further below with respect to FIG. 3B.<br>
Network connections 305 are coupled to packet processors 307. Packet<br>
processors 307 are also coupled to cell switch 304. Cell switch 304 is coupled<br>
in tum to audio channel processors 308. In one embodiment, audio channel<br>
processors 308 include four channels capable of handling four calls, i.e., there are<br>
four audio processing sections. In alternative embodiments, there are more or<br>
less audio channel processors 308.<br>
Data packets, such as IP packets, that include payloads having audio data<br>
arrive at network connections 305. In one embodiment, packet processors 307<br>
comprise one or more or eight 100Base-TX full-duplex Ethernet links capable of<br>
high speed network traffic in the realm of 300,000 packets per second per link.<br>
In another embodiment, packet processors 307 are capable of 1,000 G.711 voice<br>
ports per link and/or 8,000 G.711 voice channels per system.<br>
In additional embodiments, packet processors 307 recognize the IP<br>
headers of packets and handle all RTP routing decisions with a minimum of<br>
packet delay or jitter.<br>
In one embodiment of the present invention, packet/cell switch 304 is a<br>
non-blocking switch with 2.5Gbps of total bandwidth. In another embodiment,<br>
the packet/cell switch 204 has 5Gbps of total bandwidth.<br>
In one embodiment, the audio channel processors 308 comprise any audio<br>
source, such as digital signal processors, as described in further detail with<br>
regards to FIG. 4. The audio channel processors 308 can perform audio related<br>
services including one or more of the services 211a-f.<br>
VI. Example Audio Processing Platform Implementation<br>
FIG. 4 shows one example implementation which is illustrative and not<br>
intended to limit the present invention. As shown in FIG. 4, audio processing<br>
platform 230 can be a shelf controller card (SCC). System 400 embodies one<br>
such SCC. System 400 includes cell switch 304, call control and audio feature<br>
manager 302, a network interface controller 306, interface circuitry 410, and<br>
audio channel processors 308a-d.<br>
More specifically,, system 400 receives packets at network connections<br>
424 and 426. Network connections 424 and 426 are coupled to network interface<br>
controller 306. Network interface controller 306 includes packet processors<br>
307a-b. Packet processors 307a-b comprise controllers 420, 422, forwarding<br>
tables 412,416, and forwarding processor (EPIF) 414,418. As shown in FIG. 4,<br>
packet processor 307a is coupled to network connection 424. Network<br>
connection 424 is coupled to controller 420. Controller 420 is coupled to both<br>
forwarding table 412 andEPIF414. Packet processor 307b is coupled to network<br>
connection 426. Network connection 426 is coupled to controller 422.<br>
Controller 422 is coupled to both forwarding table 416 and EPIF 418.<br>
In one embodiment, packet processors 307 can be implemented on one or<br>
more LAN daughtercard modules. In another embodiment, each network<br>
connection 424 and 426 can be a 100Base-TX or 1000Base-T link.<br>
The IP packets received by the packet processors 307 are processed into<br>
internal packets. When a cell layer is used, the internal packets are then<br>
converted to cells (such as ATM cells' by a conventional segmentation and<br>
reassembly (SAR) module). The cells are forwarded by packet processors 307<br>
to cell switch 304. The packet processors 307 are coupled to the cell switch 304<br>
via cell buses 428,430,432,434. Cell switch 304 forwards the cells to interface<br>
circuitry 410 via cell buses 454,456,458,460. Cell switch 304 analyzes each of<br>
the cells and forwards each of the cells to the proper cell bus of cell buses 454,<br>
456, 458, 460 based on an audio channel for which that cell is destined. Cell<br>
switch 304 is a dynamic, fully-meshed switch.<br>
In one embodiment, interface circuitry 410 is a backplane connector.<br>
The resources and services available for the processing and switching of<br>
the packets and cells in system 400 are provided by call control and audio feature<br>
manager 304. Call control and audio feature manager 302 is coupled to cell<br>
switch 402 via a processor interface (PDF) 436, a SAR, and a local bus 437. Local<br>
bus 437 is further coupled to a buffer 438. Buffer 438 stores and queues<br>
instructions between the call control and'audio feature manager 302 and the cell<br>
switch 304.<br>
Call control and audio feature manager 302 is also coupled to a memory<br>
module 442 and a configuration module 440 via bus connection 444. In one<br>
embodiment, configuration module 440 provides control logic for the boot-up,<br>
initial diagnostic, and operational parameters of call control and audio feature<br>
manager 302. In one embodiment, memory module 442 comprises dual in-line<br>
memory modules (DIMMs) for random access memory (RAM) operations of call<br>
control and audio feature manager 302.<br>
Call control and audio feature manager 302 is further coupled to interface<br>
circuitry410. A network conduit 408 couples resource manager CPU 220 and/or<br>
application CPU 210 to the interface circuitry 410. In one embodiment, call<br>
control and audio feature manager 302 monitors the status of the interface<br>
circuitry 410 and additional components coupled to the interface circuitry 410.<br>
In another embodiment, call control and audio feature manager 302 controls the<br>
operations of the components coupled to the interface circuitry 410 in order to<br>
provide the resources 210 and services 212 of platform 200.<br>
A console port 470 is also coupled to call control and audio feature<br>
manager 302. Console port 470 provides direct access to the operations of call<br>
control and audio feature manager 302. For example, one could administer the<br>
operations, re-boot the media processor, or otherwise affect the performance of<br>
call control and audio feature manager 302 and thus the system 400 using the<br>
console port 470.<br>
Reference clock 468 is coupled to interface circuitry 410 and other<br>
components of the system 400 to provide consistent means of time-stamping the<br>
packets, cells and instructions of the system 400.<br>
Interface circuitry 410 is coupled to each of audio channel processors<br>
308a-308d. Each of the processors 308 comprise a PIF 476, a group 478 of one<br>
or more card processors (also referred to as "bank" processors), and a group 480<br>
of one or more digital signal processors (DSP) and SDRAM buffers. In one<br>
embodiment, there are four card processors in: group 478 and 32 DSPs in group<br>
480. In such an embodiment, each card processor of group 478 would access and<br>
operate with eight DSPs of group 480.<br>
VII. Call Control and Audio Feature Manager<br>
FIG. 3B is a block diagram of call control and audio feature manager 302<br>
according to one embodiment of the present invention. Call control and audio<br>
feature manager 302 is illustrated functionally as processor 302. Processor 302<br>
comprises a call signaling manager 352, system manager 354, connection<br>
manager 356, and feature controller 358.<br>
Call signaling manager 352 manages call signaling operation such as call<br>
establishment and removal, interface with a Softswitch, and handling signaling<br>
protocols like SIP.<br>
System manager 354 performs bootstrap and diagnostic operations on the<br>
components of system 230. System manager 354 further monitors the system 230<br>
and controls various hot-swapping and redundant operation.<br>
Connection manager 356 manages EPIF forwarding tables, such as tables<br>
412 and 416, and provides the routing protocols (such as Routing Information<br>
Protocol (RIP), Open Shortest Path First (OSPF), and the like). Further, the<br>
connection manager 356 establishes internal ATM permanent virtual circuits<br>
(PVC) and/or SVC. In one embodiment, the connection manager 356 establishes<br>
bi-directional connections between the network connections, such as network<br>
connections 424 and 426, and the DSP channels, such as DSPs 480a-d, so that<br>
data flows can be sources or processed by a DSP or other type of channel<br>
processor.<br>
In another embodiment, connection manager 356 abstracts the details of<br>
the EPIF and ATM hardware. Call signaling manager 352 and the resource<br>
manager CPU 220 can access these details so that their operations are based on<br>
the proper service set and performance parameters.<br>
Feature controller 358 provides communication interfaces and protocols<br>
such as, H.323, and MGCP (Media Gateway Control Protocol).<br>
In one embodiment, card processors 478a-d function as controllers with<br>
local managers for the handling of instructions from the call control and audio<br>
feature manager 302 and any of its modules: call signaling manager 352, system<br>
manager 354, connection manager 356, and feature controller 358. Card<br>
processors 478a-d then manage the DSP banks, network interfaces and media<br>
streams, such as audio streams.<br>
In one embodiment, the DSPs 480a-d provide the resources 210 and<br>
services 212 of platform 200.<br>
In one embodiment, call control and audio feature manager 302 of the<br>
present invention exercises control over the EPIFof the present invention through<br>
the use of applets. In such an embodiment, the commands for configuring<br>
parameters (such as port MAC address, port IP address, and the like), search table<br>
management, statistics uploading, and the like, are indirectly issued through<br>
applets.<br>
The EPIF provides a search engine to handle the functionality related to<br>
creating, deleting and searching entries. Since the platform 200 operates on the<br>
source and destination of packets, the EPIF provides search functionality of<br>
sources and destinations. The sources and destinations of packets are stored in<br>
search tables for incoming (ingress) and outgoing (egress) addresses. The EPIF<br>
can also manage RTP header information and evaluating relative priorities of<br>
egress audio streams to be transmitted as described in further detail below.<br>
VIII. Audio Processing Platform Operation<br>
The operation of audio processing platform 230 is illustrated in the flow<br>
diagrams of FIGs. 5A and 5B. FIG. 5A is a flow diagram showing the<br>
establishment of a call and ingress packet processing according to an embodiment<br>
of the present invention. FIG. 5B is a flow diagram showing egress packet<br>
processing and call completion according to an embodiment of the present<br>
invention.<br>
A. Ingress Audio Streams<br>
In FIG. 5A, the process for an ingress (also called inbound) audio stream<br>
starts at step 502 and immediately proceeds to step 504.<br>
In step 504, call control and audio feature manager 302 establishes a call<br>
with a client communicating via the network connections 305. In one<br>
embodiment, call control and audio feature manager 302 negotiates and<br>
authorizes access to the client. Once client access is authorized, call control and<br>
audio feature manager 302 provides IP and UDP address information for the call<br>
to the client. Once the call is established, the process immediately proceeds to<br>
step 506.<br>
In step 506, packet processors 307 receive IP packets carrying audio via<br>
the network connections 305. Any type of packet can be used including but not<br>
limited to IP packets, such as Appletalk, IPX, or other type of Ethernet packets.<br>
Once a packet is received, the process proceeds to step 508.<br>
In step 508, packet processors 307 check IP and UDP header address in<br>
search table to find associated SVC, and then convert the VOIP packets into<br>
interna] packets. Such internal packets for example can be made up of a payload<br>
and control header as described further below with respect to FIG. 7B. Packet<br>
processors 307 then construct packets using at least some of the data and routing<br>
information and assign a switched virtual circuit (SVC). The SVC is associated<br>
with one of the audio channel processors 308, and in particular with one of<br>
respective DSP that will process the audio payload.<br>
When a cell layer is used, internal packets are further converted or merged<br>
into cells, such as ATM cells. In this way, audio payloads in the internal packets<br>
are converted to audio payloads in a stream of one or more ATM cells. A<br>
conventional segmentation and reassembly (SAR) module can be used to convert<br>
internal packets to ATM cells. Once the packets are converted into the cells, the<br>
process proceeds to step 510.<br>
In step 510, cell switch 304 switches the cells to the proper audio channel<br>
of the audio channel processors 308 based on the SVC. The process proceeds to<br>
step 512.<br>
In step 512, audio channel processors 308 convert the cells into packets.<br>
Audio payloads in the arriving ATM cells for each channel are converted to audio<br>
payloads in a stream of one or more packets. A conventional SAR module can<br>
be used to convert ATM to packets. Packets can be internal egress packets or IP<br>
packets with audio payloads. Once the cells are converted into the internal<br>
packets, the process proceeds to step 514.<br>
In step 514, audio channel processors 308 process the audio data of the<br>
packets in the respective audio channels. In one embodiment, the audio channels<br>
are related to one or more of the media services 213a-e. For example, these<br>
media services can be telebrowsing, voice mail, conference bridging (also called<br>
conference calling), video streaming, VOIP gateway services, telephony, or any<br>
other media service for audio content.<br>
B. Egress Audio Streams<br>
In FIG. 5B, the process for an egress (also called outbound) audio stream<br>
starts at step 522 and immediately proceeds to step 524.<br>
In step 524, call control and audio feature manager 302 identifies an<br>
audio source for noiseless switch over. This audio source can be associated with<br>
an established call or other media service. Once the audio source is identified, the<br>
process immediately proceeds to step 526.<br>
In step 526, an audio source creates packets. In one embodiment, a DSP<br>
in audio channel processor 308 is an audio source. Audio data can be stored in<br>
a SDRAM associated with the DSP. This audio data is then packetized by a DSP<br>
into packets. Any type of packet can be used including but not limited to internal<br>
packets or IP packets, such as Ethernet packets. In one preferred embodiment, the<br>
packets are internal egress packets generated as described with respect to FIG.<br>
7B.<br>
In step 528, an audio channel processor 308 converts the packets into<br>
cells, such as ATM cells. Audio payloads in the packets are converted to audio<br>
payloads in a stream of one or more ATM cells. In brief, the packets are parsed<br>
and the data and routing information analyzed. Audio channel processor 308 then<br>
construct cells using at least some of the data and routing information and assigns<br>
a switched virtual circuit (SVC). A conventional SAR module can be used to<br>
convert packets to ATM cells. The SVC is associated with one of the audio<br>
channel processors 308, and in particular with a circuit connecting the respective<br>
DSP of the audio source and a destination port 305 of NIC 306. Once the packets<br>
are converted into the cells, the process proceeds to step 530.<br>
In step 530, cell switch 304 switches the cells of an audio channel of the<br>
audio channel processors 308 to a destination network connection 305 based on<br>
the SVC. The process proceeds to step 532.<br>
In step 532, packet processors 307 convert the cells into IP packets.<br>
Audio payloads in the arriving ATM cells for each channel are converted to audio<br>
payloads in a stream of one or more internal packets. A conventional SAR<br>
module can be used to convert ATM to internal packets. Any type of packet can<br>
be used including but not limited to IP packets, such as Ethernet packets. Once<br>
the cells are converted into the packets, the process proceeds to step 534.<br>
In step 534, each packet processor 307 further adds RTP, IP, and UDP<br>
header information. A search table is checked to find IP and UDP header address<br>
information associated with the SVC. IP packets are then sent carrying audio via<br>
the network connections 305 over a network to a destination device (phone,<br>
computer, palm device, PDA, etc.). Packet processors 307 process the audio data<br>
of the packets in the respective audio channels. In one embodiment, the audio<br>
channels are related to one or more of the media services 213a-e. For example,<br>
these media services can be telebrowsing, voice mail, conference bridging (also<br>
called conference calling), video streaming, VOIP gateway services, telephony,<br>
or any other media service for audio content.<br>
IX. Noiseless Switching of Egress Audio Streams<br>
According to the one aspect of the present invention, audio processing<br>
platform 230 noiselessly switches between independent egress audio streams.<br>
Audio processing platform 230 is illustrative. The present invention as it relates<br>
to noiseless switching of egress audio stream can be used in any media server,<br>
router, switch, or audio processor and is not intended to be limited to audio<br>
processing platform 230.<br>
A. Cell Switch - Internal Audio Sources<br>
FIG. 6A is diagram of a noiseless switch over system that carries out cell<br>
switching of independent egress audio streams generated by internal audio<br>
sources according to an embodiment of the present invention. FIG. 6A shows an<br>
embodiment of a system 600A for egress audio stream switching from internal<br>
audio sources. System 600A includes components of audio processing platform<br>
230 configured for an egress audio stream switching mode of operation. In<br>
particular, as shown in FIG. 6A, system 600A includes call control and audio<br>
feature controller 302 coupled to a number n of internal audio sources 604n, cell<br>
switch 304, and network interface controller 306. Internal audio sources 604a-<br>
604n can be two or more audio sources. Any type of audio source can be used<br>
including but not limited to DSPs. In one example, DSPs 480 can be audio<br>
sources. To generate audio, audio sources 604 can either create audio internally<br>
and/or convert audio received from external sources.<br>
Call control and audio feature controller 302 further includes an egress<br>
audio controller 610. Egress audio controller 610 is control logic that issues<br>
control signals to audio sources 604n, cell switch 304, and/or network interface<br>
controller 306 to carry out noiseless switching between independent egress audio<br>
streams according to the present invention. The control logic can implemented<br>
in software, firmware, microcode, hardware or any combination thereof.<br>
A cell layer including SARs 630, 632,634 is also provided. SARs 630,<br>
632 are coupled between cell switch 304 and each audio source 604a-n. SAR 634<br>
is coupled between cell switch 304 and NIC 306.<br>
In one embodiment, independent egress audio streams involve streams of<br>
IP packets with RTP information and internal egress packets. Accordingly, it is<br>
helpful to first describe IP packets and internal egress packets (FIGs. 7A-7B).<br>
Next, system 600A and its operation is described in detail with respect to<br>
independent egress audio streams (FIGs. 8-9).<br>
B. Packets<br>
In one embodiment, the present invention uses two types of packets: (1)<br>
IP packets with RTP information and (2) internal egress packets. Both of these<br>
types of packets are shown and described with respect to examples in FIGs. 7A<br>
and 7B. IP packets 700A are sent and received over a external packet-switched<br>
network by packet processors 307 in NIC 306. Internal egress packets 700B are<br>
generated by audio sources (e.g. DSPs) 604a-604n.<br>
1. IP Packets with RTP Information<br>
A standard Internet Protocol (IP) packet 700A is shown in FIG. 7A. IP<br>
packet 700A is shown with various components: media access control (MAC)<br>
field 704, IP field 706, user datagram protocol (UDP) field 708, RTP field 710,<br>
payload 712 containing digital data, and cyclic redundancy check (CRC) field<br>
714. Real-Time Transport Protocol (RTP) is a standardized protocol for carrying<br>
periodic data, such as digitized audio, from a source device to a destination<br>
device. A companion protocol, Real-Time Control Protocol (RTCP), can also be<br>
used with RTP to provide information on the quality of a session.<br>
More specifically, the MAC 704 and IP 706 fields contain addressing<br>
information to allow each packet to traverse an IP network interconnecting two<br>
devices (origin and destination). UDP field 708 contains a 2-byte port number<br>
that identifies a RTP/audio stream channel number so that it can be internally<br>
routed to the audio processor destination when received from the network<br>
interface. In one embodiment of the present invention, the audio processor is a<br>
DSP, as described herein.<br>
RTP field 710 contains a packet sequence number and timestamp.<br>
Payload 712 contains the digitized audio byte samples and can be decoded by the<br>
endpoint audio processors. Any payload type and encoding scheme for audio<br>
and/or video types of media compatible with RTP can be used as would be<br>
apparent to a person skilled in the art given this description. CRC field 714<br>
provides a way to verify the integrity of the entire packet. See, the description of<br>
RTP packets and payload types described by D. Collins, Carrier Grade Voice<br>
over IP, pp. 52-72 (the text of the entire book of which is incorporated herein by<br>
reference).<br>
2. Internal Egress Packets<br>
FIG. 7B illustrates an example internal egress packet of the present<br>
invention in greater detail. Packet 700B includes a control (CTRL) header 720<br>
and a payload 722. The advantage of internal egress packet 700B is it is simpler<br>
to create and smaller in size than IP packet 700A. This reduces the burden and<br>
work required of audio sources and other components handling the internal egress<br>
packets.<br>
In one embodiment, audio sources 604a-604n are DSPs. Each DSP adds<br>
a CTRL header 720 in front of a payload 722 that it creates in for a respective<br>
audio stream. CTRL 720 is then used to relay control information downstream.<br>
This control information for example can be priority information associated with<br>
a particular egress audio stream.<br>
Packet 700B is converted to one or more cells, such as ATM cells, and<br>
sent internally over cell switch 304 to a packet processor 307 in network interface<br>
controller 306. After the cells are converted to internal egress packets, packet<br>
processor 307 decodes and removes internal header CTRL 720. The rest of the<br>
IP packet information is added before the payload 722 is transmitted as an IP<br>
packet 700A onto an IP network. This achieves an advantage as processing work<br>
at the DSPs is reduced. DSPs only have to add a relatively short control header<br>
to payloads. The remaining processing work of adding information to create<br>
valid IP packets with RTP header information can be distributed to packet<br>
processors) 307.<br>
C. Priority Levels<br>
Network interface controller (NIC) 306 processes all internal egress<br>
packets, as well as all egress IP packets destined for the external network. Thus,<br>
NIC 306 can make final forwarding decisions about each packet sent to it based<br>
on the content of each packet. In some embodiments, NIC 306 manages the<br>
forwarding of egress IP packets based on priority information. This can include<br>
switching over to an audio stream of egress IP packets with a higher priority and<br>
buffering or not forwarding another audio stream of egress IP packets with a<br>
lower priority.<br>
In one embodiment, internal audio sources 604a-604n determine priority<br>
levels. Alternatively, NIC 306 can determine a priority for audio received from<br>
an external source at NIC 306. Any number of priority levels can be used. The<br>
priority levels distinguish the relative priority of audio sources and their<br>
respective audio streams. Priority levels can be based on any criteria selected by<br>
a user including, but not limited to, time of day, identity or group of the caller or<br>
callee, or other similar factors relevant to audio processing and media services.<br>
Components of the system 600 filter and forward the priority level information<br>
within the audio stream. In one embodiment, a resource manager in system 600<br>
can interact with external systems to alter the priority levels of audio streams. For<br>
example, an external system can be an operator informing the system to queue a<br>
billing notice or advertisement on a call. Thus, the resource manager is capable<br>
of barging into audio streams. This noiseless switch over can be triggered by user<br>
or automatically based on certain predefined events such as signaling conditions<br>
like on-hold condition, emergency event, or timed event.<br>
D. Noiseless Fully Meshed Cell Switch<br>
System 600A can be thought of as a "free pool" of multiple input (ingress)<br>
and output (egress) audio channels because a fully meshed packet/cell switch 304<br>
is used to switch egress audio channels to participate in any given call. Any<br>
egress audio channel can be called upon to participate in a telephone call at any<br>
time. During both the initial call setup and while the call is in session, any egress<br>
audio channel can be switched into and out of the call. The fully meshed<br>
switching capability of system 600A of the present invention provides a precise<br>
noiseless switching functionality which does not drop or corrupt the IP packets<br>
or the cells of the present invention. In addition, a two-stage egress switching<br>
technique is used.<br>
E. Two-Stage Egress Switching<br>
System 600A includes at least two stages of switching. In terms of egress<br>
switching, the first stage is cell switch 304. The first stage is cell-based and uses<br>
switched virtual circuits (SVCs) to switch audio streams from separate physical<br>
sources (audio sources 604a-604n) to a single destination egress network<br>
interface controller (NIC 306). Priority information is provided in the CTRL<br>
header 720 of cells generated by the audio sources. The second stage is contained<br>
within the egress NIC 306 such that it selects which of the audio streams from<br>
multiple audio sources (604a-604n) to process and send over a packet network<br>
such as an packet-switched IP network. This selection of which audio streams to<br>
forward can be performed by NIC 306 is based on the priority information<br>
provided in the CTRL headers 720. In this way, a second audio stream with a<br>
higher priori ty can be forwarded by NIC 306 on the same channel as a first audio<br>
stream. From the perspective of the destination device receiving the audio<br>
streams, the insertion of the second audio stream on the channel is received as a<br>
noiseless switch between independent audio streams.<br>
More specifically, in one embodiment, the egress audio switching can<br>
occur in a telephone call. A call is first established using audio source 604a by<br>
negotiating with the destination device's MAC, IP, and UDP information, as<br>
previously described. First audio source 604a begins generating a first audio<br>
stream during the call. The first audio stream is made up of internal egress<br>
packets having audio payload and CTRL header 720 information as described<br>
with respect to packet format 700B. Internal egress packets egress on the channel<br>
established for the call. Any type of audio payload including voice, music, tones,<br>
or other audio data can be used. SAR 630 converts the internal packets to cells<br>
for transport through cell switch 304 to SAR 634. SAR 634 then converts cells<br>
back to internal egress packets prior to delivery to NIC 306.<br>
During the flow from the audio source 604a, NIC 306 is decoding and<br>
removing the CTRL header 720 and adding the appropriate RTP, UDP, IP, MAC,<br>
and CRC fields, as previously described. CTRL header 720 includes the priority<br>
field used by NIC 306 to process the packet and send a corresponding RTP<br>
packet. NIC 306 evaluates the priority field. Given the relatively high priority<br>
field (the first audio source 604a is the only transmitting source), NIC 306<br>
forwards IP packets with synchronized RTP header information which carry the<br>
first audio stream over the network to the destination device associated with the<br>
call. (Note CTRL header 720 can also include RTP or other synchronized header<br>
information which can be used or ignored by NIC 306 if NIC 306 generates and<br>
adds RTP header information).<br>
When the egress audio controller 610 determines a call event where a<br>
noiseless switch over is to occur, a second audio source 604n begins generating<br>
a second audio stream. Audio can be generated by audio source 604n directly or<br>
by converting audio originally generated by external devices. The second audio<br>
stream is made up of internal egress packets having audio payload and CTRL<br>
header 720 information as described with respect to packet format 700B. Any<br>
type of audio payload including voice, music, or other audio data can be used.<br>
Assume the second audio stream is given a higher priority field than the first<br>
audio stream. For example, the second audio stream can represent an<br>
advertisement, emergency public service message, or other audio data that is<br>
desired to have noiselessly inserted into the first channel established with the<br>
destination device.<br>
The second audio stream's internal egress packets are then converted to<br>
cells by SAR 632. Cell switch 304 switches the cells to an SVC destined for the<br>
same destination NIC 306 as the first audio stream. SAR 634 converts the cells<br>
back to internal packets. NIC 306 now receives the internal packets for the first<br>
and second audio streams. NIC 306 evaluates the priority field in each stream.<br>
The second audio stream having internal packets with the higher priority are<br>
converted to IP packets with synchronized RTP header information and<br>
forwarded to the destination device. The first audio stream having internal<br>
packets with the lower priority are either stored in a buffer or converted to IP<br>
packets with synchronized RTP header information and stored in buffer. NIC 306<br>
can resume forwarding the first audio stream when the second audio stream is<br>
completed, after a predetermined time elapses, or when a manual or automatic<br>
control signal is received to resume.<br>
F. Call Event Triggering Noiseless Switch Over<br>
The functionality of the priority field in an embodiment of noiseless<br>
switching according to the present invention is now described with regard to<br>
FIGs. 8, 9A and 9B.<br>
In FIG. 8, a flow diagram of a noiseless switching routine 800 according<br>
to one embodiment of the present invention is shown. For brevity, the noiseless<br>
switching routine 800 is described with respect system 600.<br>
Flow 800 begins at step 802 and proceeds immediately to step 804.<br>
In step 804, call control and audio feature manager 302 establishes a call<br>
from a first audio source 604a to a destination device. Call control and audio<br>
feature manager 302 negotiates with the destination device to determine the<br>
MAC, IP and UDP port to use in a first audio stream of IP packets sent over a<br>
network.<br>
Audio source 604a delivers a first audio stream on one channel for the<br>
established call. In one embodiment, a DSP delivers the first audio stream of<br>
internal egress packets on one channel to cell switch 304 and then to NIC 306.<br>
The process proceeds to step 806.<br>
In step 806, egress audio controller 610 sets a priority field for the first<br>
audio source. In one embodiment, egress audio controller 610 sets the priority<br>
field to a value of one. In another embodiment, the priority field is stored in the<br>
CTRL header of the internally routed internal egress packets. The process<br>
immediately proceeds to step 808.<br>
In step 808, egress audio controller 610 determines the call's status In<br>
one embodiment, egress audio controller 610 determines whether or not the call<br>
allows or has been configured to allow call events to interact with it. In one<br>
embodiment of the present invention, a call can be configured so that only<br>
emergency call events will interrupt it. In another embodiment, a call can be<br>
configured to receive certain call events based on either the caller(s) or callee(s)<br>
(i.e., the one or more of the parties on the call). The process immediately<br>
proceeds to step 810.<br>
In step 810, egress audio controller 610 monitors for call events. In one<br>
embodiment, a call event can be generated within the system 600, such as<br>
notifications of time, weather, advertisements, billing ("please insert another<br>
coin" or "you have 5 minutes remaining"). In another embodiment, call events<br>
can be sent to the system 600, such as requests for news, sporting information,<br>
etc. Egress audio controller 610 can monitor both internally and externally for<br>
call events. The process proceeds immediately to step 812.<br>
In step 812, egress audio controller 610 receives a call event. If not, then<br>
egress audio controller 610 continues to monitor as stated in step 810. If so, then<br>
the process proceeds immediately to step 814.<br>
In step 814, egress audio controller 610 determines the call event and<br>
performs the operations necessitated by the call event. The process then proceeds<br>
to step 816 where it either ends or returns to step 802. In one embodiment, the<br>
process 800 repeats for as long as the call continues.<br>
In FIG. 9A-9C, flow diagram 900 of the call event processing for audio<br>
stream switching based on priority according to one embodiment of the present<br>
invention are shown. In one embodiment, flow 900 shows in more detail the<br>
operations performed in step 814 of FIG. 8.<br>
Process 900 starts at step 902 and proceeds immediately to step 904.<br>
In step 904, egress audio controller 610 reads a call event for an<br>
established call. In this operation, a first audio stream from source 604a is<br>
already being sent from NIC 306 to a destination device as part of the established<br>
call. The process proceeds to step 906.<br>
In step 906, egress audio controller 610 determines whether the call event<br>
includes a second audio source. If so, then the process proceeds to step 908. If<br>
not, then the process proceeds to step 930.<br>
In step 908, egress audio controller 610 determines the priority of the<br>
second audio source. In one embodiment, egress audio controller 610 issues a<br>
command to second audio source 604n that instructs the second audio source to<br>
generate a second audio stream of internal egress packets. Priority information<br>
for the second audio stream can be automatically generated by the second audio<br>
source 604n or generated based on a command from the egress audio controller<br>
610. The process then proceeds to step 910.<br>
In step 910, a second audio source 604n begins generating a second audio<br>
stream. The second audio stream is made up of internal egress packets having<br>
audio payload and CTRL header 720 information as described with respect to<br>
packet format 700B. Any type of audio payload including voice, music, or other<br>
audio data can be used. Audio payload is meant broadly to also include audio<br>
data included as part of video data. The process then proceeds to step 912.<br>
In step 912, the second audio stream's egress packets are then converted<br>
to cells. In one example, the cells are ATM cells. The process then proceeds to<br>
step 914.<br>
In step 914, cell switch 304 switches the cells to an SVC destined for the<br>
same destination NIC 306 on the same egress channel as the first audio stream.<br>
The process then proceeds to step 915.<br>
As shown in step 915 of FIG. 9B, SAR 634 now receives cells for the first<br>
and second audio streams. The cells are converted back to streams of internal<br>
egress packets and have control headers that include the respective priority<br>
information for the two audio streams.<br>
In step 916, NIC 306 compares the priorities of the two audio streams. If<br>
the second audio stream has a higher priority then the process proceeds to step<br>
918. If not, then the process proceeds to step 930.<br>
In step 918, the transmission of the first audio stream is held. For<br>
example, NIC 306 buffers the first audio stream or even issues a control<br>
command to audio source 604a to hold the transmission of the first audio source.<br>
The process proceeds immediately to step 920.<br>
In step 920, the transmission of the second audio stream starts. NIC 306<br>
instructs packet processor(s) 307 to create IP packets having the audio payload<br>
of the internal egress packets of the second audio stream. Packet processor(s) 307<br>
add additional synchronized RTP header information (RTP packet information)<br>
and other header information (MAC, IP, UDP fields) to the audio payload of the<br>
internal egress packets of the second audio stream.<br>
NIC 306 then sends the IP packets with synchronized RTP header<br>
information on the same egress channel of the first audio stream. In this way, a<br>
destination device receives the second audio stream noise instead of the first<br>
audio stream. Moreover, from the perspective of the destination device this<br>
second audio stream is received in real-time noiselessly without delay or<br>
interruption. Steps 918 and 920 of course can be performed at the same time or<br>
in any order. The process proceeds immediately to step 922.<br>
As shown in FIG. 9C, NIC 306 monitors for the end of the second audio<br>
stream (step 922). The process proceeds immediately to step 924.<br>
In step 924, NIC 306 determines whether the second audio stream has<br>
ended. In one example, NIC 306 reads a last packet of the second audio stream<br>
which has a priority level lower than preceding packets. If so, then the process<br>
proceeds immediately to step 930. If not, then the process proceeds to step 922.<br>
In step 930, NIC 306 either continues to forward the first audio stream<br>
(after step 906) or returns to forwarding the first audio stream (after steps 916 or<br>
924). The process proceeds to step 932.<br>
In one embodiment, NIC 306 maintains a priority level threshold value.<br>
NIC 306 then increments and sets the threshold based on priority information in<br>
the audio streams. When faced with multiple audio streams, NIC 306 forwards<br>
the audio stream having priority information equal to or greater than the priority<br>
level threshold value. For example, if the first audio stream had a priority value<br>
of 1 then the priority level threshold value is set to 1 and the first audio stream is<br>
transmitted (prior to step 904). When a second audio stream with a higher<br>
priority is received at NIC 306, then NIC 306 increments the priority threshold<br>
value to 2. The second audio stream is then transmitted as described above in<br>
step 920. When the last packet of the second audio stream having a priority field<br>
value set to 0 (or null or other special value) is read, then the priority level<br>
threshold value is decremented back to 1 as part of step 924. In this case, the first<br>
audio stream with priority information 1 is then be sent by NIC 306 as described<br>
above with respect to step 930.<br>
In step 932, egress audio controller 610 processes any remaining call<br>
events. The process then proceeds to step 934 where it terminates until re-<br>
instantiated. In one embodiment, the steps of the above-described process occur<br>
substantially at the same time, such that the process can be run in parallel or in<br>
an overlapping manner on one or more processors in the system 600.<br>
G. Audio Data Flow<br>
FIG. 6B is a diagram of audio data flow 615 in the noiseless switch over<br>
system of FIG. 6A in one embodiment. In particular, FIG. 6B shows the flow of<br>
internal packets from audio sources 604a-n to S ARs 630,632, the flow of cells<br>
through cell switch 304 to SAR 634, the flow of internal packets between SAR<br>
634 and packet processors 307, and the flow of IP packets from NIC 306 over the<br>
network.<br>
H. Other Embodiments<br>
The present invention is not limited to internal audio sources or a cell<br>
layer. Noiseless switch over can also be carried out in different embodiments<br>
using internal audio sources only, internal and external audio sources, external<br>
audio sources only, a cell switch or a packet switch. For example, FIG. 6C is<br>
diagram of a noiseless switch over system 600C that carries out cell switching<br>
between independent egress audio streams generated by internal audio source<br>
604a-n and/or external audio sources (not shown) according to an embodiment<br>
of the present invention. Noiseless switch over system 600C operates similar to<br>
system 600A described in detail above except that noiseless switch over is made<br>
to audio received from an external audio source. The audio is received in IP<br>
packets and buffered at NIC 306 as shown in FIG. 6C. NIC 306 strips IP<br>
information (stores it in forward table entry associated with external audio source<br>
and destination device) and generates internal packets assigned to a SVC. SAR<br>
634 converts the internal packets to cells and routes cells on the SVC on link 662<br>
through switch 304 back through link 664 to SAR 634 for conversion to internal<br>
packets. As described above, the internal packets are then processed by packet<br>
processor 307 to create IP packets with synchronized header information. NIC<br>
306 then sends the IP packets to destination device. In this way, a user at the<br>
destination device is noiselessly switched over to receive audio from an external<br>
audio source. FIG. 6D is diagram of audio data flow 625 for an egress audio<br>
stream received from the external audio source in the noiseless switch over<br>
system of FIG. 6C. In particular, FIG. 6D shows the flow of IP packets from an<br>
external audio source (not shown) to NIC 306, the flow of internal packets from<br>
NIC 306 to SAR 634, the flow of cells through cell switch 304 back to SAR 634,<br>
the flow of internal packets between SAR 634 and packet processors 307, and the<br>
flow of IP packets from NIC 306 over the network to a destination device (not<br>
shown).<br>
FIG. 6E is diagram of audio data flows 635,645 in a noiseless switch over<br>
system 600E that carries out packet switching between independent egress audio<br>
streams generated by internal and/or externa] audio sources according to an<br>
embodiment of the present invention. Noiseless switch over system 600E<br>
operates similar to systems 600A and 600 C described in detail above except that<br>
a packet switch 694 is used instead of a cell switch 304. In this embodiment, a<br>
cell layer including SARs 630, 632, 634 is omitted. In audio data flow 635,<br>
internal packets flow through the packet switch 694 from internal audio sources<br>
604a-n to packet processors 307. IP packets flow out to the network. In audio<br>
data flow 645, IP packets from an external audio source (not shown) are received<br>
at NIC 306. The audio is received in packets and buffered at NIC 306 as shown<br>
in FIG. 6E. NIC 306 strips IP information (stores it in forward table entry<br>
associated with external audio source and destination device) and generates<br>
internal packets assigned to a SVC (or other type of path) associated with the<br>
destination device. The internal packets are routed on the SVC through packet<br>
switch 694 to NIC 306. As described above, the internal packets are then<br>
processed by packet processor 307 to create IP packets with synchronized header<br>
information. NIC 306 then sends the IP packets to destination device. In this<br>
way, a user at the destination device is noiselessly switched over to receive audio<br>
from an external audio source.<br>
FIG. 6F is diagram of a noiseless switch over system 600F that carries out<br>
switching between independent egress audio streams generated by only external<br>
audio sources according to an embodiment of the present invention. No switch<br>
or internal audio sources are required. NIC 306 strips IP information (stores it in<br>
forward table entry associated with external audio source and destination device)<br>
and generates internal packets assigned to a SVC (or other type of path)<br>
associated with the destination device. The internal packets are routed on the<br>
SVC to NIC 306. (NIC 306 can be a common source and destination point). As<br>
described above, the internal packets are then processed by packet processor 307<br>
to create IP packets with synchronized header information. NIC 306 then sends<br>
the IP packets to destination device. In this way, a user at the destination device<br>
is noiselessly switched over to receive audio from an external audio source.<br>
Functionality described above with respect to the operation of egress<br>
audio switching system 600 can be implemented in control logic. Such control<br>
logic can be implemented in software, firmware, hardware or any combination<br>
thereof.<br>
X. Conference Call Processing<br>
A. Distributed Conference Bridge<br>
FIG. 10 is a diagram of a distributed conference bridge 1000 according to<br>
one embodiment of the present invention. Distributed conference bridge 1000 is<br>
coupled to a network 1005. Network 1005 can be any type of network or<br>
combination of networks, such as, the Internet. For example, network 1005 can<br>
include a packet-switched network or a packeted-switched network in<br>
combination with a circuit-switched network. A number of conference call<br>
participants Cl-CN can connect through network 1005 to distributed conference<br>
bridge 1000. For example, conference call participants Cl-CN can place a VOIP<br>
call through network 1005 to contact distributed conference bridge 1000.<br>
Distributed conference bridge 1000 is scalable and can handle any number of<br>
conference call participants. For example, distributed conference bridge 1000 can<br>
handle conference calls between two conference call participants up to 1000 or<br>
more conference call participants.<br>
As shown in FIG. 10, distributed conference bridge 1000 includes a<br>
conference call agent 1010, network interface controller (NIC) 1020,switch 1030,<br>
and audio source 1040. Conference call agent 1010 is coupled to NIC 1020,<br>
switch 1030 and audio source 1040. NIC 1020 is coupled between network 1005<br>
and switch 1030. Switch 1030 is coupled between NIC 1020 and audio source<br>
1040. A look-up table 1025 is coupled to NIC 1020. Look-up table 1025 (or a<br>
separate look-up table not shown) can also be coupled to audio source 1040.<br>
Switch 1030 includes a muiticaster 1050. NIC 1020 includes a packet processor<br>
1070.<br>
Conference call agent 1010 establishes a conference call for a number of<br>
participants. During a conference call, packets carrying audio, such as digitized<br>
voice, flow from the conference call participants Cl-CN to the conference bridge<br>
1000. These packets can be IP packets including, but not limited to, RTP/RTCP<br>
packets. NIC 1020 receives the packets and forwards the packets along links<br>
1028 to switch 1030. Links 1028 can be any type of logical and/or physical links<br>
such as PVCs or SVCs. In one embodiment, NIC 1020 converts IP packets (as<br>
described above with respect to FIG. 7A) to internal packets which only have a<br>
header and payload (as described with respect to FIG. 7B). The use of the<br>
internal packets further reduces processing work at audio source 1040. Incoming<br>
packets processed by NIC 1020 can also be combined by a SAR into cells, such<br>
as ATM cells, and sent over link(s) 1028 to switch 1030. Switch 1030 passes the<br>
incoming packets from NIC 1020 (or cells) to audio source J 040 on link(s) 1035.<br>
Link(s) 1035 can also be any type of logical and/or physical link including, but<br>
not limited to, a PVC or SVC.<br>
Audio provided over links 1035 is referred to in this conference bridge<br>
processing context as "external audio" since it originates from conference call<br>
participants over network 1005. Audio can also be provided internally through<br>
one or more links 1036 as shown in FIG. 10. Such "internal audio" can be<br>
speech, music, advertisements, news, or other audio content to be mixed in the<br>
conference call. The internal audio can be provided by any audio source or<br>
accessed from a storage device coupled to conference bridge 1000.<br>
Audio source 1040 mixes audio for the conference call. Audio source<br>
1040 generates outbound packets containing the mixed audio and sends the<br>
packets over link(s) 1045 to switch 1030. In particular, audio source 1040<br>
generates a fully mixed audio stream of packets and a set of partially mixed audio<br>
streams. In one embodiment, audio source 1040 (or "mixer" since it is mixing<br>
audio) dynamically generates the appropriate fully mixed and partially mixed<br>
audio streams of packets having conference identifier information (CID) and<br>
mixed audio during the conference call. The audio source retrieves the<br>
appropriate CED information of conference call participants from a relatively<br>
static look-up table (such as table 1025 or a separate table closer to audio source<br>
1040) generated and stored at the initiation of the conference call.<br>
Multicaster 1050 multicasts the packets in the fully mixed audio stream<br>
and a set of partially mixed audio streams. In one embodiment, multicaster 1050<br>
replicates the packets in each of the fully mixed audio stream and set of partially<br>
mixed audio streams N times which corresponds to the N number of conference<br>
call participants. The N replicated packets are then sent to endpoints in NIC 1020<br>
over the N switched virtual circuits (SVC1-SVCN), respectively. One advantage<br>
of distributed conference bridge 1000 is that audio source 1040 (i.e., the mixing<br>
device) is relieved of the work of replication. This replication work is distributed<br>
to multicaster 1050 and switch 1030.<br>
NIC 1020 then processes outbound packets arriving on each SVC1-SVCN<br>
to determine whether to discard or forward the packets of the fully mixed and<br>
partially mixed audio streams to a conference call participant Cl-CN. This<br>
determination is made based on packet header information in real-time during a<br>
conference call. For each packet arriving on a SVC, NIC 1020 determines based<br>
on packet header information, such as TAS and IAS fields, whether the packet is<br>
appropriate for sending to a participant associated with the SVC. If yes, then the<br>
packet is forwarded for further packet processing. The packet is processed into<br>
a network packet and forwarded to the participant. Otherwise, the packet is<br>
discarded. In one embodiment, the network packet is an IP packet which includes<br>
the destination call participant's network address information (IP/UDP address)<br>
obtained from a look-up table 1025, RTP/RTCP packet header information (time<br>
stamp/sequence information), and audio data. The audio data is the mixed audio<br>
data appropriate for the particular conference call participant. The operation of<br>
distributed conference bridge 1000 is described further below with respect to an<br>
example look-up table 1025 shown in FIG. 11, flowchart diagrams shown in<br>
FIGs. 12 and 13A-13C, and example packet diagrams shown in FIGs. 14A, 14B<br>
and 15.<br>
B. Distributed Conference Bridge Operation<br>
FIG. 12 shows a routine 1200 for establishing conference bridge<br>
processing according to the present invention. (Steps 1200-1280). In step 1220,<br>
a conference call is initiated. A number of conference call participants Cl-CN<br>
dial distributed conference bridge 1000. Each participant can use any VOIP<br>
terminal including, but not limited to, a telephone, computer, PDA, set-top box,<br>
network appliance, etc. Conference call agent 1010 performs conventional IVR<br>
processing to acknowledge that a conference call participant wishes to participate<br>
in a conference call and obtains the network address of each conference call<br>
participant. For example, the network address information can include, but is not<br>
limited to, IP and/or UDP address information.<br>
In step 1240, look-up table 1025 is generated. Conference call agent 1010<br>
can generate the look-up table or instruct NIC 1020 to generate the look-up table.<br>
As shown in the example on FIG. 11, look-up table 1025 includes N entries<br>
corresponding to the N conference call participants in the conference call initiated<br>
in step 1220. Each entry in look-up table 1025 includes an SVC identifier,<br>
conference ID (CID), and network address information. The SVC identifier is<br>
any number or tag that identifies a particular SVC. In one example, the SVC<br>
identifier is a Virtual Path Identifier and Virtual Channel Identifier (VPI/VCI).<br>
Alternatively, the SVC identifier or tag information can be omitted from look-up<br>
table 1025 and instead be inherently associated with the location of the entry in<br>
the table. For example, a first SVC can be associated with the first entry in the<br>
table, a second SVC can be associated with a second entry in the table, and so<br>
forth. The CID is any number or tag assigned by conference call agent 1010 to<br>
a conference call participant C1-CN. The network address information is the<br>
network address information collected by conference call agent 1010 for each of<br>
the N conference call participants.<br>
In step 1260, NIC 1020 assigns respective SVCs to each of the<br>
participants. For N conference call participants then N SVCs are assigned.<br>
Conference call agent 1010 instructs NIC 1020 to assign N SVCs. NIC 1020 then<br>
establishes N SVC connections between NIC 1020 and switch 1030. In step<br>
1280, the conference call then begins. Conference call agent 1010 sends a signal<br>
to NIC 1020 and switch 1030 and audio source 1040 to begin conference call<br>
processing. Although FIG. 12 is described with respect to SVCs and SVC<br>
identifiers, the present invention is not so limited and any type of link (physical<br>
and/or logical) and link identifier can be used. Also, in embodiments where an<br>
internal audio source is included, conference call agent 1010 adds the internal<br>
audio source as one of the potential N audio participants whose input is to be<br>
mixed at audio source 1040.<br>
The operation of distributed conference bridge 1000 during conference<br>
call processing is shown in FIGs. I3A-13C (steps 1300-1398). Control begins at<br>
step 1300 and proceeds to step 1310. In step 1310, audio source 1040 monitors<br>
energy in the incoming audio streams of the conference call participant CI-CN.<br>
Audio source 1040 can be any type of audio source including, but not limited to,<br>
a digital signal processor (DSP). Any conventional technique for monitoring the<br>
energy of a digitized audio sample can be used. In step 1320, audio source 1040<br>
determines a number of active speakers based on the energy monitored in step<br>
1310. Any number of active speakers can be selected. In one embodiment, a<br>
conference call is limited to three active speakers at a given time. In this case, up<br>
to three active speakers are determined which correspond to the up to three audio<br>
streams having the most energy during the monitoring in step 1320.<br>
Next, audio source 1040 generates and sends fully mixed and partially<br>
mixed audio streams (steps 1330-1360). In step 1330, one fully mixed audio<br>
stream is generated. The fully mixed audio stream includes the audio content of<br>
the active speakers determined in step 1320. In one embodiment, the fully mixed<br>
audio stream is an audio stream of packets with packet headers and payloads.<br>
Packet header information identifies the active speakers whose audio content is<br>
included in the fully mixed audio stream. In one example, as shown in FIG. 14A<br>
audio source 1040 generates an outbound internal packet 1400 having a packet<br>
header 1401 with TAS. IAS, and Sequence fields and a payload 1403. The TAS<br>
field lists CIDs of all of the current active speaker calls in the conference call.<br>
The IAS field lists CIDs of the active speakers whose audio content is in the<br>
mixed stream. The sequence information can be a timestamp, numeric sequence<br>
value, or other type of sequence information. Other fields (not shown) can<br>
include checksum or other packet information depending upon a particular<br>
application. In the case of a fully mixed audio stream, the TAS and IAS fields are<br>
identical. Payload 1403 contains a portion of the digitized mixed audio in the<br>
fully mixed audio stream.<br>
In step 1340, audio source 1040 sends the fully mixed audio stream<br>
generated in step 1330 to switch 1030. Eventually, passive participants in the<br>
conference call (that is those determined not to be in the number of active<br>
speakers determined in step 1320), will hear mixed audio from the fully mixed<br>
audio stream.<br>
In step 1350, audio source 1040 generates a set of partially mixed audio<br>
streams. The set of partially mixed audio streams is then sent to switch 1030<br>
(step 1360). Each of the partially mixed audio streams generated in step 1350 and<br>
sent in step 1360 includes the mixed audio content of the group of identified<br>
active speakers determined in step 1320 minus the audio content of a respective<br>
recipient active speaker. The recipient active speaker is the active speaker within<br>
the group of active speakers determined in step 1320 towards which a partially<br>
mixed audio stream is directed.<br>
In one embodiment, audio source 1040 inserts in packet payloads the<br>
digital audio from the group of identified active speakers minus the audio content<br>
of the recipient active speaker. In this way, the recipient active speaker will not<br>
receive audio corresponding to their own speech or audio input. However, the<br>
recipient active speaker will hear the speech or audio input of the other active<br>
speakers. In one embodiment, packet header information is included in each<br>
partially mixed audio stream to identify active speakers whose audio content is<br>
included in the respective partially mixed audio stream. In one example, audio<br>
source 1040 uses the packet format of FIG.14A and inserts one or more<br>
conference identification numbers (CIDs) into TAS and IAS header fields of<br>
packets. The TAS field lists CIDs of all of the current active speakers in the<br>
conference call. The IAS field lists CIDs of the active speakers whose audio<br>
content is in the respective partially mixed stream. In the case of a partially<br>
mixed audio stream, the TAS and IAS fields are not identical since the IAS field<br>
has one less CID. In one example, to build packets in steps 1330 and 1350, audio<br>
source 1040 retrieves the appropriate CID information of conference call<br>
participants from a relatively static look-up table (such as table 1025 or a separate<br>
table) generated and stored at the initiation of the conference call.<br>
For example, in a conference call where there are 64 participants (N = 64)<br>
of which three are identified as active speakers (1-3), then one fully mixed audio<br>
stream will contain audio from all three active speakers. This fully mixed stream<br>
is eventually sent to each of the 61 passive participants. Three partially mixed<br>
audio streams are then generated in step 1350. A first partially mixed stream 1<br>
contains audio from speakers 2-3 but not speaker 1. A second partially mixed<br>
stream 2 contains audio from speakers 1-3 but not speaker 2. A third partially<br>
mixed stream 3 contains audio from speakers 1 and 2 but not speaker 3. The first<br>
through third partially mixed audio streams are eventually sent to speakers 1-3<br>
respectively. In this way only four mixed audio streams (one fully mixed and<br>
three partially mixed) need be generated by audio source 1040. This reduces the<br>
work on audio source 1040.<br>
As shown in FIG. 13B, in step 1370, multicaster 1050 replicates packets<br>
in the fully mixed audio stream and set of partially mixed audio streams and<br>
multicasts the replicated packet copies on all of the SVCs (SVC1-SVCN)<br>
assigned to the conference call. NIC 1020 then processes each packet received<br>
on the SVC (step 1380). For clarity, each packet processed internally in<br>
distributed conference bridge 1000 (including packets received at SVCs by NIC<br>
1020) are referred to as internal packets. Internal packets can be any type of<br>
packet format including, but not limited to, IP packets and/or internal egress<br>
packets described above in Figs. 7A and 7B, and the example internal egress or<br>
outbound packet described with respect to FIG. 14A.<br>
For each SVC, NIC 1020 determines whether to discard or forward a<br>
received internal packet for further packet processing and eventual transmission<br>
to a corresponding conference call participant (step 1381). The received internal<br>
packet can be from a fully mixed or partially mixed audio stream. If yes, the<br>
packet is to be forwarded, then control proceeds to step 1390. If no, the packet<br>
is not to be forwarded, then control proceeds to step 1380 to process the next<br>
packet. In step 1390, the packet is processed into a network IP packet. In one<br>
embodiment, packet processor 1070 generates a packet header with at least the<br>
participant's network address information (IP and/or UDP address) obtained from<br>
the look-up table 1025. Packet processor 1070 further adds sequence information<br>
such as RTP/RTCP packet header information (e.g., a timestamp and/or other<br>
type of sequence information). Packet processor 1070 can generate such<br>
sequence information based on the order of received packets and/or based on<br>
sequence information (e.g. the Sequence field) provided in packets generated by<br>
the audio source 1040 (or by multicaster 1050). Packet processor 1070 further<br>
adds a payload in each network packet that includes audio from the received<br>
internal packet being forwarded to a participant. NIC 1020 (or packet processor<br>
1070) then sends the generated IP packet to the participant (step 1395).<br>
One feature of the present invention is that the packet processing<br>
determination in step 1381 can be performed quickly and in real-time during a<br>
conference call. FIG. 13C shows one example routine for carrying out the packet<br>
processing determination step 1381 according to the present invention (steps<br>
1382-1389). This routine is carried out for each outbound packet that arrives on<br>
each SVC. NIC 1020 acts as a filter or selector in determining which packets are<br>
discarded and which are converted to IP packets and sent to a call participant.<br>
When an internal packet arrives on a SVC, NIC 1020 looks up an entry<br>
in look up table 1025 that corresponds to the particular SVC and obtains a CID<br>
value (step 1382). NIC 1020 then determines whether the obtained CID value<br>
matches any CID value in the Total Active Speakers (TAS) field of the internal<br>
packet (step 1383). If yes, control proceeds to step 1384. If no, control proceeds<br>
to step 1386. In step 1384, NIC 1020 determines whether the obtained CID value<br>
matches any CID value in the Included Active Speakers (IAS) field of the internal<br>
packet. If yes, control proceeds to step 1385. If no, control proceeds to step<br>
1387. In step 1385, the packet is discarded. Control then proceeds to step 1389<br>
which returns control to step 1380 to process a next packet. In step 1387, control<br>
jumps to step 1390 for generating an IP packet from the internal packet.<br>
In step 1386, a comparison of the TAS and IAS fields is made. If the<br>
fields are identical (as in the case of a fully mixed audio stream packet), then<br>
control proceeds to step 1387. In step 1387, control jumps to step 1390. If the<br>
TAS and IAS fields are not identical, then control proceeds to step 1385 and the<br>
packet is discarded.<br>
C. Outbound Packet Flow through Distributed Conference Bridge<br>
Outbound packet flow in distributed conference bridge 1000 is described<br>
further with respect to example packets in a 64-person conference call shown in<br>
FIGs. 14 and 15. In FIGs. 14 and 15, mixed audio content in a packet payload is<br>
denoted by a bracket surrounding the respective participants whose audio is<br>
mixed (e.g., {C1,C2,C3}). CID information in packet headers is denoted by<br>
underlining the respective active speaker participants (e.g., C1, C2, C3, etc.).<br>
Sequence information is simply shown by a sequence number 0,1 etc.<br>
In this example, there are 64 participants C1-C64 in a conference call of<br>
which three are identified as active speakers at a given time (C1-C3). Audio<br>
participants C4-C64 are considered passive and their audio is not mixed. Audio<br>
source 1040 generates one fully mixed audio stream FM having audio from all 3<br>
active speakers (C1-C3). FIG. 14B shows two example internal packets 1402,<br>
1404 generated by audio source 1040 during this conference call. Packets 1402,<br>
1404 in stream FM have a packet header and payload. The payloads in packets<br>
1402,1404 each include mixed audio from each of the three active speakers C1-<br>
C3. Packets 1402,1404 each include packet headers having TAS and IAS fields.<br>
The TAS field contains CIDs for the total three active speakers C1-C3. The IAS<br>
field contains CIDs for the active speakers C1-C3 whose content is actually<br>
mixed in the payload of the packet. Packet 1402,1404 further include sequence<br>
information 0 and 1 respectively to indicate packet 1402 precedes packet 1404.<br>
Mixed audio from fully mixed stream FM is eventually sent to each of the 61<br>
currently passive participants (C4-C64).<br>
Three partially mixed audio streams PM1-PM3 are generated by audio<br>
source 1040. FIG. 14B shows two packets 1412, 1414 of first partially mixed<br>
stream PM1. Payloads in packets 1412 andl414 contain mixed audio from<br>
speakers C2 and C3 but not speaker CI. Packets 1412,1414 each include packet<br>
headers. The TAS field contains CIDs for the total three active speakers C1-C3.<br>
The IAS field contains CIDs for the two active speakers C2 and C3 whose<br>
content is actually mixed in the payload of the packet. Packet 1412,1414 have<br>
sequence information 0 and 1 respectively to indicate packet 1412 precedes<br>
packet 1414. FIG. 14B shows two packets 1422,1424 of second partially mixed<br>
stream PM2. Payloads in packets 1422 and 1424 contain mixed audio from<br>
speakers C1 and C3 but not speaker C2. Packets 1422,1424 each include packet<br>
headers. The TAS field contains CIDs for the total three active speakers C1-C3.<br>
The IAS field contains CIDs for the two active speakers C1 and C3 whose<br>
content is actually mixed in the payload of the packet. Packets 1422,1424 have<br>
sequence information 0 and 1 respectively to indicate packet 1422 precedes<br>
packet 1424. FIG. 14B further shows two packets 1432,1434 of third partially<br>
mixed stream PM3. Payloads in packets 1432 and 1434 contain mixed audio from<br>
speakers C1 and C2 but not speaker C3. Packets 1432,1434 each include packet<br>
headers. The TAS field contains CIDs for the total three active speakers C1-C3.<br>
The IAS field contains CIDs for the two active speakers C1 and C2 whose<br>
content is actually mixed in the payload of the packet. Packets 1432,1434 have<br>
sequence information 0 and 1 respectively to indicate packet 1432 precedes<br>
packet 1434.<br>
FIG. 15 is a diagram that illustrates example packet content after the<br>
packets of FIG. 14 have been multicasted and after they have been processed into<br>
IP packets to be sent to appropriate conference call participants according to the<br>
present invention. In particular, packets 1412,1422,1432,1402,1414 are shown<br>
as they are multicast across each of SVC1-SVC64 and arrive at NIC 1020. As<br>
described above with respect to step 1381, NIC 1020 determines for each SVC1-<br>
SVC64 which packets 1412,1422,1432,1402,1414 are appropriate to forward<br>
to a respective conference call participant C1-C64. Network packets (e.g. IP<br>
packets) are then generated by packet processor 1070 and sent to the respective<br>
conference call participant C1-C64.<br>
As shown in FIG. 15, for SVC1, packets 1412 and 1414 are determined<br>
to be forwarded to C1 based on their packet headers. Packets 1412,1414 have<br>
the CID of C1 in the TAS field but not the IAS field. Packets 1412 and 1414 are<br>
converted to network packets 1512 and 1514. Network packets 1512, 1514<br>
include the IP address of C1 (C1ADDR) and die mixed audio from speakers C2<br>
and C3 but not speaker CI. Packets 1512,1514 have sequence information 0 and<br>
1 respectively to indicate packet 1512 precedes packet 1514. For SVC2<br>
(corresponding to conference call participant C2), packet 1422 is determined to<br>
be forwarded to C2. Packet 1422 has the CID of C2 in the TAS field but not the<br>
IAS field. Packet 1422 is converted to network packet 1522. Network packet<br>
1522 includes the IP address of C2 (C2ADDR), sequence information 0, and the<br>
mixed audio from speakers C1 and C3 but not speaker C2. For SVC3<br>
(corresponding to conference call participant C3), packet 1432 is determined to<br>
be forwarded to C3. Packet 1432 has the CID of C3 in the TAS field but not the<br>
IAS field. Packet 1432 is converted to network packet 1532. Network packet<br>
1532 includes the IP address of C3 (C3ADDR), sequence information 0, and the<br>
mixed audio from speakers C1 and C2 but not speaker C3. For SVC4<br>
(corresponding to conference call participant C4), packet 1402 is determined to<br>
be forwarded to C4. Packet 1402 does not have the CID of C4 in the TAS field<br>
and the TAS and IAS fields are identical indicating a fully-mixed stream. Packet<br>
1402 is converted to network packet 1502. Network packet 1502 includes the IP<br>
address of C4 (C4ADDR), sequence information 0, and the mixed audio from all<br>
of the active speakers C1, C2, and C3. Each of the other passive participants C5-<br>
C64 receive similar packets. For example, for SVC64 (corresponding to<br>
conference call participant C64), packet 1402 is determined to be forwarded to<br>
C64. Packet 1402 is converted to network packet 1503. Network packet 1503<br>
includes the IP address of C64 (C64ADDR), sequence infonnation 0, and the<br>
mixed audio from all of the active speakers C1, C2, and C3.<br>
D. Control Logic and Additional Embodiments<br>
Functionality described above with respect to the operation of conference<br>
bridge 1000 (including conference call agent 1010, NIC 1020, switch 1030, audio<br>
source 1040, and multi-caster 1050) can be implemented in control logic. Such<br>
control logic can be implemented in software, firmware, hardware or any<br>
combination thereof.<br>
In one embodiment, distributed conference bridge 1000 is implemented<br>
in a media server such as media server 202. In one embodiment, distributed<br>
conference bridge 1000 is implemented in audio processing platform 230.<br>
Conference call agent 1010 is part of call control and audio feature manager 302.<br>
NIC 306 carries out the network interface functions of NIC 1020 and packet<br>
processors 307 carry out the function of packet processor 1070. Switch 304 is<br>
replaced with switch 1030 and multicaster 1050. Any of audio sources 308 can<br>
carry out the function of audio source 1040.<br>
XI. Conclusion<br>
While specific embodiments of the.present invention have been described<br>
above, it should be understood that they have been presented by way of example<br>
only, and not limitation. It will be understood by those skilled in the art that<br>
various changes in form and details may be made therein without departing from<br>
the spirit and scope of the invention as defined in the appended claims. Thus, the<br>
breadth and scope of the present invention should not be limited by any of the<br>
above-described exemplary embodiments, but should be defined only in<br>
accordance with the following claims and their equivalents.<br>
WE CLAIM :<br>
1. A method for processing audio in a conference call among participants,<br>
comprising:<br>
(a) generating a fully mixed audio stream of packets, each packet having a<br>
packet header and payload;<br>
(b) generating a set of partially mixed audio streams of packets, each packet<br>
having a packet header and payload;<br>
(c) multicasting each packet in the fully mixed audio stream and the set of<br>
partially mixed audio streams; and<br>
(d) determining which multicasted packets to forward based on packet header<br>
information Tn the respective packets.<br>
2. The method as claimed in claim 1, comprising, prior to said steps (a) and (b):<br>
initiating the conference call among the participants; and<br>
storing conference identifier information (CID) and network address<br>
information associated with each participant in theJnitiated conference call.<br>
3. The method as claimed in claim 2, comprising:<br>
assigning switched virtual circuits (SVCs) to respective participants in the<br>
conference call; wherein said storing step also comprises storing said CID and<br>
network address information such that said CID and network address information for<br>
each participant can be retrieved based on a respective assigned SVC.<br>
4. The method as claimed in claim 1, comprising:<br>
monitoring energy in inbound audio streams of the participants; and<br>
determining a number of active speakers based on the monitored energy.<br>
5. The method as claimed in claim 4, wherein said generating steps (a) and (b)<br>
generate packet headers having active speaker information based on the determined<br>
member of active speakers, and said determining step (d) determines which<br>
malticasted packets to forward to participants based on the active speaker<br>
information in the respective packet headers.<br>
6. The method as claimed in claim 5, wherein the active speaker information<br>
comprises TAS and IAS fields, and wherein said generating step (a) generates a fully<br>
mixed audio stream of packets having packet headers which include TAS and IAS<br>
fields, and said generating step (b) generates a set of partially mixed audio streams<br>
of packets having packet headers which include TAS and IAS fields.<br>
7. The method as claimed in claim 6, wherein said determining step (d)<br>
determines which multicasted packets to forward to participants based on the<br>
information in the TAS and IAS fields in the respective packet headers.<br>
8. The method as claimed in claim 6, wherein said determining step (d)<br>
comprises for each packet being processed at a SVC the steps of:<br>
obtaining a CID value for the SVC; and<br>
determining whether the obtained CID value matches any CID value in the<br>
TAS field of the packet, and if a match exits, determining whether the obtained CID<br>
value matches any CID value in the IAS field of the packet, whereby, the packet is<br>
discarded when a match exists between the obtained CID value and any CID value<br>
in the TAS field and a match exists between the obtained CID value and any CID<br>
value in the IAS field.<br>
9. The method as claimed in claim 8, comprising, when a match does not exist<br>
between the obtained CID value and any CID value in the TAS field of a packet,<br>
comparing the TAS and IAS fields, whereby, when the compared fields are identical<br>
the packet can be converted to a network packet, otherwise when the compared<br>
fields are not identical the packet can be discarded.<br>
10. The method as claimed in claim 6, wherein the packet header comprises<br>
sequence information, and wherein said generating step (a) generates a fully mixed<br>
audio stream of packets having packet headers which include the sequence<br>
information, and said generating step (b) generates a set of partially mixed audio<br>
streams of packets having packet headers which include the sequence information.<br>
11. The method as claimed in claim 1, wherein:<br>
said generating step (a) generates a fully mixed audio stream of packets, each<br>
packet having a packet header and payload, wherein the payload includes mixed<br>
audio from at least three active speakers; and<br>
said generating step (b) generates a set of partially mixed audio streams of<br>
packets, each packet having a packet header and payload, wherein for each partially<br>
mixed audio stream of packets the payload includes mixed audio from the at least<br>
three active speakers minus the audio of a respective recipient active speaker.<br>
12. The method as claimed in claim 1, comprising:<br>
processing packets determined to be forwarded in said determining step (d)<br>
into network packets having network addresses of participants in the conference call;<br>
and<br>
sending the network packets to the participants.<br>
13. The method as claimed in claim 1, comprising mixing audio received over a<br>
network from participants in the conference call who are active speakers.<br>
14. The method as claimed in claim 1, comprising mixing audio received from an<br>
internal audio source and audio received over a network from participants in the<br>
conference call who are active speakers.<br>
15. A conference bridge that processes audio in a conference call among<br>
participants, comprising:<br>
an audio source that generates a fully mixed audio stream of packets and a<br>
set of partially mixed audio streams of packets, each packet having a packet header<br>
and pay load;<br>
a switch; and<br>
a network interface controller,<br>
wherein said switch is coupled between said network interface controller and<br>
said audio source and said switch also comprises a multicaster; and<br>
wherein said multicaster multicasts each packet in the fully mixed audio<br>
stream and the set of partially mixed audio streams to the network interface<br>
controller, and said network interface controller determines which multicasted<br>
packets to forward based on packet header information in the respective packets.<br>
16. The conference bridge as claimed in claim 15, comprising a conference call<br>
agent that initiates a conference call among the participants.<br>
17. The conference bridge as claimed in claim 16, comprising a storage device<br>
that stores conference identifier.information. (CID) and network address information,<br>
associated with each participant in the established conference call.<br>
18. The conference bridge as claimed in claim 17, wherein said storage device<br>
comprises a look-up table.<br>
19. The conference bridge as claimed in claim 17, wherein said network interface<br>
controller assigns switched virtual circuits (SVCs) to respective participants in the<br>
initiated conference call, and said storage device stores said CID and network<br>
address information such that said CID and network address information for each<br>
participant can be retrieved based on a respective assigned SVC.<br>
20. The conference bridge as claimed in claim 15, wherein said audio source<br>
monitors energy in inbound audio streams of the participants, and determines a<br>
number of active speakers based on the monitored energy.<br>
21. The conference bridge as claimed in claim 20, wherein said packet headers<br>
generated by said audio source have active speaker information based on the<br>
determined number of active speakers, and said network interface controller<br>
determines which multicasted packets to forward to participants based on the active<br>
speaker information in the respective packet headers.<br>
22. The conference bridge as claimed in claim 21, wherein the active speaker<br>
information comprises TAS and IAS fields, and said network interface controller<br>
determines which multicasted packets to forward to participants based on the<br>
information in said TAS and IAS fields in the respective packet headers.<br>
23. The conference bridge as claimed in claim 22, wherein said packet headers<br>
generated by said audio source also comprise sequence information.<br>
24. The conference bridge as claimed in claim 15, wherein said fully mixed audio<br>
stream of packets have payloads which include mixed audio from at least three<br>
active speakers, and each partially mixed audio stream of packets.jn. said set have<br>
payloads which include mixed audio from the at least three active speakers minus<br>
the audio of a respective recipient active speaker.<br>
25. The conference bridge as claimed in claim 15, comprising:<br>
a packet processor that processes packets determined to be forwarded into network<br>
packets having network addresses of participants in the conference call.<br>
26. The conference bridge as claimed in claim 15, wherein said audio source<br>
mixes audio received over a network from participants in the conference call who are<br>
active speakers.<br>
27. The conference bridge as claimed in claim 15, wherein said audio source<br>
mixes audio received from an internal audio source and audio received over a<br>
network from participants in the conference call who are active speakers.<br>
28. A system for processing audio in a conference call among participants,<br>
comprising:<br>
(a) means for generating a fully mixed audio stream of packets, each packet<br>
having a packet header and payload;<br>
(b) means for generating a set of partially mixed audio streams of packets,<br>
each packet having a packet header and payload;<br>
(c) means for multicasting each packet in the fully mixed audio stream and the<br>
set of partially mixed audio streams; and<br>
(d) means for determining which multicasted packets to forward based on<br>
packet header information in the respective packets.<br>
29. A media server for use in a VOIP network, comprising:<br>
a distributed conference, bridge that processes audio in a conference call<br>
among participants, said distributed conference bridge comprising:<br>
an audio source that generates a fully mixed audio stream of packets and a<br>
set of partially mixed audio streams of packets, each packet having a packet header .<br>
and payload;<br>
a switch; and<br>
a network interface controller,<br>
wherein said switch is coupled between said network interface controller and<br>
said audio source and said switch also comprises a multicaster; and<br>
wherein said multicaster multicasts each packet in the fully mixed audio<br>
stream and the set of partially mixed audio streams to the network interface<br>
controller, and said network interface controller determines which multicasted<br>
packets to forward based on packet header information in the respective packets.<br><br>
The present invention provides a method and system for providing media services in<br>
Voice over IP telephony. A switch is coupled between one or more audio sources<br>
and a network interface controller. The switch can be a packet switch or a cell<br>
switch (304). The present invention further provides a method and system for<br>
distributed conference bridge processing in Voice over IP telephony. A distributed<br>
conference bridge multi-casts mixed audio content of a conference call in a way that<br>
reduces replication work at the mixing device. The present invention also provides a<br>
method and system for noiselessly switching between independent audio streams.<br>
Such noiseless switching preserves valid RTP information at the time of switch over.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWFzc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-assignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWNvcnJlc3BvbmRlbmNlLnBkZg==" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWV4YW1pbmF0aW9uIHJlcG9ydC5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLXJlcGx5IHRvIGV4YW1pbmF0aW9uIHJlcG9ydC5wZGY=" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NTYta29sbnAtMjAwNC1ncmFudGVkLXNwZWNpZmljYXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">56-kolnp-2004-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="233927-a-method-for-forming-molds-and-a-core-for-casting-metal.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="233929-method-of-making-mercaptoalkylalkoxysilanes.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>233928</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>56/KOLNP/2004</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>17/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>24-Apr-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>22-Apr-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>16-Jan-2004</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>IP UNITY</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>475 SYCAMORE DRIVE, MILPITAS, CALIFORNIA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DOST SERKAN RECEP</td>
											<td>1555 RIVEIRA AVENUE #625, WALNUT CREEK, CA 94596</td>
										</tr>
										<tr>
											<td>2</td>
											<td>LAURSEN DAVID</td>
											<td>4029 SKYLARK LANE, DANVILLE, CA 94506</td>
										</tr>
										<tr>
											<td>3</td>
											<td>ISRAEL DAVID</td>
											<td>2065 CARPENTER STREET, SANTA CLARA, CA 95051</td>
										</tr>
										<tr>
											<td>4</td>
											<td>MCKNIGHT THOMAS</td>
											<td>592 MILL CREEK LANE #304, SANTA CLARA,CA 95054</td>
										</tr>
										<tr>
											<td>5</td>
											<td>STANWYCK DONALD A.</td>
											<td>2182 EAST 129TH DRIVE, THORNTON, CO 80241-1910</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04L 12/16</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2002/20359</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2002-06-28</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>09/893,743</td>
									<td>2001-06-29</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>09/930,500</td>
									<td>2001-08-16</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>3</td>
									<td>10/122,397</td>
									<td>2002-04-16</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/233928-a-method-and-system-for-processing-audio-in-a-conference-call-among-participants by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:58:37 GMT -->
</html>
