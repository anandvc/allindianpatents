<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/218553-method-and-receiver-for-providing-audio-translation-data-on-demand by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:49:22 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 218553:METHOD AND RECEIVER FOR PROVIDING AUDIO TRANSLATION DATA ON DEMAND.</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND RECEIVER FOR PROVIDING AUDIO TRANSLATION DATA ON DEMAND.</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Video data are transmitted to a receiver. A language menu displayed from which a user selects a language that can be different from the original language broadcast with the video data. Video data identification information and language identification information corresponding to the language selected from the menu is derived and transmitted to e.g. an Internet server. The identification information is used to select an audio translation data set from several audio translation data sets stored in said server, wherein each of said several audio translation data sets includes a language translation of original audio data related to said video data. The selected audio translation data set is sent to the receiver and reproduced synchronously together with said video data.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>Method and receiver for providing audio translation data on<br>
demand<br>
The invention relates to the field of providing audio trans-<br>
lation data on demand to a receiver.<br>
Background<br>
The number of television (TV) channels a user; can receive<br>
has increased significantly because of the further develop-<br>
ment of terrestrial TV, satellite TV and web. T.V. technology<br>
including digital TV transmission. In addition, video media,<br>
such as cassette, CD and DVD offer more programs or movies<br>
to the home.<br>
Invention<br>
The above developments lead also to an increased share of<br>
foreign language programs or movies.<br>
In an increasing number of countries or geographical regions<br>
there are multi-language requirements: there may be used<br>
more than one native language in one country or region, or<br>
non-native residents prefer to have their native language<br>
for home-entertainment. Therefore there is a growing need<br>
for broadcasting programs or movies with audio data or sub-<br>
titles corresponding to a language translation preferred by<br>
the respective consumers.<br>
A problem to be solved by the invention is to provide audio<br>
or subtitle translation data on demand,<br>
a receiver that utilises this method <br>
and a method for providing corresponding audit or subtile<br>
translation data on demand to such receiver <br>
as described hereunder.<br>
One aspect of the invention is a method for providing audio<br>
or subtitle translation data on demand to a receiver, the<br>
method including the following steps:<br>
- receiving video data;<br>
- receiving first identification information corresponding<br>
to said video data;<br>
- detecting a user-performed selection of a preferred lan-<br>
guage;<br>
- providing second identification information corresponding<br>
to said preferred language;<br>
- transmitting, e.g. via Internet, third identification in-<br>
formation derived from said first and second identification<br>
information to a server for requesting, based on said third<br>
identification information, a desired audio or subtitle<br>
translation data set corresponding to said video data;<br>
- receiving, e.g. via Internet, said seleoted audio or sub-<br>
title translation data set;<br>
- reproducing, at least partly, data of said requested audio<br>
or subtitle translation data set temporally synchronised<br>
with said video data.<br>
According to another aspect, the invention concerns a re-<br>
ceiver for providing audio or subtitle translation data on<br>
demand, the receiver including:<br>
- means for receiving video data and firso identification<br>
information corresponding to said video data;<br>
- means for detecting a user-performed selection of a pre-<br>
ferred language;<br>
- means for providing second identification information cor-<br>
respondina to said preferred language;<br>
- means for transmitting, e.g. via Internet, third identifi-<br>
cation information derived from said first and second iden-<br>
tification information to a server for requesting, based on<br>
said third identification information, a desired audio or<br>
subtitle translation data set corresponding to said video<br>
data;<br>
- means for receiving, e.g. via Internet, said selected au-<br>
dio or subtitle translation data set;<br>
- means for reproducing, at least partly, data of said re-<br>
quested audio or subtitle translation data set temporally<br>
synchronised with said video data.<br>
According to a further aspect, the invention concerns a<br>
method for providing audio or subtitle translation data on<br>
demand, including the steps:<br>
- receiving, e.g. via Internet, identification information<br>
requested by a user, wherein said identification information<br>
corresponds to a preferred language and to video data that<br>
are originally accompanied by audio or subtitle data in a<br>
language different from said preferred language;<br>
- storing or generating audio or subtitle translation data<br>
sets assigned to different languages for related video data,<br>
wherein each of said audio or subtitle translation data sets<br>
includes a language translation of original language audio<br>
or subtitle data related to specific ones of said video<br>
data;<br>
- selecting, upon receiving said identification information,<br>
an audio or subtitle translation data set, wherein the se-<br>
lected audio or subtitle translation data set represents a<br>
language translation of said original language audio or sub-<br>
title data corresponding to said preferred language,<br>
- transmitting, e.g. via Internet, said selected audio or<br>
subtitle translation data set for providing it to a receiver<br>
of said user.<br>
The invention is based on the idea that different audio<br>
translation data sets are available in an archive,<br>
preferably an online archive. The different audio<br>
translation data sets can be ordered by a user of a<br>
television and/or video system. This allows the user to<br>
have a movie or film broadcast with audio signals<br>
corresponding to a language preferred him. For example, a<br>
visitor staying in a hotel of a foreign country can vatch<br>
movies provided with audio signals corresponding to his<br>
native language.<br>
The invention also allows to watch a movie, scientific<br>
programmes etc. in a certain foreign language or with<br>
subtitles in a certain foreign language in order to train<br>
the user"s knowledge of this specific foreign language.<br>
Drawings<br>
Exemplary embodiments of the invention are described with<br>
reference to the accompanying drawings, which show in :<br>
Fig. 1 a schematic representation of a system according to<br>
the invention;<br>
Fig. 2 a simplified block diagram of an online slation<br>
archive.<br>
US Patent 5,982,448 uses multiple sub-channels in order to<br>
transmit multiple language text together with the video<br>
signal. One of these received and already available<br>
languages can be selected There is no transmission upon<br>
request or demand for a specific language. A significant<br>
amount of available data rate is wasted because multiple<br>
non-desired language signals are transmitted. This<br>
disadvantageous effect would even be worse if the life<br>
audio signals would be transmitted.<br>
There are several inventive differences between the present<br>
invention and DE 197 13490. In the present invention :<br>
• The broadcast and received video data include<br>
identification data for these video data;<br>
• These identification data can be automatically-<br>
combined with identification data corresponding to a<br>
default user-preferred language;<br>
• The corresponding combined identification data are<br>
sent automatically to a server for automatic download<br>
of preferred-language audio/subtitle data.<br>
Thereby a fully automatic tranolation of broadcast bound is<br>
facilitated. The user, after having entered his preferred<br>
language once only, can watch TV in foreign countries<br>
together vith sound or subtitles in his language. No<br>
further action is required.<br>
In DE 19713490, however, the video data must be identified<br>
by the user, i.e. he must type in corresponding code, and<br>
he must request receiving desired subtitles on a case-by-<br>
case basis.<br>
Exemplary embodiments<br>
Referring to Figure 1, the invention can be embodied in a<br>
system including a television and/or video device 1 for<br>
broadcasting a movie or film, an interface 2, and server<br>
means 3 to which several translator accounts 4 are<br>
assigned. The server means may be any kind of computer for<br>
operating a ......................<br>
database storing an archive of trarslation data. The server<br>
may be located at the broadcast station supplying the movie<br>
or film or at a company specialized on the supply of trans-<br>
lation data.<br>
The server means may be connected with a translator studio<br>
5. A user may control the television or video device 1<br>
and/or the interface 2 by means of a remote control 6 and/or<br>
by voice control. The interface 2 may be contained in the<br>
device 1, which device can be e.g. a settop-box or a TV re-<br>
ceiver or video recorder.<br>
If a user of the device 1 likes to watch a movie broadcast<br>
in any language with audio signals in a preferred language,<br>
a language menu can be provided on a display 14 of the de-<br>
vice 1. By means of the language menu a list of several lan-<br>
guage options is presented to the user of device 1, each of<br>
the several language options representing audio translation<br>
data of a different language and/or from a different trans-<br>
lator. From the language menu the user can select a language<br>
option corresponding to the language preferred by the user.<br>
The selection of the language option may be performed by<br>
means of the remote control 6 the transmitted commands of<br>
which are received by an IR receiver 12 contained in device<br>
1.<br>
It is also possible to select a preferred language by a spo-<br>
ken command, which is detected by a microphone. This micro-<br>
phone can be integrated in the remote control or in the<br>
housing of the device 1.<br>
Furthermore, it is possible to select not only one preferred<br>
language but a most preferred language and a second most<br>
preferred language. In order to make this more clear, the<br>
following example is given. If for instance a German user<br>
stays e.g. in China and is not familiar with the Chinese<br>
language but with e.g. the English Language, he may choose<br>
German as the most preferred language and English as the<br>
second most preferred language. In this way, the German user<br>
will get translation data in German language, if these are<br>
available. If not, he will receive translation data in Eng-<br>
lish language, if these are available. Only if neither Ger-<br>
man nor English translation data is available, he has to<br>
watch the movie with the original language.<br>
The user"s selection of the language option is evaluated in<br>
means 13 for providing identification information correspon-<br>
ding to the preferred language and the video data cf the<br>
movie the user intends to watch. The identification informa-<br>
tion is automatically passed using controlling means 11 to<br>
an output of device 1, which output may be connected to the<br>
Internet or any other source providing data to the user"s<br>
device. The identification information may include the title<br>
of the movie or some other identification code extracted<br>
from VPS data, teletext data, MPEG7 data or an EPG (Elec-<br>
tronic Program Guide).<br>
The identification information is transmitted to a server 3,<br>
preferably through an interface 2 with online connection<br>
like an ISDN connection or any other Internet or cable con-<br>
nection. After processing the identification information the<br>
server 3 will supply audio translation data to the interface<br>
2 via a back channel or via the Internet or cable. The audio<br>
translation data may be compressed, e.g. by means of MP3 or<br>
MPEG4 standard. The device 1 will provide video data re-<br>
ceived from a broadcasting station 7 in synchronization with<br>
the audio translation data received from server 3, so that<br>
the user can watch the movie with audio signals and/or sub-<br>
titles corresponding to the language preferred by him.<br>
Also it is possible that the server sends back only an in-<br>
formation. about the availability of the languages of audio<br>
signals and/or subtitles for the selected title. This infor-<br>
mation can be accompanied by an information about the cost<br>
for downloading the translation data. The information about<br>
the available languages can be displayed by a second on-<br>
screen display, possibly together with the cost. The user<br>
then finally decides whether he wants downloading of the<br>
translation data.<br>
The controlling means 11 may control synchronization of the<br>
video data and the audio translation data by means of time<br>
stamps provided in the video data as well as the audio<br>
translation data. If the video data are encoded according to<br>
the MPEG-4 standard, resynchronization marker codes, which<br>
are inserted in the video data stream at certain intervals,<br>
can be used for synchronization. If the audio data are also<br>
MPEG-4 encoded, not the total audio signal but only the<br>
voices to be translated can be transmitted due to the object<br>
oriented transmission. This allows a very low transmission<br>
bit rate.<br>
The audio translation data provided to device 1 may be in-<br>
termediately stored at least partly, e.g. on a hard disc or<br>
other storage devices.<br>
In the means 13 for providing identification information, or<br>
in the controlling means 11, the user"s language selection,<br>
or selections, may be stored permanently or for a predeter-<br>
mined period of time so that, always or during the predeter-<br>
mined period of time, audio translation data corresponding<br>
to the stored preferred language selection will be automati-<br>
cally delivered to the device 1 whenever the user wants to<br>
watch a movie, without it being necessary to display the<br>
language menu on the display 14. For example, r;r a period<br>
staying in a hotel abroad, a visitor will have the opportu-<br>
nity to watch movies in the hotel with audio translation<br>
data corresponding to his native language, if a respective<br>
language selection made by the visitor is stored.<br>
The service of providing translation data on demand may be<br>
free of charge or charged, wherein the user"s payment can be<br>
controlled by means of the interface 2 or controlling means<br>
11.<br>
Referring to Figure 2, in the server means 3 the audio<br>
translation data are arranged e.g. in translator accounts<br>
10, 11, 12, each being related to a translator A, B and C,<br>
respectively, as schematically shown in Figure 2. A transla-<br>
tor A may have a respective account for German (account 10<br>
in Figure 2), English, French (account 13 in Figure 2)<br>
and/or other languages. There may be more than one set of<br>
audio translation data available in the server means 3, each<br>
set representing, for example, a German translation for a<br>
specific movie and generated by a different translator, giv-<br>
ing the user the opportunity to select German audio transla-<br>
tion data for the specific movie from a preferred transla-<br>
tor.<br>
Translators may generate audio translation data in the<br>
translator studio 5. The translator studio 5 provides a<br>
user-friendly website interface, technical support and<br>
translation guidance to the translators. An online connec-<br>
tion may be established between the translator studio 5 and<br>
the server means 4 to transmit audio translation data. The<br>
translator may set up a new translator account, add new au-<br>
dio translation data to the account 4 or delete previous<br>
version from the account 4. Audio translation data may be<br>
stored as text and/or voice data. In addition, the transla-<br>
tor studio 5 may provide online payment to the translators.<br>
It is possible to assign the required functions to different<br>
units: for instance, providing identification information<br>
can be accomplished in interface 2 whereby means 13 can be<br>
omitted and IR receiver 12 is connected directly to control-<br>
ling means 11.<br>
The audio or subtitle translation data set mentioned above<br>
can be a data set including the complete sound track/sub-<br>
title track of one program or one movie.<br>
In connection with recording a program or movie using pro-<br>
gramming, in particular VPS or ShowView programming, it is<br>
advantageous to either automatically download and intermedi-<br>
ately store the audio or subtitle translation data set in<br>
advance, or to download and record the audio or subtitle<br>
translation data set during or after finishing the recording<br>
of the related video data and possibly original audio/sub-<br>
title data.<br>
1. Mothed for providing audio or subtitle translation data<br>
on demand to a receiver (1) or video device (1), the<br>
method comprising the following steps:<br>
- said receiver or video device receiving broadcast video<br>
data for a specific program or movie together with audio<br>
or subtitle data related to a given language, which<br>
video data comprise first identification information<br>
data identifying said specific program or movie video<br>
data ;<br>
- detecting (6, 12) a user-performed selection of a pre-<br>
ferred language that is different from said given lan-<br>
guage ;<br>
- providing (13, 2) second identification information data<br>
corresponding to said preferred language;<br>
- transmitting automatically, e.g. via Internet, third<br>
identification information data derived from said first<br>
and second identification information data from said re-<br>
ceiver or video device to a server (3) for requesting,<br>
based on said third identification information data, a<br>
desired audio or subtitle translation data set corre-<br>
sponding to said video data and corresponding to said<br>
preferred language;<br>
- receiving (11), e.g. via Internet, an audio or subtitle<br>
translation data set corresponding to said third identi-<br>
fication information data;<br>
- reproducing (15), at least partly, data of said received<br>
audio or subtitle translation data set together with<br>
said video data in said receiver or video device in a<br>
temporally synchronised manner.<br>
2. Method as claimed in claim 1, further comprising the<br>
step of displaying (14) a language menu and detecting<br>
(6, 12) the user-performed selection of the preferred<br>
language from said language menu.<br>
3. Method as claimed in claim 1 or 2, wherein from several<br>
available server-stored audio or subtitle translation<br>
data sets one is selected, wherein each of said several<br>
audio or subtitle translation data sets comprises a lan-<br>
guage translation of original language audio or subtitle<br>
data related to said video data, and wherein the se-<br>
lected audio or subtitle translation data set repre-<br>
sents, corresponding to said preferred language, a lan-<br>
guage translation of said original language audio or<br>
subtitle data.<br>
4. Method as claimed in any one of claims 1 to 3, wherein<br>
said user-performed selection is detected, and said pro-<br>
vided second identification information corresponding to<br>
said preferred language is stored, before said video<br>
data are received.<br>
5. Method as claimed in claim 4, wherein said video data<br>
are recorded using programming, e.g. VPS or ShowView<br>
programming, and wherein said audio or subtitle transla-<br>
tion data set is either automatically downloaded and in-<br>
termediately stored in advance, or is downloaded and re-<br>
corded after finishing the recording of the related<br>
video data and possibly original audio or subtitle data.<br>
6. Method as claimed in any one of claims 1 to 5, wherein<br>
time stamps are used for synchronising said video data<br>
with the data of said requested or selected audio or<br>
subtitle translation data set.<br>
7. Method as claimed in claim 6, wherein the data are<br>
MPEG-4 encoded and resynchronisation marker codes are<br>
used for synchronising.<br>
8. Method as claimed in any one of claims 1 to 7, wherein<br>
said first identification information is automatically<br>
provided from corresponding teletext or MPEG7 informa-<br>
tion .<br>
9. Receiver (1) or video device (1) for providing audio or<br>
subtitle translation data on demand, said receiver or<br>
video device comprising:<br>
- means (14) for receiving broadcast video data for a spe-<br>
cific program or movie together with audio or subtitle<br>
data related to a given language, which video data com-<br>
prise first identification information data identifying<br>
said specific program or movie video data;<br>
- means (6, 12) for detecting a user-performed selection<br>
of a preferred language that is different from said<br>
given language;<br>
- means (13, 2) for providing second identification infor-<br>
mation data corresponding to said preferred language;<br>
- means (11) for automatically transmitting, e.g. via<br>
Internet, third identification information data derived<br>
from said first and second identification information<br>
data from said receiver or video device to a server (3)<br>
for requesting, based on said third identification in-<br>
formation data, a desired audio or subtitle translation<br>
data set corresponding to said preferred language;<br>
- means (11) for receiving, e.g. via Internet, an audio or<br>
subtitle translation data set corresponding to said<br>
third identification information data;<br>
- means (15) for reproducing, at least partly, data of<br>
said received audio or subtitle translation data set to-<br>
gether with said video data in said receiver or video<br>
device in a temporally synchronised manner.<br>
10. Receiver as claimed in claim 9, further comprising means<br>
(14) for displaying a language menu, wherein said de-<br>
tecting means (6, 12) detect the user-performed selec-<br>
tion of the preferred language from said language menu.<br>
11. Method for providing audio or subtitle translation data<br>
on demand, comprising the steps:<br>
- receiving (3), e.g. via Internet, identification infor-<br>
mation requested by a user, wherein said identification<br>
information corresponds to a preferred language and to<br>
video data that are originally accompanied by audio or<br>
subtitle data in a language different from said pre-<br>
ferred language;<br>
- storing or generating (A, ..., D) audio or subtitle<br>
translation data sets assigned to different languages<br>
for related video data, wherein each of said audio or<br>
subtitle translation data sets comprises a language<br>
translation of original language audio or subtitle data<br>
related to specific ones of said video data;<br>
- selecting, upon receiving said identification informa-<br>
tion, an audio or subtitle translation data set, wherein<br>
the selected audio or subtitle translation data set<br>
represents a language translation of said original lan-<br>
guage audio or subtitle data corresponding to said pre-<br>
ferred language,<br>
- transmitting (3), e.g. via Internet, said selected audio<br>
or subtitle translation data set for providing it to a<br>
receiver of said user.<br>
Video data are transmitted to a receiver (1). A language menu is<br>
displayed from which a user selects a language that can be<br>
different from the original language broadcast with the video data.<br>
Video data identification information and language identification<br>
information corresponding to the language selected from the menu<br>
is derived and transmitted to select an audio translation<br>
identification information is used to select an audio translation<br>
data set from several audio translation data sets stored in said<br>
server, wherein each of said several audio translation data sets<br>
includes a language translation of original audio data related to<br>
said video data. The selected audio translation data set is sent to<br>
the receiver and reproduced synchronously together with said<br>
video data.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtY29ycmVzcG9uZGVuY2UucGRm" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSAxMy5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSAxOC5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSAyNi5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtZm9ybSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtbGV0dGVyIHBhdGVudC5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-letter patent.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtcmVwbHkgdG8gZXhhbWluYXRpb24gcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-reply to examination report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLWdyYW50ZWQtc3BlY2lmaWNhdGlvbi5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-granted-specification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjgwLWNhbC0yMDAxLXRyYW5zbGF0ZWQgY29weSBvZiBwcmlvcml0eSBkb2N1bWVudC5wZGY=" target="_blank" style="word-wrap:break-word;">280-cal-2001-translated copy of priority document.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="218552-system-for-conveying-goods-with-a-self-contained-conveyor-belt.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="218554-novel-acyl-group-containing-composition.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>218553</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>280/CAL/2001</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>14/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>04-Apr-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>02-Apr-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>14-May-2001</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>DEUTSCHE THOMSON-BRANDT GMBH.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HERMANN-SCHWER-STR.3, D-78048 VILLINGEN-SCHWENNINGEN</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>LI HUI</td>
											<td>HALTENHOFFSTR.221, D-30419 HANNOVER</td>
										</tr>
										<tr>
											<td>2</td>
											<td>RITTNER KARSTEN</td>
											<td>EPIWEG 13, D-30453 HANNOVER</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H 04 N 7/88</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>00250152.6</td>
									<td>2000-05-18</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/218553-method-and-receiver-for-providing-audio-translation-data-on-demand by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:49:23 GMT -->
</html>
