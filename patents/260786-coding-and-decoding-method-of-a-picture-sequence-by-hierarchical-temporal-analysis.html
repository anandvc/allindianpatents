<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/260786-coding-and-decoding-method-of-a-picture-sequence-by-hierarchical-temporal-analysis by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:52:42 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 260786:&quot;CODING AND DECODING METHOD OF A PICTURE SEQUENCE BY HIERARCHICAL TEMPORAL ANALYSIS&quot;</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">&quot;CODING AND DECODING METHOD OF A PICTURE SEQUENCE BY HIERARCHICAL TEMPORAL ANALYSIS&quot;</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The method realizes a motion compensated temporal filtering (MCTF), the temporal filtering being replaced by an intra mode coding to obtain at least one low (L) or high (H) frequency picture if the current picture has a level of correlation with a lower previous picture at a threshold, the low frequency pictures obtained (L) being thus scaled to be adapted, at the energy level, to the pictures obtained by motion compensated temporal filtering, and is characterized in that, at the end of analysis: it selects the pictures obtained by intra coding of a picture of a low decomposition level with the additional condition, for the high frequency pictures, that this picture is derived itself from an intra coding. it calibrates the picture selected by carrying out at least one reverse step of the scaling step. The applications relate to video compression with temporal prediction.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>CODING AND DECODING METHOD OF A PICTURE SEQUENCE BY HIERARCHICAL<br>
TEMPORAL ANALYSIS<br>
The invention relates to a method of video coding and decoding<br>
of a picture sequence coded by hierarchical temporal analysis exploiting the<br>
motion compensated temporal filtering.<br>
The scope is that of video compression based on spatial and/or<br>
temporal scalability diagrams also known as "scalables". This involves for<br>
example a 2D+t wavelet coding comprising a motion compensated temporal<br>
filtering.<br>
In the hybrid coding standards, such as MPEG-1, MPEG-2,<br>
MPEG-4, h264, as in most of the 2D+t subband coding diagrams, such as<br>
MC-EZBC, acronym for Motion Compensated Embedded Zero Block<br>
Context, the first step of the coding system consists of taking advantage of<br>
the temporal redundancy between successive images, before exploiting the<br>
spatial redundancy within an image.<br>
Figure 1 shows a diagram of a video coder according to the<br>
prior art.<br>
The video signal is transmitted to a temporal analysis circuit 1.<br>
A motion estimation circuit 2 is connected to this first circuit to estimate the<br>
motion between two images received by the coder. The motion information is<br>
transmitted to the circuit 1 and to a coding circuit 6, for example in the form of<br>
motion vector fields. The output of circuit 1 is sent to a spatial analysis circuit<br>
3 that extracts, from the texture, the frequency coefficients of the picture.<br>
These coefficients are then quantized and coded by entropic coding, circuit 4.<br>
The coded information and motion information is sent to a packeting circuit or<br>
packetizer 5 that sends the video data in the form of video packets to<br>
constitute the video data flow.<br>
The temporal analysis circuit 1 performs motion compensated<br>
temporal prediction in the case of a hybrid diagram or a motion compensated<br>
temporal filtering in the case of a subband coding diagram. The coding<br>
algorithms with temporal prediction consist in operating motion compensation<br>
to generate prediction pictures that will subsequently used in the coding<br>
process. These algorithms are based on the same principle. The pictures to<br>
code are predicted from one or more previously coded pictures, called<br>
reference pictures. This is the case in the video MPEG standards with the<br>
Predicted (P) and Bi-directional or Bi-predictive (B) pictures. Prediction<br>
consists in carrying out a motion compensation operation from these<br>
reference pictures and motion vectors associated with the current picture.<br>
What is then coded is the residue of the prediction, that is, the difference<br>
between the current picture and the temporal prediction picture. The motion<br>
is for example described by pixe blocks and the motion compensation<br>
carried out per block.<br>
The spatial analysis circuit 3 realizes a wavelet decomposition<br>
or a discrete cosine transform. The entropic coding of circuit 4 can be a VLC<br>
type coding, acronym for Variable Length Coding, or an arithmetic coding.<br>
The function of the packeting circuit is to cut up the texture and<br>
motion information coming respectively from the entropic coding circuit and<br>
the motion field coding circuit into consistent sub-sets according to their<br>
spatial and temporal frequency and to their size, for example their weight in a<br>
bit plane coding approach. Hence, the binary flow obtained is scalable<br>
independently in resolution, field frequency and fidelity.<br>
The estimated motion fields correspond to the resolution of the<br>
source. The motion compensation step of the coder, whether it is by filtering<br>
or prediction is therefore executed on full resolution pictures whereas in the<br>
decoder, the motion compensation step can be executed on pictures of a<br>
(ower resolution, with rescaled motion fields.<br>
The main purpose of motion compensated temporal filtering,<br>
also known by the acronym MCTF, is to generate high frequency pictures H<br>
requiring the minimum of bits for the coding. Another constraint is to reduce<br>
as far as possible the number of non-connected pixels, that is, not connected<br>
by motion vectors. These two aspects are directly dependent on the quality of<br>
the motion field. The filtered information is all the more correlated as the<br>
motion used for the filtering is of good quality.<br>
In some cases, this quality of motion is unsatisfactory, for<br>
example if the motion is too complex, too great or if there is a scene cut. This<br>
consequently results in an excess of energy in the high frequency pictures H<br>
and in the significant number of pixels not connected in the low frequency<br>
pictures L, finally in a high coding cost and a poor distribution of the visual<br>
quality within the decoded group of pictures.<br>
The use of adaptive GOP enables this problem to be taken into<br>
account. The size of the GOP is adapted dynamically according to the<br>
percentage of non-connected pixels. If the total number of pixels nonconnected<br>
in a picture is greater to a predefined threshold, for example in the<br>
order of 60 to 75%, during the motion estimation carried out at a<br>
decomposition level I, the temporal decomposition into subbands is stopped.<br>
The size of the initial GOP is modified to give two GOPs, the size of the first<br>
GOP being forced automatically to 21. This solution however requires the use<br>
of GOPs of variable sizes, and the management of such GOPs is complex.<br>
Another solution consists in exploiting other coding modes such<br>
as intra mode coding, during the temporal decomposition. If there are a large<br>
number of non-connected pixels, an intra coding is carried out. But the<br>
dynamics of the pictures must then be adapted to that of the pictures<br>
obtained by MCTF filtering, leading to an additional coding cost. This to the<br>
detriment of the pictures coded according to the MCTF mode and therefore<br>
of the overall quality of the reconstituted picture sequence.<br>
The invention aims to overcome the disadvantages described<br>
above.<br>
One of the purposes of the invention is a method for coding a<br>
picture sequence comprising a hierarchical temporal analysis of a group of<br>
pictures performing a motion compensated temporal filtering of successive<br>
pairs of pictures to supply low temporal frequency pictures and high temporal<br>
frequency pictures at different temporal decomposition levels, this analysis<br>
realizing, for a given temporal decomposition level and for a pair of low<br>
temporal frequency pictures, a motion estimation step of a current picture B<br>
to a previous reference picture A to supply motion vectors then a motion<br>
compensated temporal filtering of these pictures to supply a low temporal<br>
frequency picture (L) and a high temporal frequency picture (H) at a greater<br>
decomposition level, the said temporal filtering being replaced by an intra<br>
mode coding to obtain at least one low (L) or high (H) frequency picture if the<br>
current picture has a level of correlation with a previous picture lower than a<br>
threshold, the low frequency pictures (L) obtained being thus scaled to be<br>
adapted, at the energy level, to the pictures obtained by the said motion<br>
compensated temporal filtering, characterized in that, among the low<br>
frequency picture and the final high frequency decomposed pictures obtained<br>
at the end of the analysis:<br>
- it selects the pictures obtained by intra coding of a picture at a<br>
lower decomposition level with the additional condition, for the high frequency<br>
pictures, that this picture is derived itself from an intra coding.<br>
- it calibrates the picture selected by carrying out at least one<br>
reverse step of the scaling step.<br>
The number of reverse steps carried out corresponds to the<br>
number of successive intra coding operations of a low frequency picture (L)<br>
to arrive at the picture selected if this involves a high frequency selected<br>
picture, this number being increased by one if it involves the low frequency<br>
selected picture (L).<br>
According to a particular implementation, the method comprises,<br>
for the calculation of a low L or high H frequency image, a temporal filtering<br>
between the current picture and a following picture of the following pair of<br>
pictures, if the correlation between the current picture and the previous<br>
picture is lower than a threshold and if the correlation between the current<br>
picture and this following picture is greater than a threshold, the other H or L<br>
picture being obtained by intra coding and in that this filtering operation is<br>
assimilated with the intra coding and not with the temporal filtering for the<br>
selection step.<br>
According to a particular implementation, the method assigns a<br>
picture number to each picture of the group of pictures, it monitors these<br>
numbered pictures during the decomposition by attributing a counter for each<br>
number, this counter being updated at each step,<br>
- the counter is increased each time a low frequency picture (L) is<br>
obtained in intra mode,<br>
- the counter remains unchanged each time a high frequency<br>
picture (H) is obtained in intra mode or during a temporal filtering with a<br>
following picture,<br>
- the counter is reset each time a picture is obtained by motion<br>
compensated temporal filtering with a previous picture.<br>
The invention also concerns a decoding procedure of a sequence<br>
of pictures coded according to the method described above, characterized in<br>
that it carries out a reverse calibration step of selected pictures to decode,<br>
the selection of the pictures and the number of reverse steps being<br>
dependent on the information associated with the picture to decode. This<br>
information is for example the value of the counter assigned to the picture<br>
during the coding.<br>
The invention also relates to a coder for the implementation of the<br>
method described, comprising a temporal analysis circuit using the motion<br>
compensated temporal filtering and the intra coding, characterized in that the<br>
circuit selects, among the low frequency picture and the final high frequency<br>
decomposed pictures obtained at the end of analysis, the pictures obtained<br>
by an intra coding of a picture at the lower decomposition level or by a<br>
temporal filtering between the current picture and a following picture at the<br>
lower decomposition level, with the additional condition, for the high<br>
frequency pictures, that this picture is derived itself from an intra coding and<br>
in that it carries out at least one scaling step for the pictures selected.<br>
The invention also relates to a decoder for the decoding of picture<br>
sequences coded according to the method of claim 1, comprising a temporal<br>
synthesis circuit, characterized in that the circuit comprises means for<br>
performing a reverse calibration of pictures to decode, the selection of the<br>
pictures and the number of reverse calibrations being dependent on an item<br>
of information associated with the picture to decode and received by the<br>
decoder.<br>
Owing to this reverse scaling operation of intra type pictures,<br>
the pictures coded according to the MCTF mode are not penalized. The<br>
distribution of the quality of the pictures on the entire GOP comprising both<br>
intra pictures coded in intra mode or according to the MCTF mode is<br>
improved. The coding mode information sent to the decoder enable the intra<br>
pictures to be recalibrated to carry out the synthesis of the pictures.<br>
The temporal filtering being carried out in a conditional manner,<br>
according to the quality of the motion, the temporal decomposition into<br>
subbands can be carried out up to the last level. Irrespective of the quality of<br>
the motion, the GOP structure is kept. The size of the GOPs can be kept<br>
constant, facilitating the management of bit-rates and processing, even if a<br>
scene cut occurs in the middle of a GOP. If variable size GOPs are used, the<br>
picture quality is improved.<br>
Other specific features and advantages will emerge more<br>
clearly in the following description, the description provided as a nonrestrictive<br>
example and referring to the annexed drawings wherein:<br>
- figure 1 a coding diagram according to prior art,<br>
- figure 2, a motion compensated temporal filtering on a GOP of<br>
16 pictures,<br>
- figure 3, a coding circuit,<br>
- figure 4, a coding flow chart,<br>
- figure 5, a decoding circuit.<br>
Figure 2 shows in a summary manner the motion compensated<br>
temporal filtering operations performed by the temporal analysis circuit 4,<br>
with a 4-level decomposition for GOPs comprising in this example, 16<br>
pictures shown in thick lines.<br>
The filtering mode used is called "lifting". Instead of using a<br>
complex filtering for the wavelet coding, using a linear filter of a great length,<br>
in our example the filtering will be carried out on a group of 16 pictures, this<br>
filtering method consists, in a known manner, of "factorising" the filter by<br>
using limited length filters, for example two if it is decided to filter the samples<br>
two by two, this filtering being renewed for each decomposition level. One<br>
therefore considers the case in which the filtering in the direction of motion is<br>
carried out on pairs of pictures. The low frequency and high frequency<br>
filtering on each of the pairs of the GOP, produces respectively 8 low<br>
temporal frequency images (t-L) and 8 high temporal frequency images (t-H)<br>
at the first temporal decomposition level.<br>
The low temporal frequency images are then decomposed<br>
again according to the same method. The low pass filtering of these pictures<br>
provides 4 new low temporal frequency pictures t-LL and the high pass<br>
filtering of these same pictures provides 4 high temporal frequency pictures t-<br>
LH. The third decomposition level provides 2 low temporal frequency pictures<br>
t-LLL and 2 high temporal frequency pictures t-LLH. The fourth and last level<br>
provides a low temporal frequency picture t-LLLL and a high temporal<br>
frequency picture t-LLLH.<br>
This temporal decomposition is a 5 band temporal<br>
decomposition that therefore generates 1 t-LLLL picture, 1 t-LLLH picture, 2<br>
t-LLH pictures, 4 t-LH pictures, and 8 t-H pictures per GOP of 16 pictures.<br>
The t-L, t-LL, t-LLL pictures and naturally the original pictures are ignored for<br>
the downstream coding as they are at the origin of the decomposition into<br>
subbands to provide de-correlated pictures at each level. This decomposition<br>
thus enables a new distribution of the energy by generating a useful picture<br>
with a low temporal frequency t-LLLL, which represents an average of the set<br>
of the GOP and in which is concentrated the energy and four levels of<br>
pictures of low energy high temporal frequency pictures, namely 5 frequency<br>
bands. It is these pictures that are sent to the spatial analysis circuit for<br>
spatial decomposition into subbands.<br>
To perform the filtering, a motion field is estimated between<br>
each pair of pictures to be filtered and this for each level. This is the function<br>
of the motion estimator 7.<br>
In a practical manner, only a motion vector field is computed,<br>
from A to B or from B to A. The other motion vector field is deducted from the<br>
first, generating non-connected pixels, that is not assigned a motion vector<br>
and corresponding to holes in the reverse motion vector field.<br>
The filtering operation is carried out on each picture pair of the<br>
original GOP, to obtain a first level of temporal resolution. The process is<br>
repeated several times on the resulting pictures of the low temporal<br>
frequency band, to obtain the following temporal resolution levels. For a GOP<br>
of 16 pictures, the process generates 8 temporal frequency bands called L,<br>
H, LL, LH, LLL, LLH, LLLL, LLLH.<br>
As indicated above, the problem of non-connected pixels<br>
results in a poorer decorrelation during the temporal filtering and therefore a<br>
poorer compression of the data. It can occur at each of the decomposition<br>
levels of the GOP where a motion estimation operation is performed.<br>
According to one embodiment of the invention, a mode<br>
switching circuit is implemented to control the temporal analysis, circuit<br>
controlled by the relevance of the motion estimation. It can manage the case<br>
where a large number of non-connected pixels is obtained during the motion<br>
estimation operation.<br>
Figure 4 shows a device with such a circuit. The same<br>
references are used to designate the circuits similar to those figure 1, which<br>
are not described again.<br>
The motion information coming form the motion estimation<br>
circuit, with the reference 2, are sent to a mode switching circuit, with the<br>
reference 7. This circuit is connected to the temporal analysis circuit 1 to<br>
send it the motion information and the information on the coding mode to<br>
use.<br>
Figure 4 shows a simplified flow chart of the algorithm<br>
implemented for the operation of the switching circuit.<br>
That is A and B two successive pictures of a given temporal<br>
decomposition level, available in the step referenced 7. The motion is for<br>
example estimated from the picture B to the picture A and the picture A is<br>
therefore the reference picture. A step referenced 8 estimates the motion of<br>
this picture B to the picture A. The following step 9 computes the percentage<br>
P1 of non-connected pixels in the reference picture A with respect to the<br>
number of pixels of the picture, that is, the number of pixels to which no<br>
motion vector is assigned. The following step referenced 10 compares this<br>
percentage P1 with a threshold S1 that is a predefined value. This value is<br>
for example a percentage in the order of 20 to 25%.<br>
If the number of pixels not-connected is less than or equal to<br>
this value, the motion vector field is considered as correct and the next step<br>
is step 1 1 , which performs a standard filtering operation.<br>
The low and high frequency pictures are thus computed:<br>
(Formula Removed)<br>
This filtering, equivalent to the filtering described, consists in<br>
first calculating the picture H. This picture is obtained from point to point<br>
difference of the picture B and the motion compensated picture A. Hence, a<br>
certain value is removed from a pixel B, interpolated if necessary, pointed by<br>
the displacement vector in A, motion vector computed during the motion<br>
estimation of the picture B to the picture A.<br>
The picture L is then deducted from the picture H and no longer<br>
the picture B, by addition of the picture A to the reverse motion compensated<br>
picture<br>
(Formula Removed)<br>
 corresponds to a motion "decompensation" of the<br>
picture (H). Hence, one adds, to a pixel of A, a certain value, interpolated if<br>
necessary, located, in the picture H, at the base of a displacement vector<br>
from B to A and pointing to the A pixel.<br>
[f the percentage of pixels not connected is greater than the<br>
threshold S1, the motion vector field is considered as not relevant and step<br>
1 2 follows step 10.<br>
At the temporal level processed, if there is a picture C after the<br>
picture B, test carried out in step 12, this picture C becomes a possible new<br>
reference picture and the motion is estimated from the picture B to the picture<br>
C, step 13.<br>
If there is no picture after the picture B at the current ievel<br>
processed, step 17 follows step 12. This step codes the pictures B and A into<br>
intra mode with the appropriate scale factor for the picture A.<br>
(Formula Removed)<br>
Step 14, which follows step 13, computes a percentage P2 of<br>
pixels non-connected in the picture C for the motion vector field computed<br>
between B and C.<br>
The following step 15 compares this percentage P2 with a<br>
threshold S2 that is a predefined value. This value is for example a<br>
percentage in the order of 20 to 25%.<br>
If the number of pixels not-connected is less than or equal to<br>
this value, the motion vector field is considered as correct and the next step<br>
is step 16, which performs a standard filtering operation but with this picture<br>
C. This is the backward prediction mode. The low and high frequency<br>
pictures are thus computed:<br>
(Formula Removed)<br>
The information of the picture A is thus found in the picture L<br>
and the energy of the picture H is reduced by taking this reference in the<br>
future for the filtering rather than by simply choosing the picture B or filtering<br>
it from a previous non-correlated picture. A high frequency image of low<br>
energy is thus obtained.<br>
If the percentage of non-connected pixels is lower than the<br>
threshold S2, step 17 follows step 12. This step 17 codes the pictures B and<br>
A in intra mode with the appropriate scale factor for the picture A, as in the<br>
MCTF mode or the previous backward prediction mode.<br>
(Formula Removed)<br>
The reverse is naturally possible, which consists in taking the<br>
picture A as high frequency picture (H=A) and the picture B as the low<br>
frequency picture. One can for example choose, for L, the picture with the<br>
least energy.<br>
Steps 11,16 and 17 are therefore coding modes determined by<br>
the mode switching circuit, information sent to the temporal analysis circuit.<br>
The choice of mode is here carried out for the complete picture.<br>
It is naturally just as conceivable to carry out a selection of the mode for each<br>
of the blocks or macroblocks of the picture.<br>
The term 2 , called the scale factor, relating for example to the<br>
"real" pictures L, that is, obtained by an MCTF filtering, is due to the MC lift<br>
filtering. This scale factor, also attributed to the intra mode coding of the<br>
pictures A, enables the same energy value to be obtained at the level of the<br>
pictures and aims to facilitate the matching during the motion estimation for<br>
the next temporal level, the pictures being then uniform in terms of energy.<br>
The elementary filtering stage described above is realized for<br>
each picture pair of a given temporal level and this for each temporal level up<br>
to the summit of the temporal pyramid of the GOP, irrespective of the<br>
relevance of the motion vector fields, irrespective of the mode. This means it<br>
is possible not to be affected by false scene cuts, corresponding for example<br>
to a rapid movement of the camera, revealing areas hidden up to that point.<br>
At the end of the process, the pictures A and B that have been<br>
coded in intra mode at a given decomposition level and that have not been<br>
used as a reference picture or prediction picture for the MCTF mode or for<br>
the backward prediction mode at the following temporal decomposition<br>
levels, are rescaled to match the last level for which its pixels have been<br>
used for these modes:<br>
(Formula Removed)<br>
Fi is the picture L or H resulting from the filtering of the picture A<br>
and B and F'j this picture Fj rescaled.<br>
The exponent n to apply to the scale factor is given according to<br>
the mode, by the following formulas:<br>
(Formula Removed)<br>
- Prediction mode or intra coding mode:<br>
ln(L) = n(A) + 1<br>
The value of n is thus calculated, for an image L or H at a given<br>
decomposition level, according to the value of n attributed to the picture A or<br>
B of the previous decomposition level, used respectively for the computation<br>
of L or H.<br>
Thus, if the pictures A and B are processed according to the<br>
MCTF mode to give the pictures L and H, then, irrespective of their level n(A)<br>
and n(B), the level n attributed to these pictures L and H is forced to zero.<br>
If the prediction or intra mode is used to provide the pictures L<br>
and H from the pictures A and B, assigned of the level n(A) and n(B), the<br>
level of the picture L is that of n(A) increased by one and the level of the<br>
picture H is that of the picture B, n(B).<br>
By referring to figure 2, if one considers a scene cut after the<br>
fourth picture of the GOP leading to an intra coding carried out for the first<br>
time at the third level of decomposition for the two pictures t-LLL then at the<br>
fourth and last level, the value of n(L) is equal to 2 for the picture t-LLLL and<br>
the value of n(H) is equal to 1 for the picture t-LLLH. Thus, by dividing the<br>
picture t-LLLL twice by the scale factor, one finds the picture t-LL that<br>
corresponds to the last level at which this picture is used for the MCTF mode.<br>
It is possible to assign a number to each of the original pictures<br>
of the GOP. Numbers are next attributed to the decomposed pictures, a<br>
filtering of a picture A numbered s with a picture B numbered t giving a low<br>
frequency picture numbered s, L corresponding to A, and a high frequency<br>
picture numbered t, H corresponding to B. For example, the numbers<br>
obtained for the pictures of the levels t-LLLL, t-LLLH, t-LLH are 1, 9, 5 and<br>
13. For each decomposition level, the computation of n for a numbered<br>
picture i then consists in an increase of the level n assigned to the picture i of<br>
the previous level in the case where this picture undergoes intra or predictive<br>
coding to give a low frequency picture L. The counter remains unchanged if<br>
this picture undergoes an intra or predictive coding to give a high frequency<br>
image H. The counter is reset if this picture undergoes an MCTF coding. The<br>
value n attributed to each original picture of the GOP is reset. The<br>
computation is carried out at each decomposition level up to the last level.<br>
In fact, the value n attributed to a decomposed picture<br>
corresponds:<br>
- for a final picture obtained by MCTF filtering, to the value zero,<br>
- for a final low frequency picture obtained by intra coding, to<br>
the number of intra coding operations realized on the picture of the same<br>
number resulting in this low frequency picture, increased by one,<br>
- for a high frequency picture obtained by intra coding, to the<br>
number of successive intra coding operations realized on the picture of the<br>
same number resulting in this high frequency picture,<br>
- for a high frequency picture obtained from temporal filtering<br>
with a following picture, to the number of successive intra coding operations<br>
realized on the picture of the same number, increased by one, resulting in the<br>
picture that is the object of this temporal filtering.<br>
This last rescaling step aims to calibrate the dynamic of the<br>
transformed pictures, which are not "real" temporal subbands, that is,<br>
subband pictures obtained by MCTF filtering, by reducing the weight of these<br>
images.<br>
The calibrated subband picture is a picture that is not exploited<br>
for the synthesis of the two pictures A and B, reason for which its cost is<br>
reduced.<br>
The bit-rate allocation is realized by the packetizer 5. The<br>
orthogonality of the temporal transform, and also its normalisation, are<br>
essential points so that the bit-rate allocation is optimal among the different<br>
pictures. What is realised in a natural manner during a standardised MCTF<br>
filtering can become a problem when other modes such as the backward<br>
prediction mode or the intra coding mode are implemented. If, in a coding<br>
step, a low frequency image is obtained, in intra or predictive mode, by<br>
multiplying the picture A by a scale factor to reach the dynamic of the<br>
temporal level, that is, to obtain a picture of the same energy as the pictures<br>
obtained by MCTF filtering, this weighting is no longer required at the level of<br>
bit allocation. On the contrary, particular care must be taken to favour the<br>
"real" low frequency pictures obtained by MCTF filtering, the pertinent<br>
reference pictures, for example by giving less weight to pictures coded in<br>
intra or predictive mode. Indeed, the real low frequency pictures, as has been<br>
seen above, are used at the decoder for the reconstruction of the two<br>
pictures A and B at the lower decomposition level, according to the<br>
hierarchical pyramid, B being a function of A, which is not the case for the<br>
pictures coded in intra or predictive mode.<br>
The invention also relates to a decoder using the data coded<br>
according to the method described above. Figure 5 represents such a<br>
decoder.<br>
The binary flow corresponding to the pictures coded according<br>
to the method described herein are sent to the decoder input. They are sent<br>
in parallel to the input of an entropic decoding circuit 18 and to the input of a<br>
motion decoding circuit 19. The entropic decoding circuit is connected<br>
successively to a spatial synthesis circuit 20 and to a temporal synthesis<br>
circuit 21. This latter receives motion information from the motion decoding<br>
circuit. The output of the temporal synthesis circuit is connected to the input<br>
of a post-filtering circuit 22, the output of which is the decoder output.<br>
The bitstream is therefore processed by the entropic decoding<br>
circuit 18, which performs the inverse operations of the entropic coding circuit<br>
and decodes the spatio-temporal wavelet coefficients and the filtering modes.<br>
The motion decoding circuit 19 recovers and decodes the<br>
information relating to the motion from the flow, in order to send the motion<br>
fields required for the temporal synthesis to the circuit 21.<br>
The spatial synthesis circuit 20 reconstructs the pictures<br>
corresponding to the different temporal subbands. The reconstructed<br>
subband pictures are then scaled from the appropriate scale factor, to carry<br>
out the temporal synthesis. This scaling is carried out according to the mode<br>
information sent and relating to the pictures used during the decomposition of<br>
the original GOP, to the coder, enabling the values of n to be assigned to the<br>
different pictures.<br>
Fi=Fi 2n ( F i }<br>
Next, the temporal synthesis circuit 21 reconstructs the pictures<br>
transformed up to the temporal level required, according to their mode:<br>
- MCTF mode<br>
backward prediction mode<br>
(Formula Removed)<br>
intra coding mode<br>
(Formula Removed)<br>
The motion information required for motion compensation<br>
comes from the motion decoding circuit. The temporal synthesis performs a<br>
decoding operation according to the coding mode information assigned to the<br>
picture to decode.<br>
The pictures at the output of the circuit 21 are therefore<br>
reconstructed from temporal wavelet coefficients. A final post-processing<br>
step is applied by the post-filtering circuit 22 by performing a filtering on the<br>
picture enabling the block effect type artefacts to be reduced.<br>
The percentage P1 and/or P2 used to determine the switching<br>
mode is chosen in the order of 20 to 25%. This percentage was obtained<br>
empirically and other values can naturally be used for the implementation of<br>
the switching procedure.<br>
The motion used for temporal filtering of a pair of pictures can<br>
be obtained by simplification or pruning of the motion vector field computed<br>
by motion estimation, enabling the motion coding cost to be limited.<br>
A variant of the invention consists in combining a adaptive GOP<br>
structure with the method previously described. The size of the GOP is then<br>
variable, depending for example on parameters such as the motion in the<br>
sequence.<br>
The invention also applies to a hybrid type temporal analysis<br>
circuit as well as a subband coding type.<br>
The applications of the invention relation to video compression<br>
with temporal prediction.<br><br><br><br><br><br>
CLAIMS<br>
1. Method for coding a picture sequence comprising a<br>
hierarchical temporal analysis (1) of a group of pictures performing a motion<br>
compensated temporal filtering of successive pairs of pictures (11) to supply<br>
low temporal frequency pictures and high temporal frequency pictures at<br>
different temporal decomposition levels, this analysis realizing, for a given<br>
temporal decomposition level and for a pair of low temporal frequency<br>
pictures, a motion estimation step (8) of a current picture B to a previous<br>
reference picture A to supply motion vectors then a motion compensated<br>
temporal filtering (11) of these pictures to supply a low temporal frequency<br>
picture (L) and a high temporal frequency picture (H) at a greater<br>
decomposition level, the said temporal filtering being replaced by an intra<br>
mode (16, 17) coding to obtain at least one low (L) or high (H) frequency<br>
picture if the current picture has a level of correlation with a previous picture<br>
lower than a threshold (10, 15), the low frequency pictures (L) obtained being<br>
thus scaled to be adapted, at the energy level, to the pictures obtained by the<br>
said motion compensated temporal filtering, characterized in that, among the<br>
low frequency picture and the final high frequency decomposed pictures<br>
obtained at the end of the analysis:<br>
- it selects the pictures obtained by intra coding of a picture at a<br>
lower decomposition level with the additional condition, for the high frequency<br>
pictures, that this picture is derived itself from an intra coding.<br>
- it calibrates the selected picture by carrying out at least one<br>
reverse step of the scaling step.<br>
2. Method according to claim 1, characterized in that the number<br>
of reverse steps carried out corresponds to the number of successive intra<br>
coding operations of a low frequency picture (L) to arrive at the picture<br>
selected if this involves a high frequency selected picture, this number being<br>
increased by one if it involves the low frequency selected picture (L).<br>
3. Method according to claim 2, characterized in that it comprises,<br>
for the calculation of a low L or high H frequency image, a temporal filtering<br>
between the current picture and a following picture (16) of the following pair<br>
of pictures, if the correlation between the current picture and the previous<br>
picture is lower than a threshold (10) and if the correlation between the<br>
current picture and this following picture is greater than a threshold (15), the<br>
other H or L picture being obtained by intra coding (16) and in that this<br>
filtering operation is assimilated with the intra coding and not with the<br>
temporal filtering for the selection step.<br>
4. Method according to claim 3, characterized in that it assigns a<br>
picture number to each picture of the group of pictures, and in that it monitors<br>
these numbered pictures during the decomposition by attributing a counter<br>
for each number, this counter being updated at each step:<br>
- the counter is increased each time a low frequency picture (L) is<br>
obtained in intra mode,<br>
- the counter remains unchanged each time a high frequency<br>
picture (H) is obtained in intra mode or during a temporal filtering with a<br>
following picture,<br>
- the counter is reset each time a picture is obtained by motion<br>
compensated temporal filtering with a previous picture,<br>
5. Method according to claim 1, characterized in that the high<br>
frequency pictures H and low frequency pictures L are obtained, during the<br>
motion compensated temporal filtering of two successive pictures A and B,<br>
from the following operations:<br>
MC corresponding to the motion compensation according to the B<br>
to A motion vector field, of the picture H.<br>
6. Method according to claim 5, characterized in that the pictures L<br>
and H are obtained, from intra coding, according to the formulas<br>
(Formula Removed)<br>
and in that the pictures H and L are obtained by filtering with the<br>
following picture and ifl-tbat-for H and by intra coding for L, according to the<br>
following formulas:<br>
(Formula Removed)<br>
MC corresponding to the motion compensation according to the B<br>
to C motion vector field, of the picture C.<br>
7. Method according to claim 1, characterized in that the calibrated<br>
pictures obtained by temporal analysis (1) are then processed by spatial<br>
analysis (3).<br>
8. Method according to claim 1, characterized in that the level of<br>
correlation is calculated by taking into account the number of connected<br>
pixels, that is, connected by a motion vector.<br>
9. Decoding method of a sequence of coded images according to<br>
the process of clairrM, characterized in that it implements a reverse<br>
calibration step (21) of selected pictures to be decoded, the selection of the<br>
pictures and the number of reverse steps being dependent on an element of<br>
information associated with the G0€te4-picture to be decoded.<br>
10. Method for the decoding of a sequence of coded images<br>
according to the process of claim 4, characterized in that it implements a<br>
reverse calibration step (21) of selected pictures to be decoded, the selection<br>
and the number of reverse steps being a function of the value of a counter<br>
assigned to the picture during the coding.<br>
11. Coder for the implementation of the method according to<br>
claims, comprising a temporal analysis circuit (1) using the motion<br>
compensated temporal filtering and the intra coding, characterized in that the<br>
circuit selectse d, among the low frequency picture and the final high<br>
frequency decomposed pictures obtained at the end of analysis, the pictures<br>
obtained by an intra coding of a picture at the lower decomposition level or by<br>
a temporal filtering between the current picture and a following picture at the<br>
lower decomposition level, or by a temporal filtering between the picture of a<br>
pair of pictures and the following picture of the following paiour of pictures at<br>
the lower decomposition level with the additional condition, for the high<br>
frequency pictures, that this picture is derived itself from an intra coding andin<br>
that it carries out at least one reverse step of the scaling step for the<br>
pictures selected.<br>
12. Decoder for the decoding of sequences of images according to<br>
the process of claim_1, comprising a temporal synthesis circuit (21_,<br>
characterized in that the circuit comprises means to perform a reverse<br>
calibration of pictures to be decoded, te-be-synthetized-the selection of<br>
images and the number of reverse calibrations being dependent on an<br>
element of information associated with the picture to be decoded-and<br>
received by the decoder.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LUFic3RyYWN0LSgyNC0wMi0yMDE0KS5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Abstract-(24-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LUNsYWltcy0oMjQtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Claims-(24-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMjQtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Correspondence Others-(24-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMjMtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Correspondence-Others-(23-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LURlc2NyaXB0aW9uIChDb21wbGV0ZSktKDI0LTAyLTIwMTQpLnBkZg==" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Description (Complete)-(24-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LURyYXdpbmdzLSgyNC0wMi0yMDE0KS5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Drawings-(24-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LUZvcm0tMy0oMjMtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Form-3-(23-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LUdQQS0oMjQtMDItMjAxNCkucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-GPA-(24-02-2014).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=NDU0Ny1kZWxucC0yMDA2LVBldGl0aW9uLTEzNy0oMjMtMDgtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">4547-delnp-2006-Petition-137-(23-08-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QuanBn" target="_blank" style="word-wrap:break-word;">abstract.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="260785-apparatus-at-a-draw-frame-having-a-drawing-mechanism-for-doubling-and-drafting-of-fibre-slivers-having-an-adjusting-device.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="260787-compositions-for-treatment-of-hiv-or-aids.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>260786</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>4547/DELNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>21/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>23-May-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>22-May-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>07-Aug-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON LICENSING</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46 QUAI A. LE GALLO, F-92100 BOULOGNE-BILLANCOURT, FRANCE.</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JEROME VIERON</td>
											<td>5 ALLEE JEAN PERRIN, 35137 BEDEE, FRANCE</td>
										</tr>
										<tr>
											<td>2</td>
											<td>GUILLAUME BOISSON</td>
											<td>12 RUE JEAN MALO-RENAULT, 35000 RENNES, FRANCE</td>
										</tr>
										<tr>
											<td>3</td>
											<td>PHILIPPE ROBERT</td>
											<td>7 ALLEE DU BOIS-LOUET, 35235 THORINGNE-FOUILLARD, FRANCE</td>
										</tr>
										<tr>
											<td>4</td>
											<td>GWENAELLE MARQUANT</td>
											<td>LIEU-DIT 1&#x27;HOTEL HAREL, 35630 LA CHAPELLE CHAUSSEE, FRANCE.</td>
										</tr>
										<tr>
											<td>5</td>
											<td>EDOUARD FRANCOIS</td>
											<td>ALLEE DU LOCAR, 35890 BOURG DES COMPTES, FRANCE</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/FR2005/050109</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-02-21</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>0450420</td>
									<td>2004-03-02</td>
								    <td>France</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/260786-coding-and-decoding-method-of-a-picture-sequence-by-hierarchical-temporal-analysis by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:52:43 GMT -->
</html>
