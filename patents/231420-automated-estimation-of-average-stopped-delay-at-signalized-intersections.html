<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/231420-automated-estimation-of-average-stopped-delay-at-signalized-intersections by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:17:54 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 231420:AUTOMATED ESTIMATION OF AVERAGE STOPPED DELAY AT SIGNALIZED INTERSECTIONS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">AUTOMATED ESTIMATION OF AVERAGE STOPPED DELAY AT SIGNALIZED INTERSECTIONS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method for authenticating a textile material that is initiaded by selecting a unique nucleic acid marker having a specific length and a specific sequence. A media that causes the unique nucleic acid marker to adhere to a fibrous material is then selected. The method then proceeds to generate a nucleic acid marker mixture by mixing the media with the nucleic acid marker. The nucleic acid marker mixture is then applied to the fibrous material. A marked fibrous material is produced by marking the fibrous material with the nucleic acid marker. The textile material is then authenticated by detecting the unique nucleic acid marker with primers that are specific to the unique nucleic acid. In an alternative embodiment, a viscous solution for fiber spinning is selected and mixed with the nucleic acid marker to generate a viscous dope that is extruded through an opening in a spinneret to form a marked fiber that is used to generate the textile material.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>AUTOMATED ESTIMATION OF AVERAGE STOPPED DELAY<br>
AT SIGNALIZED INTERSECTIONS<br>
RELATED APPLICATIONS<br>
[01] This application claims the benefit of U.S. Provisional Patent Application<br>
Serial No. 60/505,666, filed September 24, 2003 and entitled AUTOMATED<br>
ESTIMATION OF AVERAGE STOPPED DELAY AT SIGNALIZED<br>
INTERSECTIONS USING DIGITIZED STILL IMAGE ANALYSIS OF ACTUAL<br>
TRAFFIC FLOW, which is incorporated herein by reference.<br>
TECHNICAL FIELD<br>
[02] The present invention relates generally to the monitoring of vehicular traffic.<br>
More specifically, the present invention relates to systems and methods for providing<br>
automated estimation of average stopped delay at signalized intersections.<br>
BACKGROUND<br>
[03] With ever increasing road traffic levels there is a particular need to evaluate<br>
the performance of traffic control systems. One particular traffic control system that<br>
is almost universally encountered is signalized intersections. Evaluation of signalized<br>
intersection performance may take various forms. One form of particular importance<br>
includes the analysis of average stopped delay per vehicle. The Institute of<br>
Transportation Engineers ("ITE") defines stopped delay as the time a vehicle is<br>
standing still while waiting in line in the approach to an intersection. The average<br>
stopped delay per vehicle for a given intersection approach is the sum of the<br>
individual stopped delay divided by the volume of traffic that passes through the<br>
intersection approach including vehicles that do not stop.<br>
[04] A basic method for estimating average stopped delay per vehicle suggested by<br>
the ITE includes the use of a human observer for counting vehicles. Typically, for<br>
fifteen minutes the observer counts the number of vehicles stopped at an intersection<br>
approach at fifteen second intervals. The total number of vehicles that passed through<br>
the intersection is also recorded. Once the data are collected, the total number of<br>
vehicles that were counted as stopped is multiplied by the fifteen second time<br>
increment and then divided by the total number of vehicles that passed through the<br><br>
intersection from that approach. This method may be referred to as the ITE manual<br>
method.<br>
[05] Although the ITE manual method is common in the field of traffic<br>
engineering, it does have several possible error sources. For example, the ITE manual<br>
method assumes that vehicles counted as stopped at each fifteen-second interval have<br>
been stopped at the intersection for the entire fifteen seconds. Error can also arise<br>
from the use of human observers. Long traffic queues can make it difficult for<br>
observers to accurately count the stopped vehicles. The difficulties associated with<br>
manual analysis do not disappear even if an electronic counter is used to simplify the<br>
steps of the ITE manual method.<br>
[06] Consequently, it would be desirable to reduce the large labor cost and reduce<br>
the inaccuracies inherent in the ITE manual method. It would further be desirable to<br>
provide automated, instead of manual estimation of the average stopped delay per<br>
vehicle at a given signalized intersection.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
[07] The present embodiments will become more fully apparent from the following<br>
description and appended claims, taken in conjunction with the accompanying<br>
drawings. Understanding that these drawings depict only typical embodiments and<br>
are, therefore, not to be considered limiting of the invention's scope, the embodiments<br>
will be described with additional specificity and detail through use of the<br>
accompanying drawings in which:<br>
[08] Figure 1 is a block diagram illustrating a system for estimating the average<br>
stopped delay per vehicle at a signalized intersection;<br>
[09] Figure 2 is a digital image of a perspective view of a signalized intersection<br>
without vehicles, taken from the perspective of a traffic camera;<br>
[10] Figure 3 is another digital image of a perspective view of the signalized<br>
intersection of Figure 2 with vehicles, taken from the perspective of the traffic camera;<br>
[11] Figure 4 is a flow diagram of one embodiment of a method for estimating the<br>
average stopped delay per vehicle at a signalized intersection;<br>
[12] Figure 5 is a flow diagram of one embodiment of a method for initializing<br>
background intensities of a line of pixels in a digital image of an actual traffic lane;<br><br>
[13] Figure 6 is a flow diagram of one embodiment of a method for calculating the<br>
stopped delay for each digital image;<br>
[14] Figure 7 is a flow diagram of an alternative embodiment of a method for<br>
calculating the stopped delay for each digital image;<br>
[15] Figure 8 is a flow diagram of another alternative embodiment of a method for<br>
calculating the stopped delay for each vehicle;<br>
[16] Figure 9 is a flow diagram of one embodiment of a method for calculating the<br>
average stopped delay per vehicle; and<br>
[17] Figure 10 is a block diagram illustrating the major hardware components<br>
typically utilized in a computing device used in conjunction with a system for<br>
estimating the average stopped delay per vehicle.<br>
DETAILED DESCRIPTION<br>
[18] A method for estimating the average stopped delay per vehicle at signalized<br>
intersections is disclosed. In the method, a background is created by initializing the<br>
background intensities of a line of pixels in a digital image of an actual traffic lane<br>
absent vehicles. The process of initializing the background intensities of the line of<br>
pixels includes digitizing an image of an actual traffic lane without vehicles. A line of<br>
pixels that extends upstream into the traffic lane is then established. Each pixel in the<br>
line of pixels is assigned a length value. The intensities of each pixel are then read<br>
and stored.<br>
[19] Once the background is initialized, the identity and location of vehicles are<br>
identified by measuring the intensities of the line of pixels in a different digital image<br>
of the same traffic lane having vehicles. The difference between pixel intensities on<br>
the background and the image with vehicles is then calculated. A vehicle is located<br>
along the line of pixels by identifying a group of consecutive pixels where the<br>
difference between pixel intensities is outside of a specified threshold.<br>
[20] The stopped delay for each vehicle or for each digital image is then calculated.<br>
This may be accomplished by different methods. One method for calculating the<br>
stopped delay for each digital image includes calculating the distance between<br>
vehicles identified on the digital image. If the distance between vehicles is below a<br>
specified gap distance, it is determined that the vehicle is stopped. The total number<br><br>
of vehicles stopped on the digital image is then added together and multiplied by the<br>
time interval between each digital image.<br>
(21) If the length of one of the vehicles is greater than a specified maximum length,<br>
the long vehicle is divided into multiple vehicles which are considered stopped. The<br>
long vehicle is divided up based upon a specified average vehicle length.<br>
Alternatively, if it is determined that the vehicle is greater than the specified<br>
maximum length, the number and lengths of vehicles in substantially the same<br>
location in the previous frame are determined. The long vehicle is then divided into<br>
multiple stopped vehicles based on the number and length of vehicles in the previous<br>
frame.<br>
[22] Another method for calculating the stopped delay for each vehicle includes<br>
monitoring the location of the front and the rear of a vehicle between consecutive<br>
frames. The speed and future position of the vehicle are then calculated. The vehicle<br>
is considered stopped if it is determined that its speed is below a specified stopping<br>
speed. The total stopped delay for the vehicle over consecutive frames is then<br>
calculated.<br>
[23] If it is determined that a vehicle overlaps another vehicle, the division between<br>
vehicles is maintained through a ratio of the vehicle lengths before the vehicles were<br>
viewed as overlapping. Furthermore, when a vehicle leaves an intersection, if the<br>
vehicle becomes longer than an allowed vehicle length growth percentage, the rear of<br>
the vehicle is separated from the front of the following vehicle so that the vehicle does<br>
not become longer than the allowed vehicle length growth percentage.<br>
[24] The average stopped delay per vehicle is then calculated by calculating the<br>
total stopped delay of all digital images or the total stopped delay of all vehicles. This<br>
value is then divided by the total number of vehicles that entered the intersection<br>
during the analysis period.<br>
[25] A computing device configured for estimating the average stopped delay per<br>
vehicle at a signalized intersection is also provided. The computing device includes a<br>
processor and memory in electronic communication with the processor. The<br>
computing device also includes executable instructions that can be executed by the<br>
processor. The executable instructions are configured to initialize the background<br>
intensities of a line of pixels along a traffic lane without vehicles in a digital image of<br><br>
an actual intersection. The executable instructions are also configured to identify a<br>
vehicle by measuring the intensities of the line of pixels in a different digital image of<br>
the same intersection with vehicles. The stopped delay for each vehicle or digital<br>
image with vehicles is calculated. The average stopped delay per vehicle is then<br>
calculated.<br>
[26] A computer-readable medium for storing program data is provided as well.<br>
The program data includes executable instructions for implementing a method for<br>
estimating an average stopped delay per vehicle at a signalized intersection. In the<br>
method, the background intensities of a line of pixels in a digital image of an actual<br>
traffic lane without vehicles are initialized. Vehicle location is identified by<br>
measuring intensities of the line of pixels in a different digital image of the same<br>
intersection with vehicles. The stopped delay for each vehicle or each digital image<br>
with vehicles is calculated. The average stopped delay per vehicle is then calculated.<br>
[27] It will be readily understood that the components of the embodiments as<br>
generally described and illustrated in the Figures herein could be arranged and<br>
designed in a wide variety of different configurations. Thus, the following more<br>
detailed description of the embodiments of the systems and methods of the present<br>
invention, as represented in the Figures, is not intended to limit the scope of the<br>
invention, as claimed, but is merely representative of the embodiments of the<br>
invention.<br>
[28] The word "exemplary" is used exclusively herein to mean "serving as an<br>
example, instance, or illustration." Any embodiment described herein as "exemplary"<br>
is not necessarily to be construed as preferred or advantageous over other<br>
embodiments. While the various aspects of the embodiments are presented in<br>
drawings, the drawings are not necessarily drawn to scale unless specifically<br>
indicated.<br>
[29] Several aspects of the embodiments described herein will be illustrated as<br>
software modules or components stored in a computing device. As used herein, a<br>
software module or component may include any type of computer instruction or<br>
computer executable code located within a memory device and/or transmitted as<br>
electronic signals over a system bus or network. A software module may, for<br>
instance, comprise one or more physical or logical blocks of computer instructions,<br><br>
which may be organized as a routine, program, object, component, data structure, etc.,<br>
that performs one or more tasks or implements particular abstract data types.<br>
[30] In certain embodiments, a particular software module may comprise disparate<br>
instructions stored in different locations of a memory device, which together<br>
implement the described functionality of the module. Indeed, a module may comprise<br>
a single instruction, or many instructions, and may be distributed over several<br>
different code segments, among different programs, and across several memory<br>
devices. Some embodiments may be practiced in a distributed computing<br>
environment where tasks are performed by a remote processing device linked through<br>
a communications network. In a distributed computing environment, software<br>
modules may be located in local and/or remote memory storage devices.<br>
[31] Note that the exemplary embodiment is provided as an exemplar throughout<br>
this discussion; however, alternate embodiments may incorporate various aspects<br>
without departing from the scope of the present invention.<br>
[32] The order of the steps or actions of the methods described in connection with<br>
the embodiments disclosed herein may be changed by those skilled in the art without<br>
departing from the scope of the present invention. Thus, any order in the Figures or<br>
detailed description is for illustrative purposes only and is not meant to imply a<br>
required order.<br>
[33] Figure 1 is a block diagram illustrating a system 100 for estimating the average<br>
stopped delay per vehicle at a signalized intersection. This system 100 uses digitized<br>
still images or frames 102 of actual traffic flow to estimate the average stopped delay<br>
per vehicle. The digitized frames 102 may come from traffic cameras that are<br>
ubiquitously available in many large to medium-sized cities. The cameras may be<br>
digital and directly produce digital images 102, or the cameras may provide analog<br>
video that is subsequently converted into a plurality of digitized images 102.<br>
[34] Time data 104 is also inputted into the system 100 for estimating the average<br>
stopped delay per vehicle. The time data 104 may be the time interval between each<br>
frame 102, or alternatively could be a time stamp associated with each frame 102.<br>
Either type of time data allows for the determination of the time period that elapses<br>
between consecutive frames.<br><br>
[35] Another form of input into the system 100 for estimating the average stopped<br>
delay per vehicle is street length data 106. Such data may include actual lengths per<br>
pixel of the digitized frame at the upstream and downstream ends of an image analysis<br>
line of pixels that will be discussed with greater detail in conjunction with Figure 2.<br>
The street length data 106 may also include an actual length at an intermediate<br>
estimation point expressed as a percent of the image analysis line of pixels from the<br>
downstream end of the line. Street length data 106 is used to determine the length and<br>
position of any given vehicle in a particular digitized frame 102.<br>
[36] User input 108 is also entered by a user to specify how certain parameters of<br>
the average stopped delay estimator 110 operate. User input may include, among<br>
other things, downstream and upstream pixel location for defining a line of pixels<br>
along a traffic lane, thresholds for intensity readings, minimum gap limit thresholds,<br>
maximum vehicle length limits, minimum vehicle length limits, average vehicle<br>
lengths, signaling information, and allowed vehicle length growth percentage, all of<br>
which will be discussed in more detail below. Other forms of user input not<br>
specifically enumerated above may also be entered, some of which will also be<br>
discussed in more detail below.<br>
[37] User input 108, street length data 106, digitized image data 102 and time data<br>
104 are all inputs to the average stopped delay estimator 110 which represents a<br>
process that runs on a computing device for providing an average stopped delay per<br>
vehicle estimate 112. As opposed to the ITE manual method for estimating the<br>
average stopped delay per vehicle at a signalized intersection, the present system 100<br>
provides an automated approach using digitized still image analysis of actual traffic<br>
flow.<br>
[38] Figure 2 is a digital image 202 of a perspective view of a signalized intersection<br>
214 taken from the perspective of a traffic camera (not shown). The image 202 does not<br>
have any vehicles at the intersection, thus the signalized intersection 214 is considered<br>
empty. The image 202 may be obtained from a digital camera that is mounted<br>
proximate the intersection 214, or may alternatively be derived from analog camera data<br>
that is subsequently digitized. Typically, the images 202 are obtained from closed-<br>
circuit television ("CCTV") cameras. CCTV cameras are ubiquitously available in many<br>
large to medium-sized cities.<br><br>
[39] The digital image 202 also depicts one or more traffic lanes 216 that lead toward<br>
and away from the signalized intersection 214. The intersection 214 is signalized<br>
through the use of a traffic signal 218 which controls the flow of traffic through the<br>
intersection 214. For reference, the traffic lane 216 has a proximal end 220 which is •<br>
closest to a limit line 222 that marks the entrance into the intersection 214. The traffic<br>
lane 216 also has a distal end 224 which is further up the flow of traffic. Vehicles<br>
traveling on the traffic lane 216 approach the intersection 214 from the distal end 224<br>
toward the proximal end 220, and come to a stop before the limit line 222 if the traffic<br>
signal 218 indicates such.<br>
[40] The digital image 202 obtained from the camera may be from alternative<br>
perspectives, such as viewed from directly overhead the traffic lane 216 instead of off to<br>
one side as depicted in Figure 2. Additionally, there may be various directions of<br>
camera view that could be used to obtain images of the signalized intersection 214.<br>
[41] Also illustrated in Figure 2, is a line of pixels 226 that extends along the traffic<br>
lane 216. Pixels are the basic unit of composition of the digital image 202. The line of<br>
pixels 226 is used as a digital sensor to identify vehicles traveling within the traffic lane<br>
216. The line of pixels 226 is created by designating a first pixel point adjacent the<br>
proximal end 220 of the traffic lane 216 and a second pixel point that is adjacent the<br>
distal end 224 of the traffic lane 216. The use of the line of pixels 226 will be discussed<br>
in greater detail below.<br>
[42] Figure 3 is a representation of another digital image 302 of a perspective view of<br>
a signalized intersection 314 taken from the perspective of the traffic camera used to<br>
produce the image shown in Figure 2. This image 302 shows several vehicles 328<br>
within the traffic lane 316. Some of the vehicles 328 are at a proximal end 320 of the<br>
lane 316 and stopped before the limit line 322 previous to entering the intersection 314.<br>
The vehicles 328 approach the intersection 314 from a distal end 324 of the traffic lane<br>
316.<br>
[43] The line of pixels 326 intersects the vehicles 328 within the traffic lane 316,<br>
such that the line of pixels 326 extends through the length of the vehicles 328. Because<br>
of the angle of the camera that was used to obtain the image 302, the lengths of the<br>
vehicles 328 along the line of pixels 326 appear shorter at the distal end 324 of the<br>
traffic lane 316, and get longer as the vehicles 328 approach the proximal end 320.<br><br>
Consequently, vehicles 328 stopped at the limit line 322 intersect a larger number of<br>
pixels of the pixel line 326 than vehicles 328 further up the queue. Each pixel in the line<br>
of pixels 326 therefore, represents a different length in real space. A pixel in the line of<br>
pixels 326 near the proximal end 320 of the traffic lane 316 represents a shorter length<br>
than does a pixel near the distal end 324 of the traffic lane 316. The significance of this<br>
reality and how it is accounted for in the systems and methods of the present invention<br>
will be discussed in more detail in conjunction with Figure 5.<br>
[44] Figure 4 is a flow diagram of one embodiment of a method for estimating 430<br>
the average stopped delay per vehicle at a signalized intersection. According to this<br>
method, the estimation 430 of average stopped delay per vehicle at a signalized<br>
intersection is automated, using digitized still image analysis of actual traffic flow. This<br>
method is used to address the potential problems associated with applying automated<br>
processes to image data of real traffic flow, which, among other things, includes camera<br>
position, direction of camera view, parallax, vehicle color, pavement color and crowding<br>
of vehicles caused by parallax.<br>
[45] Since real image frames of traffic flow at a signalized intersection are used to<br>
estimate 430 the average stopped delay per vehicle, frames with vehicles are compared<br>
to a frame without vehicles. Accordingly, the method includes the step of initializing<br>
432 the background intensities of the line of pixels that extends through the pertinent<br>
traffic lane without vehicles (see Figure 2). This step includes selecting a frame of the<br>
traffic lane that is clear of vehicles.<br>
[46] The line of pixels selected extends along the traffic lane from the intersection to<br>
a point upstream in the lane, as illustrated and described in conjunction with Figure 2.<br>
The graphical intensities of each pixel in the line of pixels is read and stored in memory.<br>
According to one embodiment, the graphical images used are monochrome, with pixel<br>
intensities ranging from a numeral scale of black (0) to white (255). Those with skill in<br>
the art will realize that alternative methods for measuring pixels intensities may be used,<br>
including those that involve the analysis of color instead of monochrome pixel<br>
intensities. Initializing 432 the background intensities of the line of pixels extending<br>
through the traffic lane without vehicles will be discussed with more detail in<br>
conjunction with Figure 5.<br><br>
[47] Another step in the method for estimating 430 the average stopped delay per<br>
vehicle is to measure 434 the pixel intensities of the line of pixels on a frame that has<br>
vehicles (see for example, Figure 3). Since vehicles intersect the pixel line, the<br>
graphical intensity of the pixel line will vary from the background pixel line intensity<br>
where a vehicle is located. The values for the pixel intensities are also stored in<br>
memory. Typically, the step of initializing 432 the background intensities of the pixel<br>
line is done previous to measuring 434 the intensities of the pixel line in a frame with<br>
vehicles. However, as is true with the remaining steps of the present method, as well<br>
as other methods disclosed herein, it is possible that this particular order of steps<br>
could be reversed or done simultaneously or performed in a different order.<br>
[48] Once the background pixel intensities are initialized 432 and the pixel<br>
intensities of a frame or frames with vehicles are measured 434, the difference<br>
between the pixel intensity values of the background and the frame with vehicles is<br>
calculated 436. Since the color of a vehicle varies from vehicle to vehicle, the result<br>
of the calculation 436 may yield signal intensities that are positive, such as when a<br>
white or bright vehicle is present, or signal intensities that are negative, such as when<br>
a black or dark vehicle is present.<br>
[49] Once the difference between pixel intensity values between the background<br>
and the frame with vehicles is calculated 436, the location of each vehicle is identified<br>
438. A vehicle is identified 438 from the difference calculation 436 performed in the<br>
previous step. Any pixel in the line of pixels with an intensity difference outside a<br>
specified threshold is considered to be part of a vehicle. The appropriate threshold<br>
value may be determined through the consideration of several factors, but essentially<br>
constitutes an appropriate signal to noise ratio value given the circumstances. A<br>
group of consecutive pixels that have difference intensity values outside the threshold,<br>
without a significant gap, may be considered a vehicle. The gap may be defined by<br>
any group of consecutive pixels that do not have intensity differences outside of the<br>
threshold, whose combined length is over a specified gap limit. Accordingly, the<br>
location of each vehicle is identified 438 by a span of pixels in the line of pixels that<br>
differ from the background pixel intensities.<br>
[50] Once the vehicle location is identified 438 in a particular frame or frames, the<br>
stopped delay for a particular vehicle or frame is calculated 440. This may be done<br><br>
according to several different methods utilizing different algorithms as will be<br>
discussed in greater detail in conjunction with the discussion of Figures 6-8. At least<br>
one of these methods is used to calculate 440 the total stopped delay for all vehicles in<br>
a particular frame. Another method is used to calculate 440 the stopped delay for a<br>
particular vehicle over the span of several frames. Either method will provide data<br>
sufficient to estimate 430 the average stopped delay per vehicle.<br>
[51] Once the stopped delay for each frame or vehicle is calculated 440, it is<br>
determined 442 whether additional frames are to be analyzed. The frames are<br>
obtained from analog or digital CCTV cameras that are positioned at many<br>
intersections in most metropolitan areas. If a digital camera is used, the frames may<br>
be analyzed using the present method as they are acquired, i.e., in real-time.<br>
Alternatively, digital frames may be analyzed at a later time if desired. If an analog<br>
CCTV camera is used, then certain frames are obtained at specified time intervals and<br>
are digitized accordingly. It may be determined 442 that more frames are to be<br>
analyzed if there is additional video that needs to be analyzed. However, it may be<br>
determined 442 that more frames do not need to be analyzed if all frames or video<br>
have already been analyzed according to the method described.<br>
[52] If it is determined 442 that more frames are to be analyzed, then a new<br>
background is calculated and stored 444. This may be accomplished by averaging the<br>
intensities of the pixels that are not inside a vehicle into the background pixel<br>
intensities. A pixel is considered not inside a vehicle when the pixel intensity is not<br>
outside the threshold and is part of the gap as defined above. This new background is<br>
used in the calculations with the next frame. The method for estimating 430 the<br>
average stopped delay per vehicle is essentially repeated where the pixel intensities for<br>
the next frame are measured 434 and analyzed in conjunction with the new<br>
background as described.<br>
[53] If it is determined 442 that more frames do not need to be analyzed, then the<br>
data resulting from calculating 440 the stopped delay for each frame or vehicle is used<br>
to calculate 446 the average stopped delay per vehicle. The process for calculating<br>
446 the average stopped delay per vehicle is described in greater detail in conjunction<br>
with the discussion of Figure 9. Accordingly, the process for estimating 430 the<br>
average stopped delay per vehicle provides an automated method using digitized still<br><br>
image analysis of actual traffic flow. The method for estimating 430 average stopped<br>
delay per vehicle is accomplished without the labor intensive methods associated with<br>
the ITE manual method and helps traffic engineers to reduce the inaccuracies inherent<br>
in human-collected data.<br>
[54] Figure 5 is a flow diagram of one embodiment of a method for initializing 532<br>
background intensities of a line of pixels in a digital image of an actual traffic lane. In<br>
order to create a background from which to measure an intersection having traffic, a<br>
still image or frame of the signalized intersection without vehicles is digitized 548.<br>
This digitization 548 may be accomplished by converting an analog video stream into<br>
a plurality of digital frames. One of the digital frames that does not have vehicles in<br>
the relevant lane is used as the background. Alternatively, the digitized frame may be<br>
created by a digital CCTV camera or the like.<br>
[55] Once the frame of the empty intersection is digitized 548, a traffic engineer or<br>
other user establishes 550 a line of pixels that extends through the traffic lane. This<br>
may be accomplished through the use of a user interface component of a software<br>
module that performs the method described in conjunction with Figure 4. Through<br>
the user interface component, a user selects two pixels as end points of the line of<br>
pixels. One pixel is selected at the proximal end 220 of the traffic lane 216 as shown<br>
in Figure 2. This pixel may be located adjacent the limit line 222 that marks the<br>
entrance to the signalized intersection 214. The second pixel is selected upstream at<br>
the distal end 224 of the traffic lane 216. The resulting line of pixels having a width<br>
of one-pixel extends along the path that vehicles will travel down the traffic lane 216.<br>
[56] Referring still to Figure 5, a length value is assigned 552 to each pixel once the<br>
line of pixels is established 550. Because of the angle of the camera, the lengths of<br>
the vehicles that approach the intersection along the line of pixels appear shorter near<br>
the distal end of the traffic lane and get longer as the vehicle approaches the<br>
intersection. The same is true of the length of pavement of the traffic lane that is<br>
covered by each pixel. A single pixel covers a shorter distance at the proximal end<br>
adjacent the intersection than a pixel at the distal end upstream from the intersection.<br>
According to one embodiment, in order to maintain uniform vehicle length along the<br>
entire line of pixels, a length value is assigned 552 to each pixel by linearly<br>
interpolating between three real world lengths describing the first pixel at the<br><br>
proximal end, the last pixel at the distal end, and an intermediate pixel between the<br>
first and last pixel which formed the line. Alternative methods for assigning 552 a<br>
length value to each pixel may also be used in place of linear interpolation of three<br>
pixels, as would be apparent to one having skill in the art.<br>
[57] Once the frame having a traffic lane clear of vehicles is digitized 548 and the<br>
line of pixels is established 550, the intensities of each pixel in the line of pixels is<br>
read and stored 554. According to one embodiment, the digitized images are<br>
monochrome images having pixel intensities that range from black (0) to white (255).<br>
Each pixel in the line of pixels over the relevant empty traffic lane has some intensity<br>
value that represents the relative intensity of the section of pavement upon which the<br>
pixel is overlaid. Those with skill in the art will recognize that alternative methods<br>
for measuring 554 pixel intensities may be employed, including those that involve the<br>
analysis of color instead of just monochrome pixel intensities.<br>
[58] Figure 6 is a flow diagram of a first embodiment of a method for calculating<br>
640 the total stopped delay of all vehicles in a given digital image. The image<br>
analyzed is one that has traffic in the traffic lane as represented by example in Figure<br>
3. According to this first embodiment, the distance between vehicles along the line of<br>
pixels is calculated 656 for every real image frame. As discussed above, vehicles are<br>
identified on the line of pixels by calculating the difference in pixel intensity values<br>
between the background and the frame with vehicles. A group of consecutive pixels<br>
that have difference intensity values outside of a given threshold, without a significant<br>
gap, are considered a vehicle. The distance between vehicles is calculated 656 by<br>
determining the length of the traffic lane between vehicles that is exposed to the<br>
camera, thus providing a length of pixels in the line of pixels that have intensities<br>
comparable to those of the background.<br>
[59] Once the vehicles have been identified and the distance between them have<br>
been calculated 656, it is determined 658 whether this distance between vehicles is<br>
below a specified gap distance. According to one embodiment, the specified gap<br>
distance is user defined, and entered into the user interface component of a software<br>
module that performs the method described herein. When the gap in front of a given<br>
vehicle is below the specified gap distance, the vehicle is considered stopped.<br><br>
[60] In analyzing images from real world traffic flow, as vehicles slow down and<br>
approach a queue of vehicles at an intersection, the gaps between vehicles are not<br>
noticeable because of the camera angle. Even though in actuality two vehicles are not<br>
in contact with each other, when one comes to a stop close behind the other, the<br>
camera may not be able to view the pavement between them depending on the<br>
position and angle of the camera. Consequently, using the method for identifying<br>
vehicles as described above, the computing device and/or software algorithms will<br>
view these vehicles as one long vehicle.<br>
[61] Accordingly, the first embodiment for calculating 640 the stopped delay for<br>
each image queries 660 whether a particular vehicle is greater than a specified<br>
maximum length. In either event that the distance between vehicles is greater than or<br>
less than the specified gap distance, the method determines 660 if the vehicle is longer<br>
than the specified length. Again, according to one embodiment, the specified<br>
maximum vehicle length is user defined.<br>
[62] If the distance between vehicles is greater than the specified gap distance, and<br>
the rear vehicle is not longer than the specified vehicle length, the vehicle is<br>
considered to be moving 662 and not stopped. However, if the distance between<br>
vehicles is less than the specified gap distance, and the rear vehicle is not longer than<br>
the specified vehicle length, the vehicle is considered a single, stopped vehicle.<br>
[63] If it is determined 660 that the vehicle is longer than the specified maximum<br>
vehicle length, then the vehicle is considered to be at least two stopped vehicles. The<br>
number of vehicles that comprise the mistakenly long vehicle is determined by<br>
dividing 664 the long vehicle into a specified average vehicle length. The specified<br>
average vehicle length may be user defined, and entered into the user interface<br>
component of a software module that performs the method described herein. Any<br>
remaining length that is shorter than the average vehicle length, but longer than a<br>
specified minimum vehicle length is also counted as another vehicle. Consequently,<br>
what the software sees as an overly lengthy vehicle is divided up by average vehicle<br>
lengths and each division is counted as a stopped vehicle for purposes of calculating<br>
640 the stopped delay for each frame.<br>
[64] According to one embodiment, a user may create user input in the form of<br>
signaling information. The red light and green light cycles may be entered as a control<br><br>
parameter into the software that is used to run the methods described. If one frame<br>
shows a single vehicle at the intersection, the vehicle may be counted as stopped if<br>
there is a red light and the vehicle's proximity to the limit line is within the specified<br>
gap distance. Conversely, the single vehicle may be considered to be moving 662 if<br>
the signal is green. The entering of signaling information may also remedy problems<br>
associated with pedestrians or large vehicles that travel in cross directions in front of<br>
the vehicle stopped at the limit line.<br>
[65] For each frame the number of vehicles stopped is added 666 together to<br>
determine the total number of vehicles stopped within the frame. Although moving<br>
vehicles are counted for purposes of monitoring the total number of vehicles that pass<br>
through the intersection, only the stopped vehicles are added 666 together. The total<br>
number of stopped vehicles is then multiplied 668 by the specified time interval<br>
between frames. The resulting value represents the total stopped delay for the<br>
particular frame, and is used in conjunction with the method described in Figure 4 to<br>
determine the average stopped delay per vehicle.<br>
[66] Figure 7 is a flow diagram of a second embodiment of a method for<br>
calculating 740 the stopped delay of vehicles in each digital image. This second<br>
embodiment is similar to the first embodiment for calculating 640 stopped delay per<br>
image, but differs in that the second embodiment integrates a time element to prevent<br>
the possible miscounting of overlapping vehicles that may occur in the first<br>
embodiment.<br>
[67] According to the second embodiment for calculating 740 the total stopped<br>
delay in a particular frame, the distance between vehicles along the line of pixels is<br>
calculated 756 for every real image frame. The distance between vehicles is<br>
calculated 756 by determining the length of the traffic lane between the rear of a<br>
leading vehicle and the front of a following vehicle. This is accomplished by<br>
measuring the length of pixels in the line of pixels that have intensities comparable to<br>
those of the background.<br>
[68] Once the vehicles in the frame have been identified and the distance between<br>
them have been calculated 756, it is determined 758 whether this distance between<br>
vehicles is below a specified gap distance. As with the first embodiment discussed<br>
above, the specified gap distance in the second embodiment may be user defined, and<br><br>
entered into the user interface component of a software module that performs the<br>
method described herein. When the gap in front of a given vehicle is below the<br>
specified gap distance, the vehicle is considered stopped.<br>
[69] As was discussed above, when a vehicle comes to a stop close to the rear of<br>
another vehicle, the gap between the two may not be observable, and the two vehicles<br>
may appear as one long vehicle. Consequently, it is determined 760 whether a<br>
particular vehicle is greater than a specified maximum length. In either event that the<br>
distance between vehicles has a length greater than or less than the specified gap<br>
distance, the method determines 760 if the vehicle is longer than the specified<br>
maximum length.<br>
[70] If the distance between vehicles is greater than the specified gap distance, and<br>
the rear vehicle is not longer than the specified vehicle length, the vehicle is<br>
considered to be moving 762. However, if the distance between vehicles is less than<br>
the specified gap distance, and the rear vehicle is not longer than the specified vehicle<br>
length, the vehicle is considered a single, stopped vehicle.<br>
[71] If it is determined 760 that the vehicle is longer than the specified maximum<br>
vehicle length, the method then determines 770 the number and lengths of the vehicles<br>
that occupied the same region as the long vehicle in the preceding frame. Using the<br>
number of vehicles in the queue from the previous frame improves the count of<br>
vehicles stopped in the queue of the current frame being analyzed. Unlike the first<br>
embodiment for calculating 640 the stopped delay for each image, the second<br>
embodiment 740 does not divide long vehicles into average vehicle lengths. Instead,<br>
it evaluates the previous frame to determine 772 if there was more than one vehicle in<br>
the same region of the long vehicle.<br>
[72] If only one long vehicle existed in the previous frame, the method then queries<br>
774 whether the first question 758 was answered affirmatively, namely whether the<br>
distance between vehicles was below a specified gap distance. If it was earlier<br>
determined 758 that the distance between vehicles was not less than the specified gap<br>
distance, then the vehicle is considered to be moving 762. However, if it was earlier<br>
determined 758 that the distance between vehicles was less than the specified gap<br>
distance, then the vehicle is considered to be a long, stopped vehicle.<br><br>
[73] If more than one vehicle existed in the previous frame in the region of the<br>
lengthy vehicle of the current frame, the long vehicle is divided 764 into multiple<br>
vehicles in proportion to the vehicle sizes in the previous frame. Consequently,<br>
differing vehicle proportions are maintained because the second embodiment of the<br>
method for calculating 740 the stopped delay for each image uses the vehicle lengths<br>
in the previous frame to determine 770 each vehicle's size in proportion to the long<br>
vehicle in the current frame.<br>
[74] For a given frame the number of vehicles stopped is added 766 together to<br>
determine the total number of vehicles stopped within the frame. The total number of<br>
stopped vehicles is then multiplied 768 by the specified time interval between frames.<br>
The resulting value represents the total stopped delay for the particular frame, and is<br>
used in conjunction with the method described in Figure 4 to determine the average<br>
stopped delay per vehicle.<br>
[75] Figure 8 is flow diagram of a third embodiment of a method for calculating<br>
840 the stopped delay for each vehicle. Unlike the first two embodiments 640, 740<br>
for calculating the stopped delay for each frame, the third embodiment 840 does not<br>
evaluate gaps between vehicles to determine whether a vehicle is stopped, but instead<br>
tracks individual vehicle movement through time to determine vehicle speed and<br>
position.<br>
[76] For a given vehicle that appears on a series of frames, the front and rear of<br>
each vehicle are monitored 876 and updated between frames to determine if there has<br>
been movement of the vehicle. The speed of the front of the vehicle and the speed of<br>
the rear of the vehicle are calculated 878 by measuring the distance each moved and<br>
divided by the specified time increment between frames. The average of the speed of<br>
the front of the vehicle and the speed of the rear of the vehicle is then used to set the<br>
overall vehicle speed and to predict 878 the future position of the vehicle.<br>
[77] As the speed and future position of a particular vehicle is calculated, it is<br>
determined 880 whether multiple vehicles in one frame merge into one long vehicle in<br>
the next. If multiple vehicles merge into one long vehicle, then the division between<br>
the vehicles is maintained 882 by a ratio of vehicle lengths before the vehicles were<br>
viewed as overlapping. The speed of each overlapping vehicle is calculated from the<br>
front end or rear end of that vehicle, whichever is not overlapping another vehicle. If<br><br>
both ends of the vehicle are overlapped by other vehicles, the average speed of the<br>
predicted front and rear of the vehicle is used as discussed previously. Consequently,<br>
individual vehicle positions and speeds are preserved, even when overlapping in a<br>
given queue.<br>
[78] As the vehicle positions are monitored 876, and their speed and future<br>
positions are calculated 878, it is determined 884 whether a particular vehicle is<br>
moving slower than a specified stopping speed. If the vehicle is moving at a speed<br>
greater than the specified stopping speed, then the vehicle is considered not stopped<br>
862. However, if the vehicle is moving at a speed less than a specified stopping<br>
speed, then the vehicle is considered stopped. The specified stopping speed for this<br>
third embodiment for calculating 840 the stopped delay for each vehicle may be user<br>
defined and entered into a user interface component of a software module that<br>
performs the method described herein.<br>
[79] If the vehicle is considered stopped because it is moving slower than the<br>
specified stopping speed, the stopped delay for each vehicle is calculated 886. The<br>
stopped delay for a vehicle is increased by the specified time interval between frames<br>
for each frame that the speed of the vehicle is below the specified stopping speed.<br>
Therefore, according to this embodiment, the stopped delay for each individual<br>
vehicle is calculated 886 over the span of several frames, instead of calculating the<br>
stopped delay for all vehicles in a single frame. This value is used to calculate 446 the<br>
average stopped delay per vehicle as described in conjunction with Figure 4.<br>
[80] Referring still to Figure 8, after the stopped delay for a single vehicle is<br>
calculated 886 over the course of several frames, the vehicles will pull out of the<br>
queue and enter the intersection after the traffic light turns green. The vehicles<br>
entering the intersection are further monitored to determine 888 whether a particular<br>
vehicle becomes longer than an allowed vehicle length growth percentage, and<br>
whether a mistakenly single vehicle turns into multiple vehicles. If what was<br>
mistakenly viewed as a single vehicle as the vehicle came to a stop is in all actuality<br>
two or more vehicles, then the front of the vehicle will move while the rear remains<br>
stationary as the vehicles first start to enter the intersection. Accordingly, the method<br>
described herein will view this as a single vehicle becoming longer or being stretched,<br>
when actually there are two vehicles. When entering the intersection the front vehicle<br><br>
begins to move before the rear vehicle, thus giving the appearance of a single vehicle<br>
becoming longer through each frame.<br>
[81] Therefore, vehicles are evaluated 888 against an allowed vehicle length growth<br>
percentage. According to one embodiment, this specified vehicle length growth<br>
percentage may be a user defined value. If the length of the vehicle does not increase<br>
greater than the allowed percentage change, the vehicle is considered to be a single<br>
vehicle entering the intersection. However, if the vehicle "stretches" and its length<br>
increases greater than the allowed percentage change, then the rear of the vehicle is<br>
considered to be located within the front of the following vehicle. The length of the<br>
vehicle is not allowed to be greater than the allowed percentage change, which forces<br>
separation 889 of the rear of the vehicle from the front of the following vehicle.<br>
[82] Furthermore, if an interior gap develops in the middle of a mistakenly long<br>
vehicle as the vehicle enters the intersection, the mistakenly long vehicle is also<br>
counted as being composed of multiple vehicles. A mistakenly long vehicle will be<br>
split into its multiple vehicle components if it is determined 888 that the vehicle<br>
length grows above a specified percentage or internal gaps develop. The stopped<br>
delay of this mistaken vehicle will then be assigned 890 to all resulting vehicles.<br>
[83] Depending on the view and angle of the camera, it may be difficult to<br>
distinguish vehicles as they leave the queue and enter the intersection if there is a lot<br>
of overlap in stopped vehicles. This third embodiment 840 may falsely view vehicles<br>
speeding up almost instantly when entering the intersection. This may lead to an<br>
overestimate of the number of vehicles counted as entering the intersection and thus<br>
would decrease the estimated average stopped delay per vehicle. Therefore, the third<br>
embodiment for calculating 840 the stopped delay for each vehicle may alternatively<br>
include the step of monitoring the acceleration rate of vehicles entering the<br>
intersection. A user defined maximum acceleration rate may be added, ensuring that<br>
new vehicles entering the intersection cannot accelerate faster than is physically<br>
possible.<br>
[84] Figure 9 is a flow diagram of one embodiment of a method for estimating 946<br>
the average stopped delay per vehicle, as the concluding step 446 in the method<br>
discussed in conjunction with Figure 4. According to this method, the total stopped<br>
delay for each digital frame or for each vehicle is determined 990. The total stopped<br><br>
delay for each vehicle frame is determined 990 according to the first and second<br>
embodiments 640, 740 for calculating the total stopped delay for a particular frame.<br>
The total stopped delay for a particular vehicle is determined 990 according to the<br>
third embodiment 840 for calculating the stopped delay for each vehicle.<br>
[85] The sum of the total stopped delay in all frames or of all vehicles is<br>
subsequently calculated 992. The total stopped delay for all frames or vehicles is then<br>
divided 994 by the total number of vehicles that passed through the limit line and into<br>
the intersection during the analysis period. The resulting value yields the estimated<br>
average stopped delay per vehicle.<br>
[86] Figure 10 is a block diagram illustrating the major hardware components<br>
typically utilized in a computing device 1002 that is used in conjunction with a system<br>
for estimating the average stopped delay per vehicle as described herein. Computing<br>
devices 1002 are known in the art and are commercially available. A computing device<br>
1002 typically includes a processor 1004 in electronic communication with input<br>
components 1006 and/or output components 1008. The processor 1004 is operably<br>
connected to input 1006 and/or output components 1008 capable of electronic<br>
communication with the processor 1004, or, in other words, to devices capable of<br>
input and/or output in the form of an electrical signal. Embodiments of computing<br>
devices 1002 may include the inputs 1006, outputs 1008 and the processor 1004<br>
within the same physical structure or in separate housings or structures.<br>
[87] The electronic device 1002 may also include memory 1010. The memory<br>
1010 may be a separate component from the processor 1004, or it may be on-board<br>
memory 1010 included in the same part as the processor 1004. For example,<br>
microcontrollers often include a certain amount of on-board memory.<br>
[88] The processor 1004 is also in electronic communication with a communication<br>
interface 1012. The communication interface 1012 may be used for communications<br>
with other computing devices, servers, etc. The computing device 1002 may also<br>
include other communication ports 1014. In addition, other components 1016 may<br>
also be included in the computing device 1002.<br>
[89] Of course, those skilled in the art will appreciate the many kinds of different<br>
devices that may be used with embodiments herein. The computing device 1002 may<br>
be a one-board type of computer, such as a controller, a typical desktop computer,<br><br>
such as an IBM-PC compatible, a PDA, a Unix-based workstation, or any other<br>
available computing device that is capable of operating the algorithms and methods<br>
disclosed herein. Accordingly, the block diagram of Figure 10 is only meant to<br>
illustrate typical components of a computing device 1002 and is not meant to limit the<br>
scope of embodiments disclosed herein.<br>
[90] Those of skill in the art would understand that information and signals may be<br>
represented using any of a variety of different technologies and techniques. For<br>
example, data, instructions, commands, information, signals, bits, symbols, and chips<br>
that may be referenced throughout the above description may be represented by<br>
voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields<br>
or particles, or any combination thereof.<br>
[91] Those of skill would further appreciate that the various illustrative logical<br>
blocks, modules, circuits, and algorithm steps described in connection with the<br>
embodiments disclosed herein may be implemented as electronic hardware, computer<br>
software, or combinations of both. To clearly illustrate this interchangeability of<br>
hardware and software, various illustrative components, blocks, modules, circuits, and<br>
steps have been described above generally in terms of their functionality. Whether<br>
such functionality is implemented as hardware or software depends upon the<br>
particular application and design constraints imposed on the overall system. Skilled<br>
artisans may implement the described functionality in varying ways for each particular<br>
application, but such implementation decisions should not be interpreted as causing a<br>
departure from the scope of the present invention.<br>
[92] The various illustrative logical blocks, modules, and circuits described in<br>
connection with the embodiments disclosed herein may be implemented or performed<br>
with a general purpose processor, a digital signal processor (DSP), an application<br>
specific integrated circuit (ASIC), a field programmable gate array signal (FPGA) or<br>
other programmable logic device, discrete gate or transistor logic, discrete hardware<br>
components, or any combination thereof designed to perform the functions described<br>
herein. A general purpose processor may be a microprocessor, but in the alternative,<br>
the processor may be any conventional processor, controller, microcontroller, or state<br>
machine. A processor may also be implemented as a combination of computing<br>
devices, e.g., a combination of a DSP and a microprocessor, a plurality of<br><br>
microprocessors, one or more microprocessors in conjunction with a DSP core, or any<br>
other such configuration.<br>
[93] The steps of a method or algorithm described in connection with the<br>
embodiments disclosed herein may be embodied directly in hardware, in a software<br>
module executed by a processor, or in a combination of the two. A software module<br>
may reside in RAM memory, flash memory, ROM memory, EPROM memory,<br>
EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other<br>
form of storage medium known in the art. An exemplary storage medium is coupled<br>
to the processor such that the processor can read information from, and write<br>
information to, the storage medium. In the alternative, the storage medium may be<br>
integral to the processor. The processor and the storage medium may reside in an<br>
ASIC. The ASIC may reside in a user terminal. In the alternative, the processor and<br>
the storage medium may reside as discrete components in a user terminal.<br>
[94] The methods disclosed herein comprise one or more steps or actions for<br>
achieving the described method. The method steps and/or actions may be<br>
interchanged with one another without departing from the scope of the present<br>
invention. In other words, unless a specific order of steps or actions is required for<br>
proper operation of the embodiment, the order and/or use of specific steps and/or<br>
actions may be modified without departing from the scope of the present invention.<br>
[95] While specific embodiments and applications of the present invention have<br>
been illustrated and described, it is to be understood that the invention is not limited to<br>
the precise configuration and components disclosed herein. Various modifications,<br>
changes, and variations which will be apparent to those skilled in the art may be made<br>
in the arrangement, operation, and details of the methods and systems of the present<br>
invention disclosed herein without departing from the spirit and scope of the<br>
invention.<br><br>
CLAIMS:<br>
1.	A method for estimating an average stopped delay per vehicle at a signalized<br>
intersection, comprising:<br>
initializing background intensities of a line of pixels in a digital image of an<br>
actual traffic lane without vehicles;<br>
identifying vehicle location through measuring intensities of the line of pixels<br>
in another digital image of the actual traffic lane with vehicles;<br>
calculating a stopped delay for each vehicle or digital image with vehicles; and<br>
calculating the average stopped delay per vehicle.<br>
2.	The method of claim 1, wherein initializing background intensities comprises:<br>
digitizing an image of the actual traffic lane without vehicles;<br>
establishing the line of pixels on the digital image of the traffic lane without<br>
vehicles, such that the line of pixels extends upstream into the traffic<br>
lane;<br>
assigning a length value to each pixel in the line of pixels; and<br>
reading and storing the intensities of each pixel in the line of pixels.<br>
3.	The method of claim 2, wherein identifying vehicle location comprises:<br>
measuring the intensities of each pixel in the line of pixels on the digital image<br>
of the actual traffic lane with vehicles;<br>
calculating the difference between the pixel intensities of the line of pixels on<br>
the digital image of the traffic lane without vehicles and the pixel<br>
intensities of the line of pixels on the digital image of the traffic lane<br>
with vehicles; and<br>
identifying a group of consecutive pixels where the difference between pixel<br>
intensity is outside of a specified threshold.<br>
4.	The method of claim 1, wherein calculating the stopped delay for each digital<br>
image with vehicles comprises:<br>
calculating a distance between vehicles on the digital image with vehicles;<br>
determining whether a vehicle is stopped if the distance between vehicles is<br>
below a specified gap distance;<br>
adding together a total number of vehicles stopped in the digital image with<br>
vehicles; and<br><br>
multiplying the total number of vehicles stopped by a time interval between<br>
each digital image with vehicles.<br>
5.	The method of claim 4, wherein calculating the stopped delay for each digital<br>
image with vehicles further comprises:<br>
determining whether a length of the vehicle is greater than a specified<br>
maximum length; and<br>
dividing the vehicle into multiple stopped vehicles based on a specified<br>
average vehicle length if the length of the vehicle is greater than the<br>
specified maximum length.<br>
6.	The method of claim 4, wherein calculating the stopped delay for each digital<br>
image with vehicles further comprises:<br>
identifying a vehicle with a length greater than a specified maximum length;<br>
determining a number and length of vehicles in a previous frame in a<br>
substantially similar location as the vehicle with the length greater than<br>
the specified maximum length; and<br>
dividing the vehicle with the length greater than the specified maximum length<br>
into multiple stopped vehicles based on the number and length of<br>
vehicles in the previous frame in the substantially similar location.<br>
7.	The method of claim 1, wherein calculating the stopped delay for each vehicle<br>
comprises:<br>
monitoring a location of a front and rear of a vehicle between consecutive<br>
frames;<br>
calculating a speed and future position of the vehicle;<br>
determining the vehicle is stopped if the speed is below a specified stopping<br>
speed; and<br>
calculating a total stopped delay for the vehicle over consecutive frames.<br>
8.	The method of claim 7, wherein calculating the stopped delay for each vehicle<br>
further comprises:<br>
determining whether the vehicle overlaps another vehicle; and<br>
maintaining a division between the vehicles through a ratio of vehicle lengths<br>
before the vehicles were viewed as overlapping.<br><br>
9.	The method of claim 7, wherein calculating the stopped delay for each vehicle<br>
further comprises:<br>
determining if the vehicle becomes longer than an allowed vehicle length<br>
growth percentage when entering the intersection; and<br>
separating the rear of the vehicle from a front of a following vehicle such that<br>
the vehicle does not become longer than the allowed vehicle length<br>
growth percentage.<br>
10.	The method of claim 1, wherein calculating the average stopped delay per vehicle<br>
comprises:<br>
calculating a total stopped delay of all digital images with vehicles or a total<br>
stopped delay of all vehicles; and<br>
dividing the total stopped delay by a total number of vehicles that entered the<br>
intersection.<br>
11.	A computing device configured for estimating an average stopped delay per<br>
vehicle at a signalized intersection, the computing device comprising:<br>
a processor;<br>
memory in electronic communication with the processor; and<br>
executable instructions executable by the processor, wherein the executable<br>
instructions are configured to implement a method comprising:<br>
initializing background intensities of a line of pixels in a digital image<br>
of an actual traffic lane without vehicles;<br>
identifying vehicle location by measuring intensities of the line of<br>
pixels in another digital image of the actual traffic lane with<br>
vehicles;<br>
calculating a stopped delay for each vehicle or digital image with<br>
vehicles; and<br>
calculating the average stopped delay per vehicle.<br>
12.	The computing device of claim 11, wherein initializing background intensities<br>
comprises:<br>
digitizing an image of the actual traffic lane without vehicles;<br><br>
establishing the line of pixels on the digital image of the traffic lane without<br>
vehicles, such that the line of pixels extends upstream into the traffic<br>
lane;<br>
assigning a length value to each pixel in the line of pixels; and<br>
reading and storing the intensities of each pixel in the line of pixels.<br>
13.	The computing device of claim 12, wherein identifying vehicle location<br>
comprises:<br>
measuring the intensities of each pixel in the line of pixels on the digital image<br>
of the actual traffic lane with vehicles;<br>
calculating the difference between the pixel intensities of the line of pixels on<br>
the digital image of the traffic lane without vehicles and the pixel<br>
intensities of the line of pixels on the digital image of the traffic lane<br>
with vehicles; and<br>
identifying a group of consecutive pixels where the difference between pixel<br>
intensity is outside of a specified threshold.<br>
14.	The computing device of claim 11, wherein calculating the stopped delay for each<br>
digital image with vehicles comprises:<br>
calculating a distance between vehicles on the digital image with vehicles;<br>
determining whether a vehicle is stopped if the distance between vehicles is<br>
below a specified gap distance;<br>
adding together a total number of vehicles stopped in the digital image with<br>
vehicles; and<br>
multiplying the total number of vehicles stopped by a time interval between<br>
each digital image with vehicles.<br>
15.	The computing device of claim 14, wherein calculating the stopped delay for each<br>
digital image with vehicles further comprises:<br>
determining whether a length of the vehicle is greater than a specified<br>
maximum length; and<br>
dividing the vehicle into multiple stopped vehicles based on a specified<br>
average vehicle length if the length of the vehicle is greater than the<br>
specified maximum length.<br><br>
16.	The computing device of claim 14, wherein calculating the stopped delay for each<br>
digital image with vehicles further comprises:<br>
identifying a vehicle with a length greater than a specified maximum length;<br>
determining a number and length of vehicles in a previous frame in a<br>
substantially similar location as the vehicle with the length greater than<br>
the specified maximum length; and<br>
dividing the vehicle with the length greater than the specified maximum length<br>
into multiple stopped vehicles based on the number and length of<br>
vehicles in the previous frame in the substantially similar location.<br>
17.	The computing device of claim 11, wherein calculating the stopped delay for each<br>
vehicle comprises:<br>
monitoring a location of a front and rear of a vehicle between consecutive<br>
frames;<br>
calculating a speed and future position of the vehicle;<br>
determining the vehicle is stopped if the speed is below a specified stopping<br>
speed; and<br>
calculating a total stopped delay for the vehicle over consecutive frames.<br>
18.	The computing device of claim 17, wherein calculating the stopped delay for each<br>
vehicle further comprises:<br>
determining whether the vehicle overlaps another vehicle; and<br>
maintaining a division between the vehicles through a ratio of vehicle lengths<br>
before the vehicles were viewed as overlapping.<br>
19.	The computing device of claim 17, wherein calculating the stopped delay for each<br>
vehicle further comprises:<br>
determining if the vehicle becomes longer than an allowed vehicle length<br>
growth percentage when entering the intersection; and<br>
separating the rear of the vehicle from a front of a following vehicle such that<br>
the vehicle does not become longer than the allowed vehicle length<br>
growth percentage.<br>
20.	The computing device of claim 11, wherein calculating the average stopped delay<br>
per vehicle comprises:<br><br>
calculating a total stopped delay of all digital images with vehicles or a total<br>
stopped delay of all vehicles; and<br>
dividing the total stopped delay by a total number of vehicles that entered the<br>
intersection.<br>
21.	A computer-readable medium for storing program data, wherein the program data<br>
comprises executable instructions for implementing a method in a computing device<br>
for estimating an average stopped delay per vehicle at a signalized intersection, the<br>
method comprising:<br>
initializing background intensities of a line of pixels in a digital image of an<br>
actual traffic lane without vehicles;<br>
identifying vehicle location by measuring intensities of the line of pixels in<br>
another digital image of the actual traffic lane with vehicles;<br>
calculating a stopped delay for each vehicle or digital image with vehicles; and<br>
calculating the average stopped delay per vehicle.<br>
22.	The computer-readable medium of claim 21, wherein initializing background<br>
intensities comprises:<br>
digitizing an image of the actual traffic lane without vehicles;<br>
establishing the line of pixels on the digital image of the traffic lane without<br>
vehicles, such that the line of pixels extends upstream into the traffic<br>
lane;<br>
assigning a length value to each pixel in the line of pixels; and<br>
reading and storing the intensities of each pixel in the line of pixels.<br>
23.	The computer-readable medium of claim 22, wherein identifying vehicle location<br>
comprises:<br>
measuring the intensities of each pixel in the line of pixels on the digital image<br>
of the actual traffic lane with vehicles;<br>
calculating the difference between the pixel intensities of the line of pixels on<br>
the digital image of the traffic lane without vehicles and the pixel<br>
intensities of the line of pixels on the digital image of the traffic lane<br>
with vehicles; and<br>
identifying a group of consecutive pixels where the difference between pixel<br>
intensity is outside of a specified threshold.<br><br>
24.	The computer-readable medium of claim 21, wherein calculating the stopped<br>
delay for each digital image with vehicles comprises:<br>
calculating a distance between vehicles on the digital image with vehicles;<br>
determining whether a vehicle is stopped if the distance between vehicles is<br>
below a specified gap distance;<br>
adding together a total number of vehicles stopped in the digital image with<br>
vehicles; and<br>
multiplying the total number of vehicles stopped by a time interval between<br>
each digital image with vehicles.<br>
25.	The computer-readable medium of claim 24, wherein calculating the stopped<br>
delay for each digital image with vehicles further comprises:<br>
determining whether a length of the vehicle is greater than a specified<br>
maximum length; and<br>
dividing the vehicle into multiple stopped vehicles based on a specified<br>
average vehicle length if the length of the vehicle is greater than the<br>
specified maximum length.<br>
26.	The computer-readable medium of claim 24, wherein calculating the stopped<br>
delay for each digital image with vehicles further comprises:<br>
identifying a vehicle with a length greater than a specified maximum length;<br>
determining a number and length of vehicles in a previous frame in a<br>
substantially similar location as the vehicle with the length greater than<br>
the specified maximum length; and<br>
dividing the vehicle with the length greater than the specified maximum length<br>
into multiple stopped vehicles based on the number and length of<br>
vehicles in the previous frame in the substantially similar location.<br>
27.	The computer-readable medium of claim 21, wherein calculating the stopped<br>
delay for each vehicle comprises:<br>
monitoring a location of a front and rear of a vehicle between consecutive<br>
frames;<br>
calculating a speed and future position of the vehicle;<br>
determining the vehicle is stopped if the speed is below a specified stopping<br>
speed; and<br><br>
calculating a total stopped delay for the vehicle over consecutive frames.<br>
28.	The computer-readable medium of claim 27, wherein calculating the stopped<br>
delay for each vehicle further comprises:<br>
determining whether the vehicle overlaps another vehicle; and<br>
maintaining a division between the vehicles through a ratio of vehicle lengths<br>
before the vehicles were viewed as overlapping.<br>
29.	The computer-readable medium of claim 27, wherein calculating the stopped<br>
delay for each vehicle further comprises:<br>
determining if the vehicle becomes longer than an allowed vehicle length<br>
growth percentage when entering the intersection; and<br>
separating the rear of the vehicle from a front of a following vehicle such that<br>
the vehicle does not become longer than the allowed vehicle length<br>
growth percentage.<br>
30.	The computer-readable medium of claim 21, wherein calculating the average<br>
stopped delay per vehicle comprises:<br>
calculating a total stopped delay of all digital images with vehicles or a total<br>
stopped delay of all vehicles; and<br>
dividing the total stopped delay by a total number of vehicles that entered the<br>
intersection.<br><br>
A method for authenticating a textile<br>
material that is initiaded by selecting a unique nucleic<br>
acid marker having a specific length and a specific<br>
sequence. A media that causes the unique nucleic acid<br>
marker to adhere to a fibrous material is then selected.<br>
The method then proceeds to generate a nucleic acid<br>
marker mixture by mixing the media with the nucleic<br>
acid marker. The nucleic acid marker mixture is then<br>
applied to the fibrous material. A marked fibrous<br>
material is produced by marking the fibrous material<br>
with the nucleic acid marker. The textile material is<br>
then authenticated by detecting the unique nucleic<br>
acid marker with primers that are specific to the unique<br>
nucleic acid. In an alternative embodiment, a viscous<br>
solution for fiber spinning is selected and mixed with<br>
the nucleic acid marker to generate a viscous dope that<br>
is extruded through an opening in a spinneret to form a<br>
marked fiber that is used to generate the textile material.<br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1jb3ZlcmxldHRlci5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-coverletter.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1mb3JtMS5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-form1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1mb3JtMi5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-form2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1mb3JtMy5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-form3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1mb3JtNS5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-form5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1wY3QgZm9ybS5wZGY=" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-pct form.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDA4MTYta29sbnAtMjAwNi1wcmlvcml0eSBkb2N1bWVudHMucGRm" target="_blank" style="word-wrap:break-word;">00816-kolnp-2006-priority documents.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LUtPTE5QLTIwMDYtRk9STSAyNy5wZGY=" target="_blank" style="word-wrap:break-word;">816-KOLNP-2006-FORM 27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LUtPTE5QLTIwMDYtRk9STS0yNy5wZGY=" target="_blank" style="word-wrap:break-word;">816-KOLNP-2006-FORM-27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1jb3JyZXNwb25kZW5jZS5wZGY=" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1mb3JtIDE4LnBkZg==" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=ODE2LWtvbG5wLTIwMDYtZ3JhbnRlZC1zcGVjaWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">816-kolnp-2006-granted-specification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMDA4MTYta29sbnAtMjAwNi5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-00816-kolnp-2006.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="231419-thin-comfortable-sanitary-napkin-having-reduced-bunching.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="231421-sleeve-assembly-for-holding-digital-media-disk.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>231420</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>816/KOLNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>10/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>06-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>04-Mar-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>04-Apr-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>BRIGHAM YOUNG UNIVERSITY</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>TECHNOLOGY TRANSFER OFFICE 3760 HBLL, PROVO, UT</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HERETH WILLIAM, R.</td>
											<td>655 STINCHCOMB DRIVE, APT. 5, COLUMBUS, OH 43202</td>
										</tr>
										<tr>
											<td>2</td>
											<td>ZUNDEL, ALAN</td>
											<td>468 SOUTH 320 WEST, OREM, UT 84058</td>
										</tr>
										<tr>
											<td>3</td>
											<td>SAITO, MITSURU</td>
											<td>1485 WEST 1370 NORTH, PROVO, UT 84604</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G08G</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2004/031526</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-09-24</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10/948,104</td>
									<td>2004-09-23</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/505,666</td>
									<td>2003-09-24</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/231420-automated-estimation-of-average-stopped-delay-at-signalized-intersections by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:17:55 GMT -->
</html>
