<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/229328-method-for-encoding-and-decoding-input-video-sequences-and-device-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:00:43 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 229328:METHOD FOR ENCODING AND DECODING INPUT VIDEO SEQUENCES AND DEVICE THEREOF</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD FOR ENCODING AND DECODING INPUT VIDEO SEQUENCES AND DEVICE THEREOF</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to an encoding method applied to an input video sequence corresponding to successive scenes subdivided into successive video object planes (VOPs) and generating, for coding all the video objects of said scenes, a coded bitstream the content of which is described in terms of separate channels and constituted of encoded video data in which each data item is described by means of a bitstream syntax allowing to recognize and decode all the elements of said content, said syntax comprising an additional syntactic information provided for describing independently the type of temporal prediction of the various channels. According to the invention, said additional information is a syntactic element placed at the slice level or the macroblock level in the coded bitstream, and its meaning is either specific for each present channel or shared by all existing channels.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
"VIDEO ENCODING AND DECODING METHODS AND CORRESPONDING ENCODING AND DECODING DEVICES"<br>
FIELD OF THE INVENTION<br>
The present invention generally relates to the field of video compression and, for instance, to the video coding standards of the MPEG family (MPEG-1, MPEG-2, MPEG-4) and to the video recommendations of the ITU-H.26X family (H.261, H.263 and extensions, H.264). More specifically, this invention relates to an encoding method applied to an input video sequence corresponding to successive scenes subdivided into successive video object planes (VOPs) and generating, for coding all the video objects of said scenes, a coded bitstream the content of which is described in terms of separate channels and constituted of encoded video data in which each data item is described by means of a bitstream syntax allowing to recognize and decode all the elements of said content, said syntax comprising an additional syntactic information provided for describing independently the type of temporal prediction of the various channels, said predictions being chosen within a list comprising the following situations :<br>
-	the temporal prediction is formed by directly applying the motion field sent by the encoder on one or more reference pictures ;<br>
-	the temporal prediction is a copy of a reference image ;<br>
-	the temporal prediction is formed by the temporal interpolation of the motion field;<br>
-	the temporal prediction is formed by the temporal interpolation of the current motion field and further refined by the motion field sent by the encoder .<br>
The invention also relates to a corresponding encoding device, to a transmittable video signal consisting of a coded bitstream generated by such an encoding device, and to a method and a device for decoding a video signal consisting of such a coded bitstream.<br>
BACKGROUND OF THE INVENTION<br>
In the first video coding standards and recommendations (up to MPEG-4 and H.264), the video was assumed to be rectangular and to be described in terms of a luminance channel and two chrominance channels. With MPEG-4, an additional channel carrying shape information has been introduced. Two modes are available to<br><br>
compress those channels : the INTRA mode, according to which each channel is encoded by exploiting the spatial redundancy of the pixels in a given channel of a single image, and the INTER mode, that exploits the temporal redundancy between separate images. The INTER mode relies on a motion-compensation technique, which describes an image from one or several image(s) previously decoded by encoding the motion of pixels from one image to the other. Usually, the image to be encoded is partitioned into independent blocks or macroblocks, each of them being assigned a motion vector. A prediction of the image is then constructed by displacing pixel blocks from the reference image(s) according to the set of motion vectors (luminance and chrominance channels share the same motion description). Finally, the difference (called the residual signal) between the image to be encoded and its motion-compensated prediction is encoded in the INTER mode to further refine the decoded image. However, the fact that all pixel channels are described by the same motion information is a limitation damaging the compression efficiency of the video coding system.<br>
SUMMARY OF THE INVENTION<br>
It is therefore the object of the invention to propose a video encoding method in which said drawback is avoided by adapting the way the temporal prediction is formed.<br>
To this end, the invention relates to a method such as defined in the introductory part of the description and which is moreover characterized in that said additional syntactic information is a syntactic element placed in said generated coded bitstream and its meaning is specific for each present channel, said element being placed at the slice level or at the macroblock level according to the proposed embodiment.<br>
The invention also relates to a corresponding encoding device, to a transmittable video signal consisting of a coded bitstream generated by such an encoding device, and to a method and a device for decoding a video signal consisting of such a coded bitstream.<br>
DETAILED DESCRIPTION OF THE INVENTION<br>
According to the invention, it is proposed to introduce in the encoding syntax used by the video standards and recommendations an additional information consisting of a new syntactic element supporting their lack of flexibility and opening new possibilities to encode more efficiently and independently the temporal prediction of<br><br>
various channels. This additional syntactic element, called for example "channel temporal prediction", takes the following symbolic values :<br>
Motion_compensation<br>
Temporal_copy<br>
Temporal_interpolation<br>
Motion_compensated_temporaHnterpolation, and the meaning of these values is :<br>
a)	motion__compensation : the temporal prediction is formed by directly applying the motion field sent by the encoder on one or more reference pictures (this default mode is implicitly the INTER coding mode of most of the current coding systems);<br>
b)	temporal_copy : the temporal prediction is a copy of a reference image ;<br>
c)	temporaljnterpolation : the temporal prediction is formed by the temporal interpolation of the motion fields;<br>
d)	motion_compensated_temporal_interpolation : the temporal prediction is formed by the temporal interpolation of the current motion field and further refined by the motion field sent by the encoder.<br>
The words "temporal interpolation" must be understood in abroad sense, i.e. as meaning any operation of the type defined by an expression such as Vnew = a.Vl + b.V2 + K, where VI and V2 designate previously decoded motion fields, a and b designate coefficients respectively assigned to said motion fields, K designates an offset and Vnew is the new motion field thus obtained. It can therefore be seen that, in fact, the particular case of the temporal copy is included in the more general case of the temporal interpolation, for b = 0 and K = 0 (or a = 0 and K = 0).<br>
According to the invention, the additional syntactic element thus proposed has to be placed at the following levels in the coded bitstream that has to be stored (or to be transmitted to the decoding side):<br>
1)	either at the slice level;<br>
2)	or at the macroblock level;<br>
this additional syntactic element being in each case either specific for each present channel or, possibly, shared by all the channels.<br>
This invention may be used in some identified situations where the way of constructing the temporal prediction can be switched on a slice or macroblock basis, and also on a channel basis. A first example may be for instance a sequence with a shape channel: it is possible that the shape information does not change much, whereas the<br><br>
luminance and chrominance channels carry varying information (it is for instance the case with a video depicting a rotating planet: the shape is always a disc, but the texture of it depends on the planet rotation). In this situation, the shape channel can be recovered by temporal copy, and the luminance and chrominance channels by motion compensated temporal interpolation. A second example may be the case of a change at the macroblock level. In a video sequence showing a seascape with the sky in the upper part of the picture, unlike the sea, the sky remains the same from one image to the other. Its macroblocks can therefore be encoded by temporal copy, whereas the macroblocks of the sea have to be encoded by temporal interpolation.<br><br><br><br><br>
CLAIMS :<br>
1.	An encoding method applied to an input video sequence corresponding to<br>
successive scenes subdivided into successive video object planes (VOPs) and<br>
generating, for coding all the video objects of said scenes, a coded bitstream the content<br>
of which is described in terms of separate channels and constituted of encoded video<br>
data in which each data item is described by means of a bitstream syntax allowing to<br>
recognize and decode all the elements of said content, said syntax comprising an<br>
additional syntactic information provided for describing independently the type of<br>
temporal prediction of the various channels, said predictions being chosen within a list<br>
comprising the following situations :<br>
-	the temporal prediction is formed by directly applying the motion field sent by the encoder on one or more reference pictures ;<br>
-	the temporal prediction is a copy of a reference image ;<br>
-	the temporal prediction is formed by the temporal interpolation of the motion field;<br>
-	the temporal prediction is formed by the temporal interpolation of the current motion field and further refined by the motion field sent by the encoder;<br>
said method being further characterized in that said additional syntactic information is a syntactic element placed at the slice level in said generated coded bitstream and its meaning is specific for each present channel.<br>
2.	An encoding method applied to an input video sequence corresponding to<br>
successive scenes subdivided into successive video object planes (VOPs) and<br>
generating, for coding all the video objects of said scenes, a coded bitstream the content<br>
of which is described in terms of separate channels and constituted of encoded video<br>
data in which each data item is described by means of a bitstream syntax allowing to<br>
recognize and decode all the elements of said content, said syntax comprising an<br>
additional syntactic information provided for describing independently the type of<br>
temporal prediction of the various channels, said predictions being chosen within a list<br>
comprising the following situations :<br>
-	the temporal prediction is formed by directly applying the motion field sent by the encoder on one or more reference pictures ;<br>
-	the temporal prediction is a copy of a reference image ;<br>
-	the temporal prediction is formed by the temporal interpolation of the motion field;<br><br>
-	the temporal prediction is formed by the temporal interpolation or tne<br>
current motion field and further refined by the motion field sent by the encoder;<br>
said method being further characterized in that said additional syntactic information is a syntactic element placed at macroblock level in said generated coded bitstream and its meaning is specific for each present channel.<br>
3.	An encoding method according to anyone of claims 1 and 2, characterized in that said meaning is shared by all existing channels.<br>
4.	An encoding device processing an input video sequence that corresponds to successive scenes subdivided into successive video object planes (VOPs) and generating, for coding all the video objects of said scenes, a coded bitstream the content of which is described in terms of separate channels and constituted of encoded video data in which each data item is described by means of a bitstream syntax allowing to recognize and decode all the elements of said content, said encoding device being provided for carrying out the encoding method according to anyone of claims 1 and 2.<br>
5.	A transmittable video signal consisting of a coded bitstream generated by an encoding device processing an input video sequence that corresponds to successive scenes subdivided into successive video object planes (VOPs) and generating, for coding all the video objects of said scenes, a coded bitstream the content of which is decribed in terms of separate channels and constituted of encoded video data in which each data item is described by means of a bitstream syntax allowing to recognize and decode all the elements of said content, said transmittable video signal including an additional syntactic information provided for describing independently the type of temporal prediction of the various channels, said predictions being chosen within a list comprising the following situations :<br><br>
-	the temporal prediction is formed by directly applying the motion field sent by the encoder on one or more reference pictures ;<br>
-	the temporal prediction is a copy of a reference image ;<br>
-	the temporal prediction is formed by the temporal interpolation of the motion field;<br>
-	the temporal prediction is formed by the temporal interpolation of the current motion field and further refined by the motion field sent by the encoder ; and said additional syntactic information being a syntactic element placed at the slice level or at the macroblock level in said generated coded bitstream and its meaning is specific for each present channel.<br><br>
6.	A method for decoding a transmittable video signal consisting of a coded<br>
bitstream generated by an encoding device processing an input video sequence that<br>
corresponds to successive scenes subdivided into successive video object planes (VOPs)<br>
and generating, for coding all the video objects of said scenes, a coded bitstream the<br>
content of which is described in terms of separate channels and constituted of encoded<br>
video data in which each data item is described by means of a bitstream syntax allowing<br>
to recognize and decode all the elements of said content, said transmittable video signal<br>
including an additional syntactic information provided for describing independently the<br>
type of temporal prediction of the various channels, said predictions being chosen<br>
within a list comprising the following situations :<br>
-	the temporal prediction is formed by directly applying the motion field<br>
sent by the encoder on one or more reference pictures ;<br>
-	the temporal prediction is a copy of a reference image ;<br>
-	the temporal prediction is formed by the temporal interpolation of the motion field;<br>
-	the temporal prediction is formed by the temporal interpolation of the<br>
current motion field and further refined by the motion field sent by the encoder;<br>
and said additional syntactic information being a syntactic element placed at the slice<br>
level or at the macroblock level in said generated coded bitstream and its meaning is<br>
specific for each present channel.<br>
7.	A decoding device for carrying out a decoding method according to claim 6.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS0yMDA1LnJ0Zg==" target="_blank" style="word-wrap:break-word;">2895-2005.rtf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1ICAgRVhBTUlOQVRJT04gUkVQT1JUIFJFUExZIFJFQ0VJVkVEICAwNC0xMC0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005   EXAMINATION REPORT REPLY RECEIVED  04-10-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1ICAgT1RIRVJTICAwNC0xMC0yMDEyLnBkZg==" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005   OTHERS  04-10-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1IGFic3RyYWN0IGR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005 abstract duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1IGNsYWltcyBkdXBsaWNhdGUucGRm" target="_blank" style="word-wrap:break-word;">2895-chenp-2005 claims duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1IENPUlJFU1BPTkRFTkNFIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005 CORRESPONDENCE OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1IENPUlJFU1BPTkRFTkNFIFBPLnBkZg==" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005 CORRESPONDENCE PO.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1IGRlc2NyaXB0aW9uIChjb21wbGV0ZSkgZHVwbGljYXRlLnBkZg==" target="_blank" style="word-wrap:break-word;">2895-chenp-2005 description (complete) duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1IEZPUk0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005 FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1IEZPUk0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005 FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1DSEVOUC0yMDA1IEZPUk0gNi5wZGY=" target="_blank" style="word-wrap:break-word;">2895-CHENP-2005 FORM 6.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWNvcnJlc3BvbmRuZWNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWNvcnJlc3BvbmRuZWNlLXBvLnBkZg==" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-correspondnece-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWZvcm0gMjYucGRm" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-form 26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=Mjg5NS1jaGVucC0yMDA1LXBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">2895-chenp-2005-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="229327-wave-power-apparatus-with-linkage-unit-and-a-method-of-extracting-power-from-waves.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="229329-dithioketal-compounds.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>229328</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2895/CHENP/2005</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>12/2009</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>20-Mar-2009</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>16-Feb-2009</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>03-Nov-2005</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>NXP B.V</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>HIGH TECH CAMPUS 60, NL-5656 AG EINDHOVEN,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DUFOUR, CECILE</td>
											<td>C/O SOCIETE CIVILE SPID, 156 BOULEVARD HAUSSMANN, F-75008 PARIS,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>MARQUANT, GWENAELLE</td>
											<td>C/O SOCIETE CIVILE SPID, 156 BOULEVARD HAUSSMANN, F-75008 PARIS,</td>
										</tr>
										<tr>
											<td>3</td>
											<td>VALENTE, STEPHANE</td>
											<td>C/O SOCIETE CIVILE SPID, 156 BOULEVARD HAUSSMANN, F-75008 PARIS,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/IB04/01373</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-04-28</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>03300011.8</td>
									<td>2003-05-06</td>
								    <td>EUROPEAN UNION</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/229328-method-for-encoding-and-decoding-input-video-sequences-and-device-thereof by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 10:00:44 GMT -->
</html>
