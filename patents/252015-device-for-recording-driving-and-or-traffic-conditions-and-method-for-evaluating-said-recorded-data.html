<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/252015-device-for-recording-driving-and-or-traffic-conditions-and-method-for-evaluating-said-recorded-data by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:36:08 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 252015:DEVICE FOR RECORDING DRIVING AND/OR TRAFFIC CONDITIONS AND METHOD FOR EVALUATING SAID RECORDED DATA</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">DEVICE FOR RECORDING DRIVING AND/OR TRAFFIC CONDITIONS AND METHOD FOR EVALUATING SAID RECORDED DATA</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>According to the invention, traffic conditions can be recorded by means of at least two cameras (2, 3), which are located at a distance (15) from one another on a vehicle (1). The recording zones (11, 12) of said cameras intersect (13), thus enabling at least one reference point (R) of the environment and/or identification point of at least one second vehicle to be triangulated (T), e.g. by photogrammetry. After an accident, the behaviour of one or more vehicles (1) can be reconstructed. In addition to the respective spatial position, the three-dimensional, synchronised recording enables the speed, speed direction, changes in direction, acceleration and braking manoeuvres and the self-rotation of the individual vehicles about their centre of gravity to be identified and measured to scale, without requiring a plurality of sensors to be provided on the vehicles. The vehicles (1) can also be projected into a 3D image of the environment to calculate and reproduce a virtual representation from any spectator&quot;s perspective.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
An installation for recording travel and/or traffic situations of vehicles and a method for evaluating these recordings.<br>
The present invention relates to an installation for recording travel and/or traffic situations of vehicles. Furthermore, it relates to a method for evaluating these recordings.<br>
Different installations for recording travel situations of vehicles are known. For example, the speed or the actuation of the brake is detected by sensors and registered in a short-term memory In this manner, at a later stage, one may call up the data in the short period of time before an accident and possibly reconstruct the course of events of the accident. Supplementary to the known sensors, it is likewise known to record in pictures and sound. Apart from the microphone, for this, video cameras are installed on the vehicle which record the events in front of or also behind the vehicle. This entails the advantage that - additionally to the behaviour of ones own vehicle - one records the traffic situation. In particular, in the ideal case, the behaviour and the registration numbers of other vehicles may be recognised.<br>
Despite the number of apparatus to be installed, in the case of conflict however, one may only inadequately reconstruct the course of events of the accident, since the obtained data does not reliably represent the exact course of events and their spatial and temporal allocation with regard to the then traffic situation.<br>
On the basis of this recognition, it is the object of the invention to provide an installation which makes do with few installations on the vehicle, but despite this permits an exact spatial allocation or the events in a three-dimensional space before a traffic accident or during a critic traffic situation. Furthermore, a method for evaluating the recordings created with this installation is to be specified.<br>
In particular, apart from the exact 3D-position of all participating vehicles, their speed and acceleration are recorded in magnitude and direction.<br>
The installation according to the invention corresponds to the characterising features of patent claim 1. The method according to the invention is deduced from claim 11. Further advantageous formations of the inventive concept are evident from the dependent patent claims.<br>
One embodiment example of the invention is hereinafter described in more detail by way of the drawing.<br><br>
Fig. 1   shows a vehicle in a plan view;<br>
Fig. 2  schematically shows the part of the installation which is to be attached on the vehicle and which serves for acquiring the data;<br>
Fig. 3   shows the view of a traffic situation with two vehicles.<br>
A vehicle 1 is equipped according to the Fig. 1 and 2 with two schematically indicated detection cameras 2 and 3 serving for picture recording. Here it is preferably the case of digital cameras, to which in each case a microphone 4 and 5 is allocated. At least one memory is coupled to these detection cameras 2 and 3. In the present case, a non-volatile memory 6 or 7 is present in the manner of a circular buffer. Also each of the two detection cameras 2 and 3 may be provided with a separate memory 6 and 7. The purpose of the circular buffer will be dealt with at a later stage. Furthermore, at least one further, non-volatile memory 8 and 9 are provided, which is coupled to the memory serving as a circular buffer. This further memory may store the same quantity of data or pictures as the first one. The detection cameras 2 and 3 record pictures in rapid succession, for example 25x per second. They are mutually synchronised. Advantageously, a synchronisation at an exact time is effected. This may be effected by way of a radio clock 10. This means that the exact point in time of each picture is secured.<br>
The two detection cameras 2 and 3 are aligned such that the region in front of the vehicle 1 is detected. Here, their detection ranges 11 and 12 overlap in an overlap region 13 which encompasses at least the road 14 in front of the vehicle 1, preferably however also in each case a lane to the left and right of this. The present schematic drawing only serves for explanation. With regard to the present invention, it neither fixes the position nor the alignment of the detection cameras 2 and 3. In the meanwhile, it is advantageous if the mutual distance 15 of the two detection cameras 2 and 3 is selected as large a possible.<br>
The position and alignment of the two detection cameras 2 and 3 on the vehicle, in particular also their distance 15 to one another 15, is to be determined in each case and preferably likewise secured in a memory 16. The knowledge of the position of the detection cameras 2 and 3 to one another and their position on the vehicle itself, with methods of picture processing and photogrammetry, allows one to determine the exact position of one or more reference points. These methods are known per se. In the present case, reference points R which are visible on at least two pictures recorded synchronously by in each case one detection camera 2 and 3, may be exactly triangulated, as is indicated at T, so that their three-dimensional coordinates X, Y and Z may be exactly determined within a coordinate system.<br><br>
It is to be added here, that within the framework of the invention, one may also provide more that two detection cameras 2 and 3. The measurement accuracy may be increased even further in particular by way of the use of a group of three detection cameras. Analogously to the detection cameras acting in the travel direction here, such cameras may also additionally be arranged at the rear. In theory even on both sides of the vehicle.<br>
The practical implementation of the previously described knowledge in a traffic situation with two vehicles 1 and 17 approaching one another is evident from Fig. 3. The detection of the traffic situation by the detection cameras 2 and 3 of the first vehicle 1 is represented. If both vehicles 1 and 17 are equipped with these, this detection is effected additionally on the other vehicle and may be used for correction.<br>
The recognition points 18 and 19 on the second vehicle 17 serving as reference points for the triangulation are preferably arranged specially for the purpose of automatic evaluation. It may be the case of white circles or points. They may also be designed in an illuminating manner, be it as passively illuminating elements, for example reflection marks or also as actively illuminating elements, for example light diodes. The elements may however illuminate in a manner which is invisible to the human eye, for example by way of infrared. The recognition points 18 and 19 should be arranged at an as large as possible distance to one another. It is also conceivable to attach these recognition points 18 and 19 on the corners of a standardised number plate or a number plate frame, possibly in a standardised position. The latter solutions would simplify the fitting and retrofitting of older vehicles.<br>
It is expressly pointed out here that the application of the present installation is not limited to passenger cars. Any vehicle may be equipped with it, even two-wheeled vehicles. Finally, even the assembly on a bicycle is conceivable, since the costs and weight are relatively low. Furthermore, the installation may also be used without further ado on railed vehicles, from trams to trains. Water craft may just as easily provided with it, for example in river traffic. The application in aircraft is also conceivable. Thus for example in tight thermal regions, the risk of collision is also possible with regard to gliders.<br>
Inasmuch as - as is the case with road vehicles - the surface in space on which the vehicle 1 and/or 17 has moved is known, two recognition points 18 and 19 are adequate for spatial reconstruction. In the case that this surface is not known or the vehicles has moved freely in space - for example in the case of an aircraft or water craft - then at least three recognition points 18 and 19 are necessary. With the movement not also a spatial line, for example with rail vehicles - one recognition point 18 or 19 is also sufficient.<br><br>
The use of more than the minimal necessary number of recognition points increases the measurement accuracy. Thus also three recognition points may be provided with road vehicles. These are preferably arranged according to the Delauny criterion, i.e. as close as possible to a equilateral triangle, and at as large as possible distances. In each case, one recognition point may be attached to the headlights or the rear lights. A third recognition point may for example be arranged on the front side of the rear view mirror, or in the region of a third braking light which is often present in the rear window.<br>
The various recognition points may also be coded, be it by way of different shape and/or colour. With actively illuminating recognition points, a coding may be effected by way of different flashing frequencies or -rhythms. This simplifies their automatic recognition and allocation by way of picture processing.<br>
Of course it is however also possible to use elements which are present on the vehicle in any case as recognition points 18 and 19. These may be the headlights or the rear lights, the number plates or also elements of the vehicle design, such as edges and likewise.<br>
If the position of the detection cameras 2 and 3 in the coordinate system 20 of the first vehicle 1 and the position of the recognition points 21 of the second vehicle 17 are known and stored, then - by way of suitable software - the position and movement of the two vehicles 1 and 17 before an accident may be computed and represented.<br>
By way of the three-dimensional, temporally cycled detection, apart from the up-to-date spatial position, the momentary speed, the speed direction, direction changes, acceleration- and braking manoeuvres, as well as intrinsic rotations (spins) of the individual vehicles about their centres of gravity are visible and may be measured in a scaled manner. By way of this, one may particularly recognise how the vehicles were travelling before the accident, when a braking procedure was started, and how long it took before coming to a standstill. And this may all be accomplished without for this, having to have sensors on the steering wheels as well as the brake pedal and gas pedals. Apart from this, the knowledge of events with regard to the vehicle recorded in the picture, such as the lighting condition or indicator actuation and not least on the registration number and driver result due to the picture recording.<br>
The parts of the installation serving for the data memory are to be secured against impacts and against undesired manipulation. A sealed, impact-proof, pressure-proof and fire-resistant container may serve for this. This container may also be provided with a locating possibility which simplifies its location after an accident. This may for example be a transmitter installation, a magnetically passive diode or a flashing device.<br><br>
The evaluation of the data may be effected in an external manner after an accident or after a recorded critical traffic situation. The software required for this may be made available to a traffic expert. The evaluation may be effected automatically, semi-automatically or also manually. The described installation in any case also permits a time-saving automatic evaluation. The behaviour of a third vehicle recognisable from the recordings may be checked thereby.<br>
With the evaluation, one may also take into account the mass and contours of the recorded, participating vehicle types. With this and by way of the previously described detection of the relative movement of the coordinate systems 20 and 21 of two or more vehicles 1 and 17 to one another, and of at least one coordinate system 20 of a vehicle 1 relative to the surroundings, it is possible to reconstruct the relative position and movement of any selected points on the vehicles and/or the surroundings. The software may have a suitable data bank or call up the required data from such a data bank, for taking into account the participating vehicle types. If the vehicle type has not yet been recorded at this point in time, then this may be accomplished at a later stage without further ado. In order to include the surroundings of the accident location, the software should be designed such that the coordinate system 22 of the surroundings may also be included. The picture of the surroundings may either be taken from the present picture recordings, or at least one picture of the surroundings is recorded at a later stage. At least two pictures from different locations and viewing angles are required for the spatial reconstruction. Reference- or recognition points 23, 24 and 25 are also to be allocated to the stationary pictures of the surroundings. Thereby, it may for example be the case of recognition points 23, 24 and 25 on the central line of the road or on a guard railing or around the light points of a street post, which are present in any case. The mutual position of the vehicles 1 and 17 may be brought into relation with the stationary coordinate system 22 of the surroundings by way of this. The course of events of the accident or of the critical traffic situation may be projected into the picture of the surroundings and thus a reliable, virtual picture from the point of view of an external observer may be computed and represented, similar to the schematic representation according to Fig. 3. Thereby however it is not only the case of a static picture, but of a picture sequence, i.e. of a film of the events from a point in time before the accident up to the accident itself. The standing point of the observer may be infinitely changed, similarly to a hologram. The exact position and movement of each individual point may be called up according to requirement. In the case of conflict, this all considerably simplifies the explanation of the question of guilt.<br>
It is clearly understood that a course of events of an accident may also be reconstructed from the recordings, when no second vehicle 17 takes part.<br>
The behaviour of the one vehicle 1 may in any case be computed in relation to reference points R or recognition points 23, 24 and 25 of the surroundings<br><br>
Information on the critical traffic situation, for example near accidents which have possibly have led to consequences for third parties, may be stored in the memories 8 and 9, whilst the constantly overwriting storage in the memories 6 and 7 designed as circular buffer is not stopped. The picture- and sound information may be evaluated when required, amongst other things for determining the registration numbers of the vehicles involved.<br>
The previously mentioned intermediate storage may either be activated electronically or manually by the driver, for example by way of a button on the steering wheel. An electronic activation may be effected by the stoppage of the car 1, which may be detected by way of picture information which remains the same, or also by turning off the ignition or by way of not actuating the gas pedal for a few seconds. However, any other detectable signal may also be conceivable.<br>
Calibrating means may also be present as accessories external to the vehicles, possibly also only as software for already existing installations. A first calibration may serve for the detection and computation of the position of the recognition points 18 and 19 as well as, as the case may be, further points in the coordinate system 21 of a vehicle 17. For this, mostly two stationary detection cameras are required. Furthermore, the position of detection cameras 2 and 3 assembled on a vehicle 1 may be computed in the coordinate system 20 of this vehicle 1 by way of a stationary set of photogrammetric recognition points.<br>
The installation according to the invention for recording travel- and/or traffic situations of vehicles is relatively inexpensive. Digital cameras, as are used for example as web cams, may be obtained today at a low cost. This is also the case for microchips serving as a memory. The evaluation is indeed effected externally and creates no costs on the vehicles. Since, with regard to accidents, it is often the case of high material damage on the vehicles and possibly also expensive subsequent costs for injured persons, reliable proof is of an enormous advantage. It protects the traffic participant who behaves correctly from unjustified writs and compensation claims.<br>
The installations may be designed in a manner differently to that previously described, within the framework of the invention. Amongst other things, a control controlling the sequences may be present.<br>
Patent Claims<br>
An installation for recording travel- and/or traffic situations of vehicles, characterised by an arrangement to be attached to a vehicle (1), of at least two detection cameras (2, 3) lying at a distance (15) to one another, wherein their respective detection regions (11, 12) overlap or intersect in a common overlapping region (13), by which means at least one reference point (R) of the surroundings and/or recognition point (18, 19) at least of a second vehicle (17), recorded by two or more detection cameras (2, 3), may be triangulated (T), with the purpose, from a picture recording, of reconstructing its position and by way of this, the position and/or movement of at least one vehicle (1, 17) after an accident or after a critic traffic situation.<br>
An installation according to claim 1, characterised in that the detection cameras (2, 3) are connected to at least one memory (6, 7, 8, 9), for storing recordings and/or data on their arrangement and/or on the vehicle (1).<br>
An installation according to claim 1 or 2, characterised in that the distance (15) of the detection cameras (2, 3) amongst one another and/or their arrangement in a coordinate system (20) of a vehicle (1) is calibrated.<br>
An installation according to claim 3, characterised in that the distance (15) of the detection cameras (2, 3) amongst one another and/or their arrangement in a coordinate system (20) of a vehicles (1) is secured in a memory<br>
An installation according to one of the claims 1 - 4, characterised in that the detection cameras (2, 3) are connected to a time control (2, 3), in a manner such that their picture recording may be effected synchronised with respect to time.<br>
An installation according to one of the claims 1 - 5, characterised in that the detection cameras (2, 3) are in each case designed for recording a picture sequence, for example 25 pictures per second.<br>
An installation according to one of the claims 1 - 6, characterised in that the detection cameras (2, 3) are connected to a time measurement device, e.g. to a radio clock, with the purpose of being able to determine the absolute time of the respective picture recording.<br>
An installation according to one of the claims 1-7, characterised in that at least one sound recording device, e.g. a microphone (4, 5) is present.<br><br>
An installation according to one of the claims 2- 8, characterised by a sensor, e.g. an acceleration sensor, for the automatic activation or for securing a data storage.<br>
An installation according to one of the claims 2-9, characterised by an activation device, e.g. a button on the steering wheel, for the manual activation or for securing the data storage.<br>
. An installation according to one of the claims 2-10, characterised by at least one nonvolatile memory (6, 7) in the manner of a circular buffer and by way of at least one further, non-volatile memory (8, 9) which is coupled to the memory (6,7) serving as a circular buffer.<br>
, An installation according to one of the claims 1-11, characterised by recognition points (18, 19, 23, 24, 25) detectable by detection cameras (2, 3), which are to be arranged on a vehicle (17) and/or in the region of traffic routes.<br>
, An installation according to claim 12, characterised in that the recognition points (18, 19, 23, 24,25) are coded in shape and colour, e.g. in a manner such that each has its own shape in an arrangement of two or more recognition points (18, 19, 23, 24, 25).<br>
, An installation according to claim 12 or 13, characterised in that the recognition points (118, 19, 23, 24, 25) are designed illuminating in a passive manner, e.g. reflecting.<br>
. An installation according to claim 12 or 13, characterised in that the recognition points (18, 19, 23, 24, 25) are designed illuminating in an active manner, e.g. in the form of light diodes.<br>
. A method for evaluating recordings of travel and/or traffic situations created with the installation according to claim 1, characterised in that at least one reference point (R) and/or recognition point (18, 19, 23, 24, 25) recorded by two or more detection cameras (2, 3), is triangulated (T) with the purpose of reconstructing its position and by way of this, the position and/or movement of at least one vehicle (1, 17) after an accident or after a critic traffic situation.<br>
. A method according to claim 16, characterised in that the triangulation (R) is effected by picture processing and/or photogrammetry.<br>
. A method according to claim 16 or 17, characterised in that the computation of the position of the reference point or reference points (T) and/or recognition points (18, 19, 23,24,25) in the picture sequence of a picture recording is effected automatically in an apparatus programmable with suitable computation formulae, e.g. in a P.C.<br><br>
A method according to claim 18, characterised in that the movements of at least one vehicle (1, 17) are computed from the position change of the reference point or reference points (T) or recognition points (18, 19, 23, 24, 25) in the picture sequence of a picture recording, e.g. the travel direction and any direction changes as well as speed and any speed changes, i.e. an acceleration or a braking procedure.<br>
A method according to one of the claims 16-19, characterised in that in the computation of the position and/or movement of a vehicle (1,17), the position of the detection cameras (2,3) on a coordinate system (20) of this vehicle (1), and/or the position of recognition points (18, 19) on a coordinate system (21) at least of a second vehicle (17) are taken into account, wherein this data may be stored in a memory of the part of the installation arranged in the vehicle.<br>
A method according to one of the claims 16-20, characterised in that a coordinate system (22) of the surroundings (22) flows into the computation of the position and/or movement of a vehicle (1, 17), wherein the picture of the surroundings may either be taken from the present picture recordings of the detection cameras (2, 3), or the surroundings may be recorded at a later stage.<br>
A method according to claim 21, characterised in that reference points (R) or recognition points (23, 24) are allocated to the pictures of the surroundings, wherein it may be the case of points which are present in the surroundings in any case, e.g. on the central line of a road, on a crash barrier, or of reflecting points on a street post.<br>
A method according to one of the claims 16 to 22, characterised in that the respective vehicle type is taken into account in the computation of the position and/or movement of a vehicle (1, 17), for which the data of this vehicle type e.g. may be inputted in a manual manner, or one may fall back on a data bank containing the data of a multitude of vehicle types.<br>
A method according to one of the claims 21 - 23, characterised in that the position and the movement of one or more vehicles (1, 17) is projected into the picture of the surroundings and thus a virtual representation of the course of events of an accident or a critical traffic situation is computed and represented.<br><br>
Patent Claims of 24 March 2005 amended according to Art. 19 PCT<br>
. A method for evaluating travel and/or traffic situations with at least two detection cameras (2, 3) arranged at a distance to one another on a vehicle (1), whose respective detection regions (11, 12) overlap in a common overlapping region (13), characterised in that with the detection cameras and in a temporally synchronised and spatially calibrated manner, at least one artificially attached or naturally present reference point of the surroundings (23, 24, 25) and/or of at least one second vehicle (18, 19) is triangulated, i.e. is detected in its spatial position, and afterwards the temporal and spatial location and position (20) of the equipped vehicle (1) and/or the location and position (21) of at least one further vehicle (17) relative to one another and/or relative to the location and position of the stationary surroundings (22) is completely or partly determined.<br>
, A method according to claim 1, characterised in that an object, e.g. from a CAD data bank is linked to the spatial location and position of the detection cameras (2, 3) and/or to at least one artificially or naturally marked reference point (18, 19), whereupon the position and/or movement of at least one of these objects (1,17) is reconstructed from the picture recording.<br>
, A method according to one of the preceding claims, characterised in that the triangulation (T) is effected by picture processing and/or photogrammetry, wherein in the two-dimensional picture pair sequence of a picture recording, the computation of the position and allocation of the image pair of one or more three-dimensional reference points (18, 19, 23, 24, 25) and their subsequent transformation into the three-dimensional space is effected semi-automatically or automatically in a computer programmable with suitable computation formulae, wherein the movements at least of the equipped vehicle (1) relative to the surroundings and/or to at least one further vehicle (17) are computed, specifically the position, the travel direction and any direction changes, as well as the speed and any speed changes, i.e. an acceleration and/or a braking procedure, as well as the angular speed and any angular speed changes and thus a virtual representation of the course of events of an accident and/or of a critical traffic situation from any observers perspective may be computed and represented.<br><br>
A method according to one of the preceding claims, characterised in that when required, with subsequently recorded pictures of the surroundings or their part regions which are of relevance to the accident, a virtual, three-dimensional model of the surroundings or their part regions is applied into the present, stationary surroundings coordinate system (22), by which means this virtual, three-dimensional surroundings model is superimposed on the spatial and temporal location and position of one or more vehicles (1, 17) relative to the coordinate system (22) in a scaled manner.<br>
An installation for recording travel and/or traffic situations of vehicles according to one or more of the method claims 1 to 4, consisting of two detection cameras (2, 3) arranged at a distance (15) to one another, whose respective detection regions (11, 12) overlap in a common overlapping region (13), characterised in that the detection cameras (2, 3) in their spatial location and position in the vehicle coordinate system are photogrammetrically calibrated-in and are temporally synchronised, wherein their individual calibration data is stored on an associated memory chip, by which means at least one reference point of the surroundings (23, 24, 25) and/or of at least one second vehicle (18, 19), which is recorded by these detection cameras (2, 3) and is artificially attached or naturally present, may be triangulated, by which means the temporal and spatial three-dimensional position of these artificially or naturally marked reference points may be determined and they may be selectively linked to objects, e.g. from a CAD vehicle data bank, so that the location and position and/or movement of the coordinate system (20) of this vehicle (1) relative to a stationary surroundings coordinate system (20) and/or relative to at least one further coordinate system (21) of the vehicle (17) may be reconstructed from a serial picture recording.<br>
An installation according to claim 5, characterised in that it comprises at least one memory (6, 7) coupled to the detection cameras (2, 3) for the serial storage of a picture sequence, for example in the form of a circular buffer, and at least one further, non-volatile memory (8, 9) for storing the photogrammetric calibration data and/or the of the spatial camera arrangement in the coordinate system (20) of the equipped vehicle (1).<br>
An installation according to one of the claims 5 to 6, characterised in that the detection cameras (2, 3) are connected to a time measurement device, e.g. to radio clock, with the purpose of rendering the absolute time of the respective picture recording determinable.<br>
An installation according to one of the claims 5 to 7, characterised in that at least one sound recording device, e.g. a microphone (4, 5) is present, for the picture-synchronous recording of noises.<br><br>
An installation according to one of the claims 5 to 8, characterised in that it includes a sensor for the automatic activation or securing of a data storage, or an activation device, e.g. a button on the steering wheel, for the manual activation or for securing data storage.<br>
An installation according to one of the claims 5 to 9, characterised in that for supporting the method, artificially attached reference points (18,19, 23,24, 25) are arranged on a vehicle (1, 17) and/or in the region of traffic routes, wherein these artificial reference points (18, 19, 23, 24, 25) for the purpose of an improved automatic recognition are coded in shape and/or colour and/or are designed illuminating in a passive or active manner.<br>
Dated this 10 day of May 2006 <br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2ICAgIENPUlJFU1BPTkRFTkNFIE9USEVSUyAgIDI3LTA0LTIwMTEucGRm" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006    CORRESPONDENCE OTHERS   27-04-2011.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2ICBBTUVOREVEIENMQUlNUyAgMDItMDQtMjAxMi5wZGY=" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006  AMENDED CLAIMS  02-04-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2ICBBTUVOREVEIFBBR0VTIE9GIFNQRUNJRklDQVRJT04gIDAyLTA0LTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006  AMENDED PAGES OF SPECIFICATION  02-04-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2ICBFWEFNSU5BVElPTiBSRVBPUlQgUkVQTFkgUkVDRUlWRUQgIDAyLTA0LTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006  EXAMINATION REPORT REPLY RECEIVED  02-04-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2ICBGT1JNLTMgIDAyLTA0LTIwMTIucGRm" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006  FORM-3  02-04-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2ICBQT1dFUiBPRiBBVFRPUk5FWSAgMDItMDQtMjAxMi5wZGY=" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006  POWER OF ATTORNEY  02-04-2012.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2IENPUlJFU1BPTkRFTkNFIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006 CORRESPONDENCE OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2IENPUlJFU1BPTkRFTkNFIFBPLnBkZg==" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006 CORRESPONDENCE PO.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1DSEVOUC0yMDA2IEZPUk0gMTgucGRm" target="_blank" style="word-wrap:break-word;">1617-CHENP-2006 FORM 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWNvcnJlc3BvbmRuZWNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-correspondnece-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWRlc2NyaXB0aW9uKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MTYxNy1jaGVucC0yMDA2LXBjdC5wZGY=" target="_blank" style="word-wrap:break-word;">1617-chenp-2006-pct.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="252014-reclosable-consumable-product-package-assembly.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="252016-pressure-compensating-drip-irrigation-hose-for-distributing-water.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>252015</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1617/CHENP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>17/2012</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>27-Apr-2012</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>23-Apr-2012</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>10-May-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>TECHNIKUS AG</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>AEULESTRASSE 5, FL-9490 VADUZ, LIECHTENSTEIN</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>SOURLIER, David</td>
											<td>Gawis 1303, CH-9633 Hemberg</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G07C5/08</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/CH2004/000676</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2004-11-08</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>1936/03</td>
									<td>2003-11-11</td>
								    <td>Switzerland</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/252015-device-for-recording-driving-and-or-traffic-conditions-and-method-for-evaluating-said-recorded-data by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 13:36:09 GMT -->
</html>
