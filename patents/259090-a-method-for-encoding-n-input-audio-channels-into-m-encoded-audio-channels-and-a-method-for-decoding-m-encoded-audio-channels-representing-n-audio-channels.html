<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/259090-a-method-for-encoding-n-input-audio-channels-into-m-encoded-audio-channels-and-a-method-for-decoding-m-encoded-audio-channels-representing-n-audio-channels by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:20:06 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 259090:A METHOD FOR ENCODING N INPUT AUDIO CHANNELS INTO M ENCODED AUDIO CHANNELS AND A METHOD FOR DECODING M ENCODED AUDIO CHANNELS REPRESENTING N AUDIO CHANNELS</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">A METHOD FOR ENCODING N INPUT AUDIO CHANNELS INTO M ENCODED AUDIO CHANNELS AND A METHOD FOR DECODING M ENCODED AUDIO CHANNELS REPRESENTING N AUDIO CHANNELS</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Multiple channels of audio are combined either to a monophonic composite signal (Figure 1, reference 6) or to multiple channels of audio (Figure 6, reference 6&#x27;) along with related auxiliary information from which multiple channels of audio are reconstructed (figures 2, 7, 8, 9), including improved downmixing of multiple audio channels to a monophonic audio signal (Figure 1, reference 6) or to multiple audio channels (Figure 6, reference 6&#x27;) and improved decorrelation (Figures 2 and 7, references 38 and 42, Figure 8, references 46 and 48, and Figure 9, references 50 and 52) of multiple audio channels derived from a monophonic audio channel or from multiple audio channels. Aspects of the disclosed invention are usable in audio encoders (figures 1 and 6), decoders figures 2, 7, 8, and 9), encode/decode systems downmixers (figure 1, reference 6, figure 6, reference 6&#x27;), upmixers (figure 7, 8 and 9, reference 20), and decorelators (Figures 2 and 7, references 38 and 42, Figure 8, references 46 and 48, and Figure 9, references 50 and 52).</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
â– <br>
Technical Field<br>
The invention relates generally to audio signal processing. The invention is<br>
particularly useful in low bitrate and very low bitrate audio signal processing. More<br>
particularly, aspects of the invention relate to an encoder (or encoding process), a decoder<br>
(or decoding processes), and to an encode/decode system (or encoding/decoding process)<br>
for audio signals in which a plurality of audio channels is represented by a composite<br>
monophonic ("mono") audio channel and auxiliary ("sidechain") information.<br>
Alternatively, the plurality of audio channels is represented by a plurality of audio<br>
channels and sidechain information. Aspects of the invention also relate to a<br>
multichannel to composite monophonic channel downmixer (or downmix process), to a<br>
monophonic channel to multichannel upmixer (or upmixer process), and to a monophonic<br>
channel to multichannel decorrelator (or decorrelation process). Other aspects of the <br>
invention relate to a multichannel-to-multichannel downmixer (or downmix process), to a!<br>
multichannei-to-multichannel upmixer (or upmix process), and to a decorrelator (or<br>
decorrelation process.<br>
Background Art<br>
In the AC-3 digital audio encoding and decoding system, channels may be<br>
selectively combined or "coupled" at high frequencies when the system becomes starved<br>
for bits. Details of the AC-3 system are well known in the art - see, for example: ATSC<br>
Standard A52/A: Digital Audio Compression Standard (AC-3), Revision A, Advanced<br>
Television Systems Committee, 20 Aug. 2001.<br>
The frequency above which the AC-3 system combines channels on demand is<br>
referred to as the "coupling" frequency. Above the coupling frequency, the coupled<br>
channels are combined into a "coupling" or composite channel. The encoder generates<br>
"coupling coordinates"'(amplitude scale factors) for each subband above the coupling<br>
frequency in each channel. The coupling coordinates indicate the ratio of the original<br>
energy of each coupled channel subband to the energy of the corresponding subband in<br>
the composite channel. Below the coupling frequency, channels are encoded discretely.<br>
The phase polarity of a coupled channel's subband may be reversed before the channel is<br>
combined with one or more other coupled channels in order to reduce out-of-phase signal<br><br>
component cancellation. The composite channel along with sidechain information that<br>
includes, on a per-subband basis, the coupling coordinates and whether the channel's<br>
phase is inverted, are sent to the decoder. In practice, the coupling frequencies employed<br>
in commercial embodiments of the AC-3 system have ranged from about 10 kHz to about<br>
3500 Hz. U.S. Patents 5,583,962; 5,633,981, 5,727,119,5,-909,664, and 6,021,386<br>
include teachings that relate to the combining of multiple audio channels into a composite<br>
channel and auxiliary or sidechain information and the recovery therefrom of an<br>
approximation to the original multiple channels.<br>
Prior art methods of parametric encoding and decoding of at least two-channel audio signals<br>
are known from WO 03/069954 and WO 03 / 090208. Prior art methods of generating output<br>
signals having specified cross-correlation relationships from an input signal are know from<br>
US 5234546 and WO 91/20164.<br>
Disclosure of the Invention<br>
Aspects of the present invention may be viewed as improvements upon the<br>
"coupling" techniques of the AC-3 encoding and decoding system and also upon other<br>
techniques in which multiple channels of audio are combined either to a monophonic<br>
composite signal or to multiple channels of audio along with related auxiliary information<br>
and from which multiple channels of audio are reconstructed. Aspects of the present<br>
invention also may be viewed as improvements upon techniques for downmixing multiple<br>
audio channels to a monophonic audio signal or to multiple audio channels and for<br>
decorrelating multiple audio channels derived from a monophonic audio channel or from<br>
multiple audio channels.<br>
 Aspects of the invention may be employed in an N: 1 :N spatial audio coding<br><br>
technique (where 'N" is the number of audio channels) or an M: 1 :N spatial audio coding<br>
technique (where "M" is the number of encoded audio channels and "N" is the number of<br>
decoded audio channels) that improve on charm el coupling, by providing, among other<br>
things, improved phase compensation, decorrelation mechanisms, and signal-dependent<br>
variable time-constants. Aspects of the present invention may also be employed in N:x:N<br>
and M:x:N spatial audio coding techniques wherein "x" may be 1 or greater than 1.<br>
Goals include the reduction of coupling cancellation artifacts in the encode process by<br>
adjusting relative interchannel phase before downmixing, and improving the spatial<br><br>
dimensionality of the reproduced signal by restoring the phase angles and degrees of<br>
decorrelation in the decoder. Aspects of the invention when embodied in practical<br>
embodiments should allow for continuous rather than on-demand channel coupling and<br>
lower coupling frequencies than, for example in the AC-3 system, thereby reducing the<br>
required data rate.<br>
Description of the Accompanying Drawings<br>
FIG. 1 is an idealized block diagram showing the principal functions or devices of<br>
an N:l encoding arrangement embodying aspects of the present invention.<br>
FIG. 2 is an idealized block diagram showing the principal functions or devices of<br>
a 1:N decoding arrangement embodying aspects of the present invention.<br>
FIG. 3 shows an example of a simplified conceptual organization of bins and<br>
subbands along a (vertical) frequency axis and blocks and a frame along a (horizontal)<br>
time axis. The figure is not to scale.<br>
FIG. 4 is in the nature of a hybrid flowchart and functional block diagram<br>
showing encoding steps or devices performing functions of an encoding arrangement<br>
embodying aspects of the present invention.<br>
FIG. 5 is in the nature of a hybrid flowchart and functional block diagram<br>
showing decoding steps or devices performing functions of a decoding arrangement<br>
embodying aspects of the present invention.<br>
FIG. 6 is an idealized block diagram showing the principal functions or devices of<br>
a first N:x encoding arrangement embodying aspects of the present invention.<br>
FIG. 7 is an idealized block diagram showing the principal functions or devices of<br>
an x:M decoding arrangement embodying aspects of the present invention.<br>
FIG. 8 is an idealized block diagram showing the principal functions or devices of<br>
a first alternative x:M decoding arrangement embodying aspects of the present invention.<br>
FIG. 9 is an idealized block diagram showing the principal functions or devices of<br>
a second alternative x:M decoding arrangement embodying aspects of the present<br>
invention.<br>
Best Mode for Carrying Out the Invention<br>
Basic N:l Encoder<br>
Referring to FIG. 1, an N:1 encoder function or device embodying aspects of the<br>
present invention is shown. The figure is an example of a function or structure that<br><br>
performs as a basic encoder embodying aspects of the invention. Other functional or<br>
structural arrangements that practice aspects of the invention may be employed, including<br>
alternative and/or equivalent functional or structural arrangements described below.<br>
Two or more audio input channels are applied to the encoder. Although, in<br>
principle, aspects of the invention may be practiced by analog, digital or hybrid<br>
analog/digital embodiments, examples disclosed herein are digital embodiments. Thus,<br>
the input signals may be time samples that may have been derived from analog audio<br>
signals. The time samples may be encoded as linear pulse-code modulation (PCM)<br>
signals. Each linear PCM audio input channel is processed by a filterbank function or<br>
device having both an in-phase and a quadrature output, such as a 512-point windowed<br>
forward discrete Fourier transform (DFT) (as implemented by a Fast Fourier Transform<br>
(FFT)). The filterbank may be considered to be a time-domain to frequency-domain transform.<br>
FIG. 1 shows a first PCM channel input (channel "1") applied to a filterbank<br>
function or device, "Filterbank" 2, and a second PCM channel input (channel "n")<br>
applied, respectively, to another filterbank function or device, "Filterbank" 4. There may<br>
be "n" input channels, where "n" is a whole positive integer equal to two or more. Thus,<br>
there also are "n" Filterbanks, each receiving a unique one of the "n" input channels. For<br>
simplicity in presentation, FIG. 1 shows only two input channels, "1" and "n".<br>
When a Filterbank is implemented by an FFT, input time-domain signals are<br>
segmented into consecutive blocks and are usually processed in overlapping blocks. The<br>
FFT's discrete frequency outputs (transform coefficients) are referred to as bins, each<br>
having a complex value with real and imaginary parts corresponding, respectively, to in-<br>
phase and quadrature components. Contiguous transform bins may be grouped into<br>
subbands approximating critical bandwidths of the human ear, and most sidechain<br>
information produced by the encoder, as will be described, may be calculated and<br>
transmitted on a per-subband basis in order to minimize processing resources and to<br>
reduce the bitrate. Multiple successive time-domain blocks may be grouped into frames,<br>
with individual block values averaged or otherwise combined or accumulated across each<br>
frame, to minimize the sidechain data rate. In examples described herein, each filterbank<br>
is implemented by an FFT, contiguous transform bins are grouped into subbands, blocks<br>
are grouped into frames and sidechain data is sent on a once per-frame basis.<br><br>
Alternatively, sidechain data may be sent on a more than once per frame basis (e.g., once<br>
per block). See, for example, FIG. 3 and its description, hereinafter. As is well known,<br>
there is a tradeoff between the frequency at which sidechain information is sent and the<br>
required bitrate.<br>
A suitable practical implementation of aspects of the present invention may<br>
employ fixed length frames of about 32 milliseconds when a 48 kHz sampling rate is<br>
employed, each frame having six blocks at intervals of about 5.3 milliseconds each<br>
(employing, for example, blocks having a duration of about 10.6 milliseconds with a 50%<br>
overlap). However, neither such timings nor the employment of fixed length frames nor<br>
their division into a fixed number of blocks is critical to practicing aspects of the<br>
invention provided that information described herein as being sent on a per-frame basis is<br>
sent no less frequently than about every 40 milliseconds. Frames may be of arbitrary size<br>
and their size may vary dynamically. Variable block lengths may be employed as in the<br>
AC-3 system cited above. It is with that understanding that reference is made herein to<br>
"frames" and "blocks."<br>
In practice, if the composite mono or multichannel signal(s), or the composite<br>
mono or multichannel signal(s) and discrete low-frequency channels, are encoded, as for<br>
example by a perceptual coder, as described below, it is convenient to employ the same '<br>
frame and block configuration as employed in the perceptual coder. Moreover, if the<br>
coder employs variable block lengths such that there is, from time to time, a switching<br>
from one block length to another, it would be desirable if one or more of the sidechain<br>
information as described herein is updated when such a block switch occurs. In order to<br>
minimize the increase in data overhead upon the updating of sidechain information upon<br>
the occurrence of such a switch, the frequency resolution of the updated sidechain<br>
information may be reduced.<br>
FIG. 3 shows an example of a simplified conceptual organization of bins and<br>
subbands along a (vertical) frequency axis and blocks and a frame along a (horizontal)<br>
time axis. When bins are divided into subbands that approximate critical bands, the<br>
lowest frequency subbands have the fewest bins (e.g., one) and the number of bins per<br>
subband increase with increasing frequency.<br>
'Returning to FIG. 1, a frequency-domain version of each of the n time-domain<br>
input channels, produced by the each channel's respective Filterbank (Filterbanks 2 and 4<br><br>
in this example) are summed together ("downmixed") to a monophonic ("mono")<br>
composite audio signal by an additive combining function or device "Additive Combiner"<br>
6.<br>
The downmixing may be applied to the entire frequency bandwidth of the input<br>
audio signals or, optionally, it may be limited to frequencies above a given "coupling"<br>
frequency, inasmuch as artifacts of the downmixing process may become more audible at<br>
middle to low frequencies. In such cases, the channels may be conveyed discretely below<br>
the coupling frequency. This strategy may be desirable even if processing artifacts are<br>
not an issue, in that mid/low frequency subbands constructed by grouping transform bins<br>
into critical-band-like subbands (size roughly proportional to frequency) tend to have a<br>
small number of transform bins at low frequencies (one bin at very low frequencies) and<br>
may be directly coded with as few or fewer bits than is required to send a downmixed<br>
mono audio signal with sidechain information. A coupling or transition frequency as low<br>
as 4 kHz, 2300 Hz, 1000 Hz, or even the bottom of the frequency band of the audio<br>
signals applied to the encoder, may be acceptable for some applications; particularly those<br>
in which a very low bitrate is important. Other frequencies may provide a useful balance<br>
between bit savings and listener acceptance. The choice of a particular coupling<br>
frequency is not critical to the invention. The coupling frequency may be variable and, if<br>
variable, it may depend, for example, directly or indirectly on input signal characteristics.<br>
Before downmixing, it is an aspect of the present invention to improve the<br>
channels' phase angle alignments vis-a-vis each other, in order to reduce the cancellation<br>
of out-of-phase signal components when the channels are combined and to provide an<br>
improved mono composite channel. This may be accomplished by controllably shifting<br>
over time the "absolute angle" of some or all of the transform bins in ones of the<br>
channels. For example, all of the transform bins representing audio above a coupling<br>
frequency, thus defining a frequency band of interest, may be controllably shifted over<br>
time, as necessary, in every channel or, when one channel is used as a reference, in all but<br>
. the reference channel. ...	.......<br>
The "absolute angle" of a bin may be taken as the angle of the magnitude-and-<br>
angle representation of each complex valued transform bin produced by a filterbank.<br>
Controllable shifting of the absolute angles of bins in a channel is performed by an angle<br>
rotation function or device ("Rotate Angle"). Rotate Angle 8 processes the output of<br><br>
Filterbank 2 prior to its application to the downmix summation provided by Additive<br>
Combiner 6, while Rotate Angle 10 processes the output of Filterbank 4 prior to its<br>
application to the Additive Combiner 6. It will be appreciated that, under some signal<br>
conditions, no angle rotation may be required for a particular transform bin over a time<br>
period (the time period of a frame, in examples described herein). Below the coupling<br>
frequency, the channel information may be encoded discretely (not shown in FIG. 1).<br>
In principle, an improvement in the channels' phase angle alignments with respect<br>
to each other may be accomplished by shifting the phase of every transform bin or<br>
subband by the negative of its absolute phase angle, in each block throughout the<br>
frequency band of interest. Although this substantially avoids cancellation of out-of-<br>
phase signal components, it tends to cause artifacts that may be audible, particularly if the<br>
resulting mono composite signal is listened to in isolation. Thus, it is desirable to employ<br>
the principle of'least treatment" by shifting the absolute angles of bins in a channel only<br>
as much as necessary to minimize out-of-phase cancellation in the downmix process and<br>
minimize spatial image collapse of the multichannel signals reconstituted by the decoder.<br>
Techniques for determining such angle shifts are described below. Such techniques<br>
include time and frequency smoothing and the manner in which the signal processing<br>
responds to the presence of a transient.<br>
Energy normalization may also be performed on a per-bin basis in the encoder to<br>
reduce further any remaining out-of-phase cancellation of isolated bins, as described<br>
further below. Also as described further below, energy normalization may also be<br>
performed on a per-subband basis (in the decoder) to assure that the energy of the mono<br>
composite signal equals the sums of the energies of the contributing channels.<br>
Each input channel has an audio analyzer function or device ("Audio Analyzer")<br>
associated with it for generating the sidechain information for Ihat channel and for<br>
controlling the amount or degree of angle rotation applied to the channel before it is<br>
applied to the downmix summation 6. The Filterbank outputs of channels 1 and n are ,<br>
applied to Audio Analyzer 12 and to Audio Analyzer 14, respectively. Audio Analyzer<br>
12 generates the sidechain information for channel 1 and the amount of phase angle<br>
rotation for channel 1. Audio Analyzer 14 generates the sidechain information for<br>
channel n and the amount of angle rotation for channel n. It will be understood that such<br>
references herein to "angle" refer to phase angle.<br><br>
The sidechain information for each channel generated by an audio analyzer for<br>
each channel may include:<br>
an Amplitude Scale Factor ("Amplitude SF"),<br>
an Angle Control Parameter,<br>
a Decorrelation Scale Factor ('TDecorrelation SF"),<br>
a Transient Flag, and<br>
optionally, an Interpolation Flag.<br>
Such sidechain information may be characterized as "spatial parameters," indicative of<br>
spatial properties of the channels and/or indicative of signal characteristics that may be<br>
relevant to spatial processing, such as transients. In each case, the sidechain information<br>
applies to a single subband (except for the Transient Flag and the Interpolation Flag, each<br>
of which apply to all subbands within a channel) and may be updated once per frame, as<br>
in the examples described below, or upon the occurrence of a block switch in a related<br>
coder. Further details of the various spatial parameters are set forth below. The angle<br>
rotation for a particular channel in the encoder may be taken as the polarity-reversed<br>
Angle Control Parameter that forms part of the sidechain information.<br>
If a reference channel is employed, that channel may not require an Audio<br>
Analyzer or, alternatively, may require an Audio Analyzer that generates only Amplitude<br>
Scale Factor sidechain information. It is not necessary to send an Amplitude Scale Factor<br>
if that scale factor can be deduced with sufficient accuracy by a decoder from the<br>
Amplitude Scale Factors of the other, non-reference, channels. It is possible to deduce in<br>
the decoder the approximate value of the reference channel's Amplitude Scale Factor if<br>
the energy normalization in the encoder assures that the scale factors across channels<br>
within any subband substantially sum square to 1, as described below. The deduced<br>
approximate reference channel Amplitude Scale Factor value may have errors as a result<br>
of the relatively coarse quantization of amplitude scale factors resulting in image shifts in<br>
the reproduced multi-channel audio. However, in a low data rate environment, such<br>
artifacts may be more acceptable than using the bits to send the reference channel's<br>
Amplitude Scale Factor. Nevertheless, in some cases it may be desirable to employ an<br>
audio analyzer for the reference channel that generates, at least, Amplitude Scale Factor<br>
sidechain information.<br><br>
FIG. 1 shows in a dashed line an optional input to each audio analyzer from the<br>
PCM time domain input to the audio analyzer in the channel. This input may he used by<br>
the Audio Analyzer to detect a transient over a time period (the period of a block or<br>
frame, in the examples described herein) and to generate a transient indicator (e.g., a one-<br>
bit "Transient Flag") in response to a transient. Alternatively, as described below in the<br>
comments to Step 408 of FIG. 4, a transient may be detected in the frequency domain, in<br>
which case the Audio Analyzer need not receive a time-domain input.<br>
The mono composite audio signal and the sidechain information for all the<br>
channels (or all the channels except the reference channel) may be stored, transmitted, or<br>
stored and transmitted to a decoding process or device ("Decoder"). Preliminary to the<br>
storage, transmission, or storage and transmission, the various audio signals and various<br>
sidechain information may be multiplexed and packed into one or more bitstreams<br>
suitable for the storage, transmission or storage and transmission medium or media. The<br>
mono composite audio may be applied to a data-rate reducing encoding process or device<br>
such as, for example, a perceptual encoder or to a perceptual encoder and an entropy<br>
coder (e.g., arithmetic or Huffman coder) (sometimes referred to as a "lossless" coder)<br>
prior to storage, transmission, or storage and transmission. Also, as mentioned above, the<br>
mono composite audio and related sidechain information may be derived from multiple<br>
input channels only for audio frequencies above a certain frequency (a "coupling"<br>
frequency). In that case, the audio frequencies below the coupling frequency in each of<br>
the multiple input channels may be stored, transmitted or stored and transmitted as<br>
discrete channels or may be combined or processed in some manner other than as<br>
described herein'. Such discrete or otherwise-combined channels may also be applied to a<br>
data reducing encoding process or device such as, for example, a perceptual encoder or a<br>
perceptual encoder and an entropy encoder. The mono composite audio and the discrete<br>
multichannel audio may all be applied to an integrated perceptual encoding or perceptual<br>
and entropy encoding process or device.<br>
- -ThepaMcMarmarmermwHchsidechammformationiscam<br>
bitstream is not critical to the invention. If desired, the sidechain information may be<br>
carried in such as way that the bitstream is compatible with legacy decoders (i.e., the<br>
bitstream is baclcwards-compatible). Many suitable techniques for doing so are known.<br>
For example, many encoders generate a bitstream having unused or null bits that are<br><br>
ignored by the decoder. An example of such an arrangement is set forth in United States<br>
Patent 6,807,528 Bl of Truman et al, entitled "Adding Data to a Compressed Data<br>
Frame," October 19,2004.	â€¢<br>
Such bits may be replaced with the sidechain information. Another example is<br>
that the sidechain information may be steganographically encoded in the encoder's<br>
bitstream. Alternatively, the sidechain information may be stored or transmitted<br>
separately from the backwards-compatible bitstream by any technique that permits the<br>
transmission or storage of such information along with a mono/stereo bitstream<br>
compatible with legacy decoders.<br>
Basic 1:N and 1 :M Decoder<br>
Referring to FIG. 2, a decoder function or device ("Decoder") embodying aspects<br>
of the present invention is shown. The figure is an example of a function or structure that<br>
performs as a basic decoder embodying aspects of the invention. Other functional or<br>
structural arrangements that practice aspects of the invention may be employed, including<br>
alternative and/or equivalent functional or structural arrangements described below.<br>
The Decoder receives the mono composite audio signal and the sidechain<br>
information for all the channels or all the channels except the reference channel. If<br>
necessary, the composite audio signal and related sidechain information is demultiplexed,<br>
unpacked and/or decoded. Decoding may employ a table lookup. The goal is to derive<br>
from the mono composite audio channels a plurality of individual audio channels<br>
approximating respective ones of the audio channels applied to the Encoder of FIG. 1,<br>
subject to bitrate-reducing techniques of the present invention that are described herein.<br>
Of course, one may choose not to recover all of the channels applied to the<br>
encoder or to use only the monophonic composite signal. Alternatively, channels in<br>
addition to the ones applied to the Encoder may be derived from the output of a Decoder<br>
according to aspects of the present invention by employing aspects of the inventions<br>
described in International Application PCT/US 02/03619, filed February 7,2002,<br>
published August 15,2002, designating the United. States, and its resulting U.S.national<br>
application S.N. 10/467,213, filed August 5,2003, and in International Application<br>
PCT/US03/24570, filed August 6,2003, published March 4,2001 as WO 2004/019656,<br>
designating the United States, and its resulting U.S. national application S.N. 10/522,515,<br>
filed January 27,2005.<br><br>
Channels recovered by a Decoder practicing aspects of the present invention are<br>
particularly useful in connection with the channel multiplication techniques of the cited<br>
and incorporated applications in that the recovered channels not only have useful<br>
interchannel amplitude relationships but also have useful interchannel phase relationships.<br>
Another alternative for channel multiplication is to employ a matrix decoder to derive<br>
additional channels. The interchannel amplitude- and phase-preservation aspects of the<br>
present invention make the output channels of a decoder embodying aspects of the<br>
present invention particularly suitable for application to an amplitude- and phase-sensitive<br>
matrix decoder. Many such matrix decoders employ wideband control circuits that<br>
operate properly only when the signals applied to them are stereo throughout the signals'<br>
bandwidth. Thus, if the aspects of the present invention are embodied in an N:1:N system<br>
in which N is 2, the two channels recovered by the decoder may be applied to a 2:M<br>
active matrix decoder. Such channels may have been discrete channels below a coupling<br>
frequency, as mentioned above. Many suitable active matrix decoders are well known in<br>
the art, including, for example, matrix decoders known as "Pro Logic" and 'Tro Logic II"<br>
decoders ("Pro Logic" is a trademark of Dolby Laboratories Licensing Corporation).<br>
Aspects of Pro Logic decoders are disclosed in U.S. Patents 4,799,260 and 4,941,177.<br>
Aspects of Pro Logic II<br>
decoders are disclosed in pending U.S. Patent Application S.N. 09/532,711 of Fosgate,<br>
entitled "Method for Deriving at Least Three Audio Signals from Two Input Audio<br>
Signals,?' filed March 22,2000 and published as WO 01/41504 on June 7,2001, and in<br>
pending U.S. Patent Application S.N. 10/362,786 of Fosgate et al, entitled "Method for<br>
Apparatus for Audio Matrix Decoding," filed February 25,2003 and published as US<br>
2004/0125960 Al on July 1,2004.<br>
Some aspects of the operation of Dolby Pro Logic and Pro Logic JJ<br>
decoders are explained, for example, in papers available on the Dolby Laboratories'<br>
website (www.dolby.com): "Dolby Surround Pro Logic Decoder Principles of<br>
Operation,' by Roger-Dressier, and "Mixing with Dolby Pro LogicTf Technology,.by Jim<br>
Hilson. Other suitable active matrix decoders may include those described in one or more<br>
of the following U.S. Patents and published International Applications (each designating<br>
the United States).<br><br>
5,046,098; 5,274,740; 5,400,433; 5,625,696; 5,644,640; 5,504,819; 5,428,687; 5,172,415;<br>
and WO 02/19768.<br>
Referring again to FIG. 2, the received mono composite audio channel is applied<br>
to a plurality of signal paths from which a respective one of each of the recovered<br>
multiple audio channels is derived. Each channel-deriving path includes, in either order,<br>
an amplitude adjusting function or device ("Adjust Amplitude") and an angle rotation<br>
function or device ("Rotate Angle").<br>
The Adjust Amplitudes apply gains or losses to the mono composite signal so that,<br>
under certain signal conditions, the relative output magnitudes (or energies) of the output<br>
channels derived from it are similar to those of the channels at the input of the encoder.<br>
Alternatively, under certain signal conditions when "randomized" angle variations are<br>
imposed, as next described, a controllable amount of "randomized" amplitude variations<br>
may also be imposed on the amplitude of a recovered channel in order to improve its<br>
decorrelation with respect to other ones of the recovered channels.<br>
The Rotate Angles apply phase rotations so that, under certain signal conditions,<br>
the relative phase angles of the output channels derived from the mono composite signal<br>
are similar to those of the channels at the input of the encoder. Preferably, under certain<br>
signal conditions, a controllable amount of "randomized" angle variations is also imposed<br>
on the angle of a recovered channel in order to improve its decorrelation with respect to<br>
other ones of the recovered channels.<br>
As discussed further below, "randomized" angle amplitude variations may include<br>
not only pseudo-random and truly random variations, but also deterministically-generated<br>
variations that have the effect of reducing cross-correlation between channels. This is<br>
discussed further below in the Comments to Step 505 of FIG. 5A.<br>
Conceptually, the Adjust Amplitude and Rotate Angle for a particular channel<br>
scale the mono composite audio DFT coefficients to yield reconstructed transform bin<br>
values for the channel.<br>
The Adjust Amplitude for each channel may. be controlled at. least.by the<br>
recovered sidechain Amplitude Scale Factor for the particular channel or, in the case of<br>
the reference channel, either from the recovered sidechain Amplitude Scale Factor for the<br>
reference channel or from an Amplitude Scale Factor deduced from the recovered<br>
sidechain Amplitude Scale Factors of the other, non-reference, channels. Alternatively,<br><br>
to enhance decorrelation of the recovered channels, the Adjust Amplitude may also be<br>
controlled by a Randomized Amplitude Scale Factor Parameter derived from the<br>
recovered sidechain Decorrelation Scale Factor for a particular channel and the recovered<br>
sidechain Transient Flag for the particular channel.<br>
The Rotate Angle for each channel may be controlled at least by the recovered<br>
sidechain Angle Control Parameter (in which case, the Rotate Angle in the decoder may<br>
substantially undo the angle rotation provided by the Rotate Angle in the encoder). To<br>
enhance decorrelation of the recovered 'channels, a Rotate Angle may also be controlled<br>
by a Randomized Angle Control Parameter derived from the recovered sidechain<br>
Decorrelation Scale Factor for a particular channel and the recovered sidechain Transient<br>
Flag for the particular channel. The Randomized Angle Control Parameter for a channel,<br>
and, if employed, the Randomized Amplitude Scale Factor for a channel, may be derived<br>
from the recovered Decorrelation Scale Factor for the channel and the recovered<br>
Transient Flag for the channel by a controllable decorrelator function or device<br>
("Controllable Decorrelator").<br>
Referring to the example of FIG. 2, the recovered mono composite audio is<br>
applied to a first channel audio recovery path 22, which derives the channel 1 audio, and<br>
to a second channel audio recovery path 24, which derives the channel n audio. Audio<br>
path 22 includes an Adjust Amplitude 26, a Rotate Angle 28, and, if a PCM output is<br>
desired, an inverse filterbank function or device ("Inverse Filterbank") 30. Similarly,<br>
audio path 24 includes an Adjust Amplitude 32, a Rotate Angle 34, and, if a PCM output<br>
is desired, an inverse filterbank function or device ("Inverse Filterbank") 36. As with the<br>
case of FIG. 1, only two channels are shown for simplicity in presentation, it being<br>
understood that there may be more than two channels.<br>
The recovered sidechain information for the first channel, channel 1, may include<br>
an Amplitude Scale Factor, an Angle Control Parameter, a Decorrelation Scale Factor, a<br>
Transient Flag, and, optionally, an Interpolation Flag, as stated above in connection with<br>
the description of a basic Encoder.'. The Amplitude'Scale Factor is applied to Adjust<br>
Amplitude 26. If the optional Interpolation Flag is employed, an optional frequency<br>
interpolator or interpolator function ("Interpolator") 27 may be employed in order to<br>
interpolate the Angle Control Parameter across frequency (e.g., across the bins in each<br>
subband of a channel). Such interpolation may be, for example, a linear interpolation of<br><br>
the bin angles between the centers of each subband. The state of the one-bit Interpolation<br>
Flag selects whether or not interpolation across frequency is employed, as is explained<br>
further below. The Transient Flag and Decorrelation Scale Factor are applied to a<br>
Controllable Decorrelator 38 that generates a Randomized Angle Control Parameter in<br>
response thereto. The state of the one-bit Transient Flag selects one of two multiple<br>
modes of randomized angle decorrelation, as is explained further below. The Angle<br>
Control Parameter, which may be interpolated across frequency if the Interpolation Flag<br>
and the Interpolator are employed, and the Randomized Angle Control Parameter are<br>
summed together by an additive combiner or combining function 40 in order to provide a<br>
control signal for Rotate Angle 28. Alternatively, the Controllable Decorrelator 38 may<br>
also generate a Randomized Amplitude Scale Factor in response to the Transient Flag and<br>
Decorrelation Scale Factor, in addition to generating a Randomized Angle Control<br>
Â»<br>
Parameter. The Amplitude Scale Factor may be summed together with such a<br>
Randomized Amplitude Scale Factor by an additive combiner or combining function (not<br>
shown) in order to provide the control signal for the Adjust Amplitude 26.<br>
Similarly, recovered sidechain information for the second channel, channel n, may<br>
also include an Amplitude Scale Factor, an Angle Control Parameter, a Decorrelation<br>
Scale Factor, a Transient Flag, and, optionally, an Interpolate Flag, as described above in<br>
connection with the description of a basic encoder. The Amplitude Scale Factor is<br>
applied to Adjust Amplitude 32. A frequency interpolator or interpolator function<br>
("Interpolator") 33 may be employed in order to interpolate the Angle Control Parameter<br>
across frequency. As with channel 1, the state of the one-bit Interpolation Flag selects<br>
whether or not interpolation across frequency is employed. The Transient Flag and<br>
Decorrelation Scale Factor are applied to a Controllable Decorrelator 42 that generates a<br>
Randomized Angle Control Parameter in response thereto. As with channel 1; the state of<br>
the one-bit Transient Flag selects one of two multiple modes of randomized angle<br>
decorrelation, as is explained further below. The Angle Control Parameter and the<br>
Randomized Angle Control Parameter are summed together by an.additive combiner or- .<br>
combining function 44 in order to provide a control signal for Rotate Angle 34..<br>
Alternatively, as described above in connection with channel 1, the Controllable<br>
Decorrelator 42 may also generate a Randomized Amplitude Scale Factor in response to<br>
the Transient Flag and Decorrelation Scale Factor, in addition to generating a<br><br>
Randomized Angle Control Parameter. The Amplitude Scale Factor and Randomized<br>
Amplitude Scale Factor may be summed together by an additive combiner or combining<br>
function (not shown) in order to provide the control signal for the Adjust Amplitude 32.<br>
Although a process or topology as just described is useful for understanding,<br>
essentially the same results may be obtained with alternative processes or topologies that<br>
achieve the same or similar results. For example, the order of Adjust Amplitude 26 (32)<br>
and Rotate Angle 28 (34) may be reversed and/or there may be more than one Rotate<br>
Angle - one that responds to the Angle Control Parameter and another that responds to<br>
the Randomized Angle Control Parameter. The Rotate Angle may also be considered to<br>
be three rather than one or two functions or devices, as in the example of FIG. 5 described<br>
below. If a Randomized Amplitude Scale Factor is employed, there may be more than<br>
one Adjust Amplitude - one that responds to the Amplitude Scale Factor and one that<br>
responds to the Randomized Amplitude Scale Factor. Because of the human ear's greater<br>
sensitivity to amplitude relative to phase, if a Randomized Amplitude Scale Factor is<br>
employed, it may be desirable to scale its effect relative to the effect of the Randomized<br>
Angle Control Parameter so that its effect on amplitude is less than the effect that the<br>
Randomized Angle Control Parameter has on phase angle. As another alternative process-<br>
or topology, the Decorrelation Scale Factor may be used to control the ratio of<br>
randomized phase angle versus basic phase angle (rather than adding a parameter<br>
representing a randomized phase angle to a parameter representing the basic phase angle),<br>
and if also employed, the ratio of randomized amplitude shift versus basic amplitude shift<br>
(rather than adding a scale factor representing a randomized amplitude to a scale factor<br>
representing the basic amplitude) (i.e., a variable crossfade in each case).<br>
If a reference channel is employed, as discussed above in connection with the<br>
basic encoder, the Rotate Angle, Controllable Decorrelator and Additive Combiner for<br>
that channel may be omitted inasmuch as the sidechain information for the reference<br>
channel may include only the Amplitude Scale Factor (or, alternatively, if the sidechain<br>
â–  information does not contain an Amplitude Scale Factor for .the reference-channel, it may<br>
be deduced from Amplitude Scale Factors of the other channels when the energy<br>
normalization in the encoder assures that the scale factors across channels within a<br>
subband sum square to 1). An Amplitude Adjust is provided for the reference channel<br>
and it is controlled by a received or derived Amplitude Scale Factor for the reference<br><br>
channel. Whether the reference channel's Amplitude Scale Factor is derived from the<br>
sidechain or is deduced in the decoder, the recovered reference channel is an amplitude-<br>
scaled version of the mono composite channel. It does not require angle rotation because<br>
it is the reference for the other channels' rotations.<br>
Although adjusting the relative amplitude of recovered channels may provide a<br>
modest degree of decorrelation, if used alone amplitude adjustment is likely to result in a<br>
reproduced soundfield substantially lacking in spatiaiization or imaging for many signal<br>
conditions (e.g., a "collapsed" soundfield). Amplitude adjustment may affect interaural<br>
level differences at the ear, which is only one of the psychoacoustic directional cues<br>
employed by the ear. Thus, according to aspects of the invention, certain angle-adjusting<br>
techniques may be employed, depending on signal conditions, to provide additional<br>
decorrelation. Reference may be made to Table 1 that provides abbreviated comments<br>
useful in understanding the multiple angle-adjusting decorrelation techniques or modes of<br>
operation that may be employed in accordance with aspects of the invention. Other<br>
decorrelation techniques as described below in connection with the examples of FIGS. 8<br>
and 9 may be employed instead of or in addition to the techniques of Table 1.<br>
In practice, applying angle rotations and magnitude alterations may result in<br>
circular convolution (also known as cyclic or periodic convolution). Although, generally,<br>
it is desirable to avoid circular convolution, undesirable audible artifacts resulting from<br>
circular convolution are somewhat reduced by complementary angle shifting in an<br>
encoder and decoder. In addition, the effects of circular convolution may be tolerated in<br>
low cost implementations of aspects of the present invention, particularly those in which<br>
the downmixing to mono or multiple channels occurs only in part of the audio frequency<br>
band, such as, for example above 1500 Hz (in which case the audible effects of circular<br>
convolution are minimal). Alternatively, circular convolution may be avoided or<br>
minimized by any suitable technique, including, for example, an appropriate use of zero<br>
padding. One way to use zero padding is to transform the proposed frequency domain<br>
variation-(representing angle rotations and amplitude scaling) to the time domain, window<br>
it (with an arbitrary window), pad it with zeros, then transform back to the frequency<br>
domain and multiply by the frequency domain version of the audio to be processed (the<br>
audio need not be windowed).<br>
Table 1<br>
Angle-Adjusting Decorrelation Techniques<br><br><br>
For signals that are substantially static spectrally, such as, for example, a pitch<br>
pipe note, a first technique ("Technique 1") restores the angle of the received mono<br>
composite signal relative to the angle of each of the other recovered channels to an angle<br>
similar (subject to frequency and time granularity and to quantization) to the original<br>
angle of the channel relative to the other channels at the input of the encoder. Phase angle<br>
differences are useful, particularly, for providing decorrelation of low-frequency signal<br><br>
components below about 1500 Hz where the ear follows individual cycles of the audio<br>
signal. Preferably, Technique 1 operates under all signal conditions to provide a basic<br>
angle shift.<br>
For high-frequency signal components above about 1500 Hz, the ear does not<br>
follow individual cycles of sound but instead responds to waveform envelopes (on a<br>
critical band basis). Hence, above about 1500 Hz decorrelation is better provided by<br>
differences in signal envelopes rather than phase angle differences. Applying phase angle<br>
shifts only in accordance with Technique 1 does not alter the envelopes of signals<br>
sufficiently to decorrelate high frequency signals. The second and third techniques<br>
("Technique 2" and "Technique 3", respectively) add a controllable amount of<br>
randomized angle variations to the angle determined by Technique 1 under certain signal<br>
conditions, thereby causing a controllable amount of randomized envelope variations,<br>
which enhances decorrelation.<br>
Randomized changes in phase angle are a desirable way to cause randomized<br>
changes in the envelopes of signals. A particular envelope results from the interaction of<br>
a particular combination of amplitudes and phases of spectral components within a<br>
subband. Although changing the amplitudes of spectral components within a subband<br>
changes the envelope, large amplitude changes are required to obtain a significant change<br>
in the envelope, which is undesirable because the human ear is sensitive to variations in<br>
spectral amplitude. In contrast, changing the spectral component's phase angles has a<br>
greater effect on the envelope than changing the spectral component's amplitudes â€”<br>
spectral components no longer line up the same way, so the reinforcements and<br>
subtractions that define the envelope occur at different times, thereby changing the<br>
envelope. Although the human ear has some envelope sensitivity, the ear is relatively<br>
phase deaf, so the overall sound quality remains substantially similar. Nevertheless, for<br>
some signal conditions, some randomization of the amplitudes of spectral components<br>
along with randomization of the phases of spectral components may provide an enhanced<br>
randomization of signal, envelopes provided ihatsuch amplitude, randomization does not<br>
cause undesirable audible artifacts.<br>
Preferably, a controllable amount or degree of Technique 2 or Technique 3<br>
operates along with Technique 1 under'certain signal conditions. The Transient Flag<br>
selects Technique 2 (no transient present in the frame or block, depending on whether the<br><br>
Transient Flag is sent at the frame or block rate) or Technique 3 (transient present in the<br>
frame or block). Thus, there are multiple modes of operation, depending on whether or<br>
not a transient is present. Alternatively, in addition, under certain signal conditions, a<br>
controllable amount of degree of amplitude randomization also operates along with the<br>
amplitude scaling that seeks to restore the original channel amplitude.<br>
Technique 2 is suitable for complex continuous signals that are rich in harmonics,<br>
such, as massed orchestral violins. Technique 3 is suitable for complex impulsive or<br>
transient signals, such as applause, castanets, etc. (Technique 2 time smears claps in<br>
applause, making it unsuitable for such signals). As explained farther below, in order to<br>
minimize audible artifacts, Technique 2 and Technique 3 have different time and<br>
frequency resolutions for applying randomized angle variations â€” Technique 2 is<br>
selected when a transient is not present, whereas Technique 3 is selected when a transient<br>
is present.<br>
Technique 1 slowly shifts (frame by frame) the bin angle in a channel. The<br>
amount or degree of this basic shift is controlled by the Angle Control Parameter (no shift<br>
if the parameter is zero). As explained further below, either the same or an interpolated<br>
parameter is applied to all bins in each subband and the parameter is updated every frame.<br>
Consequently, each subband of each channel may have a phase shift with respect to other,<br>
channels, providing a degree of decorrelation at low frequencies (below about 1500 Hz).<br>
However, Technique 1, by itself, is unsuitable for a transient signal such as applause. For<br>
such signal conditions, the reproduced channels may exhibit an annoying unstable comb-<br>
filter effect. In the case of applause, essentially no decorrelation is provided by adjusting<br>
only the relative amplitude of recovered channels because all channels tend to have the<br>
same amplitude over the period of a frame.<br>
Technique 2 operates when a transient is not present. Technique 2 adds to the<br>
angle shift of Technique 1 a randomized angle shift that does not change with time, on a<br>
bin-by-bin basis (each bin has a different randomized shift) in a channel, causing the<br>
envelopes of the channels to be different from one another, thus providing decorrelation. of complex signals among the channels. Maintaining the randomized phase angle values<br>
constant over time avoids block or frame artifacts that may result from block-to-block or<br>
frame-to-ff ame alteration of bin phase angles. "While this technique is a very useful<br>
decorrelation tool when a transient is not present, it may temporally smear a transient<br><br>
(resulting in what is often referred to as "pre-noise" - the post-transient smearing is<br>
masked by the transient). The amount or degree of additional shift provided by<br>
Technique 2 is scaled directly by the Decorrelation Scale Factor (there is no additional<br>
shift if the scale factor is zero). Ideally, the amount of randomized phase angle added to<br>
the base angle shift (of Technique 1) according to Technique 2 is controlled by the<br>
Decorrelation Scale Factor in a manner that minimizes audible signal warbling artifacts.<br>
Such minimization of signal warbling artifacts results from the manner in which the<br>
Decorrelation Scale Factor is derived and the application of appropriate time smoothing,<br>
as described below. Although a different additional randomized angle shift value is<br>
applied to each bin and that shift value does not change, the same scaling is applied<br>
across a subband and the scaling is updated every frame.<br>
Technique 3 operates in the presence of a transient in the frame or block,<br>
depending on the rate at which the Transient Flag is sent. It shifts all the bins in each<br>
subband in a channel from block to block with a unique randomized angle value, common<br>
to all bins in the subband, causing not only the envelopes, but also the amplitudes and<br>
phases, of the signals in a channel to change with respect to other channels from block to<br>
block. These changes in time and frequency resolution of the angle randomizing reduce<br>
steady-state signal similarities among the channels and provide decorrelation of the<br>
channels substantially without causing "pre-noise" artifacts. The change in frequency<br>
resolution of the angle randomizing, from very fine (all bins different in a channel) in<br>
Technique 2 to coarse (all bins within a subband the same, but each subband different) in<br>
Technique 3 is particularly useful in nu'nimizing "pre-noise" artifacts. Although the ear<br>
does not respond to pure angle changes directly at high frequencies, when two or more<br>
channels mix acoustically on their way from loudspeakers to a listener, phase differences â€¢<br>
may cause amplitude changes (comb-filter effects) that may be audible and objectionable,<br>
and these are broken up by Technique 3. The impulsive characteristics of the signal<br>
minimize block-rate artifacts that might otherwise occur. Thus, Technique 3 adds to the<br>
phase shift of Technique 1 a rapidly changing (block-by-blo,ck) -randomized angle shift<br>
on a subband-by-subband basis in a channel. The amount or degree of additional shift is<br>
scaled indirectly, as described below, by the Decorrelation Scale Factor (there is no<br>
additional shift if the scale factor is zero). The same scaling is applied across a subband<br>
and the scaling is updated every frame.<br><br>
Although the angle-adjusting techniques have been characterized as three<br>
techniques, this is a matter of semantics and they may also be characterized as two<br>
techniques: (1) a combination of Technique 1 and a variable degree of Technique 2,<br>
which may be zero, and (2) a combination of Technique 1 and a variable degree<br>
Technique 3, which may be zero. For convenience in presentation, the techniques are<br>
treated as being three techniques.<br>
Aspects of the multiple mode decorrelation techniques and modifications of them<br>
may be employed in providing decorrelation of audio signals derived, as by uprnixing,<br>
from one or more audio channels even when such audio channels are not derived from an<br>
encoder according to aspects of the present invention. Such arrangements, when applied<br>
to a mono audio channel,'are sometimes referred to as "pseudo-stereo" devices and<br>
functions. Any suitable device or function (an 'hipmixer") may be employed to derive<br>
multiple signals from a mono audio channel or from multiple audio channels. Once such<br>
multiple audio channels are derived by an uprnixer, one or more of them may be<br>
decorrelated with respect to one or more of the other derived audio signals by applying<br>
the multiple mode decorrelation techniques described herein. In such an application, each<br>
derived audio channel to which the decorrelation techniques are applied may be switched<br>
from one mode of operation to another by detecting transients in the derived audio<br>
channel itself. Alternatively, the operation of the transient-present technique (Technique<br>
3) may be simplified to provide no shifting of the phase angles of spectral components<br>
when a transient is present.<br>
Sidechain Information<br>
As mentioned above, the sidechain information may include: an Amplitude Scale<br>
Factor, an Angle Control Parameter, a Decorrelation Scale Factor, a Transient Flag, and,,<br>
optionally, an Interpolation Flag. Such sidechain information for a practical embodiment<br>
of aspects, of the present invention may be summarized in the following Table 2.<br>
Typically, the sidechain information may be updated once per frame.<br><br><br><br><br><br>
la each case, the sidechain infonnation of a channel applies to a single subband<br>
(except for the Transient Flag and the Interpolation Flag, each of which apply to all<br>
subbands in a channel) and may be updated once per frame. Although the time resolution<br>
(once per frame), frequency resolution (subband), value ranges and quantization levels<br>
indicated have been found to provide useful performance and a useful compromise<br>
between a low bitrate and performance, it will be appreciated that these time and<br>
frequency resolutions, value ranges and quantization levels are not critical and that other<br>
resolutions, ranges and levels may employed in practicing aspects of the invention. For<br>
example, the Transient Flag and/or the Interpolation Flag, if employed, may be updated<br>
once per block with only a minimal increase in sidechain data overhead. In the case of<br>
the Transient Flag, doing so has the advantage that the switching from Technique 2 to<br>
Technique 3 and vice-versa is more accurate. In addition, as mentioned above, sidechain<br>
information may be updatednpon the occurrence of a block switch of a related coder.<br>
It will be noted that Technique 2, described above (see also Table 1), provides a<br>
bin frequency resolution rather than a subband frequency resolution (i.e., a different<br>
pseudo random phase angle shift is applied to each bin rather than to each subband) even<br>
though the same Subband Decorrelation Scale Factor applies to all bins in a subband. It<br><br>
will also be noted that Technique 3, described above (see also Table 1), provides a block<br>
frequency resolution (i.e., a different randomized phase angle shift is applied to each<br>
block rather than to each frame) even though the same Subband Decorrelation Scale<br>
Factor applies to all bins in a subband. Such resolutions, greater than the resolution of the<br>
sidechain information, are possible because the randomized phase angle shifts may be<br>
generated in a decoder and need not be known in the encoder (this is the case even if the<br>
encoder also applies a randomized phase angle shift to the encoded mono composite<br>
signal, an alternative that is described below). In other words, it is not necessary to send<br>
sidechain information having bin or block granularity even though the decorrelation<br>
techniques employ such granularity. The decoder may employ, for example, one or more<br>
lookup tables of randomized bin phase angles. The obtaining of time and/or frequency<br>
resolutions for decorrelation greater than the sidechain information rates is among the<br>
aspects of the present invention. Thus, decorrelation by way of randomized phases is<br>
performed either with a fine frequency resolution (bin-by-bin) that does not change with<br>
time (Technique 2), or with a coarse frequency resolution (band-by-band) ((or a fine<br>
frequency resolution (bin-by-bin) when frequency interpolation is employed, as described<br>
further below)) and a fine time resolution (block rate) (Technique 3).<br>
It will also be appreciated that as increasing degrees of randomized phase shifts<br>
are added to the phase angle of a recovered channel, the absolute phase angle of the<br>
recovered channel differs more and more from the original absolute phase angle of that<br>
channel. An aspect of the present invention is the appreciation that the resulting absolute<br>
phase angle of the recovered channel need not match that of the original channel when<br>
signal conditions are such that the randomized phase shifts are added in accordance with<br>
aspects of the present invention. For example, in extreme cases when the Decorrelation<br>
Scale Factor causes the highest degree of randomized phase shift, the phase shift caused<br>
by Technique 2 or Technique 3 overwhelms the basic phase shift caused by Technique 1.<br>
Nevertheless, this is of no concern in that a randomized phase shift is audibly the same as<br>
the different random phases in the original signal that give rise to a Decorrelation S cale<br>
Factor that causes the addition of some degree of randomized phase shifts.<br>
As mentioned above, randomized amplitude shifts may by employed in addition to<br>
randomized phase shifts. For example, the Adjust Amplitude may also be controlled by a<br>
Randomized Amplitude Scale Factor Parameter derived from the recovered sidechain<br><br>
Decorrelation Scale Factor for a particular channel and the recovered sidechain Transient<br>
Flag for the particular channel. Such randomized amplitude shifts may operate in two<br>
modes in a manner analogous to the application of randomized phase shifts. For example,<br>
in the absence of a transient, a randomized amplitude shift that does not change with time<br>
may be added on a bin-by-bin basis (different from bin to bin), and, in the presence of a<br>
transient (in the frame or block), a randomized amplitude shift that changes on a block-<br>
by-block basis (different from block to block) and changes from subband to subband (the<br>
same shift for all bins in a subband; different from subband to subband). Although the<br>
amount or degree to which randomized amplitude shifts are added may be controlled by â– <br>
the Decorrelation Scale Factor, it is believed that a particular scale factor value should<br>
cause less amplitude shift than the corresponding randomized phase shift resulting from<br>
the same scale factor value in order to avoid audible artifacts.<br>
When the Transient Flag applies to a frame, the time resolution with which the<br>
Transient Flag selects Technique 2 or Technique 3 may be enhanced by providing a<br>
supplemental transient detector in the decoder in order to provide a temporal resolution<br>
finer than the frame rate or even the block rate. Such a supplemental transient detector<br>
may detect the occurrence of a transient in the mono or multichannel composite audio<br>
signal received by the decoder and such detection information is then sent to each<br>
Controllable Decorrelator (as 38,42 of FIG. 2). Then, upon the receipt of a Transient<br>
Flag for its channel, the Controllable Decorrelator switches from Technique 2 to<br>
Technique 3 upon receipt of the decoder's local transient detection indication. Thus, a<br>
substantial improvement in temporal resolution is possible without increasing the<br>
sidechain bitrate, albeit with decreased spatial accuracy (the encoder detects transients in<br>
each input channel prior to their downmixing, whereas, detection in the decoder is done<br>
after downmixing).<br>
As an alternative to sending sidechain information on a frame-by-frame basis,<br>
sidechain information may be updated every block, at least for highly dynamic signals.<br>
As mentioned above, updating the Transient Flag, and/or the Interpolation Flag every ,<br>
block results in only a small increase in sidechain data overhead. In order to accomplish<br>
such an increase in temporal resolution for other sidechain information without<br>
substantially increasing the sidechain data rate, a block-floating-point differential coding<br>
arrangement may be used. For example, consecutive transform blocks may be collected<br><br>
in groups of six over a frame. The full sidechain information may be sent for each<br>
subband-channel in the first block. In the five subsequent blocks, only differential values<br>
may be sent, each the difference between the current-block amplitude and angle, and the<br>
equivalent values from the previous-block. This results in very low data rate for static<br>
signals, such as a pitch pipe note. For more dynamic signals, a greater range of difference<br>
values is required,'but at less precision. So, for each group of five differential values, an<br>
exponent may be sent first, using, for example, 3 bits, then differential values are<br>
quantized to, for example, 2-bit accuracy. This arrangement reduces the average worst-<br>
case sidechain data rate by about a factor of two. Further reduction may be obtained by<br>
omitting the sidechain data for a reference channel (since it can be derived from the other<br>
channels), as discussed above, and by using, for example, arithmetic coding.<br>
Alternatively or in addition, differential coding across frequency may be employed by<br>
sending, for example, differences in subband angle or amplitude.<br>
Whether sidechain information is sent on a frame-by-frame basis or more<br>
frequently, it may be useful to interpolate sidechain values across the blocks in a frame.<br>
Linear interpolation over time may be employed in the manner of the linear interpolation<br>
across frequency, as described below.<br>
One suitable implementation of aspects of the present invention employs<br>
processing steps or devices that implement the respective processing steps and are<br>
functionally related as next set forth. Although the encoding and decoding steps listed<br>
below may each be carried out by computer software instruction sequences operating in<br>
the order of the below listed steps, it will be understood that equivalent or similar results<br>
may be obtained by steps ordered in other ways, taking into account that certain quantities<br>
are derived from earlier ones. For example, multi-threaded computer software instruction<br>
sequences may be employed so that certain sequences of steps are carried out in parallel.<br>
Alternatively, the described steps may be implemented as devices that perform the<br>
described functions, the various devices having functions and functional interrelationships<br>
as described hereinafter. .	.-,-... 	<br>
Encoding<br>
The encoder or encoding function may collect a frame's worth of data before it<br>
derives sidechain information and downmixes the frame's audio channels to a single<br>
monophonic (mono) audio channel (in the manner of the example of FIG. 1, described<br><br><br>
above), or to multiple audio channels (in the manner of the example of FIG. 6, described<br>
below). By doing so, sidechain information may be sent first to a decoder, allowing the<br>
decoder to begin decoding immediately upon receipt of the mono or multiple channel<br>
audio information. Steps of an encoding process ("encoding steps") may be described as<br>
follows. With respect to encoding steps, reference is made to FIG. 4, which is in the<br>
nature of a hybrid flowchart and functional block diagram. Through Step 419, FIG. 4<br>
shows encoding steps for one channel. Steps 420 and 421 apply to all of the multiple<br>
channels that are combined to provide a composite mono signal output or are matrixed<br>
together to provide multiple channels, as described below in connection with the example<br>
of FIG. 6.<br>
Step 401, Detect Transients<br>
a.	Perform transient detection of the PCM values in an input audio channel.<br>
b.	Set a one-bit Transient Flag True if a transient is present in any block of a frame<br>
for the channel.<br>
Comments regarding Step 401:<br>
The Transient Flag forms a portion of the sidechain information and is also used<br>
in Step 411, as described below. Transient resolution finer than block rate in the decoder<br>
may improve decoder performance. Although, as discussed above, a block-rate rather .<br>
than a frame-rate Transient Flag may form a portion of the sidechain information with a<br>
modest increase in bitrate, a similar result, albeit with decreased spatial accuracy, may be<br>
accomplished without increasing the sidechain bitrate by detecting the occurrence of<br>
transients in the mono composite signal received in the decoder.<br>
There is one transient flag per channel per frame, which, because it is derived in<br>
the time domain, necessarily applies to all subbands within that channel. The transient<br>
detection may be performed in the manner similar to that employed in an AC-3 encoder<br>
for controlling the decision of when to switch between long and short length audio<br>
blocks, but with a higher sensitivity and with the Transient Flag True for any frame in<br>
which the Transient Flag- for a block is True (an AC-3 encoder.detects transients on a ..<br>
block basis). In particular, see Section 8.2.2 of the above-cited A/52A document. The<br>
sensitivity of the transient detection described in Section 8.2.2 may be increased by<br>
adding a sensitivity factor F to an equation set forth therein. Section 8.2.2 of the A/52A<br>
document is set forth below, with the sensitivity factor added (Section 8.2.2 as reproduced<br><br>
below is corrected to indicate that the low pass filter is a cascaded biquad direct form II<br>
DOR. filter rather than "form I" as in the published A/52A document; Section 8.2.2 was<br>
correct in the earlier A/52 document). Although it is not critical, a sensitivity factor of<br>
0.2 has been found to be a suitable value in a practical embodiment of aspects of the<br>
present invention.<br>
Alternatively, a similar transient detection technique described in U.S. Patent<br>
5,394,473 may be employed. The '473 patent describes aspects of the A/52A document<br>
transient detector in greater detail.<br>
As another alternative, transients may be detected in the frequency domain rather<br>
than in the time domain (see the Comments to Step 408 ). In that case, Step 401 may be<br>
omitted and an alternative step employed in the frequency domain as described below.<br>
Step 402. Window and DFT.<br>
Multiply overlapping blocks of PCM time samples by a time window and convert<br>
them to complex frequency values via a DFT as implemented by an FFT.<br>
Step 403. Convert Complex Values to Magnitude and Angle.<br>
Convert each frequency-domain complex transform bin value (a +jb) to a<br>
magnitude and angle representation using standard complex manipulations:<br>
a.	Magnitude = squarejroot (a2 + b2)<br>
b.	Angle = arctan (b/a)<br>
Comments regarding Step 403:<br>
Some of the following Steps use or may use, as an alternative, the energy of a bin,<br>
defined as the above magnitude squared (i.e., energy = (a2 + b2).<br>
Step 404. Calculate Subband Energy.<br>
a.	Calculate the subband energy per block by adding bin energy values within<br>
each subband (a summation across frequency).<br>
b.	Calculate the subband energy per frame by averaging or accumulating the<br>
energy in all the blocksin a frame (an averaging / accumulation across time).<br>
c.	If the coupling frequency of the encoder is below about 1000 Hz, apply the<br>
subband frame-averaged or frame-accumulated energy to a time smoother that operates<br>
on all subbands below that frequency and above the coupling frequency.<br>
Comments regarding Step 404c:<br><br>
Time smoothing to provide inter-frame smoothing in low frequency subbands may<br>
be useful. In order to avoid artifact-causing discontinuities between bin values at subband<br>
boundaries, it may be useful to apply a progressively-decreasing time smoothing from the<br>
lowest frequency subband encompassing and above the coupling frequency (where the<br>
smoothing may have a significant effect) up through a higher frequency subband in which<br>
the time smoothing effect is measurable, but inaudible, although nearly audible. A<br>
suitable time constant for the lowest frequency range subband (where the subband is a<br>
single bin if subbands are critical bands) may be in the range of 50 to 100 milliseconds,<br>
for example. Progressiveiy-decreasing time smoothing may continue up through a<br>
subband encompassing about 1000 Hz where the time constant may be about 10<br>
milliseconds, for example.<br>
. Although a first-order smoother is suitable, the smoother may be a two-stage<br>
smoother that has a variable time constant that shortens its attack and decay time in<br>
response to a" transient (such a two-stage smoother may be a digital equivalent of the<br>
analog two-stage smoothers described in U.S. Patents 3,846,719 and 4,922,535).<br>
In other words, the steady-state<br>
time constant may be scaled according to frequency and may also be variable in response<br>
to transients. Alternatively, such smoothing may be applied in Step 412.<br>
Step 405. Calculate Sum of Bin Magnitudes.<br>
a.	Calculate the sum per block of the bin magnitudes (Step 403) of each subband<br>
(a summation across frequency).<br>
b.	Calculate the sum per frame of the bin magnitudes of each subband by<br>
averaging or accumulating the magnitudes of Step 405a across the blocks in a frame (an<br>
averaging / accumulation across time). These sums are used to calculate an Interchannel<br>
Angle Consistency Factor in Step 410 below.<br>
c.	If the coupling frequency of the encoder is below about 1000 Hz, apply the<br>
subband frame-averaged or frame-accumulated magnitudes to a time smoother that<br>
operates on all subbands-below that frequency and above the coupling, frequency., .<br>
Comments regarding Step 405c: See comments regarding step 404c except that<br>
in the case of Step 405c, the time smoothing may alternatively be performed as part of<br>
Step 410.<br>
Step 406. Calculate Relative Interchannel Bin Phase Angle.<br><br>
Calculate the relative interchannel phase angle of each transform bin of each block<br>
by subtracting from the bin angle of Step 403 the corresponding bin angle of a reference<br>
channel (for example, the first channel). The result, as with other angle additions or<br>
subtractions herein, is taken modulo (it, -it) radians by adding or subtracting 2% until the<br>
result is within the desired range of â€”% to -hi.<br>
Step 407. Calculate Interchannel Subband Phase Angle.<br>
For each channel, calculate a frame-rate amplitude-weighted average interchannel<br>
phase angle for each subband as follows:<br>
a.	For each bin, construct a complex number from the magnitude of Step 403<br>
and the relative interchannel bin phase angle of Step 406.<br>
b.	Add the constructed complex numbers of Step 407a across each subband (a<br>
summation across frequency).<br>
Comment regarding Step 407b: For example, if a subband has two bins and<br>
one of the bins has a complex value of 1 + jl and the other bin has a complex<br>
value of 2 +j2, their complex sum is 3 + j3.<br>
c.	Average or accumulate the per block complex number sum for each<br>
subband of Step 407b across the blocks of each frame (an averaging or<br>
accumulation across time).<br>
d.	If the coupling frequency'of the encoder is below about 1000 Hz, apply the<br>
subband frame-averaged or frame-accumulated complex value to a time smoother<br>
that operates on all subbands below that frequency and above the coupling<br>
frequency.<br>
Comments regarding Step 407d: See comments regarding Step 404c except<br>
that in the case of Step 407d, the time smoothing may alternatively be performed<br>
as part of Steps 407e or 410.<br>
â–  e. Compute the magnitude of the complex result of Step 407d as per Step 403.<br>
Comment regarding Step 407e: This magnitude is used in Step 410a below.<br>
In the simple example given in Step 407b, the magnitude of 3 +j3 is squarejroot ....<br>
(9 + 9) = 4.24.<br>
f. Compute the angle of the complex result as per Step 403.<br>
Comments regarding Step 407f: In the simple example given in Step 407b,<br>
the angle of 3 + j3 is arctan (3/3) = 45 degrees = %/A radians. This subband angle<br><br>
is signal-dependently time-smoothed (see Step 413) and quantized (see Step 414)<br>
to generate the Subband Angle Control Parameter sidechain information, as<br>
described below.<br>
Step 408. Calculate Bin Spectral-Steadiness Factor<br>
For each, bin, calculate a Bin Spectral-Steadiness Factor in the range of 0 to 1 as<br>
follows:<br>
a.	Let xm = bin magnitude of present block calculated in Step 403.<br>
b.	Let ym = corresponding bin magnitude of previous block.<br>
c.	If xm &gt; ym, then Bin Dynamic Amplitude Factor = (ym/xm)2;<br>
d.	Else if ym &gt; xm, then Bin Dynamic Amplitude Factor = (Xm/ym)2,<br>
e.	Else if ym = xm, then Bin Spectral-Steadiness Factor = 1.<br>
Comment regarding Step 408:<br>
"Spectral steadiness" is a measure of the extent to which spectral components<br>
{e.g., spectral coefficients or bin values) change over time. A Bin Spectral-Steadiness<br>
Factor of 1 indicates no change over a given time period.<br>
Spectral Steadiness may also be taken as an indicator of whether a transient is<br>
present. A transient may cause a sudden rise and fall in spectral (bin) amplitude over a<br>
time period of one or more blocks, depending on its position with regard to blocks and<br>
their boundaries. Consequently, a change in the Bin Spectral-Steadiness Factor from a<br>
high value to a low value over a small number of blocks may be taken as an indication of<br>
the presence of a transient in the block or blocks having the lower value. A further<br>
confirmation of me presence of a transient, or an alternative to employing the Bin<br>
Spectral-Steadiness factor, is to observe the phase angles of bins within the block (for<br>
example, at the phase angle output of Step 403). Because a transient is likely to occupy a<br>
single temporal position within a block and have the dominant energy in the block, the<br>
existence and position of a transient may be indicated by a substantially uniform delay in<br>
phase from bin to bin in the block - namely, a substantially linear ramp of phase angles as<br>
a function of frequency. Yet a further confirmation or alternative is to observe the bin .<br>
amplitudes over a small number of blocks (for example, at the magnitude output of Step<br>
403), namely by looking directly for a sudden rise and fall of spectral level.<br>
Alternatively, Step 408 may look at three consecutive blocks instead of one block.<br>
If the coupling frequency of the encoder is below about 1000 Hz, Step 408 may look at<br><br>
more than three consecutive blocks. The number of consecutive blocks may taken into<br>
consideration vary with frequency such that the number gradually increases as the<br>
subband frequency range decreases. If the Bin Spectral-Steadiness Factor is obtained<br>
from more than one block, the detection of a transient, as just described, may be<br>
determined by separate steps that respond only to the number of blocks useful for<br>
detecting transients.<br>
As a further alternative, bin energies may be used instead of bin magnitudes.<br>
As yet a further alternative, Step 408 may employ an "event decision" detecting<br>
technique as described below in the comments following Step 409.<br>
Step 409. Compute Subband Spectral-Steadiness Factor.<br>
Compute a frame-rate Subband Spectral-Steadiness Factor on a scale of 0 to 1 by<br>
forming an amplitude-weighted average of the Bin Spectral-Steadiness Factor within each<br>
subband across the blocks in a frame as follows:<br>
a.	For each bin, calculate the product of the Bin Spectral-Steadiness Factor of Step<br>
408 and the bin magnitude of Step 403.<br>
b.	Sum the products within each subband (a summation across frequency).<br>
c.	Average or accumulate the summation of Step 409b in all the blocks in a frame<br>
(an averaging / accumulation across time).<br>
d.	If the coupling frequency of the encoder is below about 1000 Hz, apply the<br>
subband frame-averaged or frame-accumulated summation to a time smoother that<br>
operates on all subbands below that frequency and above the coupling frequency.<br>
Comments regarding Step 409d: See comments regarding Step 404c except that<br>
in the case of Step 409d, there is no suitable subsequent step in which the time<br>
smoothing may alternatively be performed.<br>
e.	Divide the results of Step 409c or Step 409d, as appropriate, by the sum of the<br>
bin magnitudes (Step 403) within the subband.<br>
Comment regarding Step 409e: The multiplication by the magnitude in Step<br>
409a and the divisionby the sum of the magnitudes in Step 409e_ provide amplitude,. .<br>
weighting. The output of Step 408 is independent of absolute amplitude and, if not<br>
amplitude weighted, may cause the output or Step 409 to be controlled by very small<br>
amplitudes, which is undesirable.<br>
f.	Scale the result to obtain the Subband Spectral-Steadiness Factor by mapping<br><br>
the range from {0.5...1} to {0...1}. This may be done by multiplying the result by 2,<br>
subtracting 1, and limiting results less than 0 to a value of 0.<br>
Comment regarding Step 409f: Step 409f may be useful in assuring that a<br>
channel of noise results in a Subband Spectral-Steadiness Factor of zero.<br>
Comments regarding Steps 408 and 409:<br>
The goal of Steps 408 and 409 is to measure spectral steadiness â€” changes in<br>
spectral composition overtime in a subband of a channel. Alternatively, aspects of an<br>
"event decision" sensing such as described in International Publication Number WO<br>
02/097792 Al (designating the United States) may be employed to measure spectral<br>
steadiness instead of the approach just described in connection with Steps 408 and 409.<br>
U.S. Patent Application S.N. 10/478,538, filed November 20,2003 is the United States'<br>
national application of the published PCT Application WO 02/097792 Al.<br>
According to these incorporated applications, the magnitudes of the<br>
complex FFT coefficient of each bin are calculated and normalized (largest magnitude is<br>
set to a value of one, for example). Then the magnitudes of corresponding bins (in dB) in<br>
consecutive blocks are subtracted (ignoring signs), the differences between bins are<br>
summed, and, if the sum exceeds a threshold, the block boundary is considered to be an<br>
auditory event boundary. Alternatively, changes in amplitude from block to block may<br>
also be considered along with spectral magnitude changes (by looking at the amount of<br>
normalization required).<br>
If aspects of the incorporated event-sensing applications are employed to measure<br>
spectral steadiness, normalization may not be required and the changes in spectral<br>
magnitude (changes in amplitude would not be measured if normalization is omitted)<br>
preferably are considered on a subband basis. Instead of performing Step 408 as<br>
indicated above, the decibel differences in spectral magnitude between corresponding<br>
bins in each subband may be summed in accordance with the teachings of said<br>
applications. Then, each of those sums, representing the degree of spectral change from<br>
block to block may be scaled so that the result is a spectral steadiness factor having a<br>
range from 0 to 1, wherein a value of 1 indicates the highest steadiness, a change of 0 dB<br>
from block to block for a given bin. A value of 0, indicating the lowest steadiness, may<br>
be assigned to decibel changes equal to or greater than a suitable amount, such as 12 dB,<br><br>
for example. These results, a Bin Spectral-Steadiness Factor, may be used by Step 409 in<br>
the same manner that Step 409 uses the results of Step 408 as described above. When<br>
Step 409 receives a Bin Spectral-Steadiness Factor obtained by employing the just-<br>
described alternative event decision sensing technique, the Subband Spectral-Steadiness<br>
Factor of Step 409 may also be used as an indicator of a transient. For example, if the<br>
range of values produced by Step 409 is 0 to 1, a transient may be considered to be<br>
present when the Subband Spectral-Steadiness Factor is a small value, such as, for<br>
example, 0.1, indicating substantial spectral unsteadiness.<br>
It will be appreciated that the Bin Spectral-Steadiness Factor produced by Step<br>
408 and by the just-described alternative to Step 408 each inherently provide a variable.<br>
threshold to a certain degree in that they are based on relative changes from block to<br>
block. Optionally, it may be useful to supplement such inherency by specifically<br>
providing a shift in the threshold in response to, for example, multiple transients in a<br>
frame or a large transient among smaller transients (e.g., a loud transient coming atop<br>
mid- to low-level applause). Li the case of the latter example, an event detector may<br>
initially identify each clap as an event, but a loud transient (e.g., a drum hit) may make it<br>
desirable to shift the threshold so that only the drum hit is identified as an event.<br>
Alternatively, a randomness metric may be employed (for example, as described<br>
in U.S. Patent Re 36,714)<br>
instead of a measure of spectral-steadiness over time.<br>
Step 410. Calculate Interchannel Angle Consistency Factor.<br>
For each subband having more than one bin, calculate a frame-rate Interchannel<br>
Angle Consistency Factor as follows:<br>
a.	Divide the magnitude of the complex sum of Step 407e by the sum of the<br>
magnitudes of Step 405. The resulting "raw" Angle Consistency Factor is a<br>
number in the range of 0 to 1.<br>
b.	Calculate a correction factor: let n = the number of values across the<br>
subband contributing-to the two quantities in the above step (in other words, "n" is.<br>
the number of bins in the subband). If n is less than 2, let the Angle Consistency<br>
Factor be 1 and go to Steps 4l 1 and 413.<br>
c.	Let r = Expected Random Variation = 1 /n. Subtract r from the result of the<br>
Step 410b.<br><br>
d. Normalize the result of Step 41 Oc by dividing by (1 - f). The result has a<br>
maximum value of 1. Limit the minimum value to 0 as necessary.<br>
Comments regarding Step 410:<br>
Interchannel Angle Consistency is a measure of how similar the interchannel<br>
phase angles are within a subband over a frame period. If all bin interchannel angles of<br>
the subband are the same, the Interchannel Angle Consistency Factor is 1.0; whereas, if<br>
the interchannel angles are randomly scattered, the value approaches zero.<br>
The Subband Angle Consistency Factor indicates if there is a phantom image<br>
between the channels. If the consistency is low, then it is desirable to decorrelate the<br>
channels. A high value indicates a fused image. Image fusion is independent of other<br>
signal characteristics.<br>
It will be noted that the Subband Angle Consistency Factor, although an angle â€¢<br>
parameter, is determined indirectly from two magnitudes. If the interchannel angles are<br>
all the same, adding the complex values and then taking the magnitude yields the same<br>
result as taking all the magnitudes and adding them, so the quotient is 1. If the<br>
interchannel angles are scattered, adding the complex values (such as adding vectors<br>
having different angles) results in at least partial cancellation, so the magnitude of the<br>
sum is less than the sum of the magnitudes, and the quotient is less than 1.<br>
Following is a simple example of a subband having two bins:<br>
Suppose that the two complex bin values are (3 +j4) and(6+j8). (Same angle<br>
each case: angle = arctan (imag/real), so anglel = arctan (4/3) and angle2 = arctan (8/6) =<br>
arctan (4/3)). Adding complex values, sum = (9 + jl2), magnitude of which is<br>
square_root (81+144) = 15.<br>
The sum of the magnitudes is magnitude of (3 + j4)+magnitude of (6 + j8) = 5 +<br>
10 = 15. The quotient is therefore 15/15 = 1 = consistency (before 1/n normalization,<br>
would also be 1 after normalization) (Normalized consistency = (1 - 0.5) / (1 - 0.5) = 1.0).<br>
If one of the above bins has a different angle, say that the second one has complex<br>
â–  value (6-j 8), which has the same magnitude, 10. The complex sum is now (9 -j4),<br>
which has magnitude of squarejroot (81 +16) = 9.85, so the quotient is 9.85 / 15 = 0.66 =<br>
consistency (before normalization). To normalize, subtract 1/n = 1/2, and divide by (1-<br>
1/n) (normalized consistency = (0.66 - 0.5) / (1 - 0.5) = 0.32.)<br><br>
Although the above-described technique for determining a Subband Angle<br>
Consistency Factor has been found useful, its use is not critical. Other suitable techniques<br>
may be employed. For example, one could calculate a standard deviation of angles using<br>
standard formulae. In any case, it is desirable to employ amplitude weighting to<br>
minimize the effect of small signals on the calculated consistency value.<br>
In addition, an alternative derivation of the Subband Angle Consistency Factor<br>
may use energy (the squares of the magnitudes) instead of magnitude. This may be<br>
accomplished by squaring the magnitude from Step 403 before it is applied to Steps 405<br>
and 407.<br>
Step 411. Derive Subband Decorrelation Scale Factor.<br>
Derive a frame-rate Decorrelation Scale Factor for each subband as follows:<br>
a.. Let x = frame-rate Spectral-Steadiness Factor of Step 409f.<br>
b.	Let y = frame-rate Angle Consistency Factor of Step 410e.<br>
c.	Then the frame-rate Subband Decorrelation Scale Factor = (1 - x) * (1 - y),<br>
a number between 0 and 1.<br>
Comments regarding Step 411:<br>
The Subband Decorrelation Scale Factor is a function of the spectral-steadiness of<br>
signal characteristics over time in a subband of a channel (the Spectral-Steadiness Factor)<br>
and the consistency in the same subband of a channel of bin angles with respect to<br>
corresponding bins of a reference channel (the Interchannel Angle Consistency Factor).<br>
The Subband Decorrelation Scale Factor is high only if both the Spectral-Steadiness<br>
Factor and the Interchannel Angle Consistency Factor are low.<br>
As explained above, the Decorrelation Scale Factor controls the degree of<br>
envelope decorrelation provided in the decoder. Signals that exhibit spectral steadiness<br>
over time preferably should not be decorrelated by altering their envelopes, regardless of<br>
what is happening in other channels, as it may result in audible artifacts, namely wavering<br>
or warbling of the signal.<br>
Step 412. Derive. Subband Aniplitude.Scale Factors.<br>
From the subband frame energy values of Step 404 and from the subband frame<br>
energy values of all other channels (as may be obtained by a step corresponding to Step<br>
404 or an equivalent thereof), derive frame-rate Subband Amplitude Scale Factors as<br>
follows:<br><br>
a.	For each subband, sum the energy values per frame across all input channels.<br>
b.	Divide each subband energy value per frame, (from Step 404) by the sum of the<br>
energy values across all input channels (from Step 412a) to create values in the range<br>
ofOtol.<br>
c.	Convert each ratio to dB, in the range of -co to 0.<br>
d.	Divide by the scale factor granularity, which may be set at 1.5 dB, for example,<br>
change sign to yield a non-negative value, limit to a maximum value which may be, for<br>
example, 31 (i.e. 5-bit precision) and round to the nearest integer to create the quantized<br>
value. These values are the frame-rate Subband Amplitude Scale Factors and are<br>
conveyed as part of the sidechain information.<br>
e.	If the coupling frequency of the encoder is below about 1000 Hz, apply the<br>
subband frame-averaged or frame-accumulated magnitudes to a time smoother that<br>
operates on all subbands below that frequency and above the coupling frequency.<br>
Comments regarding Step 412e: See comments regarding step 404c except that<br>
in the case of Step 412e, there is no suitable subsequent step in which the time smoothing<br>
may alternatively be performed.<br>
Comments for Step 412:<br>
Although the granularity (resolution) and quantization precision indicated here<br>
have been found to be useful, they are not critical and other values may provide<br>
acceptable results.<br>
Alternatively, one may use amplitude instead of energy to generate the Subband<br>
Amplitude Scale Factors. If using amplitude, one would use dB=20*log(amplitude ratio),<br>
else if using energy, one converts to dB via dB=10*log(energy ratio), where amplitude<br>
ratio = square root (energy ratio).<br>
Step 413. Signal-Dependently Time Smooth Interchannel Subband Phase<br>
Angles.<br>
Apply signal-dependent temporal smoothing to subband frame-rate interchannel<br>
angles derived in Step 407f:	-	--..-.<br>
a.	Let v = Subband Spectral-Steadiness Factor of Step 409d.<br>
b.	Let w - corresponding Angle Consistency Factor of Step 410e.<br>
c.	Let x = (1 - v) * w. This is a value between 0 and 1, which is high if the<br>
Spectral-Steadiness Factor is low and the Angle Consistency Factor is high.<br><br>
-38-<br>
d.	Let y = 1 - x. y is high if Spectral-Steadiness Factor is high and Angle<br>
Consistency Factor is low.<br>
e.	Let z = yexp, where exp is a constant, which may be = 0.1. z is also in the<br>
range of 0 to 1, but skewed toward 1, corresponding to a slow time constant.<br>
f.	If the Transient Flag (Step 401) for the channel is set, set z = 0,<br>
corresponding to a fast time constant in the presence of a transient.<br>
g.	Compute Mm, a maximum allowable value of z, lim = 1 - (0.1 * w). This<br>
ranges from 0.9 if the Angle Consistency Factor is high to 1.0 if the Angle<br>
Consistency Factor is low (0).<br>
h. Limit z by lim as necessary: if (z &gt; lim) then z = lim.<br>
i. Smooth the subband angle of Step 407f using the value of z and a running<br>
smoothed value of angle maintained for each subband. If A = angle of Step 407f<br>
and RSA = running smoothed angle value as of the previous block, and NewRSA<br>
is the new value of the running smoothed angle, then: NewRSA = RSA * z + A *<br>
(1 - z). The value of RSA is subsequently set equal to NewRSA before<br>
processing the following block. New RSA is the signal-dependently time-<br>
smoothed angle output of Step 413.<br>
Comments regarding Step 413:<br>
When a transient is detected, the subband angle update time constant is set to 0,<br>
allowing a rapid subband angle change. This is desirable because it allows the normal<br>
angle update mechanism to use a range of relatively slow time constants, rrunimizing<br>
image wandering during static or quasi-'static signals, yet fast-changing signals are treated<br>
with fast time constants.<br>
Although other smoothing techniques and parameters may be usable, a first-order<br>
smoother implementing Step 413 has been found to be suitable. If implemented as a first-<br>
order smoother / lowpass filter, the variable "z" corresponds to the feed-forward<br>
coefficient (sometimes denoted "ffD"), while "(1-z)" corresponds to the feedback<br>
coefficient (sometimes denoted "fbl").	â– <br>
Step 414. Quantize Smoothed Interchannel Subband Phase Angles.<br>
Quantize the time-smoothed subband interchannel angles derived in Step 413i to<br>
obtain the Subband Angle Control Parameter:<br>
a. If the value is less than 0, add 2%, so that all angle values to be quantized are<br><br>
in the range 0 to 2%.<br>
b. Divide by the angle granularity (resolution), which may be 2K 164 radians,<br>
and round to an integer. The maximum value may be set at 63, corresponding to<br>
6-bit quantization.<br>
Comments regarding Step 414:<br>
The quantized value is treated as a non-negative integer, so an easy way to<br>
quantize the angle is to map it to a non-negative floating point number ((add 2n if less<br>
than 0, making the range 0 to (less than) 2%)), scale by the granularity (resolution), and<br>
round to an integer. Similarly, dequantizing that integer (which could otherwise be done<br>
with a simple table lookup), can be accomplished by scaling by the inverse of the angle<br>
granularity factor, converting a non-negative integer to a non-negative floating point<br>
angle (again, range 0 to 2K), after which it can be renormalized to the range Â±TC for further<br>
use. Although such quantization of the Subband Angle Control Parameter has been found<br>
to be useful, such a quantization is not critical and other quantizations may provide<br>
acceptable results.<br>
Step 415. Quantize Subband Decorrelation Scale Factors.<br>
Quantize the Subband Decorrelation Scale Factors produced by Step 411 to, for<br>
example, 8 levels (3 bits) by multiplying by 7.49 and rounding to the nearest integer.<br>
These quantized values are part of the sidechain information.<br>
Comments regarding Step 415:<br>
Although such quantization of the Subband Decorrelation Scale Factors has been<br>
found to be useful, quantization using the example values is not critical and other<br>
quantizations may provide acceptable results.<br>
Step 416. Dequantize Subband Angle Control Parameters.<br>
Dequantize the Subband Angle Control Parameters (see Step 414), to use prior to<br>
downmixing. .<br>
Comment regarding Step 416:<br>
Use of quantized values in the encoder helps maintain synchrony between the<br>
encoder and the decoder.<br>
Step 417. Distribute Frame-Rate Dequantized Subband Angle Control<br>
Parameters Across Blocks.<br>
In preparation for downmixing, distribute the once-per-frame dequantized<br><br>
Subband Angle Control Parameters of Step 416 across time to the subbands of each block<br>
within the frame.<br>
Comment regarding Step 417:<br>
The same frame value may be assigned to each block in the frame. Alternatively,<br>
it may be useful to interpolate the Subband Angle Control Parameter values across the<br>
blocks in a frame. Linear interpolation over time may be employed in the manner of the<br>
linear interpolation across frequency, as described below.<br>
Step 418. Interpolate block Subband Angle Control Parameters to Bins<br>
Distribute the block Subband Angle Control Parameters of Step 417 for each<br>
channel across frequency to bins, preferably using linear interpolation as described below.<br>
Comment regarding Step 418:<br>
If linear interpolation across frequency is employed, Step 418 minimizes phase<br>
angle changes from bin to bin across a subband boundary, thereby minimizing aliasing<br>
artifacts. Such linear interpolation may be enabled, for example, as described below<br>
following the description of Step 422. Subband angles are calculated independently of<br>
one another, each representing an average across a subband. Thus, there may be a large<br>
change from one subband to the next. If the net angle value for a subband is applied to all<br>
bins in the subband (a "rectangular" subband distribution), the entire phase change from<br>
one subband to a neighboring subband occurs between two bins. If there is a strong<br>
signal component there, there may be severe, possibly audible, aliasing. Linear<br>
interpolation, between the centers of each subband, for example, spreads the phase angle<br>
change over all the bins in the subband, minimizing the change between any pair of bins,<br>
so that, for example, the angle at the low end of a subband mates with the angle at the<br>
high end of the subband below it, while maintaining the overall average the same as the<br>
given calculated subband angle. In other words, instead of rectangular subband<br>
distributions, the subband angle distribution may be trapezoidally shaped.<br>
For example, suppose that the lowest coupled subband has one bin and a subband<br>
-angle of 20 degrees, the next subband has three bins and a subband angle of 40 degrees,<br>
and the third subband has five bins and a subband angle of 100 degrees. With no<br>
interpolation, assume that the first bin (one subband) is shifted by an angle of 20 degrees,<br>
the next three bins (another subband) are shifted by an angle of 40 degrees and the next<br>
five bins (a further subband) are shifted by an angle of 100 degrees. In that example,<br><br>
there is a 60-degree maximum change, from bin 4 to biri 5. With linear interpolation, the<br>
first bin still is shifted by'an angle of 20 degrees, the next 3 bins are shifted by about 30,<br>
40, and 50 degrees; and the next five bins are shifted by about 67, 83,100,117, and 133<br>
degrees. The average subband angle shift is the same, but the maximum bin-to-bin<br>
change is reduced to 17 degrees.<br>
Optionally, changes in amplitude from subband to subband, in connection with<br>
this and other steps described herein, such as Step 417 may also be treated in a similar<br>
interpolative fashion. However, it may not be necessary to do so because there tends to<br>
be more natural continuity in amplitude from one subband to the next<br>
Step 419. Apply Phase Angle Rotation to Bin Transform Values for Channel.<br>
Apply phase angle rotation to each bin transform value as follows:<br>
a.	Let x = bin angle for this bin as calculated in Step 418.<br>
b.	Let y = -x;<br>
c.	Compute z, a unity-magnitude complex phase rotation scale factor with<br>
angle y, z = cos (y) +j sin (y).<br>
d.	Multiply the bin value (a +jb) by z.<br>
Comments regarding Step 419:<br>
The phase angle rotation applied in the encoder is the inverse of the angle derived<br>
from the Subband Angle Control Parameter.<br>
Phase angle adjustments, as described herein, in an encoder or encoding process<br>
prior to downmixing (Step 420) have several advantages: (1) they minimize cancellations<br>
of the channels that are summed to a mono composite signal or matrixed to multiple<br>
channels, (2) they minimize reliance on energy normalization (Step 421), and (3) they<br>
precompensate the decoder inverse phase angle rotation, thereby reducing aliasing.<br>
The phase correction factors can be applied in the encoder by subtracting each<br>
subband phase correction value from the angles of each transform bin value in that<br>
subband. This is equivalent to multiplying each complex bin value by a complex number<br>
â–  with a magnitude of 1.0 and an angle equal to the negative, of .the phase correction factor.<br>
Note that a complex number of magnitude 1, angle A is equal to cos(A)+j sin(A). This<br>
latter quantity is calculated once for each subband of each channel, with A = -phase<br>
correction for this subband, then multiplied by each bin complex signal value to realize<br>
the phase shifted bin value.<br><br>
The phase shift is circular, resulting in circular convolution (as mentioned above).<br>
While circular convolution may be benign for some continuous signals, it may create<br>
spurious spectral components for certain continuous complex signals (such as a pitch<br>
pipe) or may cause blurring of transients if different phase angles are used for different<br>
subbands. Consequently, a suitable technique to avoid circular convolution may be<br>
employed or the Transient Flag may be employed such that, for example, when the<br>
Transient Flag is True, the angle calculation results may be overridden, and all subbands<br>
in a channel may use the same phase correction factor such as zero or a randomized<br>
value.<br>
Step 420. Downmix.<br>
Downmix to mono by adding the corresponding complex transform bins across<br>
channels to produce a mono composite channel or downmix to multiple channels by<br>
matrixing the input channels, as for example, in the manner of the example of FIG. 6, as<br>
described below.<br>
Comments regarding Step 420:<br>
In the encoder, once the transform bins of all the channels have been phase<br>
shifted, the channels are summed, bin-by-bin, to create the mono composite audio signal.<br>
Alternatively, the channels may be applied to a passive or active matrix that provides<br>
either a simple summation to one channel, as in the N:l encoding of FIG. 1, or to multiple<br>
channels. The matrix coefficients may be real or complex (real and imaginary).<br>
Step 421. Normalize.<br>
To avoid cancellation of isolated bins and over-emphasis of in-phase signals,<br>
normalize the amplitude of each bin of the mono composite channel to have substantially<br>
the same energy as the sum of the contributing energies, as follows:<br>
a.	Let x = the sum across channels of bin energies {i.e., the squares of the bin<br>
magnitudes computed in Step 403).<br>
b.	Let y = energy of corresponding bin of the mono composite channel,<br>
calculated as per-Step 403. .......<br>
c.	Let z = scale factor = square_root (x/y). If x = 0 then y is 0 and z is set to<br>
1.<br>
d.	Limit z to a maximum value of, for example, 100. If z is initially greater<br>
than 100 (implying strong cancellation from downmixing), add an arbitrary value,<br><br>
for example, 0.01 * square_root (x) to the real and imaginary parts of the mono<br>
composite bin, which will assure that it is large enough to be normalized by the<br>
following step.<br>
e. Multiply the complex mono composite bin value by z.<br>
Comments regarding Step 421:<br>
Although it is generally desirable to use the same phase factors for both encoding<br>
and decoding, even the optimal choice of a subband phase correction value may cause<br>
one or more audible spectral components within the subband to be cancelled during the<br>
encode downmix process because the phase shifting of step 419 is performed on a<br>
subband rather than a bin basis. In this case, a different phase factor for isolated bins in<br>
the encoder may be used if it is detected that the sum energy of such bins is much less<br>
than the energy sum of the individual channel bins at that frequency. It is generally not<br>
necessary to apply such an isolated correction factor to the decoder, inasmuch as isolated<br>
bins usually have little effect on overall image quality. A similar normalization may be<br>
applied if multiple channels rather than a mono channel are employed.<br>
Step 422. Assemble and Pack into Bitstream(s).<br>
The Amplitude Scale Factors, Angle Control Parameters, Decorrelation Scale<br>
Factors, and Transient Flags side channel information for each channel, along with the<br>
common mono composite audio or the matrixed multiple channels are multiplexed as may<br>
be desired and packed into one or more bitstreams suitable for the storage, transmission<br>
or storage and transmission medium or media.<br>
Comment regarding Step 422:<br>
The mono composite audio or the multiple channel audio may be applied to a<br>
data-rate reducing encoding process or device such as, for example, a perceptual encoder<br>
or to a perceptual encoder and an entropy coder {e.g., arithmetic or Huffman coder)<br>
(sometimes referred to as a "lossless" coder) prior to packing. Also, as mentioned above,<br>
the mono composite audio (or the multiple channel audio) and related sidechain<br>
information may be derived from multiple input channels only for audio .frequencies<br>
above a certain frequency (a "coupling" frequency). In that case, the audio frequencies<br>
below the coupling frequency in each of the multiple input channels may be stored,<br>
transmitted or stored and transmitted as discrete channels or may be combined or<br>
processed in some manner other than as described herein. Discrete or otherwise-<br><br>
combined channels may also be applied to a data reducing encoding process or device<br>
such as, for example, a perceptual encoder or a perceptual encoder and an entropy<br>
encoder. The mono composite audio (or the multiple channel audio) and the discrete<br>
multichannel audio may all be applied to an integrated perceptual encoding or perceptual<br>
and entropy encoding process or device prior to packing.<br>
Optional Interpolation Flag (Not shown in FIG. 4)<br>
Interpolation across frequency of the basic phase angle shifts provided by the<br>
Subband Angle Control Parameters may be enabled in the Encoder (Step 418) and/or in<br>
the Decoder (Step 505, below). The optional Interpolation Flag sidechain parameter may<br>
be employed for enabling interpolation in the Decoder. Either the Interpolation Flag or<br>
an enabling flag similar to the Interpolation Flag may be used in the Encoder. Note that<br>
because the Encoder has access to data at the bin level, it may use different interpolation<br>
values than the Decoder, which interpolates the Subband Angle Control Parameters in the<br>
sidechain information.<br>
The use of such interpolation across frequency in the Encoder or the Decoder may<br>
be enabled if, for example, either of the following two conditions are true:<br>
Condition 1. If a strong, isolated spectral peak is located at or near the<br>
boundary of two subbands that have substantially different phase rotation angle<br>
assignments.<br>
Reason: without interpolation, a large phase change at the boundary may<br>
introduce a warble in the isolated spectral component. By using interpolation to<br>
spread the band-to-band phase change across the bin values within the band, the<br>
amount of change at the subband boundaries is reduced. Thresholds for spectral<br>
peak strength, closeness to a boundary and difference in phase rotation from<br>
subband to subband to satisfy this condition may be adjusted empirically.<br>
Condition 2. If, depending on the presence of a transient, either the<br>
interchannel phase angles (no transient) or the absolute phase angles within a<br>
channel (transient), comprise a-good fit to. a linear progression.<br>
Reason:. Using interpolation to reconstruct the data tends to provider<br>
better fit to the original data. Note that the slope of the linear progression need<br>
not be constant across all frequencies, only within each subband, since angle data<br>
will still be conveyed to the decoder on a subband basis; and that forms the input<br><br>
to the Interpolator Step 418. The degree to which the data provides a good fit to<br>
satisfy this condition may also be determined empirically.<br>
Other conditions, such as those determined empirically, may benefit from<br>
interpolation across frequency. The existence of the two conditions just mentioned may<br>
be determined as follows:<br>
Condition 1. If a strong, isolated spectral peak is located at or near the<br>
boundary of two subbands that have substantially different phase rotation angle<br>
assignments:<br>
for the Interpolation Flag to be used by the Decoder, the Subband Angle<br>
Control Parameters (output of Step 414), and for enabling of Step 418 within the<br>
Encoder, the output of Step 413 before quantization may be used to determine the<br>
rotation angle from subband to subband.<br>
for both the Interpolation Flag and for enabling within the Encoder, the<br>
magnitude output of Step 403, the current DFT magnitudes, may be used to find<br>
isolated peaks at subband boundaries.<br>
Condition 2. If, depending on the presence of a transient, either the<br>
interchatmel phase angles (no transient) or the absolute phase angles within a<br>
channel (transient), comprise a good fit to a linear progression.:<br>
if the Transient Flag is not true (no transient), use the relative interchannel<br>
â€¢ bin phase angles from Step 406 for the fit to a linear progression determination,<br>
and<br>
if the Transient Flag is true (transient), us the channel's absolute phase<br>
angles from Step 403.<br>
Decoding<br>
The steps of a decoding process ("decoding steps") may be described as follows.<br>
With respect to decoding steps, reference is made to FIG. 5, which is in the nature of a<br>
hybrid flowchart and functional block diagram. For simplicity, the figure shows the<br>
derivation of sidechain.information components for one channel, it being understood that - -<br>
sidechain information components must be obtained for each channel unless the channel<br>
is a reference channel for such components, as explained elsewhere.<br>
Step 501. Unpack and Decode Sidechain Information.<br>
Unpack and decode (including dequantization), as necessary, the sidechain data<br><br>
components (Amplitude Scale Factors, Angle Control Parameters, Decorrelation Scale<br>
Factors, and Transient Flag) for each frame of each channel (one channel shown in FIG.<br>
5). Table lookups may be used to decode the Amplitude Scale Factors, Angle Control<br>
Parameter, and Decorrelation Scale Factors.<br>
Comment regarding Step 501: As explained above, if a reference channel is<br>
employed, the sidechain data for the reference channel may not include the Angle Control<br>
Parameters, Decorrelation Scale Factors, and Transient Flag.<br>
Step 502. Unpack and Decode Mono Composite or Multichannel Audio<br>
Signal.<br>
Unpack and decode, as necessary, the mono composite or multichannel audio<br>
signal information to provide DFT coefficients for each transform bin of the mono<br>
composite or multichannel audio signal.<br>
Comment regarding Step 502:<br>
Step 501 and Step 502 may be considered to be part of a single unpacking and<br>
decoding step. Step 502 may include a passive or active matrix.<br>
Step 503. Distribute Angle Parameter Values Across Blocks.<br>
Block Subband Angle Control Parameter values are derived from the dequantized<br>
frame Subband Angle Control Parameter values.<br>
Comment regarding Step 503:<br>
Step 503 may be implemented by distributing the same parameter value to every<br>
block in the frame.<br>
Step 504. Distribute Subband Decorrelation Scale Factor Across Blocks.<br>
Block Subband Decorrelation Scale Factor values are derived from the<br>
dequantized frame Subband Decorrelation Scale Factor values.<br>
Comment regarding Step 504;<br>
Step 504 may be implemented by distributing the same scale factor value to every<br>
block in the frame.<br>
. Step 505. Linearly Interpolate Across Frequency. . .<br>
Optionally, derive bin angles from the block subband angles of decoder Step 503<br>
by linear interpolation across frequency as described above in connection with encoder<br>
Step 418. Linear interpolation in Step 505 may be enabled when the Interpolation Flag is<br>
used and is true.<br><br>
Step 506. Add Randomized Phase Angle Offset (Technique 3).<br>
In accordance with Technique 3, described above, when the Transient Flag<br>
indicates a transient, add to the block Subband Angle Control Parameter provided by Step<br>
503, which may have been linearly interpolated across frequency by Step 505, a<br>
randomized offset value scaled by the Decorrelation Scale Factor (the scaling may be<br>
indirect as set forth in this Step):<br>
a.	Let y = block Subband Decorrelation Scale Factor.<br>
b.	Let z = ySKp, where exp is a constant, for example = 5. z will also be in the<br>
range of 0 to 1, but skewed toward 0, reflecting a bias toward low levels of<br>
randomized variation unless the Decorrelation Scale Factor value is high.<br>
c.	Let x = a randomized number between +1.0 and 1.0, chosen separately for<br>
each subband of each block.<br>
d.	Then, the value added to the block Subband Angle Control Parameter to add<br>
a randomized angle offset value according to Technique 3 is x * pi * z.<br>
Comments regarding Step 506:<br>
As will be appreciated by those of ordinary skill in the art, "randomized" angles<br>
(or "randomized amplitudes if amplitudes are also scaled) for scaling by the Decorrelatior<br>
Scale Factor may include not only pseudo-random and truly random variations, but also<br>
deterministically-generated variations that, when applied to phase angles or to phase<br>
angles and to amplitudes, have the effect of reducing cross-correlation between channels.<br>
Such "randomized" variations may be obtained in many ways. For example, a pseudo-<br>
random number generator with various seed values may be employed. Alternatively,<br>
truly random numbers may be generated using a hardware random number generator.<br>
Inasmuch as a randomized angle resolution of only about 1 degree may be sufficient,<br>
tables of randomized numbers having two or three decimal places (e.g. 0.84 or 0.844)<br>
may be employed. Preferably, the randomized values (between -1.0 and +1.0 with<br>
reference to Step 505c, above) are uniformly distributed statistically across each channel.<br>
Although the non-linear indirect scaling of Step 506 has been found to be useful,<br>
it is not critical and other suitable scalings may be employed - in particular other values<br>
for the exponent may be employed to obtain similar results.<br>
When the Subband Decorrelation Scale Factor value is 1, a full range of random<br>
angles from -% to + % are added (in which case the block Subband Angle Control<br><br>
Parameter values produced by Step 503 are rendered irrelevant). As the Subband<br>
Decorrelation Scale Factor value decreases toward zero, the randomized angle offset also<br>
decreases toward zero, causing the output of Step 506 to move toward the Subband Angle<br>
Control Parameter values produced by Step 503.<br>
If desired, the encoder described above may also add a scaled randomized offset<br>
in accordance with Technique 3 to the angle shift applied to a channel before<br>
downmixing. Doing so may improve alias cancellation in the decoder. It may also be<br>
beneficial for improving the synchronicity of the encoder and decoder.<br>
Step 507. Add Randomized Phase Angle Offset (Technique 2).<br>
In accordance with Technique 2, described above, when the Transient Flag does<br>
not indicate a transient, for each bin, add to all the block Subband Angle Control<br>
Parameters in a frame provided by Step 503 (Step 505 operates only when the Transient<br>
Flag indicates a transient) a different randomized offset value scaled by the Decorrelation<br>
Scale Factor (the scaling may be direct as set forth herein in this step):<br>
a.	Let y = block Subband Decorrelation Scale Factor.<br>
b.	Let x = a randomized number between +1.0 and â€”1.0, chosen separately for<br>
each bin of each frame.<br>
c.	Then, the value added to the block bin Angle Control Parameter to add a<br>
randomized angle offset value according to Technique 3 is x * pi * y.<br>
Comments regarding Step 507:<br>
See comments above regarding Step 505 regarding the randomized angle offset.<br>
Although the direct scaling of Step 507 has been found to be useful, it is not<br>
critical and other suitable scalings may be employed.<br>
To minimize temporal discontinuities, the unique randomized angle value for each<br>
bin of each channel preferably does not change with time. The randomized angle values<br>
of all the bins in a subband are scaled by the same Subband Decorrelation Scale Factor<br>
value, which is updated at the frame rate. Thus, when the Subband Decorrelation Scale<br>
â€¢ Factor value isl, a full range of random angles from ~% to + it are added (in which case .<br>
block subband angle values derived from the dequantized frame subband angle values are<br>
rendered irrelevant). As the Subband Decorrelation Scale Factor value diminishes toward<br>
zero, the randomized angle offset also diminishes toward zero. Unlike Step 504, the<br>
scaling in this Step 507 may be a direct function of the Subband Decorrelation Scale<br><br>
Factor value. For example, a Subband Decorrelation Scale Factor value of 0.5<br>
proportionally reduces every random angle variation by 0.5.<br>
The scaled randomized angle value may then be added to the bin angle from<br>
decoder Step 506. The Decorrelation Scale Factor value is updated once per frame. In<br>
the presence of a Transient Flag for the frame, this step is skipped, to avoid transient<br>
prenoise artifacts.<br>
If desired, the encoder described above may also add a scaled randomized offset<br>
in accordance with Technique 2 to the angle shift applied before downmixing.. Doing so<br>
may improve alias cancellation in the decoder. It may also be beneficial for improving<br>
the synchronicity of the encoder and decoder.<br>
Step 508. Normalize Amplitude Scale Factors.<br>
Normalize Amplitude Scale Factors across channels so that they sum-square to 1.<br>
Comment regarding Step 508:<br>
For example, if two channels have dequantized scale factors of-3.0 dB (= 2 *<br>
granularity of 1.5 dB) (.70795), the sum of the squares is 1.002. Dividing each by the<br>
square root of 1.002 = 1.001 yields two values of .7072 (-3.01 dB).<br>
Step 509. Boost Subband Scale Factor Levels (Optional).<br>
Optionally, when the Transient Flag indicates no transient, apply a slight<br>
additional boost to Subband Scale Factor levels, dependent on Subband Decorrelation<br>
Scale Factor levels: multiply each normalized Subband Amplitude Scale Factor by a<br>
small factor (e.g., 1 + 0.2 * Subband Decorrelation Scale Factor). When the Transient<br>
Flag is True, skip this step.<br>
Comment regarding Step 509:<br>
This.step may be useful because the decoder decorrelation Step 507 may result in<br>
slightly reduced levels in the final inverse filterbank process.<br>
Step 510. Distribute Subband Amplitude Values Across Bins.<br>
Step 510 may be implemented by distributing the same subband amplitude scale<br>
factor value to every bin in the subband; .--.-...â€¢<br>
Step 510a. Add Randomized Amplitude Offset (Optional)<br>
Optionally, apply a randomized variation to the normalized Subband Amplitude<br>
Scale Factor dependent on Subband Decorrelation Scale Factor levels and the Transient<br>
Flag. In the absence of a transient, add a Randomized Amplitude Scale Factor that does<br><br>
not change with time on a bin-by-bin basis (different from bin to bin), and, in the<br>
presence of a transient (in the frame or block), add a Randomized Amplitude Scale Factor<br>
that changes on a block-by-block basis (different from block to block) and changes from<br>
subband to subband (the same shift for all bins in a subband; different from subband to<br>
subband). Step 510a is not shown in the drawings.<br>
Comment regarding Step 510a:<br>
Although the degree to which randomized amplitude shifts are added may be<br>
controlled by the Decorrelation Scale Factor, it is believed that a particular scale factor<br>
value should cause less amplitude shift than the corresponding randomized phase shift<br>
resulting from the same scale factor value in order to avoid audible artifacts.<br>
Step 511. Upmix.<br>
a.	For each bin of each output channel, construct a complex upmix scale<br>
factor from the amplitude of decoder Step 508 and the bin angle of decoder<br>
Step 507: (amplitude * (cos (angle) +j sin (angle)).<br>
b.	For each output channel, multiply the complex bin value and the<br>
complex upmix scale factor to produce the upmixed complex output bin value of<br>
each bin of the channel.<br>
Step 512. Perform Inverse DFT (Optional).<br>
Optionally, perform an inverse DFT transform on the bins of each output channel<br>
to yield multichannel output PCM values. As is well known, in connection with such an<br>
inverse DFT transformation, the individual blocks of time samples are windowed, and<br>
adjacent blocks are overlapped and added together in order to reconstruct the final<br>
continuous time output PCM audio signal.<br>
Comments regarding Step 512:<br>
A decoder according to the present invention may not provide PCM outputs. In<br>
the case where the decoder process is employed only above a given coupling frequency,<br>
and discrete MDCT coefficients are sent for each channel below that frequency, it may be<br>
desirable to convert the .DFT coefficients derived by the decoder upmixing Steps 511a..<br>
and 51 lb to MDCT coefficients, so that they can be combined with the lower frequency<br>
discrete MDCT coefficients and requantized in order to provide, for example, a bitstream<br>
compatible with an encoding system that has a large number of installed users, such as a<br>
standard AC-3 SP/DIF bitstream for application to an external device where an inverse<br><br>
transform may be performed. An inverse DFT transform may be applied to ones of the<br>
output channels to provide PCM outputs.<br>
Section 8.2.2 oftheA/52A Document<br>
With Sensitivity Factor "F" Added<br>
8.2.2. Transient detection<br>
Transients are detected in the full-bandwidth channels in order to decide when to<br>
switch to short length audio blocks to improve pre-echo performance. High-pass filtered<br>
versions of the signals are examined for an increase in energy from one sub-block time-<br>
segment to the next. Sub-blocks are examined at different time scales. If a transient is<br>
detected in the second half of an audio block in a channel that channel switches to a short<br>
block. A channel that is block-switched uses the D45 exponent strategy [i.e., the data has<br>
a coarser frequency resolution in order to reduce the data overhead resulting from the<br>
increase in temporal resolution].<br>
â€¢ The transient detector is used to determine when to switch from a long transform<br>
block (length 512), to the short block (length 256). It operates on 512 samples for every<br>
audio block. This is done in two passes, with each pass processing 256 samples. Transient<br>
detection is broken down into four steps: 1) high-pass filtering, 2) segmentation of the<br>
block into submultiples, 3) peak amplitude detection within each sub-block segment, and<br>
4) threshold comparison. The transient detector outputs a flag blksw[n] for each full-<br>
bandwidth channel, which when set to "one" indicates the presence of a transient in the<br>
second half of the 512 length input block for the corresponding channel.<br>
1)	High-pass filtering: The high-pass filter is implemented as a cascaded<br>
biquad direct form IIIIR filter with a cutoff of 8 kHz.<br>
2)	Block Segmentation: The block of 256 high-pass filtered samples are<br>
segmented into a hierarchical tree of levels in which level 1 represents the 256<br>
length block, level 2 is two segments of length 128, and level 3 is four segments<br>
of length 64.<br>
.3) Peak Detection: The sample with the largest magnitude is identified for<br>
each segment on every level of the hierarchical tree. The peaks for a single level<br>
are found as follows:<br>
P[j][k] = max(x(n))<br>
for n = (512 x (k-1) / 2Aj), (512 x (k-1) / 2Aj) + 1, ...(512 x k / 2Aj) - 1<br><br>
andk=l,...52AG-l);<br>
where: x(n) = the nth sample in the 256 length block<br>
j = 1,2, 3 is the hierarchical level number<br>
k = the segment number within level j<br>
Note that PQ][0], (i.e., k=0) is defined to be the peak of the last<br>
segment on level j of the tree calculated immediately prior to the current<br>
tree. For example, P[3][4] in the preceding tree is P[3][0] in the current<br>
tree.<br>
4) Threshold Comparison: The first stage of the threshold comparator<br>
checks to see if there is significant signal level in the current block. This is done<br>
by comparing the overall peak value P[1][1] of the current block to a "silence<br>
threshold". If P[1][1 j is below this threshold then a long block is forced. The silence<br>
threshold value is 100/32768. The next stage of the comparator checks the relative<br>
peak levels of adjacent segments on each level of the hierarchical tree. If the peak<br>
ratio of any two adjacent segments on a particular level exceeds a pre-defined<br>
threshold for that level, then a flag is set to indicate the presence of a transient in<br>
the current 256-length block. The ratios are compared as follows:<br>
. mag(Pp][k]) x T[j] &gt; (F * mag(P[i][(k-l)])) [Note the "F" sensitivity<br>
factor]<br>
where: T[j] is the pre-defined threshold for level j, defined as:<br>
T[l] = .l<br>
T[2] = .075<br>
T[3] = .05<br>
If this inequality is true for any two segment peaks on any level,<br>
then a transient is indicated for the first half of the 512 length input block.<br>
The second pass through this process determines the presence of transients<br>
in the second half of the 512 length input block.<br>
N:MEncoding<br>
Aspects of the present invention are not limited to N: 1 encoding as described in<br>
connection with FIG. 1. More generally, aspects of the invention are applicable to the<br>
transformation of any number of input channels (n input channels) to any number of<br><br>
output channels (m output channels) in the manner of FIG. 6 (i.e., N:M encoding).<br>
Because in many common applications the number of input channels n is greater than the<br>
number of output channels m, the N:M encoding arrangement of FIG. 6 will be referred ,<br>
to as "downmixing" for convenience in description.<br>
Referring to the details of FIG. 6, instead of summing the outputs of Rotate Angle<br>
8 and Rotate Angle 10 in the Additive Combiner 6 as in the arrangement of FIG. 1, those<br>
outputs may be applied to a downmix matrix device or function 6' ("Downmix Matrix").<br>
Downmix Matrix 6' may be a passive or active matrix that provides either a simple<br>
summation to one channel, as in the N:l encoding of FIG. 1, or to multiple channels. The<br>
matrix coefficients may be real or complex (real and imaginary). Other devices and<br>
functions in FIG. 6 may be the same as in the FIG. 1 arrangement and they bear the same<br>
reference numerals.<br>
Downmix Matrix 6' may provide a hybrid frequency-dependent function such that<br>
it provides, for example, mn-a channels in a frequency range fl to f2 and ma-s channels<br>
in. a frequency range f2 to f3. For example, below a coupling frequency of, for example,<br>
1000 Hz the Downmix Matrix 6' may provide two channels and above the coupling<br>
frequency the Downmix Matrix 6' may provide one channel. By employing two channels<br>
below the coupling frequency, better spatial fidelity may be obtained, especially if the<br>
two channels represent horizontal directions (to match the horizontality of the human<br>
ears).<br>
Although FIG. 6 shows the generation of the same sidechain information for each<br>
channel as in the FIG. 1 arrangement, it may be possible to omit certain ones of the<br>
sidechain information when more than one channel is provided by the output of the<br>
Downmix Matrix 6'. In some cases, acceptable results may be obtained when only the<br>
amplitude scale factor sidechain information is provided by the FIG. 6 arrangement.<br>
Further details regarding sidechain options are discussed below in connection with the<br>
descriptions of FIGS. 7, 8 and 9.<br>
- - As just mentioned above, the multiple channels generated by the Downmix Matrix<br>
6' need not be fewer than the number of input channels n. When the purpose of an<br>
encoder such as in FIG. 6 is to reduce the number of bits for transmission or storage, it is<br>
likely that the number of channels produced by downmix matrix 6' will be fewer than the<br>
number of input channels n. However, the arrangement of FIG. 6 may also be used as an<br><br>
"upmixer." In that case, there may be applications in which the number of channels m<br>
produced by the Downmix Matrix 6' is more than the number of input channels n.<br>
Encoders as described in connection with the examples of.FIGS. 2, 5 and 6 may<br>
also include their own local decoder or decoding function in order to determine if the<br>
audio information and the sidechain information, when decoded by such, a decoder, would<br>
provide suitable results. The results of such a determination could be used to improve the<br>
parameters by employing, for example, a recursive process. In a block encoding and<br>
decoding system, recursion calculations could be performed, for example, on every block<br>
before the next block ends in order to minimize the delay in fransinitting a block of audio<br>
information and its associated spatial parameters.<br>
An arrangement in which the encoder also includes its own decoder or decoding<br>
function could also be employed advantageously when spatial parameters are not stored<br>
or sent only for certain blocks. If unsuitable decoding would result from not sending<br>
spatial-parameter sidechain information, such sidechain information would be sent for the<br>
particular block. In this case, the decoder may be a modification of the decoder or<br>
decoding function of FIGS. 2, 5 or 6 in that the decoder would have both the ability to<br>
recover spatial-parameter sidechain information for frequencies above the coupling<br>
frequency from the incoming bitstream but also to generate simulated spatial-parameter<br>
sidechain information from the stereo information below the coupling frequency.<br>
In a simplified alternative to such local-decoder-incorporating encoder examples,<br>
rather than having a local decoder or decoder function, the encoder could simply check to<br>
determine if there were any signal content below the coupling frequency (determined in<br>
any suitable way, for example, a sum of the energy in frequency bins through the<br>
frequency range), and, if not, it would send or store spatial-parameter sidechain<br>
information rather than not doing so if the energy were above the threshold. Depending<br>
on the encoding scheme, low signal information below the coupling frequency may also<br>
result in more bits being available for sending sidechain information.<br>
M:NDecoding' . ,-<br>
A more generalized form of the arrangement of FIG. 2 is shown in FIG. 7,<br>
wherein an upmix matrix function or device ('TJpmix Matrix") 20 receives the 1 to m<br>
channels generated by the arrangement of FIG. 6. The Upmix Matrix 20 may be a<br>
passive matrix. It may be, but need not be, the conjugate transposition (i. e., the<br><br>
complement) of the Downmix Matrix 6' of the FIG. 6 arrangement. Alternatively, the<br>
Uprrdx Matrix 20 may be an active matrix - a variable matrix or a passive matrix in<br>
combination with a variable matrix. If an active matrix decoder is employed, in its<br>
relaxed or quiescent state it may be the complex conjugate of the Downmix Matrix or it<br>
may be independent of the Downmix Matrix. The sidechain information may be applied<br>
as shown in FIG. 7 so as to control the Adjust Amplitude, Rotate Angle, and (optional)<br>
Interpolator functions or devices. In that case, the Upmix Matrix, if an active matrix,<br>
operates independently of the sidechain information and responds only to the channels<br>
applied to it. Alternatively, some or all of the sidechain information may be applied to<br>
the active matrix to assist its operation. In that case, some or all of the Adjust Amplitude,<br>
Rotate Angle, and Interpolator functions or devices may be omitted. The Decoder<br>
example of FIG. 7 may also employ the alternative of applying a degree of randomized<br>
amplitude variations under certain signal conditions, as described above in connection<br>
with FIGS. 2 and 5.<br>
When Upmix Matrix 20 is an active matrix, the arrangement of FIG. 7 may be<br>
characterized as a "hybrid matrix decoder" for operating in a "hybrid matrix<br>
encoder/decoder system." "Hybrid" in this context refers to the fact that the decoder may<br>
derive some measure of control information from its input audio signal (i.e., the active<br>
matrix responds to spatial information encoded in the channels applied to it) and a further<br>
measure of control information from spatial-parameter sidechain information. Other<br>
elements of FIG. 7 are as in the arrangement of FIG. 2 and bear the same reference<br>
numerals.<br>
Suitable active matrix decoders for use in a hybrid matrix decoder may include<br>
active matrix decoders such as those mentioned above<br>
including, for example, matrix decoders known as "Pro Logic" and "Pro Logic II"<br>
decoders ("Pro Logic" is a trademark of Dolby Laboratories Licensing Corporation).<br>
Alternative Decorrelation<br>
FIGS. 8 and 9-show variationson the. generalized Decoder of FIG. 7. In<br>
particular, both the arrangement of FIG. 8 and the arrangement of FIG. 9 show<br>
alternatives to the decorrelation technique of FIGS. 2 and 7. In FIG. 8, respective<br>
decorrelator functions or devices ("Decorrelators") 46 and 48 are in the time domain,<br>
each following the respective Inverse Filterbank 30 and 36 in their channel. In FIG. 9,<br><br>
respective decorrelator functions or devices ("Decorrelators") 50 and 52 are in the<br>
frequency domain, each preceding the respective Inverse Filterbank 30 and 36 in their<br>
channel. In both the FIG. 8 and FIG. 9 arrangements, each of the Decorrelators (46,48,<br>
50,52) has a unique characteristic so that their outputs are mutually decorrelated with<br>
respect to each other. The Decorrelation Scale Factor may be used to control, for<br>
example, the ratio of decorrelated to uncorrelated signal provided in each channel.<br>
Optionally, the Transient Flag may also be used to shift the mode of operation of the<br>
Decorrelator, as is explained below. In both the FIG. 8 and FIG. 9 arrangements, each<br>
Decorrelator may be a Schroeder-type reverberator having its own unique filter<br>
characteristic, in which the amount or degree of reverberation is controlled by the<br>
decorrelation scale factor (implemented, for example, by controlling the degree to which<br>
the Decorrelator output forms a part of a linear combination of the Decorrelator input and<br>
output). Alternatively, other controllable decorrelation techniques may be employed<br>
either alone or in combination with each other or with a Schroeder-type reverberator.<br>
Schroeder-type reverberators are well known and may trace their origin to two journal<br>
papers: "'Colorless' Artificial Reverberation" by M.R. Schroeder and B.F. Logan, IRE<br>
Transactions on Audio, vol. AU-9, pp. 209-214,1961 and "Natural Sounding Artificial â€¢<br>
Reverberation" by M.R. Schroeder, JournalA.E.S., July 1962, vol. 10, no. 2, pp. 219-223.<br>
When the Decorrelators 46 and 48 operate in the time domain, as in the FIG. 8<br>
arrangement, a single (i.e., wideband) Decorrelation Scale Factor is required. This may<br>
be obtained by any of several ways. For example, only a single Decorrelation Scale<br>
Factor may be generated in the encoder of FIG. 1 or FIG. 7. Alternatively, if the encoder<br>
of FIG. 1 or FIG. 7 generates Decorrelation Scale Factors on a subband basis, the<br>
Subband Decorrelation Scale Factors may be amplitude or power summed in the encoder<br>
of FIG. 1 or FIG. 7 or in the decoder of FIG. 8.<br>
When the Decorrelators 50 and 52 operate in the frequency domain, as in the FIG.<br>
9 arrangement, they may receive a decorrelation scale factor for each subband or groups<br>
of subbands and, concomitantly, provide a commensurate degree of decorrelation for such,<br>
subbands or groups of subbands.<br>
The Decorrelators 46 and 48 of FIG. 8 and the Decorrelators 50 and 52 of FIG. 9<br>
may optionally receive the Transient Flag. In the time-domain Decorrelators of FIG. 8,<br>
the Transient Flag may be employed to shift the mode of operation of the respective<br><br>
Decorrelator. For example, the Decorrelator may operate as a Schroeder-type<br>
reverberator in the absence of the transient flag but upon its receipt and for a short<br>
subsequent time period, say 1 to 10 milliseconds, operate as a fixed delay. Each channel<br>
may have a predetermined fixed delay or the delay may be varied in response to a<br>
plurality of transients within a short time period. In the frequency-domain Decorrelators<br>
of FIG. 9, the transient flag may also be employed to shift the mode of operation of the<br>
respective Decorrelator. However, in this case, the receipt of a transient flag may, for<br>
example, trigger a short (several milliseconds) increase in amplitude in the channel in<br>
i<br>
which the flag occurred.<br>
In both the FIG. 8 and 9 arrangements, an Interpolator 27 (33), controlled by the<br>
optional Transient Flag, may provide interpolation across frequency of the phase angles<br>
output of Rotate Angle 28 (33) in a manner as described above.<br>
As mentioned.above, when two or more channels are sent in addition to sidechain<br>
information, it may be acceptable to reduce the number of sidechain parameters. For<br>
example, it may be acceptable to send only the Amplitude Scale Factor, in which case the<br>
decorrelation and angle devices or functions in the decoder may be omitted (in that case,<br>
FIGS. 7, 8 and 9 reduce to the same arrangement).<br>
Alternatively, only the amplitude scale factor, the Decorrelation Scale Factor, and,<br>
optionally, the Transient Flag may be sent. In that case, any of the FIG. 7, 8 or 9<br>
arrangements may be employed (omitting the Rotate Angle 28 and 34 in each of them).<br>
As another alternative, only the amplitude scale factor and the angle control<br>
parameter may be sent. In that case, any of the FIG. 7, 8 or 9 arrangements may be<br>
employed (omitting the Decorrelator 38 and 42 of FIG. 7 and 46,48, 50, 52 of FIGS. 8<br>
and 9).<br>
As in FIGS. 1 and 2, the arrangements of FIGS. 6-9 are intended to show any<br>
number of input and output channels although, for simplicity in presentation, only two<br>
channels are shown.<br>
It should be understood that implementation of other variations and modifications<br>
of the invention and its various aspects will be apparent to those skilled in the art, and that<br>
the invention is not limited by these specific embodiments described. It is therefore<br>
contemplated to cover by the present invention any and all modifications, variations, or<br>
equivalents that fall within the true spirit and scope of the basic underlying principles<br>
disclosed herein.<br><br>
WE CLAIM:<br>
1.	A method for encoding N input audio channels into M encoded audio channels, where<br>
N is two or more, and a set of one or more spatial parameters relating to the N input audio<br>
channels, the method involving:<br>
a)	deriving M audio signals from said N input audio channels,<br>
b)	determining a set of one or more spatial parameters indicative of spatial properties<br>
of the N input audio channels, and<br>
c)	generating M encoded signals comprising the M audio signals derived in step a)<br>
and the set of spatial parameters determined in step b),<br>
characterized in that M is one or more and step b) comprises determining said set of one<br>
or more spatial parameters such that it comprises a first parameter responsive to measures of<br>
mtrachannel spectral steadiness, which is a measure of the extent to which spectral<br>
components change over time, and interchannel phase angle similarity.<br>
2.	The method as claimed in claim 1 wherein the measure of intrachannel spectral<br>
steadiness is a measure of changes overtime of the amplitude or energy of spectral<br>
components in a first input channel.<br>
3.	The method as claimed in claim 1 or claim 2 wherein the measure of interchannel phase<br>
angle similarity is a measure of the similarity of the interchannel phase angles of spectral<br>
components of a first input audio channel relative to the corresponding spectral components<br>
of another input audio channel.<br>
4.	The method as claimed in any one of claims 1 to 3 wherein the set of parameters<br>
comprises a parameter responsive to the phase angles of spectral components in a first input<br>
audio channel relative to phase angles of corresponding spectral components in another input<br>
audio channel.<br><br>
5.	The method as claimed in claim 4 wherein said M audio signals are derived from said N<br>
input audio channels by a process that involves modifying at least one of said N input audio<br>
channels in response to a function of said parameter.<br>
6.	The method as claimed in claim 5 wherein said modifying modifies phase angles of<br>
spectral components of said at least one of said N input audio channels.<br>
7.	The method as claimed in any one of claims 1 to 6 wherein multiple audio signals are<br>
derived from said N input audio channels by a process that involves passively or actively<br>
matrixing said N input audio channels.<br>
8.	The method as claimed in any one of claims 1 to 7 wherein the set of parameters<br>
comprises a parameter responsive to the occurrence of a transient in a first input audio<br>
channel.<br>
9.	The method as claimed in any one of claims 1 to 8 wherein the set of parameters<br>
comprises a parameter responsive to the amplitude or energy of a first input audio channel.<br>
10.	The method as claimed in any one of claims 1 to 9 wherein the measure of intra-channel<br>
spectral steadiness are with respect to spectral components in a frequency band of said first<br>
input channel, and the measure of the interchannel phase angle similarity are with respect to<br>
spectral components in said frequency band of said first input channel relative to spectral<br>
components in a corresponding frequency band of said another input channel.<br>
11.	A method for decoding M encoded audio channels representing N audio channels,<br>
where N is two or more, and a set of one or more spatial parameters relating to the N audio<br>
channels, the method involving:<br>
a) receiving said M encoded audio channels and said set of spatial parameters<br>
indicative of spatial properties of the N audio channels,<br><br>
b)	deriving N audio channels from said M encoded audio channels, wherein an audio<br>
signal in each audio channel is divided into a plurality of frequency bands, wherein each<br>
band comprises one or more spectral components, and<br>
c)	generating a multichannel output signal from the N audio channels and the spatial<br>
parameters,<br>
characterized in that<br>
M is one or more and,<br>
said set of spatial parameters comprise a first parameter responsive to measures of<br>
intrachannel spectral steadiness, which is a measure of the extent to which spectral<br>
components change overtime and interchannel phase angle similarity, and<br>
end step c) comprises shifting the phase angles of spectral components in the audio<br>
signal in at least one of the N audio channels in response to one or more of said spatial<br>
parameters, wherein said shifting is at least partly in accordance with said first parameter.<br>
12.	The method as claimed in claim 11 wherein said N audio channels are derived from said<br>
M encoded audio channels by a process that involves passively or actively dematrixing said<br>
M encoded audio channels.<br>
13.	The method as claimed in claim 11 where M is two or more and said N audio channels<br>
are derived from said M encoded audio channels by a process that involves actively<br>
dematrixing said M encoded audio channels.<br>
14.	The method as claimed in claim 13 wherein the dematrixing operates at least partly in<br>
response to characteristics of said M encoded audio channels.<br>
15.	The method as claimed in claim 13 or claim 14 wherein the dematrixing operates at least<br>
partly in response to one or one of said spatial parameters.<br><br>
16.	The method as claimed in claim 11 wherein said shifting is performed in accordance<br>
with a first mode of operation or a second mode of operation, shifting the phase angles of<br>
spectral components in the audio signal in accordance with a first mode of operation<br>
comprises shifting the phase angles of spectral components in the audio signal in accordance<br>
with a first frequency resolution and a first time resolution, and shifting the phase angles of<br>
spectral components in the audio signal in accordance with a second mode of operation<br>
comprises shifting the phase angles of spectral components in the audio signal in accordance<br>
with a second frequency resolution and a second time resolution.<br>
17.	The method as claimed in claim 16 wherein the second time resolution is finer than the<br>
first time resolution.<br>
18.	The method as claimed in claim 16 wherein the second frequency resolution is coarser<br>
than or the same as the first frequency resolution, and the second time resolution is finer than<br>
the first time resolution.<br>
19.	The method as claimed in claim 17 wherein the first frequency resolution is finer than<br>
the frequency resolution of the spatial parameters.<br>
20.	The method as claimed in claim 18 or claim 19 wherein the second time resolution is<br>
finer than the time resolution of the spatial parameters.<br>
21.	The method as claimed in claim 11 wherein said shifting is performed in accordance<br>
with a first mode of operation or a second mode of operation, said first mode of operation<br>
comprises shifting the phase angles of spectral components in at least one or more of the<br>
plurality of frequency bands, wherein each spectral component is shifted by a different angle,<br>
which angle is substantially time invariant, and said second mode of operation comprises<br>
shifting the phase angles of all the spectral components in said at least one or more of the<br><br>
plurality of frequency bands by the same angle, wherein a different phase angle shift is<br>
applied to each frequency band in which phase angles are shifted and which phase angle shift<br>
varies with time.<br>
22.	The method as claimed in claim 21 wherein in said second mode of operation the phase<br>
angles of spectral components within a frequency band are interpolated to reduce phase<br>
angle changes from spectral component to spectral component across a frequency band<br>
boundary.<br>
23.	The method as claimed in claim 11 wherein said shifting is performed in accordance<br>
with a first mode of operation or a second mode of operation, the first mode of operation<br>
comprises shifting the phase angles of spectral components in at least one or more of the<br>
plurality of frequency bands, wherein each spectral component is shifted by a different angle,<br>
which angle is substantially time invariant, and said second mode of operation comprises no<br>
shifting of the phase angles of spectral components.<br>
24.	The method as claimed in any one of claims 16 to 23 wherein said shifting the phase<br>
angles of spectral components comprises a randomized shifting.<br>
25.	The method as claimed in claim 24 wherein the amount of said randomized shifting is<br>
controllable.<br>
26.	The method as claimed in any one of claims 16 to 25 comprising shifting the<br>
magnitudes of spectral components in the audio signal in response to one or ones of said<br>
spatial parameters in accordance with a first mode of operation and a second mode of<br>
operation.<br>
27.	The method as claimed in claim 26 wherein shifting the magnitude comprises a<br>
randomized shifting.<br><br>
28.	The method as claimed in claim 26 or claim 27 wherein the amount of shifting the<br>
magnitude is controllable.<br>
29.	The method as claimed in any one of claims 16 to 28 wherein the selection of the mode<br>
of operation is responsive to said audio signal.<br>
30.	The method as claimed in claim 29 wherein the selection of the mode of operation is<br>
responsive to the presence of a transient in said audio signal.<br>
31.	The method as claimed in any one of claims 16 to 30 wherein the selection of the mode<br>
of operation is responsive to a control signal.<br>
32.	The method as claimed in any one of claims 11 to 31 wherein said multichannel output<br>
signal is in the time domain.<br>
33.	The method as claimed in any one of claims 11 to 31 wherein said multichannel output<br>
signal is in the frequency domain.<br>
34.	A method for decoding M encoded audio channels representing N audio channels,<br>
where N is two or more, and a set of one or more spatial parameters, the method involving:<br><br>
a)	receiving said M encoded audio channels and said set of spatial parameters,<br>
b)	deriving N audio channels from said M encoded channels, wherein an audio signal<br>
in each audio channel is divided into a plurality of frequency bands, wherein each band<br>
comprises one or more spectral components, and<br>
c)	generating a multichannel output signal from the N audio channels and the spatial<br>
parameters, whereby<br>
M is two or more and,<br>
at least one of said N audio signals is a correlated signal derived from a weighted<br>
combination of at least two of said M encoded audio channels,<br><br>
said set of spatial parameters comprises a first parameter indicative of the amount of an<br>
uncorrelated signal to mix with a derived audio channel and,<br>
step c) involves controlling the proportion of correlated to uncorrelated signal in at least<br>
one of the N audio channels in response to one or ones of said spatial parameters, wherein<br>
said controlling is at least partly in accordance with said first parameter.<br>
35: The method as. claimed in claim 34 wherein step c) involves deriving said at least one<br>
uncorrelated signal is generated by applying an artificial reverberation filter to a correlated<br>
signal.<br>
36.	The method as claimed in claim 35 wherein step c) involves deriving said at least one<br>
uncorrelated signal by applying a plurality of artificial reverberation filters is used to<br>
generate a plurality of uncorrelated signals.<br>
37.	The method as claimed in claim 36 wherein each of the plurality of artificial<br>
reverberation filters uses has its own unique filter characteristic.<br>
38.	The method as claimed in claim 34 wherein said controlling in step c) involves deriving<br>
a separate proportion of correlated to uncorrelated signal is derived for each of said plurality<br>
of frequency bands, at least partly in accordance with said first parameter.<br>
39.	The method as claimed in claim 34 wherein said N audio channels are derived from said<br>
M encoded audio channels by a process that involves dematrixing said M audio channels.<br>
40.	The method as claimed in claim 39 wherein the dematrixing operates at least partly in<br>
response to one or ones of said spatial parameters.<br>
41.	The method as claimed in any of claims 34 to 40 comprising shifting the magnitudes of<br>
spectral components in the audio signal in response to one or ones of said spatial parameters.<br><br>
42.	The method as claimed in any of claims 34 to 41 wherein said multichannel output<br>
signal is in the time domain.<br>
43.	The method as claimed in any of claims 34 to 41 wherein said multichannel output<br>
signal is in the frequency domain.<br>
44.	The method as claimed in any of claims 34 to 43 wherein N is 3 or more.<br>
45.	An apparatus comprising means adapted to carry out each of the steps of any one of the<br>
methods as claimed in claims 34 to 44.<br><br><br><br>
ABSTRACT<br><br><br>
A Method for Encoding N Input Audio Channels into M Encoded<br>
Audio Channels and a Method for Decoding M Encoded<br>
Audio Channels Representing N Audio Channels<br>
Multiple channels of audio are combined either to a monophonic composite signal<br>
(Figure 1, reference 6) or to multiple channels of audio (Figure 6, reference 6') along with<br>
related auxiliary information from which multiple channels of audio are reconstructed<br>
(figures 2, 7, 8, 9), including improved downmixing of multiple audio channels to a<br>
monophonic audio signal (Figure 1, reference 6) or to multiple audio channels (Figure 6,<br>
reference 6') and improved decorrelation (Figures 2 and 7, references 38 and 42, Figure 8,<br>
references 46 and 48, and Figure 9, references 50 and 52) of multiple audio channels derived<br>
from a monophonic audio channel or from multiple audio channels. Aspects of the disclosed<br>
invention are usable in audio encoders (figures 1 and 6), decoders figures 2, 7, 8, and 9),<br>
encode/decode systems downmixers (figure 1, reference 6, figure 6, reference 6'), upmixers<br>
(figure 7, 8 and 9, reference 20), and decorelators (Figures 2 and 7, references 38 and 42,<br>
Figure 8, references 46 and 48, and Figure 9, references 50 and 52).</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1hc2lnbm1lbnQucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-asignment.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1hc3NpZ25tZW50LTEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-assignment-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1jb3JyZXNwb25kZW5jZSBvdGhlcnMtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-correspondence others-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1jb3JyZXNwb25kZW5jZSBvdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1jb3JyZXNwb25kZW5jZS0xLjIucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-correspondence-1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1kZXNjcmlwdGlvbihjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1mb3JtLTEucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1mb3JtLTMtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-form-3-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1mb3JtLTMucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1mb3JtLTUucGRm" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1pbnRlcm5hdGlvbmFsIHNlYXJjaCBhdXRob3JpdHkgcmVwb3J0LnBkZg==" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-international search authority report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1wY3QgZm9ybS5wZGY=" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-pct form.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIzNjIta29sbnAtMjAwNi1wcmlvcml0eSBkb2N1bWVudC5wZGY=" target="_blank" style="word-wrap:break-word;">02362-kolnp-2006-priority document.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNS0xMC0yMDEyKS1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(05-10-2012)-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNi0wNi0yMDEzKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(06-06-2013)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNi0wNi0yMDEzKS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(06-06-2013)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNi0wNi0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(06-06-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNi0wNi0yMDEzKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(06-06-2013)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwNi0wNi0yMDEzKS1QQS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(06-06-2013)-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwOS0wOC0yMDEyKS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(09-08-2012)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgwOS0wOC0yMDEyKS1FWEFNSU5BVElPTiBSRVBPUlQgUkVQTFkgUkVDSUVWRUQuUERG" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(09-08-2012)-EXAMINATION REPORT REPLY RECIEVED.PDF</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgyNi0xMS0yMDEzKS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(26-11-2013)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1LT0xOUC0yMDA2LSgyNi0xMS0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-KOLNP-2006-(26-11-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUFTU0lHTk1FTlQucGRm" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-ASSIGNMENT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUNBTkNFTExFRCBQQUdFUy5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-CANCELLED PAGES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUZPUk0gMTgtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-FORM 18-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdQQS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GPA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtRk9STSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUdSQU5URUQtU1BFQ0lGSUNBVElPTi1DT01QTEVURS5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-GRANTED-SPECIFICATION-COMPLETE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUlOVEVSTkFUSU9OQUwgUFVCTElDQVRJT04ucGRm" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-INTERNATIONAL PUBLICATION.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-INTERNATIONAL SEARCH REPORT &amp; OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LVBFVElUSU9OIFVOREVSIFJVTEUgMTM3LnBkZg==" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjM2Mi1rb2xucC0yMDA2LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">2362-kolnp-2006-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMDIzNjIta29sbnAtMjAwNi5qcGc=" target="_blank" style="word-wrap:break-word;">abstract-02362-kolnp-2006.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="259089-an-improved-process-for-lactonization-in-the-preparation-of-statins.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="259091-a-composition-for-preventing-decline-of-improvement-or-enhancement-of-normal-responses-of-cognitive-abilities-for-healthy-adults.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>259090</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2362/KOLNP/2006</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>09/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>28-Feb-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>25-Feb-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>21-Aug-2006</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>DOLBY LABORATORIES LICENSING CORPORATION</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>100,POTRERO AVENUE, SAN FRANCISCO, CA 94103-4813 U.S.A.</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>DAVIS,MARK FRANKLIN</td>
											<td>DOLBY LABORATORIES LICENSING CORPORATION100,POTRERO AVENUE,SAN FRANCISCO,CA 94103-4813U.S.A.</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G10L19/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2005/006359</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-02-28</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>60/588,256</td>
									<td>2004-07-14</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/549,368</td>
									<td>2004-03-01</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>3</td>
									<td>60/579,974</td>
									<td>2004-06-14</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/259090-a-method-for-encoding-n-input-audio-channels-into-m-encoded-audio-channels-and-a-method-for-decoding-m-encoded-audio-channels-representing-n-audio-channels by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:20:07 GMT -->
</html>
