<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/254056-method-and-apparatus-for-encoding-decoding-image by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:06:07 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 254056:METHOD AND APPARATUS FOR ENCODING/DECODING IMAGE</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR ENCODING/DECODING IMAGE</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method and apparatus encoding/decoding an image that divide an image sequence into sub-groups and determine encoding modes applied to bi-directional pictures included in each sub-group using correlation between the bi-directional pictures and reference picture are provided. The image encoding method includes dividing a group of pictures (GOP) to be encoded according to consecutive B pictures into sub-groups; calculating the correlations between each B picture included in the sub-group and reference picture according to each encoding mode; and applying one of the encoding modes wherein the reference picture having the highest correlation with the B picture are used in each sub-group to encode the image, thereby improving encoding efficiency.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>FORM 2<br>
THE PATENTS ACT, 1970<br>
(39 of 1970)<br>
&amp;<br>
THE PATENTS RULES, 2003<br>
COMPLETE SPECIFICATION<br>
(See section 10, rule 13)<br>
"METHOD AND APPARATUS FOR ENCODING/DECODING<br>
IMAGE"<br>
SAMSUNG ELECTRONICS CO., LTD., an Korean Corporation of 416, Maetan-dong, Yeongtong-gu Suwon-si, Gyeonggi-do,<br>
Republic of Korea<br>
The following specification particularly describes the invention and the manner in which it is to be performed.<br><br>
METHOD AND APPARATUS FOR ENCODING/DECODING AN<br>
IMAGE<br>
CROSS-REFERENCE TO RELATED PATENT APPLICATION<br>
[01]	This    application    claims    priority    from    Korean   Patent<br>
Application No. 10-2006-0136801, filed on December 28, 2006, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein in its entirety by reference.<br>
BACKGROUND OF THE INVENTION<br>
1.	Field of the Invention<br>
[02]	Methods and apparatuses consistent with the present invention<br>
relate to encoding/decoding an image, and more particularly, to encoding/decoding an image that divides an image sequence into sub-groups and determines encoding modes applied to bi-directional pictures included in each sub-group using correlations between the bi-directional pictures and reference pictures in order to improve encoding efficiency.<br>
2.	Description of the Related Art<br>
[03]	When video is encoded, spatial redundancy and temporal<br>
redundancy of an image sequence are removed so as to compress the image sequence. To remove temporal redundancy, a reference picture that is a picture located to the front or rear of a currently encoded picture is used to search for an area of the reference picture similar to an area of the currently encoded picture.  Then, an amount of motion between corresponding areas of<br><br><br>
the currently encoded picture and the reference picture are detected, and a residue between a prediction image obtained by the motion compensation based on the detected amount of motion and the currently encoded image is encoded.<br>
[04]	Video standards such as Moving Picture Experts Group  1<br>
(MPEG-1), MPEG-2, MPEG-4, H.264/Advanced Video Coding (AVC) and the like classify each picture of the image sequence into an I picture, a P picture, and a B picture according to a prediction encoding method. The I picture is encoded using information of the currently encoded picture itself without inter-prediction. The P picture is prediction-encoded referring to one previously processed picture located to the front or rear of the currently encoded picture. The B picture is prediction-encoded referring to two previously processed pictures located to the front or rear of the currently encoded picture.<br>
[05]	FIGS. 1A through 1C illustrate a variety of encoding modes<br>
according to encoding of B pictures included in a group of pictures (GOP). Referring to FIG. 1A, video encoding that was suggested before the H.264/AVC standard was defined does not use the B pictures as reference pictures of other pictures, but uses I pictures or P pictures as reference pictures of another picture, which are called key pictures. In an encoding mode (hereinafter referred to as a "B picture non-reference mode") where the B pictures are not used as the reference pictures of other pictures, the B pictures are prediction-encoded by using the I pictures or the P pictures that are located<br><br><br>
to the front or rear of the B pictures in terms of time and are previously<br>
processed as the reference picture. For example, the B picture Bl is prediction<br>
encoded using the I picture 10 and the P picture P4, which are previously<br>
encoded and then restored during an encoding procedure.<br>
[06]	Video standards such as H.264/ AVC can use the B pictures as<br>
the reference picture of other pictures in order to improve encoding efficiency, since the reference picture can be controlled using a picture order count type parameter transmitted from a sequence parameter set (SPS). When the B pictures can be used as the reference pictures of other pictures, the encoding of the B pictures included in the GOP is divided into an encoding mode (hereinafter referred to as a "B picture reference mode") where all the B pictures can be used as the reference pictures of other pictures, and an encoding mode (hereinafter referred to as a "pyramid mode") where the B pictures having predetermined locations in the GOP are hierarchically prediction-encoded.<br>
[07]	Referring to FIG. IB, I pictures and P pictures and previously<br>
processed B pictures can also be used as reference pictures in the B picture<br>
reference mode. For example, a B picture B2 is prediction encoded using a P<br>
picture P4 and a B picture Bl, which are first encoded and then restored.<br>
Although not shown, an I picture 10 and the B picture Bl that are previously<br>
encoded and then restored can be used as the reference pictures of the B<br>
picture B2.<br>
[08]	Referring to FIG. 1C, B pictures are prediction-encoded by<br><br><br>
using key pictures (I pictures or P pictures) to the front or rear of consecutive B pictures and a B picture in the center of the consecutive B pictures as reference pictures in the pyramid mode. For example, an I picture 10 and a P picture P4 that are previously encoded and then restored are used as the reference pictures so as to prediction-encode a B picture B2 in the center of consecutive B pictures. The I picture 10 and the B picture B2 are used as the reference pictures so as to prediction-encode a B picture B1. The B picture B2 and the P picture P4 are used as the reference pictures to prediction-encode a B picture B3.<br>
[09]	The performance of the various encoding modes is dependent<br>
on the characteristics of an image sequence to be encoded. An encoding sequence of B pictures and reference pictures thereof vary according to each of the encoding modes, which causes differences between prediction images according to each of the encoding modes and between prediction errors of B pictures. In the related art, an image is encoded by applying one of the encoding modes to pictures included in a GOP, thus failing to adaptively encode the image sequence according to the characteristics of an image.<br>
SUMMARY OF THE INVENTION<br>
[10]	The present invention provides a method and apparatus for<br>
encoding/decoding an image that adaptively apply an encoding/decoding<br>
mode to an image according to the characteristics of an image sequence in<br>
order to improve encoding/decoding efficiency.<br>
[11]	The present invention provides a method and apparatus for<br><br>
encoding/decoding an image that divide a GOP into sub-groups and apply a<br>
different  encoding/decoding  mode  to  each  sub-group  according  to  the<br>
characteristics of the image in order to improve encoding/decoding efficiency.<br>
[12]	According to an aspect of the present invention, there is<br>
provided an image encoding method comprising: dividing a GOP including a plurality of image pictures included in an image sequence into sub-groups according to consecutive bi-directional pictures; calculating correlations between the bi-directional pictures of each sub-group and reference pictures referred to by the bi-directional pictures based on a plurality of encoding modes classified according to whether the bi-directional pictures can be used as reference pictures of other pictures and the reference pictures referred to by the bi-directional pictures; selecting one of the plurality of encoding modes based on the correlations; and encoding the B pictures of each sub-group according to the selected encoding mode.<br>
[13]	The plurality of encoding modes may include a bi-directional<br>
picture non-reference mode wherein the bi-directional pictures are not used as reference pictures, a bi-directional picture reference mode wherein all the bidirectional pictures can be used as reference pictures, and a pyramid mode wherein a bi-directional picture in the center of the consecutive bi-directional pictures of each sub-group is used as a reference picture of the other bidirectional pictures.<br>
[14]	The calculating of the correlations may include calculating an<br>
average of differences between histograms of pixel values  of each bi-<br><br><br>
directional picture included in the sub-group and histograms of pixel values of<br>
the reference picture according to the plurality of encoding modes, wherein the<br>
selecting of one of the plurality of encoding modes may include increasing a<br>
counting number of the encoding mode having the smallest average value<br>
from among the plurality of encoding modes; and selecting one of the plurality<br>
of encoding modes having the largest counting number.<br>
[15]	The method may further include, that if the reference picture<br>
and the bi-directional picture have 0 through n - 1 pixel values (n is an<br>
integral), the bi-directional picture is denoted by B, the reference picture is<br>
denoted by R, HB[I] denotes the number of pixels of the bi-directional picture<br>
B having a pixel value i (i is 0~n), and HR[1] denotes the number of pixels of<br>
the reference picture R having the pixel value i, the correlations H(B,R)<br>
between the reference picture R and the bi-directional picture B are calculated<br><br>
according to the following equation,	 <br>
[16]	The calculating of the correlations may include calculating<br>
difference values between each bi-directional picture included in the subgroup and the reference picture according to the plurality of encoding modes are calculated using one of a Mean Square Error (MSE), a Sum of Absolute Differences (SAD), and a Sum of Squared Errors (SSE), wherein the selecting of one of the plurality of encoding modes may include increasing a counting number of the encoding modes having the smallest difference value from among the plurality of encoding modes; and selecting one of the plurality of<br><br><br>
encoding modes having the largest counting number.<br>
[17]	According to another aspect of the present invention, there is<br>
provided an image encoding apparatus comprising: a sub-group generator that divides a GOP including a plurality of image pictures included in an image sequence into sub-groups according to consecutive bi-directional pictures; a correlation calculator that calculates correlations between the bi-directional pictures of each sub-group and reference pictures referred to by the bidirectional pictures based on a plurality of encoding modes classified according to whether the bi-directional pictures can be used as reference pictures of other pictures, and the reference pictures referred to by the bidirectional pictures; an encoding mode selector that selects one of the plurality of encoding modes based on the correlations; and an encoding unit that encodes the B pictures of each sub-group according to the selected encoding mode.<br>
[18]	According to another aspect of the present invention, there is<br>
provided an image decoding method comprising: reading encoding mode information included in an input bitstream, dividing a plurality of encoded image pictures of the bitstream into sub-groups, and determining encoding modes used to encode bi-directional pictures of each sub-group; determining a decoding sequence of the bi-directional pictures of each sub-group and reference pictures according to the encoding modes; and decoding the bidirectional pictures of each sub-group using the decoding sequence and the reference pictures.<br><br><br>
[19]	According to another aspect of the present invention, there is<br>
provided an image decoding apparatus comprising: an encoding mode<br>
discriminator that reads encoding mode information included in an input<br>
bitstream, divides a plurality of encoded image pictures of the bitstream into<br>
sub-groups, and determines encoding modes used to encode bi-directional<br>
pictures of each sub-group; a decoding sequence determiner that determines a<br>
decoding sequence of the bi-directional pictures of each sub-group and<br>
reference pictures according to the encoding modes; and<br>
[20]	a decoding unit that decodes the bi-directional pictures of each<br>
sub-group using the decoding sequence and the reference pictures.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
[21]	The above and other features of the present invention will<br>
become more apparent by describing in detail exemplary embodiments thereof with reference to the attached drawings in which:<br>
[22]	FIGS. 1A through 1C illustrate a variety of encoding modes<br>
according to encoding of B pictures included in a GOP;<br>
[23]	FIG. 2 is a block diagram of an image encoding apparatus<br>
according to an exemplary embodiment of the present invention;<br>
[24]	FIG. 3 illustrates an exemplary embodiment of a GOP that is<br>
input into the exemplary embodiment of the image encoding apparatus illustrated in FIG. 2;<br>
[25]	FIGS. 4A and 4B illustrate an exemplary embodiment of two<br>
sub-groups, into which the GOP illustrated in FIG. 3 is divided;<br><br>
[26]	FIG. 5 is a histogram showing the distribution of values of<br>
pixels included in a picture, according to an exemplary embodiment of the present invention;<br>
[27]	FIG. 6 is a block diagram of an exemplary embodiment of the<br>
encoding unit illustrated in FIG. 2;<br>
[28]	FIG. 7 is a flowchart illustrating an image encoding method<br>
according to an exemplary embodiment of the present invention;<br>
[29]	FIG. 8 is a block diagram of an image decoding apparatus<br>
according to an exemplary embodiment of the present invention; and<br>
[30]	FIG. 9 is a flowchart illustrating an image decoding method<br>
according to an exemplary embodiment of the present invention. <br>
DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS OF<br>
THE INVENTION<br>
[31]	Hereinafter, exemplary embodiments of the present invention<br>
will be described in detail with reference to the accompanying drawings.<br>
[32]	A method and apparatus for encoding an image according to<br>
the present invention divide a GOP that includes a plurality of image pictures<br>
of an input image sequence into sub-groups, calculate correlation between<br>
object pictures of each sub-group that are to be encoded and reference pictures<br>
according to encoding modes, and determine an encoding mode based on the<br>
correlation, thereby adaptively encoding the image in the unit of a sub-group.<br>
[33]	FIG. 2 is a block diagram of an image encoding apparatus 200<br>
according to an exemplary embodiment of the present invention. Referring to<br><br><br>
FIG. 2, the image encoding apparatus 200 comprises a sub-group generator 210, a correlation calculator 220, an encoding mode selector 230, and an encoding unit 240.<br>
[34]	The sub-group generator 210 divides an input image sequence<br>
every consecutive B pictures into sub-groups.<br>
[35]	The correlation calculator 220 calculates a correlation between<br>
the B pictures of each sub-group and reference pictures referred to by the B pictures according to encoding modes.<br>
[36]	The encoding mode selector 230 selects an encoding mode<br>
where a reference picture having the highest correlation with the B pictures of a sub-group that are being currently encoded is used, based on the correlation calculated by the correlation calculator 220.<br>
[37]	The encoding unit 240 prediction-encodes each of the sub-<br>
groups according to the encoding mode selected by the encoding mode selector 230 in order to generate a bit stream.<br>
[38]	The operation of the image encoding apparatus 200 of the<br>
present exemplary embodiment will now be described.<br>
[39]	FIG. 3 illustrates a GOP 300 that is input into the image<br>
encoding apparatus 200 illustrated in FIG. 2. FIGS. 4A and 4B illustrate two sub-groups 410 and 420, into which the GOP illustrated in FIG. 3 is divided. Hereinafter, In, Pn, and Bn (n is an integral) are an nth I picture, an nth P picture, and an nth B picture, respectively, that are sequentially included in image pictures of the GOP 300.<br><br><br>
[40]	Referring to FIG. 3, it is assumed that the GOP 300 includes M<br>
consecutive B pictures and key pictures (I pictures or P pictures) in the front or rear of the M consecutive B pictures. Although the GOP 300 includes two pairs of M consecutive B pictures Bl through BM and BM+2 through B2M+1 between the key pictures, IO, PM+1, and P2M+2 in the present exemplary embodiment, the present invention can be applied to encode the image pictures of the GOP 300 including more than two pairs of consecutive B pictures. Since a B picture in the center of the consecutive B pictures is used as a reference picture for the other B pictures in a pyramid mode, M, which is the number of the consecutive B pictures, may be an odd number. For example, but not by way of limitation, if M is 5, a B picture B3 in the center of five consecutive B pictures Bl through B5 is first prediction-encoded by using the I picture IO and a P picture P6 as reference picturesThe B pictures Bl and B2 before the B picture B3 are prediction-encoded by using the I picture IO and the B picture B3 as reference pictures. The B pictures B4 and B5 after the B picture B3 are prediction-encoded by using the B picture B3 and the P picture P6 as reference pictures in the pyramid mode.<br>
[41]	The sub-group generator 210 divides the GOP 300 into sub-<br>
groups so as to include the consecutive B pictures and the key pictures (I<br>
pictures or P pictures) on both ends of the consecutive B pictures.<br>
[42]	Referring to FIGS. 4A and 4B, the GOP 300 is divided into the<br>
first sub-group 410, illustrated in FIG. 4A, that includes the M consecutive B pictures Bl, B2, through to BM and the I picture IO and the P picture PM+1<br><br><br>
on both ends of the M consecutive B pictures, and the second sub-group 420,<br>
illustrated in FIG. 4B, that includes the M consecutive B pictures BM+2,<br>
BM+3, BM+4, through to B2M+1 and the P pictures PM+1 and P2M+2 on<br>
both ends of the M consecutive B pictures. The P picture PM+1 that is the key<br>
picture of the consecutive B pictures is included in both sub-groups 410 and<br>
420 in order to calculate the correlation between the B pictures of each of the<br>
two sub-groups 410 and 420. The key pictures of each sub-group are not<br>
redundantly encoded when each sub-group is substantially encoded.<br>
[43]	The correlation calculator 220 calculates a correlation between<br>
the B pictures of each of the two sub-groups 410 and 420 and reference<br>
pictures referred to by the B pictures according to each of encoding modes.<br>
The encoding modes, as mentioned in the related art, include a B picture non-<br>
reference mode where the B pictures are not used as reference pictures, a B<br>
picture reference mode where all the B pictures that are previously encoded<br>
and then restored can be used as reference pictures, and a pyramid mode<br>
where a bi-directional picture in the center of consecutive bi-directional<br>
pictures of a sub-group is used as a reference picture. It will be clearly<br>
understood by a person of ordinary skill in the art from the detailed description<br>
that the image encoding method according to the present invention can be<br>
applied to a different type of encoding mode other than these three encoding<br>
modes, where an encoding sequence of the B pictures and reference pictures<br>
that are used are transformed.<br>
[44]	When the B  pictures  of the  GOP  300  are  bi-directional<br><br><br>
prediction-encoded in the B picture non-reference mode, the B picture reference mode, and the pyramid mode, Table 1 shows the reference pictures used to prediction-encode the B pictures of the GOP 300 according to each of the encoding modes.<br>
[Table 1]<br><br>
B pictures to be encoded	Reference   pictures   used   to   prediction-encode   B   pictures according to each of the encoding modes<br>
	B      picture      non-reference mode	B picture reference mode	Pyramid mode<br>
Bl	10, PM+1	10, PM+1	10, Bn<br>
B2	10, PM+1	Bl,PM+1	10, Bn<br>
B3	10, PM+1	B2, PM+1	10, Bn<br>
...		...	<br>
Bn-1	10, PM+1	Bn-2, PM+1	10, Bn<br>
Bn	10, PM+1	Bn-1, PM+1	10, PM+1<br>
Bn+1	IO, PM+1	Bn, PM+1	Bn, PM+1<br>
...	...	...	<br>
BM	10, PM+1	BM-l,PM+1	Bn, PM+1<br>
[45]	In Table 1, n denotes an index indicating the B picture in the<br>
center of the M consecutive B pictures. n=(M+l)/2. If M is an even number, an n value can be rounded up or down to use the B picture in the center of the consecutive B pictures.<br>
[46]	In the B picture non-reference mode, a B picture is not used as<br>
a reference picture of other pictures but instead an I picture or a P picture can be used as the reference picture. Therefore, the B picture is bi-directional prediction-encoded using the I picture or the P picture that is previously<br><br><br>
encoded and then restored in the B picture non-reference mode. For example,<br>
the I picture 10 and the P picture PM+1 that are previously encoded and then<br>
restored are used to prediction-encode the B picture Bl.<br>
[47]	In the B picture reference mode, all the B pictures that are<br>
previously encoded and then restored can be used as reference pictures of<br>
other pictures. Therefore, all B pictures that are previously encoded and then<br>
restored before a B picture that is currently encoded are used as a reference<br>
picture as shown in Table 1. For example, referring to FIG. IB and Table 1,<br>
the B picture B2 is prediction-encoded according to the B picture reference<br>
mode by using the B picture Bl and the P picture PM+1 that are completely<br>
processed before the B picture B2 as the reference pictures.<br>
[48]	In the pyramid mode, a picture in the center of consecutive B<br>
pictures is used as a reference picture. For example, referring to FIG. 4A,<br>
when a B picture in the center of the consecutive B pictures Bl through BM is<br>
Bn, the B pictures Bl through Bn-1 are bi-directional prediction-encoded by<br>
using the I picture 10 and the B picture Bn as reference pictures, and the B<br>
pictures Bn+1 through BM are bi-directional prediction-encoded by using the<br>
B picture Bn and the P picture PM+1 as reference pictures.<br>
[49]	The correlation calculator 220 calculates correlation between<br>
the B pictures of each sub-group and reference pictures used to prediction-encode the B pictures according to each of the three exemplary encoding modes. The correlation indicates the similarity between two images. The higher the correlation is, the more similar two images are.<br><br><br>
[50]	A variety of algorithms can be used to calculate the correlation<br>
between the B pictures of each sub-group and reference pictures. For example,<br>
but not by way of limitation, the correlation calculator 220 calculates the<br>
correlation by comparing histograms of a B picture that is currently encoded<br>
and histograms of a reference picture used to prediction-encode the B picture<br>
in each of the three exemplary encoding modes. The histogram is a summary<br>
graph showing the distribution of values of pixels included in a picture as<br>
illustrated in FIG. 5. Assuming that each 8-bit pixel has a value between 0<br>
through 255, FIG. 5 illustrates an exemplary embodiment of a histogram of a<br>
picture having 16 pixels with a value 0, 25 pixels with a value 1 and so on.<br>
[51]	Provided that two pictures X and Y have pixels having 0<br>
through n-1 values, the correlation H(X,Y) between the two pictures X and Y<br>
is	calculated	according	to	the	equation,<br><br><br>
	 based on the histogram of the<br>
distribution of the pixel values, wherein Hx[i] denotes the number of pixels<br>
having a value i of the picture X, and Hy[i] denotes the number of pixels<br>
having the value i of the picture Y. In detail, the correlation between the two<br>
pictures X and Y can be calculated by using an average of differences between<br>
histograms of the pixel values (the average of differences between the<br>
numbers of the same pixel values of the two pictures).<br>
[52]	The   correlation   calculator   220   calculates   the   correlation<br>
between the B pictures of each sub-group and the reference pictures by<br><br><br>
calculating an average of differences between the histograms of pixel values of each B picture and the histograms of pixel values of each reference picture according to each of the three encoding modes.<br>
[53]	For example, referring to FIG. 4A and Table 1, the correlation<br>
calculator 220 calculates the correlation H(B1,PM+1) between the P picture PM+1 that is used as a separate reference picture in each encoding mode and the B picture Bl, and the correlation H(Bl,Bn) between the B pictures Bn and B1, excluding the I picture 10 that is shared as the reference picture in all three encoding modes to determine an encoding mode where a reference picture having the highest correlation with the B picture Bl of the first sub-group 410 is used.<br>
[54]	If no common picture is used as the reference picture of a<br>
current B picture in a plurality of encoding modes, the correlation calculator 220 calculates correlations between each reference picture used in each encoding mode and the current B picture, and uses an average of the correlations as the correlation between the current B picture and the reference pictures. For example, referring to Table 1, a common picture used to prediction-encode the B picture B2 of the first sub-group 410 does not exist in the B picture non-reference mode, the B picture reference mode, or the pyramid mode. In this case, the correlation calculator 220 uses (H(B2,I0)+H(B2,PM+l))/2 as a value indicating the correlation between the B picture B2 and the I picture IO and the P picture PM+1 that are the reference pictures in the B picture non-reference mode, (H(B2,Bl)+H(B2,PM+l))/2 as a<br><br>
value indicating the correlation between the B picture B2 and the I picture 10 and the P picture PM+1 that are the reference pictures in the B picture reference mode, and (H(B2,I0)+H(B2,Bn))/2 as a value indicating the correlation between the B picture B2 and the I picture 10 and the B picture Bn that are the reference pictures in the pyramid mode.<br>
[55]	The encoding mode selector 230 counts the number of the<br>
encoding modes of each of the B pictures where reference pictures having the<br>
highest correlation with the B pictures that are currently encoded are used,<br>
based on the correlations calculated by the correlation calculator 220, and<br>
selects an encoding mode to be applied to each sub-group from the encoding<br>
modes. For example, referring to FIG. 4A, if M is 5, the counting number of<br>
the B picture reference modes is b, the counting number of the B picture non-<br>
reference modes is nr, and the counting number of the pyramid modes is<br>
p(here, b+nr+p=5), then the correlation calculator 220 calculates the<br>
correlation between each of the B pictures Bl through B5 of the first sub<br>
group 410 and the reference pictures according to each encoding mode. The<br>
encoding mode selector 230 increases the counting number of the encoding<br>
modes when the reference pictures having the largest correlation with the B<br>
pictures that are currently encoded are used. If it is determined that b=l, nr=l,<br>
and p=3, the encoding mode selector 230 selects the pyramid mode as an<br>
encoding mode of the B pictures Bl through B5 of the first sub-group 410.<br>
[56]	The   correlation   calculator  220   compares  the   correlations<br>
between the B pictures of each sub-group and the reference pictures according<br><br><br>
to each encoding mode by comparing the correlations between the B pictures of each sub-group and the reference pictures according to two encoding modes selected from a plurality of encoding modes and comparing the correlations between the B pictures of each sub-group and the reference pictures according to other combinations of two encoding modes. In detail, the correlation calculator 220 calculates the correlations between the reference pictures according to the B picture reference mode and the B picture non-reference mode and the B pictures of each sub-group, and counts the number of encoding modes having a higher correlation, calculates the correlations between the reference pictures according to the B picture non-reference mode and the pyramid mode and the B pictures of each sub-group and counts the number of encoding modes having a higher correlation, and calculates the correlations between the reference pictures according to the B picture reference mode and the pyramid mode and the B pictures of each sub-group and counts encoding modes having a higher correlation, and finally determines one of the three encoding modes having the largest counting number as an encoding mode of each sub-group.<br>
[57]	In more detail, the correlation calculator 220 calculates the<br>
correlations between the reference pictures according to the B picture reference mode and the B picture non-reference mode and the B pictures of the first sub-group 410. Table 2 shows the correlations to be compared according to the B pictures of the first sub-group 410.<br><br>
[Table 2]<br><br>
B     pictures to be encoded	Correlations to be compared according to B pictures<br>
	B    picture    non-reference mode	B picture reference mode<br>
Bl	No Comparison<br>
B2	H (B2,10)	H(B2,B1)<br>
B3	H (B3,10)	H (B3, B2)<br><br>
Bn-1	H (Bn-1,10)	H(Bn-l,Bn-2)<br>
Bn	H (Bn, 10)	H (Bn, Bn-1)<br>
Bn+1	H (Bn+1,10)	H(Bn+l,Bn)<br>
	. . .	. . .<br>
BM	H (BM, 10)	H(BM,BM-1)<br>
[58]	Referring to Tables 1 and 2, since the first B picture Bl of the<br>
first sub-group 410 is prediction-encoded by using the I picture 10 and the P picture PM+1 as the reference pictures in the B picture reference mode and the B picture non-reference mode, the correlation calculator 220 does not need to calculate the correlations between the first B picture Bl and the reference pictures according to the B picture reference mode and the B picture non-reference mode. The correlation calculator 220 calculates the correlations between the B pictures of the first sub-group 410 and the reference pictures according to the B picture reference mode and the B picture non-reference mode, and increases the number of the two encoding modes where the reference pictures having a higher correlation with the B pictures are used, excluding the same reference pictures used in the B picture reference mode and the B picture non-reference mode. For example, when the B picture B3 is<br><br><br>
prediction-encoded, since the I picture 10 and the P picture PM+1 are used as the reference pictures in the B picture non-reference mode, and the B picture B2 and the P picture PM+1 are used as the reference pictures in the B picture reference mode, the correlation calculator 220 calculates the correlation H(B3,IO) between the B picture B3 and the reference picture 10 and the correlation H(B3,B2) between the B picture B3 and the reference picture B2, and increases the counting number of the one of the two encoding modes having a higher correlation, excluding the common reference picture PM+1 used in the two encoding modes. Since the lower the H(X,Y) value is, the more similar the distribution of values of pixels of two image pictures X and Y is, then the higher the correlation between the two image pictures X and Y is. Therefore, if H(B3,I0) &gt; H(B3,B2), since the B picture B3 that is currently encoded and the reference picture B2 have the higher correlation, the correlation calculator 220 increases the counting number r of the B picture reference mode suitable for encoding the B picture B3 where the B picture B2 is used as the reference picture. If H(B3,I0) 
[59]	Next, the correlation calculator 220 calculates the correlations<br>
between the reference pictures according to the B picture non-reference mode and the pyramid mode and the B pictures of the first sub-group 410. Table 3 shows the correlations to be compared according to the B pictures of the first<br><br><br>
sub-group 410.<br>
[Table 3]<br><br>
B    pictures to be encoded	Correlations to be compared according to B pictures<br>
	B    picture    non-reference mode	Pyramid mode<br>
Bl	H(B1,PM+1)	H(Bl,Bn)<br>
B2	H(B2,PM+1)	H (B2, Bn)<br>
B3	H (B3, PM+1)	H (B3, Bn)<br>
. ..		<br>
Bn-1	H(Bn-l,PM+l)	H(Bn-l,Bn)<br>
Bn	No comparison<br>
Bn+1	H (Bn+1,10)	H(Bn+l,Bn)<br>
* . .	. . .	<br>
BM	H (BM, 10)	H (BM, Bn)<br>
[60]	Referring to Tables 1 and 3, since the B picture Bn in the center<br>
of the M consecutive B pictures of the first sub-group 410 is prediction-encoded by using the I picture 10 and the P picture PM+1 as the reference pictures in the B picture non-reference mode and the pyramid mode, the correlation calculator 220 does not need to calculate the correlations between the B picture Bn and the reference pictures according to the B picture non-reference mode and the pyramid mode. The correlation calculator 220 calculates the correlations between the B pictures of the first sub-group 410 and the reference pictures according to the B picture non-reference mode and the pyramid mode and increases the counting number of one of the two encoding modes when the reference pictures having a higher correlation with the B pictures are used, excluding the same reference pictures used in the B picture non-reference mode and the pyramid mode. For example, when the B<br><br><br>
picture B2 is prediction-encoded, since the I picture 10 and the P picture PM+1 are used as the reference pictures in the B picture non-reference mode, and the I picture 10 and the B picture Bn are used as the reference pictures in the pyramid mode, the correlation calculator 220 calculates the correlation H(B2,PM+1) between the B picture B2 and the reference picture PM+1 and the correlation H(B2,Bn) between the B pictures B2 and the reference picture Bn, and increases the counting number of the one of the two encoding modes having a higher correlation, excluding the common reference picture 10 used in the two encoding modes. If H(B2,PM+1) &gt; H(B2,Bn), since the B picture B2 that is currently encoded and the reference picture Bn have the higher correlation, the correlation calculator 220 increases the counting number p of the pyramid mode suitable for encoding the B picture B2 where the B picture Bn is used as the reference picture. If H(B2,PM+1) 
[61]	The  correlation  calculator  220  calculates  the   correlations<br>
between the reference pictures according to the B picture reference mode and the pyramid mode and the B pictures of the first sub-group 410. Table 4 shows the correlations to be compared according to the B pictures of the first sub-group 410.<br><br><br><br>
[Table 4]<br><br>
B     pictures to be encoded	Correlations to be compared according to B pictures<br>
	B picture reference mode	Pyramid mode<br>
Bl	H(B1,PM+1)	H(Bl,Bn)<br>
B2	H(B2,B1),H(B2,PM+1)	H (B2,10), H (B2, Bn)<br>
B3	H(B3,B2),H(B3,PM+1)	H (B2,10), H (B3, Bn)<br>
	. . .	<br>
Bn-1	H (Bn-1, Bn-2), H (Bn-1, PM+1)	H(B2,I0),H(Bn-l,Bn)<br>
Bn	H(Bn,Bn-l)	H (Bn, 10)<br>
Bn+1	No Comparison<br><br>
BM	H(BM,BM-1)	H (BM, Bn)<br>
[62]	Referring to Tables 1 and 4, since the B picture Bn+1 of the<br>
first sub-group 410 is prediction-encoded by using the B picture Bn and the P picture PM+1 as the reference pictures in the B picture reference mode and the pyramid mode, the correlation calculator 220 does not need to calculate the correlations between the B picture Bn and the reference pictures according to the B picture reference mode and the pyramid mode. The correlation calculator 220 calculates the correlations between the B pictures of the first sub-group 410 and the reference pictures according to the B picture reference mode and the pyramid mode and increases the counting number of one of the two encoding modes when the reference pictures having a higher correlation with the B pictures are used, excluding the same reference pictures used in the B picture reference mode and the pyramid mode. For example, when the B picture Bl is prediction-encoded, since the I picture 10 and the P picture<br><br><br>
PM+1 are used as the reference pictures in the B picture reference mode, and the I picture 10 and the B picture Bn are used as the reference pictures in the pyramid mode, the correlation calculator 220 calculates the correlation H(B1,PM+1) between the B picture Bl and the reference picture PM+1 and the correlation H(Bl,Bn) between the B picture Bl and the reference picture Bn, and increases the counting number of the one of the two encoding modes having a higher correlation, excluding the common reference picture 10 used in the two encoding modes. If H(B1,PM+1) &gt; H(Bl,Bn), since the B picture B1 that is currently encoded and the B picture Bn have the higher correlation, the correlation calculator 220 increases the number p of the pyramid mode suitable for encoding the B picture Bl when the B picture Bn is used as the reference picture. If H(B1,PM+1) 
[63]	When each encoding mode uses a different reference picture,<br>
all the correlations between the reference pictures according to each encoding mode and the B pictures that are currently encoded need to be considered. If {H(B2, B1)+H(B2, PM+1)} &gt; {H(B2, 10)+ H(B2, Bn) } as a result of calculating the correlations H(B2, Bl) and H(B2, PM+1) between the B picture B2 and the reference pictures Bl and PM+1 used in the B picture<br><br><br>
reference mode, calculating the correlations H(B2,10) and H(B2, Bn) between the B picture B2 and the reference pictures 10 and Bn used in the pyramid mode, and comparing {H(B2, B1)+H(B2, PM+1)} and {H(B2, 10)+ H(B2, Bn)}, since the B picture B2 that is currently encoded has a higher correlation with the reference pictures 10 and PM+1, the correlation calculator 220 increases the counting number p of the pyramid mode suitable for encoding the B picture B2 where the I picture 10 and the P picture PM+1 are used as the reference pictures. If {H(B2, B1)+H(B2, PM+1)} 
[64]	The   correlation   calculator   220   repeatedly   compares   the<br>
correlations between the B pictures of each sub-group and the reference pictures according to each combination of two encoding modes. The encoding mode selector 230 selects an encoding mode having the largest counting number.<br>
[65]	An algorithm used to compare the correlations between the B<br>
pictures of each sub-group and the reference pictures according to each encoding mode and select an encoding mode to be applied to each sub-group is summarized as follows.<br>
[66]	Step 1: It is established that nr is a counting number indicating<br>
that the B picture non-reference mode is determined to have a higher correlation with a B picture that is to be encoded, p is a counting number indicating that the pyramid mode is determined to have a higher correlation<br><br><br>
with the B picture, and r is a counting number indicating that the B picture reference mode is determined to have a higher correlation with the B picture, and then nr, p, and r are set to 0 at the beginning of processing the first subgroup 410.<br>
[67]	Step 2: The correlations between the B pictures of the first sub-<br>
group 410 and the reference pictures used in the B picture non-reference mode and the B picture reference mode are calculated based on Table 2, and the counting number of encoding modes having a higher correlation is increased. <br>
{ for i=2 to M<br>
if H(Bi,I0)<h bi-l then nr></h>
elser+=l;<br>
}<br>
[68]	Step 3: The correlations between the B pictures of the first sub-<br>
group 410 and the reference pictures used in the B picture non-reference mode and the pyramid mode are calculated based on Table 3, and the counting number of encoding modes having a higher correlation is increased.<br>
 { for i=l ton-1<br>
if H(Bi,PM+l)<h bn then nr></h>
elsep+=l; <br>
and for i=n+l to M<br>
if H(Bi,I0)<h bn then nr></h>
elsep+=l;<br><br>
}<br>
[69]	Step 4: The correlations between the B pictures of the first sub-<br>
group 410 and the reference pictures used in the B picture reference mode and the pyramid mode are calculated based on Table 4, and the counting number of encoding modes having a higher correlation is increased. <br>
   { for i=l<br>
if H(Bi,PM+l)<h bn then r></h>
elsep+=l; <br>
    for i=2 to n-1<br>
if (H(Bi,Bi-l)+H(Bi,PM+l) 
    for i=n<br>
if H(Bi, Bi-l)<h then r></h>
else p+=l; <br>
    and for i=n+2 to M<br>
if H(Bi,Bi-l)<h then r elsep></h>
[70]	Step 5: The counting numbers of encoding modes are compared<br>
to finally determine one of the encoding modes having the largest counting<br>
number as an encoding mode to be applied to the first sub-group 410.<br>
[71]	Step 6: The steps 1 through 5 repeat with regard to the second<br><br><br>
sub-group 420. A person of ordinary skill in the art can easily modify the<br>
exemplary embodiment of the program code parameters mentioned in the<br>
steps 1 through 5 and thus their detailed description is omitted.<br>
[72]	The correlation calculator 220 may use the input original image<br>
based on an error in the calculation complexity and quantization noise to calculate the correlations between the B pictures and the reference pictures. The correlation calculator 220 can use an error calculation algorithm such as an MSE, an SAD, and an SSE, instead of the histograms of the distribution of pixel values of two comparable pictures in order to calculate the correlations. The correlation calculator 220 calculates errors between each B picture included in each sub-group and the reference picture used in each encoding mode using one of the MSE, SAD, and SSE error calculation algorithms. The encoding mode selector 230 counts the encoding modes when the reference picture having the minimum errors with the B pictures are used, and determines the one of the encoding modes having the largest counting number as an encoding mode to be applied to each sub-group.<br>
[73]	FIG. 6 is a block diagram of the encoding unit illustrated in<br>
FIG. 2. Referring to FIG. 6, the encoding unit 600 encodes the image pictures of each sub-group according to the encoding modes determined by the encoding mode selector 230 and can be substituted with an image encoding apparatus. The encoding unit 600 includes a motion estimation unit 602, a motion compensation unit 604, an intra-prediction unit 630, a transformation unit 608, a quantization unit 610, a rearrangement unit 612, an entropy-coding<br><br><br>
unit 614, an inverse quantization unit 616, an inverse transformation unit 618,<br>
a filter 620, and a frame memory 622.<br>
[74]	The motion estimation unit 602 performs motion estimation in<br>
which a prediction value of a B or P picture that is currently encoded is<br>
searched for in a reference picture in order to prediction-encode a B or P<br>
picture included in a sub-group. The motion compensation unit 604 acquires a<br>
prediction image as a result of the motion estimation from the reference<br>
picture, and forms the prediction image of the B or P picture that is currently<br>
encoded.<br>
[75]	The  intra-prediction  unit  630  performs  intra-prediction  in<br>
which the prediction value of the I picture is searched for in the current I<br>
picture.<br>
[76]	If the prediction pictures of the current pictures are generated<br>
by inter-prediction or intra-prediction, residues that are differences between<br>
the prediction pictures and the current pictures are calculated, transformed by<br>
the transformation unit 608, and quantized by the quantization unit 610. The<br>
quantized residues  are  rearranged by the  rearrangement unit 612  in  a<br>
predetermined sequence and then entropy-encoded by the entropy-coding unit<br>
614 so as to be output in the form of a bitstream.<br>
[77]	The transformed and quantized pictures are inversely quantized<br>
by the inverse quantization unit 616 and are inversely transformed by the<br>
inverse transformation unit 618, thereby reconstructing the pictures in order to<br>
obtain a reference picture used to predict the B or P picture. The reconstructed<br><br>
pictures pass through the filter 620 that performs deblocking filtering and are<br>
stored in the frame memory 622 so as to be used for inter-prediction of a next<br>
picture.<br>
[78]	FIG. 7 is a flowchart illustrating an image encoding method<br>
according to an exemplary embodiment of the present invention. Referring to<br>
FIG. 7, a GOP including a plurality of image pictures included in an image<br>
sequence is divided according to consecutive B pictures into sub-groups<br>
(Operation 710).<br>
[79]	The correlations between B pictures of each sub-group and<br>
reference pictures referred to by the B pictures according to an applicable<br>
plurality of encoding modes are calculated (Operation 720).<br>
[80]	One of the encoding modes is selected based on the correlations<br>
between the B pictures and the reference pictures according to each encoding<br>
mode (Operation 730).    The correlations between the B pictures and the<br>
reference pictures according to each encoding mode are calculated in order to<br>
count the encoding modes where the reference pictures having a higher<br>
correlation with the B pictures are used, and to determine one of the encoding<br>
modes having the largest counting number as an encoding mode to be applied<br>
to each sub-group.<br>
[81]	Each sub-group is prediction-encoded according to the selected<br>
encoding mode (Operation 740).<br>
[82]	FIG. 8 is a block diagram of an image decoding apparatus 800<br>
according to an exemplary embodiment of the present invention. Referring to<br><br>
FIG. 8, the image decoding apparatus 800 includes an entropy-decoding unit 810, a rearrangement unit 820, an inverse quantization unit 830, an inverse transformation unit 840, a motion compensation unit 850, an intra-prediction unit 860, and a filter 870.<br>
[83]	The entropy-decoding unit 810 and the rearrangement unit 820<br>
receive a compressed bitstream and perform entropy-decoding, thereby generating a quantized coefficient X. The inverse quantization unit 830 and the inverse transformation unit 840 perform inverse quantization and inverse transformation on the quantized coefficient X in order to extract transformation encoding coefficients, motion vector information, etc. The motion compensation unit 850 and the intra-prediction unit 860 generate a prediction block according to an encoded picture type based on the decoded header information. The prediction block is added to an error value D'n to generate uF' „• uF' „ passes through the filter 870 and is reconstructed in the picture F' n.<br>
[84]	In particular, the image decoding apparatus 800 of the present<br>
exemplary embodiment reads encoding mode information included in an input<br>
bitstream, divides a plurality of encoded image pictures of the bitstream into<br>
sub-groups, determines encoding modes used to encode bi-directional pictures<br>
of each sub-group, and determines a decoding sequence of the bi-directional<br>
pictures and reference pictures according to the encoding modes to perform<br>
decoding of the image pictures.<br>
[85]	FIG. 9 is a flowchart illustrating an image decoding method<br><br>
according to an exemplary embodiment of the present invention. Referring to FIG. 9, encoding mode information included in an input bitstream is read, a plurality of encoded image pictures of the bitstream is divided into sub-groups, and encoding modes used to encode bi-directional pictures of each sub-group are determined (Operation 910).<br>
[86]	A   decoding   sequence   of the   bi-directional   pictures   and<br>
reference pictures according to the encoding modes are determined (Operation 920).<br>
[87]	The bi-directional pictures of each sub-group are decoded using<br>
the decoding sequence and the reference pictures in order to reconstruct the image (Operation 930).<br>
[88]	The present invention can also be embodied as computer-<br>
readable code on a computer-readable recording medium. The computer-<br>
readable recording medium is any data storage device that can store data<br>
which can be thereafter read by a computer system. Examples of the<br>
computer-readable recording medium include read-only memory (ROM),<br>
random-access memory (RAM), CD-ROMs, magnetic tapes, floppy disks, and<br>
optical data storage devices. The computer-readable recording medium can<br>
also be distributed over network coupled computer systems so that the<br>
computer-readable code is stored and executed in a distributed fashion.<br>
[89]	As described in the exemplary embodiments above, according<br>
to the present invention, an encoding mode, whereby reference pictures similar to pictures to be prediction-encoded are used, is determined in each sub-group,<br><br>
thereby reducing a prediction error between a prediction image and an image to be encoded according to the characteristics of the image and thus improving encoding efficiency.<br>
[90]	While the present invention has been particularly shown and<br>
described with reference to exemplary embodiments thereof, it will be understood by those of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present invention as defined by the following claims.<br><br><br>
WHAT IS CLAIMED IS;<br>
1.	An image encoding method comprising:<br>
dividing a group of pictures (GOP) including a plurality of image pictures included in an image sequence into sub-groups according to consecutive bi-directional pictures;<br>
calculating correlations between first bi-directional pictures of a first sub-group and reference pictures referred to by the first bi-directional pictures based on a plurality of encoding modes;<br>
selecting one of the plurality of encoding modes based on the correlations; and<br>
encoding B pictures of the first sub-group according to the selected encoding mode.<br>
2.	The method of claim 1, wherein the plurality of encoding modes include a bi-directional picture non-reference mode wherein the first bidirectional pictures are not used as reference pictures, a bi-directional picture reference mode wherein all the first bi-directional pictures are used as reference pictures, and a pyramid mode wherein a bi-directional picture in a center of the first bi-directional pictures of the first sub-group is used as a reference picture of other of the first bi-directional pictures.<br>
3.	The method of claim 1, wherein the calculating of the correlations comprises:<br><br><br>
calculating an average of differences between histograms of pixel values of each of the first bi-directional pictures included in the first sub-group and histograms of pixel values of the reference pictures according to the plurality of encoding modes,<br>
wherein the selecting of one of the plurality of encoding modes comprises:<br>
increasing a counting number of the encoding mode having the smallest average value from among the plurality of encoding modes; and<br>
selecting one of the plurality of encoding modes having the largest counting number.<br>
4. The method of claim 3, wherein if the reference pictures and the first bi-directional pictures have 0 through n - 1 pixel values, where n is an integral, one of the bi-directional pictures is denoted by B, one of the reference pictures is denoted by R, HB[I] denotes a number of pixels of the bi-directional picture B having a pixel value i that varies from zero to n, and HR[I] denotes a number of pixels of the reference picture R having the pixel value i, the correlations H(B,R) between the reference pictures and the first bi-directional pictures are calculated according to the following equation,  <br><br><br><br><br>
5. The method of claim 1, wherein the calculating of the correlations further comprises:<br>
calculating difference values between each of the first bi-directional pictures included in the sub-group and the reference picture according to the plurality of encoding modes using one of a Mean Square Error, a Sum of Absolute Differences, and a Sum of Squared Errors,<br>
wherein the selecting of one of the plurality of encoding modes comprises:<br>
increasing a counting number of the plurality of encoding modes having a smallest difference value from among the plurality of encoding modes; and<br>
selecting one of the plurality of encoding modes having a largest counting number.<br>
6.        An image encoding apparatus comprising:<br>
a sub-group generator that divides a group of pictures (GOP) including a plurality of image pictures included in an image sequence into subgroups according to consecutive bi-directional pictures;<br>
a correlation calculator that calculates correlations between first bidirectional pictures of a first sub-group and reference pictures referred to by the first bi-directional pictures based on a plurality of encoding modes;<br>
an encoding mode selector that selects one of the plurality of encoding modes based on the correlations; and<br><br><br>
an encoding unit that encodes B pictures of each sub-group according to the selected encoding mode.<br>
7. The apparatus of claim 6, wherein the plurality of encoding modes include a bi-directional picture non-reference mode wherein the first bidirectional pictures are not used as reference pictures, a bi-directional picture reference mode wherein all the first bi-directional pictures are used as reference pictures, and a pyramid mode wherein a bi-directional picture in a center of the first bi-directional pictures of the first sub-group is used as a reference picture of other of the first bi-directional pictures.<br>
8.	The apparatus of claim 6, wherein the correlation calculator calculates an average of differences between histograms of pixel values of each of the first bi-directional picture included in the first sub-group and histograms of pixel values of the reference pictures according to the plurality of encoding modes.<br>
9.	The apparatus of claim 6, wherein the encoding mode selector increases a counting number of the encoding mode wherein the reference pictures having a highest correlation with the first bi-directional pictures that are currently encoded are used, and selects one of the plurality of encoding modes having a largest counting number after processing the first bidirectional pictures of the first sub-group.<br><br><br>
10.	The apparatus of claim 6, wherein if the reference pictures and<br>
the bi-directional pictures have 0 through n-1 pixel values, where n is an<br>
integral, one of the bi-directional pictures is denoted by B, the reference<br>
picture is denoted by R, He[i] denotes a number of pixels of the bi-directional<br>
picture B having a pixel value i that varies from zero to n, and HR[1] denotes a<br>
number of pixels of the reference picture R having the pixel value i, the<br>
correlation calculator calculates the correlations H(B,R) between the reference<br>
pictures and the first bi-directional pictures according to the following<br><br><br><br>
equation,	 <br>
11.	The apparatus of claim 6, wherein the correlation calculates<br>
difference values between each of the first bi-directional pictures included in<br>
the sub-group and the reference pictures according to the plurality of encoding<br>
modes using one of a Mean Square Error, a Sum of Absolute Differences, and<br>
a sum of Squared Errors,<br>
wherein the encoding mode selector increases a counting number of the plurality of encoding modes having a smallest difference value from among the plurality of encoding modes, and selects one of the plurality of encoding modes having a largest counting number.<br><br><br>
12.	An image decoding method comprising:<br>
reading encoding mode information included in an input bitstream, dividing a plurality of encoded image pictures of the bitstream into sub-groups, and determining encoding modes used to encode first bi-directional pictures of a first sub-group;<br>
determining a decoding sequence of the first bi-directional pictures of the first sub-group and reference pictures according to the encoding modes; and<br>
decoding the first bi-directional pictures of the first sub-group using the decoding sequence and the reference pictures.<br>
13.	The method of claim 12, wherein the encoding modes used to<br>
encode the first bi-directional pictures of the first sub-group include a bi<br>
directional picture non-reference mode wherein the first bi-directional pictures<br>
are not used as reference pictures, a bi-directional picture reference mode<br>
wherein all the first bi-directional pictures are used as reference pictures, and a<br>
pyramid mode wherein a bi-directional picture in a center of the first bi<br>
directional pictures of the first sub-group is used as a reference picture of other<br>
of the first bi-directional pictures.<br>
14.      An image decoding apparatus comprising: an encoding mode discriminator that reads encoding mode information included in an input bitstream, divides a plurality of encoded image pictures of<br><br><br>
the input bitstream into sub-groups, and determines encoding modes used to encode bi-directional pictures of the sub-groups;<br>
a decoding sequence determiner that determines decoding sequences of the bi-directional pictures of the sub-groups and reference pictures according to the encoding modes; and<br>
a decoding unit that decodes the bi-directional pictures of the subgroups using the decoding sequences and the reference pictures.<br>
15.	The apparatus of claim 14, wherein the encoding modes used to encode bi-directional pictures of each sub-group include a bi-directional picture non-reference mode wherein the bi-directional pictures are not used as reference pictures, a bi-directional picture reference mode wherein all the bidirectional pictures are used as reference pictures, and a pyramid mode wherein bi-directional pictures in centers of the consecutive bi-directional pictures of the sub-groups are used as reference pictures of other bi-directional pictures.<br>
16.	The method of claim 1, wherein the plurality of encoding modes are classified according to whether the first bi-directional pictures are used as reference pictures of other pictures in the first sub-group and the reference pictures referred to by the first bi-directional pictures.<br>
17.	The apparatus of claim 6, wherein the plurality of encoding<br><br><br>
modes are classified according to whether the first bi-directional pictures are used as reference pictures of other pictures, and the reference pictures referred to by the first bi-directional pictures.<br><br><br>
ABSTRACT OF THE DISCLOSURE<br>
A method and apparatus for encoding/decoding an image that divide an image sequence into sub-groups and determine encoding modes applied to bidirectional pictures included in each sub-group using correlations between the bi-directional pictures and reference pictures are provided. The image encoding method includes dividing a group of pictures (GOP) to be encoded according to consecutive B pictures into sub-groups; calculating the correlations between each B picture included in the sub-group and reference picture according to each encoding mode; and applying one of the encoding modes wherein the reference picture having the highest correlation with the B picture are used in each sub-group to encode the image, thereby improving encoding efficiency.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1hYnN0cmFjdC5kb2M=" target="_blank" style="word-wrap:break-word;">2572-mum-2007-abstract.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">2572-mum-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1BTk5FWFVSRSBBICYgQigyNi00LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-ANNEXURE A &amp; B(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1DTEFJTVMoQU1FTkRFRCktKDI2LTQtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-CLAIMS(AMENDED)-(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1DTEFJTVMoTUFSS0VEIENPUFkpLSgyNi00LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-CLAIMS(MARKED COPY)-(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1jbGFpbXMuZG9j" target="_blank" style="word-wrap:break-word;">2572-mum-2007-claims.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1DT1JSRVNQT05ERU5DRSgxMi05LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-CORRESPONDENCE(12-9-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1DT1JSRVNQT05ERU5DRSgxMy0xLTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-CORRESPONDENCE(13-1-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1DT1JSRVNQT05ERU5DRSgyNS0zLTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-CORRESPONDENCE(25-3-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1DT1JSRVNQT05ERU5DRSgzLTQtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-CORRESPONDENCE(3-4-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1jb3JyZXNwb25kZW5jZS1yZWNlaXZlZC5wZGY=" target="_blank" style="word-wrap:break-word;">2572-mum-2007-correspondence-received.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1kZXNjcmlwdGlvbiAoY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-mum-2007-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1EUkFXSU5HKDI2LTQtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-DRAWING(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">2572-mum-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDEoMTItOS0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 1(12-9-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDEoMjUtMy0yMDA5KS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 1(25-3-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtIDEoMjYtMTItMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form 1(26-12-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDEoMy00LTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 1(3-4-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDEzKDEyLTktMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 13(12-9-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDEzKDMtNC0yMDA5KS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 13(3-4-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtIDEzKDMwLTMtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form 13(30-3-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDI2KDI2LTQtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 26(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDMoMTMtMS0yMDA5KS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 3(13-1-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtIDMoMjYtMTItMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form 3(26-12-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDMoMjYtNC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 3(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtIDUoMjYtMTItMjAwNykucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form 5(26-12-2007).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1GT1JNIDUoMy00LTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-FORM 5(3-4-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTEucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTE4LnBkZg==" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTIuZG9j" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-2.doc</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTIucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTI2LnBkZg==" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTMucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1tdW0tMjAwNy1mb3JtLTUucGRm" target="_blank" style="word-wrap:break-word;">2572-mum-2007-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1LT1JFQU4gRE9DVU1FTlQoMjYtNC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-KOREAN DOCUMENT(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNygyNi00LTIwMTIpLnBkZg==" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-PETITION UNDER RULE 137(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy0oMjYtNC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-PETITION UNDER RULE 137-(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1QUk9TRUNVVElPTiBISVNUT1JZIE9GIENPUlJFU1BPTkRJTkcgRVAgRE9DVU1FTlQoMjYtNC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-PROSECUTION HISTORY OF CORRESPONDING EP DOCUMENT(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1QUk9TRUNVVElPTiBISVNUT1JZIE9GIENPUlJFU1BPTkRJTkcgVVMgIERPQ1VNRU5UKDI2LTQtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-PROSECUTION HISTORY OF CORRESPONDING US  DOCUMENT(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjU3Mi1NVU0tMjAwNy1SRVBMWSBUTyBFWEFNSU5BVElPTiBSRVBPUlQoMjYtNC0yMDEyKS5wZGY=" target="_blank" style="word-wrap:break-word;">2572-MUM-2007-REPLY TO EXAMINATION REPORT(26-4-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QxLmpwZw==" target="_blank" style="word-wrap:break-word;">abstract1.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="254055-method-and-device-for-detecting-electric-arc-phenomenon-on-at-least-one-electric-cable.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="254057-polymeric-implants-preferably-containing-a-mixture-of-peg-and-plg-for-controlled-release-of-active-agents-preferably-a-gnrh.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>254056</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2572/MUM/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>38/2012</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>21-Sep-2012</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>17-Sep-2012</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>26-Dec-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>SAMSUNG ELECTRONICS CO., LTD.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>416, MAETAN-DONG, YEONGTONE-GU SUWON-SI, GYEONGGI-DO</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>HYUN-KI BAIK</td>
											<td>1208-2130 MUIGAE MAEUL JUGONG 12-DANJI APT., GUMI-DONG, BUNDANG-GU, SEONGNAM-SI, GYEONGGI-DO</td>
										</tr>
										<tr>
											<td>2</td>
											<td>NYEONG-KYU KWON</td>
											<td>105-102 DONGA APT., 201 JAYANG-DONG,DONG-GU, DAEJEON METROPOLITAN CITY</td>
										</tr>
										<tr>
											<td>3</td>
											<td>KIRAN VARAGANTI</td>
											<td>105-102 DONGA APT., 201 JAYANG-DONG, DONG-GU, DAEJEON METROPOLITAN CITY</td>
										</tr>
										<tr>
											<td>4</td>
											<td>KALYAN K. KUMAR</td>
											<td>SAMSUNG INDIA SOFTWARE OPERATIONS PVT. LTD, BAGMANE LAKEVIEW, BLOCK &#x27;B&#x27;, NO.66/1, BAGMANE TECH PARK, CV RAMAN NAGAR, BYRASANDRA, BANGALORE 560093</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/24</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10-2006-0136801</td>
									<td>2006-12-28</td>
								    <td>Republic of Korea</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/254056-method-and-apparatus-for-encoding-decoding-image by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 12:06:08 GMT -->
</html>
