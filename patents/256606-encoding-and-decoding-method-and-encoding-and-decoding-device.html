<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/256606-encoding-and-decoding-method-and-encoding-and-decoding-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 09:22:06 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 256606:ENCODING AND DECODING METHOD AND ENCODING AND DECODING DEVICE</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">ENCODING AND DECODING METHOD AND ENCODING AND DECODING DEVICE</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to a method for producing a video data stream for an expansion signal, wherein a base signal represents a first video quality degree and the expansion and base signals jointly represent a second video quality, only second syntax elements of the expansion signal which are not describable by the first syntax element of the base signal are taken into account during encoding, the coding mode of a video encoding method which is encodable by all syntax elements is selected by means of a statistical method, said second syntax elements are not representable by one or several first syntax elements and the method brings about to the production of the shortest video data stream for said second syntax elements. A decoding method for restoring the expansion signal from the video data stream, encoding and coding devices are also disclosed.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>The invention relates to an encoding method for creating a video data stream for an extension signal in accordance with the precharacterizing clause of claim 1. Furthermore the invention relates to a decoding method for reconstructing an extension signal from a video data stream and a base signal in accordance with the precharacterizing clause of claim 5. Furthermore the invention relates to an encoding device for creating a video data stream and a decoding device for reconstructing an extension signal in accordance with the precharacterizing clause of claim 7 or claim 8.<br>
For many applications digital visual signals are to be provided at a number of image quality levels. On the one hand these digital, visual signals are to be decoded and displayed on different reproduction devices, such as on a television set and also on a mobile terminal (e.g. mobile telephone) for example. On the other hand the digital visual signals are to be transferred over a plurality of transmission channels to the widest variety of devices. Thus a transmission bandwidth of several megabits per second is available in a cable network, whereas a transmission bandwidth in a mobile radio channel on the other hand possibly amounts to only a few thousand bits per second.<br>
Concepts [1, 2] are already known in which a digital visual signal is made available at a number of quality levels. The digital visual signal that represents the lowest quality level is referred to as the base signal. In documents [1, 2] the individual digital visual signals are not encoded independently of each other for this purpose, but a digital visual signal of a higher quality level is derived from one or more digital visual signals of lower quality levels (differential encoding). A differential digital visual signal of a higher quality level is referred to as an extension signal. To guarantee efficient differential encoding, the individual encoders of the various quality levels are synchronized [3]. Synchronization in this context means that decisions relating to the encoding of an image are only<br>
taken once, e.g. determining a motion vector, and then the encoders of the different quality levels are notified.<br>
The underlying object of the invention is a method and a device which make it possible for a video data stream to be created for an extension signal or for an extension signal to be reconstructed from a video data stream in a simple and efficient manner.<br>
This object is achieved, using the precharacterizing clause of claim 1 or of claim 5 respectively as its starting point, by the characterizing features of said claims. Furthermore this object is achieved, using the precharacterizing clause of claim 7 or of claim 8 respectively as its starting point, by the characterizing features of said claims.<br>
In the inventive encoding method for creating a video data stream for an extension signal, with a first video quality level being represented by a base signal and a second video quality level being represented by the extension signal together with the base signal, the base signal is assigned a number of first syntax elements and the extension signal a number of second syntax elements for description of the first or second video quality level, a modified extension signal is only allocated those second syntax elements of the extension signal which differ from the first syntax elements, the encoding mode of a video encoding standard is selected using a statistical method which can both encode all second syntax elements of the modified extension signal and which also creates the shortest video data stream, and which creates the video data stream with the second syntax elements of the modified extension signal with the selected encoding mode.<br>
Through the inventive method those second syntax elements which are already present in the first syntax elements of the base signal are no longer taken into consideration in the encoding of the extension signal. This guarantees that only those second syntax elements are encoded which cannot be reconstructed through the base signal. In this case a reduction of the volume of data of the<br>
extension signal to be transmitted is achieved. Furthermore the encoding mode for encoding the extension signal is determined which both creates all second syntax elements of the modified extension signal and also creates the shortest video data stream for them. In this case the extension signal is encoded with a small data volume and can be transmitted from a transmitter to a receiver via a narrowband radio channel.<br>
Preferably at least one second syntax element of the extension signal is assigned at least one item of information that specifies whether an image block contains at least one transform coefficient, which image area of an image block includes at least one transform coefficient and/or describes a quantizing parameter of an image block and/or signals a multiplier factor and/or includes at least one transform coefficient. Specifying at least one of these items of information guarantees that a number of encoding modes is reduced and thus an encoding mode is able to be selected more quickly by the inventive encoding method.<br>
If the selection takes account of only those encoding modes which exclude an encoding of a second syntax element which describes a motion vector of an image block, the reduction of the encoding modes to be considered enables the determination of the optimum encoding mode to be speeded up.<br>
Preferably a method in accordance with a standard, especially H.261, H.263, H.264, MPEG1, MPEG2 or MPEG4, is used as the video encoding mode. This achieves a cost-effective implementation since existing standard components can be used for the encoding. Furthermore existing standardized encoding systems can be modified with little effort in such a way as to enable the inventive encoding method to be realized.<br>
By the inventive decoding method for reconstructing an extension signal from a video data stream and a base signal, with a first video quality level being represented by a base signal and a second video quality level being represented by the extension signal together with the base signal, a modified extension signal<br>
with at least one second syntax element is created by decoding the video data stream using a decoding mode of a video encoding method and the second syntax elements of the extension signal are generated by supplementing the modified extension signal with at least one first syntax element.<br>
The inventive decoding method makes it possible to reconstruct an extension signal from a video data stream, with the video data stream having been created by the inventive encoding method.<br>
Preferably a method in accordance with a standard, especially H.261, H.263, H.264, MPEG1, MPEG2 or MPEG4, is used as the video encoding method. This achieves a cost-effective implementation of the decoding since existing standardized components can be used for the decoding. Furthermore existing standardized decoding systems can be modified with little effort in such a way as to enable the inventive decoding method to be realized.<br>
The invention further includes an encoding device for creating a video data stream for an extension signal, with a base signal for representing a first video quality level and the extension signal together with the base signal for representing a second quality level, a first means for assigning a number of second syntax elements to the extension signal and for allocating to a modified extension signal those second syntax elements that differ from first syntax elements of the base signal, a selection means for selecting that encoding mode of a video encoding method which can both encode all second syntax elements of the modified extension signal and also create the shortest video data stream, and with a second encoding module for creating the video data stream of the modified extension signal with the selected encoding mode. With the inventive encoding device the inventive encoding method can be implemented for example in an imaging device.<br>
The invention further includes a decoding device for reconstructing an extension signal from a video data stream and a base signal, with a base signal for representing a first video quality level and the extension signal together with the<br>
base signal for representing a second quality level, a second decoding means for decoding the video data stream into a modified extension signal with a number of second syntax elements using a decoding mode of a video encoding method, a second means for generating the second syntax elements of the extension signal from the second syntax elements of the modified extension signal and from at least one first syntax element. This makes it possible to execute the inventive decoding method in a reproduction device for example.<br>
Further details as well as advantages of the invention are explained in greater detail with reference to Figures 1 to 7. The individual figures show:<br>
Figure 1 a typical encoding device for creating a base video data stream with a first quality level and a video data stream with a second quality level,<br>
Figure 2 arrangement of a number of syntax elements of a base signal and of an extension signal,<br>
Figure 3 layout of different encoded video streams when one of the respective encoding modes of a video encoding method is applied,<br>
Figure 4 layout of the video data stream taking into account an encoding mode,<br>
Figures the typical layout of a decoding device for reconstructing an extension signal,<br>
Figure 6 a mobile device in the form of a portable mobile radio device with an encoding and decoding device,<br>
Figure 7 a network with a plurality of network elements and one network unit, with this network unit including an encoding and decoding device.<br>
Elements with the same method of operation and function are provided with the same reference symbols in Figures 1 to 7.<br>
The inventive method is explained in greater detail below with reference to a first exemplary embodiment using [2] the inventive method. Figure 1 shows a typical encoding device CV for creating a video data stream V for an extension signal ES.<br>
A base video data stream VB is first created with the aid of a first encoder C1 together with a first encoding module CM1. This base video data stream VB represents an encoded video signal of a first video quality level VQ1. The base video data stream VB is formed from the base signal BS, with the base signal BS also being representative of the first video quality level VQ1.<br>
A second encoder C2, a first means ZM, a selection means AM and a second encoding module CM2 create the video data stream V. This video data stream V presents an encoded video signal which, together with the base video data stream VB, represents a second quality .level VQ2. The video data stream V is formed from the extension signal ES and thus the extension signal ES together with the base signal BS also represents the second video quality level VQ2.<br>
The encoding device CV is fed a sequence of digitized input images VI. Initially a first part encoding is performed by the first encoder C1. The first encoder C1 for example thus determines with the aid of a motion estimation process a motion vector for a current image block to be encoded, forms a difference signal using coefficients from a coefficient of the current image block and a coefficient of that image block described by the motion vector determined, executes a transformation of this difference signal, for example a discrete Cosine transformation, and subsequently quantizes the transformed phase difference signal.<br>
Each transformed and quantized difference signal is referred to below as a transform coefficient. The transform coefficients of a current image block which are created by the first encoder C1 are referred to as first transform coefficients TCL1. In addition to the first transform coefficients TCL1 the first encoder C1 supplies first encoding parameters Z10, Z11, such as the first quantizing<br>
parameter Z10=QP1 for example and one or more motion vectors Z11. Thus the base signal BS includes a number of first syntax elements S10, S11, S12, such as the first quantizing parameter QP1 = 810=210, one or more motion vectors Z11 = S11 and the first transform coefficients TCL1 = S12 for example.<br>
In a next processing step the first syntax elements S10, S11, S12 are supplied to the first encoding module CM1. The task of the first encoding module CM1 is to encode the base signal BS into a base video data stream VB, In this case for example each first syntax element S10, S11, S12 is allocated a predefined position in the base video data stream VB to be created, and using compression techniques, such as a Huffman encoding for example, a reduction in data is achieved. The first encoder C1 and the first encoding module CM1 can also operate according to a video encoding method, especially according to a video encoding standard H.261, H.263, H.264, MPEG1, MPEG2 or MPEG4. The first encoder C1 and encoding module CM1 can be accommodated in a single means.<br>
In parallel to the creation of the base video data stream VB, the video data stream V for the extension signal ES is created by the second encoder C2, the first means ZM, the selection means AM and the second encoding module CM2. This is done by initially feeding the video input signal VI to the second encoder C2. By contrast with the method of operation of the first encoder C1, the second encoder is sent encoding specifications ^synchronization) by a control signal SS. In this case for example a motion vector is notified which the second encoder C2 must take into account in creating the second provisional transform coefficient TCL2*. After a motion vector to be taken into account has been transmitted to the second encoder C2 by the control signal SS for example, the second encoder C2 uses coefficients to form a difference signal from a coefficient of an image currently to be encoded and a coefficient which lies in the image area predetermined by the motion vector, executes a transformation of this difference signal, for example with the aid of a discrete Cosine transformation, and subsequently quantizes the transformed difference signal with the aid of a<br>
second quantizing parameter QP2. These transformed and quantized difference signals are referred to as second provisional transform coefficients TCL2*. In addition the second encoder C2 creates a number of second encoding parameters Z20, Z21, with for example QP2 = Z20 being the second quantizing value and Z21 being the motion vector. Alternatively one or more motion vectors can also be predetermined by means of the control signal SS.<br>
In accordance with [2] second transform coefficients TCL2 are formed using a multiplier factor a1, taking into account the second provisional transform coefficient TCL2* and the first transform coefficient TCL1. The following equation describes the precise relationship:<br>
TCL2 = TCL2* - a1 * TCL1	(1)<br>
This equation (1) is applied using coefficients.<br>
Thus the extension signal ES includes a number of second syntax elements S20, S21, S22, S23, whereby the second quantizing value QP2 = S20, the motion vector = S21, the second transform coefficient TCL2 = S22 and the multiplier factor a1 = S23. In an alternative embodiment the multiplier factor a1 can be computed from the first and second quantizing value QP1, QP2, such as a1 = QP2/QP1 for example, and thus need not be transmitted.<br>
With the aid of Figure 2 the method of operation of the first means ZM is explained in greater detail below. Figure 2 shows the individual syntax elements, first or second syntax elements for the base signal BS or for the extension signal ES. It is evident from this figure that for example the first transform coefficient TCL1 differs from the second transform coefficient TCL2, however the motion vector S11=S21 is identical in the base signal BS and also in the extension signal ES*. In a subsequent processing step the first means ZM analyzes which second syntax elements S20, ..., S23 are already present in the base signal BS, i.e. are identical to one or more first syntax elements S10, .... S12. All second syntax elements S21 which are already present in the base signal BS are removed from<br>
the extension signal ES. The result of this working step of the first means ZM is to be seen in Figure 2 in the modified extension signal ES*. This includes only the second syntax elements S20, S22, S23, since the motion vector S21 = S11 is already present in the base signal BS. This means that after this processing step by the first means ZM a modified extension signal ES* is available which only still includes those second syntax elements S20, S22, S23 which are not present in the base signal BS.<br>
In a next processing step, with the aid of the selection means AM, that encoding mode of a video encoding method is selected for creating the video data stream V with the aid of statistical methods which can both encode all second syntax elements S20, S22, S23 of the modified extension signal ES* and also creates the shortest video data stream V. This is explained in greater detail with the aid of Figure 3.<br>
Figure 3 shows the layout of different encoded video streams VS1, VS2, VS3, with the first encoded video stream VS1 being encoded with the aid of a first encoding mode and the second encoded video stream VS2 being encoded with the aid of a second encoding mode and the third encoded video stream by a third encoding mode. The first encoded video stream VS1 in this case includes the following data fields for example:<br>
Main header MH:<br>
Specifies encoding parameters, such as for example height and width of an<br>
image to be encoded, and specifies an image number within the sequence<br>
of images.<br>
Type TY:<br>
In this case a distinction can be made as to the encoding mode with which<br>
encoded video stream was created.<br>
If the encoded video stream was encoded with the aid of an interceding<br>
mode, motion vectors can follow for example. In the present exemplary<br><br>
embodiment the type TY=1 indicates that an intracoded video stream is<br>
involved here, since no motion vector follows.<br>
Quantizing parameter QP:<br>
The quantizing parameter QP specifies a value for the quantizing of the<br>
transformed difference signals.<br>
Coefficients TCL:<br>
This field includes the quantized and transformed coefficients of an image<br>
block.<br>
Extra EX:<br>
Additional parameters are specified here which can be evaluated on a<br>
proprietary basis, such as copyright information or author information for<br>
example.<br>
End field ME:<br>
This data field indicates an end of the encoded video stream.<br>
The second encoded video stream VS2 includes almost the same fields as the first encoded video stream VS1, however another type TY=2 is used to indicate that a motion vector MV is additionally present.<br>
The third encoded video stream VS3 of type TY=3 does not include any motion vector field MV and no transform coefficients TCL. Only a non-encoded field NTC is additionally present, which for example indicates that the stream contains no transform coefficients TCL.<br>
These three encoded video streams VS1,.... VS3 merely represent one possible exemplary embodiment. An actual video encoding method, such as according to the video encoding standard H.264 for example, can feature both more data fields and different data fields from this example as well as a plurality of different encoding modes.<br>
In the present exemplary embodiment the selection means AM analyzes the modified extension signal ES* and detects that at least the second quantizing value QP2, the second transform coefficient TCL2 and the multiplier vector a1<br>
must be encoded with the aid of one of the three possible encoding modes,<br>
which create either the first, second or third encoded video stream VS1	VS3.<br>
The selection means AM detects that the third encoded video stream VS3, generated by the third encoding mode, cannot encode all syntax elements S20, S22, S23 of the modified extension signal ES* to be encoded. Therefore only the first and second encoding mode will be further considered. The selection means AM now calculates the number of bits which will be needed to encode a first encoded video stream VS1 or a second encoded video stream VS2, taking into<br>
account the second syntax elements S20	 S23 of the modified extension<br>
signal ES*. The selection means AM determines for example that the first encoding mode needs 1530 bits and the second encoding mode 2860 bits for encoding. Because of this result the selection means AM decides on that encoding mode which creates the shortest video data stream V for encoding of the modified extension signal ES*. I.e. in this exemplary embodiment the selection means AM selects the first encoding mode.<br>
In a concluding processing step the second encoding means CM2 creates the video data stream V of the modified extension signal ES*. An example of this is depicted in Figure 4. In this case the video data stream V includes the main header MH, the type TY=1, the quantizing parameter QP = QP2, the second transform coefficient TCL=TCL2, in the extra field EX the multiplier factor a1 and finally the end field ME.<br>
The second encoder C2, the first means ZM, the selection means AM and the second encoding module CM2 can be combined in one or more modules. Furthermore the second encoder C2 and the second encoding module CM2 can create the video data stream V in accordance with a video encoding method, especially according to a video encoding standard H.261, H.263, H.264, MPEG1, MPEG2 or MPEG4.<br>
As shown in the exemplary embodiment in accordance with Figure 1, a motion vector to be used for the encoding by the second encoder C2 is communicated<br>
by the control signal SS for example. Thus for example the transmission of the motion vector with the aid of the video data stream V is not necessary, since the identical motion vector is transmitted by the base video data stream VB. This means that it can be useful in an alternate embodiment merely to take into account those encoding modes in the selection by the selection means AM which do not encode any motion vector. If for example three different encoding modes are present, of which the first two encoding modes execute different intra encodings, which means an encoding without motion vector, this alternative guarantees that only one of these two intra encoding modes will be taken into account.<br>
As well as the alternative in the selection of an encoding mode of taking into account one or more parameters of an entire image, it can be useful to undertake the selection of the encoding mode separately for each image block of an image.<br>
The reconstruction of the extension signal ES from the video data stream V is explained in greater detail below with reference to Figure 5. The decoding device VD for reconstructing the extension signal ES includes in this case a first decoding means DM1, which reconstructs from the base video data stream VB the first transform coefficient TCL1 and the first syntax elements S10, ...,S12. In this case the base signal BS includes the first syntax elements S10, S11, S12. With the aid of the first decoder D1 a first video output signal V1 is created which can for example be displayed with the aid of a monitor. This first video output signal V1 represents in this case a first quality level VQ1 of the video input signal VI.<br>
In addition the video data stream V is decoded with the aid of a second decoding means DM2 in such a way that a number of second syntax elements S20, S22, S23 are available at the output of the second decoding means DM2. In this case the assignment of the encoding parameters to the second syntax element is in accordance with the embodiments for Figure 1. Now, with the aid of an extension means EM, those second syntax elements S21 are recovered which were<br>
previously removed by the first means ZM from the extension signal ES. Thus for example the motion vector Z11 = S11 is copied into the second syntax element S21. Thus the extension signal ES is reconstructed which includes the second syntax elements S20=Z20, S21=Z21, S22=TCL2, S23=L1. Before a second video output signal V2 can be created with the aid of a second decoder D2, the first transform coefficient TCL1 must still be logically combined with the second transform coefficient TCL2. This is undertaken using coefficients according to the following equation:<br>
TCL2* = a1 * TCL1 + TCL2	(2)<br>
Thus the modified second transform coefficient TCL2* is created with the aid of the first transform coefficient TCL1 and the second transform coefficient TCL2. With the aid of the second syntax elements S20=Z20, S21=Z21 and the modified second transform coefficients TCL2, the second decoder D2 is able to generate the second video output signal V2, which represents a second quality level VQ2 of the video input signal VI. This can for example be output on a monitor.<br>
In an alternate embodiment in accordance with Figure 6 the encoding device CV and/or the decoding device DV can be implemented in a mobile device MG, for example a mobile radio device according to the GSM standard. Alternatively the mobile device MG can have means for executing the inventive encoding method and/or decoding method. Thus the invention can be used for example in a mobile device MG according to the GSM (GSM - Global System for Mobile) system. Furthermore the encoding device CV and/or the decoding device DV can be implemented in a processor unit, such as a computer for example.<br>
In a further alternate embodiment the network unit NET, the encoding device CV and/or the decoding device DV can be implemented in a network unit NET in accordance with Figure 7, with a network NZ including network modules NK1, NK2 and the network unit NET. Alternately the network unit NET can have means for executing the inventive encoding method and/or decoding method. The network NZ can typically be embodied in accordance with the GSM standard<br>
and/or UMTS standard (UMTS - Universal Mobile Telecommunications System). Furthermore the invention can typically be employed in a network unit according to an IMS standard (IMS - IP Multimedia Subsystem).<br>
Literature references<br>
[1] K. Illgner, J. Pandel, "Effiziente Codierung von Videosignalen fur skalierbare Multicast-Speicherung und Obertragung sowie zugehoriger Codec" (efficient encoding of video signals for scalable multicast storage and transmission as well as associated codec), publication DE 102 00 901 A1<br>
[2] P. Amon, G. Base, J. Pandel, "Pradiktion von Videosignalpegeln fQr skalierbare Simulcast-Speicherung und Obertragung" (prediction of video signal levels for scalable simulcast storage and transmission), file reference of German patent application DE 101 46 220.4<br>
[3] P. Amon, K. Illgner, J. Pandel, "Verfahren zum Codieren und Decodieren von Videosequenzen und Computerprogrammprodukt" (method for encoding and decoding of video sequences and computer program product), Publication DE 102 19 640 A1<br><br><br><br><br>
We Claim:-<br>
1. An encoding method for creating a video data stream (V) for an extension signal<br>
(ES), with a first video quality level(VQ1) being represented by a base signal (6s)<br>
and a second video quality level (VQ2) being represented by the extension signal<br>
(is) together with the.base signal (BS), comprising the following steps:<br>
a) assigning a plurality of first syntax elements (S10, S11, S12), to the base signal<br>
j3S) to describe the first video quality level;<br>
b) assigning a plurality of second syntax elements (S20JS21,S22,S23) to the<br>
extension signal (ES) to describe second video quality level;<br>
c) modifying the extension signal to form a modified extension signal (ES*) which is<br>
allocated with only those second syntax elements (520, S22, S23) of the extension<br>
signal (ES) which differ from the first syntax elements (S10, S11, S12),<br>
,<br>
d) selecting an encoding mode for video encoding from a plurality of encoding<br>
modes, the encoding mode being selected to encode all second syntax elements<br>
(520, S22, S23) of the modified extension signal (ES*) and to create the shortest<br>
video data stream (V), the encoding mode being selected using a statisticai<br>
method; and<br>
d) creating the video data stream (V) with the second syntax elements (S20, S22,<br>
S23) of the modified extension signal (ES*) with the selected encoding mode.<br>
2. The method as claimed in claim 1, wherein at least one second syntax element<br>
(S20, S22, 523) of the extension signal (ES) is allocated at least one item of<br>
information about the. presence of at least one transform coefficient of an image<br>
block and/or about an assignment of image areas of an image block which<br>
include at least one transform coefficient and/or a quantizing parameter of an<br>
imzge block and/or a multiplier factor and/or at least one transform coefficient.<br>
3. The method as claimed in claim 1, wherein the said encoding modes are taken<br>
into account in the selection which exclude an encoding of a second syntax<br>
element (S20, S22, S23) which describes a motion vector of an image block.<br>
4. A decoding method for reconstructing an original extension signal (ES) from a<br>
video data stream (V) including a base signal (BS) and a modified extension signal<br>
(ES*), the base signal representing a first video quality level (VQl), the base signal<br>
together with the original extension signal representing a second video quality<br>
ievel(VQ2), the video data stream being encoded using a selected video encoding<br>
method comprising the following steps:<br>
using a decoding mode of the selected video encoding method to reconstruct the<br>
modified extension signal, the modified extension signal having a plurality of<br>
second syntax elements (S20, S22,523);<br>
obtaining the original extension signal (ES) by supplementing the second syntax<br>
elements (S20, S21, 522, S23) of the modified extension signal (ES*)with at teast<br>
one first syntax element (SlO, S11, S12) of the base signal (BS).<br>
An encoding device (CV) for creating a video data stream (V) for an extension<br>
signal (ES), with a first video quality level (VQ1) being represented by a base<br>
signal (BS) and a second video quality level (VQ2) being represented by the<br>
extension signal together with the base signal, the base signal having a plurality<br>
of first syntax elements assigned thereto to describe the first video quality level,<br>
the extension signal having a plurality of second syntax elements assigned<br>
thereto to describe the second video quality level, comprising:<br>
a modification unit to modify the extension signal to form a modified extension<br>
signal, the modified extension signal only including those second syntax elements<br>
of the extension signal which differ from the first syntax elements;<br>
a selection unit (AM) to select an encoding mode for video encoding from a<br>
plurality of encoding modes, the encoding mode being selected to encode all<br>
second syntax elements of the modified extension signal and to create the video<br>
data stream that is shorter than a video data stream that would have been<br>
created with any of the other encoding modes, the encoding mode being<br>
selected using a statistical method; and<br>
an encoder to create the video data stream with the second syntax elements of<br>
the modified extension signal using the selected encoding mode.<br>
6. A decoding device (DV) to reconstruct an original extension signal (ES) from a<br>
video data stream (V) including a base signal (BS) and a modified extension signal,<br>
the base signal representing a first video quality level (VQl), the base signal<br>
together with the original extension signal representing a second video quality<br>
level (VQ2), the video data stream (V) being encoded using a selected video<br>
encoding method comprising:<br>
a decoding unit (DM2) to use a decoding mode of the selected video encoding<br>
method to reconstruct the modified extension signal, the modified extension<br>
signal having a plurality of second syntax elements; and<br>
a supplementing unit (EM) to obtain the original extension signal by<br>
supplementing the second syntax elements of the modified extension signal with<br>
at least one first syntax element of the base signal.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUFzc2lnbm1lbnQtKDI1LTA1LTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Assignment-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUNsYWltcy0oMTktMDMtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Claims-(19-03-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LUNsYWltcy0oMjgtMDYtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-Claims-(28-06-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMDktMDctMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-Correspondence Others-(09-07-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMTktMDMtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Correspondence Others-(19-03-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LUNvcnJlc3BvbmRlbmNlIE90aGVycy0oMjgtMDYtMjAxMykucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-Correspondence Others-(28-06-2013).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUNvcnJlc3BvbmRlbmNlLU90aGVycy0oMjUtMDUtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Correspondence-Others-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWNvcnJlc3BvbmRlbmNlLW90aGVycy0xLnBkZg==" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-correspondence-others-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWNvcnJlc3BvbmRlbmNlLW90aGVycy5wZGY=" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUZvcm0tMS0oMjUtMDUtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Form-1-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tMS5wZGY=" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tMTgucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tMi5wZGY=" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUZvcm0tMjYtKDI1LTA1LTIwMDkpLnBkZg==" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Form-26-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tMjYucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LUZvcm0tMy0oMDktMDctMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-Form-3-(09-07-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUZvcm0tMy0oMTktMDMtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Form-3-(19-03-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUZvcm0tMy0oMjUtMDUtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Form-3-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tMy5wZGY=" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LUZvcm0tNS0oMjUtMDUtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Form-5-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tNS5wZGY=" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LWZvcm0tNi0oMjUtMDUtMjAwOSkucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-form-6-(25-05-2009).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1kZWxucC0yMDA3LXBjdC0zMDQucGRm" target="_blank" style="word-wrap:break-word;">3701-delnp-2007-pct-304.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzcwMS1ERUxOUC0yMDA3LVBldGl0aW9uLTEzNy0oMTktMDMtMjAxMikucGRm" target="_blank" style="word-wrap:break-word;">3701-DELNP-2007-Petition-137-(19-03-2012).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QuanBn" target="_blank" style="word-wrap:break-word;">abstract.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="256605-a-method-for-trick-mode-operation-in-a-personal-video-recorder-and-the-personal-video-recorder-thereof.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="256607-solubilized-benzoyl-peroxide-topical-drug-formulation.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>256606</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3701/DELNP/2007</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>28/2013</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>12-Jul-2013</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>08-Jul-2013</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>17-May-2007</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>NOKIA SIEMENS NETWORKS GMBH &amp; CO. KG</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>ST. MARTIN STR. 76, 81541 MUNCHEN, GERMANY</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>AMON; PETER</td>
											<td>EINSTEINSTRABE 151, 81675 MUNCHEN, GERMANY</td>
										</tr>
										<tr>
											<td>2</td>
											<td>PANDEL; JURGEN</td>
											<td>OLBERGRING 36, 83620 FELDKIRCHEN-WESTERHAM, GERMANY</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/26</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/EP2005/055824</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2005-11-08</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10 2004 056 447.7</td>
									<td>2004-11-23</td>
								    <td>Germany</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/256606-encoding-and-decoding-method-and-encoding-and-decoding-device by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 09:22:07 GMT -->
</html>
