<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/270794-method-and-apparatus-for-bandwidth-extension-of-audio-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:30:12 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 270794:METHOD AND APPARATUS FOR BANDWIDTH EXTENSION OF AUDIO SIGNAL</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR BANDWIDTH EXTENSION OF AUDIO SIGNAL</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>One provides (101) a digital audio signal having a corresponding signal bandwidth, and then provides (102) an energy value that corresponds to at least an estimate of out-of-signal bandwidth energy as corresponds to that digital audio signal. One then uses (103) the energy value to simultaneously determine both a spectral envelope shape and a corresponding suitable energy for the spectral envelope shape for out-of-signal bandwidth content as corresponds to the digital audio signal. By one approach, if desired, one then combines (104) (on, for example, a frame by frame basis) the digital audio signal with the out-of-signal bandwidth content to provide a bandwidth extended version of the digital audio signal to be audibly rendered to thereby improve corresponding audio quality of the digital audio signal as so rendered.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>METHOD AND APPARATUS FOR BANDWIDTH EXTENSION OF AUDIO SIGNAL<br>
Technical Field<br>
[0001] This invention relates generally to rendering audible content and more<br>
particularly to bandwidth extension techniques.<br>
Background<br>
[0002] The audible rendering of audio content from a digital representation<br>
comprises a known area of endeavor. In some application settings the digital<br>
representation comprises a complete corresponding bandwidth as pertains to an<br>
original audio sample. In such a case, the audible rendering can comprise a highly<br>
accurate and natural sounding output. Such an approach, however, requires<br>
considerable overhead resources to accommodate the corresponding quantity of data.<br>
In many application settings, such as, for example, wireless communication settings,<br>
such a quantity of information cannot always be adequately supported.<br>
[0003] To accommodate such a limitation, so-called narrow-band speech<br>
techniques can serve to limit the quantity of information by, in rum, limiting the<br>
representation to less than the complete corresponding bandwidth as pertains to an<br>
original audio sample. As but one example in this regard, while natural speech<br>
includes significant components up to 8 kHz (or higher), a narrow-band representation<br>
may only provide information regarding, say, the 300 - 3,400 Hz range. The resultant<br>
content, when rendered audible, is typically sufficiently intelligible io support the<br>
functional needs of speech-based communication. Unfortunately, however, narrow-<br>
band speech processing also tends to yield speech that sounds muffled and may even<br>
have reduced intelligibility as compared to full-band speech.<br>
[0004] To meet this need, bandwidth extension techniques are sometimes<br>
employed. One artificially generates the missing information in the higher and/or<br>
lower bands based on the available narrow-band information as well as other<br>
information to select information that can be added to the narrow-band content to<br>
thereby synthesize a pseudo wide (or full) band signal. Using such techniques, for<br>
example, one can transform narrow-band speech in the 300 - 3400 Hz range to<br>
wideband speech, say, in the 100 - 8000 Hz range. Towards this end, a critical piece<br>
of information that is required is the spectral envelope in the high-band (3400 - 8000<br>
Hz). If the wideband spectral envelope is estimated, the high-band spectral envelope<br>
can then usually be easily extracted from it. One can think of the high-band spectral<br>
envelope as comprised of a shape and a gain (or equivalcntly, energy).<br>
[0005] By one approach, for example, the high-band spectral envelope shape<br>
is estimated by estimating the wideband spectral envelope from the narrow-band<br>
spectral envelope through codebook mapping. The high-band energy is then estimated<br>
by adjusting the energy within the narrow-band section of the wideband spectral<br>
envelope to match the energy of the narrow-band spectral envelope. In this approach,<br>
the high-band spectral envelope shape determines the high-band energy and any<br>
mistakes in estimating the shape will also correspondingly affect the estimates of the<br>
high-band energy.<br>
[0006] In another approach, the high-band spectral envelope shape and the<br>
high-band energy are separately estimated, and the high-band spectral envelope that is<br>
finally used is adjusted to match the estimated high-band energy. By one related<br>
approach the estimated high-band energy is used, besides other parameters, to<br>
determine the high-band spectral envelope shape. However, the resulting high-band<br>
spectral envelope is not necessarily assured of having the appropriate high-band<br>
energy. An additional step is therefore required to adjust the energy of the high-band<br>
spectral envelope to the estimated value. Unless special care is taken, this approach<br>
will result in a discontinuity in the wideband spectral envelope at the boundary<br>
between the narrow-band and high-band. While the existing approaches to bandwidth<br>
extension, and, in particular, to high-band envelope estimation are reasonably<br>
successful, they do not necessarily yield resultant speech of suitable quality in at least<br>
some application settings.<br>
[0007] In order to generate bandwidth extended speech of acceptable quality,<br>
the number of artifacts in such speech should be minimized. It is known that over-<br>
estimation of high-band energy results in annoying artifacts. Incorrect estimation of<br>
the high-band spectral envelope shape can also lead to artifacts but these artifacts are<br>
usually milder and arc easily masked by the narrow-band speech.<br>
Brief Description of the Drawings<br>
[0008] The above needs are at least partially met through provision of the<br>
method and apparatus to facilitate provision and use of an energy value to determine a<br>
spectral envelope shape for out-of-signal bandwidth content described in the<br>
following detailed description, particularly when studied in conjunction with the<br>
drawings, wherein:<br>
[0009] FIG. 1 comprises a flow diagram as configured in accordance with<br>
various embodiments of the invention;<br>
[0010] FIG. 2 comprises a graph as configured in accordance with various<br>
embodiments of the invention;<br>
[0011] FIG. 3 comprises a block diagram as configured in accordance with<br>
various embodiments of the invention;<br>
[0012] FIG. 4 comprises a block diagram as configured in accordance with<br>
various embodiments of the invention;<br>
[0013] FIG. 5 comprises a block diagram as configured in accordance with<br>
various embodiments of the invention; and<br>
[0014] FIG. 6 comprises a graph as configured in accordance with various<br>
embodiments of the invention.<br>
[0015] Skilled artisans will appreciate that elements in the figures are<br>
illustrated for simplicity and clarity and have not necessarily been drawn to scale. For<br>
example, the dimensions and/or relative positioning of some of the elements in the<br>
figures may be exaggerated relative to other elements to help to improve<br>
understanding of various embodiments of the present invention. Also, common but<br>
well-understood elements that are useful or necessary in a commercially feasible<br>
embodiment are often not depicted in order to facilitate a less obstructed view of these<br>
various embodiments of the present invention. It will further be appreciated that<br>
certain actions and/or steps may be described or depicted in a particular order of<br>
occurrence while those skilled in the art will understand that such specificity with<br>
respect to sequence is not actually required. It will also be understood that the terms<br>
and expressions used herein have the ordinary meaning as is accorded to such terms<br>
and expressions with respect to their corresponding respective areas of inquiry and<br>
study except where specific meanings have otherwise been set forth herein.<br>
Detailed Description<br>
[0016] Generally speaking, pursuant to these various embodiments, one<br>
provides a digital audio signal having a corresponding signal bandwidth, and then<br>
provides an energy value that corresponds to at least an estimate of out-of-signal<br>
bandwidth energy as corresponds to that digital audio signal. One can then use this<br>
energy value to simultaneously determine both a spectral envelope shape and a<br>
corresponding suitable energy for the spectral envelope shape for out-of-signal<br>
bandwidth content as corresponds to the digital audio signal. By one approach, if<br>
desired, one then combines (on a frame by frame basis) the digital audio signal with<br>
the out-of-signal bandwidth content to provide a bandwidth extended version of the<br>
digital audio signal to be audibly rendered to thereby improve corresponding audio<br>
quality of the digital audio signal as so rendered.<br>
[0017] So configured, the out-of-band energy implies the out-of-band spectral<br>
envelope; that is, the estimated energy value is used to determine the out-of -band<br>
spectral envelope, i.e., a spectral shape and a corresponding suitable energy. Such an<br>
approach proves to be relatively simple to implement and process. The single out-of-<br>
band energy parameter is easier to control and manipulate than the multi-dimensional<br>
out-of-band spectral envelope. As a result, this approach also tends to yield resultant<br>
audible content of a higher quality than at least some of the prior art approaches used<br>
to date.<br>
[0018] These and other benefits may become clearer upon making a thorough<br>
review and study of the following detailed description. Referring now to the drawings,<br>
and in particular to FIG. 1, a corresponding process 100 can begin with provision 101<br>
of a digital audio signal that has a corresponding signal bandwidth. In a typical<br>
application setting, this will comprise providing a plurality of frames of such content.<br>
These teachings will readily accommodate processing each such frame as per the<br>
described steps. By one approach, for example, each such frame can correspond to 10<br>
- 40 milliseconds of original audio content.<br>
|0019] This can comprise, for example, providing a digital audio signal that<br>
comprises synthesized vocal content. Such is the case, for example, when employing<br>
these teachings in conjunction with received vo-coded speech content in a portable<br>
wireless communications device. Other possibilities exist as well, however, as will be<br>
well understood by those skilled in the art. For example, the digital audio signal might<br>
instead comprise an original speech signal or a re-sampled version of either an<br>
original speech signal or synthesized speech content.<br>
[0020] Referring momentarily to FIG. 2, it will be understood that this digital<br>
audio signal pertains to some original audio signal 201 that has an original<br>
corresponding signal bandwidth 202. This original corresponding signal bandwidth<br>
202 will typically be larger than the aforementioned signal bandwidth as corresponds<br>
to the digital audio signal. This can occur, for example, when the digital audio signal<br>
represents only a portion 203 of the original audio signal 201 with other portions<br>
being left out-of-band. In the illustrative example shown, this includes a low-band<br>
portion 204 and a high-band portion 205. Those skilled in the art will recognize that<br>
this example serves an illustrative purpose only and that the unrepresented portion<br>
may only comprise a low-band portion or a high-band portion. These teachings would<br>
also be applicable for use in an application setting where the unrepresented portion<br>
falls mid-band to two or more represented portions (not shown).<br>
[0021] It will therefore be readily understood that the unrepresented portion(s)<br>
of the original audio signal 201 comprise content that these present teachings may<br>
reasonably seek to replace or otherwise represent in some reasonable and acceptable<br>
manner. It will also be understood this signal bandwidth occupies only a portion of<br>
the Nyquist bandwidth determined by the relevant sampling frequency. This, in turn,<br>
will be understood to further provide a frequency region in which to effect the desired<br>
bandwidth extension.<br>
[0022] Referring again to FIG. 1, this process 100 then provides 102 an<br>
energy value that corresponds to at least an estimate of the out-of-signal bandwidth<br>
energy as corresponds to the digital audio signal. For many application settings, this<br>
can be based, at least in part, upon an assumption that the original signal had a wider<br>
bandwidth than that of the digital audio signal itself.<br>
[0023] By one approach, this step can comprise estimating the energy value as<br>
a function, at least in part, of the digital audio signal itself. By another approach, if<br>
desired, this can comprise receiving information from the source that originally<br>
transmitted the aforementioned digital audio signal that represents, directly or<br>
indirectly, this energy value. The latter approach can be useful when the original<br>
speech coder (or other corresponding source) includes the appropriate functionality to<br>
permit such an energy value to be directly or indirectly measured and represented by<br>
one or more corresponding metrics that are transmitted, for example, along with the<br>
digital audio signal itself.<br>
[0024] This out-of-signal bandwidth energy can comprise energy that<br>
corresponds to signal content that is higher in frequency than the corresponding signal<br>
bandwidth of the digital audio signal. Such an approach is appropriate, for example,<br>
when the aforementioned removed content itself comprises content that occupies a<br>
bandwidth that is higher in frequency than the audio content that is directly<br>
represented by the digital audio signal. In the alternative, or in combination with the<br>
above, this out-of-signal bandwidth energy can correspond to signal content that is<br>
lower in frequency than the corresponding signal bandwidth of the digital audio<br>
signal. This approach, of course, can complement that situation which exists when the<br>
aforementioned removed content itself comprises content that occupies a bandwidth<br>
that is lower in frequency than the audio content that is directly represented by the<br>
digital audio signal.<br>
[0025] This process 100 then uses 103 this energy value (which may comprise<br>
multiple energy values when multiple discrete removed portions are represented<br>
thereby as suggested above) to determine a spectral envelope shape to suitably<br>
represent the out-of-signal bandwidth content as corresponds to the digital audio<br>
signal. This can comprise, for example, using the energy value to simultaneously<br>
determine a spectral envelope shape and a corresponding suitable energy for the<br>
spectral envelope shape that is consistent with the energy value for out-of-signal<br>
bandwidth content as corresponds to the digital audio signal.<br>
[0026] By one approach, this can comprise using the energy value to access a<br>
look-up table that contains a plurality of corresponding candidate spectral envelope<br>
shapes. By another approach, this can comprise using the energy value to access a<br>
look-up table that contains a plurality spectral envelope shapes and interpolating<br>
between two or more of these shapes to obtain the desired spectral envelope shape. By<br>
yet another approach, this can comprise selecting one of two or more look-up tables<br>
using one or more parameters derived from the digital audio signal and using the<br>
energy value to access the selected look-up table that contains a plurality of<br>
corresponding candidate spectral envelope shapes. This can comprise, if desired,<br>
accessing candidate shapes that are stored in a parametric form. These teachings will<br>
also accommodate deriving one or more such shapes as needed using an appropriate<br>
mathematical function of choice as versus extracting the shape from such a table if<br>
desired.<br>
[0027] This process 100 will then optionally accommodate combining 104 the<br>
digital audio signal with the out-of-signal bandwidth content to thereby provide a<br>
bandwidth extended version of the digital audio signal to thereby improve the<br>
corresponding audio quality of the digital audio signal when rendered in audible form.<br>
By one approach, this can comprise combining two items that are mutually exclusive<br>
with respect to their spectral content. In such a case, such a combination can take the<br>
segments together. By another approach, if desired, the out-of-signal bandwidth<br>
content can have a portion that is within the corresponding signal bandwidth of the<br>
digital audio signal. Such an overlap can be useful in at least some application settings<br>
to smooth and/or feather the transition from one portion to the other by combining the<br>
overlapping portion of the out-of-signal bandwidth content with the corresponding in-<br>
band portion of the digital audio signal.<br>
[0028] Those skilled in the art will appreciate that the above-described<br>
processes are readily enabled using any of a wide variety of available and/or readily<br>
configured platforms, including partially or wholly programmable platforms as arc<br>
known in the art or dedicated purpose platforms as may be desired for some<br>
applications. Referring now to FIG. 3, an illustrative approach to such a platform will<br>
now be provided.<br>
[0029] In this illustrative example, in an apparatus 300 a processor 301 of<br>
choice operably couples to an input 302 that is configured and arranged to receive a<br>
digital audio signal having a corresponding signal bandwidth. When the apparatus 300<br>
comprises a wireless two-way communications device, such a digital audio signal can<br>
be provided by a corresponding receiver 303 as is well known in the art. In such a<br>
case, for example, the digital audio signal can comprise synthesized vocal content<br>
formed as a function of received vo-coded speech content.<br>
[0030] The processor 301, in turn, can be configured and arranged (via, for<br>
example, corresponding programming when the processor 301 comprises a partially<br>
or wholly programmable platform as are known in the art) to carry out one or more of<br>
the steps or other functionality set forth herein. This can comprise, for example,<br>
providing an energy value that corresponds to at least an estimate of out-of-signal<br>
bandwidth energy as corresponds to the digital audio signal and then using that energy<br>
value and a set of energy-indexed shapes to determine a spectral envelope shape for<br>
out-of-bandwidth content as corresponds to the digital audio signal.<br>
can serve to facilitate accessing a look-up table that contains a plurality of<br>
corresponding candidate spectral envelope shapes. To support such an approach, this<br>
apparatus can also comprise, if desired, one or more look-up tables 304 that are<br>
operably coupled to the processor 301. So configured, the processor 301 can readily<br>
access the look-up table 304 as appropriate.<br>
[0032] Those skilled in the art will recognize and understand that such an<br>
apparatus 300 may be comprised of a plurality of physically distinct elements as is<br>
suggested by the illustration shown in FIG. 3. It is also possible, however, to view this<br>
illustration as comprising a logical view, in which case one or more of these elements<br>
can be enabled and realized via a shared platform. It will also be understood that such<br>
a shared platform may comprise a wholly or at least partially programmable platform<br>
as are known in the art.<br>
[0033] Referring now to FIG. 4, input narrow-band speech snb sampled at 8<br>
kHz is first up-sampled by 2 using a corresponding upsampler 401 to obtain up-<br>
sampled narrow-band speech snb sampled at 16 kHz. This can comprise performing an<br>
1:2 interpolation (for example, by inserting a zero-valued sample between each pair of<br>
original speech samples) followed by low-pass filtering using, for example, a low-<br>
pass filter (LPF) having a pass-band between 0 and 3400 Hz.<br>
[0034] From snb, the narrow-band linear predictive (LP) parameters, Anb = {1,<br>
a1, a2,..., ap) where P is the model order, are also computed using an LP analyzer<br>
402 that employs well-known LP analysis techniques. (Other possibilities exist, of<br>
course; for example, the LP parameters can be computed from a 2:1 decimated<br>
version of snb) These LP parameters model the spectral envelope of the narrow-band<br>
input speech as<br>
[0035J <br>
[0036] In the equation above, the angular frequency ? in radians/sample is<br>
given by ?= 2pf/Fs, where/is the signal frequency in Hz and Fs is the sampling<br>
frequency in Hz. For a sampling frequency Fs of 8 kHz, a suitable model order P, for<br>
example, is 10.<br>
[0037] The LP parameters Anb are then interpolated by 2 using an<br>
interpolation module 403 to obtain Anb = {1, 0, a1, 0, a2, 0, ..., 0, ap}. Using Anb, the<br>
up-sampled narrow-band speech snb is inverse filtered using an analysis filter 404 to<br>
obtain the LP residual signal rnb (which is also sampled at 16 kHz). By one approach,<br>
this inverse (or analysis) filtering operation can be described by the equation<br>
[0038] <br>
[0039] where n is the sample index.<br>
[0040] In a typical application setting, the inverse filtering of snb to obtain rnb<br>
can be done on a frame-by-frame basis where a frame is defined as a sequence of N<br>
consecutive samples over a duration of T seconds. For many speech signal<br>
applications, a good choice for T is about 20 ms with corresponding values for N of<br>
about 160 at 8 kHz and about 320 at 16 kHz sampling frequency. Successive frames<br>
may overlap each other, for example, by up to or around 50%, in which case, the<br>
second half of the samples in the current frame and the first half of the samples in the<br>
following frame are the same, and a new frame is processed every T/2 seconds. For a<br>
choice of T as 20 ms and 50% overlap, for example, the LP parameters Anb are<br>
computed from 160 consecutive snb samples every 10 ms, and are used to inverse<br>
filter the middle 160 samples of the corresponding snb frame of 320 samples to yield<br>
160 samples of rnb.<br>
[0041] One may also compute the 2P-order LP parameters for the inverse<br>
filtering operation directly from the up-sampled narrow-band speech. This approach,<br>
however, may increase the complexity of both computing the LP parameters and the<br>
inverse filtering operation, without necessarily increasing performance under at least<br>
some operating conditions.<br>
[0042] The LP residual signal rnb is next full-wave rectified using a full-wave<br>
rectifier 405 and high-pass filtering the result (using, for example, a high-pass filter<br>
(HPF) 406 with a pass-band between 3400 and 8000 Hz) to obtain the high-band<br>
rectified residual signal rrhb. In parallel, the output of a pseudo-random noise source<br>
407 is also high-pass filtered 408 to obtain the high-band noise signal nhb. These two<br>
signals, viz., rrhb, and nhb, are then mixed in a mixer 409 according to the voicing level<br>
v provided by an Estimation &amp; Control Module (ECM) 410 (which module will be<br>
described in more detail below). In this illustrative example, this voicing level v<br>
ranges from 0 to 1, with 0 indicating an unvoiced level and 1 indicating a fully-voiced<br>
level. The mixer 409 essentially forms a weighted sum of the two input signals at its<br>
output after ensuring that the two input signals are adjusted to have the same energy<br>
level. The mixer output signal mhb is given by<br>
[0043] <br>
[0044J Those skilled in the art will appreciate that other mixing rules are also<br>
possible. It is also possible to first mix the two signals, viz., the full-wave rectified LP<br>
residual signal and the pseudo-random noise signal, and then high-pass filter the<br>
mixed signal, in this case, the two high-pass filters 406 and 408 are replaced by a<br>
single high-pass filter placed at the output of the mixer 409.<br>
[0045] The resultant signal mhb is then pre-processed using a high-band (HB)<br>
excitation preprocessor 411 to form the high-band excitation signal exhb. The pre-<br>
processing steps can comprise: (i) scaling the mixer output signal mhb to match the<br>
high-band energy level Ehb, and (ii) optionally shaping the mixer output signal mhb to<br>
match the high-band spectral envelope SEhb. Both Ehb and SEhb are provided to the HB<br>
excitation pre-processor 411 by the ECM 410. When employing this approach, it may<br>
be useful in many application settings to ensure that such shaping does not affect the<br>
phase spectrum of the mixer output signal mhb; that is, the shaping may preferably be<br>
performed by a zero-phase response filter.<br>
[0046] The up-sampled narrow-band speech signal snb and the high-band<br>
excitation signal exhb are added together using a summer 412 to form the mixed-band<br>
signal smb. This resultant mixed-band signal smb is input to an equalizer filter 413 that<br>
filters that input using wide-band spectral envelope information SEwb provided by the<br>
ECM 410 to form the estimated wide-band signal swb. The equalizer filter 413<br>
essentially imposes the wide-band spectral envelope SEwb on the input signal smb to<br>
form swb (further discussion in this regard appears below). The resultant estimated<br>
wide-band signal Swb is high-pass filtered, e.g., using a high pass filter 414 having a<br>
pass-band from 3400 to 8000 Hz, and low-pass filtered, e.g., using a low pass filter<br>
415 having a pass-band from 0 to 300 Hz, to obtain respectively the high-band signal<br>
Shb and the low-band signal slb. These signals shb, slb, and the up-sampled narrow-band<br>
signal snb are added together in another summer 416 to form the bandwidth extended<br>
signal Sbwe.<br>
[0047] Those skilled in the art will appreciate that there are various other filter<br>
configurations possible to obtain the bandwidth extended signal Sbwe. If the equalizer<br>
filter 413 accurately retains the spectral content of the up-sampled narrow-band<br>
speech signal snb which is part of its input signal smb, then the estimated wide-band<br>
signal swb can be directly output as the bandwidth extended signal Sbwe thereby<br>
eliminating the high-pass filter 414, the low-pass filter 415, and the summer 416.<br>
Alternately, two equalizer filters can be used, one to recover the low frequency<br>
portion and another to recover the high-frequency portion, and the output of the<br>
former can be added to high-pass filtered output of the latter to obtain the bandwidth<br>
extended signal Sbwe.<br>
[0048] Those skilled in the art will understand and appreciate that, with this<br>
particular illustrative example, the high-band rectified residual excitation and the<br>
high-band noise excitation are mixed together according to the voicing level. When'<br>
the voicing level is 0 indicating unvoiced speech, the noise excitation is exclusively<br>
used. Similarly, when the voicing level is 1 indicating voiced speech, the high-band<br>
rectified residual excitation is exclusively used. When the voicing level is in between<br>
0 and 1 indicating mixed-voiced speech, the two excitations are mixed in appropriate<br>
proportion as determined by the voicing level and used. The mixed high-band<br>
excitation is thus suitable for voiced, unvoiced, and mixed-voiced sounds.<br>
[0049] It will be further understood and appreciated that, in this illustrative<br>
example, an equalizer filter is used to synthesize sWb. The equalizer filter considers the<br>
wide-band spectral envelope SEwb provided by the ECM as the ideal envelope and<br>
corrects (or equalizes) the spectral envelope of its input signal smb to match the ideal.<br>
Since only magnitudes are involved in the spectral envelope equalization, the phase<br>
response of the equalizer filter is chosen to be zero. The magnitude response of the<br>
equalizer filter is specified by SEwb(?)/SEmb(?). The design and implementation of<br>
such an equalizer filter for a speech coding application comprises a well understood<br>
area of endeavor. Briefly, however, the equalizer filler operates as follows using<br>
overlap-add (OLA) analysis.<br>
[0050] The input signal smb is first divided into overlapping frames, e.g., 20<br>
ms (320 samples at 16 kHz) frames with 50% overlap. Each frame of samples is then<br>
multiplied (point-wise) by a suitable window, e.g., a raised-cosine window with<br>
perfect reconstruction property. The windowed speech frame is next analyzed to<br>
estimate the LP parameters modeling its spectral envelope. The ideal wide-band<br>
spectral envelope for the frame is provided by the ECM. From the two spectral<br>
envelopes, the equalizer computes the filter magnitude response as SEwb(?)/SEmb(?)<br>
and sets the phase response to zero. The input frame is then equalized to obtain the<br>
corresponding output frame. The equalized output frames are finally overlap-added to<br>
synthesize the estimated wide-band speech swb.<br>
[0051J Those skilled in the art will appreciate that besides LP analysis, there<br>
are other methods to obtain the spectral envelope of a given speech frame, e.g.,<br>
cepstral analysis, piecewise linear or higher order curve fitting of spectral magnitude<br>
peaks, etc.<br>
[0052] Those skilled in the art will also appreciate that instead of windowing<br>
the input signal §mb directly, one could have started with windowed versions of s„b,<br>
rrf,b, and rihb to achieve the same result. It may also be convenient to keep the frame<br>
size and the percent overlap for the equalizer filter the same as those used in the<br>
analysis filter block used to obtain rnb from snb.<br>
[0053] The described equalizer filter approach to synthesizing sv.-b offers a<br>
number of advantages: i) Since the phase response of the equalizer filter 413 is zero,<br>
the different frequency components of the equalizer output are time aligned with the<br>
corresponding components of the input. This can be useful for voiced speech because<br>
the high energy segments (such as glottal pulse segments) of the rectified residual<br>
high-band excitation exu, are time aligned with the corresponding high energy<br>
segments of the up-sampled narrow-band speech s„b at the equalizer input, and<br>
preservation of this time alignment at the equalizer output will often act to ensure<br>
good speech quality; ii) the input to the equalizer filter 413 docs not need to have a<br>
flat spectrum as in the case of LP synthesis filter; iii) the equalizer filter 413 is<br>
specified in the frequency domain, and therefore a better and finer control over<br>
different parts of the spectrum is feasible; and iv) iterations are possible to improve<br>
the filtering effectiveness at the cost of additional complexity and delay (for example,<br>
the equalizer output can be fed back to the input to be equalized again and again to<br>
improve performance).<br>
[0054] Some additional details regarding the described configuration will now<br>
be presented.<br>
[0055] High-band excitation pre-processing: The magnitude response of the<br>
equalizer filter 413 is given by SEwb(?)/SEmb(?) and its phase response can be set to<br>
zero. The closer the input spectral envelope SEmb(?) is to the ideal spectral envelope<br>
SEwb(?), the easier it is for the equalizer to correct the input spectral envelope to<br>
match the ideal. At least one function of the high-band excitation pre-processor 411 is<br>
to move SEmb(?) closer to SEwb(?) and thus make the job of the equalizer filter 413<br>
easier. First, this is done by scaling the mixer output signal mhb to the correct high-<br>
band energy level Ehb provided by the ECM 410. Second, the mixer output signal mhb<br>
is, optionally shaped so that its spectral, envelope matches the high-band spectral<br>
envelope SEhb provided by the ECM 410 without affecting its phase spectrum. A<br>
second step can comprise essentially a pre-equalization step.<br>
[0056] Low-band excitation: Unlike the loss of information in the high-band<br>
caused by the band-width restriction imposed, at least in part, by the sampling<br>
frequency, the loss of information in the low-band (0 - 300 Hz) of the narrow-band<br>
signal is due, at least in large measure, to the band-limiting effect of the channel<br>
transfer function consisting of, for example, a microphone, amplifier, speech coder,<br>
transmission channel, or the like. Consequently, in a clean narrow-band signal, the<br>
low-band information is still present although at a very low level. This low-level<br>
information can be amplified in a straight-forward manner to restore the original<br>
signal. But care should be taken in this process since low level signals are easily<br>
corrupted by errors, noise, and distortions. An alternative is to synthesize a low-band<br>
excitation signal similar to the high-band excitation signal described earlier. That is,<br>
the low-band excitation signal can be formed by mixing the low-band rectified<br>
residual signal rrlb and the low-band noise signal nlb, in a way similar to the formation<br>
of the high-band mixer output signal mhb.<br>
[0057] Referring now to FIG. 5, the Estimation and Control Module (ECM)<br>
410 takes as input the narrow-band speech snb, the up-sampled narrow-band speech<br>
snb, and the narrow-band LP parameters A„b and provides as output the voicing level v,<br>
the high-band energy Ehb, the high-band spectral envelope SEhb, and the wide-band<br>
spectral envelope SEwb.<br>
[0058] Voicing level estimation: To estimate the voicing level, a zero-crossing<br>
calculator 501 calculates the number of zero-crossings zc in each frame of the narrow-<br>
band speech snb as follows:<br>
[0059] <br>
[0060] where<br>
[0061] <br>
[0062] n is the sample index, and N is the frame size in samples. It is<br>
convenient to keep the frame size and percent overlap used in the ECM 410 the same<br>
as those used in the equalizer filter 413 and the analysis filter blocks, e.g., T= 20 ms,<br>
N= 160 for 8 kHz sampling, N= 320 for 16 kHz sampling, and 50% overlap with<br>
reference to the illustrative values presented earlier. The value of the zc parameter<br>
calculated as above ranges from 0 to 1. From the zc parameter, a voicing level<br>
estimator 502 can estimate the voicing level v as follows.<br>
[0063] <br>
[0064] where, ZClow and ZChigh represent appropriately chosen low and high<br>
thresholds respectively, e.g., ZClow = 0.40 and ZChigh = 0.45. The output d of an<br>
onset/plosive detector 503 can also be fed into the voicing level detector 502. If a<br>
frame is flagged as containing an onset or a plosive with d = 1, the voicing level of<br>
that frame as well as the following frame can be set to 1. Recall that, by one approach,<br>
when the voicing level is 1, the high-band rectified residual excitation is exclusively<br>
used. This is advantageous at an onset/plosive, compared to noise-only or mixed high-<br>
band excitation, because the rectified residual excitation closely follows the energy<br>
versus time contour of the up-sampled narrow-band speech thus reducing the<br>
possibility of pre-echo type artifacts due to time dispersion in the bandwidth extended<br>
signal.<br>
[0065] In order to estimate the high-band energy, a transition-band energy<br>
estimator 504 estimates the transition-band energy from the up-sampled narrow-band<br>
speech signal Snb. The transition-hand is defined here as a frequency band that is<br>
contained within the narrow-band and close to the high-band, i.e., it serves as a<br>
transition to the high-band, (which, in this illustrative example, is about 2500 - 3400<br>
Hz). Intuitively, one would expect the high-band energy to be well correlated with the<br>
transition-band energy, which is borne out in experiments. A simple way to calculate<br>
the transition-band energy Etb is to compute the frequency spectrum of snb (for<br>
example, through a Fast Fourier Transform (FFT)) and sum the energies of the<br>
spectral components within the transition-band.<br>
[0066] From the transition-band energy Etb in dB (decibels), the high-band<br>
energy Ehbo in dB is estimated as<br>
[0067] <br>
[0068J where the coefficients a and ß are selected to minimize the mean<br>
squared error between the true and estimated values of the high-band energy over a<br>
large number of frames from a training speech database.<br>
[0069] The estimation accuracy can be further enhanced by exploiting<br>
contextual information from additional speech parameters such as the zero-crossing<br>
parameter zc and the transition-band spectral slope parameter sl as may be provided<br>
by a transition-band slope estimator 505. The zero-crossing parameter, as discussed<br>
earlier, is indicative of the speech voicing level. The slope parameter indicates the rate<br>
of change of spectral energy within the transition-band. It can be estimated from the<br>
narrow-band LP parameters Anb by approximating the spectral envelope (in dB)<br>
within the transition-band as a straight line, e.g., through linear regression, and<br>
computing its slope. The zc-sl parameter plane is then partitioned into a number of<br>
regions, and the coefficients a and ß are separately selected for each region. For<br>
example, if the ranges of zc and sl parameters are each divided into 8 equal intervals,<br>
the zc-sl parameter plane is then partitioned into 64 regions, and 64 sets of a and ß<br>
coefficients are selected, one for each region.<br>
[0070] A high-band energy estimator 506 can provide additional improvement<br>
in estimation accuracy by using higher powers of Etb in estimating Ehbo, e.g.,<br>
[0071] <br>
[0072] In this case, five different coefficients, viz., a1, a3, a2, a1, and ß, are<br>
selected for each partition of the zc-sl parameter plane. Since the above equations<br>
(refer to paragraphs 63 and 67) for estimating Ehbo are non-linear, special care must be<br>
taken to adjust the estimated high-band energy as the input signal level, i.e, energy,<br>
changes. One way of achieving this is to estimate the input signal level in dB, adjust<br>
Etb up or down to correspond to the nominal signal level, estimate Ehbo, and adjust<br>
Ehbo down or up to correspond to the actual signal level.<br>
[0073] While the high-band energy estimation method described above works<br>
quite well for most frames, occasionally there are frames for which the high-band<br>
energy is grossly under- or over-estimated. Such estimation errors can be at least<br>
partially corrected by means of an energy track smoother 507 that comprises a<br>
smoothing filter. The smoothing filter can be designed such that it allows actual<br>
transitions in the energy track to pass through unaffected, e.g., transitions between<br>
voiced and unvoiced segments, but corrects occasional gross errors in an otherwise<br>
smooth energy track, e.g., within a voiced or unvoiced segment. A suitable filter for<br>
this purpose is a median filter, e.g., a 3-point median filter described by the equation<br>
[0074] <br>
[0075J where k is the frame index, and the median (•) operator selects the<br>
median of its three arguments. The 3-point median filter introduces a delay of one<br>
frame. Other types of filters with or without delay can also be designed for smoothing<br>
the energy track.<br>
[0076] The smoothed energy value Ehb1 can be further adapted by an energy<br>
adapter 508 to obtain the final adapted high-band energy estimate Ehb. This adaptation<br>
can involve either decreasing or increasing the smoothed energy value based on the<br>
voicing level parameter v and/or the d parameter output by the onset/plosive detector<br>
503. By one approach, adapting the high-band energy value changes not only the<br>
energy level but also the spectral envelope shape since the selection of the high-band<br>
spectrum can be tied to the estimated energy.<br>
[0077] Based on the voicing level parameter v, energy adaptation can be<br>
achieved as follows. For v = 0 corresponding to an unvoiced frame, the smoothed<br>
energy value Ehbl is increased slightly, e.g., by 3 dB, to obtain the adapted energy<br>
value Ehb. The increased energy level emphasizes unvoiced speech in the band-width<br>
extended output compared to the narrow-band input and also helps to select a more<br>
appropriate spectral envelope shape for the unvoiced segments. For v = 1<br>
corresponding to a voiced frame, the smoothed energy value Ehbl is decreased<br>
slightly, e.g., by 6 dB, to obtain the adapted energy value Ehb. The slightly decreased<br>
energy level helps to mask any errors in the selection of the spectral envelope shape<br>
for the voiced segments and consequent noisy artifacts.<br>
[0078] When the voicing level v is in between 0 and 1 corresponding to a<br>
mixed-voiced frame, no adaptation of the energy value is done. Such mixed-voiced<br>
frames represent only a small fraction of the total number of frames and un-adapted<br>
energy values work fine for such frames. Based on the onset/plosive detector output d,<br>
energy adaptation is done as follows. When d = 1, it indicates that the corresponding<br>
frame contains an onset, e.g., transition from silence to unvoiced or voiced sound, or a<br>
plosive sound, e.g., /t/. In this case, the high-band energy of the particular frame as<br>
well as of the following frame is adapted to a very low value so that its high-band<br>
energy content is low in the band-width extended speech. This helps to avoid the<br>
occasional artifacts associated with such frames. For d = 0, no further adaptation of<br>
the energy is done; i.e., the energy adaptation based on voicing level v, as described<br>
above, is retained.<br>
[0079] The estimation of the wide-band spectral envelope SEwb is described<br>
next. To estimate SEwb, one can separately estimate the narrow-band spectral envelope<br>
SEnb, the high-band spectral envelope SEhb, and the low-band spectral envelope SElb,<br>
and combine the three envelopes together.<br>
[0080] A narrow-band spectrum estimator 509 can estimate the narrow-band<br>
spcetral envelope SEnb from the up-sample narrow-band spcech snb. From snb, the LB<br>
parameters, Bnb = 1, b2, b2, .. , bQ} where Q is the model order, are first computed<br>
using well-known LP analysis techniques. For an up-sampled frequency of 16 kHz, a<br>
suitable model order Q, for example, is 20. The LP parameters Bab model the spectral<br>
envelope of the up-sampled narrow-band speech as<br>
[0081] <br>
[0082] In the equation above, the angular frequency ? in radians/sample is<br>
given by where/is the signal frequency in Hz and Fs is the sampling<br>
frequency in Hz. Notice that the spectral envelopes SEnbin and SEusnb are different<br>
since the former is derived from the narrow-band input speech and the latter from the<br>
up-sampled narrow-band speech. However, inside the pass-band of 300 to 3400 Hz,<br>
they are approximately related by SEusnb (?) ~ SEnbin (2?) to within a constant.<br>
Although the spectral envelope SEusnb is defined over the range 0 - 8000 (Fs) Hz, the<br>
useful portion lies within the pass-band (in this illustrative example, 300 - 3400 Hz).<br>
[0083] As one illustrative example in this regard, the computation of SEusnb is<br>
done using FFT as follows. First, the impulse response of the inverse filter Bnh(z) is<br>
calculated to a suitable length, e.g., 1024, as [1,b1,b2, ... , bQ, 0, 0, ... ,0}. Then an<br>
FFT of the impulse response is taken, and magnitude spectral envelope SEusnb is<br>
obtained by computing the inverse magnitude at each FFT index. For an FFT length<br>
of 1024, the frequency resolution SEusnb, computed as above is 16000/1024 =<br>
15.625 Hz. From SEusnb, the narrow-band spectral envelope SEnb is estimated by<br>
simply extracting the spectral magnitudes from within the approximate range, 300 -<br>
3400 Hz.<br>
[0084] Those skilled in the art will appreciate that besides LP analysis, there<br>
are other methods to obtain the spectral envelope of a given speech frame, e.g.,<br>
cepstral analysis, piecewise linear or higher order curve fitting of spectral magnitude<br>
peaks, etc.<br>
[0085] A high-band spectrum estimator 510 takes an estimate of the high-band<br>
energy as input and selects a high-band spectral envelope shape that is consistent with<br>
the estimated high-band energy. A technique to come up with different high-band<br>
spectral envelope shapes corresponding to different high-band energies is described<br>
next.<br>
[0086] Starting with a large training database of wide-band speech sampled at<br>
16 kHz, the wide-band spectral magnitude envelope is computed for each speech<br>
frame using standard LP analysis or other techniques. From the wide-band spectral<br>
envelope of each frame, the high-band portion corresponding to 3400 - 8000 Hz is<br>
extracted and normalized by dividing through by the spectral magnitude at 3400 Hz.<br>
The resulting high-band spectral envelopes have thus a magnitude of 0 dB at 3400 Hz.<br>
The high-band energy corresponding to each normalized high-band envelope is<br>
computed next. The collection of high-band spectral envelopes is then partitioned<br>
based on the high-band energy, e.g., a sequence of nominal energy values differing by<br>
1 dB is selected to cover the entire range and all envelopes with energy within 0.5 dB<br>
of a nominal value are grouped together.<br>
[0087] For each group thus formed, the average high-band spectral envelope<br>
shape is computed and subsequently the corresponding high-band energy. In FIG. 6, a<br>
set of 60 high-band spectral envelope shapes 600 (with magnitude in dB versus<br>
frequency in Hz) at different energy levels is shown. Counting from the bottom of the<br>
figure, the 1st, 10th, 20th, 30th, 40th, 50th, and 60th shapes (referred to herein as pre-<br>
computed shapes) were obtained using a technique similar to the one described above.<br>
The remaining 53 shapes were obtained by simple linear interpolation (in the dB<br>
domain) between the nearest pre-computed shapes.<br>
[0088] The energies of these shapes range from about 4.5 dB for the 1st shape<br>
to about 43.5 dB for the 60th shape. Given the high-band energy for a frame, it is a<br>
simple matter to select the closest matching high-band spectral envelope shape as will<br>
be described later in the document. The selected shape represents the estimated high-<br>
band spectral envelope SEhb to within a constant. In FIG. 6, the average energy<br>
resolution is approximately 0.65 dB. Clearly, better resolution is possible by<br>
increasing the number of shapes. Given the shapes in FIG. 6, the selection of a shape<br>
for a particular energy is unique. One can also think of a situation where there is more<br>
than one shape for a given energy, e.g., 4 shapes per energy level, and in this case,<br>
additional information is needed to select one of the Shapes for each given energy<br>
level. Furthermore, one can have multiple sets of shapes each set indexed by the high-<br>
band energy, e.g., two sets of shapes selectable by the voicing parameter v, one for<br>
voiced frames and the other for unvoiced frames. For a mixed-voiced frame, the two<br>
shapes selected from the two sets can be appropriately combined.<br>
[0089] The high-band spectrum estimation method described above offers<br>
some clear advantages. For example, this approach offers explicit control over the<br>
time evolution of the high-band spectrum estimates. A smooth evolution of the high-<br>
band spectrum estimates within distinct speech segments, e.g., voiced speech,<br>
unvoiced speech, and so forth is often important for artifact-free band-width extended<br>
speech. For the high-band spectrum estimation method described above, it is evident<br>
from FIG. 6 that small changes in high-band energy result in small changes in the<br>
high-band spectral envelope shapes. Thus, smooth evolution of the high-band<br>
spectrum can be essentially assured by ensuring that the time evolution of the high-<br>
band energy within distinct speech segments is also smooth. This is explicitly<br>
accomplished by energy track smoothing as described earlier.<br>
[0090] Note that distinct speech segments, within which energy smoothing is<br>
done, can be identified with even finer resolution, e.g., by tracking the change in the<br>
narrow-band speech spectrum or the up-sampled narrow-band speech spectrum from<br>
frame to frame using any one of the well known spectral distance measures such as<br>
the log spectral distortion or the LP-based Itakura distortion. Using this approach, a<br>
distinct speech segment can be defined as a sequence of frames within which the<br>
spectrum is evolving slowly and which is bracketed on each side by a frame at which<br>
the computed spectral change exceeds a fixed or an adaptive threshold thereby<br>
indicating the presence of a spectral transition on either side of the distinct speech<br>
segment. Smoothing of the energy track may then be done within the distinct speech<br>
segment, but not across segment boundaries.<br>
[0091J Here, smooth evolution of the high-band energy track translates into a<br>
smooth evolution of the estimated high-band spectral envelope, which is a desirable<br>
characteristic within a distinct speech segment. Also note that this approach to<br>
ensuring a smooth evolution of the high-band spectral envelope within a distinct<br>
speech segment may also be applied as a post-processing step to a sequence of<br>
estimated high-band spectral envelopes obtained by prior-art methods. In that case,<br>
however, the high-band spectral envelopes may need to be explicitly smoothed within<br>
a distinct speech segment, unlike the straightforward energy track smoothing of the<br>
current teachings which automatically results in the smooth evolution of the high-<br>
band spectral envelope.<br>
[0092] The loss of information of the narrow-band speech signal in the low-<br>
band (which, in this illustrative example, may be from 0 - 300 Hz) is not due to the<br>
bandwidth restriction imposed by the sampling frequency as in the case of the high-<br>
band but due to the band-limiting effect of the channel transfer function consisting of,<br>
for example, the microphone, amplifier, speech coder, transmission channel, and so<br>
forth.<br>
[0093] A straight-forward approach to restore the low-band signal is then to<br>
counteract the effect of this channel transfer function within the range from 0 to 300<br>
Hz. A simple way to do this is to use a low-band spectrum estimator 511 to estimate<br>
the channel transfer function in the frequency range from 0 to 300 Hz from available<br>
data, obtain its inverse, and use the inverse to boost the spectral envelope of the up-<br>
sampled narrow-band speech. That is, the low-band spectral envelope SElh is<br>
estimated as the sum of SEusnb and a spectral envelope boost characteristic SEboost<br>
designed from the inverse of the channel transfer function (assuming that spectral<br>
envelope magnitudes are expressed in log domain, e.g., dB). For many application<br>
settings, care should be exercised in the design of SEboost- Since the restoration of the<br>
low-band signal is essentially based on the amplification of a low level signal, it<br>
involves the danger of amplifying errors, noise, and distortions typically associated<br>
with low level signals. Depending on the quality of the low level signal, the maximum<br>
boost value should be restricted appropriately. Also, within the frequency range from<br>
0 to about 60 Hz, it is desirable to design SEboost to have low (or even negative, i.e.,<br>
attenuating) values to avoid amplifying electrical hum and background noise.<br>
[0094] A wide-band spectrum estiamator 512 can then estimate the wide-band<br>
spectral envelope by combining the estimated spectral envelopes in the narrow-band,<br>
high-band, and low-band. One way of combining the three envelopes to estimate the<br>
Wide-band spectral envelope is as follows.<br>
[0095] The narrow-band spectral envelope SEnb is estimated from snb as<br>
described above and its values within the range from 400 to 3200 Hz are used without<br>
any change in the wide-band spectral envelope estimate SEwb. To select the<br>
appropriate high-band shape, the high-band energy and the starting magnitude value<br>
at 3400 Hz are needed. The high-band energy Ehb in dB is estimated as described<br>
earlier. The starting magnitude value at 3400 Hz is estimated by modeling the FFT<br>
magnitude spectrum of snb in dB within the transition band, viz., 2500 - 3400 Hz, by<br>
means of a straight line through linear regression and finding the value of the straight<br>
line at 3400 Hz. Let this magnitude value by denoted by M3400 in dB. The high-band<br>
spectral envelope shape is then selected as the one among many values, e.g., as shown<br>
in FIG. 6, that has an energy value closest to Ehb - M3400. Let this shape be denoted by<br>
SE closest Then the high-band spectral envelope estimate SEhb and therefore the wide-<br>
band spectral envelope SEwb within the range from 3400 to 8000 Hz are estimated as<br>
SEclosest + M3400.<br>
[0096] Between 3200 and 3400 Hz, SEwb is estimated as the linearly<br>
interpolated value in dB between SEnb and a straight line joining the SEnb at 3200 Hz<br>
and M3400 at 3400 Hz. The interpolation factor itself is changed linearly such that the<br>
estimated SEwb moves gradually from SEnb at 3200 Hz to M3400 at 3400 Hz. Between 0<br>
to 400 Hz, the low-band spectral envelope SElb and the wide-band spectral envelope<br>
SEwb are estimated as SEnb + SEboost, where SEboost represents an appropriately<br>
designed boost characteristic from the inverse of the channel transfer function as<br>
described earlier.<br>
[0097] As alluded to earlier, frames containing onsets and/or plosives may<br>
benefit from special handling to avoid occasional artifacts in the band-width extended<br>
speech. Such frames can be identified by the sudden increase in their energy relative<br>
to the preceding frames. The onset/plosive detector 503 output d for a frame is set to 1<br>
whenever the energy of the preceding frame is low, i.e., below a certain threshold,<br>
e.g., -50 dB, and the increase in energy of the current frame relative to the preceding<br>
frame exceeds another threshold, e.g., 15 dB. Otherwise, the detector output d is set to<br>
0. The frame energy itself is computed from the energy of the FFT magnitude<br>
spectrum of the up-sampled narrow-band speech snb within the narrow-band, i.e., 300<br>
- 3400 Hz. As noted above, the output of the onset/plosive detector 503 d is fed into<br>
the voicing level estimator 502 and the energy adapter 508. As described earlier,<br>
whenever a frame is flagged as containing an onset or a plosive with d= 1, the<br>
voicing level v of that frame as well as the following frame is set to 1. Also, the<br>
adapted high-band energy value Ehb of that frame as well as the following frame is set<br>
to a low value.<br>
[0098] Note that while the estimation of parameters such as spectral envelope,<br>
zero crossings, LP coefficients, band energies, and so forth has been described in the<br>
specific examples previously given as being done from the narrow-band speech in<br>
some cases and the up-sampled narrow-band speech in other cases, it will be<br>
appreciated by those skilled in the art that the estimation of the respective parameters<br>
and their subsequent use and application, may be modified to be done from the either<br>
of those two signals (narrow-band speech or the up-sampled narrow-band speech),<br>
without departing from the spirit and the scope of the described teachings.<br>
[0099] Those skilled in the art will recognize that a wide variety of<br>
modifications, alterations, and combinations can be made with respect to the above<br>
described embodiments without departing from the spirit and scope of the invention,<br>
and that such modifications, alterations, and combinations are to be viewed as being<br>
within the ambit of the inventive concept.<br>
We claim:<br>
1. A method comprising:<br>
providing a digital audio signal having a corresponding signal bandwidth;<br>
providing an energy value that corresponds to at least an estimate of out-of-<br>
signal bandwidth energy as corresponds to the digital audio signal;<br>
using the energy value to simultaneously determine:<br>
a spectral envelope shape; and<br>
a corresponding suitable energy for the spectral envelope shape;<br>
for out-of-signal bandwidth content as corresponds to the digital audio signal.<br>
2. The method of claim 1 wherein providing a digital audio signal comprises<br>
providing synthesized vocal content.<br>
3. The method of claim 1 wherein providing an energy value comprises, at least in<br>
part, estimating the energy value as a function, at least in part, of the digital audio<br>
signal.<br>
4. The method of claim 1 wherein using the energy value comprises, at least in part,<br>
using the energy value to access a look-up table containing a plurality of<br>
5. The method of claim 1 wherein the out-of-signal bandwidth energy comprises<br>
energy that corresponds to signal content that is higher in frequency than the<br>
corresponding signal bandwidth of the digital audio signal.<br>
6. The method of claim 1 wherein the out-of-signal bandwidth energy comprises<br>
energy that corresponds to signal content that is lower in frequency than the<br>
corresponding signal bandwidth of the digital audio signal.<br>
7. The method of claim 1 further comprising:<br>
combining the digital audio signal with the out-of-signal bandwidth content to<br>
provide a bandwidth extended version of the digital audio signal to be audibly<br>
rendered to thereby improve corresponding audio quality of the digital audio signal as<br>
so rendered.<br>
8. The method of claim 7 wherein the out-of-signal bandwidth content further<br>
comprises a portion of content that is within the corresponding signal bandwidth.<br>
9. The method of claim 8 wherein combining the digital audio signal with the out-of-<br>
signal bandwidth content further comprises combining the portion of content that is<br>
within the corresponding signal bandwidth with a corresponding in-band portion of<br>
the digital audio signal.<br>
10. An apparatus comprising:<br>
an input configured and arranged to receive a digital audio signal having a<br>
corresponding signal bandwidth;<br>
a processor operably coupled to the input and being configured and arranged<br>
to:<br>
provide an energy value that corresponds to at least an estimate of out-<br>
of-signal bandwidth energy as corresponds to the digital audio signal;<br>
use the energy value and a set of energy-indexed shapes to determine a<br>
spectral envelope shape for out-of-signal bandwidth content as<br>
corresponds to the digital audio signal.<br><br>
One provides (101) a digital audio signal having a corresponding signal bandwidth, and then provides (102) an<br>
energy value that corresponds to at least an estimate of out-of-signal bandwidth energy as corresponds to that digital audio signal.<br>
One then uses (103) the energy value to simultaneously determine both a spectral envelope shape and a corresponding suitable energy<br>
for the spectral envelope shape for out-of-signal bandwidth content as corresponds to the digital audio signal. By one approach, if<br>
desired, one then combines (104) (on, for example, a frame by frame basis) the digital audio signal with the out-of-signal bandwidth<br>
content to provide a bandwidth extended version of the digital audio signal to be audibly rendered to thereby improve corresponding<br>
audio quality of the digital audio signal as so rendered.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=s+wyftMWq2ZRdW7rrDeQHw==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==" target="_blank" style="word-wrap:break-word;">http://ipindiaonline.gov.in/patentsearch/GrantedSearch/viewdoc.aspx?id=s+wyftMWq2ZRdW7rrDeQHw==&amp;amp;loc=wDBSZCsAt7zoiVrqcFJsRw==</a></p>
		<br>
		<div class="pull-left">
			<a href="270793-novel-bronchodilating-alpha-beta-unsaturated-amides.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="270795-enzyme-preparations-obtainable-by-enzyme-immobilizates.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>270794</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>1591/KOLNP/2010</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>04/2016</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>22-Jan-2016</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>20-Jan-2016</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>05-May-2010</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>MOTOROLA MOBILITY LLC</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>600 NORTH US HIGHWAY 45,LIBERTYVILLE,IL 60048,UNITED STATES OF AMERICA</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>RAMABADRAN, TENKASI V.</td>
											<td>1852 RANCHVIEW DRIVE, NAPERVILLE, ILLINOIS 60565 UNITED STATES OF AMERICA</td>
										</tr>
										<tr>
											<td>2</td>
											<td>JASIUK, MARK A.</td>
											<td>6221 NORTH MELVINA AVENUE, CHICAGO, ILLINOIS 60646 UNITED STATES OF AMERICA</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G01L 21/02</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/US2008/079366</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2008-10-09</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>11/946,978</td>
									<td>2007-11-29</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/270794-method-and-apparatus-for-bandwidth-extension-of-audio-signal by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 03:30:13 GMT -->
</html>
