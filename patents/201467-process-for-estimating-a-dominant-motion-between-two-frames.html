<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/201467-process-for-estimating-a-dominant-motion-between-two-frames by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:30:34 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 201467:PROCESS FOR ESTIMATING A DOMINANT MOTION BETWEEN TWO FRAMES</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">PROCESS FOR ESTIMATING A DOMINANT MOTION BETWEEN TWO FRAMES</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>Process for estimating a dominant motion between two frames, it combines a phase correlation peak detection algorithm (1) and a multi-resolution robust regression algorithm (3) for improving the robustness of the estimation and n that the phase correlation peak detection algorithm (1) is implemented in several different windows to provide translational motion vectors as initializations to the multi-resolution robust regression algorithm.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>The present invention relates to a process for estimating a dominant motion between two successive frames of a video sequence. This process is valid for all kind of scene or camera motion configuration.<br>
The estimation of the dominant motion is an important step for estimating or<br>
segmenting the apparent motion between two successive frames. In a dense<br>
motion field estimation, it strongly accelerates the process by providing an<br>
initial motion near the true apparent motion over a large part of the frame.<br>
This is especially the case when the dominant motion is not constant, that is<br>
not a pure translational apparent motion, but more complicated such as a<br>
zoom or a rotation around the optical axis of the camera. In a motion <br>
segmentation process, it represents a basic step for identifying the motion of<br>
a region, since it may be applied to the entire frame as well as regions of the<br>
frame.<br>
The main commonly used approach for estimating the dominant motion between two successive frames iis based on a robust regression method. It will be called in the following 'robust regression global motion estimation'. The main characteristics of this algorithm are the following :<br>
-	it uses a global motion model for representing the dominant motion with <br>
very few parameters. In most of cases, an affine motion model, which is a <br>
good compromise between the physical reality of the apparent motion<br>
and the computational complexity, is chosen. It may represent with a good approximation apparent motions resulting from camera motions such as traveling, pan, tilt, zoom, and any combination of these motions,<br>
-	the estimation of the parameters of this model is performed using a<br>
robust regression algorithm which theoretically allows the elimination of<br>
outliers, i.e. pixels having a different motion from the dominant motion,<br>
from the estimation process.<br>
-	this process may work without a prior dense motion field estimation. Data<br>
used for the global motion estimation process are the source frames. The<br>
process is based on the estimated spatio-temporal gradients of the<br>
luminance function at each pixel, through the well-known 'optic flow<br>
constraint'.<br><br>
2<br>
-    this process may be achieved in a multi-resolution scheme, in order to deal with large motion amplitudes.<br>
In many cases this type of algorithms provides satisfactory results, and is able to identify the dominant motion.<br>
However the process strongly depends on the initial value of the global motion. In general this global motion is set initially to zero. Moreover, there are many configurations where the estimation process fails and provides a wrong global motion. If the source frames are poorly textured and contain large uniform areas, the process generally converges toward a     small amplitude motion, even if the real dominant motion is large. This            phenomena is especially true when a large foreground object, tracked by the camera, moves over a background scene.<br>
This problem can be easily explained : as said before, the 'motion' observations are based on the spatio-temporal gradients ; these observations are obviously very few informative on uniform or poorly textured areas. If such areas are majoritory in the frame, the algorithm cannot converge to a right motion value and it considers that a small motion well fits to the motion observations.<br>
It is an object of the present invention to solve the main limitations identified<br>
above.<br>
The invention relates to a process for estimating the dominant motion<br>
between two frames.   It combines  a  phase  correlation  peak detection<br>
algorithm and a multi-resolution robust regression algorithm for improving the<br>
robustness of the estimation.<br>
The invention will in the following be explained using examples to explicit<br>
some of its features and figure 1 and figure 2 wherein ;<br>
Fig. 1 is a flow chart of the dominant motion estimation algorithm<br>
Fig. 2 is a view showing a disposition of different windows for the estimation<br>
of the translational motions<br>
The invention implements a generic global motion estimation process which works in most scene and camera configurations. This algorithm combines<br><br>
3<br>
two global motion estimation methods, the phase correlation peak detection and the multi-resolution robust regression.<br>
The phase correlation peak detection algorithm is a fast and efficient tool for estimating a global translational motion over a window between two frames. In the method described hereafter, it is used for providing potential initializations to the multi-resolution robust regression algorithm. For each initialization, this algorithm computes a global motion estimation. A final step consists of choosing the best estimation.<br>
Figure 1 is a flow chart representing the generic global motion estimation process implemented by the invention.<br>
Considering a time instant t and two source frames I1 and It-1 the different steps of the process (identified with numbers 1 to 5 in figure 1) are :<br>
Step 1  :    estimation   of  translational   motions over  several   different windows  within   the  frame,   using   the  correlation   peak   detection algorithm ; Figure 2 shows emplacement of windows, in an example where five windows are used. A mobile window could also be used depending for instance on pixels areas where the global motion fits. <br>
Step 2 : translational motions are grouped if they are similar.<br>
P   translational motion vectors are defined from the N translational motion vectors estimated during step 1 (P<n></n>
Step 3 : estimation of global motions over the frame implementing the multi-resolution robust regression algorithm, using the different available initializations : the motion coming from each remaining translational motion vector, plus the previous final global motion estimated at the previous time (from frame l1-2 to frame I1-1) ; at the very first estimation, this global motion is set to zero .<br>
	 Step 4 ; choice of the best estimated global motion.<br><br>
 This final dominant motion vector is memorised at step 5 as the previous<br>
	dominant motion vector in order to be used, at step 2 and step 3, for the next<br>
source frames to be processed.<br>
A detailed description of the global motion estimation process is given hereafter:<br>
   The affine moderation of the 2D apparent motion in a video sequence is              one of the best compromises between the computation complexity (only 6<br>
parameters have to be identified) and the physical reality (that is the correct representation of the 2D apparent motion).<br>
Hence the motion model used here is the following. A 2D motion vector of a point (x,y) in the frame is modeled using six motion parameters 9 = (a,b,a,ß,?,O)T in the following way :<br>
  Equation 1<br>
A phase correlation peak detection algorithm is implemented at first step 1. The computation of phase correlation consists of the following successive phases:<br>
-	getting two pixel windows f1 and f2 which have the same sizes (n.m).I specify<br>
-	the two-dimensional Fast Fourier Transform (FFT) is applied on the luminance components of each window resulting in two complex (n, m) element arrays F1 and F2.<br>
-	the phase difference matrix is derived by forming the cross power spectrum F1.F2 and dividing by its modulus.<br>
-	a weighting function of n.m dimension can be applied to the phase difference, in order to improve the phase correlation result. The goal of this procedure is to reduce the influence of noise which can disturb the correlation surface.<br><br>
5<br>
-   Inverse Fourier Transform of the phase difference matrix gives the correlation surface with peaks for candidate displacements.<br>
        Finally the search dominant vector operation consists of looking for the<br>
	maximum peaks in the correlation surface which identifies the most dominant<br>
displacement.<br>
A second step 2 performs a translational motion vectors grouping.<br>
For each estimated translational motion vector w provided by the correlation peak detection algorithm applied to different windows within the frame, a first test is achieved :<br><br>
- if the previous estimated dominant motion 9 (previous frames) is translational,that,is,if<br><br>
 if the euclidian distance between this dominant motion and ? is lower than a given threshold.<br>
then ? is suppressed of the list of translation vectors.<br>
In the same way, the remaining translational vectors are compared together using the euclidian distance. Redundant vectors are suppressed using the same test, with the same threshold. (The Euclidian distance between two vectors with components x1,y1 and x2,<br><br>
Next step 3 performs a multi-resolution robust regression algorithm.<br>
In order to avoid the costly dense motion field estimation, which moreover can fail when large motions are present or in presence of strongly non-translational motions, the global motion estimation process is based on the spatio-temporal gradients of the frame luminance, which are linked to the 2D apparent motion by the well-known 'optic flow constraint equation' :<br>
  Equation 2<br><br>
6<br>
where dx and dy are the two components of the motion vector, ?lx, ?ly and ?lt  are the spatio-temporal gradients of the luminance, that is, an estimation of                derivates of the luminance.<br>
When dx and dy are replaced by their value depending on the global motion model, given in equation 1, this leads to the following equation :<br><br>
For estimating the global motion vector 0 = (a,b,a,ß Y,d)r over the whole	<br>
frame, a classical regression algorithm would intend to minimize over the 6   <br>
parameters of ? the following function :	<br><br>
However, in case where several global motions are present in the frame, the process will be disrupted and would provide a wrong estimation. That is the I specify reason why a robust regression algorithm is used. It theoretically allows to eliminate outliers, that is, pixels that do not have the same motion as the dominant one. This algorithm consists of minimizing the following function :<br><br>
xy'<br>
where wc(x,y) is a weighting function which intends to favour pixels for which    the current global motion estimation well fits.<br>
     Several functions may be chosen for wc (Lorentzian, Geman-Mc Lure, ...).<br>
The important point is that, in any case, this function depends on a scaling  specify<br>
factor related to the variance of the noise that corrupts the observations, and specify<br>
that must be correctly estimated for a good behaviour of the algorithm.<br>
The  estimation  process  is  iterative.  At each  iteration  k,  the  previous<br>
estimation    0k_1  is used as initialization of the estimation process. In the<br>
same way, the scaling factor Fk-1 is iteratively estimated.<br>
Initially,  is set to 5xR0, where R0 is a given value. In all our experiments,<br>
                      R0  was equcal to 50.Than at each  iteration,  is computed as follows :<br><br>
7<br>
Let  be the mean weighted motion compensation error of the estimation over the frame :<br><br>
The scaling factor is computed as :<br><br>
In order to be able to estimate large motions, the process is applied in a multiresolution way : a multiresolution pyramid of the two frames is firstly built; then the estimation process is applied from the coarsest to the finest resolution, by using as initial estimate of the motion parameters at a given level the estimation from the coarser level.<br>
The initial global motion parameters vector is set to :<br>
- the null vector if the process is just starting for the video shot,<br>
-the previous value (that is the vector calculated from the previous resolution), rescaled by taking into account the higher resolution level, if the process is just starting for the current frame.<br>
Then an iterative process is applied.<br>
Let k be the current iteration number. From the current estimation of the<br>
motion parameters vector   ?k_x, a motion compensation of the previous 1   <br>
frame is achieved, and the spatio-temporat gradients maps are computed. The continuation of this process consists of progressively correcting the first estimate of 0 until this correction becomes low. The robust regression at each iteration provides a correcting motion parameters vector d?k .<br>
The global motion parameters vector is then up-dated :<br><br><br>
8<br>
The process is iterated until the amplitude of the estimated global motion parameters correction becomes lower than a given threshold. The resulting<br>
motion parameters vector 0 is considered as the robust estimation of the dominant motion parameters vector.<br>
Next step 4 allows to choose the best global motion vector.	<br>
During the robust regression process, the final variance over the dominant motion support, that is, parts of the frame where the dominant motion fits, is computed as follows.<br>
First, inlier pixels (where the dominant motion fits) are determined by the following test:<br>
if ?I,(x,y)2 
where P is the final iteration number of the estimation process.<br>
       Then the final variance is computed as the mean of ?/t(x,y)2 over the/inliers^ set.<br>
The best global motion vector is chosen as the vector that provides the minimum final variance.<br><br>
9<br>
We Claim<br>
1.	Process for estimating a dominant motion between two frames, characterized in that it combines a phase correlation peak detection algorithm (i) and a multi-resolution robust regression algorithm (3) for improving the robustness of the estimation and in that the phase correlation peak detection algorithm (i) is implemented on several different windows to provide translational motion vectors as initializations to the multi-resolution robust regression algorithm.<br>
2.	Process as claimed in claim 1, wherein the phase correlation peak detection algorithm estimates the translational motions on atleast one mobile window.<br>
3.	Process as claimed in claim 1, wherein a motion vector grouping (2) is performed according to their Euclidean distance.<br>
4.	Process as claimed in claim 3, wherein a comparison is carried out (2) between the dominant motion calculated for a previous frame and the translational motion vectors.<br>
5.	Process as claimed in claim 1, wherein the robust regression algorithm (3) carries out a weighting function favouring pixels for which the current global motion estimation well fits.<br>
6.	Process as claimed in claim 5, wherein the weighting function depends on a scaling factor computed at each iteration and related to the variance of the noise.<br><br>
10<br>
7.	Process as claimed in claim 1, wherein the selection of the best estimated motion (4) is the one giving the minimum final variance.<br>
8.	Process as claimed in claim 7, wherein the variance is only calculated on the dominant motion support.<br>
9.	Process as claimed in claim 1, wherein the estimation is a multiresolution motion estimation.<br>
Process for estimating a dominant motion between two frames, it combines a phase correlation peak detection algorithm (1) and a multi-resolution robust regression algorithm (3) for improving the robustness of the estimation and n that the phase correlation peak detection algorithm (1) is implemented in several different windows to provide translational motion vectors as initializations to the multi-resolution robust regression algorithm.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">00222-cal-2000-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">00222-cal-2000-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtY29ycmVzcG9uZGVuY2UucGRm" target="_blank" style="word-wrap:break-word;">00222-cal-2000-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZGVzY3JpcHRpb24oY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">00222-cal-2000-description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">00222-cal-2000-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">00222-cal-2000-form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZm9ybS0xOC5wZGY=" target="_blank" style="word-wrap:break-word;">00222-cal-2000-form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZm9ybS0yLnBkZg==" target="_blank" style="word-wrap:break-word;">00222-cal-2000-form-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZm9ybS0yNi5wZGY=" target="_blank" style="word-wrap:break-word;">00222-cal-2000-form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">00222-cal-2000-form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtZm9ybS01LnBkZg==" target="_blank" style="word-wrap:break-word;">00222-cal-2000-form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtbGV0dGVycyBwYXRlbnQucGRm" target="_blank" style="word-wrap:break-word;">00222-cal-2000-letters patent.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDAyMjItY2FsLTIwMDAtcHJpb3JpdHkgZG9jdW1lbnQucGRm" target="_blank" style="word-wrap:break-word;">00222-cal-2000-priority document.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLUNBTC0yMDAwLUZPUk0tMjcucGRm" target="_blank" style="word-wrap:break-word;">222-CAL-2000-FORM-27.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtZGVzY3JpcHRpb24gKGNvbXBsZXRlKS5wZGY=" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtZm9ybSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-form 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtcHJpb3JpdHkgZG9jdW1lbnQucGRm" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-priority document.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjIyLWNhbC0yMDAwLWdyYW50ZWQtc3BlY2lmaWNhdGlvbi5wZGY=" target="_blank" style="word-wrap:break-word;">222-cal-2000-granted-specification.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="201464-an-umbilical-cord-combined-disinfected-clamp-and-cutting-device-combined-as-one-unit.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="201469-oral-formulations-of-an-antifungal.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>201467</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>222/CAL/2000</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>06/2007</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>09-Feb-2007</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>09-Feb-2007</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>17-Apr-2000</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>THOMSON MULTIMEDIA</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>46, QUAI A. LE GALLO, F-92100 BOULOGNE-BILLANCOURT,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>CHEVANCE CHRISTOPHE</td>
											<td>4 ALLEE J.J. AUDUBON F-35200 RENEES,</td>
										</tr>
										<tr>
											<td>2</td>
											<td>FRAMCPOS EDPIARD</td>
											<td>18 ALLEE DU LOCAR F-35890 BOURG DES COMPTES,</td>
										</tr>
										<tr>
											<td>3</td>
											<td>THOREAU DOMINIQUE</td>
											<td>39 RUE DU REAGE F-35510 CESSON-SEVIGNE,</td>
										</tr>
										<tr>
											<td>4</td>
											<td>VIELLARD THIERRY</td>
											<td>5 ALLEE DES ORMEAUX F-35410 OSSE,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06T 7/20</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>N/A</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td></td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>99401077.5</td>
									<td>1999-05-03</td>
								    <td>EPO</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/201467-process-for-estimating-a-dominant-motion-between-two-frames by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:30:35 GMT -->
</html>
