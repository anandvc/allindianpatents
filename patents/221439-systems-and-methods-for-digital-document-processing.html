<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/221439-systems-and-methods-for-digital-document-processing by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 09:38:25 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 221439:SYSTEMS AND METHODS FOR DIGITAL DOCUMENT PROCESSING</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">SYSTEMS AND METHODS FOR DIGITAL DOCUMENT PROCESSING</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>The invention relates to display technologies that separate the underlying functionality of an application program from the graphical display process, thereby eliminating or reducing the application&#x27;s need to control the device display and to provide graphical user interface tools and controls for the display. Additionally, such systems reduce or eliminate the need for an application program to be present on a processing system when displaying data created by or for that application program, such as a document or video stream. Thus it will be understood that in one aspect, the systems and method described herein can display content, including documents, video steams, or other content, and will provide the graphical user functions for viewing the displayed document, such as zoom, pan, or other such functions, without need for the underlying application to be present on the system that is displaying the content. The advantages over the prior art of the systems and methods described herein include the advantage of allowing different types of content from different application programs to be shown on the same display within the same work space.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td> <br><br>
Systems and Methods for Digital Document Processing<br>
2	Related Applications<br>
3	This application claims priority to earlier filed<br>
4	British Patent Application No. 0009129.8, filed 14<br>
5	April 2000, and US Patent Application Serial Number<br>
6	09/703,502 filed 31 October 2000, both having Majid<br>
7	Anwar as an inventor, the contents of which are<br>
8	hereby incorporated by reference.<br>
9	Field of the Invention<br><br>
10	The invention relates to data processing systems,<br>
11	and more particularly, to methods and systems for<br>
12	processing digital documents to generate an output<br>
13	representation of a source document as a visual<br>
14	display, a hardcopy, or in some other display<br>
15	format.<br>
16	Background<br><br>
2<br>
1	As used herein, the term "digital document" is used<br>
2	to describe a digital representation of any type of<br>
3	data processed by a data processing system which is<br>
4	intended, ultimately, to be output in some form, in<br>
5	whole or in part, to a human user, typically by<br>
6	being displayed or reproduced visually {e.g., by<br>
7	means of a visual display unit or printer), or by<br>
8	text-to-speech conversion, etc.  A digital document<br>
9	may include any features capable of representation,<br><br>
10	including but not limited to the following:  text;<br>
11	graphical images; animated graphical images; full<br>
12	motion video images; interactive icons, buttons,<br>
13	menus or hyperlinks.  A digital document may also<br>
14	include non-visual elements such as audio (sound)<br>
15	elements.<br>
16	Data processing systems, such as personal computer<br>
17	systems, are typically required to process "digital<br>
18	documents," which may originate from any one of a<br>
19	number of local or remote sources and which may<br>
20	exist in any one of a wide variety of data formats<br><br>
21	("file formats").  In order to generate an output<br>
22	version of the document, whether as a visual display<br>
23	or printed copy, for example, it is necessary for<br>
24	the computer system to interpret the original data<br>
25	file and to generate an output compatible with the<br>
26	relevant output device (e.g., monitor, or other<br>
27	visual display device or printer).  In general, this<br>
28	process will involve an application program adapted<br>
29	to interpret the data file, the operating system of<br>
30	the computer, a software "driver" specific to the<br>
31	desired output device and, in some cases<br><br>
32	(particularly for monitors or other visual display<br>
33	units), additional hardware in the form of an<br>
34	expansion card.<br>
35	This conventional approach to the processing of<br>
36	digital documents in order to generate an output is<br>
37	inefficient in terms of hardware resources, software<br>
38	overheads and processing time, and is completely<br>
39	unsuitable for low power, portable data processing<br>
40	systems, including wireless telecommunication<br><br>
10	systems, or for low cost data processing systems<br>
11	such as network terminals, etc.  Other problems are<br>
12	encountered in conventional digital document<br>
13	processing systems, including the need to configure<br>
14	multiple system components (including both hardware<br>
15	and software components) to interact in the desired<br>
16	manner, and inconsistencies in the processing of<br>
17	identical source material by different systems<br><br>
18	(e.g., differences in formatting, color<br>
19	reproduction, etc.).  In addition, the conventional<br>
20	approach to digital document processing is unable to<br>
21	exploit the commonality and/or re-usability of file<br>
22	format components.<br>
23	summary of the invention<br>
24	It is an object of the present invention to provide<br>
25	digital document processing methods and systems, and<br>
26	devices incorporating such methods and systems,<br>
27	which obviate or mitigate the aforesaid<br>
28	disadvantages of conventional methods and systems.<br><br>
29	The systems and methods described herein provide a<br>
30	display technology that separates the underlying<br>
31	functionality of an application program from the<br>
32	graphical display process, thereby eliminating or<br>
33	reducing the application's need to control the<br>
34	device display and to provide graphical user<br>
35	interface tools and controls for the display.<br>
36	Additionally, such systems reduce or eliminate the<br>
37	need for an application program to be present on a<br><br>
10	processing system when displaying data created by or<br>
11	for that application program, such as a document or<br>
12	video stream.  Thus it will be understood that in<br>
13	one aspect, the systems and methods described herein<br>
14	can display content, including documents, video<br>
15	streams, or other content, and will provide the<br>
16	graphical user functions for viewing the displayed<br>
17	document, such as zoom, pan, or other such<br>
18	functions, without need for the underlying<br>
19	application to be present on the system that is<br>
20	displaying the content.  The advantages over the<br>
21	prior art of the systems and methods described<br>
22	herein include the advantage of allowing different<br>
23	types of content from different application programs<br>
24	to be shown on the same display within the same work<br>
25	space.  Many more advantages will be apparent to<br><br>
26	those of ordinary skill in the art and those of<br>
27	those of ordinary skill in the art will also be able<br>
28	to see numerous way of employing the underlying<br>
29	technology of the invention for creating additional<br>
3D	systems, devices, and applications. These modified<br>
31	systems and alternate systems and practices will be<br><br>
1	understood to fall within the scope of the<br>
2	invention. 3<br><br>
4	More particularly, the systems and methods described<br>
5	herein include a digital content processing system<br>
6	that comprises an application dispatcher for<br>
7	receiving an input byte stream representing source<br>
8	data in one of a plurality of predetermined data<br>
9	formats and for associating the input byte stream<br><br>
10	with one of the predetermined data formats.  The<br>
11	system may also comprise a document agent for<br>
12	interpreting the input byte stream as a function of<br>
13	the associated predetermined data format and for<br>
14	parsing the input byte stream into a stream of<br>
15	document objects that provide an internal<br>
16	representation of primitive structures within the<br>
17	input byte stream.  The systems also include a core<br>
18	document engine for converting the document objects<br>
19	into an internal representation data format and for<br>
20	mapping the internal representation data to a<br><br>
21	location on a display. A shape processor within the<br>
22	system processes the internal representation data to<br>
23	drive an output device to present the content as<br>
24	expressed through the internal representation. 25<br>
2 6	Embodiments of the invention will now be described,<br>
27	by way of example only, with reference to the<br>
2 8	accompanying drawings.<br>
29	Brief Description of the Drawings<br><br>
1	The foregoing and other objects and advantages of<br>
2	the invention will be appreciated more fully from<br>
3	the following further description thereof, with<br>
4	reference to the accompanying drawings, wherein:<br>
5	Figure 1 is a block diagram illustrating an<br>
6	embodiment of a digital document processing system<br>
7	in accordance with the present invention.<br>
8	Figure 2 is a block diagreim that presents in greater<br>
9	detail the system depicted in Figure 1;<br><br>
10	Figure 3 is a flowchart diagram of one document<br>
11	agent;<br>
12	Figure 4 depicts schematically an exemplary document<br>
13	of the type that can be processed by the system of<br>
14	Figure 1;<br>
15	Figure 5 depicts flowchart diagrams of two<br>
15	exemplary processes employed to reduce redundancy<br>
17	within the internal representation of a document;<br>
18	and<br>
19	Figures 6-8 depict an exemplary data structure for<br>
20	storing an internal representation of a processed<br>
21	source document.<br>
22	Detailed Description of Certain Illustrated<br>
23	Embodiments<br>
24	The systems and methods described herein include<br>
25	computer programs that operate to process an output<br><br>
26	stream or output file generated by an application<br>
27	program for the purpose of presenting the output on<br>
28	an output device, such as a video display.  The<br>
29	applications according to the invention can process<br>
30	these streams to create an internal representation<br>
31	of that output and can further process that internal<br>
32	representation to generate a new output stream that<br>
33	may be displayed on an output device as the output<br>
34	generated by the application according to the<br><br>
10	invention. Accordingly, the systems of the<br>
11	invention decouple the application program from the<br>
12	display process thus relieving the application<br>
13	progreum from having to display its output onto a<br>
14	particular display device and further removes the<br>
15	need to have the application program present when<br>
16	processing the output of that application for the<br>
17	purpose of displaying that output.<br>
18	To illustrate this operation, Figure 1 provides a<br>
19	high-level functional block diagram of a system 10<br>
20	that allows a plurality of application programs,<br>
21	shown collectively as element 13, to deliver their<br>
22	output streams to a computer process 8 that<br>
23	processes those output streams and generates a<br>
24	representation of the collective output created by<br>
25	those streams for display on  the device 26.  The<br>
26	collective output of the application programs 13 is<br>
27	depicted in Figure 1 by the output printer device 26<br><br>
28	that presents the output content generated by the<br>
29	different application programs 13.  It will be<br>
3 0	understood by those of skill in the art the output<br>
31	device 2 6 is presenting output generated by the<br><br>
1	computer process 8 and that this output collectively<br>
2	carries the content of the plural application<br>
3	programs 13.  In the illustration provided by<br>
4	Figure 1, the presented content comprises a<br>
5	plurality of images and the output device 26 is a<br>
6	display.  However, it will be apparent to those of<br>
7	skill in the art that in other practices the content<br>
8	may be carried in a format other than images, such<br>
9	as auditory tactile, or any other format, or<br><br>
10	combination of formats suitable for conveying<br>
11	information to a user.  Moreover, it will be<br>
12	understood by those of skill in the art that the<br>
13	type of output device 26 will vary according to the<br>
14	application and may include devices for presenting<br>
15	audio content, video content, printed content,<br>
16	plotted content or any other type of content.  For<br>
17	the purpose of illustration, the systems and methods<br>
18	described herein will largely be shown as displaying<br>
19	graphical content through display devices, yet it<br>
20	will be understood that these exemplary systems are<br>
21	only for the purpose of illustration, and not to be<br>
22	understood as limiting in anyway.  Thus the output<br>
23	generated by the application programs 13 is<br>
24	processed and aggregated by the computer process 8<br>
25	to create a single display that includes all the<br>
26	content generated by the individual application<br>
27	programs 13.<br>
28	In the depicted embodiment, each of the<br>
29	representative outputs appearing on display 26 is<br>
3 0	termed a document, and each of the depicted<br>
31	documents can be associated with one of the<br><br>
1	application programs 13.  It will be understood that<br>
2	the term document as used herein will encompass<br>
3	documents, streamed video, streamed audio, web<br>
4	pages, and any other form of data that can be<br>
5	processed and displayed by the computer process 8.<br>
6	The computer process 8 generates a single output<br>
7	display that includes within that display one or<br>
8	more of the documents generated from the application<br>
9	programs 13.  The collection of displayed documents<br><br>
10	represents the content generated by the application<br>
11	programs 13 and this content is displayed within the<br>
12	program window generated by the computer process 8.<br>
13	The program window for the computer process 8 also<br>
14	may include a set of icons representative of tools<br>
15	provided with the graphical user interface and<br>
16	capable of allowing a user to control the operation,<br>
17	in this case the display, of the dociunents appearing<br>
18	in the program window.<br>
19	In contrast, the conventional approach of having<br>
20	each application program form its own display would<br>
21	result in a presentation on the display device 26<br>
22	that included several program windows, typically one<br>
23	for each application program 13.  Additionally, each<br>
24	different type of program window would include a<br>
25	different set of tools for manipulating the content<br>
26	displayed in that window.  Thus the system 10 of the<br><br>
27	invention has the advantage of providing a<br>
28	consistent user interface, and only requiring<br>
29	knowledge of one set of tools for displaying and<br>
30	controlling the different documents.  Additionally,<br>
31	the computer process 8 operates on the output of the<br><br>
32	application programs 13, thus only requiring that<br>
33	output to create the documents that appear within<br>
34	the program window.  Accordingly, it is not<br>
35	necessary that the application programs 13 be<br>
36	resident on the same machine as the process 8, nor<br>
37	that the application programs 13 operate in concert<br>
38	with the computer process 8.  The computer process 8<br>
39	needs only the output from these application<br>
40	programs 13, and this output can be derived from<br><br>
10	stored data files that were created by the<br>
11	application programs 13 at an earlier time.<br>
12	However, the systems and methods described herein<br>
13	may be employed as part of systems wherein an<br>
14	application program is capable of presenting its own<br>
15	content, controlling at least a portion of the<br>
16	display 26 and presenting that content within a<br>
17	program window associated with that application<br>
18	program.  In these embodiments the systems and<br>
19	methods of the invention can work as separate<br>
20	applications that appear on the display within a<br>
21	portion of the display provided for its use.<br>
22	More particularly. Figure 1 depicts a plurality of<br>
23	application programs 13.  These application programs<br>
24	can include word processing programs such as Word,<br>
25	WordPerfect, or any other similar word processing<br>
26	program.  It can further include programs such as<br>
27	Netscape Composer that generates HTML files, Adobe<br>
28	Acrobat that processes PDF files, a web server that<br>
29	delivers XML or HTML,  a streaming server that<br>
3 0	generates a stream of audio-visual data, an e-mail<br>
31	client or server, a database, spreadsheet or any<br><br>
1	other kind of application program that delivers<br>
2	output either as a file, data stream, or in some<br>
3	other format suitable for use by a computer process.<br>
4	In the embodiment of Figure 1 each of the<br>
5	application programs 13 presents its output content<br>
6	to the computer process 8.  In operation this can<br>
7	occur by having the application process 13 direct<br>
8	its output stream as an input byte stream to the<br>
9	computer process 8.  The use of data streams is<br><br>
10	well known to those of ordinary skill in the art and<br>
11	described in the literature, including for example,<br>
12	Stephen G. Kochan, Programming in C, Hayden<br>
13	Publishing (1983). Optionally, the application<br>
14	program 13 can create a data file such as a Word<br>
15	document, that can be streamed into the computer<br>
16	process 8 either by a separate application or by the<br>
17	computer process 8.<br>
18	The computer process 8 is capable of processing the<br>
19	various input streams to create the aggregated<br>
20	display shown on display device 26.  To this end,<br>
21	and as will be shown in greater detail hereinafter,<br>
22	the computer process 8 processes the incoming<br>
23	streams to generate an internal representation of<br>
24	each of these input streams.  In one practice this<br><br>
25	internal representation is meant to look as close as<br>
26	possible to the output stream of the respective<br>
27	application program 13.  However, in other<br>
28	embodiments the internal representation may be<br>
29	created to have a selected, simplified or partial<br>
30	likeness to the output stream generated by the<br>
31	respective application program 13.  Additionally and<br><br>
32	optionally, the systems and methods described herein<br>
33	may also apply filters to the content being<br>
34	translated thereby allowing certain portions of the<br>
35	content to be removed from the content displayed or<br>
36	otherwise presented.  Further, the systems and<br>
37	methods described herein may allow alteration of the<br>
38	structure of the source document, allowing for<br>
39	repositioning content within a document, rearranging<br>
40	the structure of the document, or selecting only<br><br>
10	certain types of data.  Similarly in an optional<br>
11	embodiment, content can be added during the<br>
12	translation process, including active content such<br>
13	as links to web sites.  In either case, the internal<br>
14	representation created by computer process 8 may be<br>
15	further processed by the computer process 8 to drive<br>
16	the display device 2 6 to create the aggregated image<br>
17	represented in Figure 1.<br>
18	Turning to Figure 2, a more detailed representation<br>
19	of the system of Figure 1 is presented.<br>
20	Specifically, Figure 2 depicts the system 10 which<br>
21	includes that computer process 8, the source<br>
22	documents 11, a and a display device 26.  The<br>
23	computer process 8 includes a plurality of document<br>
24	agents 12, an internal representation format file<br>
25	and process 14, buffer storage 15, a library of<br>
26	generic objects 16,  a core document engine that in<br>
27	this embodiment comprises a parsing module 18, and a<br>
28	rendering module 19, an internal view 20,  a shape<br>
29	processor 22 and a final output 24.  Figure 2<br>
30	further depicts an optional input device 30 for<br>
31	transmitting user input 40 to the computer process<br><br>
32	8.  The depicted embodiment includes a process 8<br>
33	that comprises a shape processor 22.  However, it<br>
34	will be apparent to those of ordinary skill in the<br>
35	art, that the depicted process 8 is only exemplary<br>
36	and that the process 8 may be realized through<br>
37	alternate processes and architectures.  For example,<br>
38	the shape processor 22 may optionally be realized as<br>
39	a hardware component, such as a semiconductor<br>
40	device, that supports the operation of the other<br><br>
10	elements of the process 8.  Moreover, it will be<br>
11	understood that although Figure 2 presents process 8<br>
12	as a functional block diagram that comprises a<br>
13	single system, it may be that process 8 is<br>
14	distributed across a number of different platforms,<br>
15	and optionally it may be that the elements operate<br>
16	at different times and that the output from one<br>
17	element of process 8 is delivered at a later time as<br>
18	input to the next element of process 8.<br>
19	As discussed above, each source document 11 is<br>
20	associated with a document agent 12 that is capable<br>
21	of translating the incoming document into an<br>
22	internal representation of the content of that<br>
23	source document 11,  To identify the appropriate<br>
24	document agent 12 to process a source document 11,<br><br>
25	the system 10 of Figure 1 includes an application<br>
26	dispatcher {not shown) that controls the interface<br>
27	between application programs and the system 10.  In<br>
28	one practice, the use of an external application<br>
29	programming interface (API) is handled by the<br>
30	application dispatcher which passes data, calls the<br>
31	appropriate document agent 12, or otherwise carries<br><br>
32	out the request made by the application program.  To<br>
33	select the appropriate document agent 12 for a<br>
34	particular source document 11, the application<br>
35	dispatcher advertises the source document 11 to all<br>
36	the loaded document agents 12.  These document<br>
37	agents 12 then respond with information regarding<br>
38	their particular suitability for translating the<br>
39	content of the published source document 11.  Once<br>
40	the document agents 12 have responded, the<br><br>
10	application dispatcher selects a document agent 12<br>
11	and passes a pointer, such as a URI of the source<br>
12	document 11, to the selected document agent 12.<br>
13	In one practice, the computer process 8 may be run<br>
14	as a service under which a plurality of threads may<br>
15	be created thereby supporting multi-processing of<br>
16	plural docviment sources 11.  In other embodiments,<br>
17	the process 8 does not support multi-threading and<br>
18	the document agent 12 selected by the application<br>
19	dispatcher will be called in the current thread.<br>
20	It will be understood that the exemplary embodiment<br>
21	of Figure 2 provides a flexible and extensible front<br>
22	end for processing incoming data streams of<br>
23	different file formats.  For example,  optionally,<br>
24	if the application dispatcher determines that the<br>
25	system lacks a document agent 12 suitable for<br><br>
26	translating the source document 11, the application<br>
27	dispatcher can signal the respective application<br>
28	program 13 indicating that the source document 11 is<br>
29	in an unrecognized format.  Optionally, the<br>
30	application program 13 may choose to allow the<br><br>
31	reformatting of the source document 11, such as by<br>
32	converting the source document 11 produced by the<br>
33	application program 13 from its present format into<br>
34	another format supported by that application program<br>
35	13.  For example an application program 13 may<br>
36	determine that the source document 11 needs to be<br>
37	saved in a different format, such as an earlier<br>
38	version of the file format.  To the extent that the<br>
39	application program 13  supports that format, the<br><br>
10	application program 13 can resave the source<br>
11	document 11 in this supported format in order that a<br>
12	document agent 12 provided by the system 10 will be<br>
13	capable of translating the source document 11.<br>
14	Optionally, the application dispatcher, upon<br>
15	detecting that the system 10 lacks a suitable<br>
16	document agent 12, can indicate to a user that a new<br>
17	document agent of a particular type may be needed<br>
18	for translating the present source document 11.  To<br>
19	this end, the computer process 8 may indicate to the<br>
20	user that a new document agent needs to be loaded<br>
21	into the system 10 and may direct the user to a<br>
22	location, such as a web site, from where the new<br>
23	document agent 12 may be downloaded.   Optionally,<br>
24	the system could fetch automatically the document<br>
25	agent without asking the user, or could identify a<br>
26	generic agent 12, such as a generic text agent that<br>
27	can extract portions of the source document 11<br>
28	representative of text.  Further, agents that prompt<br>
29	a user for input and instruction during the<br>
30	translation process may also be provided.<br><br>
1	In a still further optional embodiment, an<br>
2	application dispatcher in conjunction with the<br>
3	document agents 12 acts as an input module that<br>
4	identifies the file format of the source document 11<br>
5	on the basis of any one of a variety of criteria,<br>
6	such as an explicit file-type identification within<br>
7	the document, from the file name, including the file<br>
8	name extension, or from known characteristics of the<br>
9	content of particular file types.  The bytestream is<br><br>
10	input to the document agent 12, specific to the file<br>
11	format of the source document 11.<br>
12	Although the above description has discussed input<br>
13	data being provided by a stream or computer file, it<br>
14	shall be understood by those of skill in the art<br>
15	that the system 10 may also be applied to input<br>
16	received from an input device such as a digital<br>
17	camera or scanner as well as from an application<br>
18	program that can directly stream its output to the<br>
19	process 8, or that has its output streamed by cui<br>
20	operating system to the process 8.  In this case the<br>
21	input bytestream may originate directly from the<br>
22	input device, rather from a source document 11.<br>
23	However, the input bytestream will still be in a<br>
24	data format suitable for processing by the system 10<br>
25	and, for the purposes of the invention, input<br>
26	received from such an input device may be regarded<br>
27	as a source document 11.<br>
28	As shown in Figure 2, the document agent 12 employs<br><br>
29	the library 16 of standard objects to generate the<br>
30	internal representation 14, which describes the<br><br>
31	content of the source document in terms of a<br>
32	collection of document objects whose generic types<br>
33	are as defined in the library 16, together with<br>
34	parameters defining the properties of specific<br>
35	instances of the various document objects within the<br>
36	document. Thus, the library 16 provides a set of<br>
37	types of objects which the document agents 12, the<br>
38	parser 18 and the system 10 have knowledge of.  For<br>
39	example, the document objects employed in the<br><br>
10	internal representation 14 may include:  text,<br>
11	bitmap graphics and vector graphics document objects<br>
12	which may or may not be animated and which may be<br>
13	two- or three-dimensional:  video, audio and a<br>
14	variety of types of interactive objects such as<br>
15	buttons and icons.  Vector graphics document objects<br>
16	may be PostScript-like paths with specified fill and<br>
17	transparency.  Bitmap graphic document objects may<br>
18	include a set of sub-object types such as for<br>
19	example JPEG, GIF and PNG object types.  Text<br>
20	document objects may declare a region of stylized<br>
21	text.  The region may include a paragraph of text,<br>
22	typically understood as a set of characters that<br>
23	appears between two delimiters, like a pair of<br>
24	carriage returns.  Each text object may include a<br>
25	run of characters and the styling information for<br>
26	that character run including one or more associated<br><br>
27	typefaces, points and other such styling<br>
28	information.<br>
29	The parameters defining specific instances of<br>
30	document objects will generally include dimensional<br>
31	co-ordinates defining the physical shape, size and<br><br>
32	location of the document object and any relevant<br>
33	temporal data for defining document objects whose<br>
34	properties vary with time, thereby allowing the<br>
35	system to deal with dynamic document structures<br>
36	and/or display functions.  For example, a stream of<br>
37	video input may be treated by the system 10 as a<br>
38	series of figures that are changing at a rate of,<br>
39	for example, 30 frames per second.  In this case the<br>
40	temporal characteristic of this figure object<br><br>
10	indicates that the figure object is to be updated 30<br>
11	times per second.  As discussed above, for text<br>
12	objects, the parameters will normally also include a<br>
13	font and size to be applied to a character string.<br>
14	Object parameters may also define other properties,<br>
15	such as transparency.  It will be understood that<br>
16	the internal representation may be saved/stored in a<br>
17	file format native to the system and that the range<br>
18	of possible source documents 11 input to the system<br>
19	10 may include documents in the system's native file<br>
20	format.  It is also possible for the internal<br>
21	representation 14 to be converted into any of a<br>
22	range of other file formats if required, using<br>
23	suitable conversion agents.<br>
24	Figure 3 depicts a flow chart diagram of one<br>
25	exemplary process that may be carried out by a<br>
26	document agent 12.  Specifically, Figure 3 depicts a<br>
27	process 50 that represents the operation of an<br>
28	example document agent 12, in this case a document<br>
29	agent 12 suitable for translating the contents of a<br>
30	Microsoft Word document into an internal<br>
31	representation format.  Specifically, the process 50<br><br>
32	includes an initialization step 52 wherein the<br>
33	process 50 initializes the data structures, memory<br>
34	space, and other resources that the process 50 will<br>
35	employ while translating the source document 11.<br>
36	After step 52 the process 50 proceeds to a series of<br>
37	steps, 54, 58 and 60, wherein the source document 11<br>
38	is analyzed and divided into subsections.  In the<br>
39	process 50 depicted in Figure 3 steps 54, 58 and 60,<br>
40	subdivide the source document 11 as it is streamed<br><br>
10	into the document agent 12 first into sections, then<br>
11	subdivides the sections into paragraphs and then<br>
12	subdivides paragraphs into the individual characters<br>
13	that make up that paragraph.  The sections,<br>
14	paragraphs and characters identified within the<br>
15	source document 11 may be identified within a piece<br>
16	table that contains pointers to the different<br>
17	subsections identified within the source document<br>
18	11.   It will be understood by those of skill in the<br>
19	art that the piece table depicted in Figure 3<br>
20	represents a construct employed by MSWord for<br>
21	providing pointers to different subsections of a<br>
22	document.  It will further be understood that the<br>
23	use of a piece table or a piece table lilo construct<br>
24	is optional and depends on the application at hand,<br>
25	including depending on the type of document being<br>
26	processed.<br>
27	As the process 50 in step 60 begins to identify<br>
28	different characters that appear within a particular<br>
29	paragraph, the process 60 may proceed to step 62<br>
30	wherein a style is applied to the character or set<br>
31	of characters identified in step 60.  The<br><br>
1	application of a style is understood to associated<br>
2	the identified characters with a style of<br>
3	presentation that is being employed with those<br>
4	characters.  The style of presentation may include<br>
5	properties associated with the character including<br>
6	font type, font size, whether the characters are<br>
7	bold, italic, or otherwise stylized.  Additionally,<br>
8	in step 62 the process can determine whether the<br>
9	characters are rotated, or being positioned for<br><br>
10	following a curved path or other shape.<br>
11	Additionally, in step 62 style associated with the<br>
12	paragraph in which the characters occur may also be<br>
13	identified and associated with the characters.  Such<br>
14	properties can include the line spacing associated<br>
15	with the paragraph, the margins associated with the<br>
16	paragraph, the spacing between characters, and other<br>
17	such properties.<br>
18	After step 62 the process 50 proceeds to step 70<br>
19	wherein the internal representation is built up.<br>
20	The object which describes the structure of the<br>
21	document is created in Step 64 as an object within<br>
22	the internal representation, and the associated<br>
23	style of this object, together with the character<br>
24	run it contains, is created separately within the<br>
25	internal representation at Step 68.   Figures 6, 7<br>
26	and 8, which will be explained in more detail herein<br>
27	after, depict figuratively the file structure<br><br>
28	created by the process 50 wherein the structure of a<br>
29	document is captured by a group of dociiment objects<br>
30	and the data associated with the document objects is<br>
31	stored in a separate data structure. After step 70,<br><br>
32	a process 50 proceeds to decision block 72 wherein<br>
33	the process 50 determines whether the paragraph<br>
34	associated with the last processed character is<br>
35	complete.  If the paragraph is not complete the<br>
5	process 50 returns to step 60 wherein the next<br>
5	character from the paragraph is read.<br>
7	Alternatively, if the paragraph is complete the<br>
8	process 50 proceeds to decision block 74 wherein the<br>
9	process 50 determines whether the section is<br><br>
10	complete.  If the section is complete the process<br>
11	returns to step 58 and the next paragraph is read<br>
12	from the piece table.  Alternatively if the section<br>
13	is complete the process 50 proceeds to step 54<br>
14	wherein the next section, if there is a next section<br>
15	is read from the piece table and processing<br>
16	continues.  Once the document has been processed the<br>
17	system 8 can transmit, save, export or otherwise<br>
18	store the translated document for subsequent use.<br>
19	The system can store the translated file in a format<br>
20	compatible with the internal representation, and<br>
21	optionally in other formats as well including<br>
22	formats compatible with the file formats of the<br>
23	source documents 11 (for which it may employ 'export<br>
24	document agents' not shown capable of receiving<br>
25	internal representation data and creating source<br>
26	document data), or in a binary form, a textual<br>
27	document description structure, marked-up text or in<br>
28	any other suitable format; and may employ a<br>
29	universal text encoding model, including Unicode,<br>
30	shiftmapping, big-5, and a luminance/chrominance<br>
31	model.<br><br>
32	As can be seen from the above, the format of the<br>
33	internal representation 14 separates the "structure"<br>
34	(or "layout") of the documents, as described by the<br>
35	object types and their parameters, from the<br>
5	"content" of the various objects; e.g. thi^ character<br>
5	string (content) of a text object is separated from<br>
7	the dimensional parameters of the object; the image<br>
8	data (content) of a graphic object is separated from<br>
9	its dimensional parameters.  This allows document<br><br>
10	structures to be defined in a compact manner and<br>
11	provides the option for content data to be stored<br>
12	remotely and to be fetched by the system only when<br>
13	needed.  The internal representation 14 describes<br>
14	the document and its constituent objects in terms of<br>
15	"high-level" descriptions.<br>
16	The document agent 12 described above with reference<br>
17	to Figure 3 is capable of processing a data file<br>
18	created by the MSWord word processing application<br>
19	and translating that data file into an internal<br>
20	representation that is formed from a set of object<br>
21	types selected from the library 16, that represents<br>
22	the content of the processed document.  Accordingly,<br>
23	the document agent 12 analyzes the Word document and<br>
24	translates the structure and content of that<br>
25	document into an internal representation known to<br><br>
26	the computer process 8.  One example of one type of<br>
27	Word document that may be processed by tfee document<br>
28	agent 12 is depicted in Figure 4.  Specifically,<br>
29	Figure 4 depicts a Word document 32 of the type<br>
3 0	created by the MSWord application program. The<br>
31	depicted document 32 comprises one page of<br><br>
1	information wherein that one page includes two<br>
2	columns of text 34 and one figure 36.  Figure 4<br>
3	further depicts that the columns of text 34 and the<br>
4	figure 3 6 are positioned on the page 38 in such a<br>
5	way that one column of text runs from the top of the<br>
6	page 38 to the bottom of the page 38 and the second<br>
7	column of text runs from about the center of the<br>
8	page to the bottom of the page with the figure 36<br>
9	being disposed above the second column of text 34.<br><br>
10	As discussed above with reference to Figure 3 the<br>
11	document agent 12 begins processing the document 32<br>
12	by determining that the document 32 comprises one<br>
13	page and contains a plurality of different objects.<br>
14	For the one page found by the document agent 12, the<br>
15	document agent 12 identifies the style of the page,<br>
16	which for example may be a page style of an 8.5 x 11<br>
17	page in portrait format.  The page style identified<br>
18	by the document agent 12 is embodied in the internal<br>
19	representation for later use by the parser 18 in<br>
20	formatting and flowing text into the docviment<br>
21	created by the process 8.<br>
22	For the document 32 depicted in Figure 4 only one<br>
23	page is present.  However, it will be understood<br>
24	that the document agent 12 may process Word<br>
25	documents comprising a plurality of pages.  In such<br>
26	a case the document agent 12 would process each page<br>
27	separately by creating a page then filling it with<br>
28	objects of the type found in the library.  Thus page<br>
29	style information can include that a document<br>
30	comprises a plurality of pages and that the pages<br><br>
31	are of a certain size.  Other page style information<br>
32	may be identified by the document agent 12 and the<br>
33	page style information identified can vary according<br>
34	to the application.  Thus different page style<br>
35	information may be identified by a document agent<br>
36	capable of processing a Microsoft Excel document or<br>
37	a real media data stream,<br>
38	As further described with reference to Figure 3- 4<br>
39	once the document agent 12 has identified the page<br><br>
10	style the document agent 12 may begin to break the<br>
11	document 32 dovm into objects that can be mapped to<br>
12	document objects knovm to the system and typically<br>
13	stored in the library 16.  For example, the docioment<br>
14	agent 12 may process the document 32 to find text<br>
15	objects, bitmap objects and vector graphic objects.<br>
16	Other type of object types may optionally be<br>
17	provided including video type, animation type,<br>
18	button type, and script type. In this practice, the<br>
19	document agent 12 will identify a text object 34<br>
20	whose associated style has two columns.  The<br>
21	paragraphs of text that occur within the text object<br>
22	34 may be analyzed for identifying each character in<br>
23	each respective paragraph.  Process 50 may apply<br>
24	style properties to each identified character run<br>
25	and each character run identified within the<br>
26	document 32 may be mapped to a text object of the<br>
27	type listed within the library 16.  Each character<br>
28	run and the applied style can be understood as an<br>
29	object identified by the document agent 12 as having<br>
30	been found within the document 32 and having been<br>
31	translated to a document object, in this case a text<br><br>
1	object of the type listed within the library 16.<br>
2	This internal representation object may be streamed<br>
3	from the document agent 12 into the internal<br>
4	representation 14.  The document agent 12 may<br>
5	continue to translate the objects that appear within<br>
6	the document 32 into document objects that are known<br>
7	to the system 10 until each object has been<br>
8	translated.  The object types may be appropriate for<br>
9	the application and may include object types<br><br>
10	suitable for translating source data representative<br>
11	of a digital document, an audio/visual presentation,<br>
12	a music file, an interactive script, a user<br>
13	interface file and an image file, as well as any<br>
14	other file types.<br>
15	Turning to Figure 5, it can be seen that the<br>
16	process 80 depicted in Figure 5 allows for<br>
17	compacting similar objects appearing within the<br>
18	internal representation of the source document 11,<br>
19	for the purpose of reducing the size of the internal<br>
20	representation.  For example, Figure 5 depicts a<br>
21	process 80 wherein step 82 has a primitive library<br>
22	object A being processed by, in step 84, inserting<br>
23	that primitive object into the docximent that is<br>
24	becoming the internal representation of the source<br>
25	document 11.  In step 88 another object B, provided<br>
26	by the document agent 12 is delivered to the<br>
27	internal representation file process 14.  The<br>
28	process 80 then undertakes the depicted sequence of<br>
29	steps 92 through 98 wherein characteristics of<br>
3 0	object A are compared to the characteristics of<br>
31	object B to determine if the two objects have the<br><br>
1	same characteristics.  For example, if object A and<br>
2	object B represent two characters such as the letter<br>
3	P and the letter N, if both characters P and N are<br>
4	the scime color, same font, same size and the same<br>
5	style such as bold or italicized, then the process<br>
6	80 in step 94 joins the two objects together within<br>
7	one object classification stored within the internal<br>
8	representation.  If these characteristics do not<br>
9	match then the process 80 adds them to the internal<br><br>
10	representation as two separate objects.<br>
11	Figure 5 depicts a process 80 wherein the internal<br>
12	representation file 14 compacts the objects as a<br>
13	function of the similarity of physically adjacent<br>
14	objects.  Those of ordinary skill in the art will<br>
15	understand that this is merely one process for<br>
16	compacting the objects and that other techniques may<br>
17	be employed.  For example, in an optional practice,<br>
18	the compaction process may comprise a process for<br>
19	compacting objects that are visually adjacent.<br>
20	Figures 6, .7 and 8 depict the structure of the<br>
21	internal representation of a document that has been<br>
22	processed by the system depicted in Figures 1 and 2.<br>
23	The internal representation of the document may be<br>
24	embodied as a computer file or as data stored in<br>
25	core memory.  However, it will be apparent to those<br>
26	of ordinary skill in the art that data structure<br><br>
27	selected for capturing or transporting the internal<br>
28	representation may vary according to the application<br>
29	and any suitable data structure may be employed with<br><br>
30	the systems and methods described herein without<br>
31	departing from the scope of the invention.<br>
32	As will be described in greater detail hereinafter<br>
33	the structure of the internal representation of the<br>
34	processed document separates the structure of the<br>
35	document from the content of the document.<br>
36	Specifically, the structure of the document is<br>
37	captured by a data structure that shows the<br>
38	different document objects that make up the<br><br>
10	document, as well as the way that these document<br>
11	objects are arranged relative to each other.  This<br>
12	separation of structure from content is shown in<br>
13	Figure 6 wherein the data structure 110 captures the<br>
14	structure of the document being processed and stores<br>
15	that structure in a data format that is independent<br>
16	of the actual content associated with that document.<br>
17	Specifically, the data structure 110 includes a<br>
18	resource Table 112 and a document structure 114.<br>
19	The resource table 112 provides a list of resources<br>
20	for constructing the internal representation of the<br>
21	document.  For example the resource table 112 can<br>
22	include one or more tables of common structures that<br>
23	occur within the document, such as type faces,<br>
24	links, and color lists.  These common structures may<br>
25	be referenced numerically within the resource table<br>
26	112.  The resources of resource table 112 relate to<br>
27	the document objects that are arranged within the<br>
28	document structure 114.  As Figure 6 shows, the<br>
29	document structure 114 includes a plurality of<br>
3 0	containers 118 that are represented by the sets of<br>
31	the nested parentheses.  Within the containers 118<br><br>
1	are a plurality of document objects 120.  As shown<br>
2	in Figure 6 the containers 118 represent collections<br>
3	of document objects that appear within the document<br>
4	being processed.  As further shown by Figure 6 the<br>
5	containers 118 are also capable of holding sub-<br>
6	containers.  For example, the document structure 114<br>
7	includes one top-level container, identified by the<br>
8	set of outer parentheses labeled 1, and has three<br>
9	nested containers 2, 3 and 4.  Additionally, the<br><br>
10	container 4 is double nested within container 1 and<br>
11	container 3.<br>
12	Each container 118 represents features within a<br>
13	document, wherein the features may be a collection<br>
14	of individual document objects, such as the depicted<br>
15	dociiment objects 120.  Thus for example, a document,<br>
16	such as the document 32 depicted in Figure 4, may<br>
17	include a container representative of the character<br>
18	run wherein the character run includes the text that<br>
19	appears within the columns 34.  The different<br>
20	document objects 120 that occur within the character<br>
21	run container may, for example, be representative of<br>
22	the different paragraphs that occur within that<br>
23	character riin.  The character run container has a<br>
24	style associated with it.  For example, the<br>
25	character run depicted in Figure 4 can include style<br><br>
26	information representative of the character font<br>
27	type, font size, styling, such as bold or italic<br>
28	styling, and style information representative of the<br>
29	size of the column, including width and length, in<br>
30	which the character run, or at least a portion of<br>
31	that character run, occurs.  This style information<br><br>
32	may be later used by the parser 18 to reformat and<br>
33	reflow the text within the context specific view 20.<br>
34	Another example of a container may be a table that,<br>
35	for example, could appear within a column 34 of text<br>
36	in document 32.  The table may be a container with<br>
37	objects.  The other types and uses of containers<br>
38	will vary according to the application at hand and<br>
39	the systems and methods of the invention are not<br>
40	limited to any particular set of object types or<br><br>
10	containers.<br>
11	Thus, as the document agent 12 translates the source<br>
12	document 11, it will encounter objects that are of<br>
13	known object types, and the document agent 16 will<br>
14	request the library 16 to create an object of the<br>
15-	appropriate object type.  The docvunent agent 12 will<br>
15	then lodge that created document object into the<br>
17	appropriate location within dociament structure 114<br>
18	to preserve the overall structure of the source<br>
19	document 11.  For example, as the document agent 12<br>
20	encounters the image 36 within the source document<br>
21	11, the document agent 12 will recognize the image<br>
22	36, which may for example be a JPEG image, as an<br>
23	object of type bitmap, and optionally sub-type JPEG.<br>
24	This document agent 12, as shown in steps 64 and 68<br>
25	of Figure 3, can create the appropriate document<br>
26	object 120 and can lodge the created docioment object<br>
27	120 into the structure 114.  Additionally, the data<br>
28	for the JPEG image document object 120, or in<br>
29	another example, the data for the characters and<br>
3 0	their associated style for a character run, may be<br><br>
1	stored within the data structure 150 depicted in<br>
2	Figure 8.<br>
3	As the source document 11 is being processed, the<br>
4	document agent 12 may identify other containers<br>
5	wherein these other containers may be representative<br>
6	of a subfeature appearing within an existing<br>
7	container, such as a character run.  For example,<br>
8	these subfeatures may include links to referenced<br>
9	material, or clipped visual regions or features that<br><br>
10	appear within the document and that contain<br>
11	collections of individual document objects 120.  The<br>
12	document agent 12 can place these doc^ument objects<br>
13	120 within a separate container that will be nested<br>
14	within the existing container.  The arrangement of<br>
15	these document objects 120 and the containers 118<br>
16	are shown in Figure 7A as a tree structure 130<br>
17	wherein the individual containers 1, 2, 3 and 4 are<br>
18	shown as container objects 132, 134, 138 and 140<br>
19	respectively.  The containers 118 and the document<br>
20	objects 120 are arranged in a tree structure that<br>
21	shows the nested container structure of documents<br>
22	structure 114 and the different document objects 12 0<br>
23	that occur within the containers 118. The tree<br>
24	structure of Figure 7A also illustrates that the<br>
25	structure 114 records and preserves the structure of<br><br>
26	the source document 11, showing the source doc\iment<br>
27	as a hierarchy of document objects 120, wherein the<br>
28	document objects 120 include the style information,<br>
29	such as for example the size of columns in which a<br>
30	run of characters appears, or temporal information,<br>
31	such as the frame rate for streamed content.  Thus,<br><br><br>
8	As can be seen, Table 1 presents an example of<br>
9	parameters that may be used to describe a document's<br>
10	graphical structure.  Table one presents examples of<br>
11	such parameters, such as the object type, which in<br>
12	this case is a Bitmap object type.  A bounding box<br>
13	parameter is provided and gives the location of the<br>
14	docviment object within the source document 11.<br>
15	Table one further provides the Fill employed and an<br>
16	alpha factor that is representative of the degree of<br>
17	transparency for the object.  A Shape parameter<br>
18	provides a handle to the shape of the object, which<br>
19	in this case could be a path that defines the<br>
20	outline of the object, including irregularly shaped<br>
21	objects.  Table 1 also presents a time parameter<br>
22	representative of the temporal changing for that<br>
23	object.  In this example, the image is stable and<br>
24	does not change with time.  However, if the image<br><br>
1	object presented streamed media, then this parameter<br>
2	could contain a temporal characteristic that<br>
3	indicates the rate at which the object should<br>
4	change, such as a rate comparable to the desired<br>
5	freime rate for the content. 6<br>
7	.	Thus, the structural elements are containers with<br>
8	flowable data content, with this flowable data held<br>
9	separately and referenced by a handle from the<br><br>
10	container.  In this way, any or all data content can<br>
11	be held remotely from the document structure.  This<br>
12	allows for rendering of the docxament in a manner<br>
13	that can be achieved with a mixture of locally held<br>
14	and remotely held data content.  Additionally, this<br>
15	data structure allows for rapid progressive<br>
15	rendering of the internal representation of the<br>
17	source document 11, as the broader and higher level<br>
18	objects can be rendered first, and the finer<br>
19	features can be rendered in subsequent order.  Thus,<br>
20	the separate structure and data allows visual<br>
21	document to be rendered while streaming data to<br>
22	"fill" the content.  Additionally, the separation of<br>
23	content and structure allows the content of the<br>
24	document to readily be edited or changed.  As the<br>
25	document structure is independent from the content,<br>
26	different content can be substituted into the<br>
27	document structure.  This can be done on container<br>
28	by container basis or for the whole document.  The<br>
29	structure of the document can be delivered<br>
30	separately from the content and the content provided<br>
31	later, or made present on the platform to which the<br><br>
1	structure is delivered.<br>
2<br>
3	Additionally, Figure 7A shows that the structure of<br>
4	a source document 11 can be represented as a tree<br>
5	structure 130.  In one practice the tree structure<br>
6	may be modified and edited to change the<br>
7	presentation of the source document 11.  For<br>
8	example,  the tree structure may be modified to add<br>
9	additional structure and content to the tree 130.<br><br>
10	This is depicted in Figure 7B that shows the<br>
11	original tree structure of Figure 7A duplicated and<br>
12	presented under a higher level container.  Thus,<br>
13	Figure 7B shows that a new document structure, and<br>
14	therefore new representation, may be created by<br>
15	processing the tree structure 130 produced by the<br>
16	document agent 12.  This allows the visual position<br>
17	of objects within a document to change, while the<br>
18	relative position of different objects 120 may<br>
19	remain the same.  By adjusting the tree structure<br>
20	13 0, the systems described herein can edit and<br>
21	modify content.  For example, in those applications<br>
22	where the content within the tree structure 130 is<br>
23	representative of visual content, the systems<br>
24	described herein can edit the tree structure to<br>
25	duplicate the image of the document, and present<br><br>
26	side by side images of the document.  Alternatively,<br>
27	the tree structure 130 can be edited and<br>
28	supplemented to add additional visual information,<br>
29	such as by adding the image of a new document or a<br>
3 0	portion of that document.  Moreover, by controlling<br>
31	the rate at which the tree structure is changed, the<br>
32	systems described herein can create the illusion of<br><br>
33	a document gradually changing, such as sliding<br>
34	across a display, such as display device 26, or<br>
35	gradually changing into a new document.  Other<br>
36	effects, such as the creation of thumbnail views and<br>
37	other similar results can be achieved and those of<br>
38	ordinary skill by making modifications to the<br>
39	systems and methods described herein and such<br>
40	modified systems and methods will fall within the<br>
41	scope of the invention. 10<br><br>
11	The data of the source docximent 11 is stored<br>
12	separately from the structure 114.  To this end,<br>
13	each document object 120 includes a pointer to the<br>
14	data associated with that object and this<br>
15	information may be arranged within an indirection<br>
16	list such as the indirection list 160 depicted in<br>
17	Figure 8.  In this practice, and as shown in Figure<br>
18	8, each document object 120 is numbered and an<br>
19	indirection list 152 is created wherein each<br>
20	document object number 154 is associated with an<br>
21	offset value 158.  For example the document object<br>
22	number 1, identified by reference number 160, may be<br>
23	associated with the offset 700, identified by<br>
24	reference number 162.  Thus, the indirection list<br>
25	associates the object number 1 with the offset 700.<br>
26	The offset 700 may represent a location in core<br>
27	memory, or a file offset, wherein the data<br>
28	associated with object 1 may reside.  As further<br>
29	shown in Figure 8 a data structure 150 may be<br>
30	present wherein the data that is representative of<br>
31	the content associated with a respective document<br>
32	object 120 may be stored.  Thus for example, the<br><br>
33	depicted object 1 at jump location 700 may include<br>
34	the Unicode characters representative of the<br>
35	characters that occur within the character run of<br>
36	the container 1 depicted in Figure 6.  Similarly,<br>
37	the object 2 data, depicted in Figure 8 by reference<br>
38	number 172, and associated with in core memory<br>
39	location 810, identified by reference numeral 170,<br>
40	may be representative of the JPEG bit map associated<br>
41	with a bit map document object 120 referenced within<br><br>
10	the document structure 114 of Figure 6.<br>
11	It will be noted by those of skill in the art, that<br>
12	as the data is separated from the structure, the<br>
13	content for a source document is held in a<br>
14	centralized repository.  As such, the systems<br>
15	described herein allow for compressing across<br>
16	different types of data objects. Such processes<br>
17	provide for greater storage flexibility in limited<br>
18	resource systems.<br>
19	Returning to Figure 2, it will be understood that<br>
20	once the process for compacting the content of an<br>
21	internal representation file completes compacting<br>
22	different objects, these objects are passed to the<br>
23	parser 18.  The parser 18 parses the objects<br>
24	identified in the structure section of the internal<br>
25	representation, and with reference to the data<br>
26	content associated with this object, it re-applies<br>
27	the position and styling information to each object.<br>
28	The renderer 19 generates a context-specific<br>
29	representation or "view" 20 of the documents<br>
3 0	represented by the internal representation 14.  The<br><br>
1	required view may be of the all the documents, a<br>
2	whole document or of parts of one or some of the<br>
3	documents.  The renderer 19 receives view control<br>
4	inputs 40 which define the viewing context and any<br>
5	related temporal parameters of the specific document<br>
6	view which is to be generated.  For example, the<br>
7	system 10 may be required to generate a zoomed view<br>
8	of part of a document, and then to pan or scroll the<br>
9	zoomed view to display adjacent portions of the<br><br>
10	document.  The view control inputs 40 are<br>
11	interpreted by the renderer 19 to determine which<br>
12	parts of the internal representation are required<br>
13	for a particular view and how, when and for how long<br>
14	the view is to be displayed.<br>
15	The context-specific representation/view 20 is<br>
16	expressed in terms of primitive shapes and<br>
17	parameters.<br>
18	The renderer 19 may also perform additional pre-<br>
19	processing functions on the relevant parts of the<br>
20	internal representation 14 when generating the<br>
21	required view 20 of the source document 11. The view<br>
22	representation 20 is input to a shape processor 22<br>
23	for processing to generate an output in a format<br>
24	suitable fore driving an output device 26, such as a<br>
25	display device or printer.<br>
26	The pre-processing functions of the renderer 19 may<br><br>
27	include colour correction, resolution<br>
28	adjustment/enhancement and anti-aliasing.<br>
29	Resolution enhancement may comprise scaling<br><br>
30	functions which preserve the legibility of the<br>
31	content of objects when displayed or reproduced by<br>
32	the target output device.  Resolution adjustment may<br>
33	be context-sensitive; e.g. the display resolution of<br>
34	particular objects may be reduced while the<br>
35	displayed document view is being panned or scrolled<br>
36	and increased when the document view is static.<br>
37	Optionally, there may be a feedback path 42 between<br>
38	the parser 18 and the internal representation 14,<br><br>
10	e.g. for the purpose of triggering an update of the<br>
11	content of the internal representation 14, such as<br>
12	in the case where the source document 11 represented<br>
13	by the internal representation comprises a multi-<br>
14	frame animation.<br>
15	The output from the renderer 19 expresses the<br>
16	document in terms of primitive objects.  For each<br>
17	document object, the representation from the<br>
18	renderer 19 defines the object at least in terms of<br>
19	a physical, rectangle boundary box, the actual<br>
20	outline path of the object bounded by the boundary<br>
21	box, the data content of the object, and its<br>
22	transparency.<br>
23	The shape processor 22 interprets the primitive<br>
24	object and converts it into an output frame format<br>
25	appropriate to the target output device 26; e.g. a<br><br>
26	dot-map for a printer, vector instruction set for a<br>
27	plotter, or bitmap for a display device.  An output<br>
28	control input 44 to the shape processor 22 provides<br><br>
29	information to the shape processor 22 to generate<br>
30	output  suitable for a particular output de^^cice 26.<br>
31	The shape processor 22 preferably processes the<br>
32	objects defined by the view representation 2 0 in<br>
33	terms of "shape" (i.e. the outline shape of the<br>
34	object), "fill" (the data content of the object) and<br>
35	"alpha" (the transparency of the object), performs<br>
36	scaling and clipping appropriate to the required<br>
37	view and output device, and expresses the object in<br><br>
10	terms appropriate to the output device (typically in<br>
11	terms of pixels by scan conversion or the like, for<br>
12	most types of display device or printer). The shape<br>
13	processor 22 optionally includes an edge buffer<br>
14	which defines the shape of an object in terms of<br>
15	scan-converted pixels, and preferably applies anti-<br>
16	aliasing to the outline shape.  Anti-aliasing may be<br>
17	performed in a manner determined by the<br>
18	characteristics of the output device 26, by applying<br>
19	a grey-scale ramp across the object boundary.  This<br>
20	approach enables memory efficient shape-clipping and<br>
21	shape-intersection processes, and is memory<br>
22	efficient and processor efficient as well. A look-up<br>
23	table, or other technique, may be employed to define<br>
24	multiple tone response curves, allowing non-linear<br>
25	rendering control.  The individual primitive objects<br>
26	processed by the shape processor 22 are combined in<br><br>
27	the composite output frame.  The design of one<br>
28	shape processor suitable for use with the systems<br>
29	described herein is shown in greater detail in the<br>
30	patent application entitled Shape Processor, filed<br>
31	on even date herewith, the contents of which are<br><br>
32	incorporated by reference. However, any suitable<br>
33	shape processor system or process may be employed<br>
34	without departing from the scope of the invention.<br>
35	As discussed above, the process 8 depicted in Figure<br>
36	1 can be realized as a software component operating<br>
37	on a data processing system such as a hand held<br>
38	computer, a mobile telephone, set top box, facsimile<br>
39	machine, copier or other office equipment, an<br>
40	embedded computer system, a Windows or Unix<br><br>
10	workstation, or any other type of<br>
11	computer/processing platform capable of supporting,<br>
12	in whole or in part, the document processing system<br>
13	described above.  In these embodiments, the system<br>
14	can be implemented as a C language computer program,<br>
15	or a computer program written in any high level<br>
16	language including C++, Fortran, Java or Basic.<br>
17	Additionally, in an embodiment where<br>
18	microcontrollers or DSPs are employed, the systems<br>
19	can be realized as a computer program written in<br>
20	microcode or written in a high level language and<br>
21	compiled down to microcode that can be executed on<br>
22	the platform employed.  The development of such<br>
23	systems is known to those of skill in the art, and<br>
24	such techniques are set forth in Intel® StrongABM<br>
25	processors SA-1110 Microprocessor Advanced<br>
26	Developer's Manual.  Additionally, general<br><br>
27	techniques for high level programming are known, and<br>
28	set forth in, for example, Stephen G. Kochan,<br>
29	Programming in C, Hayden Publishing (1983).  It is<br>
30	noted that DSPs are particularly suited for<br>
31	implementing signal processing functions, including<br><br>
32	preprocessing functions such as image enhancement<br>
33	through adjustments in contrast, edge definition and<br>
34	brightness.  Developing code for the DSP and<br>
35	microcontroller systems follows from principles well<br>
36	known in the art.<br>
37	Accordingly, although Figs. 1 and 2 graphically<br>
38	depicts the computer process 8 as comprising a<br>
39	plurality of functional block elements, it will be<br>
40	apparent to one of ordinary skill in the art that<br><br>
10	these elements can be realized as computer programs<br>
11	or portions of computer programs that are capable of<br>
12	running on the data processing platform to thereby<br>
13	configure the data processing platform as a system<br>
14	according to the invention.  Moreover, although Fig.<br>
15	1 depicts the system 10 as an integrated unit of a<br>
16	document processing process 8 and a display device<br>
17	26, it will be apparent to those of ordinary skill<br>
18	in the art that this is only one embodiment, and<br>
19	that the systems described herein can be realized<br>
20	through other architectures and arrangements,<br>
21	including system architectures that separate the<br>
22	document processing functions of the process 8 from<br>
23	the document display operation performed by the<br>
24	display 26. Moreover, it will be understood that<br>
25	the systems of the invention are not limited to<br><br>
26	those systems that include a display or output<br>
27	device, but that the systems of the invention will<br>
28	encompass those processing systems that process one<br>
29	or more digital documents to create output that can<br>
30	be presented on an output device.  However, this<br>
31	output may be stored in a data file for sub&amp;equent<br><br>
32	presentation on a display device, for long term<br>
33	storage, for delivery over a network, or for some<br>
34	other purpose than for immediate display.<br>
35	Accordingly, it will be apparent to those of skill<br>
36	in the art that the systems and methods described<br>
37	herein can support many different document and<br>
38	content processing applications and that the<br>
39	structure of the system or process employed for a<br>
40	particular application will vary according to the<br><br>
10	application and the choice of the designer.<br>
11	From the foregoing, it will be understood that the<br>
12	system of the present invention may be "hard-wired";<br>
13	e.g. implemented in ROM and/or integrated into ASICs<br>
14	or other single-chip systems, or may be implemented<br>
15	as firmware (programmable ROM such as flashable<br>
16	ePROM), or as software, being stored locally or<br>
17	remotely and being fetched and executed as required<br>
18	by a particular device.  Such improvements and<br>
19	modifications may be incorporated without departing<br>
20	from the scope of the present invention.<br>
21	Those skilled in the art will know or be able to<br>
22	ascertain using no more than routine<br>
23	experimentation, many equivalents to the embodiments<br>
24	and practices described herein.   For example, the<br><br>
25	systems and methods described herein may be stand<br>
26	alone systems for processing source documents 11,<br>
27	but optionally these systems may be incorporated<br>
28	into a variety of types of data processing systems<br>
29	and devices, and into peripheral devices, in a<br>
3 0	number of different ways.  In a general purpose data<br><br>
1	processing system (the "host system"), the system of<br>
2	the present invention may be incorporated alongside<br>
3	the operating system and applications of the host<br>
4	system or may be incorporated fully or partially<br>
5	into the host operating system. For example, the<br>
6	systems described herein enable rapid display of a<br>
7	variety of types of data files on portable data<br>
8	processing devices with LCD displays without<br>
9	requiring the use of browsers or application<br><br>
10	programs. Examples of portable data processing<br>
11	devices which may employ the present system include<br>
12	"palmtop" computers, portable digital assistants<br>
13	(PDAs, including tablet-type PDAs in which the<br>
14	primary user interface comprises a graphical display<br>
15	with which the user interacts directly by means of a<br>
16	stylus device), internet-enabled mobile telephones<br>
17	and other communications devices.  This class of<br>
18	data processing devices requires small size, low<br>
19	power processors for portability.  Typically, these<br>
20	devices employ advanced RISC-type core processors<br>
21	designed in to ASICs (application specific<br>
22	integrated circuits), in order that the electronics<br>
23	package is small and integrated.  This type of<br>
24	device also has limited random access memory and<br>
25	typically has no non-volatile data store (e.g. hard<br>
26	disk).  Conventional operating system models, such<br>
27	as are employed in standard desktop computing<br><br>
28	systems (PCs), require high powered central<br>
29	processors and large amounts of memory to process<br>
30	digital documents and generate useful output, and<br>
31	are entirely unsuited for this type of data<br>
32	processing device.  In particular, conventional<br><br>
33	systems do not provide for the processing of<br>
34	multiple file formats in an integrated manner.  By<br>
35	contrast, the systems described herein employ common<br>
36	processes and pipelines for all file formats,<br>
37	thereby providing a highly integrated document<br>
38	processing system which is extremely efficient in<br>
39	terms of power consumption and usage of system<br>
40	resources.<br>
41	The system of the invention may be integrated at the<br><br>
10	BIOS level of portable data processing devices to<br>
11	enable document processing and output with much<br>
12	lower overhead than conventional system models.<br>
13	Alternatively, these systems may be implemented at<br>
14	the lowest system level just above the transport<br>
15	protocol stack.  For example, the system may be<br>
16	incorporated into a network device (card) or system,<br>
17	to provide in-line processing of network traffic<br><br>
18	(e.g. working at the packet level in a TCP/IP<br>
19	system) .<br>
20	The systems herein can be configured to operate with<br>
21	a predetermined set of data file formats and<br>
22	particular output devices; e.g. the visual display<br>
23	unit of the device and/or at least one type of<br>
24	printer.<br>
25	The systems described herein may also be<br>
26	incorporated into low cost data processing terminals<br><br>
27	such as enhanced telephones and "thin" network<br>
28	client terminals (e.g. network terminals with<br>
29	limited local processing and storage resources), and<br>
30	"set-top boxes" for use in interactive/internet-<br><br>
31	enabled cable TV systems. The systems may also be<br>
32	incorporated into peripheral devices such as<br>
33	hardcopy devices (printers and plotters), display<br>
34	devices (such as digital projectors), networking<br>
35	devices, input devices (cameras, scanners, etc.) and<br>
36	also multi-function peripherals (MFPs).  When<br>
37	incorporated into a printer, the system enables the<br>
38	printer to receive raw data files from the host data<br>
39	processing system and to reproduce the content of<br><br>
10	the original data file correctly, without the need<br>
11	for particular applications or drivers provided by<br>
12	the host system.  This avoids or reduces the need to<br>
13	configure a computer system to drive a particular<br>
14	type of printer.  The present system directly<br>
15	generates a dot-mapped image of the source document<br>
16	suitable for output by the printer (this is true<br>
17	whether the system is incorporated into the printer<br>
18	itself or into the host system).  Similar<br>
19	considerations apply to other hardcopy devices such<br>
20	as plotters.<br>
21	When incorporated into a display device, such as a<br>
22	projector, the system again enables the device to<br>
23	display the content of the original data file<br>
24	correctly without the use of applications or drivers<br>
25	on the host system, and without the need for<br>
26	specific configuration of the host system and/or<br>
27	display device.  Peripheral devices of these types,<br>
28	when equipped with the present system, may receive<br><br>
29	and output data files from any source, via any type<br>
30	of data communications network.<br><br>
31	Additionally, the systems and methods described<br>
32	herein may be incorporated into in-car systems for<br>
33	providing driver information or entertainment<br>
34	systems, to facilitate the delivery of information<br>
35	within the vehicle or to a network that communicates<br>
36	beyond the vehicle.  Further, it will be understood<br>
37	that the systems described herein can drive devices<br>
38	having multiple output sources to maintain a<br>
39	consistent display using modifications to only the<br><br>
10	control parameters.  Examples include, but are not<br>
11	limited to, a STB or in-car system incorporating a<br>
12	visual display and print head, thereby enabling<br>
13	viewing and printing of documents without the need<br>
14	for the source applications and drivers.<br>
15	From the foregoing, it will be understood that the<br>
16	system of the present invention may be "hard-wired";<br>
17	e.g. implemented in ROM and/or integrated into ASICs<br>
18	or other single-chip systems, or may be implemented<br>
19	as firmware (programmable ROM such as flashable<br>
20	ePROM), or as software, being stored locally or<br>
21	remotely and being fetched and executed as required<br>
22	by a particular device. 23<br><br>
24	Accordingly, it will be understood that the<br>
25	invention is not to be limited to the embodiments<br>
2 6	disclosed herein, but is to be understood from the<br>
27	following claims, which are to be interpreted as<br>
28	broadly as allowed under the law. 29<br><br><br>
1	CLAImS<br>
2	1.  A digital document processing system,<br>
3	comprising<br>
4	an application dispatcher for receiving an<br>
5	input bytestream representing source data in one of<br>
6	a plurality of predetermined data formats and for<br>
7	associating the input bytestream with one of said<br>
8	plurality of predetermined data formats,<br>
9	a document agent for interpreting said input<br>
10	bytestream as a function of said associated<br>
11	predetermined data format and for parsing the input<br>
12	bytestream into a stream of document objects<br>
13	representative of internal representations of<br>
14	primitive structures within the input bytestream,<br>
15	and<br>
16	a core document engine for converting said<br>
17	document objects into an internal representation<br>
18	data format and for mapping said internal<br>
19	representation data to a location on a display. 20<br><br>
21	2.   A digital document system according to claim 1,<br>
22	further comprising<br>
23	a shape processor for processing said internal<br>
24	representation data to drive an output device.<br>
25<br>
26	3.  A digital document processing system as claimed<br>
27	in claim 1 or 2, wherein said source data defines<br>
28	the content and structure of a digital document, and<br>
29	wherein said internal representation data describes<br>
30	said structure in terms of document objects of a<br>
31	plurality of data types and parameters defining<br><br>
32	properties of specific instances of the document<br>
33	objects, separately from said content.<br>
34	4.   A digital document processing system according<br>
35	to claim 3, wherein the parameters defining<br>
36	properties of specific instances include properties<br>
37	selected from the group consisting of dimensional,<br>
38	temporal, and physical.<br>
39	5.  A digital document processing system as claimed<br>
40	in claim 3 or 4, further including a library of<br><br>
10	objects types, said internal representation data<br>
11	being based on the content of said library.<br>
12	6.  A digital document processing system as claimed<br>
13	in any of claims 3 to 5, wherein said core document<br>
14	engine includes a parsing and rendering module<br>
15	adapted to generate an object and parameter based<br>
16	representation of a specific view of at least part<br>
17	of said internal representation data, on the basis<br>
18	of a first control input to said parsing and<br>
19	rendering module.<br>
20	7.  A digital document processing system according<br>
21	to claim 6 wherein said parameter based<br>
22	representation includes parameters selected from the<br>
23	group consisting of  fill, path, bounding box and<br>
24	transparency.<br>
25	8,  A digital document processing system according<br>
25	to any of claims 5 to 7, further including a shape<br>
27	processing module adapted to receive said object and<br>
28	parameter based representation of said specific view<br><br>
29	from said parsing and rendering module and to<br>
30	convert said object and parameter based<br>
31	representation into an output data format suitable<br>
32	for driving a particular output device.<br>
33	9.   A digital document processing system according<br>
34	to claim 8, wherein said shape processing module<br>
35	processes said objects on the basis of a shape<br>
36	defining the shape of the object bounded by the<br>
37	boundary box, the data content of the object and the<br><br>
10	transparency of the object.<br>
11	10.  A digital document processing system according<br>
12	to claim 8 or 9, wherein said shape processing<br>
13	module processes said objects on the basis of a<br>
14	shape defining the shape of the object bounded by<br>
15	the boundary box representative of a defined area on<br>
16	a display on which an object may be rendered.<br>
17	11.  A digital document processing system according<br>
18	to any preceding claim, wherein the system employs a<br>
19	chrominance/luminance-based colour model to describe<br>
20	colour data. 21<br><br>
22	12.  A digital document processing system according<br>
23	to any preceding claim, wherein the system employs a<br>
24	universal text encoding model. 25<br><br>
26	13.  A digital document processing system according<br>
27	to claim 12, wherein universal text encoding<br>
28	includes Unicode, shift-mapping and big-5.<br><br>
29	14.  A digital document processing system according<br>
30	to any preceding claim, further including a process<br>
31	for compacting an internal representation of a<br>
32	source document by combining document objects having<br>
33	similar attributes.<br>
34	15,  A digital document processing system according<br>
35	to any preceding claim, further including a process<br>
36	for compacting an internal representation of a<br>
37	source document by combining document objects having<br><br>
10	similar style attributes.<br>
11	16.  A digital document processing system according<br>
12	to any preceding claim, wherein the system is<br>
13	adapted for multiple parallel implementation for<br>
14	processing source data from one or more data sources<br>
15	and for generating one or more sets of output<br>
16	representation data.<br>
17	17.  A digital document processing system according<br>
18	to any preceding claim, further comprising a<br>
19	graphical user interface for generating internal<br>
20	representations of interactive visual displays to be<br>
21	employed by a user for controlling the digital<br>
22	document processing system.<br><br>
23	18.  A digital document processing system according<br>
24	to claim 17, comprising a data processing device<br>
25	incorporating a graphical user interface.<br>
26	19.  A digital document processing system according<br>
27	to any preceding claim, having a platform adapted<br>
28	for being embedded into a device selected from the<br><br>
29	group consisting of a hand held computer, a mobile<br>
30	telephone, a set top box, a facsimile machine, a<br>
31	copier, an embedded computer system, a printer, an<br>
32	in-car system and a computer workstation.<br>
33	20.  A digital document processing system according<br>
34	to any preceding claim, having a processor including<br>
35	a core processor system.<br>
36	21.  A digital document processing system according<br>
9	to claim 20, wherein said core processor is a RISC<br>
10	processor.<br>
11<br>
12	22.  A digital document processing system according<br>
13	to any preceding claim, wherein the document agent<br>
14	includes an export process for exporting data in a<br>
15	selected format. 16<br><br>
17	23.  A digital document processing system according<br>
18	to any preceding claim, adapted for operating on a<br>
19	multiple processing system.<br>
20	24.  A method for displaying content, comprising<br>
21	receiving a source of data representative of<br>
22	the digital content having a structure and data<br>
23	content,<br>
24	processing the source of data to identify a<br>
25	file format associated therewith,<br>
2 6       translating the source of data, as a function<br>
27	of its identified file format, into an internal<br>
28	representation that includes a first data structure<br>
29	for storing information about the structure of the<br><br>
30	digital content, and a second data structure for<br>
31	storing information about the data content contained<br>
32	in the digital content,<br>
4	generating a content file representative of an<br>
5	internal representation of content to be presented<br>
6	to a user, by processing the first data structure to<br>
7	determine a structure for a portion of the content<br>
8	file and by processing the second data structure to<br>
9	determine data content for the respective portion of<br><br>
10	the content file.<br>
11	25.  A method according to claim 24, wherein<br>
12	receiving a source of data includes receiving a<br>
13	stream of input data from a data source.<br>
14	26.  A method according to claim 25, wherein the<br>
15	data source is selected from the group consisting of<br>
16	a data file, a byte stream generated from a<br>
17	peripheral device, and a byte stream generated from<br>
18	a data file.<br>
19	27.  A method according to claim 25 or 26, wherein<br>
20	processing the source of data includes<br>
21	presenting information about the source of data to a<br>
22	plurality of document agents, each being capable of<br>
23	translating a data source of a known file format<br>
24	into the internal representation.<br>
25	28.  A method according to any of claims 24 to 27,<br>
26	wherein<br>
27	translating the source of data into an internal<br>
28	representation includes processing the source of<br>
29	data to identify data therein, and mapping the<br><br>
30	identified data to a set of object types<br>
31	representative of types of content that are present<br>
32	in a source of data. 4<br><br>
5	29.  A method according to claim 28, wherein mapping<br>
6	includes mapping identified data to a set of object<br>
7	types suitable for translating source data<br>
8	representative of a content selected from the group<br>
9	consisting of a digital document, an audio/visual<br><br>
10	presentation, a music file, an interactive script, a<br>
11	user interface file and an image file.<br>
12	30.  A method according to any of claims 24 to 29,<br>
13	wherein mapping includes mapping the identified data<br>
14	to a set of object types including a bitmap object<br>
15	type, a vector graphic object type, a video type, an<br>
16	animation type, a button type, a script type and a<br>
17	text object type.<br>
18	31.  A method according to any of claims 24 to 30,<br>
19	wherein translating the source of data includes<br>
20	filtering portions of the source data to create a<br>
21	filtered internal representation of the source<br>
22	document.<br><br>
23	32.  A method according to any of claims 24 to 31,<br>
24	wherein translating the source of data includes<br>
25	altering the first data structure to adjust the<br>
26	structure of the digital content.<br>
27	33.  A method according to any of claims 24 to 32,<br>
28	wherein translating the source of data includes the<br><br>
29	further act of substituting data content in the<br>
30	second data structure to thereby modify content<br>
31	presented within the internal representation.<br>
32	34.  A method according to any of claims 24 to 33,<br>
33	wherein translating the source of data includes<br>
34	translating the source of data into a set of<br>
35	document objects of known object types, wherein a<br>
36	document object includes a set of parameters that<br>
9	define dimensional, temporal and physical<br>
10	characteristics of the document object,<br>
11<br>
12	35.  A method according to any of claims 24 to 34,<br>
13	wherein the process is adapted for running on<br>
14	multiple processors. 15<br><br>
16	36.  A method according to any of claims 24 to 35,<br>
17	wherein the process provided a text encoding<br>
18	process, for encoding in a format selected from the<br>
19	group consisting of Unicode, shift-mapping and big-<br>
20	5.<br>
21	37.  A method according to any of claims 24 to 36,<br>
22	wherein generating a content data file includes<br>
23	parsing a set of document objects having associated<br>
24	parameters, to define a structure and content for<br><br>
25	the content data file.<br>
26	38.  A method according to claim 37, further<br>
27	including processing the structure and content of<br>
28	the content data file to create a set of objects<br><br>
29	that define the content data file and are capable of<br>
30	being rendered on an output device.<br>
31	39.  A method according to claim 37 or 38, wherein<br>
32	processing the document objects includes processing<br>
33	the associated parameters for flowing content into a<br>
34	structure defined by the document object.<br>
35	40.  A method according to claim 38 or claim 39 when<br>
36	dependent on claim 38, wherein the output device<br>
37	includes a display selected from the group<br><br>
10	consisting of a visual display, an audio speaker, a<br>
11	video player, a television display, printer, disc<br>
12	drive, network, and an embedded display. 13<br><br>
14	41.  A system for interacting with content in a<br>
15	digital documnent, comprising<br>
16	a documment agent for converting content in the<br>
17	digital document into a set of document objects<br>
18	representative of internal representations of<br>
19	primitive structures, and<br>
20	a core document engine for rendering said<br>
21	document objects to generate a display<br>
22	representative of the digital content,<br>
23	a user interface for detecting input signals<br>
24	representative of input for modifying the content of<br>
25	the digital document, and<br>
26	a process for changing the internal<br>
27	representation of the content as a function of the<br>
28	input signals, to modify the display of the digital<br>
29	content. 30<br><br>
30	42.  A system according to claim 41, wherein the<br>
31	user interface includes an input device selected<br>
32	from the group consisting of a mouse, a touch pad, a<br>
33	touch screen, a joy stick, a remote control and a<br>
34	keypad.<br><br>
43.	A digital document processing system substantially as herein<br>
described with reference to the accompanying drawings.<br>
44.	A  method  for displaying  content  substantially  as  herein<br>
described with reference to the accompanying drawings.<br><br></td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgYWJzdHJhY3QucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgY2xhaW1zLWR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che claims-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgY2xhaW1zLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgY29ycmVzcG9uZGVuY2Utb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che correspondence-others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgY29ycmVzcG9uZGVuY2UtcG8ucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che correspondence-po.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZGVzY3JpcHRpb24oY29tcGxldGUpLWR1cGxpY2F0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che description(complete)-duplicate.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZGVzY3JpcHRpb24oY29tcGxldGUpLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che description(complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZHJhd2luZ3MucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZm9ybS0xLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che form-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZm9ybS0xOC5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che form-18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZm9ybS0yNi5wZGY=" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che form-26.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZm9ybS0zLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che form-3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgZm9ybS01LnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che form-5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgb3RoZXJzLnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgcGN0LnBkZg==" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che pct.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=aW4tcGN0LTIwMDItMTg1My1jaGUgcGV0aXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">in-pct-2002-1853-che petition.pdf</a></p>
		<br>
		<div class="pull-left">
			<a href="221438-receiving-device-for-securely-storing-a-content-item-and-playback-device-for-playing-content-element.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="221440-a-synergestic-growth-promoting-composition.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>221439</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>IN/PCT/2002/1853/CHE</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>37/2008</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>12-Sep-2008</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>23-Jun-2008</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>12-Nov-2002</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>PICSEL (RESEARCH) LIMITED</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>TITANIUM BUILDING, BRAEHEAD BUSINESS PARK, KING&#x27;S INCH ROAD, PAISLEY PA4 8XE,</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>ANWAR, MAJID</td>
											<td>TITANIUM BUILDING, BRAEHEAD BUSINESS PARK, KING&#x27;S INCH ROAD, GLASGOW G51 4BP,</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06F17/00</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/GB01/01725</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2001-04-17</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>0009129.8</td>
									<td>2000-04-14</td>
								    <td>U.K.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>09/703,502</td>
									<td>2000-10-31</td>
								    <td>U.K.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/221439-systems-and-methods-for-digital-document-processing by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 09:38:26 GMT -->
</html>
