<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/263879-method-and-apparatus-for-decoding-encoding-a-video-signal by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 22:34:39 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 263879:METHOD AND APPARATUS FOR DECODING/ENCODING A VIDEO SIGNAL</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">METHOD AND APPARATUS FOR DECODING/ENCODING A VIDEO SIGNAL</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>A method of decoding a current layer using inter- layer prediction is disclosed. The present invention includes determining whether a position of a current block is included in a sampled reference layer, the current block included in the current layer, obtaining a plurality of prediction flags when the position of the current block is included in the sampled reference layer, and decoding the current layer using the plurality of the prediction flags.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>METHOD AND APPARATUS FOR DECODING/ENCODING A VIDEO SIGNAL<br>
TECHNICAL FIELD<br>
The present invention relates to a scheme for coding<br>
a video signal.<br>
BACKGROUND ART<br>
Generally, compression coding means a series of<br>
signal processing for transmitting digitalized information<br>
via a communication circuit or storing the digitalized<br>
information in a format suitable for a storage medium.<br>
There exist audio, video, characters and the like as<br>
targets for compression coding. Particularly, a scheme for<br>
performing compression coding on video is called video<br>
sequence compression. And, a video sequence is generally<br>
characterized in having spatial redundancy and temporal<br>
redundancy.<br>
Specifically, a scalable-video-coded bit stream can<br>
be decoded 'partially and selectively. For instance, a<br>
decoder having low complexity is capable of decoding a base<br>
layer and a bit stream of a low data rate is extractable<br>
for transport via network having a limited capacity. In<br>
order to generate an image of high resolution more<br>
gradually, it is necessary to enhance a quality of image<br><br>
step by step.<br>
DISCLOSURE OF THE INVENTION<br>
TECHNICAL PROBLEM<br>
Specifically, a scalable-video-coded bit stream can<br>
be decoded partially and selectively. For instance, a<br>
decoder having low complexity is capable of decoding a base<br>
layer and a bit stream of a low data rate is extractable<br>
for transport via network having a limited capacity. In<br>
order to generate an image of high resolution gradually, it<br>
is necessary to enhance a quality of image step by step.<br>
TECHNICAL SOLUTION<br>
Accordingly, the present invention is directed to a<br>
scheme for coding a video signal that substantially<br>
obviates one or more of the problems due to limitations and<br>
disadvantages of the related art.<br>
An object of the present invention is to provide a<br>
method of enhancing a coding efficiency in coding a video<br>
signal.<br>
Another object of the present invention is to provide<br>
a method of minimizing a transmission of information<br>
associated with inter-layer prediction in case that an area<br>
in a enhanced layer is not corresponding to a reference<br><br>
layer.<br>
Another object of the present invention is to provide<br>
a method of minimizing a transmission of information<br>
associated with inter-layer prediction in a manner of<br>
confirming configuration information on a scalable-video-<br>
coded bit stream.<br>
Another object of the present invention is to provide<br>
a method of minimizing a transmission of information<br>
associated with inter-layer prediction in a manner of<br>
confirming information indicating whether inter-layer<br>
prediction is executed.<br>
A further object of the present invention is to<br>
provide a method of raising a coding efficiency in a manner<br>
of confirming configuration information of a scalable-<br>
video-coded bit stream in a proper position.<br>
ADVANTAGEOUS EFFECTS<br>
Accordingly, the present invention provides the<br>
following effects or advantages.<br>
First of all, it is checked whether a current block<br>
in a enhanced layer can be predicted by using inter-layer<br>
prediction. In case that the current block in the enhanced<br>
layer is not predicted by using the inter-layer prediction,<br>
it is unnecessary to transmit coding information used for<br><br>
the inter-layer prediction. Hence, the present invention<br>
raises a coding efficiency. Secondly, by identifying<br>
configuration information of a scalable-video-coded bit<br>
stream in a proper position, whereby transmission<br>
information associated with inter-layer prediction can be<br>
minimized. For instance, by identifying information<br>
indicating whether inter-layer prediction is executed<br>
and/or quality identification information, transmission<br>
information associated with inter-layer prediction can be<br>
minimized. Therefore, coding efficiency of a video signal<br>
can be considerably enhanced using the above-explained<br>
various methods.<br>
DESCRIPTION OF DRAWINGS<br>
The accompanying drawings, which are included to<br>
provide a further understanding of the invention and are<br>
incorporated in and constitute a part of this specification,<br>
illustrate embodiments of the invention and together with<br>
the description serve to explain the principles of the<br>
invention.<br>
In the drawings:<br>
FIG. 1 is a schematic block diagram of a scalable<br>
video coding system according to the present invention;<br>
FIG. 2 and FIG. 3 are structural diagrams for<br><br>
configuration information on a scalable sequence addible to<br>
a scalable-video-coded bit stream and pictures for<br>
describing the configuration information according to one<br>
embodiment of the present invention, respectively;<br>
FIG. 4 is a diagram for a cropping relation between a<br>
sampled base layer and an enhanced layer;<br>
FIG. 5 and FIG. 6 are diagrams for syntaxes relevant<br>
to macroblock and sub-macroblock predictions through inter-<br>
layer prediction according to one embodiment of the present<br>
invention, respectively;<br>
FIG. 7 is a diagram of a syntax relevant to residual<br>
prediction through inter-layer prediction according to one<br>
embodiment of the present invention; and<br>
FIG. 8 is a structural diagram of a syntax for<br>
obtaining adaptive prediction information in accordance<br>
with a presence or non-presence of inter-layer prediction<br>
execution according to one embodiment of the present<br>
invention.<br>
BEST MODE<br>
Additional features and advantages of the invention<br>
will be set forth in the description which follows, and in<br>
part will be apparent from the description, or may be<br>
learned by practice of the invention. The objectives and<br><br>
other advantages of the invention will be realized and<br>
attained by the structure particularly pointed out in the<br>
written description and claims thereof as well as the<br>
appended drawings.<br>
To achieve these and other advantages and in<br>
accordance with the purpose of the present invention, as<br>
embodied and broadly described, a method of decoding a<br>
current layer using inter-layer prediction according to the<br>
present invention includes determining whether a position<br>
of a current block is included in a sampled reference layer,<br>
the current block included in the current layer, obtaining<br>
a plurality of prediction flags when the position of the<br>
current block is included in the sampled reference layer,<br>
and decoding the current layer using the plurality of the<br>
prediction flags.<br>
Preferably, the current layer differs from the<br>
reference layer, which is from a same video signal of the<br>
current layer, in a screen ratio ox a spatial resolution.<br>
Preferably, the determining is based on offset<br>
information of the reference layer and a variable<br>
indicating a position of the current block in the enhanced<br>
layer.<br>
Preferably, a plurality of the prediction flags<br>
include first information indicating whether a type of the<br><br>
current macroblock is derived from a corresponding block in<br>
the base layer, second information indicating whether to<br>
use a motion vector of the corresponding block in the base<br>
layer, and third information indicating whether to use a<br>
residual signal of the corresponding block in the base<br>
layer.<br>
To further achieve these and other advantages and in<br>
accordance with the purpose of the present invention, a<br>
method of encoding a enhanced layer using inter-layer<br>
prediction according to the present invention includes, in<br>
determining whether a current block is included in a<br>
sampled base layer, generating a prediction flag required<br>
for the inter-layer prediction based on whether the current<br>
block is included in a sampled base layer and generating a<br>
bit stream of the enhanced layer, having a resolution<br>
different from that of the base layer by using the base<br>
layer.<br>
It is to be understood that both the foregoing<br>
general description and the following detailed description<br>
are exemplary and explanatory and are intended to provide<br>
further explanation of the invention as claimed.<br>
MODS FOR INVENTION<br>
Reference will now be made in detail to the preferred<br>
embodiments of the present invention, examples of which are<br><br>
illustrated in the accompanying drawings.<br>
First of all, compression coding of video signal data<br>
takes spatial redundancy, spatial redundancy, scalable<br>
redundancy, and inter-view redundancy into consideration.<br>
Compression coding scheme, which takes scalable redundancy<br>
into consideration, is just an embodiment of the present<br>
invention. And, the technical idea of the present invention<br>
is applicable to temporal redundancy, spatial redundancy,<br>
inter-view redundancy, and the like. In the present<br>
disclosure, coding can include both concepts of encoding<br>
and decoding. And, coding can be flexibly interpreted to<br>
correspond to the technical idea and scope of the present<br>
invention.<br>
In a bit sequence configuration of a video signal,<br>
there exists a separate layer structure called a NAL<br>
(network abstraction layer) between a VCL (video coding<br>
layer) dealing with a moving picture encoding process<br>
itself and a lower system that transports and stores<br>
encoded information. An output generated from an encoding<br>
process is VCL data and is mapped by NAL unit prior to<br>
transport or storage. Each NAL unit includes compressed<br>
video data or RBSP (raw byte sequence payload: result data<br>
of moving picture compression) that is the data<br>
corresponding to header information.<br><br>
The NAL unit basically includes two parts, a NAL<br>
header and an RBSP. The NAL header includes flag<br>
information (nal_ref_idc) indicating whether a slice<br>
becoming a reference picture of the NAL unit is included<br>
and information (nal_unit_type) indicating a type of the<br>
NAL unit. Compressed original data is stored in the RBSP.<br>
And, RBSP trailing bit is added to a last portion of the<br>
RBSP to represent a length of the RBSP as an 8-bit<br>
multiplication. As the type of the NAL unit, there is IDR<br>
(instantaneous decoding refresh) picture, SPS (sequence<br>
parameter set) , PPS (picture parameter set), SEI<br>
(supplemental enhancement information), or the like.<br>
So, if the information (nal_unit_type) indicating the<br>
type of the NAL unit indicates a scalable video coded slice,<br>
coding efficiency can be raised by adding various<br>
configuration informations relevant to the scalable coding.<br>
For instance, it is able to add flag information indicating<br>
whether a current access unit is an instantaneous decoding<br>
refresh (hereinafter abbreviated IDR) access unit,<br>
dependency identification information indicating spatial<br>
scalability, quality identification information, flag<br>
information (no_inter_layer_pred_flag) indicating whether<br>
inter-layer prediction is used, priority identification<br>
information, and the like. This will be explained in detail<br><br>
with reference to FIG. 2 later.<br>
In the standardization, requirements for various<br>
profiles and levels are set to enable implementation of a<br>
target product with an appropriate cost. In this case, a<br>
decoder should meet the requirements decided according to<br>
the corresponding profile and level. Thus, two concepts,<br>
'profile' and 'level' are defined to indicate a function or<br>
parameter for representing how far the decoder can cope<br>
with a range of a compressed sequence. And, a profile<br>
identifier (profile_idc) can identify that a bit stream is<br>
based on a prescribed profile. The profile identifier means<br>
a flag indicating a profile on which a bit stream is based.<br>
For instance, in H.264/AVC, if a profile identifier is 66,<br>
it means that a bit stream is based on a baseline profile.<br>
If a profile identifier is 77, it means that a bit stream<br>
is based on a main profile. If a profile identifier is 88,<br>
it means that a bit stream is based on an extended profile.<br>
Moreover, the profile identifier can be included in a<br>
sequence parameter set.<br>
So, in order to handle a scalable sequence, it needs<br>
to be identified whether an inputted bit stream is a<br>
profile for a scalable sequence. If the inputted bit stream<br>
is identified as a profile for a scalable sequence, it is<br>
necessary to add a syntax to enable at least one additional<br><br>
information for a scalable sequence to be transmitted. In<br>
this case, the profile for the scalable sequence, which is<br>
an additional scheme of H.264/AVC, indicates a profile mode<br>
for handling scalable video. Since SVC is an additional<br>
scheme to conventional AVC, it may be more efficient to add<br>
a syntax as additional information for an SVC mode rather<br>
than add an unconditional syntax. For instance, when a<br>
profile identifier of AVC indicates a profile for a<br>
scalable sequence, if information on a scalable sequence is<br>
added, it is able to raise coding efficiency.<br>
Various embodiments to provide an efficient video<br>
signal decoding method are explained as follows.<br>
FIG. 1 is a schematic block diagram of a scalable<br>
video coding system according to the present invention.<br>
In order to provide a sequence optimized for various<br>
communication environments and various terminals, a<br>
sequence provided to a terminal should be diversified. If a<br>
sequence optimized for each terminal is provided to the<br>
corresponding terminal, it means that a single sequence<br>
source is prepared for a combination value of various<br>
parameters including the number of transmission frames per<br>
a second, resolution, the number of bits per a pixel, and<br>
the like. So, the provision of the optimized sequence<br>
imposes a burden on a contents provider. Therefore, a<br><br>
contents provider encodes an original sequence into a<br>
compressed sequence data of high bit rate. In case of<br>
receiving a sequence request made by a terminal, the<br>
contents provider decodes the original sequence, encodes it<br>
into a sequence data suitable for a sequence processing<br>
capability of the terminal, and then provides the encoded<br>
data to the terminal. Since this transcoding is accompanied<br>
with the encoding-decoding-encoding process, it is unable<br>
to avoid a time delay generated in the course of providing<br>
a sequence. So, a complicated hardware device and algorithm<br>
are additionally required.<br>
On the other hand, scalable video coding (SVC) is a<br>
coding scheme for encoding a video signal with a best image<br>
quality to enable a partial sequence of a generated picture<br>
sequence to be represented as a sequence by being decoded.<br>
In this case, the partial sequence may mean a sequence<br>
consisting of frames intermittently selected from a whole<br>
sequence. For a picture sequence encoded by SVC, a sequence<br>
size can be reduced for a low bit rate using spatial<br>
scalability. And an image quality of sequence can be<br>
lowered using quality scalability as well. In this case, a<br>
picture sequence having a small-size screen and/or a low<br>
frame number per second can be called a base layer and a<br>
sequence having a relatively large-size screen and/or a<br><br>
relatively high frame number per second can be called an<br>
enhanced or enhancement layer.<br>
A picture sequence encoded by the above-mentioned<br>
scalable scheme enables a sequence representation of a low<br>
image quality in a manner of receiving and processing the<br>
partial sequence only. Yet, if a bit rate gets lowered, an<br>
image equality is considerably degraded. To solve a problem<br>
of the degraded image quality, it is able to provide a<br>
separate auxiliary picture sequence for a low bit rate,<br>
e.g., a picture sequence having a small-size screen and/or<br>
a low frame number per second. Such an auxiliary sequence<br>
can be called a base layer and a main picture sequence can<br>
be called an enhanced or enhancement layer.<br>
In describing various embodiments for inter-layer<br>
prediction, the present disclosure uses the concept<br>
including a first layer and a second layer. For instance,<br>
the second layer can have a spatial resolution or screen<br>
ratio different from that of the first layer. And, the<br>
second layer can have an image quality different from that<br>
of the first layer. For detailed instance, the first layer<br>
can be a base layer and the second layer can be an enhanced<br>
layer. In performing inter-layer prediction, the first<br>
layer can be a reference layer and the second layer can be<br>
a current layer. The base and enhanced layers explained in<br><br>
the following description are just exemplary, which does<br>
not put restriction on the interpretation of the present<br>
invention.<br>
The scalable video coding system is explained in<br>
detail as follows. First of all, the scalable coding system<br>
includes an encoder 102 and a decoder 110. The encoder 102<br>
includes a base layer encoding unit 104, an enhanced layer<br>
encoding unit 106, and a multiplexing unit 108. And, the<br>
decoder can include a demultiplexing unit 112, a base layer<br>
decoding unit 114, and an enhanced layer decoding unit 116.<br>
The base layer' encoding unit 104 is capable of generating a<br>
base bit stream by compressing an inputted sequence signal<br>
X (n) . The enhanced layer encoding unit 106 is capable of<br>
generating an enhanced layer bit stream using the inputted<br>
sequence signal X(n) and information generated by the base<br>
layer encoding unit 104. And, the multiplexing unit 108 is<br>
capable of generating a scalable bit stream using the base<br>
layer bit stream and the enhanced layer bit stream.<br>
The generated scalable bit stream is transported to<br>
the decoder 110 via a certain channel. The transported<br>
scalable bit stream can be discriminated into an enhanced<br>
layer bit stream and a base layer bit stream by the<br>
demultiplexing unit 112 of the decoder 110. The base layer<br>
decoding unit 114 receives the base layer bit stream and<br><br>
then decodes the base layer bit stream into a sequence<br>
signal of intra-macroblock and residual and motion<br>
information of inter-block. In this case, the corresponding<br>
decoding can be carried out based on single loop decoding<br>
method.<br>
The enhanced layer decoding unit 116 receives the<br>
enhanced layer bit stream, and decodes an output sequence<br>
signal Xe(n) with reference to a base layer bit stream<br>
reconstructed by the base layer decoding unit 114. In this<br>
case, the output sequence signal Xb(n) will be a sequence<br>
signal having an image quality or resolution lower than<br>
that of the latter output sequence signal Xe(n).<br>
Thus, each of the enhanced layer encoding unit 10 6<br>
and the enhanced layer decoding unit 116 performs coding<br>
using inter-layer prediction. The inter-layer prediction<br>
may mean that a sequence signal of an enhanced layer is<br>
predicted by using motion information and/or texture<br>
information of a base layer. In this case, the texture<br>
information may mean a image data or a pixel value<br>
belonging to a macroblock. For instance, in the inter-layer<br>
prediction method, there are an intra base prediction mode<br>
or a residual prediction mode. The intra base prediction<br>
mode may mean a mode for predicting a block of the enhanced<br>
layer based on a corresponding area in the base layer. In<br><br>
this case, the corresponding area in the base layer may<br>
mean an area coded in an intra mode. Meanwhile, the<br>
residual prediction mode can use a corresponding area,<br>
having residual data that is an image difference value, in<br>
the base layer. In both case, the corresponding area in the<br>
base layer can be enlarged or reduced to use by sampling.<br>
The sampling may mean that image resolution is varied. And,<br>
the sampling can include resampling, downsampling,<br>
upsampling, and the like. For instance, it is able to<br>
resample intra samples to perform inter-layer prediction.<br>
And, image resolution can be reduced by regenerating pixel<br>
data using a downsampling filter. This can be called<br>
downsampling. Moreover, several additional pixel data can<br>
be made using an upsampling filter to increase image<br>
resolution. This can be called upsampling. The resampling<br>
can include both concepts of the downsampling and the<br>
upsampling. In the present disclosure, the terminology<br>
'sampling' can be properly interpreted in accordance with a<br>
technical idea and scope of a corresponding embodiment of<br>
the present invention.<br>
Meanwhile, a base layer and an enhanced layer are<br>
generated for different usages or purposes for the same<br>
sequence contents and may differ from each other in spatial<br>
resolution, frame rate, bit rate, and the like. In coding a<br><br>
video signal by inter-layer prediction,, a non-dyadic case,<br>
a ratio of an enhanced layer to a base layer in spatial<br>
resolution is not an integer of 2, can be called extended<br>
spatial scalability (ESS) . For instance, when an enhanced<br>
layer is coded by inter-layer prediction for a video signal<br>
having a ratio of 16:9 (horizontal:vertical), a case in<br>
which a base layer is coded into an image having a ratio of<br>
4:3 may occur. In this case, since the base layer is coded<br>
in a cropping state that an original video signal is<br>
cropped in part, it is unable to cover a full area of an<br>
enhanced layer even if the base layer is enlarged for the<br>
inter-layer prediction. So, since the partial area of the<br>
enhanced layer fails to have a corresponding area in the<br>
upsampled base layer, the partial area may not use the<br>
upsampled base layer for inter-layer prediction. Namely, it<br>
means that the inter-layer prediction is not applicable to<br>
the partial area. In this case, coding informations used<br>
for the inter-layer prediction may not be transported.<br>
Detailed embodiments for this will be explained in detail<br>
with reference to FIGs. 5 to 8.<br>
FIG. 2 and FIG. 3 are structural diagrams for<br>
configuration information on a scalable sequence addible to<br>
a scalable-video-coded bit stream and pictures for<br>
describing the configuration information according to one<br><br>
embodiment of the present invention, respectively;<br>
FIG. 2 shows an example of a configuration of NAL<br>
unit enabling configuration informations on a scalable<br>
sequence to be added thereto. First of all, the NAL unit<br>
can mainly include a NAL unit header and an RBSP (raw byte<br>
sequence payload: result data of moving picture<br>
compression) . The NAL unit header can include<br>
identification information (nal_ref_idc) indicating whether<br>
the NAL unit includes a slice of a reference picture and<br>
information (nal_unit_type) indicating a type of the NAL<br>
unit. And, an extension area of the NAL-unit header can be<br>
limitedly included. For instance, if the information<br>
indicating the type of the NAL unit is associated with<br>
scalable video coding or indicates a prefix NAL unit, the<br>
NAL unit is able to include an extension area of the NAL<br>
unit header. In particular, if the nal__unit_type = 20 or 14,<br>
the NAL unit is able to include the extension area of the<br>
NAL unit header. And, configuration informations for a<br>
scalable sequence can be added to the extension area of the<br>
NAL unit header according to flag information<br>
(svc_mvc_flag) capable of identifying whether it is SVC bit<br>
stream.<br>
For another instance, if the information indicating<br>
the type of the NAL unit is information indicating a subset<br><br>
sequence parameter set, the RBSP can include information on<br>
the subset sequence parameter set. In particular, if<br>
nal_unit_type = 15, the RBSP can include information on a<br>
subset sequence parameter set, information on a slice layer,<br>
and the like. In this case, the subset sequence parameter<br>
set can include an extension area of the sequence parameter<br>
set according to profile information. For example, if<br>
profile information (profile_idc) is a profile relevant to<br>
scalable video coding, the subset sequence parameter set<br>
can include an extension area of the sequence parameter set.<br>
Alternatively, a sequence parameter set can include an<br>
extension area of a sequence parameter set according to<br>
profile information. The extension area of the sequence<br>
parameter set can include information for controlling<br>
characteristics of a deblocking filter for inter-layer<br>
prediction, parameters associated with information for an<br>
upsampling process, and the like. Various configuration<br>
informations on a scalable sequence, e.g., configuration<br>
informations that can be included in an extension area of<br>
NAL unit header, an extension area of a sequence parameter<br>
set, and a slice layer, are explained in detail as follows.<br>
First of all, it is possible to obtain flag<br>
information(inter_layer_deblocking_filter_control_present_f<br>
lag) indicating whether there exists the information for<br><br>
controlling the characteristics of the deblocking filter<br>
for inter-layer prediction from the extension area of the<br>
sequence parameter set. And, it is possible to obtain<br>
information (extended_spatial_scalability) indicating a<br>
position of the parameter associated information for the<br>
upsampling process from the extension area of the sequence<br>
parameter set. In particular, for example, if<br>
extended_spatial_scalability = 0, it can mean that any<br>
parameter for the upsampling process does not exist in a<br>
sequence parameter set or a slice header. If<br>
extended_spatial_scalability = 1, it can mean that a<br>
parameter for the upsampling process exists in a sequence<br>
parameter set. If extended_spatial_scalability =2, it can<br>
mean that a parameter for the upsampling process exists in<br>
a slice header.<br>
Information © indicating whether inter-layer<br>
prediction is used may mean flag information indicating<br>
whether inter-layer prediction is used in decoding a coded<br>
slice. The flag information can be obtained from an<br>
extension area of a NAL header. For instance, if the flag<br>
information is set to 1, it may mean that the inter-layer<br>
prediction is not used. If the flag information is set to 0,<br>
the inter-layer prediction can be used or not in accordance<br>
with a coding scheme in a macroblock. This is because the<br><br>
inter-layer prediction in a macroblock unit may be used or<br>
not.<br>
Quality identification information ® means<br>
information identifying a quality for a NAL unit. In<br>
describing the configuration information, FIG. 3 is<br>
referred to. For instance, a single picture can be coded<br>
into layers differing from each other in quality. In FIG. 3,<br>
layers in Spa_Layer0 and Spa_Layerl can be coded into<br>
layers differing from each other in quality. In particular,<br>
assuming that information identifying a quality for the NAL<br>
unit is named quality_id, layers Bl, B2, ..., BIO can be set<br>
to quality_id=0. And, layers Ql, Q2, ..., Q10 can be set to<br>
quality_id=l. Namely, the layers Bl, B2, ..., B10 may mean<br>
the layers having the lowest image quality. These are<br>
called base pictures. The layers Ql, Q2, ..., Q10 correspond<br>
to layers including the layers Bl, B2, ..., B10 and have<br>
image qualities better than those of the layers Bl, B2, ...,<br>
B10. And, the quality identification information can be<br>
defined in various ways. For instance, the quality<br>
identification information can be represented as 16 steps.<br>
Identification information indicating spatial<br>
scalability means information identifying dependency on NAL<br>
unit. In describing the configuration information, FIG. 3<br>
is referred to. For instance, the dependency may vary in<br><br>
accordance with spatial resolution. In FIG. 3, layers in<br>
Spa_Layer0 and Spa_Layerl can have the same resolution.<br>
Layers in Spa_Layer0 can include pictures obtained by<br>
performing downsampling on layers in Spa_Layerl. In<br>
particular, for example, assuming that information<br>
identifying dependency on NAL unit is represented as<br>
dependency_id, layers in Spa_Layer0 may have the relation<br>
of dependency_id=0. And, layers in Spa_Layerl may have the<br>
relation of dependency_id=l. The dependency identification<br>
information can be defined in various ways. Thus, NAL units<br>
having the same value as the information identifying the<br>
dependency can be represented as dependency representation.<br>
Meanwhile, a single layer can be defined in<br>
accordance with the information identifying the dependency<br>
and the quality identification information. In this case,<br>
NAL units having the same values as the information<br>
identifying the dependency and the quality identification<br>
information can be represented as layer representation.<br>
Identification information indicating temporal<br>
scalability means information identifying a temporal level<br>
for NAL unit. The temporal level can be described in a<br>
hierarchical B picture structure. For instance, a layer (Bl,<br>
Ql) and a layer (B3, Q3) in Spa_Layer0 can have an<br>
identical temporal level Tem_Layer0. If a layer (B5, Q5)<br><br>
refers to a layer (Bl, Ql) and a layer (B3, Q3) , the layer<br>
(B5, Q5) can have a temporal level Tem_Layerl higher than a<br>
temporal level Tem_LayerO of the layer (Bl, Ql) and the<br>
layer (B3, Q3) . Likewise, if a layer (B7, Q7) refers to a<br>
layer (Bl, Ql) and a layer (B5, Q5), the layer (B7, Q7) can<br>
have a temporal level Tem_Layer2 higher than a temporal<br>
level Tem_Layerl of the layer (B5, Q5) . All the NAL units<br>
within a single access unit can have an identical temporal<br>
level value. In case of an IDR access unit, the temporal<br>
level value may become 0.<br>
Flag information indicating whether a reference base<br>
picture is used as a reference picture indicates whether<br>
reference base pictures are used as reference pictures in<br>
an inter-layer prediction process or decoded pictures are<br>
used as reference pictures in the inter-layer prediction<br>
process. The flag information can have the same value for<br>
NAL units in a same layer, i.e., for NAL units having the<br>
same information identifying dependency.<br>
Priority identification information means information<br>
identifying a priority of NAL unit. It is possible to<br>
provide inter-layer extensibility or inter-picture<br>
extensibility using the priority identification information.<br>
For instance, it is possible to provide a user with<br>
sequences at various temporal and spatial levels using the<br><br>
priority identification information. So, the user is able<br>
to view a sequence in specific time and space or a sequence<br>
in accordance with a different restriction condition only.<br>
The priority information can be configured in various ways<br>
in accordance with its reference condition. The priority<br>
information can be randomly configured without being based<br>
on a special reference. And, the priority information can<br>
be determined by a decoder.<br>
And, configuration information in an extension area<br>
of NAL unit header can include flag information indicating<br>
whether a current access unit is an IDR'access unit.<br>
Various information for inter-layer prediction can be<br>
included in a slice layer. For instance, information ©<br>
indicating a handling of a slice boundary in an upsampling<br>
process, information © associated with an operation of a<br>
deblocking filter, information © related to a phase shift<br>
of a chroma signal, offset information © indicating a<br>
position difference between layers, and information <br>
indicating a presence or non-presence of an execution of<br>
adaptive prediction, and the like can be included. The<br>
above information can be obtained from a slice header.<br>
As examples of the information ® associated with the<br>
operation of the deblocking filter, there may be<br>
information (disable_deblocking_filter_idc) indicating an<br><br>
operational method of the deblocking filter, offset<br>
information (inter_layer_slice_alpha_c0_offset_div2,<br>
inter_layer_ slice_beta_offset_div2) necessary for a<br>
deblocking filtering execution, and the like.<br>
As examples of the information © on the phase shift<br>
of the chroma signal, there may be informations<br>
(scaled_ref_layer_left_offset, scaled_ref_layer_top_offset,<br>
scaled_ref_layer_right_offset,<br>
scaled_ref_layer_bottom_offset) on horizontal and vertical<br>
phase shifts of a chroma component of a picture used for<br>
inter-layer prediction.<br>
As examples of the offset information ® indicating<br>
the position difference between layers, there may be offset<br>
informations	(scaled_ref_layer_left_offset,<br>
scaled_ref_layer_top_offset, scaled_ref_layer_right_offset,<br>
scaled_ref_layer_bottom_offset) indicating top, bottom,<br>
left and right position differences between an upsampled<br>
picture used for inter-layer prediction and a current<br>
picture.<br>
As an example of the information © indicating the<br>
handling of a macroblock located on slice boundary in the<br>
base layer upsampling process, there may be information<br>
(constrained_intra_resampling_flag) indicating whether a<br>
current macroblock can not be predicted by using<br><br>
corresponding intra-coded block in the first layer in case<br>
that a corresponding intra-coded block in the first layer<br>
exists over at least two slices in the second layer.<br>
And, the information ® indicating a presence or non-<br>
presence of the execution of the adaptive prediction is<br>
capable of indicating a presence or non-presence of<br>
prediction associated information within a slice header and<br>
a macroblock layer. In accordance with the information<br>
indicating the presence or non-presence of the execution of<br>
the adaptive prediction, it is able to decide what kind of<br>
an adaptive prediction method will be used. This will be<br>
explained in detail with reference to FIG. 8 later.<br>
FIG. 4 is a diagram for a cropping relation between a<br>
sampled base layer and an enhanced layer.<br>
In scalable video coding, it is possible to check<br>
whether a current block of an enhanced layer can use inter-<br>
layer prediction. For instance, it is possible to check<br>
whether an area corresponding to all pixels within a<br>
current block exists In a base layer. As a result of the<br>
checking process, if the current block of the enhanced<br>
layer is not used for inter-layer prediction, it is<br>
unnecessary to transport coding information used for inter-<br>
layer prediction. Hence, it is able to raise a coding<br>
efficiency.<br><br>
Thus, it is able to define a function capable of<br>
checking whether a current block of an enhanced layer can<br>
use inter-layer prediction. For instance, a function<br>
'in_crop_window()' can be defined as a function for<br>
checking whether an area corresponding to all pixels within<br>
a current block exists in a base layer. Assuming that a<br>
macroblock index in a horizontal direction on an enhance<br>
layer is set to ^mbldxX' and a macroblock index in a<br>
vertical direction is set to 'mbldxY', if the following<br>
conditions are met, the function in_crop_window() can<br>
return a value 'TRUE (or 'l')'.<br>
mbldxX ≥ (ScaledBaseLeftOffset +15) / 16<br>
mbldxX ≤ (ScaledBaseLeftOffset + ScaledBaseWidth - 1)<br>
/ 16<br>
mbldxY ≥ (ScaledBaseTopOffset + 15) / 16<br>
mbldxY ≤ (ScaledBaseTopOffset + ScaledBaseHeight - 1)<br>
/ 16<br>
The 'mbldxX' can be derived using a macroblock<br>
address and the number of macroblocks in the horizontal<br>
direction. The 'mbldxY' can be derived by a method<br>
differing according to whether application of macroblock<br>
adaptive frame-field is applied or not. For instance, if<br>
the macroblock adaptive frame-field is applied, it can be<br>
derived by considering a macroblock pair. In considering<br><br>
the macroblock pair, it is assumed that an index of a top<br>
macroblock is set to 'mbIdxYO' and that an index of a<br>
bottom macroblock is set to 'mbldxYl'. The 'mbIdxYO' can be<br>
derived from offset information indicating a top position<br>
difference between an upsampled picture used for inter-<br>
layer prediction and a current picture and macroblock<br>
number information in a horizontal direction. In this case,<br>
a value of the horizontal macroblock number information may<br>
differ in accordance with whether a current picture is a<br>
frame picture or a field picture. The 'mbIdxYl' can be<br>
derived from offset information indicating a top position<br>
difference between an upsampled picture used for inter-<br>
layer prediction and a current picture and macroblock<br>
number information in a vertical direction. Meanwhile, if<br>
the macroblock adaptive frame-field is not applied, the<br>
'mbIdxYO' and the 'mbldxYl' can be set to the same value.<br>
The 'ScaledBaseLeftOffset' indicates offset<br>
information indicating a left position difference between<br>
an upsampled picture used for inter-layer prediction and a<br>
current picture. The 'ScaledBaseTopOffset' indicates offset<br>
information indicating a top position difference between an<br>
upsampled picture used for inter-layer prediction and a<br>
current picture. The 'ScaledBaseWidth' indicates a<br>
horizontal width of an upsampled picture. And, the<br><br>
'ScaledBaseHeight' indicates a vertical height of an<br>
upsampled picture.<br>
If any one of the above conditions is not satisfied,<br>
the function in_crop_window{) can return a value of 'FALSE<br>
(or '0')'.<br>
In case that a pixel corresponding to at least one<br>
pixel within a current block (CurrMbAddr) is not in an<br>
upsampled base layer, i.e., in case that the function<br>
in_crop_window(CurrMbAddr) returns the value of 'FALSE',<br>
information associated with inter-layer prediction is not<br>
used for the current block and this information may not be<br>
transported. Hence, according to the embodiment of the<br>
present invention, if it is identified that the<br>
correspondeing base layer area does not exist via the<br>
in_crop_window (CurrMbAddr) , it is able to omit the<br>
transport of the information associated with the inter-<br>
layer prediction for the current block.<br>
According to one embodiment of the present invention,<br>
a case of performing coding by using the function<br>
in_crop_window() is explained as follows.<br>
First of all, in case that it is identified that an<br>
area corresponding to a current block exists in a base<br>
layer via 'in_crop__window (CurrMbAddr)', the enhanced layer<br>
encoding unit 106 performs inter-layer prediction using<br><br>
texture and/or motion information of the base layer. In<br>
this case, the motion information can include reference<br>
index information, motion vector information, partition<br>
information, etc.<br>
In case that texture and/or motion information of the<br>
current block is set to the texture and/or motion<br>
information of the corresponding block or in case that<br>
texture and/or motion information of the current block is<br>
derived from the texture and/or motion information of the<br>
corresponding block, the enhanced layer encoding unit 106<br>
adds instruction information instructing the intact or<br>
derived information to a data stream of an enhanced layer,<br>
and then informs the decoder 110 of the addition. But, in<br>
case that it is identified that an area corresponding to a<br>
current block does not exist in a base layer via<br>
'in_crop_window(CurrMbAddr)', the enhanced layer encoding<br>
unit 106 is able to generate an enhanced layer without<br>
performing inter-layer prediction. Meanwhile, if the<br>
decoder 110 confirms that an area corresponding to a<br>
current block does not exist in a base layer via<br>
'in_crop_window(CurrMbAddr)', the decoder 110 decides that<br>
the instruction information has not been transmitted.<br>
FIG. 5 and FIG. 6 are diagrams for syntaxes relevant<br>
to macroblock and sub-macroblock predictions through inter-<br><br>
layer prediction according to one embodiment of the present<br>
invention, respectively.<br>
In case of performing inter-layer prediction,<br>
information associated with inter-layer prediction in slice<br>
data of a current NAL is transported to a decoder. For<br>
instance, in case of motion vector prediction of a current<br>
block of an enhanced layer, a flag<br>
(motion_prediction_flag_lx) indicating whether to use a<br>
motion vector of a base layer can be obtained from a<br>
macroblock layer. According to an embodiment of the present<br>
invention, the decoder is able to know 'whether the<br>
information associated with inter-layer prediction is<br>
transported by an encoder in a manner of checking<br>
'in_crop_window(CurrMbAddr)' [510, 610]. For instance, if<br>
an area corresponding to a current block does not exist in<br>
a base layer in accordance with the<br>
'in_crop_window(CurrMbAddr)',	the	flag<br>
'motion_prediction_flag_10/ll' may not be transported on a<br>
bit stream [520/530, 620/630].<br>
And, a flag 'adaptive_motion_prediction_flag'<br>
indicating whether information associated with motion<br>
vector prediction is present within a macroblock layer can<br>
be obtained from slice data of a current NAL. According to<br>
an embodiment of the present invention, information<br><br>
associated with inter-layer prediction may not be<br>
transported by the encoder in a manner of checking both of<br>
the 'adaptive_motion_prediction_flag' and the<br>
'in_crop_window(CurrMbAddr) ' [510]. For instance, if an<br>
area corresponding to a current block does not exist in a<br>
base layer in accordance with the<br>
'in_crop_window(CurrMbAddr)' or if information associated<br>
with motion vector prediction does not exist within a<br>
macroblock in accordance with the<br>
'adaptive_motion_prediction_flag',	the flag<br>
'motion_predidtion_flag_10/ll' may not be transported<br>
[520/530, 620/630]. The above-described technical idea is<br>
identically applicable to sub-macroblock prediction shown<br>
in FIG. 6.<br>
Thus, only if both of the two kinds of conditions are<br>
satisfied after identification of the two kinds of<br>
informations, the information associated with inter-layer<br>
prediction is transported. Hence, a coding efficiency can<br>
be raised.<br>
FIG. 7 is a diagram of a syntax relevant to residual<br>
prediction through inter-layer prediction according to one<br>
embodiment of the present invention.<br>
In case of performing inter-layer prediction,<br>
information associated with inter-layer prediction in slice<br><br>
data of a current NAL is transported to a decoder. For<br>
instance, in case of predicting a residual signal of a<br>
current block, a flag 'residual_prediction_flag' indicating<br>
whether to use a residual signal of a base layer can be<br>
obtained from a macroblock layer [740] .. In this case, the<br>
base layer can be known using layer representation<br>
information. According to an embodiment of the present<br>
invention, information associated with inter-layer<br>
prediction may not be transported by an encoder in a manner<br>
of confirming the 'in_crop_window(CurrMbAddr)'.<br>
For instance, the 'residual_prediction_flag' can be<br>
obtained in accordance with information<br>
'adaptive_residual_prediction_flag' indicating a presence<br>
of information associated with prediction of a residual<br>
signal within a macroblock and information of a slice type<br>
of current block [710]. The 'residual_prediction_flag' also<br>
can be obtained according to 'base_mode_flag'. The<br>
'base_mode_flag' indicates that whether a type (mb_type) of<br>
a current macroblock is deri-ved from a corresponding area<br>
of a base layer [720]. The 'residual_prediction_flag' also<br>
can be obtained according to a type of the current<br>
macroblock and the function in_crop_window(CurrMbAddr). For<br>
example, The 'residual_prediction_flag' can be obtained<br>
when a type of macroblock and sub-macroblock is not intra<br><br>
mode [MbPartPredType(mb_type, 0) != Intra_16xl6(8x8 and<br>
4x4)] and the value of in_crop_window(CurrMbAddr) is 'true',<br>
which means that an area corresponding to a current<br>
macroblock exists in a base layer [730]. If the type of the<br>
current macroblock is not the intra mode or the area<br>
corresponding to a current macroblock do not exist in the<br>
base layer [in_crop_window(CurrMbAddr) = 0], the residual<br>
prediction is not performed. And, the encoder 102 generates<br>
an enhanced layer while the 'residual_prediction_flag' is<br>
not included.<br>
If the 'residual_prediction_flag' is set to '1', a<br>
residual signal of a current block is predicted from a<br>
residual signal of the base layer. If the<br>
'residual_prediction_flag' is set to '0', a residual signal<br>
is encoded without a inter-layer prediction. If the<br>
'residual_prediction_flag' does not exist in macroblock<br>
layer, it can be derived as follows. For instance, only if<br>
the following conditions are entirely satisfied, the<br>
'residual_prediction_flag' can be derived into a preset<br>
value (default_residual_prediction_flag). First of all,<br>
'base_mode_flag' should be set to '1' or a type of a<br>
current macroblock should not be an intra mode. Secondly,<br>
'in_crop_window(CurrMbAddr)' should be set to '1'. Thirdly,<br>
a flag 'no_inter_layer_pred_flag' indicating whether inter-<br><br>
layer prediction is used should be set to '0'. Fourthly, a<br>
slice type should not be an El slice. Otherwise, it can be<br>
derived into '0'.<br>
When an area corresponding to a current sequence<br>
block does not exist in a base layer via<br>
'in_crop_window(CurrMbAddr) ' , the enhanced layer decoding<br>
unit 116 decides that motion prediction flag<br>
(motion_prediction_flag) information does not exist in a<br>
macroblock or a sub-macroblock and reconstructs a video<br>
signal using a data bit stream of an enhanced layer only<br>
without inter-layer prediction. If a syntax element for the<br>
residual prediction is not included in a data bit stream of<br>
an enhanced layer, the enhanced layer decoding unit 116 is<br>
able to derive a residual prediction flag<br>
'residual_prediction_flag' . In doing so, it is able to<br>
consider whether an area corresponding to a current block<br>
exists in a base layer via 'in_crop_window(CurrMbAddr)' . If<br>
the 'in_crop_window(CurrMbAddr)' is set to '0', the<br>
enhanced layer decoding unit 116 can confirm that the area<br>
corresponding to the current sequence block does not exist<br>
in the base layer. In this case, the<br>
'residual_prediction_flag' is derived into '0' and then is<br>
able to reconstruct a video signal using data of an<br>
enhanced layer only without residual prediction using a<br><br>
residual signal of the base layer.<br>
FIG. 8 is a diagram of a syntax for obtaining<br>
adaptive prediction information in accordance with a<br>
presence or non-presence of inter-layer prediction<br>
execution according to one embodiment of the present<br>
invention.<br>
According to an embodiment of the present invention,<br>
in a manner of confirming configuration information of the<br>
scalable-video-coded bit stream, information associated<br>
with inter-layer prediction may not be transported by an<br>
encoder. The configuration information 'of the scalable-<br>
video-coded bit stream can be obtained from an extension<br>
area of a NAL header. For instance, adaptive prediction<br>
information can be obtained based on information<br>
'no_inter_layer_pred_flag' indicating whether inter-layer<br>
prediction is used [810]. The adaptive prediction<br>
information can indicate whether a syntax associated with<br>
prediction exists in a corresponding position. For instance,<br>
there may exist information 'adaptive_prediction_flag'<br>
indicating whether a syntax associated with prediction<br>
exists in a slice header and a macroblock layer,<br>
information 'adaptive_motion_prediction_flag' indicating<br>
whether a syntax associated with motion prediction exists<br>
in a macroblock layer, information<br><br>
'adaptive_residual_prediction_flag' indicating whether a<br>
syntax associated with residual prediction exists in a<br>
macroblock layer, and the like.<br>
In case that inter-layer prediction is carried out in<br>
accordance with the information indicating whether the<br>
inter-layer prediction is used, a flag information<br>
Aslice_skip_flag' indicating a presence or non-presence of<br>
slice data can be firstly obtained [820]. By confirming the<br>
information indicating the presence of the slice data, it<br>
is able to decide whether to derive informations within a<br>
macroblock to perform inter-layer prediction. In accordance<br>
with the information indicating the presence of the slice<br>
data, if the slice data exists within the slice [830], it<br>
is able to obtain an adaptive prediction flag<br>
'adaptive_prediction_flag' [840] . And, it is also able to<br>
obtain information 'adaptive_residual_prediction_flag'<br>
indicating whether a syntax associated with residual<br>
prediction exists in a macroblock layer [880]. In<br>
accordance with the adaptive prediction flag, it is able to<br>
obtain information 'default_base__mode_flag' indicating how<br>
to derive information that indicates whether to predict<br>
motion information and the like from a correspondent block<br>
of the base layer [850] . In case that the motion<br>
information and the like are not predicted from a<br><br>
correspondent block of the base layer [855], it is able to<br>
obtain information 'adaptive_motion_prediction_flag'<br>
indicating whether a syntax associated with motion<br>
prediction exists in the macroblock layer [860]. If the<br>
syntax associated with motion prediction does not exist in<br>
the macroblock layer [865] , it is able to obtain<br>
information Mefault_motion_prediction_flag' indicating how<br>
to infer motion prediction flag information [870].<br>
The information 'adapt ive_rnot.ion_prediction_f lag'<br>
indicating whether the syntax associated with motion<br>
prediction exists in the macroblock layer and ' the<br>
information 'adaptive_residual_prediction_flag' indicating<br>
whether the syntax associated with residual prediction<br>
exists in the macroblock layer are usable within the<br>
macroblock layer. For instance, it is able to obtain a flag<br>
'motion_prediction_flag_lx' indicating whether to use a<br>
motion vector of the base layer based on the<br>
'adaptive_motion_prediction_flag' . And, it is able to<br>
obtain a flag 'residual_prediction__flag' indicating whether<br>
to use a residual signal of the base layer based on the<br>
'adaptive_residual_prediction_flag' .<br>
As mentioned in the foregoing description, the<br>
decoder/encoder, to which the present invention is<br>
applicable, is provided to a broadcast transmitter/receiver<br><br>
for multimedia broadcasting such as DMB (digital multimedia<br>
broadcasting) to be used in decoding video signal, data<br>
signals, etc. And, the multimedia broadcast<br>
transmitter/receiver can include a mobile communication<br>
terminal.<br>
A decoding/encoding method, to which the present<br>
invention is applied, is configured with a program for<br>
computer execution and then stored in a computer-readable<br>
recording medium. And, multimedia data having a data<br>
structure of the present invention can be stored in<br>
computer-readable recording medium. The computer-readable<br>
recording media include all kinds of storage devices for<br>
storing data that can be read by a computer system. The<br>
computer-readable recording media include ROM, RAM, CD-ROM,<br>
magnetic tapes, floppy discs, optical data storage devices,<br>
etc. and also includes a device implemented with carrier<br>
waves (e.g., transmission via internet). And, a bit stream<br>
generated by the encoding method is stored in a computer-<br>
readable recording medium or transmitted via wire/wireless<br>
communication network.<br>
INDUSTRIAL APPLICABILITY<br>
Accordingly, while the present invention has been<br>
described and illustrated herein with reference to the<br><br>
preferred embodiments thereof, it will be apparent to those<br>
skilled in the art that various modifications and<br>
variations can be made therein without departing from the<br>
spirit and scope of the invention. Thus, it is intended<br>
that the present invention covers the modifications and<br>
variations of this invention that come within the scope of<br>
the appended claims and their equivalents.<br><br>
WHAT IS CLAIMED IS:<br>
1.	A method of decoding a current layer using<br>
inter-layer prediction, comprising:<br>
determining whether a position of a current block is<br>
included in a sampled reference layer, the current block<br>
included in the current layer;<br>
obtaining a plurality of prediction flags when the<br>
position of the current block is included in the sampled<br>
reference layer; and<br>
decoding the current layer using the plurality of the<br>
prediction flags.<br>
2.	The method of claim 1, wherein the current<br>
layer differs from the reference layer in a screen ratio or<br>
a spatial resolution, the reference layer being from a same<br>
video signal of the current layer,.<br>
3. The method of claim 1, wherein the determining<br>
step is based on offset information of the reference layer<br>
and a variable indicating a position of the current layer.<br>
4. The method of claim 3, wherein the determining<br>
step is based on a resolution of the reference layer.<br><br>
5.	The method of claim 1, wherein the plurality of<br>
the prediction flags include information indicating whether<br>
a type of the current block is derived from a corresponding<br>
block in the reference layer, information indicating<br>
whether to use a motion vector of the corresponding block<br>
in the reference layer when a motion vector of the current<br>
block is predicted, and information indicating whether to<br>
use a residual signal of the corresponding block in the<br>
reference layer when a residual signal of the current block<br>
is predicted.<br>
6.	The method of claim 5, wherein the plurality of<br>
the prediction flags are obtained from a macroblock layer.<br>
7.	The method of claim 5, wherein the plurality of<br>
the prediction flags are obtained as predetermined values<br>
from a slice layer.<br>
8.	A method of encoding a current layer using<br>
inter-layer prediction, comprising:<br>
determining whether a current block in the current<br>
layer is included in a sampled reference layer;<br>
generating a plurality of prediction flag required<br><br>
for the inter-layer prediction based on whether the current<br>
block is included in the sampled reference layer; and<br>
generating a bit stream of the current layer having a<br>
resolution different from that of a reference layer by<br>
encoding a video signal by using information of the<br>
reference layer.<br>
9.	The method of claim 8, wherein if the current<br>
block is not included in the sampled reference layer, the<br>
current block is encoded without using information of the<br>
reference layer.<br>
10.	The method of claim 8, wherein if the current<br>
block is included in the sampled reference layer, the<br>
plurality of prediction flags required for the inter-layer<br>
prediction is generated.<br>
11.	The method of claim 1, wherein the video signal<br>
is received as a broadcast signal.<br>
12.	The method of claim 1, wherein the video signal<br>
is received via a digital medium.<br>
13.	A computer-readable medium in which a program to execute the method of claim 1 is recorded.<br><br>
A method of decoding a current layer using inter- layer prediction is disclosed. The present invention includes determining whether a position of a current block is included in a sampled reference layer, the current block included in the current layer, obtaining a plurality of prediction flags when the position of the current block is included in the sampled reference layer, and decoding the current layer using the plurality of the prediction flags.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1QQS5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LSgxMC0wNy0yMDE0KS1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-(10-07-2014)-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWFic3RyYWN0LnBkZg==" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LUFTU0lHTk1FTlQucGRm" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-ASSIGNMENT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWNsYWltcy5wZGY=" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LUNPUlJFU1BPTkRFTkNFIDEuMi5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-CORRESPONDENCE 1.2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LUNPUlJFU1BPTkRFTkNFLTEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-CORRESPONDENCE-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWNvcnJlc3BvbmRlbmNlLnBkZg==" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-correspondence.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWRlc2NyaXB0aW9uIChjb21wbGV0ZSkucGRm" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-description (complete).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWRyYXdpbmdzLnBkZg==" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWZvcm0gMS5wZGY=" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1LT0xOUC0yMDA4LUZPUk0gMy0xLjEucGRm" target="_blank" style="word-wrap:break-word;">3235-KOLNP-2008-FORM 3-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWZvcm0gMy5wZGY=" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWZvcm0gNS5wZGY=" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWdwYS5wZGY=" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-gpa.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWludGVybmF0aW9uYWwgcHVibGljYXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LWludGVybmF0aW9uYWwgc2VhcmNoIHJlcG9ydC5wZGY=" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-international search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LXBjdCBwcmlvcml0eSBkb2N1bWVudCBub3RpZmljYXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-pct priority document notification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MzIzNS1rb2xucC0yMDA4LXNwZWNpZmljYXRpb24ucGRm" target="_blank" style="word-wrap:break-word;">3235-kolnp-2008-specification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMzIzNS1rb2xucC0yMDA4LmpwZw==" target="_blank" style="word-wrap:break-word;">abstract-3235-kolnp-2008.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="263878-substrate-provided-with-a-multilayer-having-thermal-properties.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="263880-ethanol-production-from-citrus-processing-waste.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>263879</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>3235/KOLNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>48/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>28-Nov-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>26-Nov-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>07-Aug-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>LG ELECTRONICS INC.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>20, YEOUIDO-DONG, YEONGDEUNGPO-GU SEOUL</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>JEON, BYEONG MOON</td>
											<td>306-1005 HYUNDAI APT., GWANGJANG-DONG, GWANGJIN-GU, SEOUL, 143-754</td>
										</tr>
										<tr>
											<td>2</td>
											<td>PARK, SEUNG WOOK</td>
											<td>1429-7, SILLIM-DONG, GWANAK-GU, SEOUL, 151-891</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>H04N 7/24</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/KR2007/005651</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2007-11-09</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>10-2006-0132282</td>
									<td>2006-12-22</td>
								    <td>U.S.A.</td>
								</tr>
								<tr>
									<td>2</td>
									<td>60/857802</td>
									<td>2006-11-09</td>
								    <td>U.S.A.</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/263879-method-and-apparatus-for-decoding-encoding-a-video-signal by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 04 Apr 2024 22:34:40 GMT -->
</html>
