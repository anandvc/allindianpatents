<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.allindianpatents.com/patents/263378-image-input-apparatus-and-image-input-method-for-inputting-an-image-of-an-object-within-a-living-body by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:08:08 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indian Patents. 263378:IMAGE INPUT APPARATUS AND IMAGE INPUT METHOD FOR INPUTTING AN IMAGE OF AN OBJECT WITHIN A LIVING BODY</title>
    <meta content="authenticity_token" name="csrf-param" />
<meta content="cYcP52B8zyTWKbLwby2YPh9z/gvY/RLjWOwY4YXkiXg=" name="csrf-token" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.1/html5shiv.js" type="text/javascript"></script>
    <![endif]-->

    <link href="../assets/application-e80cf34975c5b1730c80b2f7170e7d26.css" media="all" rel="stylesheet" type="text/css" />

  </head>
  <body>

    <div class="navbar navbar-fluid-top">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Indian Patents</a>
          <div class="container-fluid nav-collapse">
            <ul class="nav">
              <li><a href="../recently-granted.html">Recently Granted Patents</a></li>
              <li><a href="../recently-published.html">Recently Published Patents</a></li>
            </ul>
            <form id="gform" class="navbar-search pull-right" action="https://www.google.com/search" method="get" target="_blank" onsubmit="document.getElementById('gform').q.value='site:http://www.allindianpatents.com '+document.getElementById('gform').q.value">
                <input type="text" name="q" id="q" class="search-query" placeholder="Search" onclick="this.value=''" autocomplete="off">
            </form>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span12">

          <style>
          .allindianpatents-top { width: 320px; height: 50px; }
          @media(min-width: 500px) { .allindianpatents-top { width: 468px; height: 60px; } }
          @media(min-width: 800px) { .allindianpatents-top { width: 728px; height: 90px; } }
          </style>
          <center>
          </center>
          
          <div class="row-fluid">
	<div class="span8">

		<table class="table">
			<tr>
				<th>Title of Invention</th>
				<td><h1 style="font-size:large;">IMAGE INPUT APPARATUS AND IMAGE INPUT METHOD FOR INPUTTING AN IMAGE OF AN OBJECT WITHIN A LIVING BODY</h1></td>
			</tr>
			<tr>
				<th>Abstract</th>
				<td>An image input apparatus that inputs an image of an object residing within a living body is disclosed. The image input apparatus includes a light source that irradiates near infrared light on the living body, a lens array arranged at a position facing the living body and including plural lenses each having a face with zero or negative power arranged at a side facing the living body and a face with positive power arranged at a side facing an image surface, an imaging unit arranged at the image surface side of the lens array that forms a compound-eye image corresponding to a collection of ommatidium images formed by the lenses of the lens array, and a reconstruction unit that reconstructs a single image from the compound-eye image using a parallax between the ommatidium images. The reconstructed single image is input as the image of the object.</td>
			</tr>
		</table>

					<style>
					.allindianpatents-post-abstract { width: 320px; height: 50px; }
					@media(min-width: 880px) { .allindianpatents-post-abstract { width: 468px; height: 60px; } }
					@media(min-width: 1267px) { .allindianpatents-post-abstract { width: 728px; height: 90px; } }
					</style>
					<center>
					<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
					<!-- AllIndianPatents-post-abstract -->
					<ins class="adsbygoogle allindianpatents-post-abstract"
					     style="display:inline-block"
					     data-ad-client="ca-pub-7914358224572760"
					     data-ad-slot="9152759240"></ins>
					<script>
					(adsbygoogle = window.adsbygoogle || []).push({});
					</script>					
					</center>

		<table class="table">
			<tr>
				<th>Full Text</th>
				<td>DESCRIPTION<br>
IMAGE INPUT APPARATUS, IMAGE INPUT METHOD, PERSONAL<br>
AUTHENTICATION APPARATUS, AND ELECTRONIC APPARATUS<br>
TECHNICAL FIELD<br>
The present invention relates to an input apparatus<br>
and an input method suitable for inputting an image of an<br>
object within a living body (e.g., veins of a finger,<br>
subdermal fingerprints), and a personal authentication<br>
apparatus that uses such the image of such an object.<br>
BACKGROUND ART<br>
Patent Document 1 (Japanese Laid-Open Patent No.<br>
2004-27281) , Patent Document 2 (Japanese Laid-Open Patent No.<br>
2005-92375) , and Patent Document 3 (Japanese Laid-Open Patent<br>
No. 7-21373) disclose embodiments of a personal authentication<br>
apparatus that irradiates infrared light or near infrared<br>
light on a finger to capture an image of a vein pattern within<br>
the finger and perform personal authentication based on the<br>
vein pattern.<br>
Also, Patent Document 4 (Japanese Patent No.<br>
3705766), Patent Document 5 (Japanese Laid-Open Patent No.<br>
2001-61109), and Non-Patent Document 1 (Rui Shogenji et al.,<br>
"Development of Thin Image Input Apparatus using Compound-Eye<br><br>
Optical System", The Journal of the Institute of Image<br>
Information and Television Engineers, Vol. 57, No. 9, pp.<br>
1135-1141, 2003) disclose embodiments of a thin image input<br>
apparatus that uses a compound-eye optical system. Further,<br>
Non-Patent Document 1 discloses an exemplary fingerprint<br>
inputting technique to be applied to a fingerprint<br>
authentication system.<br>
The personal authentication apparatuses disclosed<br>
in Patent Documents 1, 2, and 3 use single-eye optical systems<br>
for inputting the vein pattern image so that restrictions are<br>
imposed with respect to the object distance and imaging<br>
distance and the apparatus may not be adequately miniaturized.<br>
It is noted that in order to enable installation of a personal<br>
authentication apparatus in an electronic apparatus such as a<br>
mobile phone, a miniature information terminal such as a PDA,<br>
or a laptop computer, the personal authentication apparatus<br>
has to be adequately miniaturized.<br>
To miniaturize the personal authentication<br>
apparatus, the image input apparatus for inputting the image<br>
of an object within a living body such the veins of a finger<br>
or subdermal fingerprints has to be miniaturized as well. As<br>
is noted in Patent Documents 4 and 5, in miniaturizing the<br>
image input apparatus, it is generally advantageous to use a<br>
compound-eye optical system. However, in the case of using<br>
the image input apparatus for personal authentication, the<br><br>
image of the object within a living body to be input and used<br>
for personal authentication has to be captured with adequate<br>
image quality in addition to miniaturizing the image input<br>
apparatus.<br>
DISCLOSURE OF THE INVENTION<br>
Aspects of the present invention are directed to<br>
providing a miniaturized (thin) image input apparatus that may<br>
be suitably used for inputting an image of an imaging object<br>
such as the veins or subdermal finger prints within a living<br>
body and a personal authentication apparatus using such an<br>
image input apparatus.<br>
According to one aspect of the present invention,<br>
an image input apparatus is provided that inputs an image of<br>
an object residing within a living body, the apparatus<br>
including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facing the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br><br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the compound-eye image formed<br>
by the imaging unit using a parallax between the ommatidium<br>
images, the reconstructed single image being input as the<br>
image of the object.<br>
According to another aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power at a side facing the living body<br>
and a face with positive power at a side facing an image<br>
surface;<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the ommatidium<br>
images of the compound-eye image formed by the imaging unit<br><br>
based on optical transfer function data pertaining to the<br>
lenses that are prepared beforehand and generate a corrected<br>
compound-eye image; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the corrected compound-eye<br>
image generated by the correction unit using a parallax<br>
between the ommatidium images, the reconstructed single image<br>
being input as the image of the object.<br>
According to another aspect of the present<br>
invention, an image input method is provided for inputting an<br>
image of an object residing within a living body, the method<br>
including the steps of:<br>
using an imaging optical system that includes<br>
a light source that irradiates near infrared<br>
light on the living body;<br>
a lens array that is arranged at a position<br>
facing the living body and includes a plurality of lenses,<br>
each of the lenses having a face with zero or negative power<br>
at a side facing the living body and a face with positive<br>
power at a side facing an image surface; and<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
correcting image degradation caused by the lenses<br><br>
in the ommatidium images of the compound-eye image formed by<br>
the imaging unit based on optical transfer function data<br>
pertaining to the lenses that are prepared beforehand to<br>
generate a corrected compound-eye image;<br>
reconstructing a single image from the corrected<br>
compound-eye image using a parallax between the ommatidium<br>
images; and<br>
inputting the reconstructed single image as the<br>
image of the object.<br>
BRIEF DESCRIPTION OF THE DRAWINGS<br>
FIG. 1 is a diagram illustrating a first embodiment<br>
of the present invention;<br>
FIG. 2 is a diagram showing a light shielding<br>
member having a tapered opening;<br>
FIG. 3 is a diagram showing a light shielding<br>
member having a layered structure;<br>
FIG. 4 is a diagram illustrating an exemplary<br>
simulation for generating a compound-eye image;<br>
FIGS. 5A and 5B are diagrams illustrating a<br>
difference in the size of overlapping regions between adjacent<br>
ommatidium images according to a difference in the object<br>
distance;<br>
FIG. 6 is a graph illustrating variations in the<br>
sum E of squared values of the pixel luminance difference<br><br>
between ommatidium images according to variations in the<br>
parallax of the ommatidium images;<br>
FIG. 7 is a diagram illustrating a method of<br>
arranging pixels in a process of reconstructing a single image<br>
from a compound-eye image;<br>
FIG. 8 is a flowchart illustrating exemplary<br>
process steps for reconstructing a single image from a<br>
compound-eye image;<br>
FIG. 9 is a diagram illustrating a second<br>
embodiment of the present invention;<br>
FIGS. 10A and 10B are graphs illustrating MTF<br>
characteristics of a plano-convex lens in relation to the<br>
object visual angle in a case where the convex face of the<br>
plano-convex lens faces the object side and a case where the<br>
convex face faces the image surface side;<br>
FIG. 11 is a graph illustrating MTF characteristics<br>
of a plano-convex lens in relation to the object distance in<br>
the case where the convex face of the plano-convex lens faces<br>
the image surface side;<br>
FIG. 12 is a diagram illustrating a third<br>
embodiment of the present invention;<br>
FIG. 13 is a diagram illustrating a fourth<br>
embodiment of the present invention;<br>
FIG. 14 is a graph illustrating image sampling<br>
timings in a case of modulating the intensity of irradiated<br><br>
light into a sine wave, dividing the modulation period into<br>
four phases, and sampling images at these phase intervals;<br>
FIG. 15 is a diagram illustrating an example of<br>
lowering the optical magnification and enlarging the field of<br>
view of an imaging optical system; and<br>
FIGS. 16A and 16B are perspective views of<br>
exemplary electronic apparatuses each having a personal<br>
authentication apparatus according to an embodiment of the<br>
present invention installed therein.<br>
BEST MODE FOR CARRYING OUT THE INVENTION<br>
In the following, preferred embodiments of the<br>
present invention are described with reference to the<br>
accompanying drawings. It is noted that in the examples<br>
described below, it is assumed that a human finger corresponds<br>
to a living body, and the internal veins of the finger<br>
correspond to the object to be imaged. Further, it is assumed<br>
that the image of the veins is input so that its vein pattern<br>
may be used to perform personal authentication. Also, in the<br>
drawings, component elements that are similar or substantially<br>
identical are given the same numerical references in order to<br>
reduce overlapping descriptions.<br>
(First Embodiment)<br>
FIG. 1 is a diagram showing an image input<br>
apparatus and a personal authentication apparatus according to<br><br>
a first embodiment of the present invention. In FIG. 1, an<br>
imaging optical system 100, a preprocessing unit 101, a<br>
reconstruction operation unit 102, and a post processing unit<br>
103 make up an image input apparatus. Also, an authentication<br>
operation unit 104 and a registered data memory 105 make up an<br>
authentication process part that performs a personal<br>
authentication process based on a vein pattern. Such an<br>
authentication process part and an image input apparatus make<br>
up a personal authentication apparatus according to the<br>
present embodiment.<br>
In FIG. 1, a finger (living body) 1 is placed on a<br>
certain location of the imaging optical system 100. The<br>
imaging optical system 100 captures an image of a vein 2<br>
within the finger 1 as an object, and inputs the captured<br>
image. The imaging optical system 100 includes a light source<br>
6, a lens array 3, a light shielding member 4, an image pickup<br>
device 5, and an optical band pass filter 7.<br>
The lens array 3 is for forming the image of the<br>
object, and includes plural lenses 3a that are arranged into a<br>
two-dimensional array within a plane that is substantially<br>
perpendicular to the lens axis. However, the present<br>
invention is not limited to such an arrangement and the lenses<br>
3a may alternatively be arranged into a one-dimensional array,<br>
for example.<br>
According to an embodiment of the present invention,<br><br>
the lenses 3a making up the lens array 3 each have a face with<br>
a power of 0 or a negative power at the object side and a face<br>
with a positive power at the image surface side (i.e., lower<br>
face side). In the illustrated example of FIG. 1, a plano-<br>
convex lens with its convex face facing the image surface side<br>
is used as the lens 3a. It is noted that the convex face may-<br>
be either a spherical surface or an aspheric surface. In the<br>
case where the convex face of the lens 3a is aspheric, design<br>
flexibility for improving the optical characteristics of the<br>
lens 3a may be enhanced.<br>
The light shielding member 4 is for preventing<br>
crosstalk between light rays passing through the lenses 3a of<br>
the lens array 3 at the image surface and preventing<br>
generation of noise light such as ghost light and flared light.<br>
According to one embodiment, the light shielding member 4 is<br>
arranged to have a height extending from the lenses 3a of the<br>
lens array 3 to the image surface and includes openings<br>
(through holes) at the positions of the lenses 3a that are<br>
arranged into a two-dimensional array, each of the openings<br>
having a square cross-section. In another embodiment, the<br>
light shielding member may be a pin hole array having openings<br>
corresponding to the positions of the lenses 3a of the lens<br>
array 3. In yet another embodiment, the light shielding<br>
member may be made of a transparent parallel flat plate having<br>
openings corresponding to the lenses 3a of the lens array<br><br>
formed thereon and one or more non-transparent films deposited<br>
through vapor deposition, for example, on the upper face<br>
and/or lower face of the transparent parallel flat plate.<br>
The image pickup device 5 is for forming a<br>
compound-eye image corresponding to a collection of images<br>
(ommatidium images) formed by the lenses 3a of the lens array<br>
3. For example, a CCD image pickup device or a CMOS image<br>
pickup device having photo receiving elements 5a arranged into<br>
a two-dimensional array may be used. In one embodiment, the<br>
image pickup device 5 may include a circuit for adjusting the<br>
gain of a photoelectric transfer signal from the photo<br>
receiving element 5a and converting an analogue signal into a<br>
digital signal to be configured to output a captured image as<br>
digital image data. It is noted that the image pickup device<br>
5 forms an image made up of plural pixels from the ommatidium<br>
images.<br>
The light source 6 may be a light emitting diode<br>
(LED), for example, that irradiates near infrared light, which<br>
is absorbed at a relatively low absorption rate, on the finger<br>
(living body) 1. The near infrared light irradiated on the<br>
finger (living body) 1 by the light source 6 is absorbed by<br>
reduced hemoglobin within the veins (imaging object) 2 of the<br>
finger 1. However, the near infrared light is hardly absorbed<br>
by portions of the finger 1 other than the vein 2. In this<br>
way, the vein pattern may be visualized. Specifically, the<br><br>
vein pattern may be imaged on the imaging surface of the image<br>
pickup device 5 by the lenses 3a of the lens array 3 as a<br>
complex-eye image.<br>
The optical band pass filter 7 only passes light<br>
within a predetermined wavelength range including the<br>
wavelength of the near infrared light irradiated by the light<br>
source 6. The optical band pass filter 7 is arranged to<br>
remove influences of noise light from light sources other than<br>
the light source 6. It is noted that the band pass filter 7<br>
may not have to be included in a case where noise light does<br>
not have to be taken into consideration, or in a case where<br>
influences of noise light are removed by image data processing<br>
as is described below in relation to a fifth embodiment of the<br>
present invention. Also, in one embodiment, the optical band<br>
pass filter 7 may be arranged on the image surface side of the<br>
lens array 3 such as the imaging surface of the image pickup<br>
device 5.<br>
It is noted that in the illustrated example of FIG.<br>
1, only one light source 6 is shown. However, in other<br>
embodiments, plural light sources may be arranged to irradiate<br>
light on a region of the imaging object. Also, in one<br>
embodiment, a laser diode (LD) may be used as the light source<br>
6. Further, it is noted that in the illustrated example of<br>
FIG. 1, the light source 6 is arranged to irradiate light on<br>
the finger (imaging object) 1 from a side not facing the lens<br><br>
array 3 (i.e., upper side of FIG. 1). However, in other<br>
embodiments, the light source 6 may be arranged to irradiate<br>
light on the finger 1 from the side or the bottom, for example.<br>
That is, since the near infrared light irradiated on the<br>
finger 1 is diffused in all directions within the finger 1,<br>
the vein pattern image of the finger 1 may be adequately<br>
captured in these embodiments as well. In another embodiment,<br>
a light conductor that guides the near infrared light<br>
generated at the light source 6 toward the finger 1 may be<br>
added.<br>
The image pickup device 5 captures a compound-eye<br>
image of the vein pattern (object image) from the images<br>
formed by the lenses 3a of the lens array 3, and outputs the<br>
captured image as digital image data. The digital image data<br>
are preprocessed by the preprocessing unit 101 and transferred<br>
to the reconstruction operation unit 102. The preprocessing<br>
unit 101 may extract regions of the ommatidium images from the<br>
compound-eye image by removing shade portions created by the<br>
light shielding member 4 and performing a smoothing process or<br>
an averaging process on the individual ommatidium images; or<br>
extract the ommatidium images including the vein pattern and<br>
perform an emphasizing process on the ommatidium images for<br>
sharpening the vein pattern image, for example. The<br>
reconstruction operation unit 102 reconstructs a single image<br>
from the preprocessed ommatidium images by performing a<br><br>
reconstruction operation process using the parallax between<br>
the ommatidium images which is described in greater detail<br>
below. Then, post processing such as noise removal may be<br>
performed on the single image data by the post processing unit<br>
103 as is necessary or desired after which the single image<br>
data are input to the authentication operation unit 104 as<br>
vein (object) image data. The above-described operations<br>
correspond to exemplary image input operations of the image<br>
input apparatus according to the present embodiment. It is<br>
noted that the above-described preprocessing and post<br>
processing operations correspond to processes to be performed<br>
before and after the image reconstruction process.<br>
Accordingly, the operations of the preprocessing unit 101 and<br>
the post processing unit 103 may be regarded as image<br>
reconstruction operations along with the operations of the<br>
reconstruction operation unit 102.<br>
The authentication operation unit 104 may extract a<br>
characteristic amount of the vein pattern from the input vein<br>
image data and compare the extracted characteristic amount<br>
with a vein pattern of a registered person stored in the<br>
registered data memory 105 to conduct personal authentication,<br>
for example. Specifically, if the difference between the<br>
extracted characteristic amount and the registered<br>
characteristic amount of the registered person is less than or<br>
equal to a predetermined value, the person subject to<br><br>
authentication (i.e., owner of the finer 1) may be<br>
authenticated as the registered person. On the other hand, if<br>
the difference is greater than the predetermined value,<br>
authentication is denied. Since personal authentication<br>
techniques using a vein pattern are conventionally known,<br>
further detailed descriptions thereof are hereby omitted.<br>
The lens array 3 may be made of transparent resin<br>
or glass material. The lens array 3 may be fabricated using a<br>
processing technique such as the reflow method, the area<br>
ration gray scale masking method, or the polishing method, for<br>
example. Alternatively, the lens array 3 may be fabricated<br>
through molding using a mold that is fabricated using the<br>
above processing techniques, for example. The light shielding<br>
member 4 may also be fabricated through similar processing<br>
using materials such as resin, glass, or metal. However, it<br>
is noted that the light shielding member 4 is arranged to<br>
prevent light from passing therethrough or being reflected<br>
thereon by using a nontransparent material or performing a<br>
coating process on a transparent material, for example.<br>
It is noted that in the illustrated example of FIG.<br>
1, the opening (through hole) of the light shielding member 4<br>
has substantially the same cross-sectional area across planes<br>
approximately orthogonal to the lens axis from the lens 3a to<br>
the imaging surface of the image pickup device 5. In an<br>
alternative embodiment as is shown in FIG. 2, the cross-<br><br>
sectional areas of the opening 4a may become smaller toward<br>
the imaging surface side so that the opening 4a may be<br>
arranged into a tapered structure. As is illustrated by the<br>
arrows shown in FIG. 2, by arranging the opening 4a into a<br>
tapered structure, light rays entering the opening 4a in a<br>
diagonal direction may be prevented from being reflected<br>
within the opening 4a and onto the imaging surface of the<br>
image pickup device 5 so that flares and ghosts may be<br>
prevented, for example. Also, it is noted that when the<br>
height of the light shielding member 4 has to be relatively<br>
high in accordance with the size of the opening 4a, processing<br>
of the light shielding member may become difficult. In such a<br>
case, the light shielding member 4 may be fabricated by<br>
layering plural layers having a suitable height for easy<br>
processing and bonding these layers together. FIG. 3<br>
illustrates an example in which the light shielding member 4<br>
is fabricated by layering two layers of the light shielding<br>
member 4 having a suitable height for easy processing.<br>
FIGS. 4A and 4B are diagrams illustrating a<br>
simulation example of forming a compound-eye image with the<br>
imaging optical system 100. FIG. 4A shows an original image<br>
from which a compound-eye image is formed. FIG. 4B shows the<br>
compound-eye image obtained from the original image of FIG. 4A.<br>
In the compound-eye image shown in FIG. 4B the black portions<br>
arranged between the ommatidium images correspond to shade<br><br>
portions formed by the light shielding member 4. The<br>
ommatidium images are formed by the lenses 3a of the lens<br>
array 3. Specifically, different portions of the imaging<br>
object are imaged according to the lens positions of the<br>
lenses 3a of the lens array 3. In FIG. 1, the region<br>
identified by the reference 2a represents the field of view of<br>
one lens 3a corresponding to a region to be observed and<br>
imaged as an ommatidium image by the lens 3a. Also, the<br>
regions identified by the reference 2b represent an<br>
overlapping portion at which the fields of view of two<br>
adjacent lenses 3a overlap one another. This portion<br>
corresponds to an overlapping region of adjacent ommatidium<br>
images of the compound-eye image shown in FIG. 4B.<br>
It is noted that the distance from the skin surface<br>
of the finger to the vein varies depending on each person, and<br>
therefore, the distance from the lens array 3 of to the vein 2<br>
of FIG. 1 varies depending on the person being authenticated.<br>
When the distance between the vein 2 and the lens array 3 is<br>
reduced as is shown in FIG. 5A, or when the height of the<br>
light shielding member 4 is increased, the overlapping region<br>
between adjacent ommatidium images may not be created, for<br>
example. On the other hand, when the distance between the<br>
vein 2 and the lens array 3 is increased as is shown in FIG.<br>
5B or when the height of the light shielding member 4 is<br>
reduced, the overlapping region between adjacent ommatidium<br><br>
images may be enlarged.<br>
When there is no overlapping region between two<br>
adjacent ommatidium images, a single image may be<br>
reconstructed by extracting the individual ommatidium images<br>
within the compound-eye image, reorienting the extracted<br>
ommatidium images that are inverted by the lenses 3a to their<br>
original orientations, and simply connecting the reverted<br>
ommatidium images together. However, when overlapping regions<br>
exist between two adjacent ommatidium images, one of the<br>
overlapping regions becomes invalid so that in this case, when<br>
a single image is reconstructed by simply connecting together<br>
the ommatidium images, the size and the number of pixels<br>
making up the reconstructed image may be reduced and the image<br>
resolution may be decreased. Also, when the distance between<br>
the vein 2 and the lens array 3 increases as in the example of<br>
FIG. 5B, the area of overlapping regions and the number of<br>
invalid pixels increase and the optical magnification of the<br>
imaging optical system decreases so that the vein pattern<br>
image becomes smaller and the image resolution is lowered.<br>
An embodiment of the present invention is directed<br>
to compensating for such a decrease in the image resolution<br>
due to an increase in the number of invalid pixels and a<br>
decrease in the optical magnification, for example, by<br>
performing a single image reconstruction process using the<br>
parallax between ommatidium images at the reconstruction<br><br>
operation unit 102 as is described below.<br>
It is noted that a parallax exists between the<br>
ommatidium images due to the positional relationship between<br>
the lenses 3a and the vein (imaging object) 2. Thus, the<br>
ommatidium images correspond to images that are shifted<br>
according to the parallax. In the following descriptions, a<br>
parallax between ommatidium images refers to the shift amount<br>
(in length units) of a given ommatidium image with respect to<br>
a reference ommatidium image within a compound-eye image.<br>
Using the parallax between the ommatidium images, an image of<br>
an object structure buried in the pixels of ommatidium images<br>
may be reproduced. In one example, the parallax between the<br>
ommatidium images may be detected through calculating the sum<br>
of squares of the luminance difference between the ommatidium<br>
images using the below formula (1).<br><br>
In the above formula (1), IB denotes the reference<br>
ommatidium image of the compound-eye image that may be<br>
arbitrarily set to be used as a reference based on which the<br>
parallaxes of the individual ommatidium images are obtained.<br>
Im denotes the individual ommatidium images, m denotes a number<br>
identifying the individual ommatidium images that may be a<br><br>
value ranging from 1 to N (N representing the number of lenses<br>
3a making up the lens array 3) . Px and Py denote parallaxes in<br>
the x and y directions, respectively, of a given ommatidium<br>
image with respect to the reference ommatidium image.<br>
According to the present example, the luminance difference<br>
between the given ommatidium image and the reference<br>
ommatidium image is obtained for all pixels making up the<br>
ommatidium images, and the sum E of the squared values of the<br>
luminance differences are obtained. The value E is<br>
successively calculated while gradually changing the values of<br>
Px and Py, and the values of Px and Py when the value E takes a<br>
minimum value are determined as values representing the<br>
parallaxes in the x and y directions, respectively, with<br>
respect to the reference ommatidium image. FIG. 6 is a three-<br>
dimensional graph illustrating the change in the value of E in<br>
relation to the changes in the values of Px and Py, the x axis<br>
representing the value of Px, the y axis representing the value<br>
of Py, and the z axis representing the value of E.<br>
As can be appreciated from the graph of FIG. 6, the<br>
values of Px and Py when E takes a minimum value correspond to<br>
the parallaxes in the x and y directions, respectively, for<br>
the ommatidium image Im with respect to the reference<br>
ommatidium image IB. In the case where the parallax dimension<br>
may be smaller than the pixel size of the image pickup device<br>
5, the ommatidium image may be enlarged so that the parallax<br><br>
dimension corresponds to the pixel size of the image pickup<br>
device 5 or an integer multiple thereof. That is, the number<br>
of pixels making up the ommatidium image may be increased, and<br>
the parallax may be obtained by determining the minimum sum of<br>
squares of the luminance difference between the enlarged<br>
ommatidium images. To enlarge the ommatidium images,<br>
interpolation operation has to be implemented that involves<br>
determining the luminance of each pixel by referring to its<br>
adjacent pixel. As for the rate of expansion, since an<br>
approximate value of the parallax may be estimated from the<br>
optical magnification, the lens pitch of the lens array 3, and<br>
the pixel size of the image pickup device 5, the rate of<br>
expansion may be determined so that the estimated parallax may<br>
correspond to the pixel size of the image pickup device 5. In<br>
the case where the lens pitch processing accuracy of the lens<br>
array 3 is adequately high, the parallax of the ommatidium<br>
images may be geometrically calculated if the distance between<br>
the object and the lens array 3 is known. In this respect,<br>
according to one example, the parallax of the ommatidium<br>
images may be obtained by detecting the parallax between one<br>
pair of ommatidium images and calculating the below formula<br>
(2) , in which 8 denotes the parallax of a given ommatidium<br>
image, A denotes the parallax of the ommatidium image that is<br>
actually detected, N denotes the distance between the center<br>
of the ommatidium image for which the parallax has been<br><br>
detected and the center of the reference ommatidium image with<br>
respect to the x or y direction (horizontal or vertical<br>
direction) within an image, and n denotes the distance between<br>
the center of the given ommatidium image and the center of the<br>
reference ommatidium image.<br><br>
In a case where the distance between the imaging<br>
object and the lens array 3 is relatively short so that the<br>
parallax between ommatidium images is relatively large, it may<br>
be preferable to detect parallaxes between adjacent ommatidium<br>
images rather than fixing a reference ommatidium image. In<br>
such a case, one of a pair of adjacent ommatidium images<br>
becomes the reference ommatidium image and the other becomes<br>
the ommatidium image for which the parallax is detected. As<br>
is mentioned above, there may be one or more ommatidium images<br>
that do not contain images of the vein pattern. Accordingly,<br>
in one preferred embodiment, the ommatidium images containing<br>
images of the vein pattern may be extracted in a preprocessing<br>
operation, and parallaxes may be detected for the extracted<br>
ommatidium images while the parallaxes for the rest of the<br>
ommatidium images without the images of the vein pattern may<br>
be obtained by calculating the above formula (2) using the<br><br>
detected parallaxes of the extracted ommatidium images. In<br>
another embodiment, the parallaxes of the ommatidium images<br>
may be detected by performing cross correlation calculation<br>
between the ommatidium images instead of calculating the sum<br>
of squares of the luminance differences between the ommatidium<br>
images.<br>
FIG. 7 is a diagram illustrating a method of<br>
reconstructing a single image. In the illustrated example of<br>
FIG. 7, the pixel luminance is extracted from each ommatidium<br>
image 9a of a compound-eye image 9, and the extracted pixel<br>
luminance is arranged at a corresponding position of a<br>
reconstructed image 8 within a virtual space which position is<br>
determined based on the position of the ommatidium image 9a<br>
within the compound-eye image 9 and its parallax. By<br>
performing the above process of arranging the pixel luminance<br>
for all the pixels of the ommatidium images, a reconstructed<br>
image 8 may be obtained.<br>
It is noted that when there are pixels that do not<br>
contain luminance within the reconstructed image owing to<br>
influences of the parallax dimension and/or shaded portions<br>
created by the light shielding member 4, for example,<br>
interpolation may be performed on such a pixel based on the<br>
luminance of its adjacent pixel. Also, in a case where the<br>
parallax is smaller than the pixel size, the reconstructed<br>
image is enlarged so that the parallax dimension may be equal<br><br>
to the pixel size or an integer multiple thereof. That is,<br>
the number of pixels making up the reconstructed image is<br>
increased, and the above-described process of arranging the<br>
pixel luminance may be performed thereafter.<br>
FIG. 8 is a flowchart illustrating exemplary<br>
process steps that may be performed by the reconstruction<br>
operation unit 102. According to FIG. 8, first, the<br>
reconstruction operation unit 102 acquires a compound-eye<br>
image (step S1). Then, a reference ommatidium image for<br>
parallax detection is selectively set from the ommatidium<br>
images containing images of the vein pattern that are<br>
extracted in a preprocess (step S2), and parallaxes of<br>
individual ommatidium images with respect to the reference<br>
ommatidium image are detected (step S3). However, it is noted<br>
that parallaxes may not be detected for the ommatidium images<br>
that do not contain images of the vein pattern, and the<br>
parallaxes of such ommatidium images may be obtained by<br>
calculating the above formula (2) , for example. Then,<br>
reconstruction operation is performed for constructing a<br>
single image from the compound-eye image using the parallaxes<br>
of the individual ommatidium images (step S4) after which the<br>
reconstructed single image is output (step S5). By performing<br>
such a reconstruction process, an image of an object structure<br>
that is buried in the pixels of the ommatidium images may be<br>
reproduced, and even when the distance between the object and<br><br>
the lens array 3 is increased and the resolution is decreased,<br>
a single image with improved resolution may be obtained.<br>
It is noted that when the overlap between<br>
ommatidium images is relatively small, the detected parallax<br>
may be a very small value or an abnormal value, for example.<br>
In this respect, a threshold value for the parallax may be set,<br>
and the parallax to be used may be compared with the threshold<br>
value in step S4, for example. If the parallax is less than<br>
the threshold value, a single image may be reconstructed by<br>
simply reorienting the ommatidium images to their original<br>
orientations and connecting the ommatidium images together.<br>
On the other hand, if the parallax is greater than or equal to<br>
the threshold value, the above-described reconstruction<br>
process using the parallax may be performed.<br>
In order to adequately perform the above-described<br>
reconstruction process using the parallax between ommatidium<br>
images provided that the distance between an object and the<br>
lens array 3 is within a predetermined permissible range, a<br>
given pair of adjacent ommatidium images that are imaged by<br>
the image pickup device 5 must have at least one pixel image<br>
in common representing the same portion of the object.<br>
Accordingly, design measures have to be implemented to ensure<br>
that adjacent images always have overlapping regions when the<br>
distance between the object and the lens array is within the<br>
predetermined permissible range. For example, the height of<br><br>
the light shielding member 4 and the distance between the<br>
lenses 3a of the lens array 3 may be properly adjusted so that<br>
adj acent ommatidium images may always have overlapping regions<br>
even when the distance between the object and the lens array 3<br>
is at the minimum value of the predetermined permissible range.<br>
In another example, a transparent plate (not shown) for<br>
adjusting the distance between the object and the lens array 3<br>
may be arranged between the finger (living body) 1 and the<br>
lens array 3, on the upper face of the optical band pass<br>
filter 7, for example, in order to prevent the distance from<br>
becoming smaller than the minimum value of the predetermined<br>
permissible range. In yet another example, when the optical<br>
band pass filter 7 is not provided, such a transparent plate<br>
may be arranged in place of the optical band pass filter 7.<br>
By implementing such measures, a compound-eye image that<br>
includes overlapping regions may always be obtained so that<br>
the reconstruction process may not have to be switched<br>
according to the results comparing the parallax to the<br>
threshold value as is described above. Also, since variations<br>
in the distance between the object and the lens array 3 may be<br>
reflected in the parallax, the reconstruction process<br>
according to an embodiment of the invention that uses the<br>
parallax may easily reflect such variations in the distance<br>
caused by differences in the thickness of the skin, for<br>
example.<br><br>
It is noted that an exemplary case of inputting the<br>
vein pattern of a finger and using the vein pattern to perform<br>
personal authentication is described above. However, the<br>
present invention is not limited to such an example, and in<br>
other embodiments, a vein pattern of the palm or a finger<br>
print pattern of the finger may be imaged to perform personal<br>
authentication. In further embodiments, the present invention<br>
may be applied to imaging techniques for obtaining biological<br>
system image information to be used for non-invasive blood<br>
sugar level measurement, for example.<br>
As is shown in FIG. 15, by reducing the back focus<br>
of the lens array 3, the optical magnification may be lowered<br>
and a wider field of view may be secured. In a case where the<br>
size of the object is relatively large, a general purpose<br>
image pickup device may not be capable of adequately imaging<br>
the object so that a dedicated image pickup device may have to<br>
be used which may raise the overall cost of the apparatus.<br>
Thus, in order to prevent such a cost increase, according to<br>
one preferred embodiment, a suitable optical magnification may<br>
be set based on the object size and the size of the general<br>
purpose image pickup device so that the overall image of the<br>
object may be adequately imaged using the general purpose<br>
image pickup device. It is noted that FIG. 15 illustrates a<br>
case where the optical magnification is reduced by adjusting<br>
the lens array 3; however, other measures may be implemented<br><br>
such as adding another optical system for de-magnifying the<br>
object image, for example.<br>
(Second Embodiment)<br>
FIG. 9 is a diagram illustrating an image input<br>
apparatus and a persona authentication apparatus according to<br>
a second embodiment of the present invention. The apparatus<br>
according to the present embodiment differs from that of the<br>
first embodiment in that it includes a correction operation<br>
unit 201 and a memory 202 as a correction processing part for<br>
correcting (e.g., through MTF correction) image degradation<br>
caused by the lenses 3a of the lens array 3. It is noted that<br>
other features of the apparatus according to the present<br>
embodiment may be substantially identical to the first<br>
embodiment. It is noted that optical transfer function (OTF)<br>
data pertaining to the plano-convex lens 3a having its convex<br>
face facing the image surface are stored in the memory 202<br>
beforehand.<br>
FIGS. 10A and 10B are graphs illustrating the<br>
relationship between the MTF corresponding to the gain of the<br>
optical transfer function of a plano-convex lens and the<br>
visual angle of an object in a case where the convex face of<br>
the plano-convex lens faces the object side and in a case<br>
where the convex face of the plano-convex lens faces the image<br>
surface side.<br>
FIG. 10A shows the MTF characteristics of a piano-<br><br>
convex lens that has its convex face facing the object side,<br>
and FIG. 10B shows the MTF characteristics of a plano-convex<br>
lens that has its convex face facing the image surface side as<br>
with the lens 3a used the present embodiment. It is noted<br>
that the thin solid lines, dotted lines, and dashed lines<br>
shown in FIGS. 11A and 11B illustrate different angles of<br>
light rays incident to the lens; that is, the lines illustrate<br>
different visual angles of the object. Also, the thick solid<br>
line shown in FIG. 11B illustrates MTF characteristics after<br>
correction.<br>
As is shown in FIG. 10A, in the case where the<br>
convex face of the plano-convex lens faces the object side,<br>
although relatively high MTF values may be obtained up to a<br>
relatively high spatial frequency band at certain visual<br>
angles, the MTF and the cutoff frequency vary significantly<br>
depending on the visual angle and the image may be prone to<br>
degradation. For example, to maintain a high MTF and a high<br>
cutoff frequency throughout a permissible visual angle range<br>
in this case, the permissible visual angle range may have to<br>
be very narrow and/or the lens may be required to have a<br>
complicated structure such as a layered structure or an<br>
aspheric structure, for example. In other words, it may be<br>
difficult to achieve adequate performance throughout a wide<br>
range of visual angles with a simple lens configuration in<br>
this case. It is noted that if the MTF can be limited within<br><br>
a predetermined range, the MTF characteristics may be improved<br>
through correction operation. However, in the case of FIG.<br>
10A, since the MTF varies significantly depending on the<br>
visual angle, correction may have to be separately performed<br>
for different visual angles so that the processing load for<br>
performing the correction may be rather large. Also, since<br>
the MTF may easily drop to 0 at certain visual angles, the<br>
range of visual angles on which correction may be performed<br>
may be rather limited.<br>
On the other hand, as is shown in FIG. 10B, in a<br>
case where the convex face of a plano-convex lens faces the<br>
image surface side as with the lens 3a used in the present<br>
embodiment, although the overall MTF level may be decreased,<br>
variations in the MTF with respect to variations in the visual<br>
angle may be reduced and variations in the cutoff frequency<br>
may also be reduced. Thus, in the case of performing MTF<br>
correction operation, the convex face of a plano-convex lens<br>
is preferably arranged to face the image surface side and the<br>
convex face configuration is preferably adjusted so that the<br>
MTF may be uniform and limited within a predetermined range in<br>
order to maintain MTF performance throughout a relatively wide<br>
range of visual angles with a relatively small processing load.<br>
For example, the MTF characteristics represented by the thick,<br>
solid line shown in FIG. 11B may be easily achieved with the<br>
present configuration. In addition to achieving improvements<br><br>
in MTF characteristics as is described above, it is noted that<br>
in-plane errors such as distortions and curvatures may be<br>
reduced by arranging the convex face of a plano-convex lens to<br>
face the image surface side. Also, the above-described<br>
advantageous effects may be equally obtained in the case of<br>
using a lens having a lens face with a negative power at the<br>
object side and a lens face with a positive power at the image<br>
surface side.<br>
In the following, the MTF correction process<br>
performed by the correction operation unit 201 is described.<br>
It is noted that the correction operation unit 201 according<br>
to the present embodiment is configured to perform a process<br>
of extracting ommatidium images of a compound-eye image formed<br>
by the image pickup device 5 while excluding shade portions<br>
created by the light shielding member 4 before performing he<br>
correction process. Thus, in the present embodiment, the<br>
preprocessing unit 101 does not have to perform the process of<br>
extracting the ommatidium images other than the shade portions.<br>
The image of an object that has been degraded by<br>
the lens 3a, that is, the intensity data of each individual<br>
ommatidium image of a compound-eye image may be expressed by<br>
the below formula (3) :<br><br><br>
It is noted that in the above formula (3), x and y denote<br>
position coordinates of an ommatidium image, I denotes the<br>
intensity data of an ommatidium image, S denotes intensity<br>
data of the object, OTF denotes optical transfer function data<br>
of the lens 3a, FFT denotes a Fourier transfer operator, and<br>
FFT-1 denotes an inverse Fourier transfer operator. It is<br>
noted that the optical transfer function data OTF of the lens<br>
3a may be obtained through autocorrelation of the pupil<br>
function of the lens 3a the using wave aberration data of the<br>
lens 3a obtained during the lens design stage.<br>
The correction operation unit 201 uses the optical<br>
transfer function data OTF of the lens 3a that are calculated<br>
and stored in the memory 202 beforehand and performs<br>
computation of the below formula (4) on each ommatidium image<br>
of the compound image to correct image degradation caused by<br>
the lens 3a and generate an ommatidium image with improved MTF<br>
(and a compound-eye image corresponding to a collection of the<br>
corrected ommatidium images). It is noted that in the below<br>
formula (4), R denotes the intensity data of an ommatidium<br>
image after correction, a denotes a constant for preventing<br>
division by zero or noise amplification.<br><br><br>
It is noted that when the optical transfer function<br>
does not change according to the change in the light ray angle,<br>
this means that the optical transfer function may not change<br>
even when the lens itself is slightly tilted, for example.<br>
Therefore, influences of lens positioning errors upon<br>
installing the image pickup device 5 may be reduced in such as<br>
case. Also, it is noted that when the light focusing<br>
performance level of the lens is high, the focal point may<br>
easily spread to cause image degradation even with a slight<br>
deviation of the image surface position with respect to the<br>
optical axis. However, in a case where the light focusing<br>
performance level of the lens is relatively low as in the<br>
example of FIG. 11B, the focal point may be prevented from<br>
spreading very far when the image surface position is slightly<br>
deviated from the optical axis. In this way, influences of<br>
errors in setting the distance between the lens and the image<br>
surface may be reduced, for example. Further, in a preferred<br>
embodiment, the lens array 3 may be coupled to the light<br>
shielding member 4 upon assembling the apparatus.<br>
Specifically, the convex faces of the lenses 3a facing the<br>
image surface side may engage corresponding openings (through<br>
holes) of the light shielding member 4 so that alignment of<br>
the lens array 3 and the light shielding member 4 may be<br>
facilitated, for example.<br>
It is noted that a correction process that involves<br><br>
frequency filtering using FFT is described above as an<br>
illustrative example. However, a similar correction process<br>
may be performed through de-convolution using a point-spread<br>
function pattern, for example. It is noted that a process<br>
using a point-spread function pattern may be simpler than that<br>
using FFT (fast Fourier transform) so that the cost of the<br>
overall apparatus may be reduced in the case of fabricating a<br>
dedicated processing circuit, for example. In another<br>
preferred embodiment, optical transfer function data for<br>
correction operation may be calculated for each of plural<br>
visual angles and stored in the memory 202 beforehand so that<br>
correction may be performed using corresponding optical<br>
transfer function data for each of image regions corresponding<br>
to the different visual angles. In a further embodiment,<br>
correction may be performed on in-plane errors such as<br>
curvatures and distortions by estimating their error levels<br>
beforehand.<br>
According to one modified example of the embodiment<br>
shown in FIG. 9, the correction processing part for correcting<br>
image degradation caused by the lens 3a (MTF correction) may<br>
be arranged to come after the post processing unit 103 rather<br>
than before the preprocessing unit 101. Specifically, a<br>
correction operation unit may be arranged between the post<br>
processing unit 103 and the authentication operation unit 104,<br>
and a memory for storing optical transfer function data may be<br><br>
connected to this correction operation unit so that image<br>
degradation correction (MTF correction) • may be performed on a<br>
reconstructed single image. It is noted that correction<br>
process with respect to a single image may be completed by<br>
performing one correction process sequence on the<br>
reconstructed single image so that operation time may be<br>
reduced compared to the case of performing correction on each<br>
ommatidium image. However, it is noted that since the optical<br>
transfer function data to be used in the correction process<br>
pertain to the individual lenses 3a and are intended to be<br>
used for correcting the individual ommatidium images, when the<br>
correction process is performed on the single image rather<br>
than the individual ommatidium images, correction errors may<br>
inevitably be increased compared to the case of performing<br>
correction on the individual ommatidium images.<br>
(Third Embodiment)<br>
It is noted that the optical transfer function of a<br>
lens may vary depending on the object distance (i.e., distance<br>
from the object 2 to the lens array 3). Particularly, in an<br>
imaging optical system of an image input apparatus according<br>
to an embodiment of the present invention where the object is<br>
positioned relatively close to the lens array 3, the optical<br>
transfer function may greatly vary in response to variations<br>
in the object distance.<br>
FIG. 11 is a graph illustrating exemplary<br><br>
variations in MTF characteristics according to the object<br>
distance in a plano-convex lens having its convex face facing<br>
the image surface side as in the case of FIG. 10B.<br>
Specifically, in FIG. 11, MTF characteristics at a<br>
predetermined visual angle when the object distance is equal<br>
to A, B, and C are illustrated by a thin solid line, a dotted<br>
line, and a dashed line, respectively. As can be appreciated<br>
from this example, in a case where variations in the object<br>
distance cannot be disregarded (i.e., when MTF characteristics<br>
vary depending on the object distance), correction errors may<br>
occur when image degradation correction (MTF correction) is<br>
performed based on optical transfer function data for a<br>
predetermined distance. Thus, in order to reduce correction<br>
errors, optical transfer function data for different object<br>
distances are preferably prepared beforehand so that the<br>
optical transfer function data to be used for image<br>
degradation correction may be selected according to the object<br>
distance. By performing image degradation correction<br>
according to the object distance in the manner described above,<br>
image degradation may be appropriately corrected to obtain<br>
suitable MTF characteristics as is illustrated by a thick<br>
solid line in FIG. 11, for example.<br>
FIG. 12 is a diagram showing an image input<br>
apparatus and a personal authentication apparatus according to<br>
a third embodiment of the present invention. In the present<br><br>
embodiment, an object distance detecting unit 301 is added for<br>
detecting the object distance (i.e., distance from the object<br>
2 to the lens array 3). Also, the memory 202 stores optical<br>
transfer data for different object distances with respect to<br>
the lenses 3a, and the correction operation unit 201: is<br>
configured to read the optical transfer function stored in the<br>
memory 202 that are associated with an object distance that is<br>
closest to the object distance detected by the object distance<br>
detecting unit 301 to perform image degradation correction<br>
(MTF correction) on each ommatidium image of a compound-eye<br>
image using the read optical transfer function data. It is<br>
noted that other features of the apparatus according to the<br>
present embodiment may be identical to those of the second<br>
embodiment.<br>
As is described above in relation to the first<br>
embodiment of the present invention, the overlapping regions<br>
between ommatidium images may vary depending on the object<br>
distance (see FIG. 5). Accordingly, the object distance may<br>
be calculated based on the triangulation principle using<br>
information on the overlapping regions, namely, the detected<br>
parallax. The object distance detecting unit 301 according to<br>
the present embodiment employs such a method to detect the<br>
object distance. Specifically, the object distance detecting<br>
unit 301 detects the parallax between ommatidium images of a<br>
compound-eye image that is captured by the image pickup device<br><br>
5 and calculates the object distance based on the<br>
triangulation principle using the detected parallax.; It is<br>
noted that the object distance may be obtained by detecting<br>
the parallax between two ommatidium images; that is, the<br>
parallaxes for all the ommatidium images of the compound-eye<br>
image are not required for obtaining the object distance.<br>
Also, the parallax between ommatidium images may be detected<br>
using the detection method as is described above.<br>
According to a modified example of the embodiment<br>
shown in FIG. 12, the correction processing part for<br>
correcting image degradation caused by the lens 3a (MTF<br>
correction) may be arranged to come after the post processing<br>
unit 103 rather than before the preprocessing unit 101.<br>
Specifically, a correction operation unit may be arranged<br>
between the post processing unit 103 and the authentication<br>
operation unit 104, and a memory for storing optical transfer<br>
function data may be connected to this correction operation<br>
unit so that image degradation correction (MTF correction) may.<br>
be performed on a reconstructed single image using the optical<br>
transfer function data associated with the object distance<br>
detected by the object distance detecting unit 301.! It is<br>
noted that correction process with respect to a single image<br>
may be completed by performing one correction process sequence<br>
on the reconstructed single image so that operation  time may<br>
be reduced compared to the case of performing correction on<br><br>
each ommatidium image. However, it is noted that sijnce the<br>
optical transfer function data to be used in the correction<br>
process pertain to the individual lenses 3a and are intended<br>
to be used for correcting the individual ommatidium images,<br>
when the correction process is performed on the single image<br>
rather than the individual ommatidium images, correction<br>
errors may inevitably be increased compared to the case of<br>
performing correction on the individual ommatidium images.<br>
(Fourth Embodiment)<br>
FIG. 13 is a diagram showing an image input<br>
apparatus and a personal authentication apparatus according to<br>
a fourth embodiment of the present invention. According to<br>
the present embodiment, a bias component removing unit 401 and<br>
a control unit 401 for controlling drive operations of the<br>
light source 6 are used to obtain compound-eye image data<br>
having bias components of external light other than the near<br>
infrared light irradiated from the light source 6 (bias light)<br>
removed therefrom. Also, an image pickup drive unit 403 is<br>
j<br>
used for driving the image pickup device 5. It is noted that<br>
other features of the present embodiment may be identical to<br>
any one of the previously described embodiments or<br>
modifications thereof so that illustrations of such features<br>
i<br>
are omitted in FIG. 13. Also, it is noted that although a<br>
band pass filter 7 is included in FIG. 13, such a component<br>
may alternatively be omitted. In the case of omitting the<br><br>
band pass filter 7, a transparent plate for adjusting the<br>
object distance and/or protecting the lens array 3 may be<br>
arranged at the position of the band pass filter 7, for<br>
example. Also, it is noted that although the image pickup<br>
drive unit 403 is not shown in the drawings representing the<br>
previously-described embodiments, illustrations of such a<br>
component are merely omitted in these drawings and means for<br>
driving the image pickup device 5 is used in these elmbodiments<br>
as well.<br>
(Example 1)<br>
According to a first exemplary implementation of<br>
the present embodiment, the control unit 402 turns on/off a<br>
drive current for the light source to control the light source<br>
6 to intermittently emit light. In other words, light<br>
emission of the light source 6 is intermittently turned on/off.<br>
In this case, compound-eye images at emission-on time and<br>
emission-off time of the light source 6 are captured by the<br>
j<br>
image pickup device 5, and timing signals in synch With the<br>
emission on and off times of the light source 6 are supplied<br>
to the image pickup drive unit 403 and the bias component<br>
removing unit 401 by the control unit 402 in order to control<br>
the bias component removing unit 401 to acquire these<br>
compound-eye images. The bias component removing unit 401<br>
obtains a difference between the compound-eye image captured<br>
at the light source 6 emission-on time and the compound-eye<br><br>
image captured at the light source 6 emission-off time to<br>
remove bias components of external light and generate a<br>
compound-eye image that is made up of light components of<br>
light emitted from the light source 6.<br>
i<br>
(Example 2)<br>
According to a second exemplary implementation of<br>
the present embodiment, the control unit 402 modulates the<br>
drive current for the light source 6 into a sine wave so that<br>
the intensity of the near infrared light irradiated from the<br>
light source 6 may be changed according to the sine wave.<br>
Since external light (bias light) is superposed on t.he near<br>
infrared light, provided that such lights are directly<br>
incident on the image pickup device 5, light intensity<br>
modulation as is shown in FIG. 9 may be successively obtained<br>
for every pixel. It is noted that the intensity of the pixel<br>
at a given image position (x, y) within an image may be<br>
expressed by the below formula (5).<br>
I(x,y) = A(x,y) + B(x,y)-cos{Φ(x,y)}	(5)<br>
In the above formula (5), I denotes the intensity<br>
of the given pixel, A denotes the intensity of the external<br>
light, namely, the bias light, B denotes the modulation<br>
amplitude of the light irradiated by the light source 6, and Φ<br>
denotes the modulation phase of the light irradiated by the<br><br>
light source 6.<br>
When the modulation period is divided into four<br>
time intervals and images are captured at time points tl, t2,<br>
t3, and t4 as is shown in FIG. 9, for example, the image<br>
intensity of the images obtained at the above time points may<br>
be expressed by the below formulae (6)-(9)<br><br>
The modulation amplitude of the light irradiated by<br>
the light source 6 may be obtained by the below formula (10)<br>
using the above formulae (6)-(9) . Thus, by computing the<br>
below formula (10) using the images captured at the above time<br>
points, the bias component removing unit 401 may generate a<br>
compound-eye image having bias components removed therefrom.<br><br><br>
It is noted that in the above-described example,<br>
the modulation period is divided into four and images are<br>
sampled at the divided time intervals; however, in other<br>
alternative implementations, the sampling frequency within the<br>
modulation period may be increased, or discrete Fourier<br>
transform may be used in the computation for extracting the<br>
modulation amplitude, for example. It is noted that when the<br>
sampling frequency is increased, bias components may be more<br>
accurately removed.<br>
(Fifth Embodiment)<br>
The overall imaging optical system of a personal<br>
authentication apparatus according to an embodiment of the<br>
present invention may be arranged into a relatively thin<br>
structure so that the authentication apparatus may be readily<br>
installed in various electronic apparatuses. In this way,<br>
operations of the electronic apparatus may be controlled<br>
according to the authentication result obtained by the<br>
authentication apparatus and usage of the electronic apparatus<br>
may be limited to certain users, for example.<br>
FIGS. 16A and 16B are diagrams showing a miniature<br>
information terminal (e.g., PDA) and a laptop computer as<br>
exemplary electronic apparatuses each having a personal<br>
authentication apparatus 500 according to an embodiment of the<br>
present invention installed therein. In the examples of FIGS.<br>
16A and 16B, only a portion of the personal authentication<br><br>
apparatus 500 on which a finger is to be placed (e.g., portion<br>
of the optical band pass filter 7) is exposed. A person that<br>
wishes to use the information terminal or the laptop computer<br>
may place his/her finger on the exposed portion of the<br>
personal authentication apparatus 500 to have the vein pattern<br>
of his/her finger read and authenticated by the personal<br>
authentication apparatus 500. The electronic apparatus (i.e.,<br>
the information terminal or the laptop computer) may control<br>
user access by allowing the person to login when the person is<br>
authenticated as a registered user while refusing tc let the<br>
person login when the person is not authenticated as a<br>
registered user.<br>
(Miscellaneous)<br>
According to certain embodiments, the<br>
reconstruction operation unit, the correction operation unit,<br>
the object distance detecting unit, the bias component<br>
removing unit, and the authentication processing unit of used<br>
in the above-described first though fourth embodiments may be<br>
configured, at least in part, by software.<br>
Also, the above-described operations of the image<br>
input apparatus according to the first through fourth<br>
embodiments may be construed as image input methods according<br>
to embodiments of the present invention.<br>
In the following, overall descriptions of possible<br>
embodiments of the present invention and their advantageous<br><br>
effects are given.<br>
According to a first aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facing the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the compound-eye image formed<br>
by the imaging unit using a parallax between the ommatidium<br>
images, the reconstructed single image being input as the<br>
image of the object.<br>
According to a second aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus comprising:<br><br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power at a side facing the living body<br>
and a face with positive power at a side facing an image<br>
surface;<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the ommatidium<br>
images of the compound-eye image formed by the imaging unit<br>
based on optical transfer function data pertaining to the<br>
lenses that are prepared beforehand and generate a corrected<br>
compound-eye image; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the corrected compound-eye<br>
image generated by the correction unit using a parallax<br>
between the ommatidium images, the reconstructed single image<br>
being input as the image of the object.<br>
According to a third aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br><br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facir.g the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the :.mage<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the compound-eye image formed<br>
by the imaging unit using a parallax between the omnatidium<br>
images; and<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the reconstructed<br>
single image based on optical transfer function data<br>
pertaining to the lenses that are prepared beforehand, the<br>
corrected single image being input as the image of the object.<br>
According to a fourth aspect of the present<br>
invention, the above-described image input apparatuses<br>
according to the first through third aspects of the present<br>
invention may further include:<br><br>
an optical band pass filter that is configured to<br>
pass light having a wavelength within a predetermined<br>
wavelength range including a wavelength of the near infrared<br>
light irradiated by the light source, the optical band pass<br>
filter being arranged at the living body side or the: image<br>
surface side of the lens array.<br>
According to a fifth aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a control unit that controls light irradiation by<br>
the light source to be turned on/off;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facing the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a bias component removing unit that is configured<br>
to obtain a difference between a compound-eye image formed by<br><br>
the imaging unit when the light source is turned on and a<br>
compound-eye image formed by the imaging unit when the light<br>
source is turned off and generate a bias-removed compound-eye<br>
image having a bias component of light other than the near<br>
infrared light irradiated by the light source removed<br>
therefrom; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the bias-removed compound-eye<br>
image generated by the bias component removing unit using a<br>
parallax between the ommatidium images, the reconstructed<br>
single image being input as the image of the object.<br>
According to a sixth aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus comprising:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a control unit that controls light irradiation by<br>
the light source to be turned on/off;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power at a side facing the living body<br>
and a face with positive power at a side facing an image<br>
surface;<br>
an imaging unit that is arranged on the image<br><br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a bias component removing unit that is configured<br>
to obtain a difference between a compound-eye image formed by<br>
the imaging unit when the light source is turned on and a<br>
compound-eye image formed by the imaging unit when the light<br>
source is turned off and generate a bias-removed conpound-eye<br>
image having a bias component of light other than tne near<br>
infrared light irradiated by the light source removed<br>
therefrom;<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the ommatidium<br>
images of the bias-removed compound-eye image generated by the<br>
bias component removing unit based on optical transfer<br>
function data pertaining to the lenses that are prepared<br>
beforehand and generate a corrected compound-eye image; and<br>
a reconstruction unit that is configured to .<br>
reconstruct a single image from the corrected compound-eye<br>
image generated by the correction unit using a parallax<br>
between the ommatidium images, the reconstructed single image<br>
being input as the image of the object.<br>
According to a seventh aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br><br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a control unit that controls light irradiation by<br>
the light source to be turned on/off;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facing the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a bias component removing unit that is configured<br>
to obtain a difference between a compound-eye image formed by<br>
the imaging unit when the light source is turned on and a<br>
compound-eye image formed by the imaging unit when the light<br>
source is turned off and generate a bias-removed compound-eye<br>
image having a bias component of light other than the near<br>
infrared light irradiated by the light source removed<br>
therefrom;<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the bias-removed compound-eye<br>
image formed by the bias component removing unit using a<br><br>
parallax between the ommatidium images; and<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the reconstructed<br>
single image based on optical transfer function data<br>
pertaining to the lenses that are prepared beforehand, the<br>
corrected single image being input as the image of the object.<br>
According to an eighth aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a control unit that changes an intensity of the<br>
near infrared light irradiated on the living body by the light<br>
source into a sine wave;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facing the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a bias component removing unit that is configured<br><br>
to perform computation processes on plural compound-eye images<br>
formed by the imaging unit at plural different phase points<br>
within a sine wave change period of the intensity of the near<br>
infrared light irradiated on the living body by the light<br>
source and generate a bias-removed compound-eye image having a<br>
bias component of light other than the near infrared light<br>
irradiated by the light source removed therefrom; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the bias-removed compound-eye<br>
image generated by the bias component removing unit using a<br>
parallax between the ommatidium images, the reconstructed<br>
single image being input as the image of the object.<br>
According to a ninth aspect of the present<br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus comprising:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a control unit that changes an intensity of the<br>
near infrared light irradiated on the living body by the light<br>
source into a sine wave;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power at a side facing the living body<br>
and a face with positive power at a side facing an image<br><br>
surface;<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a bias component removing unit that is configured<br>
to perform computation processes on plural compound-eye images<br>
formed by the imaging unit at plural different phase points<br>
within a sine wave change period of the intensity of the near<br>
infrared light irradiated on the living body by the light<br>
source and generate a bias-removed compound-eye image having a<br>
bias component of light other than the near infrared light<br>
irradiated by the light source removed therefrom;<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the ommatidium<br>
images of the bias-removed compound-eye image generated by the<br>
bias component removing unit based on optical transfer<br>
function data pertaining to the lenses that are prepared<br>
beforehand and generate a corrected compound-eye image; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the corrected compound-eye<br>
image generated by the correction unit using a parallax<br>
between the ommatidium images, the reconstructed single image<br>
being input as the image of the object.<br>
According to a tenth aspect of the present<br><br>
invention, an image input apparatus is provided that inputs an<br>
image of an object residing within a living body, the<br>
apparatus including:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a control unit that changes an intensity of the<br>
near infrared light irradiated on the living body by the light<br>
source into a sine wave;<br>
a lens array that is arranged at a position facing<br>
the living body and includes plural lenses each having a face<br>
with zero or negative power arranged at a side facing the<br>
living body and a face with positive power arranged at a side<br>
facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a bias component removing unit that is configured<br>
to perform computation processes on plural compound-eye images<br>
formed by the imaging unit at plural different phase points<br>
within a sine wave change period of the intensity of the near<br>
infrared light irradiated on the living body by the light<br>
source and generate a bias-removed compound-eye image having a<br>
bias component of light other than the near infrared light<br>
irradiated by the light source removed therefrom;<br><br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the bias-removed compound-eye<br>
image formed by the bias component removing unit using a<br>
parallax between the ommatidium images; and<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the reconstructed<br>
single image based on optical transfer function data<br>
pertaining to the lenses that are prepared beforehand, the<br>
corrected single image being input as the image of the object.<br>
the image input apparatus as claimed in claim 1, further<br>
comprising:<br>
a transparent plate for adjusting a distance<br>
between the object and the lens array which transparent plate<br>
is arranged at the living body side of the lens array.<br>
According to an eleventh aspect of the present<br>
invention, the above-described image input apparatuses<br>
according to the second, third, sixth, seventh, ninth and<br>
tenth aspects of the present invention may further include:<br>
a distance detecting unit that is configured to<br>
detect a distance between the object and the lens array; and<br>
the correction unit may select a set of optical<br>
transfer function data from the optical transfer function data<br>
pertaining to the lenses that are prepared beforehand<br>
according to the distance detected by the distance detecting<br><br>
unit and use the selected set of optical transfer function<br>
data for correcting the image degradation caused by the lenses.<br>
According to a twelfth aspect of the present<br>
invention, in the above-described image input apparatus<br>
according to the eleventh aspect,<br>
the distance detecting unit may detect the distance<br>
based on the parallax between the ommatidium images of the<br>
compound-eye image formed by the imaging unit.<br>
According to a thirteenth aspect of the present<br>
invention, the above-described image input apparatuses<br>
according to the first through twelfth aspects may further<br>
include:<br>
a transparent plate for adjusting a distance<br>
between the object and the lens array which transparent plate<br>
is arranged at the living body side of the lens array.<br>
According to a fourteenth embodiment of the present<br>
invention, the above described image input apparatuses<br>
according to the first through thirteenth aspects may further<br>
include:<br>
a light shielding member that prevents occurrence<br>
of crosstalk between the lenses of the lens array at the image<br>
surface side.<br>
According to a fifteenth aspect of the present<br>
invention, a personal authentication apparatus is provided<br>
that includes any one of the image input apparatuses according<br><br>
to the first through fourteenth aspects of the present<br>
invention, and an authentication unit that performs personal<br>
authentication based on the image of the object input by the<br>
image inputting apparatus.<br>
According to a sixteenth aspect of the present<br>
invention, an electronic apparatus is provided that includes<br>
the above-described personal authentication apparatus<br>
according to the fifteenth aspect of the present invention,<br>
the operations of the electronic apparatus being controlled<br>
according to an authentication result obtained by the personal<br>
authentication apparatus.<br>
According to a seventeenth aspect of the present<br>
invention, an image input method is provided for inputting an<br>
image of an object residing within a living body, the method<br>
including the steps of:<br>
using an imaging optical system that includes<br>
a light source that irradiates near infrared<br>
light on the living body;<br>
a lens array that is arranged at a position<br>
facing the living body and includes a plurality of lenses,<br>
each of the lenses having a face with zero or negative power<br>
at a side facing the living body and a face with positive<br>
power at a side facing an image surface; and<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br><br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
correcting image degradation caused by the lenses<br>
in the ommatidium images of the compound-eye image formed by<br>
the imaging unit based on optical transfer function data<br>
pertaining to the lenses that are prepared beforehand to<br>
generate a corrected compound-eye image;<br>
reconstructing a single image from the corrected<br>
compound-eye image using a parallax between the ommatidium<br>
images; and<br>
inputting the reconstructed single image as the<br>
image of the object.<br>
According to an eighteenth aspect of the present<br>
invention, an image input method is provided for inputting an<br>
image of an object residing within a living body, the method<br>
including the steps of:<br>
using an imaging optical system that includes<br>
a light source that irradiates near infrared<br>
light on the living body;<br>
a lens array that is arranged at a position<br>
facing the living body and includes a plurality of lenses,<br>
each of the lenses having a face with zero or negative power<br>
at a side facing the living body and a face with positive<br>
power at a side facing an image surface; and<br>
an imaging unit that is arranged on the image<br><br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
controlling the light source to irradiate light<br>
intermittently;<br>
obtaining a difference between a compound-eye image<br>
formed by the imaging unit when the light source is turned on<br>
and a compound-eye image formed by the imaging unit when the<br>
light source is turned off to generate a bias-removed<br>
compound-eye image having bias components of light other than<br>
the near infrared light irradiated by the light source removed<br>
therefrom;<br>
correcting image degradation caused by the lenses<br>
in the ommatidium images of the bias-removed compound-eye<br>
image based on optical transfer function data pertaining to<br>
the lenses that are prepared beforehand to generate a<br>
corrected compound-eye image;<br>
reconstructing a single image from the corrected<br>
compound-eye image using a parallax between the ommatidium<br>
images; and<br>
inputting the reconstructed single image as the<br>
image of the object.<br>
According to a nineteenth aspect of the present<br>
invention, an image input method is provided for inputting an<br>
image of an object residing within a living body, the method<br><br>
including the steps of:<br>
using an imaging optical system that includes<br>
a light source that irradiates near infrared<br>
light on the living body;<br>
a lens array that is arranged at a position<br>
facing the living body and includes a plurality of lenses,<br>
each of the lenses having a face with zero or negative power<br>
at a side facing the living body and a face with positive<br>
power at a side facing an image surface; and<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
changing the intensity of the near infrared light<br>
irradiated by the light source into a sine wave;<br>
performing computation processes on plural<br>
compound-eye images formed by the imaging unit at plural<br>
different phase points within a sine wave change period of the<br>
intensity of the near infrared light irradiated by the light<br>
source to generate a bias-removed compound-eye image having<br>
bias components of light other than the near infrared light<br>
irradiated by the light source removed therefrom;<br>
correcting image degradation caused by the lenses<br>
in the ommatidium images of the bias-removed compound-eye<br>
image based on optical transfer function data pertaining to<br><br>
the lenses that are prepared beforehand to generate a<br>
corrected compound-eye image;<br>
reconstructing a single image from the corrected<br>
compound-eye image using a parallax between the ommatidium<br>
images; and<br>
inputting the reconstructed single image as the<br>
image of the object.<br>
According to the first through fourteenth aspects<br>
of the present invention, the imaging optical system including<br>
the light source, the lens array, and the imaging unit may be<br>
arranged into a relatively thin and simple structure so that<br>
the overall thickness of the image input apparatus may be<br>
reduced, for example.<br>
Also, since near infrared light, which is absorbed<br>
at a high absorption rate by an imaging obj ect such as veins<br>
residing within the living body but is hardly absorbed by<br>
portions of the living body other than the imaging object, is<br>
irradiated on the living body by the light source, a clear<br>
image of the imaging object such as veins may be formed. Also,<br>
it is noted that in a compound-eye optical system, normally, a<br>
face of a lens of a lens array with positive power (e.g.,<br>
convex face of a plano-convex lens) is arranged to face the<br>
imaging object side. However, in embodiments of the present<br>
invention, a lens having a face with zero or negative power<br>
arranged at the object side and a face with positive power<br><br>
arranged at the image surface side (e.g., plano-concave lens<br>
having a concave face facing the image surface side) is used<br>
as the lenses of a lens array so that even when the object<br>
distance is small, variations in the MTF due to variations in<br>
the object visual angle (angle of incidence of light incident<br>
to the lens) may be reduced, and occurrence of in-plane errors<br>
such as distortions and curvatures may be prevented, for<br>
example. Further, it is noted that the object distance may<br>
vary depending on the skin thickness of each person, for<br>
example. However, the process of reconstructing a single<br>
image from a compound-eye image using the parallax between<br>
ommatidium images according to embodiments of the present<br>
invention may easily adapt to variations in the object<br>
distance and compensate for a decrease in the image resolution,<br>
for example. In this way, a high quality image of an imaging<br>
object such as veins within a living body may be input.<br>
Further, by correcting a compound-eye image by<br>
performing correction processes on the individual ommatidium<br>
images of the compound-eye image based on the optical transfer<br>
function data of the lenses as in the second, sixth, and ninth<br>
aspects of the present invention, or correcting a single image<br>
reconstructed from a compound-eye image based on such optical<br>
transfer function data as in the third, seventh, and tenth<br>
aspects of the present invention, an even higher quality image<br>
in which image degradation caused by the lenses are corrected<br><br>
may be input. Also, by enabling selection of the optical<br>
transfer function data to be used in the image degradation<br>
correction process according to the object distance as in the<br>
eleventh aspect of the present invention, image degradation<br>
correction may be accurately performed even when the object<br>
distance varies. In this way, influences caused by<br>
differences in the object distance may be reduced, and the<br>
input image quality may be further improved. Also, by using a<br>
lens having a face with zero or negative power arranged at the<br>
object side and a face with positive power arranged at the<br>
image surface side as the lenses of the lens array, variations<br>
in the MTF due to variations in the object visual angle (angle<br>
of incidence of light incident to the lens) may be reduced so<br>
that the image degradation correction process may be<br>
simplified, for example.<br>
By arranging an optical band pass filter that only<br>
passes light having a wavelength within a predetermined<br>
wavelength range including the wavelength of the near infrared<br>
light irradiated by the light source as in the fourth aspect<br>
of the present invention, or by removing bias components<br>
through light source modulation and computation processes as<br>
in the fifth through tenth aspects of the present invention,<br>
influences of external light, namely, light other than the<br>
irradiation light from the light source, may be reduced, and a<br>
stable image of the object may be input, for example.<br><br>
In a case where the object is positioned too close<br>
to the lens array so that overlapping image regions do not<br>
exist between adjacent ommatidium images, image reconstruction<br>
using the parallax between the ommatidium images may not be<br>
effectively performed. Such a problem may be prevented by<br>
arranging a transparent plate for adjusting the distance<br>
between the object and the lens array as in the thirteenth<br>
aspect of the present invention, for example.<br>
Also, by including a light shielding member as in<br>
the fourteenth aspect of the present invention, cross talk<br>
between the lenses of the lens array at the image surface side<br>
may be prevented so that noise such as ghosts and flares may<br>
be reduced in the input image, for example.<br>
According to the fifteenth aspect of the present<br>
invention, by using a thin image input apparatus with a simple<br>
configuration according to an aspect of the present invention,<br>
a thin personal authentication apparatus that is suitable for<br>
installation in an electronic apparatus may be realized, for<br>
example.<br>
According to the sixteenth aspect of the present<br>
invention, by installing a personal authentication apparatus<br>
according to an aspect of the present invention into an<br>
electronic apparatus, enlargement of the electronic apparatus<br>
due to installation of the personal authentication apparatus<br>
may not be necessary, for example.<br><br>
Also, login access to an electronic apparatus such<br>
as a miniature information terminal or a laptop computer may-<br>
be controlled according to authentication results obtained by<br>
the personal authentication apparatus so that security of the<br>
electronic apparatus may be improved, for example.<br>
According to the seventeenth through nineteenth<br>
aspects of the present invention, advantageous effects similar<br>
to those obtained in the first through fourteenth aspects of<br>
the present invention may be obtained. For example, by<br>
implementing an image input method according an aspect of the<br>
present invention, a high quality image of an object such as<br>
veins within a living body may be input, and/or a stable image<br>
that is not readily influenced by light other than irradiation<br>
light from the light source may be input.<br>
Although the present invention is shown and<br>
described with respect to certain preferred embodiments, it is<br>
obvious that equivalents and modifications will occur to<br>
others skilled in the art upon reading and understanding the<br>
specification. The present invention includes all such<br>
equivalents and modifications, and is limited only by the<br>
scope of the claims.<br>
The present application is based on and claims the<br>
benefit of the earlier filing date of Japanese Patent<br>
Application No. 2006-278423 filed on October 12, 2006, the<br>
entire contents of which are hereby incorporated by reference.<br><br>
CLAIMS<br>
1. An image input apparatus that inputs an image of<br>
an object residing within a living body, the apparatus<br>
comprising:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes a plurality of lenses, each of<br>
the lenses having a face with zero or negative power arranged<br>
at a side facing the living body and a face with positive<br>
power arranged at a side facing an image surface;<br>
an imaging unit that is arranged at the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the compound-eye image formed<br>
by the imaging unit using a parallax between the ommatidium<br>
images, said reconstructed single image being input as the<br>
image of the object.<br>
2. The image input apparatus as claimed in claim 1,<br>
further comprising:<br>
an optical band pass filter that is configured to<br><br>
pass light having a wavelength within a predetermined<br>
wavelength range including a wavelength of the near infrared<br>
light irradiated by the light source, said optical band pass<br>
filter being arranged at the living body side or the image<br>
surface side of the lens array.<br>
3.	The image input apparatus as claimed in claim 1,<br>
further comprising:<br>
a transparent plate for adjusting a distance<br>
between the object and the lens array which transparent plate<br>
is arranged at the living body side of the lens array.<br>
4.	The image input apparatus as claimed in claim 1,<br>
further comprising:<br>
a light shielding member that prevents occurrence<br>
of crosstalk between the lenses of the lens array at the image<br>
surface side.<br>
5.	An image input apparatus that inputs an image of<br>
an object residing within a living body, the apparatus<br>
comprising:<br>
a light source that irradiates near infrared light<br>
on the living body;<br>
a lens array that is arranged at a position facing<br>
the living body and includes a plurality of lenses, each of<br><br>
the lenses having a face with zero or negative power at a side<br>
facing the living body and a face with positive power at a<br>
side facing an image surface;<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
a correction unit that is configured to correct<br>
image degradation caused by the lenses in the ommatidium<br>
images of the compound-eye image formed by the imaging unit<br>
based on optical transfer function data pertaining to the<br>
lenses that are prepared beforehand and generate a corrected<br>
compound-eye image; and<br>
a reconstruction unit that is configured to<br>
reconstruct a single image from the corrected compound-eye<br>
image generated by the correction unit using a parallax<br>
between the ommatidium images, said reconstructed single image<br>
being input as the image of the object.<br>
6. The image input apparatus as claimed in claim 5,<br>
further comprising:<br>
an optical band pass filter that is configured to<br>
pass light having a wavelength within a predetermined<br>
wavelength range including a wavelength of the near infrared<br>
light irradiated by the light source, said optical band pass<br><br>
filter being arranged at the living body side or the image<br>
surface side of the lens array.<br>
7.	The image input apparatus as claimed in claim 5,<br>
further comprising:<br>
a distance detecting unit that is configured to<br>
detect a distance between the object and the lens array;<br>
wherein the correction unit selects a set of<br>
optical transfer function data from the optical transfer<br>
function data pertaining to the lenses that are prepared<br>
beforehand according to the distance detected by the distance<br>
detecting unit and uses the selected set of optical transfer<br>
function data for correcting the image degradation caused by<br>
the lenses.<br>
8.	The image input apparatus as claimed in claim 7,<br>
wherein<br>
the distance detecting unit detects the distance<br>
based on the parallax between the ommatidium images of the<br>
compound-eye image formed by the imaging unit.<br>
9.	The image input apparatus as claimed in claim 5,<br>
further comprising:<br>
a transparent plate for adjusting a distance<br>
between the object and the lens array which transparent plate<br><br>
is arranged at the living body side of the lens array.<br>
10. The image input apparatus as claimed in claim 5,<br>
further comprising:<br>
a light shielding member that prevents occurrence<br>
of crosstalk between the lenses of the lens array at the image<br>
surface side.<br>
11. An image input method for inputting an image of<br>
an object residing within a living body, the method comprising<br>
the steps of:<br>
using an imaging optical system that includes<br>
a light source that irradiates near infrared<br>
light on the living body;<br>
a lens array that is arranged at a position<br>
facing the living body and includes a plurality of lenses,<br>
each of the lenses having a face with zero or negative power<br>
at a side facing the living body and a face with positive<br>
power at a side facing an image surface; and<br>
an imaging unit that is arranged on the image<br>
surface side of the lens array and is configured to form a<br>
compound-eye image corresponding to a collection of ommatidium<br>
images formed by the lenses of the lens array;<br>
correcting image degradation caused by the lenses<br>
in the ommatidium images of the compound-eye image formed by<br><br>
the imaging unit based on optical transfer function data<br>
pertaining to the lenses that are prepared beforehand to<br>
generate a corrected compound-eye image;<br>
reconstructing a single image from the corrected<br>
compound-eye image using a parallax between the ommatidium<br>
images; and<br>
inputting the reconstructed single image as the<br>
image of the object.<br><br>
An image input apparatus that inputs an image of an<br>
object residing within a living body is disclosed. The image<br>
input apparatus includes a light source that irradiates near<br>
infrared light on the living body, a lens array arranged at a<br>
position facing the living body and including plural lenses<br>
each having a face with zero or negative power arranged at a<br>
side facing the living body and a face with positive power<br>
arranged at a side facing an image surface, an imaging unit<br>
arranged at the image surface side of the lens array that<br>
forms a compound-eye image corresponding to a collection of<br>
ommatidium images formed by the lenses of the lens array, and<br>
a reconstruction unit that reconstructs a single image from<br>
the compound-eye image using a parallax between the ommatidium<br>
images. The reconstructed single image is input as the image<br>
of the object.</td>
			</tr>
		</table>	
		<br>
		<h3>Documents:</h3>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1hYnN0cmFjdC5wZGY=" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-abstract.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1jbGFpbXMucGRm" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-claims.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1jb3JyZXNwb25kZW5jZSBvdGhlcnMucGRm" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-correspondence others.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1kZXNjcmlwdGlvbiBjb21wbGV0ZS5wZGY=" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-description complete.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1kcmF3aW5ncy5wZGY=" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-drawings.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1mb3JtIDEucGRm" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-form 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1mb3JtIDMucGRm" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-form 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1mb3JtIDUucGRm" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-form 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1pbnRlcm5hdGlvbmFsIHB1YmxpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-international publication.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1pbnRlcm5hdGlvbmFsIHNlYXJjaCByZXBvcnQucGRm" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-international search report.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1wY3QgcHJpb3JpdHkgZG9jdW1lbnQgbm90aWZpY2F0aW9uLnBkZg==" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-pct priority document notification.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MDIxMTEta29sbnAtMjAwOC1wY3QgcmVxdWVzdCBmb3JtLnBkZg==" target="_blank" style="word-wrap:break-word;">02111-kolnp-2008-pct request form.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgwOS0xMC0yMDEzKS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(09-10-2013)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgxMC0wMS0yMDE0KS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(10-01-2014)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgxOC0wNi0yMDE0KS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(18-06-2014)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyMS0wMy0yMDEzKS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(21-03-2013)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyMS0wMy0yMDEzKS1GT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(21-03-2013)-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1BQlNUUkFDVC5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1BTk5FWFVSRSBUTyBGT1JNIDMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-ANNEXURE TO FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1DTEFJTVMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1DT1JSRVNQT05ERU5DRS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1ERVNDUklQVElPTiAoQ09NUExFVEUpLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1EUkFXSU5HUy5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1GT1JNLTEucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-FORM-1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1GT1JNLTEzLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-FORM-13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1GT1JNLTIucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-FORM-2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1PVEhFUlMuMS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-OTHERS.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1PVEhFUlMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LSgyOS0wNS0yMDE0KS1QRVRJVElPTiBVTkRFUiBSVUxFIDEzNy5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-(29-05-2014)-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUFTU0lHTk1FTlQtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-ASSIGNMENT-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUFTU0lHTk1FTlQucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-ASSIGNMENT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUNBTkNFTExFRCBQQUdFUy5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-CANCELLED PAGES.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUNPUlJFU1BPTkRFTkNFIDEuMS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-CORRESPONDENCE 1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUNPUlJFU1BPTkRFTkNFLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-CORRESPONDENCE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUZPUk0gMTMucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-FORM 13.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUZPUk0gMTgtMS4xLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-FORM 18-1.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1rb2xucC0yMDA4LWZvcm0gMTgucGRm" target="_blank" style="word-wrap:break-word;">2111-kolnp-2008-form 18.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUZPUk0gMy4xLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-FORM 3.1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtQUJTVFJBQ1QucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-ABSTRACT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtQ0xBSU1TLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-CLAIMS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtREVTQ1JJUFRJT04gKENPTVBMRVRFKS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-DESCRIPTION (COMPLETE).pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtRFJBV0lOR1MucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-DRAWINGS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtRk9STSAxLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-FORM 1.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtRk9STSAyLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-FORM 2.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtRk9STSAzLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-FORM 3.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtRk9STSA1LnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-FORM 5.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUdSQU5URUQtU1BFQ0lGSUNBVElPTi1DT01QTEVURS5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-GRANTED-SPECIFICATION-COMPLETE.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUlOVEVSTkFUSU9OQUwgUFVCTElDQVRJT04ucGRm" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-INTERNATIONAL PUBLICATION.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LUlOVEVSTkFUSU9OQUwgU0VBUkNIIFJFUE9SVCAmIE9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-INTERNATIONAL SEARCH REPORT &amp; OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LU9USEVSUy5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-OTHERS.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LVBBLnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-PA.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LVBFVElUSU9OIFVOREVSIFJVTEUgMTM3LnBkZg==" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-PETITION UNDER RULE 137.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=MjExMS1LT0xOUC0yMDA4LVJFUExZIFRPIEVYQU1JTkFUSU9OIFJFUE9SVC5wZGY=" target="_blank" style="word-wrap:break-word;">2111-KOLNP-2008-REPLY TO EXAMINATION REPORT.pdf</a></p>
				<p><a href="http://ipindiaonline.gov.in/patentsearch/GrantedSearch/pdfviewer.aspx?AppNo=YWJzdHJhY3QtMjExMS1rb2xucC0yMDA4LmpwZw==" target="_blank" style="word-wrap:break-word;">abstract-2111-kolnp-2008.jpg</a></p>
		<br>
		<div class="pull-left">
			<a href="263377-thiophene-compounds-and-thrombopoietin-receptor-activators.html">&laquo; Previous Patent</a>
		</div>
		<div class="pull-right">
			<a href="263379-linear-time-code-receiver.html">Next Patent &raquo;</a>
		</div>			
	</div><!-- /span8 -->
	<div class="span4">
		<div class="well infobox">
			<table class="table table-condensed">
				<tr>
					<th>Patent Number</th>
					<td>263378</td>
				</tr>
				<tr>
					<th>Indian Patent Application Number</th>
					<td>2111/KOLNP/2008</td>
				</tr>
				<tr>
					<th>PG Journal Number</th>
					<td>44/2014</td>
				</tr>
				<tr>
					<th>Publication Date</th>
					<td>31-Oct-2014</td>
				</tr>
				<tr>
					<th>Grant Date</th>
					<td>24-Oct-2014</td>
				</tr>
				<tr>
					<th>Date of Filing</th>
					<td>26-May-2008</td>
				</tr>
				<tr>
					<th>Name of Patentee</th>
					<td>RICOH COMPANY, LTD.</td>
				</tr>
				<tr>
					<th>Applicant Address</th>
					<td>3-6, NAKAMAGOME 1-CHOME, OHTA-KU TOKYO</td>
				</tr>
				<tr>
					<td colspan=2>
								<h5>Inventors:</h5>
								<table class="table">
									<tr>
										<th>#</th>
										<th>Inventor's Name</th>
										<th>Inventor's Address</th>
									</tr>

										<tr>
											<td>1</td>
											<td>MORITA NOBUHIRO</td>
											<td>11-16-504, MINAMIRINKAN 2-CHOME, YAMATO-SHI, KANAGAWA 242-0006</td>
										</tr>
										<tr>
											<td>2</td>
											<td>ISEKI TOSHIYUKI</td>
											<td>4-1, AIZAWA 2-CHOME, SEYA-KU, YOKOHAMA-SHI, KANAGAWA 246-0013</td>
										</tr>
										<tr>
											<td>3</td>
											<td>NASUKAWA, TOSHIMICHI</td>
											<td>C/O RICOH OPTICAL INDUSTRIES CO., LTD., 10-109, OHHATA, HANAMAKI-SHI, IWATE 025-0303</td>
										</tr>
										<tr>
											<td>4</td>
											<td>KOSUGA SHINICHI</td>
											<td>C/O RICOH OPTICAL INDUSTRIES CO., LTD., 10-109, OHHATA, HANAMAKI-SHI, IWATE 025-0303</td>
										</tr>
										<tr>
											<td>5</td>
											<td>TAKAHASHI HIROAKI</td>
											<td>C/O RICOH OPTICAL INDUSTRIES CO., LTD., 10-109, OHHATA, HANAMAKI-SHI, IWATE 025-0303</td>
										</tr>
										<tr>
											<td>6</td>
											<td>TAKAHASHI AKIRA</td>
											<td>C/O RICOH OPTICAL INDUSTRIES CO., LTD., 10-109, OHHATA, HANAMAKI-SHI, IWATE 025-0303</td>
										</tr>
										<tr>
											<td>7</td>
											<td>YAMANAKA YUJI</td>
											<td>5-8-109, SAIWAICHO, ATSUGI-SHI, KANAGAWA 243-0012</td>
										</tr>
								</table>
					</td>
				</tr>
				<tr>
					<th>PCT International Classification Number</th>
					<td>G06T 1/00,A61B 1/117</td>
				</tr>
				<tr>
					<th>PCT International Application Number</th>
					<td>PCT/JP2007/070025</td>
				</tr>
				<tr>
					<th>PCT International Filing date</th>
					<td>2007-10-05</td>
				</tr>
				<tr>
					<td colspan=2>
						<h5>PCT Conventions:</h5>
						<table class="table">
							<tr>
								<th>#</th>
								<th>PCT Application Number</th>
								<th>Date of Convention</th>
								<th>Priority Country</th>
							</tr>

								<tr>
									<td>1</td>
									<td>2006-278423</td>
									<td>2006-10-12</td>
								    <td>Japan</td>
								</tr>

						</table>
					</td>
				</tr>
			</table>
		</div><!-- /well -->
	</div><!-- /span4 -->
</div><!-- /row-fluid -->

        </div>

      </div><!--/row-->

      <footer class="footer">

        <style>
        .allindianpatents-footer { width: 320px; height: 50px; }
        @media(min-width: 500px) { .allindianpatents-footer { width: 468px; height: 60px; } }
        @media(min-width: 800px) { .allindianpatents-footer { width: 728px; height: 90px; } }
        </style>
        <center>
        </center>

        <p>&copy; All Indian Patents, 2013-2021.</p>
        <p>Patent data available in the public domain from Indian Patents Office, Department of Industrial Policy and Promotions, Ministry of Commerce and Industry, Government of India.</p>
      </footer>

    </div> <!-- /container -->

    <!-- Javascripts
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/application-95f297ff0d8d2015987f04b30593c800.js" type="text/javascript"></script>

    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=8902313; 
    var sc_invisible=1; 
    var sc_security="3c1f8147"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/8902313/0/3c1f8147/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-244143-31', 'allindianpatents.com');
      ga('send', 'pageview');

    </script>

  </body>

<!-- Mirrored from www.allindianpatents.com/patents/263378-image-input-apparatus-and-image-input-method-for-inputting-an-image-of-an-object-within-a-living-body by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 05 Apr 2024 01:08:09 GMT -->
</html>
